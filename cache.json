{"2024-06-24T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2406.16864v1","updated":"2024-06-24T17:59:58Z","published":"2024-06-24T17:59:58Z","title":"StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal","summary":"  This work addresses the challenge of high-quality surface normal estimation\nfrom monocular colored inputs (i.e., images and videos), a field which has\nrecently been revolutionized by repurposing diffusion priors. However, previous\nattempts still struggle with stochastic inference, conflicting with the\ndeterministic nature of the Image2Normal task, and costly ensembling step,\nwhich slows down the estimation process. Our method, StableNormal, mitigates\nthe stochasticity of the diffusion process by reducing inference variance, thus\nproducing \"Stable-and-Sharp\" normal estimates without any additional ensembling\nprocess. StableNormal works robustly under challenging imaging conditions, such\nas extreme lighting, blurring, and low quality. It is also robust against\ntransparent and reflective surfaces, as well as cluttered scenes with numerous\nobjects. Specifically, StableNormal employs a coarse-to-fine strategy, which\nstarts with a one-step normal estimator (YOSO) to derive an initial normal\nguess, that is relatively coarse but reliable, then followed by a\nsemantic-guided refinement process (SG-DRN) that refines the normals to recover\ngeometric details. The effectiveness of StableNormal is demonstrated through\ncompetitive performance in standard datasets such as DIODE-indoor, iBims,\nScannetV2 and NYUv2, and also in various downstream tasks, such as surface\nreconstruction and normal enhancement. These results evidence that StableNormal\nretains both the \"stability\" and \"sharpness\" for accurate normal estimation.\nStableNormal represents a baby attempt to repurpose diffusion priors for\ndeterministic estimation. To democratize this, code and models have been\npublicly available in hf.co/Stable-X\n","authors":["Chongjie Ye","Lingteng Qiu","Xiaodong Gu","Qi Zuo","Yushuang Wu","Zilong Dong","Liefeng Bo","Yuliang Xiu","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2406.16864v1.pdf","comment":"HF Demo: hf.co/Stable-X, Video:\n  https://www.youtube.com/watch?v=sylXTxG_U2U"},{"id":"http://arxiv.org/abs/2406.16853v1","updated":"2024-06-24T17:58:13Z","published":"2024-06-24T17:58:13Z","title":"GeoMFormer: A General Architecture for Geometric Molecular\n  Representation Learning","summary":"  Molecular modeling, a central topic in quantum mechanics, aims to accurately\ncalculate the properties and simulate the behaviors of molecular systems. The\nmolecular model is governed by physical laws, which impose geometric\nconstraints such as invariance and equivariance to coordinate rotation and\ntranslation. While numerous deep learning approaches have been developed to\nlearn molecular representations under these constraints, most of them are built\nupon heuristic and costly modules. We argue that there is a strong need for a\ngeneral and flexible framework for learning both invariant and equivariant\nfeatures. In this work, we introduce a novel Transformer-based molecular model\ncalled GeoMFormer to achieve this goal. Using the standard Transformer modules,\ntwo separate streams are developed to maintain and learn invariant and\nequivariant representations. Carefully designed cross-attention modules bridge\nthe two streams, allowing information fusion and enhancing geometric modeling\nin each stream. As a general and flexible architecture, we show that many\nprevious architectures can be viewed as special instantiations of GeoMFormer.\nExtensive experiments are conducted to demonstrate the power of GeoMFormer. All\nempirical results show that GeoMFormer achieves strong performance on both\ninvariant and equivariant tasks of different types and scales. Code and models\nwill be made publicly available at https://github.com/c-tl/GeoMFormer.\n","authors":["Tianlang Chen","Shengjie Luo","Di He","Shuxin Zheng","Tie-Yan Liu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16853v1.pdf","comment":"25 pages, 13 tables, l figure; ICML 2024 camera ready version"},{"id":"http://arxiv.org/abs/2406.16851v1","updated":"2024-06-24T17:58:03Z","published":"2024-06-24T17:58:03Z","title":"Losing Visual Needles in Image Haystacks: Vision Language Models are\n  Easily Distracted in Short and Long Contexts","summary":"  We present LoCoVQA, a dynamic benchmark generator for evaluating long-context\nextractive reasoning in vision language models (VLMs). LoCoVQA augments test\nexamples for mathematical reasoning, VQA, and character recognition tasks with\nincreasingly long visual contexts composed of both in-distribution and\nout-of-distribution distractor images.\n  Across these tasks, a diverse set of VLMs rapidly lose performance as the\nvisual context length grows, often exhibiting a striking exponential decay\ntrend. This test assesses how well VLMs can ignore irrelevant information when\nanswering queries -- a task that is quite easy for language models (LMs) in the\ntext domain -- demonstrating that current state-of-the-art VLMs lack this\nessential capability for many long-context applications.\n","authors":["Aditya Sharma","Michael Saxon","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16851v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16833v1","updated":"2024-06-24T17:41:53Z","published":"2024-06-24T17:41:53Z","title":"USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and\n  $\\underline{D}$ogmatism in Long $\\underline{C}$onversations","summary":"  Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].\n","authors":["Mounika Marreddy","Subba Reddy Oota","Venkata Charan Chinni","Manish Gupta","Lucie Flek"],"pdf_url":"https://arxiv.org/pdf/2406.16833v1.pdf","comment":"32 pages, 18 figures"},{"id":"http://arxiv.org/abs/2406.16829v1","updated":"2024-06-24T17:38:02Z","published":"2024-06-24T17:38:02Z","title":"Understanding and Mitigating Tokenization Bias in Language Models","summary":"  State-of-the-art language models are autoregressive and operate on subword\nunits known as tokens. Specifically, one must encode the conditioning string\ninto a list of tokens before passing to the language models for next-token\nprediction. We show that, for encoding schemes such as maximum prefix matching,\ntokenization induces a sampling bias that cannot be mitigated with more\ntraining or data. To counter this universal problem, we propose a novel\nalgorithm to obtain unbiased estimates from a model that was trained on\ntokenized data. Our method does not require finetuning the model, and its\ncomplexity, defined as the number of model runs, scales linearly with the\nsequence length. As a consequence, we show that one can simulate token-free\nbehavior from a tokenized language model. We empirically verify the correctness\nof our method through a Markov-chain setup, where it accurately recovers the\ntransition probabilities, as opposed to the conventional method of directly\nprompting tokens into the language model.\n","authors":["Buu Phan","Marton Havasi","Matthew Muckley","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2406.16829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16828v1","updated":"2024-06-24T17:37:52Z","published":"2024-06-24T17:37:52Z","title":"Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024\n  Retrieval-Augmented Generation Track","summary":"  Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we've\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI's\nGPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.\n","authors":["Ronak Pradeep","Nandan Thakur","Sahel Sharifymoghaddam","Eric Zhang","Ryan Nguyen","Daniel Campos","Nick Craswell","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2406.16828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16821v1","updated":"2024-06-24T17:31:41Z","published":"2024-06-24T17:31:41Z","title":"General Binding Affinity Guidance for Diffusion Models in\n  Structure-Based Drug Design","summary":"  Structure-Based Drug Design (SBDD) focuses on generating valid ligands that\nstrongly and specifically bind to a designated protein pocket. Several methods\nuse machine learning for SBDD to generate these ligands in 3D space,\nconditioned on the structure of a desired protein pocket. Recently, diffusion\nmodels have shown success here by modeling the underlying distributions of\natomic positions and types. While these methods are effective in considering\nthe structural details of the protein pocket, they often fail to explicitly\nconsider the binding affinity. Binding affinity characterizes how tightly the\nligand binds to the protein pocket, and is measured by the change in free\nenergy associated with the binding process. It is one of the most crucial\nmetrics for benchmarking the effectiveness of the interaction between a ligand\nand protein pocket. To address this, we propose BADGER: Binding Affinity\nDiffusion Guidance with Enhanced Refinement. BADGER is a general guidance\nmethod to steer the diffusion sampling process towards improved protein-ligand\nbinding, allowing us to adjust the distribution of the binding affinity between\nligands and proteins. Our method is enabled by using a neural network (NN) to\nmodel the energy function, which is commonly approximated by AutoDock Vina\n(ADV). ADV's energy function is non-differentiable, and estimates the affinity\nbased on the interactions between a ligand and target protein receptor. By\nusing a NN as a differentiable energy function proxy, we utilize the gradient\nof our learned energy function as a guidance method on top of any trained\ndiffusion model. We show that our method improves the binding affinity of\ngenerated ligands to their protein receptors by up to 60\\%, significantly\nsurpassing previous machine learning methods. We also show that our guidance\nmethod is flexible and can be easily applied to other diffusion-based SBDD\nframeworks.\n","authors":["Yue Jian","Curtis Wu","Danny Reidenbach","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2406.16821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16810v1","updated":"2024-06-24T17:22:36Z","published":"2024-06-24T17:22:36Z","title":"PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs","summary":"  Recently, machine unlearning, which seeks to erase specific data stored in\nthe pre-trained or fine-tuned models, has emerged as a crucial protective\nmeasure for LLMs. However, unlearning approaches for LLMs that have been\nconsidered thus far have focused on the removal of independent data points and\nhave not taken into account that the stored facts are logically connected to\none another and form an implicit knowledge graph. To facilitate the development\nof structural unlearning methods, which are essential for the practical\napplication of unlearning, we propose PISTOL, a pipeline for compiling\nmulti-scenario datasets for benchmarking structural LLM unlearning.\nAdditionally, leveraging sample datasets synthesized using PISTOL, we conducted\nbenchmarks with four distinct unlearning methods on both Llama2-7B and\nMistral-7B models. This analysis helps to illustrate the prevailing challenges\nin effectively and robustly removing highly inter-connected data, batched data,\nor data skewed towards a specific domain. It also highlights the choice of\npre-trained model can impact unlearning performance. This work not only\nadvances our understandings on the limitation of current LLMs unlearning\nmethods and proposes future research directions, but also provides a replicable\nframework for ongoing exploration and validation in the field.\n","authors":["Xinchi Qiu","William F. Shen","Yihong Chen","Nicola Cancedda","Pontus Stenetorp","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2406.16810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03287v2","updated":"2024-06-24T17:00:43Z","published":"2023-05-05T05:32:50Z","title":"Low-Resource Multi-Granularity Academic Function Recognition Based on\n  Multiple Prompt Knowledge","summary":"  Fine-tuning pre-trained language models (PLMs), e.g., SciBERT, generally\nrequires large numbers of annotated data to achieve state-of-the-art\nperformance on a range of NLP tasks in the scientific domain. However,\nobtaining the fine-tune data for scientific NLP task is still challenging and\nexpensive. Inspired by recent advancement in prompt learning, in this paper, we\npropose the Mix Prompt Tuning (MPT), which is a semi-supervised method to\nalleviate the dependence on annotated data and improve the performance of\nmulti-granularity academic function recognition tasks with a small number of\nlabeled examples. Specifically, the proposed method provides multi-perspective\nrepresentations by combining manual prompt templates with automatically learned\ncontinuous prompt templates to help the given academic function recognition\ntask take full advantage of knowledge in PLMs. Based on these prompt templates\nand the fine-tuned PLM, a large number of pseudo labels are assigned to the\nunlabeled examples. Finally, we fine-tune the PLM using the pseudo training\nset. We evaluate our method on three academic function recognition tasks of\ndifferent granularity including the citation function, the abstract sentence\nfunction, and the keyword function, with datasets from computer science domain\nand biomedical domain. Extensive experiments demonstrate the effectiveness of\nour method and statistically significant improvements against strong baselines.\nIn particular, it achieves an average increase of 5% in Macro-F1 score compared\nwith fine-tuning, and 6% in Macro-F1 score compared with other semi-supervised\nmethod under low-resource settings. In addition, MPT is a general method that\ncan be easily applied to other low-resource scientific classification tasks.\n","authors":["Jiawei Liu","Zi Xiong","Yi Jiang","Yongqiang Ma","Wei Lu","Yong Huang","Qikai Cheng"],"pdf_url":"https://arxiv.org/pdf/2305.03287v2.pdf","comment":"This article has been accepted by The Electronic Library and the full\n  article is now available on Emerald Insight"},{"id":"http://arxiv.org/abs/2406.16797v1","updated":"2024-06-24T16:58:23Z","published":"2024-06-24T16:58:23Z","title":"Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs","summary":"  Existing methods for adapting large language models (LLMs) to new tasks are\nnot suited to multi-task adaptation because they modify all the model weights\n-- causing destructive interference between tasks. The resulting effects, such\nas catastrophic forgetting of earlier tasks, make it challenging to obtain good\nperformance on multiple tasks at the same time. To mitigate this, we propose\nLottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies\nand optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide\nrange of challenging tasks such as instruction following, reasoning, math, and\nsummarization. LoTA obtains better performance than full fine-tuning and\nlow-rank adaptation (LoRA), and maintains good performance even after training\non other tasks -- thus, avoiding catastrophic forgetting. By extracting and\nfine-tuning over \\emph{lottery tickets} (or \\emph{sparse task vectors}), LoTA\nalso enables model merging over highly dissimilar tasks.\n","authors":["Ashwinee Panda","Berivan Isik","Xiangyu Qi","Sanmi Koyejo","Tsachy Weissman","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2406.16797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16793v1","updated":"2024-06-24T16:56:41Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the number of learning rates in Adam: Instead of assigning an\nindividual learning rate for each parameter using $1/\\sqrt{v}$, Adam-mini uses\nthe average of $v$ within a pre-defined parameter block as the learning rate\nfor that block. Such a design is inspired by two empirical findings. First, the\nHessian of Transformers exhibits a near-block diagonal structure with different\nsizes of dense sub-blocks. Second, for each of these dense sub-blocks, there\nexists a single high-quality learning rate that can outperform Adam, provided\nthat sufficient resources are available to search it out. Adam-mini provides\none cost-effective way to find these good learning rates and manage to cut down\n$\\geq 90% v$ in Adam. Empirically, we verify that Adam-mini performs on par or\nbetter than AdamW on various language models sized from 125M to 7B for\npre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of\nAdam-mini also alleviates communication overheads among GPUs and CPUs, thereby\nincreasing throughput. For instance, Adam-mini achieves 49.6% higher throughput\nthan AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16784v1","updated":"2024-06-24T16:45:28Z","published":"2024-06-24T16:45:28Z","title":"The Progression of Transformers from Language to Vision to MOT: A\n  Literature Review on Multi-Object Tracking with Transformers","summary":"  The transformer neural network architecture allows for autoregressive\nsequence-to-sequence modeling through the use of attention layers. It was\noriginally created with the application of machine translation but has\nrevolutionized natural language processing. Recently, transformers have also\nbeen applied across a wide variety of pattern recognition tasks, particularly\nin computer vision. In this literature review, we describe major advances in\ncomputer vision utilizing transformers. We then focus specifically on\nMulti-Object Tracking (MOT) and discuss how transformers are increasingly\nbecoming competitive in state-of-the-art MOT works, yet still lag behind\ntraditional deep learning methods.\n","authors":["Abhi Kamboj"],"pdf_url":"https://arxiv.org/pdf/2406.16784v1.pdf","comment":"This report was written in November 2022, and may not contain more\n  recent works since then"},{"id":"http://arxiv.org/abs/2406.16783v1","updated":"2024-06-24T16:45:13Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2402.16788v3","updated":"2024-06-24T16:41:30Z","published":"2024-02-26T18:01:41Z","title":"Why Transformers Need Adam: A Hessian Perspective","summary":"  SGD performs worse than Adam by a significant margin on Transformers, but the\nreason remains unclear. In this work, we provide an explanation through the\nlens of Hessian: (i) Transformers are \"heterogeneous\": the Hessian spectrum\nacross parameter blocks vary dramatically, a phenomenon we call \"block\nheterogeneity\"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam on\nproblems with block heterogeneity. To validate (i) and (ii), we check various\nTransformers, CNNs, MLPs, and quadratic problems, and find that SGD can perform\non par with Adam on problems without block heterogeneity, but performs worse\nthan Adam when the heterogeneity exists. Our initial theoretical analysis\nindicates that SGD performs worse because it applies one single learning rate\nto all blocks, which cannot handle the heterogeneity among blocks. This\nlimitation could be ameliorated if we use coordinate-wise learning rates, as\ndesigned in Adam.\n","authors":["Yushun Zhang","Congliang Chen","Tian Ding","Ziniu Li","Ruoyu Sun","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2402.16788v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16777v1","updated":"2024-06-24T16:38:17Z","published":"2024-06-24T16:38:17Z","title":"Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech\n  Translation System for IWSLT 2024","summary":"  Large Language Models (LLMs) are currently under exploration for various\ntasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),\nand even End-to-End Speech Translation (ST). In this paper, we present KIT's\noffline submission in the constrained + LLM track by incorporating recently\nproposed techniques that can be added to any cascaded speech translation.\nSpecifically, we integrate\nMistral-7B\\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to\nenhance it in two ways. Firstly, we refine the ASR outputs by utilizing the\nN-best lists generated by our system and fine-tuning the LLM to predict the\ntranscript accurately. Secondly, we refine the MT outputs at the document level\nby fine-tuning the LLM, leveraging both ASR and MT predictions to improve\ntranslation quality. We find that integrating the LLM into the ASR and MT\nsystems results in an absolute improvement of $0.3\\%$ in Word Error Rate and\n$0.65\\%$ in COMET for tst2019 test set. In challenging test sets with\noverlapping speakers and background noise, we find that integrating LLM is not\nbeneficial due to poor ASR performance. Here, we use ASR with chunked long-form\ndecoding to improve context usage that may be unavailable when transcribing\nwith Voice Activity Detection segmentation alone.\n","authors":["Sai Koneru","Thai-Binh Nguyen","Ngoc-Quan Pham","Danni Liu","Zhaolin Li","Alexander Waibel","Jan Niehues"],"pdf_url":"https://arxiv.org/pdf/2406.16777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16772v1","updated":"2024-06-24T16:31:12Z","published":"2024-06-24T16:31:12Z","title":"OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?","summary":"  In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).\n","authors":["Zhen Huang","Zengzhi Wang","Shijie Xia","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16772v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2406.16768v1","updated":"2024-06-24T16:24:34Z","published":"2024-06-24T16:24:34Z","title":"WARP: On the Benefits of Weight Averaged Rewarded Policies","summary":"  Reinforcement learning from human feedback (RLHF) aligns large language\nmodels (LLMs) by encouraging their generations to have high rewards, using a\nreward model trained on human preferences. To prevent the forgetting of\npre-trained knowledge, RLHF usually incorporates a KL regularization; this\nforces the policy to remain close to its supervised fine-tuned initialization,\nthough it hinders the reward optimization. To tackle the trade-off between KL\nand reward, in this paper we introduce a novel alignment strategy named Weight\nAveraged Rewarded Policies (WARP). WARP merges policies in the weight space at\nthree distinct stages. First, it uses the exponential moving average of the\npolicy as a dynamic anchor in the KL regularization. Second, it applies\nspherical interpolation to merge independently fine-tuned policies into a new\nenhanced one. Third, it linearly interpolates between this merged model and the\ninitialization, to recover features from pre-training. This procedure is then\napplied iteratively, with each iteration's final model used as an advanced\ninitialization for the next, progressively refining the KL-reward Pareto front,\nachieving superior rewards at fixed KL. Experiments with GEMMA policies\nvalidate that WARP improves their quality and alignment, outperforming other\nopen-source LLMs.\n","authors":["Alexandre Ramé","Johan Ferret","Nino Vieillard","Robert Dadashi","Léonard Hussenot","Pierre-Louis Cedoz","Pier Giuseppe Sessa","Sertan Girgin","Arthur Douillard","Olivier Bachem"],"pdf_url":"https://arxiv.org/pdf/2406.16768v1.pdf","comment":"11 main pages (34 pages with Appendix)"},{"id":"http://arxiv.org/abs/2406.15252v2","updated":"2024-06-24T16:22:55Z","published":"2024-06-21T15:43:46Z","title":"VideoScore: Building Automatic Metrics to Simulate Fine-grained Human\n  Feedback for Video Generation","summary":"  The recent years have witnessed great advances in video generation. However,\nthe development of automatic video metrics is lagging significantly behind.\nNone of the existing metric is able to provide reliable scores over generated\nvideos. The main barrier is the lack of large-scale human-annotated dataset. In\nthis paper, we release VideoFeedback, the first large-scale dataset containing\nhuman-provided multi-aspect score over 37.6K synthesized videos from 11\nexisting video generative models. We train VideoScore (initialized from Mantis)\nbased on VideoFeedback to enable automatic video quality assessment.\nExperiments show that the Spearman correlation between VideoScore and humans\ncan reach 77.1 on VideoFeedback-test, beating the prior best metrics by about\n50 points. Further result on other held-out EvalCrafter, GenAI-Bench, and\nVBench show that VideoScore has consistently much higher correlation with human\njudges than other metrics. Due to these results, we believe VideoScore can\nserve as a great proxy for human raters to (1) rate different video models to\ntrack progress (2) simulate fine-grained human feedback in Reinforcement\nLearning with Human Feedback (RLHF) to improve current video generation models.\n","authors":["Xuan He","Dongfu Jiang","Ge Zhang","Max Ku","Achint Soni","Sherman Siu","Haonan Chen","Abhranil Chandra","Ziyan Jiang","Aaran Arulraj","Kai Wang","Quy Duc Do","Yuansheng Ni","Bohan Lyu","Yaswanth Narsupalli","Rongqi Fan","Zhiheng Lyu","Yuchen Lin","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.15252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17012v3","updated":"2024-06-24T16:18:45Z","published":"2024-02-26T20:41:50Z","title":"Pandora's White-Box: Precise Training Data Detection and Extraction in\n  Large Language Models","summary":"  In this paper we develop state-of-the-art privacy attacks against Large\nLanguage Models (LLMs), where an adversary with some access to the model tries\nto learn something about the underlying training data. Our headline results are\nnew membership inference attacks (MIAs) against pretrained LLMs that perform\nhundreds of times better than baseline attacks, and a pipeline showing that\nover 50% (!) of the fine-tuning dataset can be extracted from a fine-tuned LLM\nin natural settings. We consider varying degrees of access to the underlying\nmodel, pretraining and fine-tuning data, and both MIAs and training data\nextraction. For pretraining data, we propose two new MIAs: a supervised neural\nnetwork classifier that predicts training data membership on the basis of\n(dimensionality-reduced) model gradients, as well as a variant of this attack\nthat only requires logit access to the model by leveraging recent\nmodel-stealing work on LLMs. To our knowledge this is the first MIA that\nexplicitly incorporates model-stealing information. Both attacks outperform\nexisting black-box baselines, and our supervised attack closes the gap between\nMIA attack success against LLMs and the strongest known attacks for other\nmachine learning models. In fine-tuning, we find that a simple attack based on\nthe ratio of the loss between the base and fine-tuned models is able to achieve\nnear-perfect MIA performance; we then leverage our MIA to extract a large\nfraction of the fine-tuning dataset from fine-tuned Pythia and Llama models.\nOur code is available at github.com/safr-ai-lab/pandora-llm.\n","authors":["Jeffrey G. Wang","Jason Wang","Marvin Li","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2402.17012v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09246v3","updated":"2024-06-24T16:06:50Z","published":"2024-02-14T15:34:38Z","title":"Who Plays First? Optimizing the Order of Play in Stackelberg Games with\n  Many Robots","summary":"  We consider the multi-agent spatial navigation problem of computing the\nsocially optimal order of play, i.e., the sequence in which the agents commit\nto their decisions, and its associated equilibrium in an N-player Stackelberg\ntrajectory game. We model this problem as a mixed-integer optimization problem\nover the space of all possible Stackelberg games associated with the order of\nplay's permutations. To solve the problem, we introduce Branch and Play (B&P),\nan efficient and exact algorithm that provably converges to a socially optimal\norder of play and its Stackelberg equilibrium. As a subroutine for B&P, we\nemploy and extend sequential trajectory planning, i.e., a popular multi-agent\ncontrol approach, to scalably compute valid local Stackelberg equilibria for\nany given order of play. We demonstrate the practical utility of B&P to\ncoordinate air traffic control, swarm formation, and delivery vehicle fleets.\nWe find that B&P consistently outperforms various baselines, and computes the\nsocially optimal equilibrium.\n","authors":["Haimin Hu","Gabriele Dragotto","Zixu Zhang","Kaiqu Liang","Bartolomeo Stellato","Jaime F. Fisac"],"pdf_url":"https://arxiv.org/pdf/2402.09246v3.pdf","comment":"Robotics: Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2406.16756v1","updated":"2024-06-24T16:03:57Z","published":"2024-06-24T16:03:57Z","title":"Addressing Polarization and Unfairness in Performative Prediction","summary":"  When machine learning (ML) models are used in applications that involve\nhumans (e.g., online recommendation, school admission, hiring, lending), the\nmodel itself may trigger changes in the distribution of targeted data it aims\nto predict. Performative prediction (PP) is a framework that explicitly\nconsiders such model-dependent distribution shifts when learning ML models.\nWhile significant efforts have been devoted to finding performative stable (PS)\nsolutions in PP for system robustness, their societal implications are less\nexplored and it is unclear whether PS solutions are aligned with social norms\nsuch as fairness. In this paper, we set out to examine the fairness property of\nPS solutions in performative prediction. We first show that PS solutions can\nincur severe polarization effects and group-wise loss disparity. Although\nexisting fairness mechanisms commonly used in literature can help mitigate\nunfairness, they may fail and disrupt the stability under model-dependent\ndistribution shifts. We thus propose novel fairness intervention mechanisms\nthat can simultaneously achieve both stability and fairness in PP settings.\nBoth theoretical analysis and experiments are provided to validate the proposed\nmethod.\n","authors":["Kun Jin","Tian Xie","Yang Liu","Xueru Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16746v1","updated":"2024-06-24T15:55:49Z","published":"2024-06-24T15:55:49Z","title":"The Responsible Foundation Model Development Cheatsheet: A Review of\n  Tools & Resources","summary":"  Foundation model development attracts a rapidly expanding body of\ncontributors, scientists, and applications. To help shape responsible\ndevelopment practices, we introduce the Foundation Model Development\nCheatsheet: a growing collection of 250+ tools and resources spanning text,\nvision, and speech modalities. We draw on a large body of prior work to survey\nresources (e.g. software, documentation, frameworks, guides, and practical\ntools) that support informed data selection, processing, and understanding,\nprecise and limitation-aware artifact documentation, efficient model training,\nadvance awareness of the environmental impact from training, careful model\nevaluation of capabilities, risks, and claims, as well as responsible model\nrelease, licensing and deployment practices. We hope this curated collection of\nresources helps guide more responsible development. The process of curating\nthis list, enabled us to review the AI development ecosystem, revealing what\ntools are critically missing, misused, or over-used in existing practices. We\nfind that (i) tools for data sourcing, model evaluation, and monitoring are\ncritically under-serving ethical and real-world needs, (ii) evaluations for\nmodel safety, capabilities, and environmental impact all lack reproducibility\nand transparency, (iii) text and particularly English-centric analyses continue\nto dominate over multilingual and multi-modal analyses, and (iv) evaluation of\nsystems, rather than just models, is needed so that capabilities and impact are\nassessed in context.\n","authors":["Shayne Longpre","Stella Biderman","Alon Albalak","Hailey Schoelkopf","Daniel McDuff","Sayash Kapoor","Kevin Klyman","Kyle Lo","Gabriel Ilharco","Nay San","Maribeth Rauh","Aviya Skowron","Bertie Vidgen","Laura Weidinger","Arvind Narayanan","Victor Sanh","David Adelani","Percy Liang","Rishi Bommasani","Peter Henderson","Sasha Luccioni","Yacine Jernite","Luca Soldaini"],"pdf_url":"https://arxiv.org/pdf/2406.16746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05271v3","updated":"2024-06-24T15:55:34Z","published":"2024-02-07T21:31:53Z","title":"Feature learning as alignment: a structural property of gradient descent\n  in non-linear neural networks","summary":"  Understanding the mechanisms through which neural networks extract statistics\nfrom input-label pairs through feature learning is one of the most important\nunsolved problems in supervised learning. Prior works demonstrated that the\ngram matrices of the weights (the neural feature matrices, NFM) and the average\ngradient outer products (AGOP) become correlated during training, in a\nstatement known as the neural feature ansatz (NFA). Through the NFA, the\nauthors introduce mapping with the AGOP as a general mechanism for neural\nfeature learning. However, these works do not provide a theoretical explanation\nfor this correlation or its origins. In this work, we further clarify the\nnature of this correlation, and explain its emergence. We show that this\ncorrelation is equivalent to alignment between the left singular structure of\nthe weight matrices and the newly defined pre-activation tangent features at\neach layer. We further establish that the alignment is driven by the\ninteraction of weight changes induced by SGD with the pre-activation features,\nand analyze the resulting dynamics analytically at early times in terms of\nsimple statistics of the inputs and labels. Finally, motivated by the\nobservation that the NFA is driven by this centered correlation, we introduce a\nsimple optimization rule that dramatically increases the NFA correlations at\nany given layer and improves the quality of features learned.\n","authors":["Daniel Beaglehole","Ioannis Mitliagkas","Atish Agarwala"],"pdf_url":"https://arxiv.org/pdf/2402.05271v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16745v1","updated":"2024-06-24T15:53:11Z","published":"2024-06-24T15:53:11Z","title":"Bandits with Preference Feedback: A Stackelberg Game Perspective","summary":"  Bandits with preference feedback present a powerful tool for optimizing\nunknown target functions when only pairwise comparisons are allowed instead of\ndirect value queries. This model allows for incorporating human feedback into\nonline inference and optimization and has been employed in systems for\nfine-tuning large language models. The problem is well understood in simplified\nsettings with linear target functions or over finite small domains that limit\npractical interest. Taking the next step, we consider infinite domains and\nnonlinear (kernelized) rewards. In this setting, selecting a pair of actions is\nquite challenging and requires balancing exploration and exploitation at two\nlevels: within the pair, and along the iterations of the algorithm. We propose\nMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and\nchooses action pairs that are informative and yield favorable rewards.\nMAXMINLCB consistently outperforms existing algorithms and satisfies an\nanytime-valid rate-optimal regret guarantee. This is due to our novel\npreference-based confidence sequences for kernelized logistic estimators.\n","authors":["Barna Pásztor","Parnian Kassraie","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2406.16745v1.pdf","comment":"30 pages, 8 figures"},{"id":"http://arxiv.org/abs/2406.05673v2","updated":"2024-06-24T15:49:09Z","published":"2024-06-09T07:06:58Z","title":"Flow of Reasoning: Efficient Training of LLM Policy with Divergent\n  Thinking","summary":"  Divergent thinking, the cognitive process of generating diverse solutions, is\na hallmark of human creativity and problem-solving. For machines, sampling\ndiverse solution trajectories in complex reasoning problems is crucial for\nrobust outcomes, data augmentation, and enhanced model generalization. Large\nlanguage models (LLMs) often struggle with generating high-quality, diverse\nreasoning. While supervised fine-tuning helps with quality, it requires\nextensive supervision data to capture the full diversity of solutions.\nAlternatively, reinforcement learning methods like PPO aim to find limited\nhighest-reward solutions while neglecting the solution diversity, akin to\nconvergent thinking. To address these limitations, we propose Flow of Reasoning\n(FoR) -- an efficient LLM training approach enabling diverse reasoning with\nminimal data. FoR formulates multi-step LLM reasoning as a Markovian flow from\nan initial state to terminal states. The formulation allows to adapt principled\nGFlowNet approaches to train the LLM as a policy, which is able to sample\nmultiple reasoning paths with probabilities proportional to the unnormalized\nreward. Empirical results show that, with limited training data (e.g., 15\nexamples), FoR can discover diverse high-quality solutions that excel greatly\nbeyond current state-of-the-art methods across three tasks, including embodied\nreasoning (BlocksWorld), math puzzle solving (Game24), and logical reasoning\n(PrOntoQA). Code is available at https://github.com/Yu-Fangxu/FoR.\n","authors":["Fangxu Yu","Lai Jiang","Haoqiang Kang","Shibo Hao","Lianhui Qin"],"pdf_url":"https://arxiv.org/pdf/2406.05673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16741v1","updated":"2024-06-24T15:48:19Z","published":"2024-06-24T15:48:19Z","title":"Extracting thin film structures of energy materials using transformers","summary":"  Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),\na neural network model using transformer architecture, is introduced for\nneutron reflectometry data analysis. It offers fast, accurate initial parameter\nestimations and efficient refinements, improving efficiency and precision for\nreal-time data analysis of lithium-mediated nitrogen reduction for\nelectrochemical ammonia synthesis, with relevance to other chemical\ntransformations and batteries. Despite limitations in generalizing across\nsystems, it shows promises for the use of transformers as the basis for models\nthat could replace trial-and-error approaches to modeling reflectometry data.\n","authors":["Chen Zhang","Valerie A. Niemann","Peter Benedek","Thomas F. Jaramillo","Mathieu Doucet"],"pdf_url":"https://arxiv.org/pdf/2406.16741v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.16738v1","updated":"2024-06-24T15:45:20Z","published":"2024-06-24T15:45:20Z","title":"Inducing Group Fairness in LLM-Based Decisions","summary":"  Prompting Large Language Models (LLMs) has created new and interesting means\nfor classifying textual data. While evaluating and remediating group fairness\nis a well-studied problem in classifier fairness literature, some classical\napproaches (e.g., regularization) do not carry over, and some new opportunities\narise (e.g., prompt-based remediation). We measure fairness of LLM-based\nclassifiers on a toxicity classification task, and empirically show that\nprompt-based classifiers may lead to unfair decisions. We introduce several\nremediation techniques and benchmark their fairness and performance trade-offs.\nWe hope our work encourages more research on group fairness in LLM-based\nclassifiers.\n","authors":["James Atwood","Preethi Lahoti","Ananth Balashankar","Flavien Prost","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2406.16738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00435v2","updated":"2024-06-24T15:42:52Z","published":"2024-02-01T09:01:58Z","title":"A practical existence theorem for reduced order models based on\n  convolutional autoencoders","summary":"  In recent years, deep learning has gained increasing popularity in the fields\nof Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM),\nproviding domain practitioners with new powerful data-driven techniques such as\nPhysics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator\nNetworks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context,\ndeep autoencoders based on Convolutional Neural Networks (CNNs) have proven\nextremely effective, outperforming established techniques, such as the reduced\nbasis method, when dealing with complex nonlinear problems. However, despite\nthe empirical success of CNN-based autoencoders, there are only a few\ntheoretical results supporting these architectures, usually stated in the form\nof universal approximation theorems. In particular, although the existing\nliterature provides users with guidelines for designing convolutional\nautoencoders, the subsequent challenge of learning the latent features has been\nbarely investigated. Furthermore, many practical questions remain unanswered,\ne.g., the number of snapshots needed for convergence or the neural network\ntraining strategy. In this work, using recent techniques from sparse\nhigh-dimensional function approximation, we fill some of these gaps by\nproviding a new practical existence theorem for CNN-based autoencoders when the\nparameter-to-solution map is holomorphic. This regularity assumption arises in\nmany relevant classes of parametric PDEs, such as the parametric diffusion\nequation, for which we discuss an explicit application of our general theory.\n","authors":["Nicola Rares Franco","Simone Brugiapaglia"],"pdf_url":"https://arxiv.org/pdf/2402.00435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14469v2","updated":"2024-06-24T15:40:40Z","published":"2024-06-20T16:32:18Z","title":"Fusion of Movement and Naive Predictions for Point Forecasting in\n  Univariate Random Walks","summary":"  Traditional methods for point forecasting in univariate random walks often\nfail to surpass naive benchmarks due to data unpredictability. This study\nintroduces a novel forecasting method that fuses movement prediction (binary\nclassification) with naive forecasts for accurate one-step-ahead point\nforecasting. The method's efficacy is demonstrated through theoretical\nanalysis, simulations, and real-world data experiments. It reliably exceeds\nnaive forecasts with movement prediction accuracies as low as 0.55,\noutperforming baseline models like ARIMA, linear regression, MLP, and LSTM\nnetworks in forecasting the S\\&P 500 index and Bitcoin prices. This method is\nparticularly advantageous when accurate point predictions are challenging but\naccurate movement predictions are attainable, translating movement predictions\ninto point forecasts in random walk contexts.\n","authors":["Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.14469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04233v2","updated":"2024-06-24T15:39:17Z","published":"2024-06-06T16:31:47Z","title":"FairytaleQA Translated: Enabling Educational Question and Answer\n  Generation in Less-Resourced Languages","summary":"  Question Answering (QA) datasets are crucial in assessing reading\ncomprehension skills for both machines and humans. While numerous datasets have\nbeen developed in English for this purpose, a noticeable void exists in\nless-resourced languages. To alleviate this gap, our paper introduces\nmachine-translated versions of FairytaleQA, a renowned QA dataset designed to\nassess and enhance narrative comprehension skills in young children. By\nemploying fine-tuned, modest-scale models, we establish benchmarks for both\nQuestion Generation (QG) and QA tasks within the translated datasets. In\naddition, we present a case study proposing a model for generating\nquestion-answer pairs, with an evaluation incorporating quality metrics such as\nquestion well-formedness, answerability, relevance, and children suitability.\nOur evaluation prioritizes quantifying and describing error cases, along with\nproviding directions for future work. This paper contributes to the advancement\nof QA and QG research in less-resourced languages, promoting accessibility and\ninclusivity in the development of these models for reading comprehension. The\ncode and data is publicly available at\ngithub.com/bernardoleite/fairytaleqa-translated.\n","authors":["Bernardo Leite","Tomás Freitas Osório","Henrique Lopes Cardoso"],"pdf_url":"https://arxiv.org/pdf/2406.04233v2.pdf","comment":"Preprint - Accepted for publication at ECTEL 2024"},{"id":"http://arxiv.org/abs/2406.16730v1","updated":"2024-06-24T15:35:51Z","published":"2024-06-24T15:35:51Z","title":"Convolutional neural network for Lyman break galaxies classification and\n  redshift regression in DESI (Dark Energy Spectroscopic Instrument)","summary":"  DESI is a groundbreaking international project to observe more than 40\nmillion quasars and galaxies over a 5-year period to create a 3D map of the\nsky. This map will enable us to probe multiple aspects of cosmology, from dark\nenergy to neutrino mass. We are focusing here on one type of object observed by\nDESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to\ndetermine whether they are indeed LBGs, and if so, to determine their distance\nfrom the Earth using a phenomenon called redshift. This will enable us to place\nthese galaxies on the DESI 3D map.\n  The aim is therefore to develop a convolutional neural network (CNN) inspired\nby QuasarNET (See arXiv:1808.09955), performing simultaneously a classification\n(LBG type or not) and a regression task (determine the redshift of the LBGs).\nInitially, data augmentation techniques such as shifting the spectra in\nwavelengths, adding noise to the spectra, or adding synthetic spectra were used\nto increase the model training dataset from 3,019 data to over 66,000. In a\nsecond phase, modifications to the QuasarNET architecture, notably through\ntransfer learning and hyperparameter tuning with Bayesian optimization, boosted\nmodel performance.\n  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is\nused to evaluate model performance, particularly in areas with interesting\nredshifts, at low (around 2) and high (around 4) redshifts. The best model\nobtained an average score of 94%, compared with 75% for the initial model.\n","authors":["Julien Taran"],"pdf_url":"https://arxiv.org/pdf/2406.16730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.10253v3","updated":"2024-06-24T15:34:17Z","published":"2023-09-19T02:19:48Z","title":"GPTFUZZER: Red Teaming Large Language Models with Auto-Generated\n  Jailbreak Prompts","summary":"  Large language models (LLMs) have recently experienced tremendous popularity\nand are widely used from casual conversations to AI-driven programming.\nHowever, despite their considerable success, LLMs are not entirely reliable and\ncan give detailed guidance on how to conduct harmful or illegal activities.\nWhile safety measures can reduce the risk of such outputs, adversarial\njailbreak attacks can still exploit LLMs to produce harmful content. These\njailbreak templates are typically manually crafted, making large-scale testing\nchallenging.\n  In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzing\nframework inspired by the AFL fuzzing framework. Instead of manual engineering,\nGPTFuzz automates the generation of jailbreak templates for red-teaming LLMs.\nAt its core, GPTFuzz starts with human-written templates as initial seeds, then\nmutates them to produce new templates. We detail three key components of\nGPTFuzz: a seed selection strategy for balancing efficiency and variability,\nmutate operators for creating semantically equivalent or similar sentences, and\na judgment model to assess the success of a jailbreak attack.\n  We evaluate GPTFuzz against various commercial and open-source LLMs,\nincluding ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Our\nresults indicate that GPTFuzz consistently produces jailbreak templates with a\nhigh success rate, surpassing human-crafted templates. Remarkably, GPTFuzz\nachieves over 90% attack success rates against ChatGPT and Llama-2 models, even\nwith suboptimal initial seed templates. We anticipate that GPTFuzz will be\ninstrumental for researchers and practitioners in examining LLM robustness and\nwill encourage further exploration into enhancing LLM safety.\n","authors":["Jiahao Yu","Xingwei Lin","Zheng Yu","Xinyu Xing"],"pdf_url":"https://arxiv.org/pdf/2309.10253v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16728v1","updated":"2024-06-24T15:33:47Z","published":"2024-06-24T15:33:47Z","title":"CausalMMM: Learning Causal Structure for Marketing Mix Modeling","summary":"  In online advertising, marketing mix modeling (MMM) is employed to predict\nthe gross merchandise volume (GMV) of brand shops and help decision-makers to\nadjust the budget allocation of various advertising channels. Traditional MMM\nmethods leveraging regression techniques can fail in handling the complexity of\nmarketing. Although some efforts try to encode the causal structures for better\nprediction, they have the strict restriction that causal structures are\nprior-known and unchangeable. In this paper, we define a new causal MMM problem\nthat automatically discovers the interpretable causal structures from data and\nyields better GMV predictions. To achieve causal MMM, two essential challenges\nshould be addressed: (1) Causal Heterogeneity. The causal structures of\ndifferent kinds of shops vary a lot. (2) Marketing Response Patterns. Various\nmarketing response patterns i.e., carryover effect and shape effect, have been\nvalidated in practice. We argue that causal MMM needs dynamically discover\nspecific causal structures for different shops and the predictions should\ncomply with the prior known marketing response patterns. Thus, we propose\nCausalMMM that integrates Granger causality in a variational inference\nframework to measure the causal relationships between different channels and\npredict the GMV with the regularization of both temporal and saturation\nmarketing response patterns. Extensive experiments show that CausalMMM can not\nonly achieve superior performance of causal structure learning on synthetic\ndatasets with improvements of 5.7%\\sim 7.1%, but also enhance the GMV\nprediction results on a representative E-commerce platform.\n","authors":["Chang Gong","Di Yao","Lei Zhang","Sheng Chen","Wenbin Li","Yueyang Su","Jingping Bi"],"pdf_url":"https://arxiv.org/pdf/2406.16728v1.pdf","comment":"WSDM 2024, full version"},{"id":"http://arxiv.org/abs/2406.16714v1","updated":"2024-06-24T15:16:45Z","published":"2024-06-24T15:16:45Z","title":"AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models","summary":"  Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.\n","authors":["Jiale Cheng","Yida Lu","Xiaotao Gu","Pei Ke","Xiao Liu","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16707v1","updated":"2024-06-24T15:09:22Z","published":"2024-06-24T15:09:22Z","title":"Probabilistic Subgoal Representations for Hierarchical Reinforcement\n  learning","summary":"  In goal-conditioned hierarchical reinforcement learning (HRL), a high-level\npolicy specifies a subgoal for the low-level policy to reach. Effective HRL\nhinges on a suitable subgoal represen tation function, abstracting state space\ninto latent subgoal space and inducing varied low-level behaviors. Existing\nmethods adopt a subgoal representation that provides a deterministic mapping\nfrom state space to latent subgoal space. Instead, this paper utilizes Gaussian\nProcesses (GPs) for the first probabilistic subgoal representation. Our method\nemploys a GP prior on the latent subgoal space to learn a posterior\ndistribution over the subgoal representation functions while exploiting the\nlong-range correlation in the state space through learnable kernels. This\nenables an adaptive memory that integrates long-range subgoal information from\nprior planning steps allowing to cope with stochastic uncertainties.\nFurthermore, we propose a novel learning objective to facilitate the\nsimultaneous learning of probabilistic subgoal representations and policies\nwithin a unified framework. In experiments, our approach outperforms\nstate-of-the-art baselines in standard benchmarks but also in environments with\nstochastic elements and under diverse reward conditions. Additionally, our\nmodel shows promising capabilities in transferring low-level policies across\ndifferent tasks.\n","authors":["Vivienne Huiling Wang","Tinghuai Wang","Wenyan Yang","Joni-Kristian Kämäräinen","Joni Pajarinen"],"pdf_url":"https://arxiv.org/pdf/2406.16707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11433v2","updated":"2024-06-24T15:03:52Z","published":"2023-09-20T16:10:53Z","title":"A Systematic Review of Few-Shot Learning in Medical Imaging","summary":"  The lack of annotated medical images limits the performance of deep learning\nmodels, which usually need large-scale labelled datasets. Few-shot learning\ntechniques can reduce data scarcity issues and enhance medical image analysis,\nespecially with meta-learning. This systematic review gives a comprehensive\noverview of few-shot learning in medical imaging. We searched the literature\nsystematically and selected 80 relevant articles published from 2018 to 2023.\nWe clustered the articles based on medical outcomes, such as tumour\nsegmentation, disease classification, and image registration; anatomical\nstructure investigated (i.e. heart, lung, etc.); and the meta-learning method\nused. For each cluster, we examined the papers' distributions and the results\nprovided by the state-of-the-art. In addition, we identified a generic pipeline\nshared among all the studies. The review shows that few-shot learning can\novercome data scarcity in most outcomes and that meta-learning is a popular\nchoice to perform few-shot learning because it can adapt to new tasks with few\nlabelled samples. In addition, following meta-learning, supervised learning and\nsemi-supervised learning stand out as the predominant techniques employed to\ntackle few-shot learning challenges in medical imaging and also best\nperforming. Lastly, we observed that the primary application areas\npredominantly encompass cardiac, pulmonary, and abdominal domains. This\nsystematic review aims to inspire further research to improve medical image\nanalysis and patient care.\n","authors":["Eva Pachetti","Sara Colantonio"],"pdf_url":"https://arxiv.org/pdf/2309.11433v2.pdf","comment":"48 pages, 29 figures, 10 tables, submitted to Elsevier on 19 Sep 2023"},{"id":"http://arxiv.org/abs/2406.16697v1","updated":"2024-06-24T15:00:59Z","published":"2024-06-24T15:00:59Z","title":"Expected Runtime Comparisons Between Breadth-First Search and\n  Constant-Depth Restarting Random Walks","summary":"  When greedy search algorithms encounter a local minima or plateau, the search\ntypically devolves into a breadth-first search (BrFS), or a local search\ntechnique is used in an attempt to find a way out. In this work, we formally\nanalyze the performance of BrFS and constant-depth restarting random walks\n(RRW) -- two methods often used for finding exits to a plateau/local minima --\nto better understand when each is best suited. In particular, we formally\nderive the expected runtime for BrFS in the case of a uniformly distributed set\nof goals at a given goal depth. We then prove RRW will be faster than BrFS on\ntrees if there are enough goals at that goal depth. We refer to this threshold\nas the crossover point. Our bound shows that the crossover point grows linearly\nwith the branching factor of the tree, the goal depth, and the error in the\nrandom walk depth, while the size of the tree grows exponentially in branching\nfactor and goal depth. Finally, we discuss the practical implications and\napplicability of this bound.\n","authors":["Daniel Platnick","Richard Anthony Valenzano"],"pdf_url":"https://arxiv.org/pdf/2406.16697v1.pdf","comment":"ICAPS 2024 Heuristics and Search for Domain-Independent Planning\n  Workshop, 5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.16696v1","updated":"2024-06-24T15:00:01Z","published":"2024-06-24T15:00:01Z","title":"Public Constitutional AI","summary":"  We are increasingly subjected to the power of AI authorities. As AI decisions\nbecome inescapable, entering domains such as healthcare, education, and law, we\nmust confront a vital question: how can we ensure AI systems have the\nlegitimacy necessary for effective governance? This essay argues that to secure\nAI legitimacy, we need methods that engage the public in designing and\nconstraining AI systems, ensuring these technologies reflect the community's\nshared values. Constitutional AI, proposed by Anthropic, represents a step\ntowards this goal, offering a model for democratic control of AI. However,\nwhile Constitutional AI's commitment to hardcoding explicit principles into AI\nmodels enhances transparency and accountability, it falls short in two crucial\naspects: addressing the opacity of individual AI decisions and fostering\ngenuine democratic legitimacy. To overcome these limitations, this essay\nproposes \"Public Constitutional AI.\" This approach envisions a participatory\nprocess where diverse stakeholders, including ordinary citizens, deliberate on\nthe principles guiding AI development. The resulting \"AI Constitution\" would\ncarry the legitimacy of popular authorship, grounding AI governance in the\npublic will. Furthermore, the essay proposes \"AI Courts\" to develop \"AI case\nlaw,\" providing concrete examples for operationalizing constitutional\nprinciples in AI training. This evolving combination of constitutional\nprinciples and case law aims to make AI governance more responsive to public\nvalues. By grounding AI governance in deliberative democratic processes, Public\nConstitutional AI offers a path to imbue automated authorities with genuine\ndemocratic legitimacy, addressing the unique challenges posed by increasingly\npowerful AI systems while ensuring their alignment with the public interest.\n","authors":["Gilad Abiri"],"pdf_url":"https://arxiv.org/pdf/2406.16696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14903v2","updated":"2024-06-24T14:57:18Z","published":"2024-06-21T06:50:42Z","title":"GIEBench: Towards Holistic Evaluation of Group Identity-based Empathy\n  for Large Language Models","summary":"  As large language models (LLMs) continue to develop and gain widespread\napplication, the ability of LLMs to exhibit empathy towards diverse group\nidentities and understand their perspectives is increasingly recognized as\ncritical. Most existing benchmarks for empathy evaluation of LLMs focus\nprimarily on universal human emotions, such as sadness and pain, often\noverlooking the context of individuals' group identities. To address this gap,\nwe introduce GIEBench, a comprehensive benchmark that includes 11 identity\ndimensions, covering 97 group identities with a total of 999 single-choice\nquestions related to specific group identities. GIEBench is designed to\nevaluate the empathy of LLMs when presented with specific group identities such\nas gender, age, occupation, and race, emphasizing their ability to respond from\nthe standpoint of the identified group. This supports the ongoing development\nof empathetic LLM applications tailored to users with different identities. Our\nevaluation of 23 LLMs revealed that while these LLMs understand different\nidentity standpoints, they fail to consistently exhibit equal empathy across\nthese identities without explicit instructions to adopt those perspectives.\nThis highlights the need for improved alignment of LLMs with diverse values to\nbetter accommodate the multifaceted nature of human identities. Our datasets\nare available at https://github.com/GIEBench/GIEBench.\n","authors":["Leyan Wang","Yonggang Jin","Tianhao Shen","Tianyu Zheng","Xinrun Du","Chenchen Zhang","Wenhao Huang","Jiaheng Liu","Shi Wang","Ge Zhang","Liuyu Xiang","Zhaofeng He"],"pdf_url":"https://arxiv.org/pdf/2406.14903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.19361v2","updated":"2024-06-24T14:48:29Z","published":"2024-02-29T17:12:39Z","title":"Watermark Stealing in Large Language Models","summary":"  LLM watermarking has attracted attention as a promising way to detect\nAI-generated content, with some works suggesting that current schemes may\nalready be fit for deployment. In this work we dispute this claim, identifying\nwatermark stealing (WS) as a fundamental vulnerability of these schemes. We\nshow that querying the API of the watermarked LLM to approximately\nreverse-engineer a watermark enables practical spoofing attacks, as\nhypothesized in prior work, but also greatly boosts scrubbing attacks, which\nwas previously unnoticed. We are the first to propose an automated WS algorithm\nand use it in the first comprehensive study of spoofing and scrubbing in\nrealistic settings. We show that for under $50 an attacker can both spoof and\nscrub state-of-the-art schemes previously considered safe, with average success\nrate of over 80%. Our findings challenge common beliefs about LLM watermarking,\nstressing the need for more robust schemes. We make all our code and additional\nexamples available at https://watermark-stealing.org.\n","authors":["Nikola Jovanović","Robin Staab","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2402.19361v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.16687v1","updated":"2024-06-24T14:46:34Z","published":"2024-06-24T14:46:34Z","title":"Link Prediction with Untrained Message Passing Layers","summary":"  Message passing neural networks (MPNNs) operate on graphs by exchanging\ninformation between neigbouring nodes. MPNNs have been successfully applied to\nvarious node-, edge-, and graph-level tasks in areas like molecular science,\ncomputer vision, natural language processing, and combinatorial optimization.\nHowever, most MPNNs require training on large amounts of labeled data, which\ncan be costly and time-consuming. In this work, we explore the use of various\nuntrained message passing layers in graph neural networks, i.e. variants of\npopular message passing architecture where we remove all trainable parameters\nthat are used to transform node features in the message passing step. Focusing\non link prediction, we find that untrained message passing layers can lead to\ncompetitive and even superior performance compared to fully trained MPNNs,\nespecially in the presence of high-dimensional features. We provide a\ntheoretical analysis of untrained message passing by relating the inner\nproducts of features implicitly produced by untrained message passing layers to\npath-based topological node similarity measures. As such, untrained message\npassing architectures can be viewed as a highly efficient and interpretable\napproach to link prediction.\n","authors":["Lisi Qarkaxhija","Anatol E. Wegner","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2406.16687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16678v1","updated":"2024-06-24T14:36:11Z","published":"2024-06-24T14:36:11Z","title":"Segment Any Text: A Universal Approach for Robust, Efficient and\n  Adaptable Sentence Segmentation","summary":"  Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.\n","authors":["Markus Frohmann","Igor Sterner","Ivan Vulić","Benjamin Minixhofer","Markus Schedl"],"pdf_url":"https://arxiv.org/pdf/2406.16678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16672v1","updated":"2024-06-24T14:27:54Z","published":"2024-06-24T14:27:54Z","title":"CAVE: Controllable Authorship Verification Explanations","summary":"  Authorship Verification (AV) (do two documents have the same author?) is\nessential for many sensitive real-life applications. AV is often used in\nproprietary domains that require a private, offline model, making SOTA online\nmodels like ChatGPT undesirable. Other SOTA systems use methods, e.g. Siamese\nNetworks, that are uninterpretable, and hence cannot be trusted in high-stakes\napplications. In this work, we take the first step to address the above\nchallenges with our model CAVE (Controllable Authorship Verification\nExplanations): CAVE generates free-text AV explanations that are controlled to\nbe 1) structured (can be decomposed into sub-explanations with respect to\nrelevant linguistic features), and 2) easily verified for explanation-label\nconsistency (via intermediate labels in sub-explanations). In this work, we\ntrain a Llama-3-8B as CAVE; since there are no human-written corpora for AV\nexplanations, we sample silver-standard explanations from GPT-4-TURBO and\ndistill them into a pretrained Llama-3-8B. Results on three difficult AV\ndatasets IMdB2, Blog-Auth, and FanFiction show that CAVE generates high quality\nexplanations (as measured by automatic and human evaluation) as well as\ncompetitive task accuracies.\n","authors":["Sahana Ramnath","Kartik Pandey","Elizabeth Boschee","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11778v2","updated":"2024-06-24T14:23:30Z","published":"2024-02-19T02:08:09Z","title":"Towards Theoretical Understandings of Self-Consuming Generative Models","summary":"  This paper tackles the emerging challenge of training generative models\nwithin a self-consuming loop, wherein successive generations of models are\nrecursively trained on mixtures of real and synthetic data from previous\ngenerations. We construct a theoretical framework to rigorously evaluate how\nthis training procedure impacts the data distributions learned by future\nmodels, including parametric and non-parametric models. Specifically, we derive\nbounds on the total variation (TV) distance between the synthetic data\ndistributions produced by future models and the original real data distribution\nunder various mixed training scenarios for diffusion models with a\none-hidden-layer neural network score function. Our analysis demonstrates that\nthis distance can be effectively controlled under the condition that mixed\ntraining dataset sizes or proportions of real data are large enough.\nInterestingly, we further unveil a phase transition induced by expanding\nsynthetic data amounts, proving theoretically that while the TV distance\nexhibits an initial ascent, it declines beyond a threshold point. Finally, we\npresent results for kernel density estimation, delivering nuanced insights such\nas the impact of mixed data training on error propagation.\n","authors":["Shi Fu","Sen Zhang","Yingjie Wang","Xinmei Tian","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2402.11778v2.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2308.13279v2","updated":"2024-06-24T13:57:01Z","published":"2023-08-25T10:01:53Z","title":"Hyperbolic Random Forests","summary":"  Hyperbolic space is becoming a popular choice for representing data due to\nthe hierarchical structure - whether implicit or explicit - of many real-world\ndatasets. Along with it comes a need for algorithms capable of solving\nfundamental tasks, such as classification, in hyperbolic space. Recently,\nmultiple papers have investigated hyperbolic alternatives to hyperplane-based\nclassifiers, such as logistic regression and SVMs. While effective, these\napproaches struggle with more complex hierarchical data. We, therefore, propose\nto generalize the well-known random forests to hyperbolic space. We do this by\nredefining the notion of a split using horospheres. Since finding the globally\noptimal split is computationally intractable, we find candidate horospheres\nthrough a large-margin classifier. To make hyperbolic random forests work on\nmulti-class data and imbalanced experiments, we furthermore outline a new\nmethod for combining classes based on their lowest common ancestor and a\nclass-balanced version of the large-margin loss. Experiments on standard and\nnew benchmarks show that our approach outperforms both conventional random\nforest algorithms and recent hyperbolic classifiers.\n","authors":["Lars Doorenbos","Pablo Márquez-Neila","Raphael Sznitman","Pascal Mettes"],"pdf_url":"https://arxiv.org/pdf/2308.13279v2.pdf","comment":"Accepted at TMLR. Code available at\n  https://github.com/LarsDoorenbos/HoroRF"},{"id":"http://arxiv.org/abs/2406.10670v2","updated":"2024-06-24T13:52:37Z","published":"2024-06-15T15:28:02Z","title":"CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language\n  Model Pre-training","summary":"  Selecting high-quality data for pre-training is crucial in shaping the\ndownstream task performance of language models. A major challenge lies in\nidentifying this optimal subset, a problem generally considered intractable,\nthus necessitating scalable and effective heuristics. In this work, we propose\na data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering),\nwhich leverages an empirical Bayes-inspired approach to derive a simple and\ncomputationally efficient selection criterion based on the relative loss values\nof two auxiliary models.\n  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically\non two language modeling tasks: (1) selecting data from C4 for domain\nadaptation to evaluation on Books and (2) selecting data from C4 for a suite of\ndownstream multiple-choice question answering tasks. We demonstrate favorable\nscaling both as we subselect more aggressively and using small auxiliary models\nto select data for large target models. As one headline result, CoLoR-Filter\ndata selected using a pair of 150m parameter auxiliary models can train a 1.2b\nparameter target model to match a 1.2b parameter model trained on 25b randomly\nselected tokens with 25x less data for Books and 11x less data for the\ndownstream tasks.\n  Code: https://github.com/davidbrandfonbrener/color-filter-olmo\n  Filtered data:\nhttps://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4\n","authors":["David Brandfonbrener","Hanlin Zhang","Andreas Kirsch","Jonathan Richard Schwarz","Sham Kakade"],"pdf_url":"https://arxiv.org/pdf/2406.10670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16641v1","updated":"2024-06-24T13:45:31Z","published":"2024-06-24T13:45:31Z","title":"Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind\n  AI Generated Image Quality Assessment","summary":"  Recently, textual prompt tuning has shown inspirational performance in\nadapting Contrastive Language-Image Pre-training (CLIP) models to natural image\nquality assessment. However, such uni-modal prompt learning method only tunes\nthe language branch of CLIP models. This is not enough for adapting CLIP models\nto AI generated image quality assessment (AGIQA) since AGIs visually differ\nfrom natural images. In addition, the consistency between AGIs and user input\ntext prompts, which correlates with the perceptual quality of AGIs, is not\ninvestigated to guide AGIQA. In this letter, we propose vision-language\nconsistency guided multi-modal prompt learning for blind AGIQA, dubbed\nCLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in\nlanguage and vision branches of CLIP models, respectively. Moreover, we design\na text-to-image alignment quality prediction task, whose learned\nvision-language consistency knowledge is used to guide the optimization of the\nabove multi-modal prompts. Experimental results on two public AGIQA datasets\ndemonstrate that the proposed method outperforms state-of-the-art quality\nassessment models. The source code is available at\nhttps://github.com/JunFu1995/CLIP-AGIQA.\n","authors":["Jun Fu","Wei Zhou","Qiuping Jiang","Hantao Liu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2406.16641v1.pdf","comment":"Accepted by IEEE Signal Processing Letter"},{"id":"http://arxiv.org/abs/2406.16638v1","updated":"2024-06-24T13:44:06Z","published":"2024-06-24T13:44:06Z","title":"Feature Fusion for Human Activity Recognition using Parameter-Optimized\n  Multi-Stage Graph Convolutional Network and Transformer Models","summary":"  Human activity recognition (HAR) is a crucial area of research that involves\nunderstanding human movements using computer and machine vision technology.\nDeep learning has emerged as a powerful tool for this task, with models such as\nConvolutional Neural Networks (CNNs) and Transformers being employed to capture\nvarious aspects of human motion. One of the key contributions of this work is\nthe demonstration of the effectiveness of feature fusion in improving HAR\naccuracy by capturing spatial and temporal features, which has important\nimplications for the development of more accurate and robust activity\nrecognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,\nand TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and\nevaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG\nachieved high accuracies and f1-scores, while LARa and PKU-MMD had lower\nscores. Feature fusion improved results across datasets.\n","authors":["Mohammad Belal","Taimur Hassan","Abdelfatah Ahmed","Ahmad Aljarah","Nael Alsheikh","Irfan Hussain"],"pdf_url":"https://arxiv.org/pdf/2406.16638v1.pdf","comment":"7 pages, 1 figure, conference"},{"id":"http://arxiv.org/abs/2406.16635v1","updated":"2024-06-24T13:41:08Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated techniques like quantization and\nsparsity. Contextual sparsity, where the sparsity pattern is input-dependent,\nis crucial in LLMs because the permanent removal of attention heads or neurons\nfrom LLMs can significantly degrade accuracy. Prior work has attempted to model\ncontextual sparsity using neural networks trained to predict activation\nmagnitudes, which can be used to dynamically prune structures with low\npredicted activation magnitude. In this paper, we look beyond magnitude-based\npruning criteria to assess attention head and neuron importance in LLMs. We\ndeveloped a novel predictor called ShadowLLM, which can shadow the LLM behavior\nand enforce better sparsity patterns, resulting in over 15% improvement in\nend-to-end accuracy without increasing latency compared to previous methods.\nShadowLLM achieves up to a 20\\% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on models with up to 30 billion\nparameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02051v3","updated":"2024-06-24T13:26:47Z","published":"2023-06-03T08:39:25Z","title":"A Comprehensive Survey on Relation Extraction: Recent Advances and New\n  Frontiers","summary":"  Relation extraction (RE) involves identifying the relations between entities\nfrom underlying content. RE serves as the foundation for many natural language\nprocessing (NLP) and information retrieval applications, such as knowledge\ngraph completion and question answering. In recent years, deep neural networks\nhave dominated the field of RE and made noticeable progress. Subsequently, the\nlarge pre-trained language models have taken the state-of-the-art RE to a new\nlevel. This survey provides a comprehensive review of existing deep learning\ntechniques for RE. First, we introduce RE resources, including datasets and\nevaluation metrics. Second, we propose a new taxonomy to categorize existing\nworks from three perspectives, i.e., text representation, context encoding, and\ntriplet prediction. Third, we discuss several important challenges faced by RE\nand summarize potential techniques to tackle these challenges. Finally, we\noutline some promising future directions and prospects in this field. This\nsurvey is expected to facilitate researchers' collaborative efforts to address\nthe challenges of real-world RE systems.\n","authors":["Xiaoyan Zhao","Yang Deng","Min Yang","Lingzhi Wang","Rui Zhang","Hong Cheng","Wai Lam","Ying Shen","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2306.02051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16369v3","updated":"2024-06-24T13:19:17Z","published":"2024-03-25T02:17:54Z","title":"Learning Action-based Representations Using Invariance","summary":"  Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.\n","authors":["Max Rudolph","Caleb Chuck","Kevin Black","Misha Lvovsky","Scott Niekum","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16369v3.pdf","comment":"Published at the Reinforcement Learning Conference 2024"},{"id":"http://arxiv.org/abs/2406.16626v1","updated":"2024-06-24T13:18:02Z","published":"2024-06-24T13:18:02Z","title":"Hacking a surrogate model approach to XAI","summary":"  In recent years, the number of new applications for highly complex AI systems\nhas risen significantly. Algorithmic decision-making systems (ADMs) are one of\nsuch applications, where an AI system replaces the decision-making process of a\nhuman expert. As one approach to ensure fairness and transparency of such\nsystems, explainable AI (XAI) has become more important. One variant to achieve\nexplainability are surrogate models, i.e., the idea to train a new simpler\nmachine learning model based on the input-output-relationship of a black box\nmodel. The simpler machine learning model could, for example, be a decision\ntree, which is thought to be intuitively understandable by humans. However,\nthere is not much insight into how well the surrogate model approximates the\nblack box.\n  Our main assumption is that a good surrogate model approach should be able to\nbring such a discriminating behavior to the attention of humans; prior to our\nresearch we assumed that a surrogate decision tree would identify such a\npattern on one of its first levels. However, in this article we show that even\nif the discriminated subgroup - while otherwise being the same in all\ncategories - does not get a single positive decision from the black box ADM\nsystem, the corresponding question of group membership can be pushed down onto\na level as low as wanted by the operator of the system.\n  We then generalize this finding to pinpoint the exact level of the tree on\nwhich the discriminating question is asked and show that in a more realistic\nscenario, where discrimination only occurs to some fraction of the\ndisadvantaged group, it is even more feasible to hide such discrimination.\n  Our approach can be generalized easily to other surrogate models.\n","authors":["Alexander Wilhelm","Katharina A. Zweig"],"pdf_url":"https://arxiv.org/pdf/2406.16626v1.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.16611v1","updated":"2024-06-24T12:52:02Z","published":"2024-06-24T12:52:02Z","title":"Evaluation of Language Models in the Medical Context Under\n  Resource-Constrained Settings","summary":"  Since the emergence of the Transformer architecture, language model\ndevelopment has increased, driven by their promising potential. However,\nreleasing these models into production requires properly understanding their\nbehavior, particularly in sensitive domains such as medicine. Despite this\nneed, the medical literature still lacks technical assessments of pre-trained\nlanguage models, which are especially valuable in resource-constrained settings\nin terms of computational power or limited budget. To address this gap, we\nprovide a comprehensive survey of language models in the medical domain. In\naddition, we selected a subset of these models for thorough evaluation,\nfocusing on classification and text generation tasks. Our subset encompasses 53\nmodels, ranging from 110 million to 13 billion parameters, spanning the three\nfamilies of Transformer-based models and from diverse knowledge domains. This\nstudy employs a series of approaches for text classification together with\nzero-shot prompting instead of model training or fine-tuning, which closely\nresembles the limited resource setting in which many users of language models\nfind themselves. Encouragingly, our findings reveal remarkable performance\nacross various tasks and datasets, underscoring the latent potential of certain\nmodels to contain medical knowledge, even without domain specialization.\nConsequently, our study advocates for further exploration of model applications\nin medical contexts, particularly in resource-constrained settings. The code is\navailable on https://github.com/anpoc/Language-models-in-medicine.\n","authors":["Andrea Posada","Daniel Rueckert","Felix Meissen","Philip Müller"],"pdf_url":"https://arxiv.org/pdf/2406.16611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16609v1","updated":"2024-06-24T12:48:44Z","published":"2024-06-24T12:48:44Z","title":"Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by\n  Evolving Adversarial Instances","summary":"  Deep neural networks (DNN) are increasingly being used to perform\nalgorithm-selection in combinatorial optimisation domains, particularly as they\naccommodate input representations which avoid designing and calculating\nfeatures. Mounting evidence from domains that use images as input shows that\ndeep convolutional networks are vulnerable to adversarial samples, in which a\nsmall perturbation of an instance can cause the DNN to misclassify. However, it\nremains unknown as to whether deep recurrent networks (DRN) which have recently\nbeen shown promise as algorithm-selectors in the bin-packing domain are equally\nvulnerable. We use an evolutionary algorithm (EA) to find perturbations of\ninstances from two existing benchmarks for online bin packing that cause\ntrained DRNs to misclassify: adversarial samples are successfully generated\nfrom up to 56% of the original instances depending on the dataset. Analysis of\nthe new misclassified instances sheds light on the `fragility' of some training\ninstances, i.e. instances where it is trivial to find a small perturbation that\nresults in a misclassification and the factors that influence this. Finally,\nthe method generates a large number of new instances misclassified with a wide\nvariation in confidence, providing a rich new source of training data to create\nmore robust models.\n","authors":["Emma Hart","Quentin Renau","Kevin Sim","Mohamad Alissa"],"pdf_url":"https://arxiv.org/pdf/2406.16609v1.pdf","comment":"To appear in the proceedings of the 18th International Conference on\n  Parallel Problem Solving from Nature (PPSN 2024)"},{"id":"http://arxiv.org/abs/2406.16605v1","updated":"2024-06-24T12:46:15Z","published":"2024-06-24T12:46:15Z","title":"CLEAR: Can Language Models Really Understand Causal Graphs?","summary":"  Causal reasoning is a cornerstone of how humans interpret the world. To model\nand reason about causality, causal graphs offer a concise yet effective\nsolution. Given the impressive advancements in language models, a crucial\nquestion arises: can they really understand causal graphs? To this end, we\npioneer an investigation into language models' understanding of causal graphs.\nSpecifically, we develop a framework to define causal graph understanding, by\nassessing language models' behaviors through four practical criteria derived\nfrom diverse disciplines (e.g., philosophy and psychology). We then develop\nCLEAR, a novel benchmark that defines three complexity levels and encompasses\n20 causal graph-based tasks across these levels. Finally, based on our\nframework and benchmark, we conduct extensive experiments on six leading\nlanguage models and summarize five empirical findings. Our results indicate\nthat while language models demonstrate a preliminary understanding of causal\ngraphs, significant potential for improvement remains. Our project website is\nat https://github.com/OpenCausaLab/CLEAR.\n","authors":["Sirui Chen","Mengying Xu","Kun Wang","Xingyu Zeng","Rui Zhao","Shengjie Zhao","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.16605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16512v4","updated":"2024-06-24T12:41:52Z","published":"2024-03-25T07:55:29Z","title":"LLMs Are Few-Shot In-Context Low-Resource Language Learners","summary":"  In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages. Our code is publicly\nreleased at https://github.com/SamuelCahyawijaya/in-context-alignment\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2403.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04067v3","updated":"2024-06-24T12:32:41Z","published":"2024-04-05T12:51:37Z","title":"CLUE: A Clinical Language Understanding Evaluation for LLMs","summary":"  Large Language Models (LLMs) are expected to significantly contribute to\npatient care, diagnostics, and administrative processes. Emerging biomedical\nLLMs aim to address healthcare-specific challenges, including privacy demands\nand computational constraints. Assessing the models' suitability for this\nsensitive application area is of the utmost importance. However, evaluation has\nprimarily been limited to non-clinical tasks, which do not reflect the\ncomplexity of practical clinical applications. To fill this gap, we present the\nClinical Language Understanding Evaluation (CLUE), a benchmark tailored to\nevaluate LLMs on clinical tasks. CLUE includes six tasks to test the practical\napplicability of LLMs in complex healthcare settings. Our evaluation includes a\ntotal of $25$ LLMs. In contrast to previous evaluations, CLUE shows a decrease\nin performance for nine out of twelve biomedical models. Our benchmark\nrepresents a step towards a standardized approach to evaluating and developing\nLLMs in healthcare to align future model development with the real-world needs\nof clinical application. We open-source all evaluation scripts and datasets for\nfuture research at https://github.com/TIO-IKIM/CLUE.\n","authors":["Amin Dada","Marie Bauer","Amanda Butler Contreras","Osman Alperen Koraş","Constantin Marc Seibold","Kaleb E Smith","Jens Kleesiek"],"pdf_url":"https://arxiv.org/pdf/2404.04067v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16578v1","updated":"2024-06-24T12:14:24Z","published":"2024-06-24T12:14:24Z","title":"QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds","summary":"  While pets offer companionship, their limited intelligence restricts advanced\nreasoning and autonomous interaction with humans. Considering this, we propose\nQuadrupedGPT, a versatile agent designed to master a broad range of complex\ntasks with agility comparable to that of a pet. To achieve this goal, the\nprimary challenges include: i) effectively leveraging multimodal observations\nfor decision-making; ii) mastering agile control of locomotion and path\nplanning; iii) developing advanced cognition to execute long-term objectives.\nQuadrupedGPT processes human command and environmental contexts using a large\nmultimodal model (LMM). Empowered by its extensive knowledge base, our agent\nautonomously assigns appropriate parameters for adaptive locomotion policies\nand guides the agent in planning a safe but efficient path towards the goal,\nutilizing semantic-aware terrain analysis. Moreover, QuadrupedGPT is equipped\nwith problem-solving capabilities that enable it to decompose long-term goals\ninto a sequence of executable subgoals through high-level reasoning. Extensive\nexperiments across various benchmarks confirm that QuadrupedGPT can adeptly\nhandle multiple tasks with intricate instructions, demonstrating a significant\nstep towards the versatile quadruped agents in open-ended worlds. Our website\nand codes can be found at https://quadruped-hub.github.io/Quadruped-GPT/.\n","authors":["Ye Wang","Yuting Mei","Sipeng Zheng","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.16578v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16571v1","updated":"2024-06-24T12:09:19Z","published":"2024-06-24T12:09:19Z","title":"Differentiable Distributionally Robust Optimization Layers","summary":"  In recent years, there has been a growing research interest in\ndecision-focused learning, which embeds optimization problems as a layer in\nlearning pipelines and demonstrates a superior performance than the\nprediction-focused approach. However, for distributionally robust optimization\n(DRO), a popular paradigm for decision-making under uncertainty, it is still\nunknown how to embed it as a layer, i.e., how to differentiate decisions with\nrespect to an ambiguity set. In this paper, we develop such differentiable DRO\nlayers for generic mixed-integer DRO problems with parameterized second-order\nconic ambiguity sets and discuss its extension to Wasserstein ambiguity sets.\nTo differentiate the mixed-integer decisions, we propose a novel dual-view\nmethodology by handling continuous and discrete parts of decisions via\ndifferent principles. Specifically, we construct a differentiable energy-based\nsurrogate to implement the dual-view methodology and use importance sampling to\nestimate its gradient. We further prove that such a surrogate enjoys the\nasymptotic convergency under regularization. As an application of the proposed\ndifferentiable DRO layers, we develop a novel decision-focused learning\npipeline for contextual distributionally robust decision-making tasks and\ncompare it with the prediction-focused approach in experiments.\n","authors":["Xutao Ma","Chao Ning","Wenli Du"],"pdf_url":"https://arxiv.org/pdf/2406.16571v1.pdf","comment":"In Forty-first International Conference on Machine Learning (2024)"},{"id":"http://arxiv.org/abs/2401.15351v2","updated":"2024-06-24T12:08:06Z","published":"2024-01-27T08:52:19Z","title":"A Survey on Neural Topic Models: Methods, Applications, and Challenges","summary":"  Topic models have been prevalent for decades to discover latent topics and\ninfer topic proportions of documents in an unsupervised fashion. They have been\nwidely used in various applications like text analysis and context\nrecommendation. Recently, the rise of neural networks has facilitated the\nemergence of a new research field -- Neural Topic Models (NTMs). Different from\nconventional topic models, NTMs directly optimize parameters without requiring\nmodel-specific derivations. This endows NTMs with better scalability and\nflexibility, resulting in significant research attention and plentiful new\nmethods and applications. In this paper, we present a comprehensive survey on\nneural topic models concerning methods, applications, and challenges.\nSpecifically, we systematically organize current NTM methods according to their\nnetwork structures and introduce the NTMs for various scenarios like short\ntexts and bilingual documents. We also discuss a wide range of popular\napplications built on NTMs. Finally, we highlight the challenges confronted by\nNTMs to inspire future research. We accompany this survey with a repository for\neasier access to the mentioned paper resources:\nhttps://github.com/bobxwu/Paper-Neural-Topic-Models.\n","authors":["Xiaobao Wu","Thong Nguyen","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2401.15351v2.pdf","comment":"Accepted to Artificial Intelligence Review. See\n  https://doi.org/10.1007/s10462-023-10661-7 and a paper list at\n  https://github.com/BobXWu/Paper-Neural-Topic-Models"},{"id":"http://arxiv.org/abs/2403.17209v4","updated":"2024-06-24T12:04:06Z","published":"2024-03-25T21:37:30Z","title":"Generation of Asset Administration Shell with Large Language Model\n  Agents: Toward Semantic Interoperability in Digital Twins in the Context of\n  Industry 4.0","summary":"  This research introduces a novel approach for achieving semantic\ninteroperability in digital twins and assisting the creation of Asset\nAdministration Shell (AAS) as digital twin model within the context of Industry\n4.0. The foundational idea of our research is that the communication based on\nsemantics and the generation of meaningful textual data are directly linked,\nand we posit that these processes are equivalent if the exchanged information\ncan be serialized in text form. Based on this, we construct a \"semantic node\"\ndata structure in our research to capture the semantic essence of textual data.\nThen, a system powered by large language models is designed and implemented to\nprocess the \"semantic node\" and generate standardized digital twin models from\nraw textual data collected from datasheets describing technical assets. Our\nevaluation demonstrates an effective generation rate of 62-79%, indicating a\nsubstantial proportion of the information from the source text can be\ntranslated error-free to the target digital twin instance model with the\ngenerative capability of large language models. This result has a direct\napplication in the context of Industry 4.0, and the designed system is\nimplemented as a data model generation tool for reducing the manual effort in\ncreating AAS model. In our evaluation, a comparative analysis of different LLMs\nand an in-depth ablation study of Retrieval-Augmented Generation (RAG)\nmechanisms provide insights into the effectiveness of LLM systems for\ninterpreting technical concepts and translating data. Our findings emphasize\nLLMs' capability to automate AAS instance creation and contribute to the\nbroader field of semantic interoperability for digital twins in industrial\napplications. The prototype implementation and evaluation results are presented\non our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.\n","authors":["Yuchen Xia","Zhewen Xiao","Nasser Jazdi","Michael Weyrich"],"pdf_url":"https://arxiv.org/pdf/2403.17209v4.pdf","comment":"Published in IEEE Access"},{"id":"http://arxiv.org/abs/2406.16555v1","updated":"2024-06-24T11:43:18Z","published":"2024-06-24T11:43:18Z","title":"Homomorphisms and Embeddings of STRIPS Planning Models","summary":"  Determining whether two STRIPS planning instances are isomorphic is the\nsimplest form of comparison between planning instances. It is also a particular\ncase of the problem concerned with finding an isomorphism between a planning\ninstance $P$ and a sub-instance of another instance $P_0$ . One application of\nsuch a mapping is to efficiently produce a compiled form containing all\nsolutions to P from a compiled form containing all solutions to $P_0$. We also\nintroduce the notion of embedding from an instance $P$ to another instance\n$P_0$, which allows us to deduce that $P_0$ has no solution-plan if $P$ is\nunsolvable. In this paper, we study the complexity of these problems. We show\nthat the first is GI-complete, and can thus be solved, in theory, in\nquasi-polynomial time. While we prove the remaining problems to be NP-complete,\nwe propose an algorithm to build an isomorphism, when possible. We report\nextensive experimental trials on benchmark problems which demonstrate\nconclusively that applying constraint propagation in preprocessing can greatly\nimprove the efficiency of a SAT solver.\n","authors":["Arnaud Lequen","Martin C. Cooper","Frédéric Maris"],"pdf_url":"https://arxiv.org/pdf/2406.16555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16552v1","updated":"2024-06-24T11:41:12Z","published":"2024-06-24T11:41:12Z","title":"Inference of Sequential Patterns for Neural Message Passing in Temporal\n  Graphs","summary":"  The modelling of temporal patterns in dynamic graphs is an important current\nresearch issue in the development of time-aware GNNs. Whether or not a specific\nsequence of events in a temporal graph constitutes a temporal pattern not only\ndepends on the frequency of its occurrence. We consider whether it deviates\nfrom what is expected in a temporal graph where timestamps are randomly\nshuffled. While accounting for such a random baseline is important to model\ntemporal patterns, it has mostly been ignored by current temporal graph neural\nnetworks. To address this issue we propose HYPA-DBGNN, a novel two-step\napproach that combines (i) the inference of anomalous sequential patterns in\ntime series data on graphs based on a statistically principled null model, with\n(ii) a neural message passing approach that utilizes a higher-order De Bruijn\ngraph whose edges capture overrepresented sequential patterns. Our method\nleverages hypergeometric graph ensembles to identify anomalous edges within\nboth first- and higher-order De Bruijn graphs, which encode the temporal\nordering of events. The model introduces an inductive bias that enhances model\ninterpretability. We evaluate our approach for static node classification using\nbenchmark datasets and a synthetic dataset that showcases its ability to\nincorporate the observed inductive bias regarding over- and under-represented\ntemporal edges. We demonstrate the framework's effectiveness in detecting\nsimilar patterns within empirical datasets, resulting in superior performance\ncompared to baseline methods in node classification tasks. To the best of our\nknowledge, our work is the first to introduce statistically informed GNNs that\nleverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path\nfor bridging the gap between statistical graph inference and neural graph\nrepresentation learning, with potential applications to static GNNs.\n","authors":["Jan von Pichowski","Vincenzo Perri","Lisi Qarkaxhija","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2406.16552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01658v4","updated":"2024-06-24T11:34:19Z","published":"2023-05-02T04:11:23Z","title":"A Non-autoregressive Multi-Horizon Flight Trajectory Prediction\n  Framework with Gray Code Representation","summary":"  Flight Trajectory Prediction (FTP) is an essential task in Air Traffic\nControl (ATC), which can assist air traffic controllers in managing airspace\nmore safely and efficiently. Existing approaches generally perform\nmulti-horizon FTP tasks in an autoregressive manner, thereby suffering from\nerror accumulation and low-efficiency problems. In this paper, a novel\nframework, called FlightBERT++, is proposed to i) forecast multi-horizon flight\ntrajectories directly in a non-autoregressive way, and ii) improve the\nlimitation of the binary encoding (BE) representation in the FlightBERT\nframework. Specifically, the proposed framework is implemented by a generalized\nencoder-decoder architecture, in which the encoder learns the temporal-spatial\npatterns from historical observations and the decoder predicts the flight\nstatus for the future horizons. Compared to conventional architecture, an\ninnovative horizon-aware contexts generator is dedicatedly designed to consider\nthe prior horizon information, which further enables non-autoregressive\nmulti-horizon prediction. Additionally, the Gray code representation and the\ndifferential prediction paradigm are designed to cope with the high-bit\nmisclassifications of the BE representation, which significantly reduces the\noutliers in the predictions. Moreover, a differential prompted decoder is\nproposed to enhance the capability of the differential predictions by\nleveraging the stationarity of the differential sequence. Extensive experiments\nare conducted to validate the proposed framework on a real-world flight\ntrajectory dataset. The experimental results demonstrated that the proposed\nframework outperformed the competitive baselines in both FTP performance and\ncomputational efficiency.\n","authors":["Dongyue Guo","Zheng Zhang","Zhen Yan","Jianwei Zhang","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2305.01658v4.pdf","comment":"An extend version based on the AAAI version"},{"id":"http://arxiv.org/abs/2406.16537v1","updated":"2024-06-24T11:16:37Z","published":"2024-06-24T11:16:37Z","title":"Character-Adapter: Prompt-Guided Region Control for High-Fidelity\n  Character Customization","summary":"  Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods\n","authors":["Yuhang Ma","Wenting Xu","Jiji Tang","Qinfeng Jin","Rongsheng Zhang","Zeng Zhao","Changjie Fan","Zhipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2406.16537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16535v1","updated":"2024-06-24T11:16:26Z","published":"2024-06-24T11:16:26Z","title":"Token-based Decision Criteria Are Suboptimal in In-context Learning","summary":"  In-Context Learning (ICL) typically utilizes classification criteria from\nprobabilities of manually selected label tokens. However, we argue that such\ntoken-based classification criteria lead to suboptimal decision boundaries,\ndespite delicate calibrations through translation and constrained rotation. To\naddress this problem, we propose Hidden Calibration, which renounces token\nprobabilities and uses the nearest centroid classifier on the LM's last hidden\nstates. In detail, we use the nearest centroid classification on the hidden\nstates, assigning the category of the nearest centroid previously observed from\na few-shot calibration set to the test sample as the predicted label. Our\nexperiments on 3 models and 10 classification datasets indicate that Hidden\nCalibration consistently outperforms current token-based calibrations by about\n20%. Our further analysis demonstrates that Hidden Calibration finds better\nclassification criteria with less inter-categories overlap, and LMs provide\nlinearly separable intra-category clusters with the help of demonstrations,\nwhich supports Hidden Calibration and gives new insights into the conventional\nICL.\n","authors":["Hakaze Cho","Yoshihiro Sakai","Mariko Kato","Kenshiro Tanaka","Akira Ishii","Naoya Inoue"],"pdf_url":"https://arxiv.org/pdf/2406.16535v1.pdf","comment":"21 pages, 14 figures, 8 tables"},{"id":"http://arxiv.org/abs/2406.16526v1","updated":"2024-06-24T11:04:28Z","published":"2024-06-24T11:04:28Z","title":"NARRepair: Non-Autoregressive Code Generation Model for Automatic\n  Program Repair","summary":"  With the advancement of deep learning techniques, the performance of\nAutomatic Program Repair(APR) techniques has reached a new level. Previous deep\nlearning-based APR techniques essentially modified program sentences in the\nAutoregressive(AR) manner, which predicts future values based on past values.\nDue to the manner of word-by-word generation, the AR-based APR technique has a\nhuge time delay. This negative consequence overshadows the widespread adoption\nof APR techniques in real-life software development.\n  To address the issue, we aim to apply the Non-Autoregressive(NAR) method to\nthe APR task, which can output target code in a parallel manner to avoid huge\ninference delays. To effectively adapt the NAR manner for the APR task, we in\nthis paper propose NARRepair, the first customized NAR code generation model\nfor the APR task. The NARRepair features three major novelties, including 1)\nusing repair actions to alleviate the over-correction issue, 2) extracting\ndependency information from AST to alleviate the issue of lacking inter-word\ndependency information, 3) employing two-stage decoding to alleviate the issue\nof lacking contextual information. We evaluated NARRepair on three widely used\ndatasets in the APR community, and the results show that our technique can\nsignificantly improve the inference speed while maintaining high repair\naccuracy.\n","authors":["Zhenyu Yang","Zhen Yang","Zhongxing Yu"],"pdf_url":"https://arxiv.org/pdf/2406.16526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16521v1","updated":"2024-06-24T10:55:31Z","published":"2024-06-24T10:55:31Z","title":"Carrot and Stick: Inducing Self-Motivation with Positive & Negative\n  Feedback","summary":"  Positive thinking is thought to be an important component of self-motivation\nin various practical fields such as education and the workplace. Previous work,\nincluding sentiment transfer and positive reframing, has focused on the\npositive side of language. However, self-motivation that drives people to reach\ntheir goals has not yet been studied from a computational perspective.\nMoreover, negative feedback has not yet been explored, even though positive and\nnegative feedback are both necessary to grow self-motivation. To facilitate\nself-motivation, we propose CArrot and STICk (CASTIC) dataset, consisting of\n12,590 sentences with 5 different strategies for enhancing self-motivation. Our\ndata and code are publicly available at here.\n","authors":["Jimin Sohn","Jeihee Cho","Junyong Lee","Songmu Heo","Ji-Eun Han","David R. Mortensen"],"pdf_url":"https://arxiv.org/pdf/2406.16521v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2405.08011v2","updated":"2024-06-24T10:25:19Z","published":"2024-05-10T18:05:37Z","title":"A Survey of Large Language Models for Graphs","summary":"  Graphs are an essential data structure utilized to represent relationships in\nreal-world scenarios. Prior research has established that Graph Neural Networks\n(GNNs) deliver impressive outcomes in graph-centric tasks, such as link\nprediction and node classification. Despite these advancements, challenges like\ndata sparsity and limited generalization capabilities continue to persist.\nRecently, Large Language Models (LLMs) have gained attention in natural\nlanguage processing. They excel in language comprehension and summarization.\nIntegrating LLMs with graph learning techniques has attracted interest as a way\nto enhance performance in graph learning tasks. In this survey, we conduct an\nin-depth review of the latest state-of-the-art LLMs applied in graph learning\nand introduce a novel taxonomy to categorize existing methods based on their\nframework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as\nPrefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key\nmethodologies within each category. We explore the strengths and limitations of\neach framework, and emphasize potential avenues for future research, including\novercoming current integration challenges between LLMs and graph learning\ntechniques, and venturing into new application areas. This survey aims to serve\nas a valuable resource for researchers and practitioners eager to leverage\nlarge language models in graph learning, and to inspire continued progress in\nthis dynamic field. We consistently maintain the related open-source materials\nat \\url{https://github.com/HKUDS/Awesome-LLM4Graph-Papers}.\n","authors":["Xubin Ren","Jiabin Tang","Dawei Yin","Nitesh Chawla","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2405.08011v2.pdf","comment":"Published as a KDD'24 survey paper"},{"id":"http://arxiv.org/abs/2406.16505v1","updated":"2024-06-24T10:21:29Z","published":"2024-06-24T10:21:29Z","title":"$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep\n  Reinforcement Learning","summary":"  Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.\n","authors":["Feng Xu","Yan Yin","Xinyu Zhang","Tianyuan Liu","Shengyi Jiang","Zongzhang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16501v1","updated":"2024-06-24T10:10:03Z","published":"2024-06-24T10:10:03Z","title":"UNICAD: A Unified Approach for Attack Detection, Noise Reduction and\n  Novel Class Identification","summary":"  As the use of Deep Neural Networks (DNNs) becomes pervasive, their\nvulnerability to adversarial attacks and limitations in handling unseen classes\nposes significant challenges. The state-of-the-art offers discrete solutions\naimed to tackle individual issues covering specific adversarial attack\nscenarios, classification or evolving learning. However, real-world systems\nneed to be able to detect and recover from a wide range of adversarial attacks\nwithout sacrificing classification accuracy and to flexibly act in {\\bf unseen}\nscenarios. In this paper, UNICAD, is proposed as a novel framework that\nintegrates a variety of techniques to provide an adaptive solution.\n  For the targeted image classification, UNICAD achieves accurate image\nclassification, detects unseen classes, and recovers from adversarial attacks\nusing Prototype and Similarity-based DNNs with denoising autoencoders. Our\nexperiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness\nin adversarial mitigation and unseen class classification, outperforming\ntraditional models.\n","authors":["Alvaro Lopez Pellicer","Kittipos Giatgong","Yi Li","Neeraj Suri","Plamen Angelov"],"pdf_url":"https://arxiv.org/pdf/2406.16501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14963v2","updated":"2024-06-24T10:05:24Z","published":"2024-02-22T20:57:17Z","title":"Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich\n  Reasoning","summary":"  While Large language models (LLMs) have the capability to iteratively reflect\non their own outputs, recent studies have observed their struggles with\nknowledge-rich problems without access to external resources. In addition to\nthe inefficiency of LLMs in self-assessment, we also observe that LLMs struggle\nto revisit their predictions despite receiving explicit negative feedback.\nTherefore, We propose Mirror, a Multiple-perspective self-reflection method for\nknowledge-rich reasoning, to avoid getting stuck at a particular reflection\niteration. Mirror enables LLMs to reflect from multiple-perspective clues,\nachieved through a heuristic interaction between a Navigator and a Reasoner. It\nguides agents toward diverse yet plausibly reliable reasoning trajectory\nwithout access to ground truth by encouraging (1) diversity of directions\ngenerated by Navigator and (2) agreement among strategically induced\nperturbations in responses generated by the Reasoner. The experiments on five\nreasoning datasets demonstrate that Mirror's superiority over several\ncontemporary self-reflection approaches. Additionally, the ablation study\nstudies clearly indicate that our strategies alleviate the aforementioned\nchallenges.\n","authors":["Hanqi Yan","Qinglin Zhu","Xinyu Wang","Lin Gui","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2402.14963v2.pdf","comment":"ACL24, Main Conference, long paper. Code is available at\n  https://github.com/hanqi-qi/Mirror.git"},{"id":"http://arxiv.org/abs/2406.16495v1","updated":"2024-06-24T10:05:23Z","published":"2024-06-24T10:05:23Z","title":"OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to\n  construct Observer-Thinker-Conceiver-Expresser","summary":"  Recent research has shown that combining Mamba with Transformer architecture,\nwhich has selective state space and quadratic self-attention mechanism,\noutperforms using Mamba or Transformer architecture alone in language modeling\ntasks. The quadratic self-attention mechanism effectively alleviates the\nshortcomings of selective state space in handling long-term dependencies of any\nelement in the sequence. We propose a position information injection method\nthat connects the selective state space model with the quadratic attention, and\nintegrates these two architectures with hybrid experts with cross-sharing\ndomains, so that we can enjoy the advantages of both. We design a new\narchitecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser\n(OTCE), which can compete with well-known medium-scale open-source language\nmodels on a small scale in language modeling tasks.\n","authors":["Jingze Shi","Ting Xie","Bingheng Wu","Chunjun Zheng","Kai Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16494v1","updated":"2024-06-24T10:02:24Z","published":"2024-06-24T10:02:24Z","title":"Cross-domain Transfer of Valence Preferences via a Meta-optimization\n  Approach","summary":"  Cross-domain recommendation offers a potential avenue for alleviating data\nsparsity and cold-start problems. Embedding and mapping, as a classic\ncross-domain research genre, aims to identify a common mapping function to\nperform representation transformation between two domains. Nevertheless,\nprevious coarse-grained preference representations, non-personalized mapping\nfunctions, and excessive reliance on overlapping users limit their performance,\nespecially in scenarios where overlapping users are sparse. To address\naforementioned challenges, we propose a novel cross-domain approach, namely\nCVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture\nof parametric meta-learning and self-supervised learning, which not only\ntransfers user preferences at a finer level, but also enables signal\nenhancement with the knowledge of non-overlapping users. Specifically, with\ndeep insights into user preferences and valence preference theory, we believe\nthat there exists significant difference between users' positive preferences\nand negative behaviors, and thus employ differentiated encoders to learn their\ndistributions. In particular, we further utilize the pre-trained model and item\npopularity to sample pseudo-interaction items to ensure the integrity of both\ndistributions. To guarantee the personalization of preference transfer, we\ntreat each user's mapping as two parts, the common transformation and the\npersonalized bias, where the network used to generate the personalized bias is\noutput by a meta-learner. Furthermore, in addition to the supervised loss for\noverlapping users, we design contrastive tasks for non-overlapping users from\nboth group and individual-levels to avoid model skew and enhance the semantics\nof representations. Exhaustive data analysis and extensive experimental results\ndemonstrate the effectiveness and advancement of our proposed framework.\n","authors":["Chuang Zhao","Hongke Zhao","Ming He","Xiaomeng Li","Jianping Fan"],"pdf_url":"https://arxiv.org/pdf/2406.16494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09585v3","updated":"2024-06-24T09:56:35Z","published":"2024-05-15T07:31:06Z","title":"An Embarrassingly Simple Approach to Enhance Transformer Performance in\n  Genomic Selection for Crop Breeding","summary":"  Genomic selection (GS), as a critical crop breeding strategy, plays a key\nrole in enhancing food production and addressing the global hunger crisis. The\npredominant approaches in GS currently revolve around employing statistical\nmethods for prediction. However, statistical methods often come with two main\nlimitations: strong statistical priors and linear assumptions. A recent trend\nis to capture the non-linear relationships between markers by deep learning.\nHowever, as crop datasets are commonly long sequences with limited samples, the\nrobustness of deep learning models, especially Transformers, remains a\nchallenge. In this work, to unleash the unexplored potential of attention\nmechanism for the task of interest, we propose a simple yet effective\nTransformer-based framework that enables end-to-end training of the whole\nsequence. Via experiments on rice3k and wheat3k datasets, we show that, with\nsimple tricks such as k-mer tokenization and random masking, Transformer can\nachieve overall superior performance against seminal methods on GS tasks of\ninterest.\n","authors":["Renqi Chen","Wenwei Han","Haohao Zhang","Haoyang Su","Zhefan Wang","Xiaolei Liu","Hao Jiang","Wanli Ouyang","Nanqing Dong"],"pdf_url":"https://arxiv.org/pdf/2405.09585v3.pdf","comment":"Accepted by IJCAI2024. Code is available at\n  https://github.com/RenqiChen/Genomic-Selection"},{"id":"http://arxiv.org/abs/2406.16486v1","updated":"2024-06-24T09:40:39Z","published":"2024-06-24T09:40:39Z","title":"Towards Comprehensive Preference Data Collection for Reward Modeling","summary":"  Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment\nof large language models (LLMs) with human preferences, thereby enhancing the\nquality of responses generated. A critical component of RLHF is the reward\nmodel, which is trained on preference data and outputs a scalar reward during\nthe inference stage. However, the collection of preference data still lacks\nthorough investigation. Recent studies indicate that preference data is\ncollected either by AI or humans, where chosen and rejected instances are\nidentified among pairwise responses. We question whether this process\neffectively filters out noise and ensures sufficient diversity in collected\ndata. To address these concerns, for the first time, we propose a comprehensive\nframework for preference data collection, decomposing the process into four\nincremental steps: Prompt Generation, Response Generation, Response Filtering,\nand Human Labeling. This structured approach ensures the collection of\nhigh-quality preferences while reducing reliance on human labor. We conducted\ncomprehensive experiments based on the data collected at different stages,\ndemonstrating the effectiveness of the proposed data collection method.\n","authors":["Yulan Hu","Qingyang Li","Sheng Ouyang","Ge Chen","Kaihui Chen","Lijun Mei","Xucheng Ye","Fuzheng Zhang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16479v1","updated":"2024-06-24T09:33:56Z","published":"2024-06-24T09:33:56Z","title":"Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications\n  for Neuromorphic Computing","summary":"  Advances in neural computation have predominantly relied on the gradient\nbackpropagation algorithm (BP). However, the recent shift towards\nnon-stationary data modeling has highlighted the limitations of this heuristic,\nexposing that its adaptation capabilities are far from those seen in biological\nbrains. Unlike BP, where weight updates are computed through a reverse error\npropagation path, Hebbian learning dynamics provide synaptic updates using only\ninformation within the layer itself. This has spurred interest in biologically\nplausible learning algorithms, hypothesized to overcome BP's shortcomings. In\nthis context, Hinton recently introduced the Forward-Forward Algorithm (FFA),\nwhich employs local learning rules for each layer and has empirically proven\nits efficacy in multiple data modeling tasks. In this work we argue that when\nemploying a squared Euclidean norm as a goodness function driving the local\nlearning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To\nverify this result, we compare the training behavior of FFA in analog networks\nwith its Hebbian adaptation in spiking neural networks. Our experiments\ndemonstrate that both versions of FFA produce similar accuracy and latent\ndistributions. The findings herein reported provide empirical evidence linking\nbiological learning rules with currently used training algorithms, thus paving\nthe way towards extrapolating the positive outcomes from FFA to Hebbian\nlearning rules. Simultaneously, our results imply that analog networks trained\nunder FFA could be directly applied to neuromorphic computing, leading to\nreduced energy usage and increased computational speed.\n","authors":["Erik B. Terres-Escudero","Javier Del Ser","Pablo García-Bringas"],"pdf_url":"https://arxiv.org/pdf/2406.16479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12227v2","updated":"2024-06-24T09:29:28Z","published":"2024-06-18T03:05:08Z","title":"Interpretable Catastrophic Forgetting of Large Language Model\n  Fine-tuning via Instruction Vector","summary":"  Fine-tuning large language models (LLMs) can cause them to lose their general\ncapabilities. However, the intrinsic mechanisms behind such forgetting remain\nunexplored. In this paper, we begin by examining this phenomenon by focusing on\nknowledge understanding and instruction following, with the latter identified\nas the main contributor to forgetting during fine-tuning. Consequently, we\npropose the Instruction Vector (IV) framework to capture model representations\nhighly related to specific instruction-following capabilities, thereby making\nit possible to understand model-intrinsic forgetting. Through the analysis of\nIV dynamics pre and post-training, we suggest that fine-tuning mostly adds\nspecialized reasoning patterns instead of erasing previous skills, which may\nappear as forgetting. Building on this insight, we develop IV-guided training,\nwhich aims to preserve original computation graph, thereby mitigating\ncatastrophic forgetting. Empirical tests on three benchmarks confirm the\nefficacy of this new approach, supporting the relationship between IVs and\nforgetting. Our code will be made available soon.\n","authors":["Gangwei Jiang","Caigao Jiang","Zhaoyi Li","Siqiao Xue","Jun Zhou","Linqi Song","Defu Lian","Ying Wei"],"pdf_url":"https://arxiv.org/pdf/2406.12227v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09234v4","updated":"2024-06-24T09:26:42Z","published":"2023-10-13T16:37:53Z","title":"ClickPrompt: CTR Models are Strong Prompt Generators for Adapting\n  Language Models to CTR Prediction","summary":"  Click-through rate (CTR) prediction has become increasingly indispensable for\nvarious Internet applications. Traditional CTR models convert the multi-field\ncategorical data into ID features via one-hot encoding, and extract the\ncollaborative signals among features. Such a paradigm suffers from the problem\nof semantic information loss. Another line of research explores the potential\nof pretrained language models (PLMs) for CTR prediction by converting input\ndata into textual sentences through hard prompt templates. Although semantic\nsignals are preserved, they generally fail to capture the collaborative\ninformation (e.g., feature interactions, pure ID features), not to mention the\nunacceptable inference overhead brought by the huge model size. In this paper,\nwe aim to model both the semantic knowledge and collaborative knowledge for\naccurate CTR estimation, and meanwhile address the inference inefficiency\nissue. To benefit from both worlds and close their gaps, we propose a novel\nmodel-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models\nto generate interaction-aware soft prompts for PLMs. We design a\nprompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM\nhas to recover the masked tokens based on the language context, as well as the\nsoft prompts generated by CTR model. The collaborative and semantic knowledge\nfrom ID and textual features would be explicitly aligned and interacted via the\nprompt interface. Then, we can either tune the CTR model with PLM for superior\nperformance, or solely tune the CTR model without PLM for inference efficiency.\nExperiments on four real-world datasets validate the effectiveness of\nClickPrompt compared with existing baselines.\n","authors":["Jianghao Lin","Bo Chen","Hangyu Wang","Yunjia Xi","Yanru Qu","Xinyi Dai","Kangning Zhang","Ruiming Tang","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.09234v4.pdf","comment":"Accepted by WWW 2024"},{"id":"http://arxiv.org/abs/2406.14570v2","updated":"2024-06-24T09:25:33Z","published":"2024-06-06T09:46:14Z","title":"Deep-Learning Approach for Tissue Classification using Acoustic Waves\n  during Ablation with an Er:YAG Laser (Updated)","summary":"  Today's mechanical tools for bone cutting (osteotomy) cause mechanical trauma\nthat prolongs the healing process. Medical device manufacturers aim to minimize\nthis trauma, with minimally invasive surgery using laser cutting as one\ninnovation. This method ablates tissue using laser light instead of mechanical\ntools, reducing post-surgery healing time. A reliable feedback system is\ncrucial during laser surgery to prevent damage to surrounding tissues. We\npropose a tissue classification method analyzing acoustic waves generated\nduring laser ablation, demonstrating its applicability in an ex-vivo\nexperiment. The ablation process with a microsecond pulsed Er:YAG laser\nproduces acoustic waves, acquired with an air-coupled transducer. These waves\nwere used to classify five porcine tissue types: hard bone, soft bone, muscle,\nfat, and skin. For automated tissue classification, we compared five Neural\nNetwork (NN) approaches: a one-dimensional Convolutional Neural Network (CNN)\nwith time-dependent input, a Fully-connected Neural Network (FcNN) with either\nthe frequency spectrum or principal components of the frequency spectrum as\ninput, and a combination of a CNN and an FcNN with time-dependent data and its\nfrequency spectrum as input. Consecutive acoustic waves were used to improve\nclassification accuracy. Grad-Cam identified the activation map of the\nfrequencies, showing low frequencies as the most important for this task. Our\nresults indicated that combining time-dependent data with its frequency\nspectrum achieved the highest classification accuracy (65.5%-75.5%). We also\nfound that using the frequency spectrum alone was sufficient, with no\nadditional benefit from applying Principal Components Analysis (PCA).\n","authors":["Carlo Seppi","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2406.14570v2.pdf","comment":"This paper is an updated version of Deep-Learning Approach for Tissue\n  Classification using Acoustic Waves during Ablation with an Er:YAG Laser\n  originally published in DOI:10.1109/ACCESS.2021.3113055. This update\n  addresses several issues and incorporates corrections as outlined in\n  DOI:10.1109/ACCESS.2024.3395071. We provide here a detailed description of\n  our experiments and the new models we used"},{"id":"http://arxiv.org/abs/2406.16473v1","updated":"2024-06-24T09:25:02Z","published":"2024-06-24T09:25:02Z","title":"Seeking Certainty In Uncertainty: Dual-Stage Unified Framework Solving\n  Uncertainty in Dynamic Facial Expression Recognition","summary":"  The contemporary state-of-the-art of Dynamic Facial Expression Recognition\n(DFER) technology facilitates remarkable progress by deriving emotional\nmappings of facial expressions from video content, underpinned by training on\nvoluminous datasets. Yet, the DFER datasets encompass a substantial volume of\nnoise data. Noise arises from low-quality captures that defy logical labeling,\nand instances that suffer from mislabeling due to annotation bias, engendering\ntwo principal types of uncertainty: the uncertainty regarding data usability\nand the uncertainty concerning label reliability. Addressing the two types of\nuncertainty, we have meticulously crafted a two-stage framework aiming at\n\\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain\ndata (SCIU). This initiative aims to purge the DFER datasets of these\nuncertainties, thereby ensuring that only clean, verified data is employed in\ntraining processes. To mitigate the issue of low-quality samples, we introduce\nthe Coarse-Grained Pruning (CGP) stage, which assesses sample weights and\nprunes those deemed unusable due to their low weight. For samples with\nincorrect annotations, the Fine-Grained Correction (FGC) stage evaluates\nprediction stability to rectify mislabeled data. Moreover, SCIU is conceived as\na universally compatible, plug-and-play framework, tailored to integrate\nseamlessly with prevailing DFER methodologies. Rigorous experiments across\nprevalent DFER datasets and against numerous benchmark methods substantiates\nSCIU's capacity to markedly elevate performance metrics.\n","authors":["Haoran Wang","Xinji Mai","Zeng Tao","Xuan Tong","Junxiong Lin","Yan Wang","Jiawen Yu","Boyang Wang","Shaoqi Yan","Qing Zhao","Ziheng Zhou","Shuyong Gao","Wenqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16464v1","updated":"2024-06-24T09:13:42Z","published":"2024-06-24T09:13:42Z","title":"InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for\n  Multi-modal Sarcasm Detection","summary":"  The prevalence of sarcasm in social media, conveyed through text-image\ncombinations, presents significant challenges for sentiment analysis and\nintention mining. Current multi-modal sarcasm detection methods have been\nproven to struggle with biases from spurious cues, leading to a superficial\nunderstanding of the complex interactions between text and image. To address\nthese issues, we propose InterCLIP-MEP, a robust framework for multi-modal\nsarcasm detection. InterCLIP-MEP introduces a refined variant of CLIP,\nInteractive CLIP (InterCLIP), as the backbone, enhancing sample representations\nby embedding cross-modality information in each encoder. Furthermore, a novel\ntraining strategy is designed to adapt InterCLIP for a Memory-Enhanced\nPredictor (MEP). MEP uses dynamic dual-channel memory to store valuable\nhistorical knowledge of test samples and then leverages this memory as a\nnon-parametric classifier to derive the final prediction. By using InterCLIP to\nencode text-image interactions more effectively and incorporating MEP,\nInterCLIP-MEP offers a more robust recognition of multi-modal sarcasm.\nExperiments demonstrate that InterCLIP-MEP achieves state-of-the-art\nperformance on the MMSD2.0 benchmark. Code and data are available at\n[https://github.com/CoderChen01/InterCLIP-MEP](https://github.com/CoderChen01/InterCLIP-MEP).\n","authors":["Junjie Chen","Subin Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16464v1.pdf","comment":"8 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2312.10251v3","updated":"2024-06-24T09:07:33Z","published":"2023-12-15T22:50:12Z","title":"Advancing Surgical VQA with Scene Graph Knowledge","summary":"  Modern operating room is becoming increasingly complex, requiring innovative\nintra-operative support systems. While the focus of surgical data science has\nlargely been on video analysis, integrating surgical computer vision with\nlanguage capabilities is emerging as a necessity. Our work aims to advance\nVisual Question Answering (VQA) in the surgical context with scene graph\nknowledge, addressing two main challenges in the current surgical VQA systems:\nremoving question-condition bias in the surgical VQA dataset and incorporating\nscene-aware reasoning in the surgical VQA model design. First, we propose a\nSurgical Scene Graph-based dataset, SSG-QA, generated by employing segmentation\nand detection models on publicly available datasets. We build surgical scene\ngraphs using spatial and action information of instruments and anatomies. These\ngraphs are fed into a question engine, generating diverse QA pairs. Our SSG-QA\ndataset provides a more complex, diverse, geometrically grounded, unbiased, and\nsurgical action-oriented dataset compared to existing surgical VQA datasets. We\nthen propose SSG-QA-Net, a novel surgical VQA model incorporating a lightweight\nScene-embedded Interaction Module (SIM), which integrates geometric scene\nknowledge in the VQA model design by employing cross-attention between the\ntextual and the scene features. Our comprehensive analysis of the SSG-QA\ndataset shows that SSG-QA-Net outperforms existing methods across different\nquestion types and complexities. We highlight that the primary limitation in\nthe current surgical VQA systems is the lack of scene knowledge to answer\ncomplex queries. We present a novel surgical VQA dataset and model and show\nthat results can be significantly improved by incorporating geometric scene\nfeatures in the VQA model design. The source code and the dataset will be made\npublicly available at: https://github.com/CAMMA-public/SSG-QA\n","authors":["Kun Yuan","Manasi Kattel","Joel L. Lavanchy","Nassir Navab","Vinkle Srivastav","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2312.10251v3.pdf","comment":"IPCAI 2024, Int J CARS (2024)"},{"id":"http://arxiv.org/abs/2406.07595v3","updated":"2024-06-24T09:02:57Z","published":"2024-06-11T13:42:57Z","title":"VulDetectBench: Evaluating the Deep Capability of Vulnerability\n  Detection with Large Language Models","summary":"  Large Language Models (LLMs) have training corpora containing large amounts\nof program code, greatly improving the model's code comprehension and\ngeneration capabilities. However, sound comprehensive research on detecting\nprogram vulnerabilities, a more specific task related to code, and evaluating\nthe performance of LLMs in this more specialized scenario is still lacking. To\naddress common challenges in vulnerability analysis, our study introduces a new\nbenchmark, VulDetectBench, specifically designed to assess the vulnerability\ndetection capabilities of LLMs. The benchmark comprehensively evaluates LLM's\nability to identify, classify, and locate vulnerabilities through five tasks of\nincreasing difficulty. We evaluate the performance of 17 models (both open- and\nclosed-source) and find that while existing models can achieve over 80%\naccuracy on tasks related to vulnerability identification and classification,\nthey still fall short on specific, more detailed vulnerability analysis tasks,\nwith less than 30% accuracy, making it difficult to provide valuable auxiliary\ninformation for professional vulnerability mining. Our benchmark effectively\nevaluates the capabilities of various LLMs at different levels in the specific\ntask of vulnerability detection, providing a foundation for future research and\nimprovements in this critical area of code security. VulDetectBench is publicly\navailable at https://github.com/Sweetaroo/VulDetectBench.\n","authors":["Yu Liu","Lang Gao","Mingxin Yang","Yu Xie","Ping Chen","Xiaojin Zhang","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2406.07595v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16455v1","updated":"2024-06-24T08:50:26Z","published":"2024-06-24T08:50:26Z","title":"Guardrails for avoiding harmful medical product recommendations and\n  off-label promotion in generative AI models","summary":"  Generative AI (GenAI) models have demonstrated remarkable capabilities in a\nwide variety of medical tasks. However, as these models are trained using\ngeneralist datasets with very limited human oversight, they can learn uses of\nmedical products that have not been adequately evaluated for safety and\nefficacy, nor approved by regulatory agencies. Given the scale at which GenAI\nmay reach users, unvetted recommendations pose a public health risk. In this\nwork, we propose an approach to identify potentially harmful product\nrecommendations, and demonstrate it using a recent multimodal large language\nmodel.\n","authors":["Daniel Lopez-Martinez"],"pdf_url":"https://arxiv.org/pdf/2406.16455v1.pdf","comment":"CVPR 2024 Responsible Generative AI (ReGenAI) workshop"},{"id":"http://arxiv.org/abs/2402.05359v5","updated":"2024-06-24T08:49:29Z","published":"2024-02-08T02:37:30Z","title":"Prompting with Divide-and-Conquer Program Makes Large Language Models\n  Discerning to Hallucination and Deception","summary":"  Foundation models, such as Large language Models (LLMs), have attracted\nsignificant amount of interest due to their large number of applications.\nHowever, when handling tasks involving repetitive sub-tasks and/or deceptive\ncontents, such as arithmetic calculation and article-level fake news detection,\nsimple instructional prompts suffer from inaccurate responses. Existing works\nshow that more complicated prompting strategies, such as Chain-of-Thoughts and\nLeast-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent\nresearches reveal that simple divide-and-conquer prompting strategy, i.e.\nsimply dividing the input sequence to multiple sub-inputs, can also\nsubstantially improve LLM's performance in some specific tasks such as\nmisinformation detection. In this paper, we aim at examining the utility of\ndivide-and-conquer prompting strategy and answer on which kind of tasks this\nstrategy gets advantages. Specifically, we provide a theoretic analysis to\ndivide-and-conquer prompting strategy and help us identify the specific tasks\nwhere DaC prompting can bring performance boost with theoretic guarantee. We\nthen present two cases (large integer arithmetic and fact verification) where\nexperimental results aligns with our theoretic analysis.\n","authors":["Yizhou Zhang","Lun Du","Defu Cao","Qiang Fu","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2402.05359v5.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.16453v1","updated":"2024-06-24T08:45:03Z","published":"2024-06-24T08:45:03Z","title":"Learning in Wilson-Cowan model for metapopulation","summary":"  The Wilson-Cowan model for metapopulation, a Neural Mass Network Model,\ntreats different subcortical regions of the brain as connected nodes, with\nconnections representing various types of structural, functional, or effective\nneuronal connectivity between these regions. Each region comprises interacting\npopulations of excitatory and inhibitory cells, consistent with the standard\nWilson-Cowan model. By incorporating stable attractors into such a\nmetapopulation model's dynamics, we transform it into a learning algorithm\ncapable of achieving high image and text classification accuracy. We test it on\nMNIST and Fashion MNIST, in combination with convolutional neural networks, on\nCIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture\n(BERT), on IMDB, always showing high classification accuracy. These numerical\nevaluations illustrate that minimal modifications to the Wilson-Cowan model for\nmetapopulation can reveal unique and previously unobserved dynamics.\n","authors":["Raffaele Marino","Lorenzo Buffoni","Lorenzo Chicchi","Francesca Di Patti","Diego Febbe","Lorenzo Giambagli","Duccio Fanelli"],"pdf_url":"https://arxiv.org/pdf/2406.16453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16437v1","updated":"2024-06-24T08:29:58Z","published":"2024-06-24T08:29:58Z","title":"Theory on Mixture-of-Experts in Continual Learning","summary":"  Continual learning (CL) has garnered significant attention because of its\nability to adapt to new tasks that arrive over time. Catastrophic forgetting\n(of old tasks) has been identified as a major issue in CL, as the model adapts\nto new tasks. The Mixture-of-Experts (MoE) model has recently been shown to\neffectively mitigate catastrophic forgetting in CL, by employing a gating\nnetwork to sparsify and distribute diverse tasks among multiple experts.\nHowever, there is a lack of theoretical analysis of MoE and its impact on the\nlearning performance in CL. This paper provides the first theoretical results\nto characterize the impact of MoE in CL via the lens of overparameterized\nlinear regression tasks. We establish the benefit of MoE over a single expert\nby proving that the MoE model can diversify its experts to specialize in\ndifferent tasks, while its router learns to select the right expert for each\ntask and balance the loads across all experts. Our study further suggests an\nintriguing fact that the MoE in CL needs to terminate the update of the gating\nnetwork after sufficient training rounds to attain system convergence, which is\nnot needed in the existing MoE studies that do not consider the continual task\narrival. Furthermore, we provide explicit expressions for the expected\nforgetting and overall generalization error to characterize the benefit of MoE\nin the learning performance in CL. Interestingly, adding more experts requires\nadditional rounds before convergence, which may not enhance the learning\nperformance. Finally, we conduct experiments on both synthetic and real\ndatasets to extend these insights from linear models to deep neural networks\n(DNNs), which also shed light on the practical algorithm design for MoE in CL.\n","authors":["Hongbo Li","Sen Lin","Lingjie Duan","Yingbin Liang","Ness B. Shroff"],"pdf_url":"https://arxiv.org/pdf/2406.16437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12560v2","updated":"2024-06-24T08:27:13Z","published":"2024-06-18T12:40:15Z","title":"Towards Bayesian Data Selection","summary":"  A wide range of machine learning algorithms iteratively add data to the\ntraining sample. Examples include semi-supervised learning, active learning,\nmulti-armed bandits, and Bayesian optimization. We embed this kind of data\naddition into decision theory by framing data selection as a decision problem.\nThis paves the way for finding Bayes-optimal selections of data. For the\nillustrative case of self-training in semi-supervised learning, we derive the\nrespective Bayes criterion. We further show that deploying this criterion\nmitigates the issue of confirmation bias by empirically assessing our method\nfor generalized linear models, semi-parametric generalized additive models, and\nBayesian neural networks on simulated and real-world data.\n","authors":["Julian Rodemann"],"pdf_url":"https://arxiv.org/pdf/2406.12560v2.pdf","comment":"5th Workshop on Data-Centric Machine Learning Research (DMLR) at ICML\n  2024"},{"id":"http://arxiv.org/abs/2311.15036v2","updated":"2024-06-24T08:25:50Z","published":"2023-11-25T14:18:29Z","title":"On-Device Soft Sensors: Real-Time Fluid Flow Estimation from Level\n  Sensor Data","summary":"  Soft sensors are crucial in bridging autonomous systems' physical and digital\nrealms, enhancing sensor fusion and perception. Instead of deploying soft\nsensors on the Cloud, this study shift towards employing on-device soft\nsensors, promising heightened efficiency and bolstering data security. Our\napproach substantially improves energy efficiency by deploying Artificial\nIntelligence (AI) directly on devices within a wireless sensor network.\nFurthermore, the synergistic integration of the Microcontroller Unit and\nField-Programmable Gate Array (FPGA) leverages the rapid AI inference\ncapabilities of the latter. Empirical evidence from our real-world use case\ndemonstrates that FPGA-based soft sensors achieve inference times ranging\nremarkably from 1.04 to 12.04 microseconds. These compelling results highlight\nthe considerable potential of our innovative approach for executing real-time\ninference tasks efficiently, thereby presenting a feasible alternative that\neffectively addresses the latency challenges intrinsic to Cloud-based\ndeployments.\n","authors":["Tianheng Ling","Chao Qian","Gregor Schiele"],"pdf_url":"https://arxiv.org/pdf/2311.15036v2.pdf","comment":"8 pages, 6 figures, 1 Table, Accepted by the 1st AUTONOMOUS\n  UBIQUITOUS SYSTEMS (AUTOQUITOUS) WORKSHOP of EAI MobiQuitous 2023 - 20th EAI\n  International Conference on Mobile and Ubiquitous Systems: Computing,\n  Networking and Services"},{"id":"http://arxiv.org/abs/2406.13210v2","updated":"2024-06-24T08:22:40Z","published":"2024-06-19T04:43:41Z","title":"Surgical Triplet Recognition via Diffusion Model","summary":"  Surgical triplet recognition is an essential building block to enable\nnext-generation context-aware operating rooms. The goal is to identify the\ncombinations of instruments, verbs, and targets presented in surgical video\nframes. In this paper, we propose DiffTriplet, a new generative framework for\nsurgical triplet recognition employing the diffusion model, which predicts\nsurgical triplets via iterative denoising. To handle the challenge of triplet\nassociation, two unique designs are proposed in our diffusion framework, i.e.,\nassociation learning and association guidance. During training, we optimize the\nmodel in the joint space of triplets and individual components to capture the\ndependencies among them. At inference, we integrate association constraints\ninto each update of the iterative denoising process, which refines the triplet\nprediction using the information of individual components. Experiments on the\nCholecT45 and CholecT50 datasets show the superiority of the proposed method in\nachieving a new state-of-the-art performance for surgical triplet recognition.\nOur codes will be released.\n","authors":["Daochang Liu","Axel Hu","Mubarak Shah","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2406.13210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16427v1","updated":"2024-06-24T08:20:53Z","published":"2024-06-24T08:20:53Z","title":"Dynamic Pseudo Label Optimization in Point-Supervised Nuclei\n  Segmentation","summary":"  Deep learning has achieved impressive results in nuclei segmentation, but the\nmassive requirement for pixel-wise labels remains a significant challenge. To\nalleviate the annotation burden, existing methods generate pseudo masks for\nmodel training using point labels. However, the generated masks are inevitably\ndifferent from the ground truth, and these dissimilarities are not handled\nreasonably during the network training, resulting in the subpar performance of\nthe segmentation model. To tackle this issue, we propose a framework named\nDoNuSeg, enabling \\textbf{D}ynamic pseudo label \\textbf{O}ptimization in\npoint-supervised \\textbf{Nu}clei \\textbf{Seg}mentation. Specifically, DoNuSeg\ntakes advantage of class activation maps (CAMs) to adaptively capture regions\nwith semantics similar to annotated points. To leverage semantic diversity in\nthe hierarchical feature levels, we design a dynamic selection module to choose\nthe optimal one among CAMs from different encoder blocks as pseudo masks.\nMeanwhile, a CAM-guided contrastive module is proposed to further enhance the\naccuracy of pseudo masks. In addition to exploiting the semantic information\nprovided by CAMs, we consider location priors inherent to point labels,\ndeveloping a task-decoupled structure for effectively differentiating nuclei.\nExtensive experiments demonstrate that DoNuSeg outperforms state-of-the-art\npoint-supervised methods. The code is available at\nhttps://github.com/shinning0821/MICCAI24-DoNuSeg.\n","authors":["Ziyue Wang","Ye Zhang","Yifeng Wang","Linghan Cai","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16427v1.pdf","comment":"early accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2406.16426v1","updated":"2024-06-24T08:20:43Z","published":"2024-06-24T08:20:43Z","title":"Fault Detection for agents on power grid topology optimization: A\n  Comprehensive analysis","summary":"  The topology optimization of transmission networks using Deep Reinforcement\nLearning (DRL) has increasingly come into focus. Various researchers have\nproposed different DRL agents, which are often benchmarked on the Grid2Op\nenvironment from the Learning to Run a Power Network (L2RPN) challenges. The\nenvironments have many advantages with their realistic chronics and underlying\npower flow backends. However, the interpretation of agent survival or failure\nis not always clear, as there are a variety of potential causes. In this work,\nwe focus on the failures of the power grid to identify patterns and detect them\na priori. We collect the failed chronics of three different agents on the WCCI\n2022 L2RPN environment, totaling about 40k data points. By clustering, we are\nable to detect five distinct clusters, identifying different failure types.\nFurther, we propose a multi-class prediction approach to detect failures\nbeforehand and evaluate five different models. Here, the Light\nGradient-Boosting Machine (LightGBM) shows the best performance, with an\naccuracy of 86%. It also correctly identifies in 91% of the time failure and\nsurvival observations. Finally, we provide a detailed feature importance\nanalysis that identifies critical features and regions in the grid.\n","authors":["Malte Lehna","Mohamed Hassouna","Dmitry Degtyar","Sven Tomforde","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2406.16426v1.pdf","comment":"11 Pages plus references and appendix. The appendix consist of\n  additional material of the paper and is not included in the initial\n  submission"},{"id":"http://arxiv.org/abs/2403.13372v3","updated":"2024-06-24T08:20:04Z","published":"2024-03-20T08:08:54Z","title":"LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models","summary":"  Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It provides a\nsolution for flexibly customizing the fine-tuning of 100+ LLMs without the need\nfor coding through the built-in web UI LlamaBoard. We empirically validate the\nefficiency and effectiveness of our framework on language modeling and text\ngeneration tasks. It has been released at\nhttps://github.com/hiyouga/LLaMA-Factory and received over 24,000 stars and\n3,000 forks.\n","authors":["Yaowei Zheng","Richong Zhang","Junhao Zhang","Yanhan Ye","Zheyan Luo","Zhangchi Feng","Yongqiang Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13372v3.pdf","comment":"13 pages, accepted to ACL 2024 System Demonstration Track"},{"id":"http://arxiv.org/abs/2406.15111v2","updated":"2024-06-24T08:19:00Z","published":"2024-06-21T12:59:20Z","title":"Investigating the impact of 2D gesture representation on co-speech\n  gesture generation","summary":"  Co-speech gestures play a crucial role in the interactions between humans and\nembodied conversational agents (ECA). Recent deep learning methods enable the\ngeneration of realistic, natural co-speech gestures synchronized with speech,\nbut such approaches require large amounts of training data. \"In-the-wild\"\ndatasets, which compile videos from sources such as YouTube through human pose\ndetection models, offer a solution by providing 2D skeleton sequences that are\npaired with speech. Concurrently, innovative lifting models have emerged,\ncapable of transforming these 2D pose sequences into their 3D counterparts,\nleading to large and diverse datasets of 3D gestures. However, the derived 3D\npose estimation is essentially a pseudo-ground truth, with the actual ground\ntruth being the 2D motion data. This distinction raises questions about the\nimpact of gesture representation dimensionality on the quality of generated\nmotions, a topic that, to our knowledge, remains largely unexplored. In this\nwork, we evaluate the impact of the dimensionality of the training data, 2D or\n3D joint coordinates, on the performance of a multimodal speech-to-gesture deep\ngenerative model. We use a lifting model to convert 2D-generated sequences of\nbody pose to 3D. Then, we compare the sequence of gestures generated directly\nin 3D to the gestures generated in 2D and lifted to 3D as post-processing.\n","authors":["Teo Guichoux","Laure Soulier","Nicolas Obin","Catherine Pelachaud"],"pdf_url":"https://arxiv.org/pdf/2406.15111v2.pdf","comment":"8 pages. Paper accepted at WACAI 2024"},{"id":"http://arxiv.org/abs/2406.16424v1","updated":"2024-06-24T08:18:19Z","published":"2024-06-24T08:18:19Z","title":"Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial\n  Optimization","summary":"  Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an RL approach that leverages memory to improve the adaptation of\nneural solvers at inference time. MEMENTO enables updating the action\ndistribution dynamically based on the outcome of previous decisions. We\nvalidate its effectiveness on benchmark problems, in particular Traveling\nSalesman and Capacitated Vehicle Routing, demonstrating it can successfully be\ncombined with standard methods to boost their performance under a given budget,\nboth in and out-of-distribution, improving their performance on all 12\nevaluated tasks.\n","authors":["Felix Chalumeau","Refiloe Shabe","Noah de Nicola","Arnu Pretorius","Thomas D. Barrett","Nathan Grinsztajn"],"pdf_url":"https://arxiv.org/pdf/2406.16424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16422v1","updated":"2024-06-24T08:14:09Z","published":"2024-06-24T08:14:09Z","title":"Exploring Cross-Domain Few-Shot Classification via Frequency-Aware\n  Prompting","summary":"  Cross-Domain Few-Shot Learning has witnessed great stride with the\ndevelopment of meta-learning. However, most existing methods pay more attention\nto learning domain-adaptive inductive bias (meta-knowledge) through\nfeature-wise manipulation or task diversity improvement while neglecting the\nphenomenon that deep networks tend to rely more on high-frequency cues to make\nthe classification decision, which thus degenerates the robustness of learned\ninductive bias since high-frequency information is vulnerable and easy to be\ndisturbed by noisy information. Hence in this paper, we make one of the first\nattempts to propose a Frequency-Aware Prompting method with mutual attention\nfor Cross-Domain Few-Shot classification, which can let networks simulate the\nhuman visual perception of selecting different frequency cues when facing new\nrecognition tasks. Specifically, a frequency-aware prompting mechanism is first\nproposed, in which high-frequency components of the decomposed source image are\nswitched either with normal distribution sampling or zeroing to get\nfrequency-aware augment samples. Then, a mutual attention module is designed to\nlearn generalizable inductive bias under CD-FSL settings. More importantly, the\nproposed method is a plug-and-play module that can be directly applied to most\noff-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks\ndemonstrate the effectiveness of our proposed method as well as robustly\nimprove the performance of existing CD-FLS methods. Resources at\nhttps://github.com/tinkez/FAP_CDFSC.\n","authors":["Tiange Zhang","Qing Cai","Feng Gao","Lin Qi","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2406.16422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15168v2","updated":"2024-06-24T08:13:07Z","published":"2024-06-21T14:12:15Z","title":"This actually looks like that: Proto-BagNets for local and global\n  interpretability-by-design","summary":"  Interpretability is a key requirement for the use of machine learning models\nin high-stakes applications, including medical diagnosis. Explaining black-box\nmodels mostly relies on post-hoc methods that do not faithfully reflect the\nmodel's behavior. As a remedy, prototype-based networks have been proposed, but\ntheir interpretability is limited as they have been shown to provide coarse,\nunreliable, and imprecise explanations. In this work, we introduce\nProto-BagNets, an interpretable-by-design prototype-based model that combines\nthe advantages of bag-of-local feature models and prototype learning to provide\nmeaningful, coherent, and relevant prototypical parts needed for accurate and\ninterpretable image classification tasks. We evaluated the Proto-BagNet for\ndrusen detection on publicly available retinal OCT data. The Proto-BagNet\nperformed comparably to the state-of-the-art interpretable and\nnon-interpretable models while providing faithful, accurate, and clinically\nmeaningful local and global explanations. The code is available at\nhttps://github.com/kdjoumessi/Proto-BagNets.\n","authors":["Kerol Djoumessi","Bubacarr Bah","Laura Kühlewein","Philipp Berens","Lisa Koch"],"pdf_url":"https://arxiv.org/pdf/2406.15168v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16388v1","updated":"2024-06-24T07:59:34Z","published":"2024-06-24T07:59:34Z","title":"PenSLR: Persian end-to-end Sign Language Recognition Using Ensembling","summary":"  Sign Language Recognition (SLR) is a fast-growing field that aims to fill the\ncommunication gaps between the hearing-impaired and people without hearing\nloss. Existing solutions for Persian Sign Language (PSL) are limited to\nword-level interpretations, underscoring the need for more advanced and\ncomprehensive solutions. Moreover, previous work on other languages mainly\nfocuses on manipulating the neural network architectures or hardware\nconfigurations instead of benefiting from the aggregated results of multiple\nmodels. In this paper, we introduce PenSLR, a glove-based sign language system\nconsisting of an Inertial Measurement Unit (IMU) and five flexible sensors\npowered by a deep learning framework capable of predicting variable-length\nsequences. We achieve this in an end-to-end manner by leveraging the\nConnectionist Temporal Classification (CTC) loss function, eliminating the need\nfor segmentation of input signals. To further enhance its capabilities, we\npropose a novel ensembling technique by leveraging a multiple sequence\nalignment algorithm known as Star Alignment. Furthermore, we introduce a new\nPSL dataset, including 16 PSL signs with more than 3000 time-series samples in\ntotal. We utilize this dataset to evaluate the performance of our system based\non four word-level and sentence-level metrics. Our evaluations show that PenSLR\nachieves a remarkable word accuracy of 94.58% and 96.70% in subject-independent\nand subject-dependent setups, respectively. These achievements are attributable\nto our ensembling algorithm, which not only boosts the word-level performance\nby 0.51% and 1.32% in the respective scenarios but also yields significant\nenhancements of 1.46% and 4.00%, respectively, in sentence-level accuracy.\n","authors":["Amirparsa Salmankhah","Amirreza Rajabi","Negin Kheirmand","Ali Fadaeimanesh","Amirreza Tarabkhah","Amirreza Kazemzadeh","Hamed Farbeh"],"pdf_url":"https://arxiv.org/pdf/2406.16388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16386v1","updated":"2024-06-24T07:58:36Z","published":"2024-06-24T07:58:36Z","title":"Automatically Generating UI Code from Screenshot: A\n  Divide-and-Conquer-Based Approach","summary":"  Websites are critical in today's digital world, with over 1.11 billion\ncurrently active and approximately 252,000 new sites launched daily. Converting\nwebsite layout design into functional UI code is a time-consuming yet\nindispensable step of website development. Manual methods of converting visual\ndesigns into functional code present significant challenges, especially for\nnon-experts. To explore automatic design-to-code solutions, we first conduct a\nmotivating study on GPT-4o and identify three types of issues in generating UI\ncode: element omission, element distortion, and element misarrangement. We\nfurther reveal that a focus on smaller visual segments can help multimodal\nlarge language models (MLLMs) mitigate these failures in the generation\nprocess. In this paper, we propose DCGen, a divide-and-conquer-based approach\nto automate the translation of webpage design to UI code. DCGen starts by\ndividing screenshots into manageable segments, generating descriptions for each\nsegment, and then reassembling them into complete UI code for the entire\nscreenshot. We conduct extensive testing with a dataset comprised of real-world\nwebsites and various MLLMs and demonstrate that DCGen achieves up to a 14%\nimprovement in visual similarity over competing methods. To the best of our\nknowledge, DCGen is the first segment-aware prompt-based approach for\ngenerating UI code directly from screenshots.\n","authors":["Yuxuan Wan","Chaozheng Wang","Yi Dong","Wenxuan Wang","Shuqing Li","Yintong Huo","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2406.16386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14283v2","updated":"2024-06-24T07:50:56Z","published":"2024-06-20T13:08:09Z","title":"Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning","summary":"  Large Language Models (LLMs) have demonstrated impressive capability in many\nnatural language tasks. However, the auto-regressive generation process makes\nLLMs prone to produce errors, hallucinations and inconsistent statements when\nperforming multi-step reasoning. In this paper, by casting multi-step reasoning\nof LLMs as a heuristic search problem, we aim to alleviate the pathology by\nintroducing Q*, a general, versatile and agile framework for guiding LLMs\ndecoding process with deliberative planning. By learning a plug-and-play\nQ-value model as heuristic function for estimating expected future rewards, our\nQ* can effectively guide LLMs to select the most promising next reasoning step\nwithout fine-tuning LLMs for the current task, which avoids the significant\ncomputational overhead and potential risk of performance degeneration on other\ntasks. Extensive experiments on GSM8K, MATH and MBPP demonstrate the\nsuperiority of our method, contributing to improving the reasoning performance\nof existing open-source LLMs.\n","authors":["Chaojie Wang","Yanchen Deng","Zhiyi Lv","Shuicheng Yan","An Bo"],"pdf_url":"https://arxiv.org/pdf/2406.14283v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15250v2","updated":"2024-06-24T07:49:25Z","published":"2024-03-22T14:47:35Z","title":"Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A\n  Multifaceted Statistical Approach","summary":"  Amidst the rapid evolution of LLMs, the significance of evaluation in\ncomprehending and propelling these models forward is increasingly paramount.\nEvaluations have revealed that factors such as scaling, training types,\narchitectures and other factors profoundly impact the performance of LLMs.\nHowever, the extent and nature of these impacts continue to be subjects of\ndebate because most assessments have been restricted to a limited number of\nmodels and data points. Clarifying the effects of these factors on performance\nscores can be more effectively achieved through a statistical lens. Our study\nembarks on a thorough re-examination of these LLMs, targeting the inadequacies\nin current evaluation methods. With the advent of a uniform evaluation\nframework, our research leverages an expansive dataset of evaluation results,\nintroducing a comprehensive statistical methodology. This includes the\napplication of ANOVA, Tukey HSD tests, GAMM, and clustering technique, offering\na robust and transparent approach to deciphering LLM performance data. Contrary\nto prevailing findings, our results challenge assumptions about emergent\nabilities and the influence of given training types and architectures in LLMs.\nThese findings furnish new perspectives on the characteristics, intrinsic\nnature, and developmental trajectories of LLMs. By providing straightforward\nand reliable methods to scrutinize and reassess LLM performance data, this\nstudy contributes a nuanced perspective on LLM efficiency and potentials.\n","authors":["Kun Sun","Rong Wang","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2403.15250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16377v1","updated":"2024-06-24T07:42:32Z","published":"2024-06-24T07:42:32Z","title":"On the Transformations across Reward Model, Parameter Update, and\n  In-Context Prompt","summary":"  Despite the general capabilities of pre-trained large language models (LLMs),\nthey still need further adaptation to better serve practical applications. In\nthis paper, we demonstrate the interchangeability of three popular and distinct\nadaptation tools: parameter updating, reward modeling, and in-context\nprompting. This interchangeability establishes a triangular framework with six\ntransformation directions, each of which facilitates a variety of applications.\nOur work offers a holistic view that unifies numerous existing studies and\nsuggests potential research directions. We envision our work as a useful\nroadmap for future research on LLMs.\n","authors":["Deng Cai","Huayang Li","Tingchen Fu","Siheng Li","Weiwen Xu","Shuaiyi Li","Bowen Cao","Zhisong Zhang","Xinting Huang","Leyang Cui","Yan Wang","Lemao Liu","Taro Watanabe","Shuming Shi"],"pdf_url":"https://arxiv.org/pdf/2406.16377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05365v2","updated":"2024-06-24T07:39:26Z","published":"2024-06-08T06:04:55Z","title":"CaLM: Contrasting Large and Small Language Models to Verify Grounded\n  Generation","summary":"  Grounded generation aims to equip language models (LMs) with the ability to\nproduce more credible and accountable responses by accurately citing verifiable\nsources. However, existing methods, by either feeding LMs with raw or\npreprocessed materials, remain prone to errors. To address this, we introduce\nCaLM, a novel verification framework. CaLM leverages the insight that a robust\ngrounded response should be consistent with information derived solely from its\ncited sources. Our framework empowers smaller LMs, which rely less on\nparametric memory and excel at processing relevant information given a query,\nto validate the output of larger LMs. Larger LM responses that closely align\nwith the smaller LMs' output, which relies exclusively on cited documents, are\nverified. Responses showing discrepancies are iteratively refined through a\nfeedback loop. Experiments on three open-domain question-answering datasets\ndemonstrate significant performance gains of 1.5% to 7% absolute average\nwithout any required model fine-tuning.\n","authors":["I-Hung Hsu","Zifeng Wang","Long T. Le","Lesly Miculicich","Nanyun Peng","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2406.05365v2.pdf","comment":"ACL 2024 Camera Ready Version"},{"id":"http://arxiv.org/abs/2311.09086v3","updated":"2024-06-24T07:31:19Z","published":"2023-11-15T16:30:44Z","title":"The Uli Dataset: An Exercise in Experience Led Annotation of oGBV","summary":"  Online gender based violence has grown concomitantly with adoption of the\ninternet and social media. Its effects are worse in the Global majority where\nmany users use social media in languages other than English. The scale and\nvolume of conversations on the internet has necessitated the need for automated\ndetection of hate speech, and more specifically gendered abuse. There is,\nhowever, a lack of language specific and contextual data to build such\nautomated tools. In this paper we present a dataset on gendered abuse in three\nlanguages- Hindi, Tamil and Indian English. The dataset comprises of tweets\nannotated along three questions pertaining to the experience of gender abuse,\nby experts who identify as women or a member of the LGBTQIA community in South\nAsia. Through this dataset we demonstrate a participatory approach to creating\ndatasets that drive AI systems.\n","authors":["Arnav Arora","Maha Jinadoss","Cheshta Arora","Denny George"," Brindaalakshmi","Haseena Dawood Khan","Kirti Rawat"," Div"," Ritash","Seema Mathur","Shivani Yadav","Shehla Rashid Shora","Rie Raut","Sumit Pawar","Apurva Paithane"," Sonia"," Vivek","Dharini Priscilla"," Khairunnisha","Grace Banu","Ambika Tandon","Rishav Thakker","Rahul Dev Korra","Aatman Vaidya","Tarunima Prabhakar"],"pdf_url":"https://arxiv.org/pdf/2311.09086v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14745v2","updated":"2024-06-24T06:57:05Z","published":"2024-06-20T21:27:57Z","title":"Relation Extraction with Fine-Tuned Large Language Models in Retrieval\n  Augmented Generation Frameworks","summary":"  Information Extraction (IE) is crucial for converting unstructured data into\nstructured formats like Knowledge Graphs (KGs). A key task within IE is\nRelation Extraction (RE), which identifies relationships between entities in\ntext. Various RE methods exist, including supervised, unsupervised, weakly\nsupervised, and rule-based approaches. Recent studies leveraging pre-trained\nlanguage models (PLMs) have shown significant success in this area. In the\ncurrent era dominated by Large Language Models (LLMs), fine-tuning these models\ncan overcome limitations associated with zero-shot LLM prompting-based RE\nmethods, especially regarding domain adaptation challenges and identifying\nimplicit relations between entities in sentences. These implicit relations,\nwhich cannot be easily extracted from a sentence's dependency tree, require\nlogical inference for accurate identification. This work explores the\nperformance of fine-tuned LLMs and their integration into the Retrieval\nAugmented-based (RAG) RE approach to address the challenges of identifying\nimplicit relations at the sentence level, particularly when LLMs act as\ngenerators within the RAG framework. Empirical evaluations on the TACRED,\nTACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant\nperformance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,\nand T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,\nwhere implicit relations are common, surpassing previous results on this\ndataset. Additionally, our method outperforms previous works on TACRED, TACREV,\nand Re-TACRED, demonstrating exceptional performance across diverse evaluation\nscenarios.\n","authors":["Sefika Efeoglu","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2406.14745v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2406.16357v1","updated":"2024-06-24T06:53:37Z","published":"2024-06-24T06:53:37Z","title":"Towards Lightweight Graph Neural Network Search with Curriculum Graph\n  Sparsification","summary":"  Graph Neural Architecture Search (GNAS) has achieved superior performance on\nvarious graph-structured tasks. However, existing GNAS studies overlook the\napplications of GNAS in resource-constraint scenarios. This paper proposes to\ndesign a joint graph data and architecture mechanism, which identifies\nimportant sub-architectures via the valuable graph data. To search for optimal\nlightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural\nArchitecture Search with Graph SparsIfication and Network Pruning (GASSIP)\nmethod. In particular, GASSIP comprises an operation-pruned architecture search\nmodule to enable efficient lightweight GNN search. Meanwhile, we design a novel\ncurriculum graph data sparsification module with an architecture-aware\nedge-removing difficulty measurement to help select optimal sub-architectures.\nWith the aid of two differentiable masks, we iteratively optimize these two\nmodules to efficiently search for the optimal lightweight architecture.\nExtensive experiments on five benchmarks demonstrate the effectiveness of\nGASSIP. Particularly, our method achieves on-par or even higher node\nclassification performance with half or fewer model parameters of searched GNNs\nand a sparser graph.\n","authors":["Beini Xie","Heng Chang","Ziwei Zhang","Zeyang Zhang","Simin Wu","Xin Wang","Yuan Meng","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.16357v1.pdf","comment":"Accepted by KDD 2024. The two first authors made equal contributions"},{"id":"http://arxiv.org/abs/2406.16346v1","updated":"2024-06-24T06:39:02Z","published":"2024-06-24T06:39:02Z","title":"Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific\n  Training Tasks","summary":"  Large language models (LLMs) and large visual language models (LVLMs) have\nbeen at the forefront of the artificial intelligence field, particularly for\ntasks like text generation, video captioning, and question-answering.\nTypically, it is more applicable to train these models on broader knowledge\nbases or datasets to increase generalizability, learn relationships between\ntopics, and recognize patterns. Instead, we propose to provide instructional\ndatasets specific to the task of each modality within a distinct domain and\nthen fine-tune the parameters of the model using LORA. With our approach, we\ncan eliminate all noise irrelevant to the given task while also ensuring that\nthe model generates with enhanced precision. For this work, we use Video-LLaVA\nto generate recipes given cooking videos without transcripts. Video-LLaVA's\nmultimodal architecture allows us to provide cooking images to its image\nencoder, cooking videos to its video encoder, and general cooking questions to\nits text encoder. Thus, we aim to remove all noise unrelated to cooking while\nimproving our model's capabilities to generate specific ingredient lists and\ndetailed instructions. As a result, our approach to fine-tuning Video-LLaVA\nleads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.\nWhile this may seem like a marginal increase, our model trains on an image\ninstruction dataset 2.5% the size of Video-LLaVA's and a video instruction\ndataset 23.76% of Video-LLaVA's.\n","authors":["Daniel Wen","Nafisa Hussain"],"pdf_url":"https://arxiv.org/pdf/2406.16346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10467v3","updated":"2024-06-24T06:32:27Z","published":"2024-05-16T23:24:48Z","title":"Agent Design Pattern Catalogue: A Collection of Architectural Patterns\n  for Foundation Model based Agents","summary":"  Foundation model-enabled generative artificial intelligence facilitates the\ndevelopment and implementation of agents, which can leverage distinguished\nreasoning and language processing capabilities to takes a proactive, autonomous\nrole to pursue users' goals. Nevertheless, there is a lack of systematic\nknowledge to guide practitioners in designing the agents considering challenges\nof goal-seeking (including generating instrumental goals and plans), such as\nhallucinations inherent in foundation models, explainability of reasoning\nprocess, complex accountability, etc. To address this issue, we have performed\na systematic literature review to understand the state-of-the-art foundation\nmodel-based agents and the broader ecosystem. In this paper, we present a\npattern catalogue consisting of 17 architectural patterns with analyses of the\ncontext, forces, and trade-offs as the outcomes from the previous literature\nreview. The proposed catalogue can provide holistic guidance for the effective\nuse of patterns, and support the architecture design of foundation model-based\nagents by facilitating goal-seeking and plan generation.\n","authors":["Yue Liu","Sin Kit Lo","Qinghua Lu","Liming Zhu","Dehai Zhao","Xiwei Xu","Stefan Harrer","Jon Whittle"],"pdf_url":"https://arxiv.org/pdf/2405.10467v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10638v6","updated":"2024-06-24T06:28:42Z","published":"2023-10-16T17:57:12Z","title":"In-context Pretraining: Language Modeling Beyond Document Boundaries","summary":"  Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).\n","authors":["Weijia Shi","Sewon Min","Maria Lomeli","Chunting Zhou","Margaret Li","Gergely Szilvasy","Rich James","Xi Victoria Lin","Noah A. Smith","Luke Zettlemoyer","Scott Yih","Mike Lewis"],"pdf_url":"https://arxiv.org/pdf/2310.10638v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16333v1","updated":"2024-06-24T06:12:16Z","published":"2024-06-24T06:12:16Z","title":"Prompt-Consistency Image Generation (PCIG): A Unified Framework\n  Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models","summary":"  The rapid advancement of Text-to-Image(T2I) generative models has enabled the\nsynthesis of high-quality images guided by textual descriptions. Despite this\nsignificant progress, these models are often susceptible in generating contents\nthat contradict the input text, which poses a challenge to their reliability\nand practical deployment. To address this problem, we introduce a novel\ndiffusion-based framework to significantly enhance the alignment of generated\nimages with their corresponding descriptions, addressing the inconsistency\nbetween visual output and textual input. Our framework is built upon a\ncomprehensive analysis of inconsistency phenomena, categorizing them based on\ntheir manifestation in the image. Leveraging a state-of-the-art large language\nmodule, we first extract objects and construct a knowledge graph to predict the\nlocations of these objects in potentially generated images. We then integrate a\nstate-of-the-art controllable image generation model with a visual text\ngeneration module to generate an image that is consistent with the original\nprompt, guided by the predicted object locations. Through extensive experiments\non an advanced multimodal hallucination benchmark, we demonstrate the efficacy\nof our approach in accurately generating the images without the inconsistency\nwith the original prompt. The code can be accessed via\nhttps://github.com/TruthAI-Lab/PCIG.\n","authors":["Yichen Sun","Zhixuan Chu","Zhan Qin","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16330v1","updated":"2024-06-24T05:57:55Z","published":"2024-06-24T05:57:55Z","title":"Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer\n  Merging","summary":"  While large language models (LLMs) excel in many domains, their complexity\nand scale challenge deployment in resource-limited environments. Current\ncompression techniques, such as parameter pruning, often fail to effectively\nutilize the knowledge from pruned parameters. To address these challenges, we\npropose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA),\na novel approach that uses manifold learning and the Normalized Pairwise\nInformation Bottleneck (NPIB) measure to merge similar layers, reducing model\nsize while preserving essential performance. We evaluate MKA on multiple\nbenchmark datasets and various LLMs. Our findings show that MKA not only\npreserves model performance but also achieves substantial compression ratios,\noutperforming traditional pruning methods. Moreover, when coupled with\nquantization, MKA delivers even greater compression. Specifically, on the MMLU\ndataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75%\nwith a minimal performance decrease of only 2.82\\%. The proposed MKA method\noffers a resource-efficient and performance-preserving model compression\ntechnique for LLMs.\n","authors":["Deyuan Liu","Zhanyue Qin","Hairu Wang","Zhao Yang","Zecheng Wang","Fangying Rong","Qingbin Liu","Yanchao Hao","Xi Chen","Cunhang Fan","Zhao Lv","Zhiying Tu","Dianhui Chu","Bo Li","Dianbo Sui"],"pdf_url":"https://arxiv.org/pdf/2406.16330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12842v2","updated":"2024-06-24T05:40:38Z","published":"2024-02-20T09:10:08Z","title":"PromptKD: Distilling Student-Friendly Knowledge for Generative Language\n  Models via Prompt Tuning","summary":"  Recent advancements in large language models (LLMs) have raised concerns\nabout inference costs, increasing the need for research into model compression.\nWhile knowledge distillation (KD) is a prominent method for this, research on\nKD for generative language models like LLMs is relatively sparse, and the\napproach of distilling student-friendly knowledge, which has shown promising\nperformance in KD for classification models, remains unexplored in generative\nlanguage models. To explore this approach, we propose PromptKD, a simple yet\neffective method that utilizes prompt tuning - for the first time in KD - to\nenable generative language models to transfer student-friendly knowledge.\nUnlike previous works in classification that require fine-tuning the entire\nteacher model for extracting student-friendly knowledge, PromptKD achieves\nsimilar effects by adding a small number of prompt tokens and tuning only the\nprompt with student guidance. Extensive experiments on instruction-following\ndatasets show that PromptKD achieves state-of-the-art performance while adding\nonly 0.0007% of the teacher's parameters as prompts. Further analysis suggests\nthat distilling student-friendly knowledge alleviates exposure bias effectively\nthroughout the entire training process, leading to performance enhancements.\n","authors":["Gyeongman Kim","Doohyuk Jang","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2402.12842v2.pdf","comment":"Code: https://github.com/gmkim-ai/PromptKD"},{"id":"http://arxiv.org/abs/2406.16321v1","updated":"2024-06-24T05:14:09Z","published":"2024-06-24T05:14:09Z","title":"Multimodal Graph Benchmark","summary":"  Associating unstructured data with structured information is crucial for\nreal-world tasks that require relevance search. However, existing graph\nlearning benchmarks often overlook the rich semantic information associate with\neach node. To bridge such gap, we introduce the Multimodal Graph Benchmark\n(MM-GRAPH), the first comprehensive multi-modal graph benchmark that\nincorporates both textual and visual information. MM-GRAPH surpasses previous\nefforts, which have primarily focused on text-attributed graphs with various\nconnectivity patterns. MM-GRAPH consists of five graph learning datasets of\nvarious scales that are appropriate for different learning tasks. Their\nmultimodal node features, enabling a more comprehensive evaluation of graph\nlearning algorithms in real-world scenarios. To facilitate research on\nmultimodal graph learning, we further provide an extensive study on the\nperformance of various graph neural networks in the presence of features from\nvarious modalities. MM-GRAPH aims to foster research on multimodal graph\nlearning and drive the development of more advanced and robust graph learning\nalgorithms. By providing a diverse set of datasets and benchmarks, MM-GRAPH\nenables researchers to evaluate and compare their models in realistic settings,\nultimately leading to improved performance on real-world applications that rely\non multimodal graph data.\n","authors":["Jing Zhu","Yuhang Zhou","Shengyi Qian","Zhongmou He","Tong Zhao","Neil Shah","Danai Koutra"],"pdf_url":"https://arxiv.org/pdf/2406.16321v1.pdf","comment":"https://mm-graph-benchmark.github.io/"},{"id":"http://arxiv.org/abs/2406.16316v1","updated":"2024-06-24T04:50:12Z","published":"2024-06-24T04:50:12Z","title":"Does Cross-Cultural Alignment Change the Commonsense Morality of\n  Language Models?","summary":"  Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.\n","authors":["Yuu Jinnai"],"pdf_url":"https://arxiv.org/pdf/2406.16316v1.pdf","comment":"The 2nd Workshop on Cross-Cultural Considerations in NLP (C3NLP) at\n  ACL 2024"},{"id":"http://arxiv.org/abs/2402.14208v3","updated":"2024-06-24T04:49:16Z","published":"2024-02-22T01:20:51Z","title":"LLM-Assisted Content Conditional Debiasing for Fair Text Embedding","summary":"  Mitigating biases in machine learning models has become an increasing concern\nin Natural Language Processing (NLP), particularly in developing fair text\nembeddings, which are crucial yet challenging for real-world applications like\nsearch engines. In response, this paper proposes a novel method for learning\nfair text embeddings. First, we define a novel content-conditional equal\ndistance (CCED) fairness for text embeddings, ensuring content-conditional\nindependence between sensitive attributes and text embeddings. Building on\nCCED, we introduce a content-conditional debiasing (CCD) loss to ensure that\nembeddings of texts with different sensitive attributes but identical content\nmaintain the same distance from the embedding of their corresponding neutral\ntext. Additionally, we tackle the issue of insufficient training data by using\nLarge Language Models (LLMs) with instructions to fairly augment texts into\ndifferent sensitive groups. Our extensive evaluations show that our approach\neffectively enhances fairness while maintaining the utility of embeddings.\nFurthermore, our augmented dataset, combined with the CCED metric, serves as an\nnew benchmark for evaluating fairness.\n","authors":["Wenlong Deng","Blair Chen","Beidi Zhao","Chiyu Zhang","Xiaoxiao Li","Christos Thrampoulidis"],"pdf_url":"https://arxiv.org/pdf/2402.14208v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16308v1","updated":"2024-06-24T04:17:03Z","published":"2024-06-24T04:17:03Z","title":"Anomaly Detection of Tabular Data Using LLMs","summary":"  Large language models (LLMs) have shown their potential in long-context\nunderstanding and mathematical reasoning. In this paper, we study the problem\nof using LLMs to detect tabular anomalies and show that pre-trained LLMs are\nzero-shot batch-level anomaly detectors. That is, without extra\ndistribution-specific model fitting, they can discover hidden outliers in a\nbatch of data, demonstrating their ability to identify low-density data\nregions. For LLMs that are not well aligned with anomaly detection and\nfrequently output factual errors, we apply simple yet effective data-generating\nprocesses to simulate synthetic batch-level anomaly detection datasets and\npropose an end-to-end fine-tuning strategy to bring out the potential of LLMs\nin detecting real anomalies. Experiments on a large anomaly detection benchmark\n(ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art\ntransductive learning-based anomaly detection methods and ii) the efficacy of\nour synthetic dataset and fine-tuning strategy in aligning LLMs to this task.\n","authors":["Aodong Li","Yunhan Zhao","Chen Qiu","Marius Kloft","Padhraic Smyth","Maja Rudolph","Stephan Mandt"],"pdf_url":"https://arxiv.org/pdf/2406.16308v1.pdf","comment":"accepted at the Anomaly Detection with Foundation Models workshop"},{"id":"http://arxiv.org/abs/2406.07599v2","updated":"2024-06-24T04:14:26Z","published":"2024-06-11T16:42:02Z","title":"CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence","summary":"  Cyber threat intelligence (CTI) is crucial in today's cybersecurity\nlandscape, providing essential insights to understand and mitigate the\never-evolving cyber threats. The recent rise of Large Language Models (LLMs)\nhave shown potential in this domain, but concerns about their reliability,\naccuracy, and hallucinations persist. While existing benchmarks provide general\nevaluations of LLMs, there are no benchmarks that address the practical and\napplied aspects of CTI-specific tasks. To bridge this gap, we introduce\nCTIBench, a benchmark designed to assess LLMs' performance in CTI applications.\nCTIBench includes multiple datasets focused on evaluating knowledge acquired by\nLLMs in the cyber-threat landscape. Our evaluation of several state-of-the-art\nmodels on these tasks provides insights into their strengths and weaknesses in\nCTI contexts, contributing to a better understanding of LLM capabilities in\nCTI.\n","authors":["Md Tanvirul Alam","Dipkamal Bhusal","Le Nguyen","Nidhi Rastogi"],"pdf_url":"https://arxiv.org/pdf/2406.07599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11217v2","updated":"2024-06-24T03:55:30Z","published":"2024-06-17T05:23:18Z","title":"WeatherQA: Can Multimodal Language Models Reason about Severe Weather?","summary":"  Severe convective weather events, such as hail, tornadoes, and thunderstorms,\noften occur quickly yet cause significant damage, costing billions of dollars\nevery year. This highlights the importance of forecasting severe weather\nthreats hours in advance to better prepare meteorologists and residents in\nat-risk areas. Can modern large foundation models perform such forecasting?\nExisting weather benchmarks typically focus only on predicting time-series\nchanges in certain weather parameters (e.g., temperature, moisture) with\ntext-only features. In this work, we introduce WeatherQA, the first multimodal\ndataset designed for machines to reason about complex combinations of weather\nparameters (a.k.a., ingredients) and predict severe weather in real-world\nscenarios. The dataset includes over 8,000 (multi-images, text) pairs for\ndiverse severe weather events. Each pair contains rich information crucial for\nforecasting -- the images describe the ingredients capturing environmental\ninstability, surface observations, and radar reflectivity, and the text\ncontains forecast analyses written by human experts. With WeatherQA, we\nevaluate state-of-the-art vision language models, including GPT4, Claude3.5,\nGemini-1.5, and a fine-tuned Llama3-based VLM, by designing two challenging\ntasks: (1) multi-choice QA for predicting affected area and (2) classification\nof the development potential of severe convection. These tasks require deep\nunderstanding of domain knowledge (e.g., atmospheric dynamics) and complex\nreasoning over multimodal data (e.g., interactions between weather parameters).\nWe show a substantial gap between the strongest VLM, GPT4o, and human\nreasoning. Our comprehensive case study with meteorologists further reveals the\nweaknesses of the models, suggesting that better training and data integration\nare necessary to bridge this gap. WeatherQA link:\nhttps://github.com/chengqianma/WeatherQA.\n","authors":["Chengqian Ma","Zhanxiang Hua","Alexandra Anderson-Frey","Vikram Iyer","Xin Liu","Lianhui Qin"],"pdf_url":"https://arxiv.org/pdf/2406.11217v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.16301v1","updated":"2024-06-24T03:55:25Z","published":"2024-06-24T03:55:25Z","title":"UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos","summary":"  With the surge in the amount of video data, video summarization techniques,\nincluding visual-modal(VM) and textual-modal(TM) summarization, are attracting\nmore and more attention. However, unimodal summarization inevitably loses the\nrich semantics of the video. In this paper, we focus on a more comprehensive\nvideo summarization task named Bimodal Semantic Summarization of Videos\n(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in\n(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing\nmethods, our construction procedure contains a VM-Summary extraction algorithm\naiming to preserve the most salient content within long videos. Based on BIDS,\nwe propose a Unified framework UBiSS for the BiSSV task, which models the\nsaliency information in the video and generates a TM-summary and VM-summary\nsimultaneously. We further optimize our model with a list-wise ranking-based\nobjective to improve its capacity to capture highlights. Lastly, we propose a\nmetric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.\nExperiments show that our unified framework achieves better performance than\nmulti-stage summarization pipelines. Code and data are available at\nhttps://github.com/MeiYutingg/UBiSS.\n","authors":["Yuting Mei","Linli Yao","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.16301v1.pdf","comment":"Accepted by ACM International Conference on Multimedia Retrieval\n  (ICMR'24)"},{"id":"http://arxiv.org/abs/2406.16299v1","updated":"2024-06-24T03:52:52Z","published":"2024-06-24T03:52:52Z","title":"Compensate Quantization Errors: Make Weights Hierarchical to Compensate\n  Each Other","summary":"  Emergent Large Language Models (LLMs) use their extraordinary performance and\npowerful deduction capacity to discern from traditional language models.\nHowever, the expenses of computational resources and storage for these LLMs are\nstunning, quantization then arises as a trending conversation. To address\naccuracy decay caused by quantization, two streams of works in post-training\nquantization methods stand out. One uses other weights to compensate existing\nquantization error, while the other transfers the quantization difficulty to\nother parts in the model. Combining both merits, we introduce Learnable\nSingular value Increment (LSI) as an advanced solution. LSI uses Singular Value\nDecomposition to extract singular values of the weights and make them learnable\nto help weights compensate each other conditioned on activation. Incorporating\nLSI with existing techniques, we achieve state-of-the-art performance in\ndiverse quantization settings, no matter in weight-only, weight-activation or\nextremely low bit scenarios. By unleashing the potential of LSI, efficient\nfinetuning on quantized model is no longer a prohibitive problem.\n","authors":["Yifei Gao","Jie Ou","Lei Wang","Yuting Xiao","Zhiyuan Xiang","Ruiting Dai","Jun Cheng"],"pdf_url":"https://arxiv.org/pdf/2406.16299v1.pdf","comment":"Efficient quantization method"},{"id":"http://arxiv.org/abs/2406.02081v2","updated":"2024-06-24T03:38:46Z","published":"2024-06-04T08:04:23Z","title":"FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement\n  Learning","summary":"  Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.\n","authors":["Wenzhe Li","Zihan Ding","Seth Karten","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2406.02081v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.16295v1","updated":"2024-06-24T03:37:51Z","published":"2024-06-24T03:37:51Z","title":"Relaxing Continuous Constraints of Equivariant Graph Neural Networks for\n  Physical Dynamics Learning","summary":"  Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive\nbiases into graph neural networks has improved their generalization ability and\ndata efficiency in unbounded physical dynamics modeling. However, in various\nscientific and engineering applications, the symmetries of dynamics are\nfrequently discrete due to the boundary conditions. Thus, existing GNNs either\noverlook necessary symmetry, resulting in suboptimal representation ability, or\nimpose excessive equivariance, which fails to generalize to unobserved\nsymmetric dynamics. In this work, we propose a general Discrete Equivariant\nGraph Neural Network (DEGNN) that guarantees equivariance to a given discrete\npoint group. Specifically, we show that such discrete equivariant message\npassing could be constructed by transforming geometric features into\npermutation-invariant embeddings. Through relaxing continuous equivariant\nconstraints, DEGNN can employ more geometric feature combinations to\napproximate unobserved physical object interaction functions. Two\nimplementation approaches of DEGNN are proposed based on ranking or pooling\npermutation-invariant functions. We apply DEGNN to various physical dynamics,\nranging from particle, molecular, crowd to vehicle dynamics. In twenty\nscenarios, DEGNN significantly outperforms existing state-of-the-art\napproaches. Moreover, we show that DEGNN is data efficient, learning with less\ndata, and can generalize across scenarios such as unobserved orientation.\n","authors":["Zinan Zheng","Yang Liu","Jia Li","Jianhua Yao","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2406.16295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16294v1","updated":"2024-06-24T03:36:29Z","published":"2024-06-24T03:36:29Z","title":"LangSuitE: Planning, Controlling and Interacting with Large Language\n  Models in Embodied Text Environments","summary":"  Recent advances in Large Language Models (LLMs) have shown inspiring\nachievements in constructing autonomous agents that rely on language\ndescriptions as inputs. However, it remains unclear how well LLMs can function\nas few-shot or zero-shot embodied agents in dynamic interactive environments.\nTo address this gap, we introduce LangSuitE, a versatile and simulation-free\ntestbed featuring 6 representative embodied tasks in textual embodied worlds.\nCompared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to\ndiverse environments without multiple simulation engines, (ii) evaluates\nagents' capacity to develop ``internalized world knowledge'' with embodied\nobservations, and (iii) allows easy customization of communication and action\nstrategies. To address the embodiment challenge, we devise a novel\nchain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t.\nhistory information. Comprehensive benchmark results illustrate challenges and\ninsights of embodied planning. LangSuitE represents a significant step toward\nbuilding embodied generalists in the context of language models.\n","authors":["Zixia Jia","Mengmeng Wang","Baichen Tong","Song-Chun Zhu","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.16294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16293v1","updated":"2024-06-24T03:36:19Z","published":"2024-06-24T03:36:19Z","title":"Combining Supervised Learning and Reinforcement Learning for Multi-Label\n  Classification Tasks with Partial Labels","summary":"  Traditional supervised learning heavily relies on human-annotated datasets,\nespecially in data-hungry neural approaches. However, various tasks, especially\nmulti-label tasks like document-level relation extraction, pose challenges in\nfully manual annotation due to the specific domain knowledge and large class\nsets. Therefore, we address the multi-label positive-unlabelled learning\n(MLPUL) problem, where only a subset of positive classes is annotated. We\npropose Mixture Learner for Partially Annotated Classification (MLPAC), an\nRL-based framework combining the exploration ability of reinforcement learning\nand the exploitation ability of supervised learning. Experimental results\nacross various tasks, including document-level relation extraction, multi-label\nimage classification, and binary PU learning, demonstrate the generalization\nand effectiveness of our framework.\n","authors":["Zixia Jia","Junpeng Li","Shichuan Zhang","Anji Liu","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.16293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16282v1","updated":"2024-06-24T03:09:15Z","published":"2024-06-24T03:09:15Z","title":"Reducing Fine-Tuning Memory Overhead by Approximate and Memory-Sharing\n  Backpropagation","summary":"  Fine-tuning pretrained large models to downstream tasks is an important\nproblem, which however suffers from huge memory overhead due to large-scale\nparameters. This work strives to reduce memory overhead in fine-tuning from\nperspectives of activation function and layer normalization. To this end, we\npropose the Approximate Backpropagation (Approx-BP) theory, which provides the\ntheoretical feasibility of decoupling the forward and backward passes. We apply\nour Approx-BP theory to backpropagation training and derive memory-efficient\nalternatives of GELU and SiLU activation functions, which use derivative\nfunctions of ReLUs in the backward pass while keeping their forward pass\nunchanged. In addition, we introduce a Memory-Sharing Backpropagation strategy,\nwhich enables the activation memory to be shared by two adjacent layers,\nthereby removing activation memory usage redundancy. Our method neither induces\nextra computation nor reduces training efficiency. We conduct extensive\nexperiments with pretrained vision and language models, and the results\ndemonstrate that our proposal can reduce up to $\\sim$$30\\%$ of the peak memory\nusage. Our code is released at https://github.com/yyyyychen/LowMemoryBP.\n","authors":["Yuchen Yang","Yingdong Shi","Cheems Wang","Xiantong Zhen","Yuxuan Shi","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2406.16282v1.pdf","comment":"25 pages, ICML 2024 Accepted"},{"id":"http://arxiv.org/abs/2308.11131v5","updated":"2024-06-24T02:44:28Z","published":"2023-08-22T02:25:04Z","title":"ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential\n  Behavior Comprehension in Recommendation","summary":"  With large language models (LLMs) achieving remarkable breakthroughs in\nnatural language processing (NLP) domains, LLM-enhanced recommender systems\nhave received much attention and have been actively explored currently. In this\npaper, we focus on adapting and empowering a pure large language model for\nzero-shot and few-shot recommendation tasks. First and foremost, we identify\nand formulate the lifelong sequential behavior incomprehension problem for LLMs\nin recommendation domains, i.e., LLMs fail to extract useful information from a\ntextual context of long user behavior sequence, even if the length of context\nis far from reaching the context limitation of LLMs. To address such an issue\nand improve the recommendation performance of LLMs, we propose a novel\nframework, namely Retrieval-enhanced Large Language models (ReLLa) for\nrecommendation tasks in both zero-shot and few-shot settings. For zero-shot\nrecommendation, we perform semantic user behavior retrieval (SUBR) to improve\nthe data quality of testing samples, which greatly reduces the difficulty for\nLLMs to extract the essential knowledge from user behavior sequences. As for\nfew-shot recommendation, we further design retrieval-enhanced instruction\ntuning (ReiT) by adopting SUBR as a data augmentation technique for training\nsamples. Specifically, we develop a mixed training dataset consisting of both\nthe original data samples and their retrieval-enhanced counterparts. We conduct\nextensive experiments on three real-world public datasets to demonstrate the\nsuperiority of ReLLa compared with existing baseline models, as well as its\ncapability for lifelong sequential behavior comprehension. To be highlighted,\nwith only less than 10% training samples, few-shot ReLLa can outperform\ntraditional CTR models that are trained on the entire training set (e.g.,\nDCNv2, DIN, SIM). The code is available\n\\url{https://github.com/LaVieEnRose365/ReLLa}.\n","authors":["Jianghao Lin","Rong Shan","Chenxu Zhu","Kounianhua Du","Bo Chen","Shigang Quan","Ruiming Tang","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.11131v5.pdf","comment":"Accepted by WWW 2024. Full and More Readable Version"},{"id":"http://arxiv.org/abs/2406.16272v1","updated":"2024-06-24T02:38:30Z","published":"2024-06-24T02:38:30Z","title":"Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via\n  Attention-Guided Feature Enhancement","summary":"  Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention\nfor their ability to generate high-quality images from textual descriptions.\nHowever, these models often produce images that do not fully align with the\ninput prompts, resulting in semantic inconsistencies. The most prominent issue\namong these semantic inconsistencies is catastrophic-neglect, where the images\ngenerated by T2I DMs miss key objects mentioned in the prompt. We first conduct\nan empirical study on this issue, exploring the prevalence of\ncatastrophic-neglect, potential mitigation strategies with feature enhancement,\nand the insights gained. Guided by the empirical findings, we propose an\nautomated repair approach named Patcher to address catastrophic-neglect in T2I\nDMs. Specifically, Patcher first determines whether there are any neglected\nobjects in the prompt, and then applies attention-guided feature enhancement to\nthese neglected objects, resulting in a repaired prompt. Experimental results\non three versions of Stable Diffusion demonstrate that Patcher effectively\nrepairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct\nRate in image generation compared to baselines.\n","authors":["Zhiyuan Chang","Mingyang Li","Junjie Wang","Yi Liu","Qing Wang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16272v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2404.01054v3","updated":"2024-06-24T02:31:06Z","published":"2024-04-01T11:26:50Z","title":"Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language\n  Model Alignment","summary":"  Best-of-N (BoN) sampling with a reward model has been shown to be an\neffective strategy for aligning Large Language Models (LLMs) to human\npreferences at the time of decoding. BoN sampling is susceptible to a problem\nknown as reward hacking. Because the reward model is an imperfect proxy for the\ntrue objective, over-optimizing its value can compromise its performance on the\ntrue objective. A common solution to prevent reward hacking in preference\nlearning techniques is to optimize a reward using proximity regularization\n(e.g., KL regularization), which ensures that the language model remains close\nto the reference model. In this research, we propose Regularized Best-of-N\n(RBoN), a variant of BoN that aims to mitigate reward hacking by incorporating\na proximity term in response selection, similar to preference learning\ntechniques. We evaluate RBoN on the AlpacaFarm and Anthropic's hh-rlhf datasets\nand find that it outperforms BoN. As an application of RBoN, we use RBoN to\ngenerate a pairwise preference learning dataset. Experimental results show that\na DPO model trained on a dataset generated with RBoN outperforms a DPO model\ngenerated with vanilla BoN. Our code is available at\nhttps://github.com/CyberAgentAILab/regularized-bon\n","authors":["Yuu Jinnai","Tetsuro Morimura","Kaito Ariu","Kenshi Abe"],"pdf_url":"https://arxiv.org/pdf/2404.01054v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.07269v3","updated":"2024-06-24T02:17:57Z","published":"2023-08-14T16:52:42Z","title":"EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language\n  Models","summary":"  Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy\nissues, which means they are unaware of unseen events or generate text with\nincorrect facts owing to outdated/noisy data. To this end, many knowledge\nediting approaches for LLMs have emerged -- aiming to subtly inject/edit\nupdated knowledge or adjust undesired behavior while minimizing the impact on\nunrelated inputs. Nevertheless, due to significant differences among various\nknowledge editing methods and the variations in task setups, there is no\nstandard implementation framework available for the community, which hinders\npractitioners from applying knowledge editing to applications. To address these\nissues, we propose EasyEdit, an easy-to-use knowledge editing framework for\nLLMs. It supports various cutting-edge knowledge editing approaches and can be\nreadily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc.\nEmpirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,\ndemonstrating that knowledge editing surpasses traditional fine-tuning in terms\nof reliability and generalization. We have released the source code on GitHub,\nalong with Google Colab tutorials and comprehensive documentation for beginners\nto get started. Besides, we present an online system for real-time knowledge\nediting, and a demo video.\n","authors":["Peng Wang","Ningyu Zhang","Bozhong Tian","Zekun Xi","Yunzhi Yao","Ziwen Xu","Mengru Wang","Shengyu Mao","Xiaohan Wang","Siyuan Cheng","Kangwei Liu","Yuansheng Ni","Guozhou Zheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2308.07269v3.pdf","comment":"ACL 2024 System Demonstrations; Code:\n  https://github.com/zjunlp/EasyEdit HF Demo:\n  https://huggingface.co/spaces/zjunlp/EasyEdit Video:\n  https://youtu.be/Gm6T0QaaskU Docs: https://zjunlp.gitbook.io/easyedit"},{"id":"http://arxiv.org/abs/2402.03049v4","updated":"2024-06-24T02:10:23Z","published":"2024-02-05T14:33:56Z","title":"EasyInstruct: An Easy-to-use Instruction Processing Framework for Large\n  Language Models","summary":"  In recent years, instruction tuning has gained increasing attention and\nemerged as a crucial technique to enhance the capabilities of Large Language\nModels (LLMs). To construct high-quality instruction datasets, many instruction\nprocessing approaches have been proposed, aiming to achieve a delicate balance\nbetween data quantity and data quality. Nevertheless, due to inconsistencies\nthat persist among various instruction processing methods, there is no standard\nopen-source instruction processing implementation framework available for the\ncommunity, which hinders practitioners from further developing and advancing.\nTo facilitate instruction processing research and development, we present\nEasyInstruct, an easy-to-use instruction processing framework for LLMs, which\nmodularizes instruction generation, selection, and prompting, while also\nconsidering their combination and interaction. EasyInstruct is publicly\nreleased and actively maintained at https://github.com/zjunlp/EasyInstruct,\nalong with an online demo app and a demo video for quick-start, calling for\nbroader research centered on instruction data and synthetic data.\n","authors":["Yixin Ou","Ningyu Zhang","Honghao Gui","Ziwen Xu","Shuofei Qiao","Yida Xue","Runnan Fang","Kangwei Liu","Lei Li","Zhen Bi","Guozhou Zheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2402.03049v4.pdf","comment":"ACL 2024 System Demonstrations; Project website:\n  https://zjunlp.github.io/project/EasyInstruct Code:\n  https://github.com/zjunlp/EasyInstruct Video: https://youtu.be/rfQOWYfziFo\n  Demo: https://huggingface.co/spaces/zjunlp/EasyInstruct"},{"id":"http://arxiv.org/abs/2406.16264v1","updated":"2024-06-24T02:03:57Z","published":"2024-06-24T02:03:57Z","title":"One Thousand and One Pairs: A \"novel\" challenge for long-context\n  language models","summary":"  Synthetic long-context LLM benchmarks (e.g., \"needle-in-the-haystack\") test\nonly surface-level retrieval capabilities, but how well can long-context LLMs\nretrieve, synthesize, and reason over information across book-length inputs? We\naddress this question by creating NoCha, a dataset of 1,001 minimally different\npairs of true and false claims about 67 recently-published English fictional\nbooks, written by human readers of those books. In contrast to existing\nlong-context benchmarks, our annotators confirm that the largest share of pairs\nin NoCha require global reasoning over the entire book to verify. Our\nexperiments show that while human readers easily perform this task, it is\nenormously challenging for all ten long-context LLMs that we evaluate: no\nopen-weight model performs above random chance (despite their strong\nperformance on synthetic benchmarks), while GPT-4o achieves the highest\naccuracy at 55.8%. Further analysis reveals that (1) on average, models perform\nmuch better on pairs that require only sentence-level retrieval vs. global\nreasoning; (2) model-generated explanations for their decisions are often\ninaccurate even for correctly-labeled claims; and (3) models perform\nsubstantially worse on speculative fiction books that contain extensive\nworld-building. The methodology proposed in NoCha allows for the evolution of\nthe benchmark dataset and the easy analysis of future models.\n","authors":["Marzena Karpinska","Katherine Thai","Kyle Lo","Tanya Goyal","Mohit Iyyer"],"pdf_url":"https://arxiv.org/pdf/2406.16264v1.pdf","comment":"preprint, 29 pages"},{"id":"http://arxiv.org/abs/2406.16260v1","updated":"2024-06-24T01:56:12Z","published":"2024-06-24T01:56:12Z","title":"Video-Infinity: Distributed Long Video Generation","summary":"  Diffusion models have recently achieved remarkable results for video\ngeneration. Despite the encouraging performances, the generated videos are\ntypically constrained to a small number of frames, resulting in clips lasting\nmerely a few seconds. The primary challenges in producing longer videos include\nthe substantial memory requirements and the extended processing time required\non a single GPU. A straightforward solution would be to split the workload\nacross multiple GPUs, which, however, leads to two issues: (1) ensuring all\nGPUs communicate effectively to share timing and context information, and (2)\nmodifying existing video diffusion models, which are usually trained on short\nsequences, to create longer videos without additional training. To tackle\nthese, in this paper we introduce Video-Infinity, a distributed inference\npipeline that enables parallel processing across multiple GPUs for long-form\nvideo generation. Specifically, we propose two coherent mechanisms: Clip\nparallelism and Dual-scope attention. Clip parallelism optimizes the gathering\nand sharing of context information across GPUs which minimizes communication\noverhead, while Dual-scope attention modulates the temporal self-attention to\nbalance local and global contexts efficiently across the devices. Together, the\ntwo mechanisms join forces to distribute the workload and enable the fast\ngeneration of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our\nmethod generates videos up to 2,300 frames in approximately 5 minutes, enabling\nlong video generation at a speed 100 times faster than the prior methods.\n","authors":["Zhenxiong Tan","Xingyi Yang","Songhua Liu","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16259v1","updated":"2024-06-24T01:55:01Z","published":"2024-06-24T01:55:01Z","title":"User Story Tutor (UST) to Support Agile Software Developers","summary":"  User Stories record what must be built in projects that use agile practices.\nUser Stories serve both to estimate effort, generally measured in Story Points,\nand to plan what should be done in a Sprint. Therefore, it is essential to\ntrain software engineers on how to create simple, easily readable, and\ncomprehensive User Stories. For that reason, we designed, implemented, applied,\nand evaluated a web application called User Story Tutor (UST). UST checks the\ndescription of a given User Story for readability, and if needed, recommends\nappropriate practices for improvement. UST also estimates a User Story effort\nin Story Points using Machine Learning techniques. As such UST may support the\ncontinuing education of agile development teams when writing and reviewing User\nStories. UST's ease of use was evaluated by 40 agile practitioners according to\nthe Technology Acceptance Model (TAM) and AttrakDiff. The TAM evaluation\naverages were good in almost all considered variables. Application of the\nAttrakDiff evaluation framework produced similar good results. Apparently, UST\ncan be used with good reliability. Applying UST to assist in the construction\nof User Stories is a viable technique that, at the very least, can be used by\nagile developments to complement and enhance current User Story creation.\n","authors":["Giseldo da Silva Neo","José Antão Beltrão Moura","Hyggo Oliveira de Almeida","Alana Viana Borges da Silva Neo","Olival de Gusmão Freitas Júnior"],"pdf_url":"https://arxiv.org/pdf/2406.16259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16258v1","updated":"2024-06-24T01:51:09Z","published":"2024-06-24T01:51:09Z","title":"MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from\n  Intervention","summary":"  Aligning robot behavior with human preferences is crucial for deploying\nembodied AI agents in human-centered environments. A promising solution is\ninteractive imitation learning from human intervention, where a human expert\nobserves the policy's execution and provides interventions as feedback.\nHowever, existing methods often fail to utilize the prior policy efficiently to\nfacilitate learning, thus hindering sample efficiency. In this work, we\nintroduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning),\ndesigned for sample-efficient alignment from human intervention. Instead of\ninferring the complete human behavior characteristics, MEReQ infers a residual\nreward function that captures the discrepancy between the human expert's and\nthe prior policy's underlying reward functions. It then employs Residual\nQ-Learning (RQL) to align the policy with human preferences using this residual\nreward function. Extensive evaluations on simulated and real-world tasks\ndemonstrate that MEReQ achieves sample-efficient policy alignment from human\nintervention.\n","authors":["Yuxin Chen","Chen Tang","Chenran Li","Ran Tian","Peter Stone","Masayoshi Tomizuka","Wei Zhan"],"pdf_url":"https://arxiv.org/pdf/2406.16258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17137v2","updated":"2024-06-24T01:42:55Z","published":"2023-11-28T18:59:02Z","title":"Intrinsic LoRA: A Generalist Approach for Discovering Knowledge in\n  Generative Models","summary":"  Generative models excel at creating images that closely mimic real scenes,\nsuggesting they inherently encode scene representations. We introduce Intrinsic\nLoRA (I-LoRA), a general approach that uses Low-Rank Adaptation (LoRA) to\ndiscover scene intrinsics such as normals, depth, albedo, and shading from a\nwide array of generative models. I-LoRA is lightweight, adding minimally to the\nmodel's parameters and requiring very small datasets for this knowledge\ndiscovery. Our approach, applicable to Diffusion models, GANs, and\nAutoregressive models alike, generates intrinsics using the same output head as\nthe original images. Through control experiments, we establish a correlation\nbetween the generative model's quality and the extracted intrinsics' accuracy.\nFinally, scene intrinsics obtained by our method with just hundreds to\nthousands of labeled images, perform on par with those from supervised methods\ntrained on millions of labeled examples.\n","authors":["Xiaodan Du","Nicholas Kolkin","Greg Shakhnarovich","Anand Bhattad"],"pdf_url":"https://arxiv.org/pdf/2311.17137v2.pdf","comment":"https://intrinsic-lora.github.io/"},{"id":"http://arxiv.org/abs/2406.16255v1","updated":"2024-06-24T01:37:18Z","published":"2024-06-24T01:37:18Z","title":"Uncertainty-Aware Reward-Free Exploration with General Function\n  Approximation","summary":"  Mastering multiple tasks through exploration and learning in an environment\nposes a significant challenge in reinforcement learning (RL). Unsupervised RL\nhas been introduced to address this challenge by training policies with\nintrinsic rewards rather than extrinsic rewards. However, current intrinsic\nreward designs and unsupervised RL algorithms often overlook the heterogeneous\nnature of collected samples, thereby diminishing their sample efficiency. To\novercome this limitation, in this paper, we propose a reward-free RL algorithm\ncalled \\alg. The key idea behind our algorithm is an uncertainty-aware\nintrinsic reward for exploring the environment and an uncertainty-weighted\nlearning process to handle heterogeneous uncertainty in different samples.\nTheoretically, we show that in order to find an $\\epsilon$-optimal policy,\nGFA-RFE needs to collect $\\tilde{O} (H^2 \\log N_{\\mathcal F} (\\epsilon)\n\\mathrm{dim} (\\mathcal F) / \\epsilon^2 )$ number of episodes, where $\\mathcal\nF$ is the value function class with covering number $N_{\\mathcal F} (\\epsilon)$\nand generalized eluder dimension $\\mathrm{dim} (\\mathcal F)$. Such a result\noutperforms all existing reward-free RL algorithms. We further implement and\nevaluate GFA-RFE across various domains and tasks in the DeepMind Control\nSuite. Experiment results show that GFA-RFE outperforms or is comparable to the\nperformance of state-of-the-art unsupervised RL algorithms.\n","authors":["Junkai Zhang","Weitong Zhang","Dongruo Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2406.16255v1.pdf","comment":"32 pages, 5 figures, 4 tables, accepted by ICML 2024"},{"id":"http://arxiv.org/abs/2406.16254v1","updated":"2024-06-24T01:31:03Z","published":"2024-06-24T01:31:03Z","title":"Confidence Regulation Neurons in Language Models","summary":"  Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.\n","authors":["Alessandro Stolfo","Ben Wu","Wes Gurnee","Yonatan Belinkov","Xingyi Song","Mrinmaya Sachan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.16254v1.pdf","comment":"25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2405.04309v2","updated":"2024-06-24T01:30:48Z","published":"2024-05-07T13:33:50Z","title":"Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment\n  and Spatially-variant Deformation Modeling","summary":"  Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively\nstudied and great progress has been made, there are still key challenges that\nhinder their broad real-world applications: 1) the inherent motion/rotation\nambiguity requires either explicit camera motion recovery with extra constraint\nor complex Procrustean Alignment; 2) existing low-rank modeling of the global\nshape can over-penalize drastic deformations in the 3D shape sequence. This\npaper proposes to resolve the above issues from a spatial-temporal modeling\nperspective. First, we propose a novel Temporally-smooth Procrustean Alignment\nmodule that estimates 3D deforming shapes and adjusts the camera motion by\naligning the 3D shape sequence consecutively. Our new alignment module remedies\nthe requirement of complex reference 3D shape during alignment, which is more\nconductive to non-isotropic deformation modeling. Second, we propose a\nspatial-weighted approach to enforce the low-rank constraint adaptively at\ndifferent locations to accommodate drastic spatially-variant deformation\nreconstruction better. Our modeling outperform existing low-rank based methods,\nand extensive experiments across different datasets validate the effectiveness\nof our method.\n","authors":["Jiawei Shi","Hui Deng","Yuchao Dai"],"pdf_url":"https://arxiv.org/pdf/2405.04309v2.pdf","comment":"Accepted by CVPR 2024; V2 adds new experiments"},{"id":"http://arxiv.org/abs/2406.16252v1","updated":"2024-06-24T01:22:54Z","published":"2024-06-24T01:22:54Z","title":"Graph-Augmented LLMs for Personalized Health Insights: A Case Study in\n  Sleep Analysis","summary":"  Health monitoring systems have revolutionized modern healthcare by enabling\nthe continuous capture of physiological and behavioral data, essential for\npreventive measures and early health intervention. While integrating this data\nwith Large Language Models (LLMs) has shown promise in delivering interactive\nhealth advice, traditional methods like Retrieval-Augmented Generation (RAG)\nand fine-tuning often fail to fully utilize the complex, multi-dimensional, and\ntemporally relevant data from wearable devices. These conventional approaches\ntypically provide limited actionable and personalized health insights due to\ntheir inadequate capacity to dynamically integrate and interpret diverse health\ndata streams. In response, this paper introduces a graph-augmented LLM\nframework designed to significantly enhance the personalization and clarity of\nhealth insights. Utilizing a hierarchical graph structure, the framework\ncaptures inter and intra-patient relationships, enriching LLM prompts with\ndynamic feature importance scores derived from a Random Forest Model. The\neffectiveness of this approach is demonstrated through a sleep analysis case\nstudy involving 20 college students during the COVID-19 lockdown, highlighting\nthe potential of our model to generate actionable and personalized health\ninsights efficiently. We leverage another LLM to evaluate the insights for\nrelevance, comprehensiveness, actionability, and personalization, addressing\nthe critical need for models that process and interpret complex health data\neffectively. Our findings show that augmenting prompts with our framework\nyields significant improvements in all 4 criteria. Through our framework, we\ncan elicit well-crafted, more thoughtful responses tailored to a specific\npatient.\n","authors":["Ajan Subramanian","Zhongqi Yang","Iman Azimi","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2406.16252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04929v2","updated":"2024-06-24T00:37:16Z","published":"2024-02-07T14:56:13Z","title":"Source-Free Domain Adaptation with Diffusion-Guided Source Data\n  Generation","summary":"  This paper introduces a novel approach to leverage the generalizability of\nDiffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed\nDMSFDA method involves fine-tuning a pre-trained text-to-image diffusion model\nto generate source domain images using features from the target images to guide\nthe diffusion process. Specifically, the pre-trained diffusion model is\nfine-tuned to generate source samples that minimize entropy and maximize\nconfidence for the pre-trained source model. We then use a diffusion\nmodel-based image mixup strategy to bridge the domain gap between the source\nand target domains. We validate our approach through comprehensive experiments\nacross a range of datasets, including Office-31 [39], Office-Home [48], and\nVisDA [35]. The results demonstrate significant improvements in SFDA\nperformance, highlighting the potential of diffusion models in generating\ncontextually relevant, domain-specific images.\n","authors":["Shivang Chopra","Suraj Kothawade","Houda Aynaou","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2402.04929v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2310.01701"},{"id":"http://arxiv.org/abs/2406.10289v2","updated":"2024-06-24T23:53:05Z","published":"2024-06-12T21:23:48Z","title":"VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable\n  Reasoning","summary":"  The proliferation of fake news poses a significant threat not only by\ndisseminating misleading information but also by undermining the very\nfoundations of democracy. The recent advance of generative artificial\nintelligence has further exacerbated the challenge of distinguishing genuine\nnews from fabricated stories. In response to this challenge, we introduce\nVeraCT Scan, a novel retrieval-augmented system for fake news detection. This\nsystem operates by extracting the core facts from a given piece of news and\nsubsequently conducting an internet-wide search to identify corroborating or\nconflicting reports. Then sources' credibility is leveraged for information\nverification. Besides determining the veracity of news, we also provide\ntransparent evidence and reasoning to support its conclusions, resulting in the\ninterpretability and trust in the results. In addition to GPT-4 Turbo, Llama-2\n13B is also fine-tuned for news content understanding, information\nverification, and reasoning. Both implementations have demonstrated\nstate-of-the-art accuracy in the realm of fake news detection.\n","authors":["Cheng Niu","Yang Guan","Yuanhao Wu","Juno Zhu","Juntong Song","Randy Zhong","Kaihua Zhu","Siliang Xu","Shizhe Diao","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.10289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13004v4","updated":"2024-06-24T23:43:30Z","published":"2023-06-22T16:04:16Z","title":"Can Differentiable Decision Trees Enable Interpretable Reward Learning\n  from Human Feedback?","summary":"  Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular\nparadigm for capturing human intent to alleviate the challenges of\nhand-crafting the reward values. Despite the increasing interest in RLHF, most\nworks learn black box reward functions that while expressive are difficult to\ninterpret and often require running the whole costly process of RL before we\ncan even decipher if these frameworks are actually aligned with human\npreferences. We propose and evaluate a novel approach for learning expressive\nand interpretable reward functions from preferences using Differentiable\nDecision Trees (DDTs). Our experiments across several domains, including\nCartPole, Visual Gridworld environments and Atari games, provide evidence that\nthe tree structure of our learned reward function is useful in determining the\nextent to which the reward function is aligned with human preferences. We also\nprovide experimental evidence that not only shows that reward DDTs can often\nachieve competitive RL performance when compared with larger capacity deep\nneural network reward functions but also demonstrates the diagnostic utility of\nour framework in checking alignment of learned reward functions. We also\nobserve that the choice between soft and hard (argmax) output of reward DDT\nreveals a tension between wanting highly shaped rewards to ensure good RL\nperformance, while also wanting simpler, more interpretable rewards. Videos and\ncode, are available at: https://sites.google.com/view/ddt-rlhf\n","authors":["Akansha Kalra","Daniel S. Brown"],"pdf_url":"https://arxiv.org/pdf/2306.13004v4.pdf","comment":"Accepted at RLC 2024"},{"id":"http://arxiv.org/abs/2403.19651v2","updated":"2024-06-24T23:41:29Z","published":"2024-03-28T17:59:20Z","title":"MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions","summary":"  Image retrieval, i.e., finding desired images given a reference image,\ninherently encompasses rich, multi-faceted search intents that are difficult to\ncapture solely using image-based measures. Recent works leverage text\ninstructions to allow users to more freely express their search intents.\nHowever, they primarily focus on image pairs that are visually similar and/or\ncan be characterized by a small set of pre-defined relations. The core thesis\nof this paper is that text instructions can enable retrieving images with\nricher relations beyond visual similarity. To show this, we introduce\nMagicLens, a series of self-supervised image retrieval models that support\nopen-ended instructions. MagicLens is built on a key novel insight: image pairs\nthat naturally occur on the same web pages contain a wide range of implicit\nrelations (e.g., inside view of), and we can bring those implicit relations\nexplicit by synthesizing instructions via foundation models. Trained on 36.7M\n(query image, instruction, target image) triplets with rich semantic relations\nmined from the web, MagicLens achieves results comparable with or better than\nprior best on eight benchmarks of various image retrieval tasks, while\nmaintaining high parameter efficiency with a significantly smaller model size.\nAdditional human analyses on a 1.4M-image unseen corpus further demonstrate the\ndiversity of search intents supported by MagicLens. Code and models are\npublicly available at https://open-vision-language.github.io/MagicLens/.\n","authors":["Kai Zhang","Yi Luan","Hexiang Hu","Kenton Lee","Siyuan Qiao","Wenhu Chen","Yu Su","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2403.19651v2.pdf","comment":"ICML 2024 (Oral); Project Website:\n  https://open-vision-language.github.io/MagicLens/"},{"id":"http://arxiv.org/abs/2406.06644v2","updated":"2024-06-24T23:41:23Z","published":"2024-06-09T23:39:31Z","title":"Latent Diffusion Model-Enabled Real-Time Semantic Communication\n  Considering Semantic Ambiguities and Channel Noises","summary":"  Semantic communication (SemCom) has emerged as a new paradigm for 6G\ncommunication, with deep learning (DL) models being one of the key drives to\nshift from the accuracy of bit/symbol to the semantics and pragmatics of data.\nNevertheless, DL-based SemCom systems often face performance bottlenecks due to\noverfitting, poor generalization, and sensitivity to outliers. Furthermore, the\nvarying-fading gains and noises with uncertain signal-to-noise ratios (SNRs)\ncommonly present in wireless channels usually restrict the accuracy of semantic\ninformation transmission. Consequently, this paper constructs a latent\ndiffusion model-enabled SemCom system, and proposes three improvements compared\nto existing works: i) To handle potential outliers in the source data, semantic\nerrors obtained by projected gradient descent based on the vulnerabilities of\nDL models, are utilized to update the parameters and obtain an outlier-robust\nencoder. ii) A lightweight single-layer latent space transformation adapter\ncompletes one-shot learning at the transmitter and is placed before the decoder\nat the receiver, enabling adaptation for out-of-distribution data and enhancing\nhuman-perceptual quality. iii) An end-to-end consistency distillation (EECD)\nstrategy is used to distill the diffusion models trained in latent space,\nenabling deterministic single or few-step real-time denoising in various noisy\nchannels while maintaining high semantic quality. Extensive numerical\nexperiments across different datasets demonstrate the superiority of the\nproposed SemCom system, consistently proving its robustness to outliers, the\ncapability to transmit data with unknown distributions, and the ability to\nperform real-time channel denoising tasks while preserving high human\nperceptual quality, outperforming the existing denoising approaches in semantic\nmetrics.\n","authors":["Jianhua Pei","Cheng Feng","Ping Wang","Hina Tabassum","Dongyuan Shi"],"pdf_url":"https://arxiv.org/pdf/2406.06644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17169v1","updated":"2024-06-24T23:02:56Z","published":"2024-06-24T23:02:56Z","title":"Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability\n  of Large Language Models","summary":"  As Large Language Models (LLMs) continue to exhibit remarkable performance in\nnatural language understanding tasks, there is a crucial need to measure their\nability for human-like multi-step logical reasoning. Existing logical reasoning\nevaluation benchmarks often focus primarily on simplistic single-step or\nmulti-step reasoning with a limited set of inference rules. Furthermore, the\nlack of datasets for evaluating non-monotonic reasoning represents a crucial\ngap since it aligns more closely with human-like reasoning. To address these\nlimitations, we propose Multi-LogiEval, a comprehensive evaluation dataset\nencompassing multi-step logical reasoning with various inference rules and\ndepths. Multi-LogiEval covers three logic types--propositional, first-order,\nand non-monotonic--consisting of more than 30 inference rules and more than 60\nof their combinations with various depths. Leveraging this dataset, we conduct\nevaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,\nand Mistral, employing a zero-shot chain-of-thought. Experimental results show\nthat there is a significant drop in the performance of LLMs as the reasoning\nsteps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).\nWe further conduct a thorough investigation of reasoning chains generated by\nLLMs which reveals several important findings. We believe that Multi-LogiEval\nfacilitates future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data is available at\nhttps://github.com/Mihir3009/Multi-LogiEval.\n","authors":["Nisarg Patel","Mohith Kulkarni","Mihir Parmar","Aashna Budhiraja","Mutsumi Nakamura","Neeraj Varshney","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2406.17169v1.pdf","comment":"23 Pages"},{"id":"http://arxiv.org/abs/2406.17168v1","updated":"2024-06-24T23:02:18Z","published":"2024-06-24T23:02:18Z","title":"Reinforcement Learning via Auxiliary Task Distillation","summary":"  We present Reinforcement Learning via Auxiliary Task Distillation\n(AuxDistill), a new method that enables reinforcement learning (RL) to perform\nlong-horizon robot control problems by distilling behaviors from auxiliary RL\ntasks. AuxDistill achieves this by concurrently carrying out multi-task RL with\nauxiliary tasks, which are easier to learn and relevant to the main task. A\nweighted distillation loss transfers behaviors from these auxiliary tasks to\nsolve the main task. We demonstrate that AuxDistill can learn a\npixels-to-actions policy for a challenging multi-stage embodied object\nrearrangement task from the environment reward without demonstrations, a\nlearning curriculum, or pre-trained skills. AuxDistill achieves $2.3 \\times$\nhigher success than the previous state-of-the-art baseline in the Habitat\nObject Rearrangement benchmark and outperforms methods that use pre-trained\nskills and expert demonstrations.\n","authors":["Abhinav Narayan Harish","Larry Heck","Josiah P. Hanna","Zsolt Kira","Andrew Szot"],"pdf_url":"https://arxiv.org/pdf/2406.17168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01529v3","updated":"2024-06-24T22:52:28Z","published":"2022-12-03T04:08:56Z","title":"Laplacian Convolutional Representation for Traffic Time Series\n  Imputation","summary":"  Spatiotemporal traffic data imputation is of great significance in\nintelligent transportation systems and data-driven decision-making processes.\nTo perform efficient learning and accurate reconstruction from partially\nobserved traffic data, we assert the importance of characterizing both global\nand local trends in time series. In the literature, substantial works have\ndemonstrated the effectiveness of utilizing the low-rank property of traffic\ndata by matrix/tensor completion models. In this study, we first introduce a\nLaplacian kernel to temporal regularization for characterizing local trends in\ntraffic time series, which can be formulated as a circular convolution. Then,\nwe develop a low-rank Laplacian convolutional representation (LCR) model by\nputting the circulant matrix nuclear norm and the Laplacian kernelized temporal\nregularization together, which is proved to meet a unified framework that has a\nfast Fourier transform (FFT) solution in log-linear time complexity. Through\nextensive experiments on several traffic datasets, we demonstrate the\nsuperiority of LCR over several baseline models for imputing traffic time\nseries of various time series behaviors (e.g., data noises and strong/weak\nperiodicity) and reconstructing sparse speed fields of vehicular traffic flow.\nThe proposed LCR model is also an efficient solution to large-scale traffic\ndata imputation over the existing imputation models.\n","authors":["Xinyu Chen","Zhanhong Cheng","HanQin Cai","Nicolas Saunier","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.01529v3.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.17163v1","updated":"2024-06-24T22:30:26Z","published":"2024-06-24T22:30:26Z","title":"Paraphrase and Aggregate with Large Language Models for Minimizing\n  Intent Classification Errors","summary":"  Large language models (LLM) have achieved remarkable success in natural\nlanguage generation but lesser focus has been given to their applicability in\ndecision making tasks such as classification. We show that LLMs like LLaMa can\nachieve high performance on large multi-class classification tasks but still\nmake classification errors and worse, generate out-of-vocabulary class labels.\nTo address these critical issues, we introduce Paraphrase and AGgregate\n(PAG)-LLM approach wherein an LLM generates multiple paraphrases of the input\nquery (parallel queries), performs multi-class classification for the original\nquery and each paraphrase, and at the end aggregate all the classification\nlabels based on their confidence scores. We evaluate PAG-LLM on two large\nmulti-class classication datasets: CLINC, and Banking and show 22.7% and 15.1%\nerror reduction. We show that PAG-LLM is especially effective for hard examples\nwhere LLM is uncertain, and reduces the critical misclassification and\nhallucinated label generation errors\n","authors":["Vikas Yadav","Zheng Tang","Vijay Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.17163v1.pdf","comment":"Accepted at SIGIR 2024"},{"id":"http://arxiv.org/abs/2406.17162v1","updated":"2024-06-24T22:29:30Z","published":"2024-06-24T22:29:30Z","title":"Virtual Mines -- Component-level recycling of printed circuit boards\n  using deep learning","summary":"  This contribution gives an overview of an ongoing project using machine\nlearning and computer vision components for improving the electronic waste\nrecycling process. In circular economy, the \"virtual mines\" concept refers to\nproduction cycles where interesting raw materials are reclaimed in an efficient\nand cost-effective manner from end-of-life items. In particular, the growth of\ne-waste, due to the increasingly shorter life cycle of hi-tech goods, is a\nglobal problem. In this paper, we describe a pipeline based on deep learning\nmodel to recycle printed circuit boards at the component level. A pre-trained\nYOLOv5 model is used to analyze the results of the locally developed dataset.\nWith a different distribution of class instances, YOLOv5 managed to achieve\nsatisfactory precision and recall, with the ability to optimize with large\ncomponent instances.\n","authors":["Muhammad Mohsin","Stefano Rovetta","Francesco Masulli","Alberto Cabri"],"pdf_url":"https://arxiv.org/pdf/2406.17162v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2312.02659v2","updated":"2024-06-24T22:15:57Z","published":"2023-12-05T10:53:31Z","title":"Supervised learning of spatial features with STDP and homeostasis using\n  Spiking Neural Networks on SpiNNaker","summary":"  Artificial Neural Networks (ANN) have gained significant popularity thanks to\ntheir ability to learn using the well-known backpropagation algorithm.\nConversely, Spiking Neural Networks (SNNs), despite having broader capabilities\nthan ANNs, have always posed challenges in the training phase. This paper shows\na new method to perform supervised learning on SNNs, using Spike Timing\nDependent Plasticity (STDP) and homeostasis, aiming at training the network to\nidentify spatial patterns. Spatial patterns refer to spike patterns without a\ntime component, where all spike events occur simultaneously. The method is\ntested using the SpiNNaker digital architecture. A SNN is trained to recognise\none or multiple patterns and performance metrics are extracted to measure the\nperformance of the network. Some considerations are drawn from the results\nshowing that, in the case of a single trained pattern, the network behaves as\nthe ideal detector, with 100% accuracy in detecting the trained pattern.\nHowever, as the number of trained patterns on a single network increases, the\naccuracy of identification is linked to the similarities between these\npatterns. This method of training an SNN to detect spatial patterns may be\napplied to pattern recognition in static images or traffic analysis in computer\nnetworks, where each network packet represents a spatial pattern. It will be\nstipulated that the homeostatic factor may enable the network to detect\npatterns with some degree of similarity, rather than only perfectly matching\npatterns.The principles outlined in this article serve as the fundamental\nbuilding blocks for more complex systems that utilise both spatial and temporal\npatterns by converting specific features of input signals into spikes.One\nexample of such a system is a computer network packet classifier, tasked with\nreal-time identification of packet streams based on features within the packet\ncontent\n","authors":["Sergio Davies","Andrew Gait","Andrew Rowley","Alessandro Di Nuovo"],"pdf_url":"https://arxiv.org/pdf/2312.02659v2.pdf","comment":"14 pages, 6 figures (figure 6 has 9 sub-figures) for a total of 14\n  images, 10 tables, submitted to the Journal of Neural Networks"},{"id":"http://arxiv.org/abs/2405.15756v2","updated":"2024-06-24T22:14:42Z","published":"2024-05-24T17:51:39Z","title":"Sparse Expansion and Neuronal Disentanglement","summary":"  We show how to improve the inference efficiency of an LLM by expanding it\ninto a mixture of sparse experts, where each expert is a copy of the original\nweights, one-shot pruned for a specific cluster of input values. We call this\napproach $\\textit{Sparse Expansion}$. We show that, for models such as Llama 2\n70B, as we increase the number of sparse experts, Sparse Expansion outperforms\nall other one-shot sparsification approaches for the same inference FLOP budget\nper token, and that this gap grows as sparsity increases, leading to inference\nspeedups.\n  But why? To answer this, we provide strong evidence that the mixture of\nsparse experts is effectively $\\textit{disentangling}$ the input-output\nrelationship of every individual neuron across clusters of inputs.\nSpecifically, sparse experts approximate the dense neuron output distribution\nwith fewer weights by decomposing the distribution into a collection of simpler\nones, each with a separate sparse dot product covering it. Interestingly, we\nshow that the Wasserstein distance between a neuron's output distribution and a\nGaussian distribution is an indicator of its entanglement level and\ncontribution to the accuracy of the model. Every layer of an LLM has a fraction\nof highly entangled Wasserstein neurons, and model performance suffers more\nwhen these are sparsified as opposed to others. The code for Sparse Expansion\nis available at: https://github.com/Shavit-Lab/Sparse-Expansion .\n","authors":["Shashata Sawmya","Linghao Kong","Ilia Markov","Dan Alistarh","Nir Shavit"],"pdf_url":"https://arxiv.org/pdf/2405.15756v2.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.15161v3","updated":"2024-06-24T22:07:55Z","published":"2023-11-26T01:44:01Z","title":"Hessian Aware Low-Rank Perturbation for Order-Robust Continual Learning","summary":"  Continual learning aims to learn a series of tasks sequentially without\nforgetting the knowledge acquired from the previous ones. In this work, we\npropose the Hessian Aware Low-Rank Perturbation algorithm for continual\nlearning. By modeling the parameter transitions along the sequential tasks with\nthe weight matrix transformation, we propose to apply the low-rank\napproximation on the task-adaptive parameters in each layer of the neural\nnetworks. Specifically, we theoretically demonstrate the quantitative\nrelationship between the Hessian and the proposed low-rank approximation. The\napproximation ranks are then globally determined according to the marginal\nincrement of the empirical loss estimated by the layer-specific gradient and\nlow-rank approximation error. Furthermore, we control the model capacity by\npruning less important parameters to diminish the parameter growth. We conduct\nextensive experiments on various benchmarks, including a dataset with\nlarge-scale tasks, and compare our method against some recent state-of-the-art\nmethods to demonstrate the effectiveness and scalability of our proposed\nmethod. Empirical results show that our method performs better on different\nbenchmarks, especially in achieving task order robustness and handling the\nforgetting issue. The source code is at https://github.com/lijiaqi/HALRP.\n","authors":["Jiaqi Li","Yuanhao Lai","Rui Wang","Changjian Shui","Sabyasachi Sahoo","Charles X. Ling","Shichun Yang","Boyu Wang","Christian Gagné","Fan Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.15161v3.pdf","comment":"Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)"},{"id":"http://arxiv.org/abs/2406.02500v2","updated":"2024-06-24T21:51:23Z","published":"2024-06-04T17:18:40Z","title":"Demystifying the Compression of Mixture-of-Experts Through a Unified\n  Framework","summary":"  Scaling large language models has revolutionized the performance across\ndiverse domains, yet the continual growth in model size poses significant\nchallenges for real-world deployment. The Mixture of Experts (MoE) approach\naddresses this by dynamically selecting and activating only a subset of\nexperts, significantly reducing computational costs while maintaining high\nperformance. However, MoE introduces potential redundancy (e.g., parameters)\nand extra costs (e.g., communication overhead). Despite numerous compression\ntechniques developed for mitigating the redundancy in dense models, the\ncompression of MoE remains under-explored. We first bridge this gap with a\ncutting-edge unified framework that not only seamlessly integrates mainstream\ncompression methods but also helps systematically understand MoE compression.\nThis framework approaches compression from two perspectives: Expert Slimming\nwhich compresses individual experts and Expert Trimming which removes\nstructured modules. Within this framework, we explore the optimization space\nunexplored by existing methods,and further introduce aggressive Expert Trimming\ntechniques, i.e., Layer Drop and Block Drop, to eliminate redundancy at larger\nscales. Based on these insights,we present a comprehensive recipe to guide\npractitioners in compressing MoE effectively. Extensive experimental results\ndemonstrate the effectiveness of the compression methods under our framework\nand the proposed recipe, achieving a 6.05x speedup and only 20.0GB memory usage\nwhile maintaining over 92% of performance on Mixtral-8x7B. Code is released at\n\\url{https://github.com/DaizeDong/Unified-MoE-Compression}.\n","authors":["Shwai He","Daize Dong","Liang Ding","Ang Li"],"pdf_url":"https://arxiv.org/pdf/2406.02500v2.pdf","comment":"20 pages, 15 figures, 5 tables"},{"id":"http://arxiv.org/abs/2406.17150v1","updated":"2024-06-24T21:44:37Z","published":"2024-06-24T21:44:37Z","title":"Peirce in the Machine: How Mixture of Experts Models Perform Hypothesis\n  Construction","summary":"  Mixture of experts is a prediction aggregation method in machine learning\nthat aggregates the predictions of specialized experts. This method often\noutperforms Bayesian methods despite the Bayesian having stronger inductive\nguarantees. We argue that this is due to the greater functional capacity of\nmixture of experts. We prove that in a limiting case of mixture of experts will\nhave greater capacity than equivalent Bayesian methods, which we vouchsafe\nthrough experiments on non-limiting cases. Finally, we conclude that mixture of\nexperts is a type of abductive reasoning in the Peircian sense of hypothesis\nconstruction.\n","authors":["Bruce Rushing"],"pdf_url":"https://arxiv.org/pdf/2406.17150v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2406.17147v1","updated":"2024-06-24T21:38:13Z","published":"2024-06-24T21:38:13Z","title":"Quantifying Heterogeneous Ecosystem Services With Multi-Label Soft\n  Classification","summary":"  Understanding and quantifying ecosystem services are crucial for sustainable\nenvironmental management, conservation efforts, and policy-making. The\nadvancement of remote sensing technology and machine learning techniques has\ngreatly facilitated this process. Yet, ground truth labels, such as\nbiodiversity, are very difficult and expensive to measure. In addition, more\neasily obtainable proxy labels, such as land use, often fail to capture the\ncomplex heterogeneity of the ecosystem. In this paper, we demonstrate how land\nuse proxy labels can be implemented with a soft, multi-label classifier to\npredict ecosystem services with complex heterogeneity.\n","authors":["Zhihui Tian","John Upchurch","G. Austin Simon","José Dubeux","Alina Zare","Chang Zhao","Joel B. Harley"],"pdf_url":"https://arxiv.org/pdf/2406.17147v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2406.17145v1","updated":"2024-06-24T21:32:51Z","published":"2024-06-24T21:32:51Z","title":"GraphPipe: Improving Performance and Scalability of DNN Training with\n  Graph Pipeline Parallelism","summary":"  Deep neural networks (DNNs) continue to grow rapidly in size, making them\ninfeasible to train on a single device. Pipeline parallelism is commonly used\nin existing DNN systems to support large-scale DNN training by partitioning a\nDNN into multiple stages, which concurrently perform DNN training for different\nmicro-batches in a pipeline fashion. However, existing pipeline-parallel\napproaches only consider sequential pipeline stages and thus ignore the\ntopology of a DNN, resulting in missed model-parallel opportunities. This paper\npresents graph pipeline parallelism (GPP), a new pipeline-parallel scheme that\npartitions a DNN into pipeline stages whose dependencies are identified by a\ndirected acyclic graph. GPP generalizes existing sequential pipeline\nparallelism and preserves the inherent topology of a DNN to enable concurrent\nexecution of computationally-independent operators, resulting in reduced memory\nrequirement and improved GPU performance. In addition, we develop GraphPipe, a\ndistributed system that exploits GPP strategies to enable performant and\nscalable DNN training. GraphPipe partitions a DNN into a graph of stages,\noptimizes micro-batch schedules for these stages, and parallelizes DNN training\nusing the discovered GPP strategies. Evaluation on a variety of DNNs shows that\nGraphPipe outperforms existing pipeline-parallel systems such as PipeDream and\nPiper by up to 1.6X. GraphPipe also reduces the search time by 9-21X compared\nto PipeDream and Piper.\n","authors":["Byungsoo Jeon","Mengdi Wu","Shiyi Cao","Sunghyun Kim","Sunghyun Park","Neeraj Aggarwal","Colin Unger","Daiyaan Arfeen","Peiyuan Liao","Xupeng Miao","Mohammad Alizadeh","Gregory R. Ganger","Tianqi Chen","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2406.17145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16137v7","updated":"2024-06-24T21:22:00Z","published":"2023-08-30T16:47:51Z","title":"LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language\n  Models","summary":"  Today's large language models (LLMs) typically train on short text segments\n(e.g., <4K tokens) due to the quadratic complexity of their Transformer\narchitectures. As a result, their performance suffers drastically on inputs\nlonger than those encountered during training, substantially limiting their\napplications in real-world tasks involving long contexts such as encoding\nscientific articles, code repositories, or long dialogues. Through theoretical\nanalysis and empirical investigation, this work identifies three major factors\ncontributing to this length generalization failure. Our theoretical analysis\nfurther reveals that commonly used techniques like truncating the attention\nwindow or relative positional encodings are inadequate to address them.\nAnswering these challenges, we propose LM-Infinite, a simple and effective\nmethod for enhancing LLMs' capabilities of handling long contexts. LM-Infinite\nis highly flexible and can be used with most modern LLMs off-the-shelf. Without\nany parameter updates, it allows LLMs pre-trained with 2K or 4K-long segments\nto generalize to up to 200M length inputs while retaining perplexity. It also\nimproves performance on downstream tasks such as Passkey Retrieval and Qasper\nin the zero-shot setting. LM-Infinite brings substantial efficiency\nimprovements: it achieves 2.7x decoding speed up and 7.5x memory saving over\nthe original model. Our codes are released at\n\\url{https://github.com/Glaciohound/LM-Infinite}.\n","authors":["Chi Han","Qifan Wang","Hao Peng","Wenhan Xiong","Yu Chen","Heng Ji","Sinong Wang"],"pdf_url":"https://arxiv.org/pdf/2308.16137v7.pdf","comment":"NAACL 2024 Outstanding paper, 9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.12229v2","updated":"2024-06-24T21:16:36Z","published":"2024-05-09T19:51:27Z","title":"Multi-task learning for molecular electronic structure approaching\n  coupled-cluster accuracy","summary":"  Machine learning (ML) plays an important role in quantum chemistry, providing\nfast-to-evaluate predictive models for various properties of molecules.\nHowever, most existing ML models for molecular electronic properties use\ndensity functional theory (DFT) databases as ground truth in training, and\ntheir prediction accuracy cannot surpass that of DFT. In this work, we\ndeveloped a unified ML method for electronic structures of organic molecules\nusing the gold-standard CCSD(T) calculations as training data. Tested on\nhydrocarbon molecules, our model outperforms DFT with the widely-used hybrid\nand double hybrid functionals in computational costs and prediction accuracy of\nvarious quantum chemical properties. As case studies, we apply the model to\naromatic compounds and semiconducting polymers on both ground state and excited\nstate properties, demonstrating its accuracy and generalization capability to\ncomplex systems that are hard to calculate using CCSD(T)-level methods.\n","authors":["Hao Tang","Brian Xiao","Wenhao He","Pero Subasic","Avetik R. Harutyunyan","Yao Wang","Fang Liu","Haowei Xu","Ju Li"],"pdf_url":"https://arxiv.org/pdf/2405.12229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17115v1","updated":"2024-06-24T20:08:07Z","published":"2024-06-24T20:08:07Z","title":"Evaluating the Quality of Hallucination Benchmarks for Large\n  Vision-Language Models","summary":"  Despite the rapid progress and outstanding performance of Large\nVision-Language Models (LVLMs) in recent years, LVLMs have been plagued by the\nissue of hallucination, i.e., LVLMs tend to generate responses that are\ninconsistent with the corresponding visual inputs. To evaluate the degree of\nhallucination in LVLMs, previous works have proposed a series of benchmarks\nfeaturing different types of tasks and evaluation metrics. However, we find\nthat the quality of the existing hallucination benchmarks varies, with some\nsuffering from problems, e.g., inconsistent evaluation results under repeated\ntests, and misalignment with human evaluation. To this end, we propose a\nHallucination benchmark Quality Measurement framework (HQM), which leverages\nvarious indicators to assess the reliability and validity of existing\nhallucination benchmarks separately. Specifically, for reliability we explore\ntest-retest reliability and parallel-forms reliability, while for validity we\nexamine criterion validity and coverage of hallucination types. Furthermore,\nbased on the results of our quality measurement, we construct a High-Quality\nHallucination Benchmark (HQH) for LVLMs. We conduct an extensive evaluation of\nover 10 representative LVLMs, including GPT-4o and Gemini-Vision-Pro, to\nprovide an in-depth analysis of the hallucination issues in existing models.\nOur benchmark is publicly available at https://github.com/HQHBench/HQHBench.\n","authors":["Bei Yan","Jie Zhang","Zheng Yuan","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15297v3","updated":"2024-06-24T19:45:42Z","published":"2024-03-22T15:44:59Z","title":"Sphere Neural-Networks for Rational Reasoning","summary":"  The success of Large Language Models (LLMs), e.g., ChatGPT, is witnessed by\ntheir planetary popularity, their capability of human-like communication, and\nalso by their steadily improved reasoning performance. However, it remains\nunclear whether LLMs reason. It is an open problem how traditional neural\nnetworks can be qualitatively extended to go beyond the statistic paradigm and\nachieve high-level cognition. Here, we present a novel qualitative extension by\ngeneralising computational building blocks from vectors to spheres. We propose\nSphere Neural Networks (SphNNs) for human-like reasoning through model\nconstruction and inspection, and develop SphNN for syllogistic reasoning, a\nmicrocosm of human rationality. SphNN is a hierarchical neuro-symbolic\nKolmogorov-Arnold geometric GNN, and uses a neuro-symbolic transition map of\nneighbourhood spatial relations to transform the current sphere configuration\ntowards the target. SphNN is the first neural model that can determine the\nvalidity of long-chained syllogistic reasoning in one epoch without training\ndata, with the worst computational complexity of O(N). SphNN can evolve into\nvarious types of reasoning, such as spatio-temporal reasoning, logical\nreasoning with negation and disjunction, event reasoning, neuro-symbolic\nunification, and humour understanding (the highest level of cognition). All\nthese suggest a new kind of Herbert A. Simon's scissors with two neural blades.\nSphNNs will tremendously enhance interdisciplinary collaborations to develop\nthe two neural blades and realise deterministic neural reasoning and\nhuman-bounded rationality and elevate LLMs to reliable psychological AI. This\nwork suggests that the non-zero radii of spheres are the missing components\nthat prevent traditional deep-learning systems from reaching the realm of\nrational reasoning and cause LLMs to be trapped in the swamp of hallucination.\n","authors":["Tiansi Dong","Mateja Jamnik","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2403.15297v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10561v3","updated":"2024-06-24T19:43:21Z","published":"2023-12-16T23:31:20Z","title":"Enabling Accelerators for Graph Computing","summary":"  The advent of Graph Neural Networks (GNNs) has revolutionized the field of\nmachine learning, offering a novel paradigm for learning on graph-structured\ndata. Unlike traditional neural networks, GNNs are capable of capturing complex\nrelationships and dependencies inherent in graph data, making them particularly\nsuited for a wide range of applications including social network analysis,\nmolecular chemistry, and network security. GNNs, with their unique structure\nand operation, present new computational challenges compared to conventional\nneural networks. This requires comprehensive benchmarking and a thorough\ncharacterization of GNNs to obtain insight into their computational\nrequirements and to identify potential performance bottlenecks. In this thesis,\nwe aim to develop a better understanding of how GNNs interact with the\nunderlying hardware and will leverage this knowledge as we design specialized\naccelerators and develop new optimizations, leading to more efficient and\nfaster GNN computations. A pivotal component within GNNs is the Sparse General\nMatrix-Matrix Multiplication (SpGEMM) kernel, known for its computational\nintensity and irregular memory access patterns. In this thesis, we address the\nchallenges posed by SpGEMM by implementing a highly optimized hashing-based\nSpGEMM kernel tailored for a custom accelerator. Synthesizing these insights\nand optimizations, we design state-of-the-art hardware accelerators capable of\nefficiently handling various GNN workloads. Our accelerator architectures are\nbuilt on our characterization of GNN computational demands, providing clear\nmotivation for our approaches. This exploration into novel models underlines\nour comprehensive approach, as we strive to enable accelerators that are not\njust performant, but also versatile, able to adapt to the evolving landscape of\ngraph computing.\n","authors":["Kaustubh Shivdikar"],"pdf_url":"https://arxiv.org/pdf/2312.10561v3.pdf","comment":"Northeastern University Doctoral Dissertation"},{"id":"http://arxiv.org/abs/2406.17098v1","updated":"2024-06-24T19:36:45Z","published":"2024-06-24T19:36:45Z","title":"Learning Temporal Distances: Contrastive Successor Features Can Provide\n  a Metric Structure for Decision-Making","summary":"  Temporal distances lie at the heart of many algorithms for planning, control,\nand reinforcement learning that involve reaching goals, allowing one to\nestimate the transit time between two states. However, prior attempts to define\nsuch temporal distances in stochastic settings have been stymied by an\nimportant limitation: these prior approaches do not satisfy the triangle\ninequality. This is not merely a definitional concern, but translates to an\ninability to generalize and find shortest paths. In this paper, we build on\nprior work in contrastive learning and quasimetrics to show how successor\nfeatures learned by contrastive learning (after a change of variables) form a\ntemporal distance that does satisfy the triangle inequality, even in stochastic\nsettings. Importantly, this temporal distance is computationally efficient to\nestimate, even in high-dimensional and stochastic settings. Experiments in\ncontrolled settings and benchmark suites demonstrate that an RL algorithm based\non these new temporal distances exhibits combinatorial generalization (i.e.,\n\"stitching\") and can sometimes learn more quickly than prior methods, including\nthose based on quasimetrics.\n","authors":["Vivek Myers","Chongyi Zheng","Anca Dragan","Sergey Levine","Benjamin Eysenbach"],"pdf_url":"https://arxiv.org/pdf/2406.17098v1.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)"},{"id":"http://arxiv.org/abs/2406.17096v1","updated":"2024-06-24T19:35:26Z","published":"2024-06-24T19:35:26Z","title":"Model-Free Robust Reinforcement Learning with Sample Complexity Analysis","summary":"  Distributionally Robust Reinforcement Learning (DR-RL) aims to derive a\npolicy optimizing the worst-case performance within a predefined uncertainty\nset. Despite extensive research, previous DR-RL algorithms have predominantly\nfavored model-based approaches, with limited availability of model-free methods\noffering convergence guarantees or sample complexities. This paper proposes a\nmodel-free DR-RL algorithm leveraging the Multi-level Monte Carlo (MLMC)\ntechnique to close such a gap. Our innovative approach integrates a threshold\nmechanism that ensures finite sample requirements for algorithmic\nimplementation, a significant improvement than previous model-free algorithms.\nWe develop algorithms for uncertainty sets defined by total variation,\nChi-square divergence, and KL divergence, and provide finite sample analyses\nunder all three cases. Remarkably, our algorithms represent the first\nmodel-free DR-RL approach featuring finite sample complexity for total\nvariation and Chi-square divergence uncertainty sets, while also offering an\nimproved sample complexity and broader applicability compared to existing\nmodel-free DR-RL algorithms for the KL divergence model. The complexities of\nour method establish the tightest results for all three uncertainty models in\nmodel-free DR-RL, underscoring the effectiveness and efficiency of our\nalgorithm, and highlighting its potential for practical applications.\n","authors":["Yudan Wang","Shaofeng Zou","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17096v1.pdf","comment":"UAI 2024"},{"id":"http://arxiv.org/abs/2406.17092v1","updated":"2024-06-24T19:29:47Z","published":"2024-06-24T19:29:47Z","title":"BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in\n  Instruction-tuned Language Models","summary":"  Safety backdoor attacks in large language models (LLMs) enable the stealthy\ntriggering of unsafe behaviors while evading detection during normal\ninteractions. The high dimensionality of potential triggers in the token space\nand the diverse range of malicious behaviors make this a critical challenge. We\npresent BEEAR, a mitigation approach leveraging the insight that backdoor\ntriggers induce relatively uniform drifts in the model's embedding space. Our\nbi-level optimization method identifies universal embedding perturbations that\nelicit unwanted behaviors and adjusts the model parameters to reinforce safe\nbehaviors against these perturbations. Experiments show BEEAR reduces the\nsuccess rate of RLHF time backdoor attacks from >95% to <1% and from 47% to 0%\nfor instruction-tuning time backdoors targeting malicious code generation,\nwithout compromising model utility. Requiring only defender-defined safe and\nunwanted behaviors, BEEAR represents a step towards practical defenses against\nsafety backdoors in LLMs, providing a foundation for further advancements in AI\nsafety and security.\n","authors":["Yi Zeng","Weiyu Sun","Tran Ngoc Huynh","Dawn Song","Bo Li","Ruoxi Jia"],"pdf_url":"https://arxiv.org/pdf/2406.17092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11837v2","updated":"2024-06-24T19:28:08Z","published":"2024-05-20T07:25:09Z","title":"Improving the Explain-Any-Concept by Introducing Nonlinearity to the\n  Trainable Surrogate Model","summary":"  In the evolving field of Explainable AI (XAI), interpreting the decisions of\ndeep neural networks (DNNs) in computer vision tasks is an important process.\nWhile pixel-based XAI methods focus on identifying significant pixels, existing\nconcept-based XAI methods use pre-defined or human-annotated concepts. The\nrecently proposed Segment Anything Model (SAM) achieved a significant step\nforward to prepare automatic concept sets via comprehensive instance\nsegmentation. Building upon this, the Explain Any Concept (EAC) model emerged\nas a flexible method for explaining DNN decisions. EAC model is based on using\na surrogate model which has one trainable linear layer to simulate the target\nmodel. In this paper, by introducing an additional nonlinear layer to the\noriginal surrogate model, we show that we can improve the performance of the\nEAC model. We compare our proposed approach to the original EAC model and\nreport improvements obtained on both ImageNet and MS COCO datasets.\n","authors":["Mounes Zaval","Sedat Ozer"],"pdf_url":"https://arxiv.org/pdf/2405.11837v2.pdf","comment":"This paper is accepted for publication at IEEE SIU conference, 2024"},{"id":"http://arxiv.org/abs/2406.17090v1","updated":"2024-06-24T19:27:34Z","published":"2024-06-24T19:27:34Z","title":"Exploring Biomarker Relationships in Both Type 1 and Type 2 Diabetes\n  Mellitus Through a Bayesian Network Analysis Approach","summary":"  Understanding the complex relationships of biomarkers in diabetes is pivotal\nfor advancing treatment strategies, a pressing need in diabetes research. This\nstudy applies Bayesian network structure learning to analyze the Shanghai Type\n1 and Type 2 diabetes mellitus datasets, revealing complex relationships among\nkey diabetes-related biomarkers. The constructed Bayesian network presented\nnotable predictive accuracy, particularly for Type 2 diabetes mellitus, with\nroot mean squared error (RMSE) of 18.23 mg/dL, as validated through\nleave-one-domain experiments and Clarke error grid analysis. This study not\nonly elucidates the intricate dynamics of diabetes through a deeper\nunderstanding of biomarker interplay but also underscores the significant\npotential of integrating data-driven and knowledge-driven methodologies in the\nrealm of personalized diabetes management. Such an approach paves the way for\nmore custom and effective treatment strategies, marking a notable advancement\nin the field.\n","authors":["Yuyang Sun","Jingyu Lei","Panagiotis Kosmas"],"pdf_url":"https://arxiv.org/pdf/2406.17090v1.pdf","comment":"Paper is accepted by EMBC 2024"},{"id":"http://arxiv.org/abs/2406.17073v1","updated":"2024-06-24T18:59:24Z","published":"2024-06-24T18:59:24Z","title":"Meta-GCN: A Dynamically Weighted Loss Minimization Method for Dealing\n  with the Data Imbalance in Graph Neural Networks","summary":"  Although many real-world applications, such as disease prediction, and fault\ndetection suffer from class imbalance, most existing graph-based classification\nmethods ignore the skewness of the distribution of classes; therefore, tend to\nbe biased towards the majority class(es). Conventional methods typically tackle\nthis problem through the assignment of weights to each one of the class samples\nbased on a function of their loss, which can lead to over-fitting on outliers.\nIn this paper, we propose a meta-learning algorithm, named Meta-GCN, for\nadaptively learning the example weights by simultaneously minimizing the\nunbiased meta-data set loss and optimizing the model weights through the use of\na small unbiased meta-data set. Through experiments, we have shown that\nMeta-GCN outperforms state-of-the-art frameworks and other baselines in terms\nof accuracy, the area under the receiver operating characteristic (AUC-ROC)\ncurve, and macro F1-Score for classification tasks on two different datasets.\n","authors":["Mahdi Mohammadizadeh","Arash Mozhdehi","Yani Ioannou","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02416v4","updated":"2024-06-24T18:55:16Z","published":"2024-02-04T09:24:51Z","title":"Aligner: Efficient Alignment by Learning to Correct","summary":"  With the rapid development of large language models (LLMs) and ever-evolving\npractical requirements, finding an efficient and effective alignment method has\nnever been more critical. However, the tension between the complexity of\ncurrent alignment methods and the need for rapid iteration in deployment\nscenarios necessitates the development of a model-agnostic alignment approach\nthat can operate under these constraints. In this paper, we introduce Aligner,\na novel and simple alignment paradigm that learns the correctional residuals\nbetween preferred and dispreferred answers using a small model. Designed as a\nmodel-agnostic, plug-and-play module, Aligner can be directly applied to\nvarious open-source and API-based models with only one-off training, making it\nsuitable for rapid iteration. Notably, Aligner can be applied to any powerful,\nlarge-scale upstream models. Moreover, it can even iteratively bootstrap the\nupstream models using corrected responses as synthetic human preference data,\nbreaking through the model's performance ceiling. Our experiments demonstrate\nperformance improvements by deploying the same Aligner model across 11\ndifferent LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and\nhonesty). Specifically, Aligner-7B has achieved an average improvement of 68.9%\nin helpfulness and 23.8% in harmlessness across the tested LLMs while also\neffectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking\nAligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%,\nsurpassing GPT-4 Omni's 57.5% Win Rate (community report).\n","authors":["Jiaming Ji","Boyuan Chen","Hantao Lou","Donghai Hong","Borong Zhang","Xuehai Pan","Juntao Dai","Tianyi Qiu","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2402.02416v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17066v1","updated":"2024-06-24T18:33:45Z","published":"2024-06-24T18:33:45Z","title":"Tolerance of Reinforcement Learning Controllers against Deviations in\n  Cyber Physical Systems","summary":"  Cyber-physical systems (CPS) with reinforcement learning (RL)-based\ncontrollers are increasingly being deployed in complex physical environments\nsuch as autonomous vehicles, the Internet-of-Things(IoT), and smart cities. An\nimportant property of a CPS is tolerance; i.e., its ability to function safely\nunder possible disturbances and uncertainties in the actual operation. In this\npaper, we introduce a new, expressive notion of tolerance that describes how\nwell a controller is capable of satisfying a desired system requirement,\nspecified using Signal Temporal Logic (STL), under possible deviations in the\nsystem. Based on this definition, we propose a novel analysis problem, called\nthe tolerance falsification problem, which involves finding small deviations\nthat result in a violation of the given requirement. We present a novel,\ntwo-layer simulation-based analysis framework and a novel search heuristic for\nfinding small tolerance violations. To evaluate our approach, we construct a\nset of benchmark problems where system parameters can be configured to\nrepresent different types of uncertainties and disturbancesin the system. Our\nevaluation shows that our falsification approach and heuristic can effectively\nfind small tolerance violations.\n","authors":["Changjian Zhang","Parv Kapoor","Eunsuk Kang","Romulo Meira-Goes","David Garlan","Akila Ganlath","Shatadal Mishra","Nejib Ammar"],"pdf_url":"https://arxiv.org/pdf/2406.17066v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.07462"},{"id":"http://arxiv.org/abs/2310.01720v2","updated":"2024-06-24T18:31:38Z","published":"2023-10-03T01:13:17Z","title":"Perceiver-based CDF Modeling for Time Series Forecasting","summary":"  Transformers have demonstrated remarkable efficacy in forecasting time series\ndata. However, their extensive dependence on self-attention mechanisms demands\nsignificant computational resources, thereby limiting their practical\napplicability across diverse tasks, especially in multimodal problems. In this\nwork, we propose a new architecture, called perceiver-CDF, for modeling\ncumulative distribution functions (CDF) of time series data. Our approach\ncombines the perceiver architecture with a copula-based attention mechanism\ntailored for multimodal time series prediction. By leveraging the perceiver,\nour model efficiently transforms high-dimensional and multimodal data into a\ncompact latent space, thereby significantly reducing computational demands.\nSubsequently, we implement a copula-based attention mechanism to construct the\njoint distribution of missing data for prediction. Further, we propose an\noutput variance testing mechanism to effectively mitigate error propagation\nduring prediction. To enhance efficiency and reduce complexity, we introduce\nmidpoint inference for the local attention mechanism. This enables the model to\nefficiently capture dependencies within nearby imputed samples without\nconsidering all previous samples. The experiments on the unimodal and\nmultimodal benchmarks consistently demonstrate a 20% improvement over\nstate-of-the-art methods while utilizing less than half of the computational\nresources.\n","authors":["Cat P. Le","Chris Cannella","Ali Hasan","Yuting Ng","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2310.01720v2.pdf","comment":"Accepted in Winter Simulation Conference 2024"},{"id":"http://arxiv.org/abs/2402.15368v2","updated":"2024-06-24T18:27:35Z","published":"2024-02-23T15:02:44Z","title":"Safe Task Planning for Language-Instructed Multi-Robot Systems using\n  Conformal Prediction","summary":"  This paper addresses task planning problems for language-instructed robot\nteams. Tasks are expressed in natural language (NL), requiring the robots to\napply their capabilities at various locations and semantic objects. Several\nrecent works have addressed similar planning problems by leveraging pre-trained\nLarge Language Models (LLMs) to design effective multi-robot plans. However,\nthese approaches lack mission completion guarantees. To address this challenge,\nwe introduce a new decentralized LLM-based planner, called S-ATLAS for Safe\nplAnning for Teams of Language-instructed AgentS, that is capable of achieving\nuser-defined mission success rates. This is accomplished by leveraging\nconformal prediction (CP), a distribution-free uncertainty quantification tool\nin black-box models. CP allows the proposed multi-robot planner to reason about\nits inherent uncertainty in a decentralized fashion, enabling robots to make\nindividual decisions when they are sufficiently certain and seek help\notherwise. We show, both theoretically and empirically, that the proposed\nplanner can achieve user-specified task success rates while minimizing the\noverall number of help requests. We provide comparative experiments against\nrelated works showing that our method is significantly more computational\nefficient and achieves lower help rates. The advantage of our algorithm over\nbaselines becomes more pronounced with increasing robot team size.\n","authors":["Jun Wang","Guocheng He","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2402.15368v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.16864v1","updated":"2024-06-24T17:59:58Z","published":"2024-06-24T17:59:58Z","title":"StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal","summary":"  This work addresses the challenge of high-quality surface normal estimation\nfrom monocular colored inputs (i.e., images and videos), a field which has\nrecently been revolutionized by repurposing diffusion priors. However, previous\nattempts still struggle with stochastic inference, conflicting with the\ndeterministic nature of the Image2Normal task, and costly ensembling step,\nwhich slows down the estimation process. Our method, StableNormal, mitigates\nthe stochasticity of the diffusion process by reducing inference variance, thus\nproducing \"Stable-and-Sharp\" normal estimates without any additional ensembling\nprocess. StableNormal works robustly under challenging imaging conditions, such\nas extreme lighting, blurring, and low quality. It is also robust against\ntransparent and reflective surfaces, as well as cluttered scenes with numerous\nobjects. Specifically, StableNormal employs a coarse-to-fine strategy, which\nstarts with a one-step normal estimator (YOSO) to derive an initial normal\nguess, that is relatively coarse but reliable, then followed by a\nsemantic-guided refinement process (SG-DRN) that refines the normals to recover\ngeometric details. The effectiveness of StableNormal is demonstrated through\ncompetitive performance in standard datasets such as DIODE-indoor, iBims,\nScannetV2 and NYUv2, and also in various downstream tasks, such as surface\nreconstruction and normal enhancement. These results evidence that StableNormal\nretains both the \"stability\" and \"sharpness\" for accurate normal estimation.\nStableNormal represents a baby attempt to repurpose diffusion priors for\ndeterministic estimation. To democratize this, code and models have been\npublicly available in hf.co/Stable-X\n","authors":["Chongjie Ye","Lingteng Qiu","Xiaodong Gu","Qi Zuo","Yushuang Wu","Zilong Dong","Liefeng Bo","Yuliang Xiu","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2406.16864v1.pdf","comment":"HF Demo: hf.co/Stable-X, Video:\n  https://www.youtube.com/watch?v=sylXTxG_U2U"},{"id":"http://arxiv.org/abs/2406.16866v1","updated":"2024-06-24T17:59:58Z","published":"2024-06-24T17:59:58Z","title":"Revisiting Referring Expression Comprehension Evaluation in the Era of\n  Large Multimodal Models","summary":"  Referring expression comprehension (REC) involves localizing a target\ninstance based on a textual description. Recent advancements in REC have been\ndriven by large multimodal models (LMMs) like CogVLM, which achieved 92.44%\naccuracy on RefCOCO. However, this study questions whether existing benchmarks\nsuch as RefCOCO, RefCOCO+, and RefCOCOg, capture LMMs' comprehensive\ncapabilities. We begin with a manual examination of these benchmarks, revealing\nhigh labeling error rates: 14% in RefCOCO, 24% in RefCOCO+, and 5% in RefCOCOg,\nwhich undermines the authenticity of evaluations. We address this by excluding\nproblematic instances and reevaluating several LMMs capable of handling the REC\ntask, showing significant accuracy improvements, thus highlighting the impact\nof benchmark noise. In response, we introduce Ref-L4, a comprehensive REC\nbenchmark, specifically designed to evaluate modern REC models. Ref-L4 is\ndistinguished by four key features: 1) a substantial sample size with 45,341\nannotations; 2) a diverse range of object categories with 365 distinct types\nand varying instance scales from 30 to 3,767; 3) lengthy referring expressions\naveraging 24.2 words; and 4) an extensive vocabulary comprising 22,813 unique\nwords. We evaluate a total of 24 large models on Ref-L4 and provide valuable\ninsights. The cleaned versions of RefCOCO, RefCOCO+, and RefCOCOg, as well as\nour Ref-L4 benchmark and evaluation code, are available at\nhttps://github.com/JierunChen/Ref-L4.\n","authors":["Jierun Chen","Fangyun Wei","Jinjing Zhao","Sizhe Song","Bohuai Wu","Zhuoxuan Peng","S. -H. Gary Chan","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16863v1","updated":"2024-06-24T17:59:56Z","published":"2024-06-24T17:59:56Z","title":"FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models","summary":"  Diffusion model has demonstrated remarkable capability in video generation,\nwhich further sparks interest in introducing trajectory control into the\ngeneration process. While existing works mainly focus on training-based methods\n(e.g., conditional adapter), we argue that diffusion model itself allows decent\ncontrol over the generated content without requiring any training. In this\nstudy, we introduce a tuning-free framework to achieve trajectory-controllable\nvideo generation, by imposing guidance on both noise construction and attention\ncomputation. Specifically, 1) we first show several instructive phenomenons and\nanalyze how initial noises influence the motion trajectory of generated\ncontent. 2) Subsequently, we propose FreeTraj, a tuning-free approach that\nenables trajectory control by modifying noise sampling and attention\nmechanisms. 3) Furthermore, we extend FreeTraj to facilitate longer and larger\nvideo generation with controllable trajectories. Equipped with these designs,\nusers have the flexibility to provide trajectories manually or opt for\ntrajectories automatically generated by the LLM trajectory planner. Extensive\nexperiments validate the efficacy of our approach in enhancing the trajectory\ncontrollability of video diffusion models.\n","authors":["Haonan Qiu","Zhaoxi Chen","Zhouxia Wang","Yingqing He","Menghan Xia","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16863v1.pdf","comment":"Project Page: http://haonanqiu.com/projects/FreeTraj.html, Code Repo:\n  https://github.com/arthur-qiu/FreeTraj"},{"id":"http://arxiv.org/abs/2406.16862v1","updated":"2024-06-24T17:59:45Z","published":"2024-06-24T17:59:45Z","title":"Dreamitate: Real-World Visuomotor Policy Learning via Video Generation","summary":"  A key challenge in manipulation is learning a policy that can robustly\ngeneralize to diverse visual environments. A promising mechanism for learning\nrobust policies is to leverage video generative models, which are pretrained on\nlarge-scale datasets of internet videos. In this paper, we propose a visuomotor\npolicy learning framework that fine-tunes a video diffusion model on human\ndemonstrations of a given task. At test time, we generate an example of an\nexecution of the task conditioned on images of a novel scene, and use this\nsynthesized execution directly to control the robot. Our key insight is that\nusing common tools allows us to effortlessly bridge the embodiment gap between\nthe human hand and the robot manipulator. We evaluate our approach on four\ntasks of increasing complexity and demonstrate that harnessing internet-scale\ngenerative models allows the learned policy to achieve a significantly higher\ndegree of generalization than existing behavior cloning approaches.\n","authors":["Junbang Liang","Ruoshi Liu","Ege Ozguroglu","Sruthi Sudhakar","Achal Dave","Pavel Tokmakov","Shuran Song","Carl Vondrick"],"pdf_url":"https://arxiv.org/pdf/2406.16862v1.pdf","comment":"Project page: https://dreamitate.cs.columbia.edu/"},{"id":"http://arxiv.org/abs/2406.16860v1","updated":"2024-06-24T17:59:42Z","published":"2024-06-24T17:59:42Z","title":"Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs","summary":"  We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a\nvision-centric approach. While stronger language models can enhance multimodal\ncapabilities, the design choices for vision components are often insufficiently\nexplored and disconnected from visual representation learning research. This\ngap hinders accurate sensory grounding in real-world scenarios. Our study uses\nLLMs and visual instruction tuning as an interface to evaluate various visual\nrepresentations, offering new insights into different models and architectures\n-- self-supervised, strongly supervised, or combinations thereof -- based on\nexperiments with over 20 vision encoders. We critically examine existing MLLM\nbenchmarks, addressing the difficulties involved in consolidating and\ninterpreting results from various tasks, and introduce a new vision-centric\nbenchmark, CV-Bench. To further improve visual grounding, we propose the\nSpatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that\nintegrates high-resolution vision features with LLMs while reducing the number\nof tokens. Additionally, we discuss the curation of high-quality visual\ninstruction-tuning data from publicly available sources, emphasizing the\nimportance of data source balancing and distribution ratio. Collectively,\nCambrian-1 not only achieves state-of-the-art performance but also serves as a\ncomprehensive, open cookbook for instruction-tuned MLLMs. We provide model\nweights, code, supporting tools, datasets, and detailed instruction-tuning and\nevaluation recipes. We hope our release will inspire and accelerate\nadvancements in multimodal systems and visual representation learning.\n","authors":["Shengbang Tong","Ellis Brown","Penghao Wu","Sanghyun Woo","Manoj Middepogu","Sai Charitha Akula","Jihan Yang","Shusheng Yang","Adithya Iyer","Xichen Pan","Austin Wang","Rob Fergus","Yann LeCun","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2406.16860v1.pdf","comment":"Website at https://cambrian-mllm.github.io"},{"id":"http://arxiv.org/abs/2406.16855v1","updated":"2024-06-24T17:58:47Z","published":"2024-06-24T17:58:47Z","title":"DreamBench++: A Human-Aligned Benchmark for Personalized Image\n  Generation","summary":"  Personalized image generation holds great promise in assisting humans in\neveryday work and life due to its impressive function in creatively generating\npersonalized content. However, current evaluations either are automated but\nmisalign with humans or require human evaluations that are time-consuming and\nexpensive. In this work, we present DreamBench++, a human-aligned benchmark\nautomated by advanced multimodal GPT models. Specifically, we systematically\ndesign the prompts to let GPT be both human-aligned and self-aligned, empowered\nwith task reinforcement. Further, we construct a comprehensive dataset\ncomprising diverse images and prompts. By benchmarking 7 modern generative\nmodels, we demonstrate that DreamBench++ results in significantly more\nhuman-aligned evaluation, helping boost the community with innovative findings.\n","authors":["Yuang Peng","Yuxin Cui","Haomiao Tang","Zekun Qi","Runpei Dong","Jing Bai","Chunrui Han","Zheng Ge","Xiangyu Zhang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2406.16855v1.pdf","comment":"Project page: https://dreambenchplus.github.io/"},{"id":"http://arxiv.org/abs/2406.16852v1","updated":"2024-06-24T17:58:06Z","published":"2024-06-24T17:58:06Z","title":"Long Context Transfer from Language to Vision","summary":"  Video sequences offer valuable temporal information, but existing large\nmultimodal models (LMMs) fall short in understanding extremely long videos.\nMany works address this by reducing the number of visual tokens using visual\nresamplers. Alternatively, in this paper, we approach this problem from the\nperspective of the language model. By simply extrapolating the context length\nof the language backbone, we enable LMMs to comprehend orders of magnitude more\nvisual tokens without any video training. We call this phenomenon long context\ntransfer and carefully ablate its properties. To effectively measure LMMs'\nability to generalize to long contexts in the vision modality, we develop\nV-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmark\ninspired by the language model's NIAH test. Our proposed Long Video Assistant\n(LongVA) can process 2000 frames or over 200K visual tokens without additional\ncomplexities. With its extended context length, LongVA achieves\nstate-of-the-art performance on Video-MME among 7B-scale models by densely\nsampling more input frames. Our work is open-sourced at\nhttps://github.com/EvolvingLMMs-Lab/LongVA.\n","authors":["Peiyuan Zhang","Kaichen Zhang","Bo Li","Guangtao Zeng","Jingkang Yang","Yuanhan Zhang","Ziyue Wang","Haoran Tan","Chunyuan Li","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16851v1","updated":"2024-06-24T17:58:03Z","published":"2024-06-24T17:58:03Z","title":"Losing Visual Needles in Image Haystacks: Vision Language Models are\n  Easily Distracted in Short and Long Contexts","summary":"  We present LoCoVQA, a dynamic benchmark generator for evaluating long-context\nextractive reasoning in vision language models (VLMs). LoCoVQA augments test\nexamples for mathematical reasoning, VQA, and character recognition tasks with\nincreasingly long visual contexts composed of both in-distribution and\nout-of-distribution distractor images.\n  Across these tasks, a diverse set of VLMs rapidly lose performance as the\nvisual context length grows, often exhibiting a striking exponential decay\ntrend. This test assesses how well VLMs can ignore irrelevant information when\nanswering queries -- a task that is quite easy for language models (LMs) in the\ntext domain -- demonstrating that current state-of-the-art VLMs lack this\nessential capability for many long-context applications.\n","authors":["Aditya Sharma","Michael Saxon","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16851v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16850v1","updated":"2024-06-24T17:57:05Z","published":"2024-06-24T17:57:05Z","title":"From Perfect to Noisy World Simulation: Customizable Embodied\n  Multi-modal Perturbations for SLAM Robustness Benchmarking","summary":"  Embodied agents require robust navigation systems to operate in unstructured\nenvironments, making the robustness of Simultaneous Localization and Mapping\n(SLAM) models critical to embodied agent autonomy. While real-world datasets\nare invaluable, simulation-based benchmarks offer a scalable approach for\nrobustness evaluations. However, the creation of a challenging and controllable\nnoisy world with diverse perturbations remains under-explored. To this end, we\npropose a novel, customizable pipeline for noisy data synthesis, aimed at\nassessing the resilience of multi-modal SLAM models against various\nperturbations. The pipeline comprises a comprehensive taxonomy of sensor and\nmotion perturbations for embodied multi-modal (specifically RGB-D) sensing,\ncategorized by their sources and propagation order, allowing for procedural\ncomposition. We also provide a toolbox for synthesizing these perturbations,\nenabling the transformation of clean environments into challenging noisy\nsimulations. Utilizing the pipeline, we instantiate the large-scale\nNoisy-Replica benchmark, which includes diverse perturbation types, to evaluate\nthe risk tolerance of existing advanced RGB-D SLAM models. Our extensive\nanalysis uncovers the susceptibilities of both neural (NeRF and Gaussian\nSplatting -based) and non-neural SLAM models to disturbances, despite their\ndemonstrated accuracy in standard benchmarks. Our code is publicly available at\nhttps://github.com/Xiaohao-Xu/SLAM-under-Perturbation.\n","authors":["Xiaohao Xu","Tianyi Zhang","Sibo Wang","Xiang Li","Yongqi Chen","Ye Li","Bhiksha Raj","Matthew Johnson-Roberson","Xiaonan Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16850v1.pdf","comment":"50 pages. arXiv admin note: substantial text overlap with\n  arXiv:2402.08125"},{"id":"http://arxiv.org/abs/2406.16848v1","updated":"2024-06-24T17:55:02Z","published":"2024-06-24T17:55:02Z","title":"Unsupervised Domain Adaptation for Pediatric Brain Tumor Segmentation","summary":"  Significant advances have been made toward building accurate automatic\nsegmentation models for adult gliomas. However, the performance of these models\noften degrades when applied to pediatric glioma due to their imaging and\nclinical differences (domain shift). Obtaining sufficient annotated data for\npediatric glioma is typically difficult because of its rare nature. Also,\nmanual annotations are scarce and expensive. In this work, we propose\nDomain-Adapted nnU-Net (DA-nnUNet) to perform unsupervised domain adaptation\nfrom adult glioma (source domain) to pediatric glioma (target domain).\nSpecifically, we add a domain classifier connected with a gradient reversal\nlayer (GRL) to a backbone nnU-Net. Once the classifier reaches a very high\naccuracy, the GRL is activated with the goal of transferring domain-invariant\nfeatures from the classifier to the segmentation model while preserving\nsegmentation accuracy on the source domain. The accuracy of the classifier\nslowly degrades to chance levels. No annotations are used in the target domain.\nThe method is compared to 8 different supervised models using BraTS-Adult\nglioma (N=1251) and BraTS-PED glioma data (N=99). The proposed method shows\nnotable performance enhancements in the tumor core (TC) region compared to the\nmodel that only uses adult data: ~32% better Dice scores and ~20 better 95th\npercentile Hausdorff distances. Moreover, our unsupervised approach shows no\nstatistically significant difference compared to the practical upper bound\nmodel using manual annotations from both datasets in TC region. The code is\nshared at https://github.com/Fjr9516/DA_nnUNet.\n","authors":["Jingru Fu","Simone Bendazzoli","Örjan Smedby","Rodrigo Moreno"],"pdf_url":"https://arxiv.org/pdf/2406.16848v1.pdf","comment":"10 pages, 4 figures, conference"},{"id":"http://arxiv.org/abs/2403.01263v2","updated":"2024-06-24T17:49:37Z","published":"2024-03-02T16:51:35Z","title":"Single-image camera calibration with model-free distortion correction","summary":"  Camera calibration is a process of paramount importance in computer vision\napplications that require accurate quantitative measurements. The popular\nmethod developed by Zhang relies on the use of a large number of images of a\nplanar grid of fiducial points captured in multiple poses. Although flexible\nand easy to implement, Zhang's method has some limitations. The simultaneous\noptimization of the entire parameter set, including the coefficients of a\npredefined distortion model, may result in poor distortion correction at the\nimage boundaries or in miscalculation of the intrinsic parameters, even with a\nreasonably small reprojection error. Indeed, applications involving image\nstitching (e.g. multi-camera systems) require accurate mapping of distortion up\nto the outermost regions of the image. Moreover, intrinsic parameters affect\nthe accuracy of camera pose estimation, which is fundamental for applications\nsuch as vision servoing in robot navigation and automated assembly. This paper\nproposes a method for estimating the complete set of calibration parameters\nfrom a single image of a planar speckle pattern covering the entire sensor. The\ncorrespondence between image points and physical points on the calibration\ntarget is obtained using Digital Image Correlation. The effective focal length\nand the extrinsic parameters are calculated separately after a prior evaluation\nof the principal point. At the end of the procedure, a dense and uniform\nmodel-free distortion map is obtained over the entire image. Synthetic data\nwith different noise levels were used to test the feasibility of the proposed\nmethod and to compare its metrological performance with Zhang's method.\nReal-world tests demonstrate the potential of the developed method to reveal\naspects of the image formation that are hidden by averaging over multiple\nimages.\n","authors":["Katia Genovese"],"pdf_url":"https://arxiv.org/pdf/2403.01263v2.pdf","comment":"Accepted manuscript"},{"id":"http://arxiv.org/abs/2406.16817v1","updated":"2024-06-24T17:26:06Z","published":"2024-06-24T17:26:06Z","title":"GPT-4V Explorations: Mining Autonomous Driving","summary":"  This paper explores the application of the GPT-4V(ision) large visual\nlanguage model to autonomous driving in mining environments, where traditional\nsystems often falter in understanding intentions and making accurate decisions\nduring emergencies. GPT-4V introduces capabilities for visual question\nanswering and complex scene comprehension, addressing challenges in these\nspecialized settings.Our evaluation focuses on its proficiency in scene\nunderstanding, reasoning, and driving functions, with specific tests on its\nability to recognize and interpret elements such as pedestrians, various\nvehicles, and traffic devices. While GPT-4V showed robust comprehension and\ndecision-making skills, it faced difficulties in accurately identifying\nspecific vehicle types and managing dynamic interactions. Despite these\nchallenges, its effective navigation and strategic decision-making demonstrate\nits potential as a reliable agent for autonomous driving in the complex\nconditions of mining environments, highlighting its adaptability and\noperational viability in industrial settings.\n","authors":["Zixuan Li"],"pdf_url":"https://arxiv.org/pdf/2406.16817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16815v1","updated":"2024-06-24T17:25:39Z","published":"2024-06-24T17:25:39Z","title":"ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians","summary":"  High-fidelity 3D garment synthesis from text is desirable yet challenging for\ndigital avatar creation. Recent diffusion-based approaches via Score\nDistillation Sampling (SDS) have enabled new possibilities but either\nintricately couple with human body or struggle to reuse. We introduce\nClotheDreamer, a 3D Gaussian-based method for generating wearable,\nproduction-ready 3D garment assets from text prompts. We propose a novel\nrepresentation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate\noptimization. DCGS represents clothed avatar as one Gaussian model but freezes\nbody Gaussian splats. To enhance quality and completeness, we incorporate\nbidirectional SDS to supervise clothed avatar and garment RGBD renderings\nrespectively with pose conditions and propose a new pruning strategy for loose\nclothing. Our approach can also support custom clothing templates as input.\nBenefiting from our design, the synthetic 3D garment can be easily applied to\nvirtual try-on and support physically accurate animation. Extensive experiments\nshowcase our method's superior and competitive performance. Our project page is\nat https://ggxxii.github.io/clothedreamer.\n","authors":["Yufei Liu","Junshu Tang","Chu Zheng","Shijie Zhang","Jinkun Hao","Junwei Zhu","Dongjin Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16815v1.pdf","comment":"Project Page: https://ggxxii.github.io/clothedreamer"},{"id":"http://arxiv.org/abs/2406.16807v1","updated":"2024-06-24T17:19:34Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16784v1","updated":"2024-06-24T16:45:28Z","published":"2024-06-24T16:45:28Z","title":"The Progression of Transformers from Language to Vision to MOT: A\n  Literature Review on Multi-Object Tracking with Transformers","summary":"  The transformer neural network architecture allows for autoregressive\nsequence-to-sequence modeling through the use of attention layers. It was\noriginally created with the application of machine translation but has\nrevolutionized natural language processing. Recently, transformers have also\nbeen applied across a wide variety of pattern recognition tasks, particularly\nin computer vision. In this literature review, we describe major advances in\ncomputer vision utilizing transformers. We then focus specifically on\nMulti-Object Tracking (MOT) and discuss how transformers are increasingly\nbecoming competitive in state-of-the-art MOT works, yet still lag behind\ntraditional deep learning methods.\n","authors":["Abhi Kamboj"],"pdf_url":"https://arxiv.org/pdf/2406.16784v1.pdf","comment":"This report was written in November 2022, and may not contain more\n  recent works since then"},{"id":"http://arxiv.org/abs/2406.16776v1","updated":"2024-06-24T16:35:58Z","published":"2024-06-24T16:35:58Z","title":"Instance Consistency Regularization for Semi-Supervised 3D Instance\n  Segmentation","summary":"  Large-scale datasets with point-wise semantic and instance labels are crucial\nto 3D instance segmentation but also expensive. To leverage unlabeled data,\nprevious semi-supervised 3D instance segmentation approaches have explored\nself-training frameworks, which rely on high-quality pseudo labels for\nconsistency regularization. They intuitively utilize both instance and semantic\npseudo labels in a joint learning manner. However, semantic pseudo labels\ncontain numerous noise derived from the imbalanced category distribution and\nnatural confusion of similar but distinct categories, which leads to severe\ncollapses in self-training. Motivated by the observation that 3D instances are\nnon-overlapping and spatially separable, we ask whether we can solely rely on\ninstance consistency regularization for improved semi-supervised segmentation.\nTo this end, we propose a novel self-training network InsTeacher3D to explore\nand exploit pure instance knowledge from unlabeled data. We first build a\nparallel base 3D instance segmentation model DKNet, which distinguishes each\ninstance from the others via discriminative instance kernels without reliance\non semantic segmentation. Based on DKNet, we further design a novel instance\nconsistency regularization framework to generate and leverage high-quality\ninstance pseudo labels. Experimental results on multiple large-scale datasets\nshow that the InsTeacher3D significantly outperforms prior state-of-the-art\nsemi-supervised approaches. Code is available:\nhttps://github.com/W1zheng/InsTeacher3D.\n","authors":["Yizheng Wu","Zhiyu Pan","Kewei Wang","Xingyi Li","Jiahao Cui","Liwen Xiao","Guosheng Lin","Zhiguo Cao"],"pdf_url":"https://arxiv.org/pdf/2406.16776v1.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.15252v2","updated":"2024-06-24T16:22:55Z","published":"2024-06-21T15:43:46Z","title":"VideoScore: Building Automatic Metrics to Simulate Fine-grained Human\n  Feedback for Video Generation","summary":"  The recent years have witnessed great advances in video generation. However,\nthe development of automatic video metrics is lagging significantly behind.\nNone of the existing metric is able to provide reliable scores over generated\nvideos. The main barrier is the lack of large-scale human-annotated dataset. In\nthis paper, we release VideoFeedback, the first large-scale dataset containing\nhuman-provided multi-aspect score over 37.6K synthesized videos from 11\nexisting video generative models. We train VideoScore (initialized from Mantis)\nbased on VideoFeedback to enable automatic video quality assessment.\nExperiments show that the Spearman correlation between VideoScore and humans\ncan reach 77.1 on VideoFeedback-test, beating the prior best metrics by about\n50 points. Further result on other held-out EvalCrafter, GenAI-Bench, and\nVBench show that VideoScore has consistently much higher correlation with human\njudges than other metrics. Due to these results, we believe VideoScore can\nserve as a great proxy for human raters to (1) rate different video models to\ntrack progress (2) simulate fine-grained human feedback in Reinforcement\nLearning with Human Feedback (RLHF) to improve current video generation models.\n","authors":["Xuan He","Dongfu Jiang","Ge Zhang","Max Ku","Achint Soni","Sherman Siu","Haonan Chen","Abhranil Chandra","Ziyan Jiang","Aaran Arulraj","Kai Wang","Quy Duc Do","Yuansheng Ni","Bohan Lyu","Yaswanth Narsupalli","Rongqi Fan","Zhiheng Lyu","Yuchen Lin","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.15252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01902v2","updated":"2024-06-24T16:11:33Z","published":"2023-06-02T20:19:19Z","title":"Unlearnable Examples for Diffusion Models: Protect Data from\n  Unauthorized Exploitation","summary":"  Diffusion models have demonstrated remarkable performance in image generation\ntasks, paving the way for powerful AIGC applications. However, these\nwidely-used generative models can also raise security and privacy concerns,\nsuch as copyright infringement, and sensitive data leakage. To tackle these\nissues, we propose a method, Unlearnable Diffusion Perturbation, to safeguard\nimages from unauthorized exploitation. Our approach involves designing an\nalgorithm to generate sample-wise perturbation noise for each image to be\nprotected. This imperceptible protective noise makes the data almost\nunlearnable for diffusion models, i.e., diffusion models trained or fine-tuned\non the protected data cannot generate high-quality and diverse images related\nto the protected training data. Theoretically, we frame this as a max-min\noptimization problem and introduce EUDP, a noise scheduler-based method to\nenhance the effectiveness of the protective noise. We evaluate our methods on\nboth Denoising Diffusion Probabilistic Model and Latent Diffusion Models,\ndemonstrating that training diffusion models on the protected data lead to a\nsignificant reduction in the quality of the generated images. Especially, the\nexperimental results on Stable Diffusion demonstrate that our method\neffectively safeguards images from being used to train Diffusion Models in\nvarious tasks, such as training specific objects and styles. This achievement\nholds significant importance in real-world scenarios, as it contributes to the\nprotection of privacy and copyright against AI-generated content.\n","authors":["Zhengyue Zhao","Jinhao Duan","Xing Hu","Kaidi Xu","Chenan Wang","Rui Zhang","Zidong Du","Qi Guo","Yunji Chen"],"pdf_url":"https://arxiv.org/pdf/2306.01902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16754v1","updated":"2024-06-24T16:00:20Z","published":"2024-06-24T16:00:20Z","title":"The MRI Scanner as a Diagnostic: Image-less Active Sampling","summary":"  Despite the high diagnostic accuracy of Magnetic Resonance Imaging (MRI),\nusing MRI as a Point-of-Care (POC) disease identification tool poses\nsignificant accessibility challenges due to the use of high magnetic field\nstrength and lengthy acquisition times. We ask a simple question: Can we\ndynamically optimise acquired samples, at the patient level, according to an\n(automated) downstream decision task, while discounting image reconstruction?\nWe propose an ML-based framework that learns an active sampling strategy, via\nreinforcement learning, at a patient-level to directly infer disease from\nundersampled k-space. We validate our approach by inferring Meniscus Tear in\nundersampled knee MRI data, where we achieve diagnostic performance comparable\nwith ML-based diagnosis, using fully sampled k-space data. We analyse\ntask-specific sampling policies, showcasing the adaptability of our active\nsampling approach. The introduced frugal sampling strategies have the potential\nto reduce high field strength requirements that in turn strengthen the\nviability of MRI-based POC disease identification and associated preliminary\nscreening tools.\n","authors":["Yuning Du","Rohan Dharmakumar","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2406.16754v1.pdf","comment":"Accepted in MICCAI 2024"},{"id":"http://arxiv.org/abs/2404.02072v5","updated":"2024-06-24T15:52:57Z","published":"2024-04-02T16:20:02Z","title":"EGTR: Extracting Graph from Transformer for Scene Graph Generation","summary":"  Scene Graph Generation (SGG) is a challenging task of detecting objects and\npredicting relationships between objects. After DETR was developed, one-stage\nSGG models based on a one-stage object detector have been actively studied.\nHowever, complex modeling is used to predict the relationship between objects,\nand the inherent relationship between object queries learned in the multi-head\nself-attention of the object detector has been neglected. We propose a\nlightweight one-stage SGG model that extracts the relation graph from the\nvarious relationships learned in the multi-head self-attention layers of the\nDETR decoder. By fully utilizing the self-attention by-products, the relation\ngraph can be extracted effectively with a shallow relation extraction head.\nConsidering the dependency of the relation extraction task on the object\ndetection task, we propose a novel relation smoothing technique that adjusts\nthe relation label adaptively according to the quality of the detected objects.\nBy the relation smoothing, the model is trained according to the continuous\ncurriculum that focuses on object detection task at the beginning of training\nand performs multi-task learning as the object detection performance gradually\nimproves. Furthermore, we propose a connectivity prediction task that predicts\nwhether a relation exists between object pairs as an auxiliary task of the\nrelation extraction. We demonstrate the effectiveness and efficiency of our\nmethod for the Visual Genome and Open Image V6 datasets. Our code is publicly\navailable at https://github.com/naver-ai/egtr.\n","authors":["Jinbae Im","JeongYeon Nam","Nokyung Park","Hyungmin Lee","Seunghyun Park"],"pdf_url":"https://arxiv.org/pdf/2404.02072v5.pdf","comment":"CVPR 2024 (Best paper award candidate)"},{"id":"http://arxiv.org/abs/2311.08695v2","updated":"2024-06-24T15:51:13Z","published":"2023-11-15T04:50:30Z","title":"Attribute Diversity Determines the Systematicity Gap in VQA","summary":"  The degree to which neural networks can generalize to new combinations of\nfamiliar concepts, and the conditions under which they are able to do so, has\nlong been an open question. In this work, we study the systematicity gap in\nvisual question answering: the performance difference between reasoning on\npreviously seen and unseen combinations of object attributes. To test, we\nintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased\nquantity of training data does not reduce the systematicity gap, increased\ntraining data diversity of the attributes in the unseen combination does. In\nall, our experiments suggest that the more distinct attribute type combinations\nare seen during training, the more systematic we can expect the resulting model\nto be.\n","authors":["Ian Berlot-Attwell","Kumar Krishna Agrawal","A. Michael Carrell","Yash Sharma","Naomi Saphra"],"pdf_url":"https://arxiv.org/pdf/2311.08695v2.pdf","comment":"33 pages, 20 figures"},{"id":"http://arxiv.org/abs/2312.00084v2","updated":"2024-06-24T15:44:42Z","published":"2023-11-30T07:17:43Z","title":"Can Protective Perturbation Safeguard Personal Data from Being Exploited\n  by Stable Diffusion?","summary":"  Stable Diffusion has established itself as a foundation model in generative\nAI artistic applications, receiving widespread research and application. Some\nrecent fine-tuning methods have made it feasible for individuals to implant\npersonalized concepts onto the basic Stable Diffusion model with minimal\ncomputational costs on small datasets. However, these innovations have also\ngiven rise to issues like facial privacy forgery and artistic copyright\ninfringement. In recent studies, researchers have explored the addition of\nimperceptible adversarial perturbations to images to prevent potential\nunauthorized exploitation and infringements when personal data is used for\nfine-tuning Stable Diffusion. Although these studies have demonstrated the\nability to protect images, it is essential to consider that these methods may\nnot be entirely applicable in real-world scenarios. In this paper, we\nsystematically evaluate the use of perturbations to protect images within a\npractical threat model. The results suggest that these approaches may not be\nsufficient to safeguard image privacy and copyright effectively. Furthermore,\nwe introduce a purification method capable of removing protected perturbations\nwhile preserving the original image structure to the greatest extent possible.\nExperiments reveal that Stable Diffusion can effectively learn from purified\nimages over all protective methods.\n","authors":["Zhengyue Zhao","Jinhao Duan","Kaidi Xu","Chenan Wang","Rui Zhang","Zidong Du","Qi Guo","Xing Hu"],"pdf_url":"https://arxiv.org/pdf/2312.00084v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00816v4","updated":"2024-06-24T15:40:01Z","published":"2023-06-01T15:42:06Z","title":"Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and\n  Compatible Triggers","summary":"  Deep neural networks (DNNs) can be manipulated to exhibit specific behaviors\nwhen exposed to specific trigger patterns, without affecting their performance\non benign samples, dubbed \\textit{backdoor attack}. Currently, implementing\nbackdoor attacks in physical scenarios still faces significant challenges.\nPhysical attacks are labor-intensive and time-consuming, and the triggers are\nselected in a manual and heuristic way. Moreover, expanding digital attacks to\nphysical scenarios faces many challenges due to their sensitivity to visual\ndistortions and the absence of counterparts in the real world. To address these\nchallenges, we define a novel trigger called the \\textbf{V}isible,\n\\textbf{S}emantic, \\textbf{S}ample-Specific, and \\textbf{C}ompatible (VSSC)\ntrigger, to achieve effective, stealthy and robust simultaneously, which can\nalso be effectively deployed in the physical scenario using corresponding\nobjects. To implement the VSSC trigger, we propose an automated pipeline\ncomprising three modules: a trigger selection module that systematically\nidentifies suitable triggers leveraging large language models, a trigger\ninsertion module that employs generative models to seamlessly integrate\ntriggers into images, and a quality assessment module that ensures the natural\nand successful insertion of triggers through vision-language models. Extensive\nexperimental results and analysis validate the effectiveness, stealthiness, and\nrobustness of the VSSC trigger. It can not only maintain robustness under\nvisual distortions but also demonstrates strong practicality in the physical\nscenario. We hope that the proposed VSSC trigger and implementation approach\ncould inspire future studies on designing more practical triggers in backdoor\nattacks.\n","authors":["Ruotong Wang","Hongrui Chen","Zihao Zhu","Li Liu","Baoyuan Wu"],"pdf_url":"https://arxiv.org/pdf/2306.00816v4.pdf","comment":"23 pages, 21 figures, 18 tables"},{"id":"http://arxiv.org/abs/2311.01380v2","updated":"2024-06-24T15:39:13Z","published":"2023-11-02T16:37:27Z","title":"Sim2Real Bilevel Adaptation for Object Surface Classification using\n  Vision-Based Tactile Sensors","summary":"  In this paper, we address the Sim2Real gap in the field of vision-based\ntactile sensors for classifying object surfaces. We train a Diffusion Model to\nbridge this gap using a relatively small dataset of real-world images randomly\ncollected from unlabeled everyday objects via the DIGIT sensor. Subsequently,\nwe employ a simulator to generate images by uniformly sampling the surface of\nobjects from the YCB Model Set. These simulated images are then translated into\nthe real domain using the Diffusion Model and automatically labeled to train a\nclassifier. During this training, we further align features of the two domains\nusing an adversarial procedure. Our evaluation is conducted on a dataset of\ntactile images obtained from a set of ten 3D printed YCB objects. The results\nreveal a total accuracy of 81.9%, a significant improvement compared to the\n34.7% achieved by the classifier trained solely on simulated images. This\ndemonstrates the effectiveness of our approach. We further validate our\napproach using the classifier on a 6D object pose estimation task from tactile\ndata.\n","authors":["Gabriele M. Caddeo","Andrea Maracani","Paolo D. Alfano","Nicola A. Piga","Lorenzo Rosasco","Lorenzo Natale"],"pdf_url":"https://arxiv.org/pdf/2311.01380v2.pdf","comment":"6 pages, accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2406.14862v2","updated":"2024-06-24T15:30:34Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\nLatentExplainer, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\nLatentExplainer tackles three main challenges: inferring the meaning of latent\nvariables, aligning explanations with inductive biases, and handling varying\ndegrees of explainability. By perturbing latent variables and interpreting\nchanges in generated data, the framework provides a systematic approach to\nunderstanding and controlling the data generation process, enhancing the\ntransparency and interpretability of deep generative models. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations of\nlatent variables.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16724v1","updated":"2024-06-24T15:29:08Z","published":"2024-06-24T15:29:08Z","title":"μ-Net: A Deep Learning-Based Architecture for μ-CT Segmentation","summary":"  X-ray computed microtomography ({\\mu}-CT) is a non-destructive technique that\ncan generate high-resolution 3D images of the internal anatomy of medical and\nbiological samples. These images enable clinicians to examine internal anatomy\nand gain insights into the disease or anatomical morphology. However,\nextracting relevant information from 3D images requires semantic segmentation\nof the regions of interest, which is usually done manually and results\ntime-consuming and tedious. In this work, we propose a novel framework that\nuses a convolutional neural network (CNN) to automatically segment the full\nmorphology of the heart of Carassius auratus. The framework employs an\noptimized 2D CNN architecture that can infer a 3D segmentation of the sample,\navoiding the high computational cost of a 3D CNN architecture. We tackle the\nchallenges of handling large and high-resoluted image data (over a thousand\npixels in each dimension) and a small training database (only three samples) by\nproposing a standard protocol for data normalization and processing. Moreover,\nwe investigate how the noise, contrast, and spatial resolution of the sample\nand the training of the architecture are affected by the reconstruction\ntechnique, which depends on the number of input images. Experiments show that\nour framework significantly reduces the time required to segment new samples,\nallowing a faster microtomography analysis of the Carassius auratus heart\nshape. Furthermore, our framework can work with any bio-image (biological and\nmedical) from {\\mu}-CT with high-resolution and small dataset size\n","authors":["Pierangela Bruno","Edoardo De Rose","Carlo Adornetto","Francesco Calimeri","Sandro Donato","Raffaele Giuseppe Agostino","Daniela Amelio","Riccardo Barberi","Maria Carmela Cerra","Maria Caterina Crocco","Mariacristina Filice","Raffaele Filosa","Gianluigi Greco","Sandra Imbrogno","Vincenzo Formoso"],"pdf_url":"https://arxiv.org/pdf/2406.16724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16710v1","updated":"2024-06-24T15:11:35Z","published":"2024-06-24T15:11:35Z","title":"Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image","summary":"  While recent works have achieved great success on one-shot 3D common object\ngeneration, high quality and fidelity 3D head generation from a single image\nremains a great challenge. Previous text-based methods for generating 3D heads\nwere limited by text descriptions and image-based methods struggled to produce\nhigh-quality head geometry. To handle this challenging problem, we propose a\nnovel framework, Portrait3D, to generate high-quality 3D heads while preserving\ntheir identities. Our work incorporates the identity information of the\nportrait image into three parts: 1) geometry initialization, 2) geometry\nsculpting, and 3) texture generation stages. Given a reference portrait image,\nwe first align the identity features with text features to realize ID-aware\nguidance enhancement, which contains the control signals representing the face\ninformation. We then use the canny map, ID features of the portrait image, and\na pre-trained text-to-normal/depth diffusion model to generate ID-aware\ngeometry supervision, and 3D-GAN inversion is employed to generate ID-aware\ngeometry initialization. Furthermore, with the ability to inject identity\ninformation into 3D head generation, we use ID-aware guidance to calculate\nID-aware Score Distillation (ISD) for geometry sculpting. For texture\ngeneration, we adopt the ID Consistent Texture Inpainting and Refinement which\nprogressively expands the view for texture inpainting to obtain an\ninitialization UV texture map. We then use the id-aware guidance to provide\nimage-level supervision for noisy multi-view images to obtain a refined texture\nmap. Extensive experiments demonstrate that we can generate high-quality 3D\nheads with accurate geometry and texture from single in-the-wild portrait\nimages. The project page is at https://jinkun-hao.github.io/Portrait3D/.\n","authors":["Jinkun Hao","Junshu Tang","Jiangning Zhang","Ran Yi","Yijia Hong","Moran Li","Weijian Cao","Yating Wang","Lizhuang Ma"],"pdf_url":"https://arxiv.org/pdf/2406.16710v1.pdf","comment":"https://jinkun-hao.github.io/Portrait3D/"},{"id":"http://arxiv.org/abs/2406.09681v2","updated":"2024-06-24T15:11:27Z","published":"2024-06-14T03:07:23Z","title":"Asymmetrical Siamese Network for Point Clouds Normal Estimation","summary":"  In recent years, deep learning-based point cloud normal estimation has made\ngreat progress. However, existing methods mainly rely on the PCPNet dataset,\nleading to overfitting. In addition, the correlation between point clouds with\ndifferent noise scales remains unexplored, resulting in poor performance in\ncross-domain scenarios. In this paper, we explore the consistency of intrinsic\nfeatures learned from clean and noisy point clouds using an Asymmetric Siamese\nNetwork architecture. By applying reasonable constraints between features\nextracted from different branches, we enhance the quality of normal estimation.\nMoreover, we introduce a novel multi-view normal estimation dataset that\nincludes a larger variety of shapes with different noise levels. Evaluation of\nexisting methods on this new dataset reveals their inability to adapt to\ndifferent types of shapes, indicating a degree of overfitting. Extensive\nexperiments show that the proposed dataset poses significant challenges for\npoint cloud normal estimation and that our feature constraint mechanism\neffectively improves upon existing methods and reduces overfitting in current\narchitectures.\n","authors":["Wei Jin","Jun Zhou","Nannan Li","Haba Madeline","Xiuping Liu"],"pdf_url":"https://arxiv.org/pdf/2406.09681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18435v2","updated":"2024-06-24T15:07:34Z","published":"2024-03-19T17:57:24Z","title":"QUBIQ: Uncertainty Quantification for Biomedical Image Segmentation\n  Challenge","summary":"  Uncertainty in medical image segmentation tasks, especially inter-rater\nvariability, arising from differences in interpretations and annotations by\nvarious experts, presents a significant challenge in achieving consistent and\nreliable image segmentation. This variability not only reflects the inherent\ncomplexity and subjective nature of medical image interpretation but also\ndirectly impacts the development and evaluation of automated segmentation\nalgorithms. Accurately modeling and quantifying this variability is essential\nfor enhancing the robustness and clinical applicability of these algorithms. We\nreport the set-up and summarize the benchmark results of the Quantification of\nUncertainties in Biomedical Image Quantification Challenge (QUBIQ), which was\norganized in conjunction with International Conferences on Medical Image\nComputing and Computer-Assisted Intervention (MICCAI) 2020 and 2021. The\nchallenge focuses on the uncertainty quantification of medical image\nsegmentation which considers the omnipresence of inter-rater variability in\nimaging datasets. The large collection of images with multi-rater annotations\nfeatures various modalities such as MRI and CT; various organs such as the\nbrain, prostate, kidney, and pancreas; and different image dimensions 2D-vs-3D.\nA total of 24 teams submitted different solutions to the problem, combining\nvarious baseline models, Bayesian neural networks, and ensemble model\ntechniques. The obtained results indicate the importance of the ensemble\nmodels, as well as the need for further research to develop efficient 3D\nmethods for uncertainty quantification methods in 3D segmentation tasks.\n","authors":["Hongwei Bran Li","Fernando Navarro","Ivan Ezhov","Amirhossein Bayat","Dhritiman Das","Florian Kofler","Suprosanna Shit","Diana Waldmannstetter","Johannes C. Paetzold","Xiaobin Hu","Benedikt Wiestler","Lucas Zimmer","Tamaz Amiranashvili","Chinmay Prabhakar","Christoph Berger","Jonas Weidner","Michelle Alonso-Basant","Arif Rashid","Ujjwal Baid","Wesam Adel","Deniz Ali","Bhakti Baheti","Yingbin Bai","Ishaan Bhatt","Sabri Can Cetindag","Wenting Chen","Li Cheng","Prasad Dutand","Lara Dular","Mustafa A. Elattar","Ming Feng","Shengbo Gao","Henkjan Huisman","Weifeng Hu","Shubham Innani","Wei Jiat","Davood Karimi","Hugo J. Kuijf","Jin Tae Kwak","Hoang Long Le","Xiang Lia","Huiyan Lin","Tongliang Liu","Jun Ma","Kai Ma","Ting Ma","Ilkay Oksuz","Robbie Holland","Arlindo L. Oliveira","Jimut Bahan Pal","Xuan Pei","Maoying Qiao","Anindo Saha","Raghavendra Selvan","Linlin Shen","Joao Lourenco Silva","Ziga Spiclin","Sanjay Talbar","Dadong Wang","Wei Wang","Xiong Wang","Yin Wang","Ruiling Xia","Kele Xu","Yanwu Yan","Mert Yergin","Shuang Yu","Lingxi Zeng","YingLin Zhang","Jiachen Zhao","Yefeng Zheng","Martin Zukovec","Richard Do","Anton Becker","Amber Simpson","Ender Konukoglu","Andras Jakab","Spyridon Bakas","Leo Joskowicz","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2405.18435v2.pdf","comment":"initial technical report"},{"id":"http://arxiv.org/abs/2406.16701v1","updated":"2024-06-24T15:04:14Z","published":"2024-06-24T15:04:14Z","title":"Demystifying the Effect of Receptive Field Size in U-Net Models for\n  Medical Image Segmentation","summary":"  Medical image segmentation is a critical task in healthcare applications, and\nU-Nets have demonstrated promising results. This work delves into the\nunderstudied aspect of receptive field (RF) size and its impact on the U-Net\nand Attention U-Net architectures. This work explores several critical elements\nincluding the relationship between RF size, characteristics of the region of\ninterest, and model performance, as well as the balance between RF size and\ncomputational costs for U-Net and Attention U-Net methods for different\ndatasets. This work also proposes a mathematical notation for representing the\ntheoretical receptive field (TRF) of a given layer in a network and proposes\ntwo new metrics - effective receptive field (ERF) rate and the Object rate to\nquantify the fraction of significantly contributing pixels within the ERF\nagainst the TRF area and assessing the relative size of the segmentation object\ncompared to the TRF size respectively. The results demonstrate that there\nexists an optimal TRF size that successfully strikes a balance between\ncapturing a wider global context and maintaining computational efficiency,\nthereby optimizing model performance. Interestingly, a distinct correlation is\nobserved between the data complexity and the required TRF size; segmentation\nbased solely on contrast achieved peak performance even with smaller TRF sizes,\nwhereas more complex segmentation tasks necessitated larger TRFs. Attention\nU-Net models consistently outperformed their U-Net counterparts, highlighting\nthe value of attention mechanisms regardless of TRF size. These novel insights\npresent an invaluable resource for developing more efficient U-Net-based\narchitectures for medical imaging and pave the way for future exploration. A\ntool is also developed that calculates the TRF for a U-Net (and Attention\nU-Net) model, and also suggest an appropriate TRF size for a given model and\ndataset.\n","authors":["Vincent Loos","Rohit Pardasani","Navchetan Awasthi"],"pdf_url":"https://arxiv.org/pdf/2406.16701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11433v2","updated":"2024-06-24T15:03:52Z","published":"2023-09-20T16:10:53Z","title":"A Systematic Review of Few-Shot Learning in Medical Imaging","summary":"  The lack of annotated medical images limits the performance of deep learning\nmodels, which usually need large-scale labelled datasets. Few-shot learning\ntechniques can reduce data scarcity issues and enhance medical image analysis,\nespecially with meta-learning. This systematic review gives a comprehensive\noverview of few-shot learning in medical imaging. We searched the literature\nsystematically and selected 80 relevant articles published from 2018 to 2023.\nWe clustered the articles based on medical outcomes, such as tumour\nsegmentation, disease classification, and image registration; anatomical\nstructure investigated (i.e. heart, lung, etc.); and the meta-learning method\nused. For each cluster, we examined the papers' distributions and the results\nprovided by the state-of-the-art. In addition, we identified a generic pipeline\nshared among all the studies. The review shows that few-shot learning can\novercome data scarcity in most outcomes and that meta-learning is a popular\nchoice to perform few-shot learning because it can adapt to new tasks with few\nlabelled samples. In addition, following meta-learning, supervised learning and\nsemi-supervised learning stand out as the predominant techniques employed to\ntackle few-shot learning challenges in medical imaging and also best\nperforming. Lastly, we observed that the primary application areas\npredominantly encompass cardiac, pulmonary, and abdominal domains. This\nsystematic review aims to inspire further research to improve medical image\nanalysis and patient care.\n","authors":["Eva Pachetti","Sara Colantonio"],"pdf_url":"https://arxiv.org/pdf/2309.11433v2.pdf","comment":"48 pages, 29 figures, 10 tables, submitted to Elsevier on 19 Sep 2023"},{"id":"http://arxiv.org/abs/2406.16695v1","updated":"2024-06-24T14:58:17Z","published":"2024-06-24T14:58:17Z","title":"Geometry-Aware Score Distillation via 3D Consistent Noising and Gradient\n  Consistency Modeling","summary":"  Score distillation sampling (SDS), the methodology in which the score from\npretrained 2D diffusion models is distilled into 3D representation, has\nrecently brought significant advancements in text-to-3D generation task.\nHowever, this approach is still confronted with critical geometric\ninconsistency problems such as the Janus problem. Starting from a hypothesis\nthat such inconsistency problems may be induced by multiview inconsistencies\nbetween 2D scores predicted from various viewpoints, we introduce GSD, a simple\nand general plug-and-play framework for incorporating 3D consistency and\ntherefore geometry awareness into the SDS process. Our methodology is composed\nof three components: 3D consistent noising, designed to produce 3D consistent\nnoise maps that perfectly follow the standard Gaussian distribution,\ngeometry-based gradient warping for identifying correspondences between\npredicted gradients of different viewpoints, and novel gradient consistency\nloss to optimize the scene geometry toward producing more consistent gradients.\nWe demonstrate that our method significantly improves performance, successfully\naddressing the geometric inconsistency problems in text-to-3D generation task\nwith minimal computation cost and being compatible with existing score\ndistillation-based models. Our project page is available at\nhttps://ku-cvlab.github.io/GSD/.\n","authors":["Min-Seop Kwak","Donghoon Ahn","Ines Hyeonsu Kim","Jin-wha Kim","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2406.16695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16683v1","updated":"2024-06-24T14:43:02Z","published":"2024-06-24T14:43:02Z","title":"Repulsive Score Distillation for Diverse Sampling of Diffusion Models","summary":"  Score distillation sampling has been pivotal for integrating diffusion models\ninto generation of complex visuals. Despite impressive results it suffers from\nmode collapse and lack of diversity. To cope with this challenge, we leverage\nthe gradient flow interpretation of score distillation to propose Repulsive\nScore Distillation (RSD). In particular, we propose a variational framework\nbased on repulsion of an ensemble of particles that promotes diversity. Using a\nvariational approximation that incorporates a coupling among particles, the\nrepulsion appears as a simple regularization that allows interaction of\nparticles based on their relative pairwise similarity, measured e.g., via\nradial basis kernels. We design RSD for both unconstrained and constrained\nsampling scenarios. For constrained sampling we focus on inverse problems in\nthe latent space that leads to an augmented variational formulation, that\nstrikes a good balance between compute, quality and diversity. Our extensive\nexperiments for text-to-image generation, and inverse problems demonstrate that\nRSD achieves a superior trade-off between diversity and quality compared with\nstate-of-the-art alternatives.\n","authors":["Nicolas Zilberstein","Morteza Mardani","Santiago Segarra"],"pdf_url":"https://arxiv.org/pdf/2406.16683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16658v1","updated":"2024-06-24T14:08:27Z","published":"2024-06-24T14:08:27Z","title":"Sampling Strategies in Bayesian Inversion: A Study of RTO and Langevin\n  Methods","summary":"  This paper studies two classes of sampling methods for the solution of\ninverse problems, namely Randomize-Then-Optimize (RTO), which is rooted in\nsensitivity analysis, and Langevin methods, which are rooted in the Bayesian\nframework. The two classes of methods correspond to different assumptions and\nyield samples from different target distributions. We highlight the main\nconceptual and theoretical differences between the two approaches and compare\nthem from a practical point of view by tackling two classical inverse problems\nin imaging: deblurring and inpainting. We show that the choice of the sampling\nmethod has a significant impact on the quality of the reconstruction and that\nthe RTO method is more robust to the choice of the parameters.\n","authors":["Remi Laumont","Yiqiu Dong","Martin Skovgaard Andersen"],"pdf_url":"https://arxiv.org/pdf/2406.16658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16641v1","updated":"2024-06-24T13:45:31Z","published":"2024-06-24T13:45:31Z","title":"Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind\n  AI Generated Image Quality Assessment","summary":"  Recently, textual prompt tuning has shown inspirational performance in\nadapting Contrastive Language-Image Pre-training (CLIP) models to natural image\nquality assessment. However, such uni-modal prompt learning method only tunes\nthe language branch of CLIP models. This is not enough for adapting CLIP models\nto AI generated image quality assessment (AGIQA) since AGIs visually differ\nfrom natural images. In addition, the consistency between AGIs and user input\ntext prompts, which correlates with the perceptual quality of AGIs, is not\ninvestigated to guide AGIQA. In this letter, we propose vision-language\nconsistency guided multi-modal prompt learning for blind AGIQA, dubbed\nCLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in\nlanguage and vision branches of CLIP models, respectively. Moreover, we design\na text-to-image alignment quality prediction task, whose learned\nvision-language consistency knowledge is used to guide the optimization of the\nabove multi-modal prompts. Experimental results on two public AGIQA datasets\ndemonstrate that the proposed method outperforms state-of-the-art quality\nassessment models. The source code is available at\nhttps://github.com/JunFu1995/CLIP-AGIQA.\n","authors":["Jun Fu","Wei Zhou","Qiuping Jiang","Hantao Liu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2406.16641v1.pdf","comment":"Accepted by IEEE Signal Processing Letter"},{"id":"http://arxiv.org/abs/2406.16638v1","updated":"2024-06-24T13:44:06Z","published":"2024-06-24T13:44:06Z","title":"Feature Fusion for Human Activity Recognition using Parameter-Optimized\n  Multi-Stage Graph Convolutional Network and Transformer Models","summary":"  Human activity recognition (HAR) is a crucial area of research that involves\nunderstanding human movements using computer and machine vision technology.\nDeep learning has emerged as a powerful tool for this task, with models such as\nConvolutional Neural Networks (CNNs) and Transformers being employed to capture\nvarious aspects of human motion. One of the key contributions of this work is\nthe demonstration of the effectiveness of feature fusion in improving HAR\naccuracy by capturing spatial and temporal features, which has important\nimplications for the development of more accurate and robust activity\nrecognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,\nand TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and\nevaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG\nachieved high accuracies and f1-scores, while LARa and PKU-MMD had lower\nscores. Feature fusion improved results across datasets.\n","authors":["Mohammad Belal","Taimur Hassan","Abdelfatah Ahmed","Ahmad Aljarah","Nael Alsheikh","Irfan Hussain"],"pdf_url":"https://arxiv.org/pdf/2406.16638v1.pdf","comment":"7 pages, 1 figure, conference"},{"id":"http://arxiv.org/abs/2406.16633v1","updated":"2024-06-24T13:30:55Z","published":"2024-06-24T13:30:55Z","title":"MLAAN: Scaling Supervised Local Learning with Multilaminar Leap\n  Augmented Auxiliary Network","summary":"  End-to-end (E2E) training approaches are commonly plagued by high memory\nconsumption, reduced efficiency in training, challenges in model\nparallelization, and suboptimal biocompatibility. Local learning is considered\na novel interactive training method that holds promise as an alternative to\nE2E. Nonetheless, conventional local learning methods fall short in achieving\nhigh model accuracy due to inadequate local inter-module interactions. In this\npaper, we introduce a new model known as the Scaling Supervised Local Learning\nwith Multilaminar Leap Augmented Auxiliary Network (MLAAN). MLAAN features an\ninnovative supervised local learning approach coupled with a robust\nreinforcement module. This dual-component design enables the MLAAN to integrate\nsmoothly with established local learning techniques, thereby enhancing the\nefficacy of the foundational methods. The method simultaneously acquires the\nlocal and global features of the model separately by constructing an\nindependent auxiliary network and a cascade auxiliary network on the one hand\nand incorporates a leap augmented module, which serves to counteract the\nreduced learning capacity often associated with weaker supervision. This\narchitecture not only augments the exchange of information amongst the local\nmodules but also effectively mitigates the model's tendency toward myopia. The\nexperimental evaluations conducted on four benchmark datasets, CIFAR-10,\nSTL-10, SVHN, and ImageNet, demonstrate that the integration of MLAAN with\nexisting supervised local learning methods significantly enhances the original\nmethodologies. Of particular note, MLAAN enables local learning methods to\ncomprehensively outperform end-to-end training approaches in terms of optimal\nperformance while saving GPU memory.\n","authors":["Yuming Zhang","Shouxin Zhang","Peizhe Wang","Feiyu Zhu","Dongzhi Guan","Jiabin Liu","Changpeng Cai"],"pdf_url":"https://arxiv.org/pdf/2406.16633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16623v1","updated":"2024-06-24T13:13:31Z","published":"2024-06-24T13:13:31Z","title":"Articulate your NeRF: Unsupervised articulated object modeling via\n  conditional view synthesis","summary":"  We propose a novel unsupervised method to learn the pose and\npart-segmentation of articulated objects with rigid parts. Given two\nobservations of an object in different articulation states, our method learns\nthe geometry and appearance of object parts by using an implicit model from the\nfirst observation, distils the part segmentation and articulation from the\nsecond observation while rendering the latter observation. Additionally, to\ntackle the complexities in the joint optimization of part segmentation and\narticulation, we propose a voxel grid-based initialization strategy and a\ndecoupled optimization procedure. Compared to the prior unsupervised work, our\nmodel obtains significantly better performance, and generalizes to objects with\nmultiple parts while it can be efficiently from few views for the latter\nobservation.\n","authors":["Jianning Deng","Kartic Subr","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2406.16623v1.pdf","comment":"9 pages for the maincontent, excluding references and supplementaries"},{"id":"http://arxiv.org/abs/2406.16620v1","updated":"2024-06-24T13:05:39Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10212v2","updated":"2024-06-24T13:02:57Z","published":"2024-06-14T17:48:45Z","title":"NeST: Neural Stress Tensor Tomography by leveraging 3D Photoelasticity","summary":"  Photoelasticity enables full-field stress analysis in transparent objects\nthrough stress-induced birefringence. Existing techniques are limited to 2D\nslices and require destructively slicing the object. Recovering the internal 3D\nstress distribution of the entire object is challenging as it involves solving\na tensor tomography problem and handling phase wrapping ambiguities. We\nintroduce NeST, an analysis-by-synthesis approach for reconstructing 3D stress\ntensor fields as neural implicit representations from polarization\nmeasurements. Our key insight is to jointly handle phase unwrapping and tensor\ntomography using a differentiable forward model based on Jones calculus. Our\nnon-linear model faithfully matches real captures, unlike prior linear\napproximations. We develop an experimental multi-axis polariscope setup to\ncapture 3D photoelasticity and experimentally demonstrate that NeST\nreconstructs the internal stress distribution for objects with varying shape\nand force conditions. Additionally, we showcase novel applications in stress\nanalysis, such as visualizing photoelastic fringes by virtually slicing the\nobject and viewing photoelastic fringes from unseen viewpoints. NeST paves the\nway for scalable non-destructive 3D photoelastic analysis.\n","authors":["Akshat Dave","Tianyi Zhang","Aaron Young","Ramesh Raskar","Wolfgang Heidrich","Ashok Veeraraghavan"],"pdf_url":"https://arxiv.org/pdf/2406.10212v2.pdf","comment":"Project webpage: https://akshatdave.github.io/nest"},{"id":"http://arxiv.org/abs/2406.16615v1","updated":"2024-06-24T12:55:06Z","published":"2024-06-24T12:55:06Z","title":"The Championship-Winning Solution for the 5th CLVISION Challenge 2024","summary":"  In this paper, we introduce our approach to the 5th CLVision Challenge, which\npresents distinctive challenges beyond traditional class incremental learning.\nUnlike standard settings, this competition features the recurrence of\npreviously encountered classes and includes unlabeled data that may contain\nOut-of-Distribution (OOD) categories. Our approach is based on Winning\nSubnetworks to allocate independent parameter spaces for each task addressing\nthe catastrophic forgetting problem in class incremental learning and employ\nthree training strategies: supervised classification learning, unsupervised\ncontrastive learning, and pseudo-label classification learning to fully utilize\nthe information in both labeled and unlabeled data, enhancing the\nclassification performance of each subnetwork. Furthermore, during the\ninference stage, we have devised an interaction strategy between subnetworks,\nwhere the prediction for a specific class of a particular sample is the average\nlogits across different subnetworks corresponding to that class, leveraging the\nknowledge learned from different subnetworks on recurring classes to improve\nclassification accuracy. These strategies can be simultaneously applied to the\nthree scenarios of the competition, effectively solving the difficulties in the\ncompetition scenarios. Experimentally, our method ranks first in both the\npre-selection and final evaluation stages, with an average accuracy of 0.4535\nduring the preselection stage and an average accuracy of 0.4805 during the\nfinal evaluation stage.\n","authors":["Sishun Pan","Tingmin Li","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.16615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01188v4","updated":"2024-06-24T12:49:35Z","published":"2024-04-01T15:45:58Z","title":"MonoBox: Tightness-free Box-supervised Polyp Segmentation using\n  Monotonicity Constraint","summary":"  We propose MonoBox, an innovative box-supervised segmentation method\nconstrained by monotonicity to liberate its training from the user-unfriendly\nbox-tightness assumption. In contrast to conventional box-supervised\nsegmentation, where the box edges must precisely touch the target boundaries,\nMonoBox leverages imprecisely-annotated boxes to achieve robust pixel-wise\nsegmentation. The 'linchpin' is that, within the noisy zones around box edges,\nMonoBox discards the traditional misguiding multiple-instance learning loss,\nand instead optimizes a carefully-designed objective, termed monotonicity\nconstraint. Along directions transitioning from the foreground to background,\nthis new constraint steers responses to adhere to a trend of monotonically\ndecreasing values. Consequently, the originally unreliable learning within the\nnoisy zones is transformed into a correct and effective monotonicity\noptimization. Moreover, an adaptive label correction is introduced, enabling\nMonoBox to enhance the tightness of box annotations using predicted masks from\nthe previous epoch and dynamically shrink the noisy zones as training\nprogresses. We verify MonoBox in the box-supervised segmentation task of\npolyps, where satisfying box-tightness is challenging due to the vague\nboundaries between the polyp and normal tissues. Experiments on both public\nsynthetic and in-house real noisy datasets demonstrate that MonoBox exceeds\nother anti-noise state-of-the-arts by improving Dice by at least 5.5% and 3.3%,\nrespectively. Codes are at https://github.com/Huster-Hq/MonoBox.\n","authors":["Qiang Hu","Zhenyu Yi","Ying Zhou","Ting Li","Fan Huang","Mei Liu","Qiang Li","Zhiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2404.01188v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16608v1","updated":"2024-06-24T12:47:21Z","published":"2024-06-24T12:47:21Z","title":"When Invariant Representation Learning Meets Label Shift: Insufficiency\n  and Theoretical Insights","summary":"  As a crucial step toward real-world learning scenarios with changing\nenvironments, dataset shift theory and invariant representation learning\nalgorithm have been extensively studied to relax the identical distribution\nassumption in classical learning setting. Among the different assumptions on\nthe essential of shifting distributions, generalized label shift (GLS) is the\nlatest developed one which shows great potential to deal with the complex\nfactors within the shift. In this paper, we aim to explore the limitations of\ncurrent dataset shift theory and algorithm, and further provide new insights by\npresenting a comprehensive understanding of GLS. From theoretical aspect, two\ninformative generalization bounds are derived, and the GLS learner is proved to\nbe sufficiently close to optimal target model from the Bayesian perspective.\nThe main results show the insufficiency of invariant representation learning,\nand prove the sufficiency and necessity of GLS correction for generalization,\nwhich provide theoretical supports and innovations for exploring generalizable\nmodel under dataset shift. From methodological aspect, we provide a unified\nview of existing shift correction frameworks, and propose a kernel\nembedding-based correction algorithm (KECA) to minimize the generalization\nerror and achieve successful knowledge transfer. Both theoretical results and\nextensive experiment evaluations demonstrate the sufficiency and necessity of\nGLS correction for addressing dataset shift and the superiority of proposed\nalgorithm.\n","authors":["You-Wei Luo","Chuan-Xian Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16608v1.pdf","comment":"Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)"},{"id":"http://arxiv.org/abs/2406.16601v1","updated":"2024-06-24T12:41:51Z","published":"2024-06-24T12:41:51Z","title":"Do As I Do: Pose Guided Human Motion Copy","summary":"  Human motion copy is an intriguing yet challenging task in artificial\nintelligence and computer vision, which strives to generate a fake video of a\ntarget person performing the motion of a source person. The problem is\ninherently challenging due to the subtle human-body texture details to be\ngenerated and the temporal consistency to be considered. Existing approaches\ntypically adopt a conventional GAN with an L1 or L2 loss to produce the target\nfake video, which intrinsically necessitates a large number of training samples\nthat are challenging to acquire. Meanwhile, current methods still have\ndifficulties in attaining realistic image details and temporal consistency,\nwhich unfortunately can be easily perceived by human observers. Motivated by\nthis, we try to tackle the issues from three aspects: (1) We constrain\npose-to-appearance generation with a perceptual loss and a theoretically\nmotivated Gromov-Wasserstein loss to bridge the gap between pose and\nappearance. (2) We present an episodic memory module in the pose-to-appearance\ngeneration to propel continuous learning that helps the model learn from its\npast poor generations. We also utilize geometrical cues of the face to optimize\nfacial details and refine each key body part with a dedicated local GAN. (3) We\nadvocate generating the foreground in a sequence-to-sequence manner rather than\na single-frame manner, explicitly enforcing temporal inconsistency. Empirical\nresults on five datasets, iPER, ComplexMotion, SoloDance, Fish, and Mouse\ndatasets, demonstrate that our method is capable of generating realistic target\nvideos while precisely copying motion from a source video. Our method\nsignificantly outperforms state-of-the-art approaches and gains 7.2% and 12.4%\nimprovements in PSNR and FID respectively.\n","authors":["Sifan Wu","Zhenguang Liu","Beibei Zhang","Roger Zimmermann","Zhongjie Ba","Xiaosong Zhang","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16593v1","updated":"2024-06-24T12:33:56Z","published":"2024-06-24T12:33:56Z","title":"Measuring the Recyclability of Electronic Components to Assist Automatic\n  Disassembly and Sorting Waste Printed Circuit Boards","summary":"  The waste of electrical and electronic equipment has been increased due to\nthe fast evolution of technology products and competition of many IT sectors.\nEvery year millions of tons of electronic waste are thrown into the environment\nwhich causes high consequences for human health. Therefore, it is crucial to\ncontrol this waste flow using technology, especially using Artificial\nIntelligence but also reclamation of critical raw materials for new production\nprocesses. In this paper, we focused on the measurement of recyclability of\nwaste electronic components (WECs) from waste printed circuit boards (WPCBs)\nusing mathematical innovation model. This innovative approach evaluates both\nthe recyclability and recycling difficulties of WECs, integrating an AI model\nfor improved disassembly and sorting. Assessing the recyclability of individual\nelectronic components present on WPCBs provides insight into the recovery\npotential of valuable materials and indicates the level of complexity involved\nin recycling in terms of economic worth and production utility. This novel\nmeasurement approach helps AI models in accurately determining the number of\nclasses to be identified and sorted during the automated disassembly of\ndiscarded PCBs. It also facilitates the model in iterative training and\nvalidation of individual electronic components.\n","authors":["Muhammad Mohsin","Xianlai Zeng","Stefano Rovetta","Francesco Masulli"],"pdf_url":"https://arxiv.org/pdf/2406.16593v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.16592v1","updated":"2024-06-24T12:33:21Z","published":"2024-06-24T12:33:21Z","title":"Toward Fairer Face Recognition Datasets","summary":"  Face recognition and verification are two computer vision tasks whose\nperformance has progressed with the introduction of deep representations.\nHowever, ethical, legal, and technical challenges due to the sensitive\ncharacter of face data and biases in real training datasets hinder their\ndevelopment. Generative AI addresses privacy by creating fictitious identities,\nbut fairness problems persist. We promote fairness by introducing a demographic\nattributes balancing mechanism in generated training datasets. We experiment\nwith an existing real dataset, three generated training datasets, and the\nbalanced versions of a diffusion-based dataset. We propose a comprehensive\nevaluation that considers accuracy and fairness equally and includes a rigorous\nregression-based statistical analysis of attributes. The analysis shows that\nbalancing reduces demographic unfairness. Also, a performance gap persists\ndespite generation becoming more accurate with time. The proposed balancing\nmethod and comprehensive verification evaluation promote fairer and transparent\nface recognition and verification.\n","authors":["Alexandre Fournier-Mongieux","Michael Soumm","Adrian Popescu","Bertrand Luvison","Hervé Le Borgne"],"pdf_url":"https://arxiv.org/pdf/2406.16592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16583v1","updated":"2024-06-24T12:16:51Z","published":"2024-06-24T12:16:51Z","title":"Personalized federated learning based on feature fusion","summary":"  Federated learning enables distributed clients to collaborate on training\nwhile storing their data locally to protect client privacy. However, due to the\nheterogeneity of data, models, and devices, the final global model may need to\nperform better for tasks on each client. Communication bottlenecks, data\nheterogeneity, and model heterogeneity have been common challenges in federated\nlearning. In this work, we considered a label distribution skew problem, a type\nof data heterogeneity easily overlooked. In the context of classification, we\npropose a personalized federated learning approach called pFedPM. In our\nprocess, we replace traditional gradient uploading with feature uploading,\nwhich helps reduce communication costs and allows for heterogeneous client\nmodels. These feature representations play a role in preserving privacy to some\nextent.\n  We use a hyperparameter $a$ to mix local and global features, which enables\nus to control the degree of personalization. We also introduced a relation\nnetwork as an additional decision layer, which provides a non-linear learnable\nclassifier to predict labels. Experimental results show that, with an\nappropriate setting of $a$, our scheme outperforms several recent FL methods on\nMNIST, FEMNIST, and CRIFAR10 datasets and achieves fewer communications.\n","authors":["Wolong Xing","Zhenkui Shi","Hongyan Peng","Xiantao Hu","Xianxian Li"],"pdf_url":"https://arxiv.org/pdf/2406.16583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07189v2","updated":"2024-06-24T12:09:46Z","published":"2024-06-11T12:01:11Z","title":"RGB-Sonar Tracking Benchmark and Spatial Cross-Attention Transformer\n  Tracker","summary":"  Vision camera and sonar are naturally complementary in the underwater\nenvironment. Combining the information from two modalities will promote better\nobservation of underwater targets. However, this problem has not received\nsufficient attention in previous research. Therefore, this paper introduces a\nnew challenging RGB-Sonar (RGB-S) tracking task and investigates how to achieve\nefficient tracking of an underwater target through the interaction of RGB and\nsonar modalities. Specifically, we first propose an RGBS50 benchmark dataset\ncontaining 50 sequences and more than 87000 high-quality annotated bounding\nboxes. Experimental results show that the RGBS50 benchmark poses a challenge to\ncurrently popular SOT trackers. Second, we propose an RGB-S tracker called\nSCANet, which includes a spatial cross-attention module (SCAM) consisting of a\nnovel spatial cross-attention layer and two independent global integration\nmodules. The spatial cross-attention is used to overcome the problem of spatial\nmisalignment of between RGB and sonar images. Third, we propose a SOT\ndata-based RGB-S simulation training method (SRST) to overcome the lack of\nRGB-S training datasets. It converts RGB images into sonar-like saliency images\nto construct pseudo-data pairs, enabling the model to learn the semantic\nstructure of RGB-S-like data. Comprehensive experiments show that the proposed\nspatial cross-attention effectively achieves the interaction between RGB and\nsonar modalities and SCANet achieves state-of-the-art performance on the\nproposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/RGBS50.\n","authors":["Yunfeng Li","Bo Wang","Jiuran Sun","Xueyi Wu","Ye Li"],"pdf_url":"https://arxiv.org/pdf/2406.07189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02956v2","updated":"2024-06-24T12:07:52Z","published":"2024-02-05T12:34:03Z","title":"AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a\n  Single High-Resolution Image","summary":"  The process of estimating and counting tree density using only a single\naerial or satellite image is a difficult task in the fields of photogrammetry\nand remote sensing. However, it plays a crucial role in the management of\nforests. The huge variety of trees in varied topography severely hinders tree\ncounting models to perform well. The purpose of this paper is to propose a\nframework that is learnt from the source domain with sufficient labeled trees\nand is adapted to the target domain with only a limited number of labeled\ntrees. Our method, termed as AdaTreeFormer, contains one shared encoder with a\nhierarchical feature extraction scheme to extract robust features from the\nsource and target domains. It also consists of three subnets: two for\nextracting self-domain attention maps from source and target domains\nrespectively and one for extracting cross-domain attention maps. For the\nlatter, an attention-to-adapt mechanism is introduced to distill relevant\ninformation from different domains while generating tree density maps; a\nhierarchical cross-domain feature alignment scheme is proposed that\nprogressively aligns the features from the source and target domains. We also\nadopt adversarial learning into the framework to further reduce the gap between\nsource and target domains. Our AdaTreeFormer is evaluated on six designed\ndomain adaptation tasks using three tree counting datasets, \\ie Jiangsu,\nYosemite, and London. Experimental results show that AdaTreeFormer\nsignificantly surpasses the state of the art, \\eg in the cross domain from the\nYosemite to Jiangsu dataset, it achieves a reduction of 15.9 points in terms of\nthe absolute counting errors and an increase of 10.8\\% in the accuracy of the\ndetected trees' locations. The codes and datasets are available at\n\\emph{\\color{magenta}{https://github.com/HAAClassic/AdaTreeFormer}}.\n","authors":["Hamed Amini Amirkolaee","Miaojing Shi","Lianghua He","Mark Mulligan"],"pdf_url":"https://arxiv.org/pdf/2402.02956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00933v4","updated":"2024-06-24T12:03:00Z","published":"2023-04-03T12:45:52Z","title":"Knowledge Accumulation in Continually Learned Representations and the\n  Issue of Feature Forgetting","summary":"  Continual learning research has shown that neural networks suffer from\ncatastrophic forgetting \"at the output level\", but it is debated whether this\nis also the case at the level of learned representations. Multiple recent\nstudies ascribe representations a certain level of innate robustness against\nforgetting -- that they only forget minimally in comparison with forgetting at\nthe output level. We revisit and expand upon the experiments that revealed this\ndifference in forgetting and illustrate the coexistence of two phenomena that\naffect the quality of continually learned representations: knowledge\naccumulation and feature forgetting. Taking both aspects into account, we show\nthat, even though forgetting in the representation (i.e. feature forgetting)\ncan be small in absolute terms, when measuring relative to how much was learned\nduring a task, forgetting in the representation tends to be just as\ncatastrophic as forgetting at the output level. Next we show that this feature\nforgetting is problematic as it substantially slows down the incremental\nlearning of good general representations (i.e. knowledge accumulation).\nFinally, we study how feature forgetting and knowledge accumulation are\naffected by different types of continual learning methods.\n","authors":["Timm Hess","Eli Verwimp","Gido M. van de Ven","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2304.00933v4.pdf","comment":"TMLR 2024"},{"id":"http://arxiv.org/abs/2406.16564v1","updated":"2024-06-24T12:01:55Z","published":"2024-06-24T12:01:55Z","title":"FASTC: A Fast Attentional Framework for Semantic Traversability\n  Classification Using Point Cloud","summary":"  Producing traversability maps and understanding the surroundings are crucial\nprerequisites for autonomous navigation. In this paper, we address the problem\nof traversability assessment using point clouds. We propose a novel pillar\nfeature extraction module that utilizes PointNet to capture features from point\nclouds organized in vertical volume and a 2D encoder-decoder structure to\nconduct traversability classification instead of the widely used 3D\nconvolutions. This results in less computational cost while even better\nperformance is achieved at the same time. We then propose a new spatio-temporal\nattention module to fuse multi-frame information, which can properly handle the\nvarying density problem of LIDAR point clouds, and this makes our module able\nto assess distant areas more accurately. Comprehensive experimental results on\naugmented Semantic KITTI and RELLIS-3D datasets show that our method is able to\nachieve superior performance over existing approaches both quantitatively and\nquantitatively.\n","authors":["Yirui Chen","Pengjin Wei","Zhenhuan Liu","Bingchao Wang","Jie Yang","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16564v1.pdf","comment":"Accepted to ECAI2023 Our code is publicly available at\n  [this](https://github.com/chenyirui/FASTC)"},{"id":"http://arxiv.org/abs/2308.04702v2","updated":"2024-06-24T12:01:20Z","published":"2023-08-09T04:46:16Z","title":"Continual Road-Scene Semantic Segmentation via Feature-Aligned Symmetric\n  Multi-Modal Network","summary":"  State-of-the-art multimodal semantic segmentation strategies combining LiDAR\nand color data are usually designed on top of asymmetric information-sharing\nschemes and assume that both modalities are always available. This strong\nassumption may not hold in real-world scenarios, where sensors are prone to\nfailure or can face adverse conditions that make the acquired information\nunreliable. This problem is exacerbated when continual learning scenarios are\nconsidered since they have stringent data reliability constraints. In this\nwork, we re-frame the task of multimodal semantic segmentation by enforcing a\ntightly coupled feature representation and a symmetric information-sharing\nscheme, which allows our approach to work even when one of the input modalities\nis missing. We also introduce an ad-hoc class-incremental continual learning\nscheme, proving our approach's effectiveness and reliability even in\nsafety-critical settings, such as autonomous driving. We evaluate our approach\non the SemanticKITTI dataset, achieving impressive performances.\n","authors":["Francesco Barbato","Elena Camuffo","Simone Milani","Pietro Zanuttigh"],"pdf_url":"https://arxiv.org/pdf/2308.04702v2.pdf","comment":"Accepted ad ICIP 2024, 6 pages, 5 figures, 3 tables, 7 equations"},{"id":"http://arxiv.org/abs/2406.16562v1","updated":"2024-06-24T11:56:15Z","published":"2024-06-24T11:56:15Z","title":"EvalAlign: Evaluating Text-to-Image Models through Precision Alignment\n  of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations","summary":"  The recent advancements in text-to-image generative models have been\nremarkable. Yet, the field suffers from a lack of evaluation metrics that\naccurately reflect the performance of these models, particularly lacking\nfine-grained metrics that can guide the optimization of the models. In this\npaper, we propose EvalAlign, a metric characterized by its accuracy, stability,\nand fine granularity. Our approach leverages the capabilities of Multimodal\nLarge Language Models (MLLMs) pre-trained on extensive datasets. We develop\nevaluation protocols that focus on two key dimensions: image faithfulness and\ntext-image alignment. Each protocol comprises a set of detailed, fine-grained\ninstructions linked to specific scoring options, enabling precise manual\nscoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to\nalign closely with human evaluative judgments, resulting in a robust evaluation\nmodel. Our comprehensive tests across 24 text-to-image generation models\ndemonstrate that EvalAlign not only provides superior metric stability but also\naligns more closely with human preferences than existing metrics, confirming\nits effectiveness and utility in model assessment.\n","authors":["Zhiyu Tan","Xiaomeng Yang","Luozheng Qin","Mengping Yang","Cheng Zhang","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2406.16562v1.pdf","comment":"Github Repository: https://github.com/SAIS-FUXI/EvalAlign"},{"id":"http://arxiv.org/abs/2406.16544v1","updated":"2024-06-24T11:29:52Z","published":"2024-06-24T11:29:52Z","title":"Hierarchical B-frame Video Coding for Long Group of Pictures","summary":"  Learned video compression methods already outperform VVC in the low-delay\n(LD) case, but the random-access (RA) scenario remains challenging. Most works\non learned RA video compression either use HEVC as an anchor or compare it to\nVVC in specific test conditions, using RGB-PSNR metric instead of Y-PSNR and\navoiding comprehensive evaluation. Here, we present an end-to-end learned video\ncodec for random access that combines training on long sequences of frames,\nrate allocation designed for hierarchical coding and content adaptation on\ninference. We show that under common test conditions (JVET-CTC), it achieves\nresults comparable to VTM (VVC reference software) in terms of YUV-PSNR BD-Rate\non some classes of videos, and outperforms it on almost all test sets in terms\nof VMAF BD-Rate. On average it surpasses open LD and RA end-to-end solutions in\nterms of VMAF and YUV BD-Rates.\n","authors":["Ivan Kirillov","Denis Parkhomenko","Kirill Chernyshev","Alexander Pletnev","Yibo Shi","Kai Lin","Dmitry Babin"],"pdf_url":"https://arxiv.org/pdf/2406.16544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16540v1","updated":"2024-06-24T11:20:44Z","published":"2024-06-24T11:20:44Z","title":"Improving robustness to corruptions with multiplicative weight\n  perturbations","summary":"  Deep neural networks (DNNs) excel on clean images but struggle with corrupted\nones. Incorporating specific corruptions into the data augmentation pipeline\ncan improve robustness to those corruptions but may harm performance on clean\nimages and other types of distortion. In this paper, we introduce an\nalternative approach that improves the robustness of DNNs to a wide range of\ncorruptions without compromising accuracy on clean images. We first demonstrate\nthat input perturbations can be mimicked by multiplicative perturbations in the\nweight space. Leveraging this, we propose Data Augmentation via Multiplicative\nPerturbation (DAMP), a training method that optimizes DNNs under random\nmultiplicative weight perturbations. We also examine the recently proposed\nAdaptive Sharpness-Aware Minimization (ASAM) and show that it optimizes DNNs\nunder adversarial multiplicative weight perturbations. Experiments on image\nclassification datasets (CIFAR-10/100, TinyImageNet and ImageNet) and neural\nnetwork architectures (ResNet50, ViT-S/16) show that DAMP enhances model\ngeneralization performance in the presence of corruptions across different\nsettings. Notably, DAMP is able to train a ViT-S/16 on ImageNet from scratch,\nreaching the top-1 error of 23.7% which is comparable to ResNet50 without\nextensive data augmentations.\n","authors":["Trung Trinh","Markus Heinonen","Luigi Acerbi","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2406.16540v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16537v1","updated":"2024-06-24T11:16:37Z","published":"2024-06-24T11:16:37Z","title":"Character-Adapter: Prompt-Guided Region Control for High-Fidelity\n  Character Customization","summary":"  Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods\n","authors":["Yuhang Ma","Wenting Xu","Jiji Tang","Qinfeng Jin","Rongsheng Zhang","Zeng Zhao","Changjie Fan","Zhipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2406.16537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16531v1","updated":"2024-06-24T11:10:41Z","published":"2024-06-24T11:10:41Z","title":"GIM: A Million-scale Benchmark for Generative Image Manipulation\n  Detection and Localization","summary":"  The extraordinary ability of generative models emerges as a new trend in\nimage editing and generating realistic images, posing a serious threat to the\ntrustworthiness of multimedia data and driving the research of image\nmanipulation detection and location(IMDL). However, the lack of a large-scale\ndata foundation makes IMDL task unattainable. In this paper, a local\nmanipulation pipeline is designed, incorporating the powerful SAM, ChatGPT and\ngenerative models. Upon this basis, We propose the GIM dataset, which has the\nfollowing advantages: 1) Large scale, including over one million pairs of\nAI-manipulated images and real images. 2) Rich Image Content, encompassing a\nbroad range of image classes 3) Diverse Generative Manipulation, manipulated\nimages with state-of-the-art generators and various manipulation tasks. The\naforementioned advantages allow for a more comprehensive evaluation of IMDL\nmethods, extending their applicability to diverse images. We introduce two\nbenchmark settings to evaluate the generalization capability and comprehensive\nperformance of baseline methods. In addition, we propose a novel IMDL\nframework, termed GIMFormer, which consists of a ShadowTracer,\nFrequency-Spatial Block (FSB), and a Multi-window Anomalous Modelling (MWAM)\nModule. Extensive experiments on the GIM demonstrate that GIMFormer surpasses\nprevious state-of-the-art works significantly on two different benchmarks.\n","authors":["Yirui Chen","Xudong Huang","Quan Zhang","Wei Li","Mingjian Zhu","Qiangyu Yan","Simiao Li","Hanting Chen","Hailin Hu","Jie Yang","Wei Liu","Jie Hu"],"pdf_url":"https://arxiv.org/pdf/2406.16531v1.pdf","comment":"Code page: https://github.com/chenyirui/GIM"},{"id":"http://arxiv.org/abs/2406.01467v2","updated":"2024-06-24T11:04:08Z","published":"2024-06-03T15:56:58Z","title":"RaDe-GS: Rasterizing Depth in Gaussian Splatting","summary":"  Gaussian Splatting (GS) has proven to be highly effective in novel view\nsynthesis, achieving high-quality and real-time rendering. However, its\npotential for reconstructing detailed 3D shapes has not been fully explored.\nExisting methods often suffer from limited shape accuracy due to the discrete\nand unstructured nature of Gaussian splats, which complicates the shape\nextraction. While recent techniques like 2D GS have attempted to improve shape\nreconstruction, they often reformulate the Gaussian primitives in ways that\nreduce both rendering quality and computational efficiency. To address these\nproblems, our work introduces a rasterized approach to render the depth maps\nand surface normal maps of general 3D Gaussian splats. Our method not only\nsignificantly enhances shape reconstruction accuracy but also maintains the\ncomputational efficiency intrinsic to Gaussian Splatting. It achieves a Chamfer\ndistance error comparable to NeuraLangelo on the DTU dataset and maintains\nsimilar computational efficiency as the original 3D GS methods. Our method is a\nsignificant advancement in Gaussian Splatting and can be directly integrated\ninto existing Gaussian Splatting-based methods.\n","authors":["Baowen Zhang","Chuan Fang","Rakesh Shrestha","Yixun Liang","Xiaoxiao Long","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2406.01467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16518v1","updated":"2024-06-24T10:47:45Z","published":"2024-06-24T10:47:45Z","title":"Vision Mamba-based autonomous crack segmentation on concrete, asphalt,\n  and masonry surfaces","summary":"  Convolutional neural networks (CNNs) and Transformers have shown advanced\naccuracy in crack detection under certain conditions. Yet, the fixed local\nattention can compromise the generalisation of CNNs, and the quadratic\ncomplexity of the global self-attention restricts the practical deployment of\nTransformers. Given the emergence of the new-generation architecture of Mamba,\nthis paper proposes a Vision Mamba (VMamba)-based framework for crack\nsegmentation on concrete, asphalt, and masonry surfaces, with high accuracy,\ngeneralisation, and less computational complexity. Having 15.6% - 74.5% fewer\nparameters, the encoder-decoder network integrated with VMamba could obtain up\nto 2.8% higher mDS than representative CNN-based models while showing about the\nsame performance as Transformer-based models. Moreover, the VMamba-based\nencoder-decoder network could process high-resolution image input with up to\n90.6% lower floating-point operations.\n","authors":["Zhaohui Chen","Elyas Asadi Shamsabadi","Sheng Jiang","Luming Shen","Daniel Dias-da-Costa"],"pdf_url":"https://arxiv.org/pdf/2406.16518v1.pdf","comment":"23 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.16513v1","updated":"2024-06-24T10:40:46Z","published":"2024-06-24T10:40:46Z","title":"Multi-Modal Vision Transformers for Crop Mapping from Satellite Image\n  Time Series","summary":"  Using images acquired by different satellite sensors has shown to improve\nclassification performance in the framework of crop mapping from satellite\nimage time series (SITS). Existing state-of-the-art architectures use\nself-attention mechanisms to process the temporal dimension and convolutions\nfor the spatial dimension of SITS. Motivated by the success of purely\nattention-based architectures in crop mapping from single-modal SITS, we\nintroduce several multi-modal multi-temporal transformer-based architectures.\nSpecifically, we investigate the effectiveness of Early Fusion, Cross Attention\nFusion and Synchronized Class Token Fusion within the Temporo-Spatial Vision\nTransformer (TSViT). Experimental results demonstrate significant improvements\nover state-of-the-art architectures with both convolutional and self-attention\ncomponents.\n","authors":["Theresa Follath","David Mickisch","Jan Hemmerling","Stefan Erasmi","Marcel Schwieder","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2406.16513v1.pdf","comment":"5 pages, 2 figures, 1 table. Accepted at IEEE International\n  Geoscience and Remote Sensing Symposium (IGARSS) 2024. Our code is available\n  at https://git.tu-berlin.de/rsim/mmtsvit"},{"id":"http://arxiv.org/abs/2402.08506v3","updated":"2024-06-24T10:24:14Z","published":"2024-02-13T15:02:46Z","title":"P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient\n  Pediatric Echocardiographic Left Ventricular Segmentation","summary":"  In pediatric cardiology, the accurate and immediate assessment of cardiac\nfunction through echocardiography is crucial since it can determine whether\nurgent intervention is required in many emergencies. However, echocardiography\nis characterized by ambiguity and heavy background noise interference, causing\nmore difficulty in accurate segmentation. Present methods lack efficiency and\nare prone to mistakenly segmenting some background noise areas, such as the\nleft ventricular area, due to noise disturbance. To address these issues, we\nintroduce P-Mamba, which integrates the Mixture of Experts (MoE) concept for\nefficient pediatric echocardiographic left ventricular segmentation.\nSpecifically, we utilize the recently proposed ViM layers from the vision mamba\nto enhance our model's computational and memory efficiency while modeling\nglobal dependencies.In the DWT-based Perona-Malik Diffusion (PMD) Block, we\ndevise a PMD Block for noise suppression while preserving the left ventricle's\nlocal shape cues. Consequently, our proposed P-Mamba innovatively combines the\nPMD's noise suppression and local feature extraction capabilities with Mamba's\nefficient design for global dependency modeling. We conducted segmentation\nexperiments on two pediatric ultrasound datasets and a general ultrasound\ndataset, namely Echonet-dynamic, and achieved state-of-the-art (SOTA) results.\nLeveraging the strengths of the P-Mamba block, our model demonstrates superior\naccuracy and efficiency compared to established models, including vision\ntransformers with quadratic and linear computational complexity.\n","authors":["Zi Ye","Tianxiang Chen","Fangyijie Wang","Hanwei Zhang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.08506v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16538v2","updated":"2024-06-24T10:21:17Z","published":"2024-04-25T11:53:36Z","title":"OpenDlign: Enhancing Open-World 3D Learning with Depth-Aligned Images","summary":"  Recent open-world 3D representation learning methods using Vision-Language\nModels (VLMs) to align 3D data with image-text information have shown superior\n3D zero-shot performance. However, CAD-rendered images for this alignment often\nlack realism and texture variation, compromising alignment robustness.\nMoreover, the volume discrepancy between 3D and 2D pretraining datasets\nhighlights the need for effective strategies to transfer the representational\nabilities of VLMs to 3D learning. In this paper, we present OpenDlign, a novel\nopen-world 3D model using depth-aligned images generated from a diffusion model\nfor robust multimodal alignment. These images exhibit greater texture diversity\nthan CAD renderings due to the stochastic nature of the diffusion model. By\nrefining the depth map projection pipeline and designing depth-specific\nprompts, OpenDlign leverages rich knowledge in pre-trained VLM for 3D\nrepresentation learning with streamlined fine-tuning. Our experiments show that\nOpenDlign achieves high zero-shot and few-shot performance on diverse 3D tasks,\ndespite only fine-tuning 6 million parameters on a limited ShapeNet dataset. In\nzero-shot classification, OpenDlign surpasses previous models by 8.0% on\nModelNet40 and 16.4% on OmniObject3D. Additionally, using depth-aligned images\nfor multimodal alignment consistently enhances the performance of other\nstate-of-the-art models.\n","authors":["Ye Mao","Junpeng Jing","Krystian Mikolajczyk"],"pdf_url":"https://arxiv.org/pdf/2404.16538v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2406.16502v1","updated":"2024-06-24T10:12:03Z","published":"2024-06-24T10:12:03Z","title":"LOGCAN++: Local-global class-aware network for semantic segmentation of\n  remote sensing images","summary":"  Remote sensing images usually characterized by complex backgrounds, scale and\norientation variations, and large intra-class variance. General semantic\nsegmentation methods usually fail to fully investigate the above issues, and\nthus their performances on remote sensing image segmentation are limited. In\nthis paper, we propose our LOGCAN++, a semantic segmentation model customized\nfor remote sensing images, which is made up of a Global Class Awareness (GCA)\nmodule and several Local Class Awareness (LCA) modules. The GCA module captures\nglobal representations for class-level context modeling to reduce the\ninterference of background noise. The LCA module generates local class\nrepresentations as intermediate perceptual elements to indirectly associate\npixels with the global class representations, targeting at dealing with the\nlarge intra-class variance problem. In particular, we introduce affine\ntransformations in the LCA module for adaptive extraction of local class\nrepresentations to effectively tolerate scale and orientation variations in\nremotely sensed images. Extensive experiments on three benchmark datasets show\nthat our LOGCAN++ outperforms current mainstream general and remote sensing\nsemantic segmentation methods and achieves a better trade-off between speed and\naccuracy. Code is available at https://github.com/xwmaxwma/rssegmentation.\n","authors":["Xiaowen Ma","Rongrong Lian","Zhenkai Wu","Hongbo Guo","Mengting Ma","Sensen Wu","Zhenhong Du","Siyang Song","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16502v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.16501v1","updated":"2024-06-24T10:10:03Z","published":"2024-06-24T10:10:03Z","title":"UNICAD: A Unified Approach for Attack Detection, Noise Reduction and\n  Novel Class Identification","summary":"  As the use of Deep Neural Networks (DNNs) becomes pervasive, their\nvulnerability to adversarial attacks and limitations in handling unseen classes\nposes significant challenges. The state-of-the-art offers discrete solutions\naimed to tackle individual issues covering specific adversarial attack\nscenarios, classification or evolving learning. However, real-world systems\nneed to be able to detect and recover from a wide range of adversarial attacks\nwithout sacrificing classification accuracy and to flexibly act in {\\bf unseen}\nscenarios. In this paper, UNICAD, is proposed as a novel framework that\nintegrates a variety of techniques to provide an adaptive solution.\n  For the targeted image classification, UNICAD achieves accurate image\nclassification, detects unseen classes, and recovers from adversarial attacks\nusing Prototype and Similarity-based DNNs with denoising autoencoders. Our\nexperiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness\nin adversarial mitigation and unseen class classification, outperforming\ntraditional models.\n","authors":["Alvaro Lopez Pellicer","Kittipos Giatgong","Yi Li","Neeraj Suri","Plamen Angelov"],"pdf_url":"https://arxiv.org/pdf/2406.16501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16481v1","updated":"2024-06-24T09:36:58Z","published":"2024-06-24T09:36:58Z","title":"Improving Quaternion Neural Networks with Quaternionic Activation\n  Functions","summary":"  In this paper, we propose novel quaternion activation functions where we\nmodify either the quaternion magnitude or the phase, as an alternative to the\ncommonly used split activation functions. We define criteria that are relevant\nfor quaternion activation functions, and subsequently we propose our novel\nactivation functions based on this analysis. Instead of applying a known\nactivation function like the ReLU or Tanh on the quaternion elements\nseparately, these activation functions consider the quaternion properties and\nrespect the quaternion space $\\mathbb{H}$. In particular, all quaternion\ncomponents are utilized to calculate all output components, carrying out the\nbenefit of the Hamilton product in e.g. the quaternion convolution to the\nactivation functions. The proposed activation functions can be incorporated in\narbitrary quaternion valued neural networks trained with gradient descent\ntechniques. We further discuss the derivatives of the proposed activation\nfunctions where we observe beneficial properties for the activation functions\naffecting the phase. Specifically, they prove to be sensitive on basically the\nwhole input range, thus improved gradient flow can be expected. We provide an\nelaborate experimental evaluation of our proposed quaternion activation\nfunctions including comparison with the split ReLU and split Tanh on two image\nclassification tasks using the CIFAR-10 and SVHN dataset. There, especially the\nquaternion activation functions affecting the phase consistently prove to\nprovide better performance.\n","authors":["Johannes Pöppelbaum","Andreas Schwung"],"pdf_url":"https://arxiv.org/pdf/2406.16481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03066v2","updated":"2024-06-24T09:35:41Z","published":"2023-06-05T17:43:50Z","title":"Of Mice and Mates: Automated Classification and Modelling of Mouse\n  Behaviour in Groups using a Single Model across Cages","summary":"  Behavioural experiments often happen in specialised arenas, but this may\nconfound the analysis. To address this issue, we provide tools to study mice in\nthe home-cage environment, equipping biologists with the possibility to capture\nthe temporal aspect of the individual's behaviour and model the interaction and\ninterdependence between cage-mates with minimal human intervention. Our main\ncontribution is the novel Group Behaviour Model (GBM) which summarises the\njoint behaviour of groups of mice across cages, using a permutation matrix to\nmatch the mouse identities in each cage to the model. In support of the above,\nwe also (a) developed the Activity Labelling Module (ALM) to automatically\nclassify mouse behaviour from video, and (b) released two datasets, ABODe for\ntraining behaviour classifiers and IMADGE for modelling behaviour.\n","authors":["Michael P. J. Camilleri","Rasneer S. Bains","Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2306.03066v2.pdf","comment":"International Journal of Computer Vision (2024)"},{"id":"http://arxiv.org/abs/2406.16477v1","updated":"2024-06-24T09:30:36Z","published":"2024-06-24T09:30:36Z","title":"DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World\n  Image Super-Resolution","summary":"  Image super-resolution pursuits reconstructing high-fidelity high-resolution\ncounterpart for low-resolution image. In recent years, diffusion-based models\nhave garnered significant attention due to their capabilities with rich prior\nknowledge. The success of diffusion models based on general text prompts has\nvalidated the effectiveness of textual control in the field of text2image.\nHowever, given the severe degradation commonly presented in low-resolution\nimages, coupled with the randomness characteristics of diffusion models,\ncurrent models struggle to adequately discern semantic and degradation\ninformation within severely degraded images. This often leads to obstacles such\nas semantic loss, visual artifacts, and visual hallucinations, which pose\nsubstantial challenges for practical use. To address these challenges, this\npaper proposes to leverage degradation-aligned language prompt for accurate,\nfine-grained, and high-fidelity image restoration. Complementary priors\nincluding semantic content descriptions and degradation prompts are explored.\nSpecifically, on one hand, image-restoration prompt alignment decoder is\nproposed to automatically discern the degradation degree of LR images, thereby\ngenerating beneficial degradation priors for image restoration. On the other\nhand, much richly tailored descriptions from pretrained multimodal large\nlanguage model elicit high-level semantic priors closely aligned with human\nperception, ensuring fidelity control for image restoration. Comprehensive\ncomparisons with state-of-the-art methods have been done on several popular\nsynthetic and real-world benchmark datasets. The quantitative and qualitative\nanalysis have demonstrated that the proposed method achieves a new\nstate-of-the-art perceptual quality level, especially in real-world cases based\non reference-free metrics.\n","authors":["Aiwen Jiang","Zhi Wei","Long Peng","Feiqiang Liu","Wenbo Li","Mingwen Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16476v1","updated":"2024-06-24T09:28:21Z","published":"2024-06-24T09:28:21Z","title":"ResMaster: Mastering High-Resolution Image Generation via Structural and\n  Fine-Grained Guidance","summary":"  Diffusion models excel at producing high-quality images; however, scaling to\nhigher resolutions, such as 4K, often results in over-smoothed content,\nstructural distortions, and repetitive patterns. To this end, we introduce\nResMaster, a novel, training-free method that empowers resolution-limited\ndiffusion models to generate high-quality images beyond resolution\nrestrictions. Specifically, ResMaster leverages a low-resolution reference\nimage created by a pre-trained diffusion model to provide structural and\nfine-grained guidance for crafting high-resolution images on a patch-by-patch\nbasis. To ensure a coherent global structure, ResMaster meticulously aligns the\nlow-frequency components of high-resolution patches with the low-resolution\nreference at each denoising step. For fine-grained guidance, tailored image\nprompts based on the low-resolution reference and enriched textual prompts\nproduced by a vision-language model are incorporated. This approach could\nsignificantly mitigate local pattern distortions and improve detail refinement.\nExtensive experiments validate that ResMaster sets a new benchmark for\nhigh-resolution image generation and demonstrates promising efficiency. The\nproject page is https://shuweis.github.io/ResMaster .\n","authors":["Shuwei Shi","Wenbo Li","Yuechen Zhang","Jingwen He","Biao Gong","Yinqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.16476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16473v1","updated":"2024-06-24T09:25:02Z","published":"2024-06-24T09:25:02Z","title":"Seeking Certainty In Uncertainty: Dual-Stage Unified Framework Solving\n  Uncertainty in Dynamic Facial Expression Recognition","summary":"  The contemporary state-of-the-art of Dynamic Facial Expression Recognition\n(DFER) technology facilitates remarkable progress by deriving emotional\nmappings of facial expressions from video content, underpinned by training on\nvoluminous datasets. Yet, the DFER datasets encompass a substantial volume of\nnoise data. Noise arises from low-quality captures that defy logical labeling,\nand instances that suffer from mislabeling due to annotation bias, engendering\ntwo principal types of uncertainty: the uncertainty regarding data usability\nand the uncertainty concerning label reliability. Addressing the two types of\nuncertainty, we have meticulously crafted a two-stage framework aiming at\n\\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain\ndata (SCIU). This initiative aims to purge the DFER datasets of these\nuncertainties, thereby ensuring that only clean, verified data is employed in\ntraining processes. To mitigate the issue of low-quality samples, we introduce\nthe Coarse-Grained Pruning (CGP) stage, which assesses sample weights and\nprunes those deemed unusable due to their low weight. For samples with\nincorrect annotations, the Fine-Grained Correction (FGC) stage evaluates\nprediction stability to rectify mislabeled data. Moreover, SCIU is conceived as\na universally compatible, plug-and-play framework, tailored to integrate\nseamlessly with prevailing DFER methodologies. Rigorous experiments across\nprevalent DFER datasets and against numerous benchmark methods substantiates\nSCIU's capacity to markedly elevate performance metrics.\n","authors":["Haoran Wang","Xinji Mai","Zeng Tao","Xuan Tong","Junxiong Lin","Yan Wang","Jiawen Yu","Boyang Wang","Shaoqi Yan","Qing Zhao","Ziheng Zhou","Shuyong Gao","Wenqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16469v1","updated":"2024-06-24T09:18:15Z","published":"2024-06-24T09:18:15Z","title":"Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark\n  with Human-VLM Collaboration","summary":"  To create culturally inclusive vision-language models (VLMs), the foremost\nrequirement is developing a test benchmark that can diagnose the models'\nability to respond to questions reflecting cultural elements. This paper\naddresses the necessity for such benchmarks, noting that existing research has\nrelied on human annotators' manual efforts, which impedes diversity and\nefficiency. We propose a semi-automated pipeline for constructing cultural VLM\nbenchmarks to enhance diversity and efficiency. This pipeline leverages\nhuman-VLM collaboration, where VLMs generate questions based on guidelines,\nhuman-annotated examples, and image-wise relevant knowledge, which are then\nreviewed by native speakers for quality and cultural relevance. The\neffectiveness of our adaptable pipeline is demonstrated through a specific\napplication: creating a dataset tailored to Korean culture, dubbed K-Viscuit.\nThe resulting benchmark features two types of questions: Type 1 questions\nmeasure visual recognition abilities, while Type 2 assess fine-grained visual\nreasoning skills. This ensures a thorough diagnosis of VLM models across\nvarious aspects. Our evaluation using K-Viscuit revealed that open-source\nmodels notably lag behind proprietary models in understanding Korean culture,\nhighlighting areas for improvement. We provided diverse analyses of VLM\nperformance across different cultural aspects. Besides, we explored the\npotential of incorporating external knowledge retrieval to enhance the\ngeneration process, suggesting future directions for improving cultural\ninterpretation ability of VLMs. Our dataset and code will be made publicly\navailable.\n","authors":["Yujin Baek","ChaeHun Park","Jaeseok Kim","Yu-Jung Heo","Du-Seong Chang","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2406.16469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16466v1","updated":"2024-06-24T09:16:17Z","published":"2024-06-24T09:16:17Z","title":"SLOctolyzer: Fully automatic analysis toolkit for segmentation and\n  feature extracting in scanning laser ophthalmoscopy images","summary":"  Purpose: To describe SLOctolyzer: an open-source analysis toolkit for en face\nretinal vessels appearing in infrared reflectance scanning laser ophthalmoscopy\n(SLO) images.\n  Methods: SLOctolyzer includes two main modules: segmentation and measurement.\nThe segmentation module use deep learning methods to delineate retinal anatomy,\nwhile the measurement module quantifies key retinal vascular features such as\nvessel complexity, density, tortuosity, and calibre. We evaluate the\nsegmentation module using unseen data and measure its reproducibility.\n  Results: SLOctolyzer's segmentation module performed well against unseen\ninternal test data (Dice for all-vessels, 0.9097; arteries, 0.8376; veins,\n0.8525; optic disc, 0.9430; fovea, 0.8837). External validation against severe\nretinal pathology showed decreased performance (Dice for arteries, 0.7180;\nveins, 0.7470; optic disc, 0.9032). SLOctolyzer had good reproducibility (mean\ndifference for fractal dimension, -0.0007; vessel density, -0.0003; vessel\ncalibre, -0.3154 $\\mu$m; tortuosity density, 0.0013). SLOctolyzer can process a\nmacula-centred SLO image in under 20 seconds and a disc-centred SLO image in\nunder 30 seconds using a standard laptop CPU.\n  Conclusions: To our knowledge, SLOctolyzer is the first open-source tool to\nconvert raw SLO images into reproducible and clinically meaningful retinal\nvascular parameters. SLO images are captured simultaneous to optical coherence\ntomography (OCT), and we believe our software will be useful for extracting\nretinal vascular measurements from large OCT image sets and linking them to\nocular or systemic diseases. It requires no specialist knowledge or proprietary\nsoftware, and allows manual correction of segmentations and re-computing of\nvascular metrics. SLOctolyzer is freely available at\nhttps://github.com/jaburke166/SLOctolyzer.\n","authors":["Jamie Burke","Samuel Gibbon","Justin Engelmann","Adam Threlfall","Ylenia Giarratano","Charlene Hamid","Stuart King","Ian J. C. MacCormick","Tom MacGillivray"],"pdf_url":"https://arxiv.org/pdf/2406.16466v1.pdf","comment":"10 pages, 5 figures, 6 tables + Supplementary (7 pages, 10 figures, 4\n  tables). Submitted for peer review at Translational Vision Science and\n  Technology"},{"id":"http://arxiv.org/abs/2406.16464v1","updated":"2024-06-24T09:13:42Z","published":"2024-06-24T09:13:42Z","title":"InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for\n  Multi-modal Sarcasm Detection","summary":"  The prevalence of sarcasm in social media, conveyed through text-image\ncombinations, presents significant challenges for sentiment analysis and\nintention mining. Current multi-modal sarcasm detection methods have been\nproven to struggle with biases from spurious cues, leading to a superficial\nunderstanding of the complex interactions between text and image. To address\nthese issues, we propose InterCLIP-MEP, a robust framework for multi-modal\nsarcasm detection. InterCLIP-MEP introduces a refined variant of CLIP,\nInteractive CLIP (InterCLIP), as the backbone, enhancing sample representations\nby embedding cross-modality information in each encoder. Furthermore, a novel\ntraining strategy is designed to adapt InterCLIP for a Memory-Enhanced\nPredictor (MEP). MEP uses dynamic dual-channel memory to store valuable\nhistorical knowledge of test samples and then leverages this memory as a\nnon-parametric classifier to derive the final prediction. By using InterCLIP to\nencode text-image interactions more effectively and incorporating MEP,\nInterCLIP-MEP offers a more robust recognition of multi-modal sarcasm.\nExperiments demonstrate that InterCLIP-MEP achieves state-of-the-art\nperformance on the MMSD2.0 benchmark. Code and data are available at\n[https://github.com/CoderChen01/InterCLIP-MEP](https://github.com/CoderChen01/InterCLIP-MEP).\n","authors":["Junjie Chen","Subin Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16464v1.pdf","comment":"8 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2312.10251v3","updated":"2024-06-24T09:07:33Z","published":"2023-12-15T22:50:12Z","title":"Advancing Surgical VQA with Scene Graph Knowledge","summary":"  Modern operating room is becoming increasingly complex, requiring innovative\nintra-operative support systems. While the focus of surgical data science has\nlargely been on video analysis, integrating surgical computer vision with\nlanguage capabilities is emerging as a necessity. Our work aims to advance\nVisual Question Answering (VQA) in the surgical context with scene graph\nknowledge, addressing two main challenges in the current surgical VQA systems:\nremoving question-condition bias in the surgical VQA dataset and incorporating\nscene-aware reasoning in the surgical VQA model design. First, we propose a\nSurgical Scene Graph-based dataset, SSG-QA, generated by employing segmentation\nand detection models on publicly available datasets. We build surgical scene\ngraphs using spatial and action information of instruments and anatomies. These\ngraphs are fed into a question engine, generating diverse QA pairs. Our SSG-QA\ndataset provides a more complex, diverse, geometrically grounded, unbiased, and\nsurgical action-oriented dataset compared to existing surgical VQA datasets. We\nthen propose SSG-QA-Net, a novel surgical VQA model incorporating a lightweight\nScene-embedded Interaction Module (SIM), which integrates geometric scene\nknowledge in the VQA model design by employing cross-attention between the\ntextual and the scene features. Our comprehensive analysis of the SSG-QA\ndataset shows that SSG-QA-Net outperforms existing methods across different\nquestion types and complexities. We highlight that the primary limitation in\nthe current surgical VQA systems is the lack of scene knowledge to answer\ncomplex queries. We present a novel surgical VQA dataset and model and show\nthat results can be significantly improved by incorporating geometric scene\nfeatures in the VQA model design. The source code and the dataset will be made\npublicly available at: https://github.com/CAMMA-public/SSG-QA\n","authors":["Kun Yuan","Manasi Kattel","Joel L. Lavanchy","Nassir Navab","Vinkle Srivastav","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2312.10251v3.pdf","comment":"IPCAI 2024, Int J CARS (2024)"},{"id":"http://arxiv.org/abs/2406.16459v1","updated":"2024-06-24T08:58:43Z","published":"2024-06-24T08:58:43Z","title":"Suppressing Uncertainties in Degradation Estimation for Blind\n  Super-Resolution","summary":"  The problem of blind image super-resolution aims to recover high-resolution\n(HR) images from low-resolution (LR) images with unknown degradation modes.\nMost existing methods model the image degradation process using blur kernels.\nHowever, this explicit modeling approach struggles to cover the complex and\nvaried degradation processes encountered in the real world, such as high-order\ncombinations of JPEG compression, blur, and noise. Implicit modeling for the\ndegradation process can effectively overcome this issue, but a key challenge of\nimplicit modeling is the lack of accurate ground truth labels for the\ndegradation process to conduct supervised training. To overcome this\nlimitations inherent in implicit modeling, we propose an\n\\textbf{U}ncertainty-based degradation representation for blind\n\\textbf{S}uper-\\textbf{R}esolution framework (\\textbf{USR}). By suppressing the\nuncertainty of local degradation representations in images, USR facilitated\nself-supervised learning of degradation representations. The USR consists of\ntwo components: Adaptive Uncertainty-Aware Degradation Extraction (AUDE) and a\nfeature extraction network composed of Variable Depth Dynamic Convolution\n(VDDC) blocks. To extract Uncertainty-based Degradation Representation from LR\nimages, the AUDE utilizes the Self-supervised Uncertainty Contrast module with\nUncertainty Suppression Loss to suppress the inherent model uncertainty of the\nDegradation Extractor. Furthermore, VDDC block integrates degradation\ninformation through dynamic convolution. Rhe VDDC also employs an Adaptive\nIntensity Scaling operation that adaptively adjusts the degradation\nrepresentation according to the network hierarchy, thereby facilitating the\neffective integration of degradation information. Quantitative and qualitative\nexperiments affirm the superiority of our approach.\n","authors":["Junxiong Lin","Zeng Tao","Xuan Tong","Xinji Mai","Haoran Wang","Boyang Wang","Yan Wang","Qing Zhao","Jiawen Yu","Yuxuan Lin","Shaoqi Yan","Shuyong Gao","Wenqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16449v1","updated":"2024-06-24T08:42:42Z","published":"2024-06-24T08:42:42Z","title":"Evaluating and Analyzing Relationship Hallucinations in LVLMs","summary":"  The issue of hallucinations is a prevalent concern in existing Large\nVision-Language Models (LVLMs). Previous efforts have primarily focused on\ninvestigating object hallucinations, which can be easily alleviated by\nintroducing object detectors. However, these efforts neglect hallucinations in\ninter-object relationships, which is essential for visual comprehension. In\nthis work, we introduce R-Bench, a novel benchmark for evaluating Vision\nRelationship Hallucination. R-Bench features image-level questions that focus\non the existence of relationships and instance-level questions that assess\nlocal visual comprehension. We identify three types of relationship\nco-occurrences that lead to hallucinations: relationship-relationship,\nsubject-relationship, and relationship-object. The visual instruction tuning\ndataset's long-tail distribution significantly impacts LVLMs' understanding of\nvisual relationships. Furthermore, our analysis reveals that current LVLMs tend\nto disregard visual content and overly rely on the common sense knowledge of\nLarge Language Models. They also struggle with reasoning about spatial\nrelationships based on contextual information.\n","authors":["Mingrui Wu","Jiayi Ji","Oucheng Huang","Jiale Li","Yuhang Wu","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2406.16449v1.pdf","comment":"ICML2024"},{"id":"http://arxiv.org/abs/2406.16442v1","updated":"2024-06-24T08:33:02Z","published":"2024-06-24T08:33:02Z","title":"EmoLLM: Multimodal Emotional Understanding Meets Large Language Models","summary":"  Multi-modal large language models (MLLMs) have achieved remarkable\nperformance on objective multimodal perception tasks, but their ability to\ninterpret subjective, emotionally nuanced multimodal content remains largely\nunexplored. Thus, it impedes their ability to effectively understand and react\nto the intricate emotions expressed by humans through multimodal media. To\nbridge this gap, we introduce EmoBench, the first comprehensive benchmark\ndesigned specifically to evaluate the emotional capabilities of MLLMs across\nfive popular emotional tasks, using a diverse dataset of 287k images and videos\npaired with corresponding textual instructions. Meanwhile, we propose EmoLLM, a\nnovel model for multimodal emotional understanding, incorporating with two core\ntechniques. 1) Multi-perspective Visual Projection, it captures diverse\nemotional cues from visual data from multiple perspectives. 2) EmoPrompt, it\nguides MLLMs to reason about emotions in the correct direction. Experimental\nresults demonstrate that EmoLLM significantly elevates multimodal emotional\nunderstanding performance, with an average improvement of 12.1% across multiple\nfoundation models on EmoBench. Our work contributes to the advancement of MLLMs\nby facilitating a deeper and more nuanced comprehension of intricate human\nemotions, paving the way for the development of artificial emotional\nintelligence capabilities with wide-ranging applications in areas such as\nhuman-computer interaction, mental health support, and empathetic AI systems.\nCode, data, and model will be released.\n","authors":["Qu Yang","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2406.16442v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.16439v1","updated":"2024-06-24T08:30:03Z","published":"2024-06-24T08:30:03Z","title":"Exploring Test-Time Adaptation for Object Detection in Continually\n  Changing Environments","summary":"  For real-world applications, neural network models are commonly deployed in\ndynamic environments, where the distribution of the target domain undergoes\ntemporal changes. Continual Test-Time Adaptation (CTTA) has recently emerged as\na promising technique to gradually adapt a source-trained model to test data\ndrawn from a continually changing target domain. Despite recent advancements in\naddressing CTTA, two critical issues remain: 1) The use of a fixed threshold\nfor pseudo-labeling in existing methodologies leads to the generation of\nlow-quality pseudo-labels, as model confidence varies across categories and\ndomains; 2) While current solutions utilize stochastic parameter restoration to\nmitigate catastrophic forgetting, their capacity to preserve critical\ninformation is undermined by its intrinsic randomness. To tackle these\nchallenges, we present CTAOD, aiming to enhance the performance of detection\nmodels in CTTA scenarios. Inspired by prior CTTA works for effective\nadaptation, CTAOD is founded on the mean-teacher framework, characterized by\nthree core components. Firstly, the object-level contrastive learning module\ntailored for object detection extracts object-level features using the\nteacher's region of interest features and optimizes them through contrastive\nlearning. Secondly, the dynamic threshold strategy updates the\ncategory-specific threshold based on predicted confidence scores to improve the\nquality of pseudo-labels. Lastly, we design a data-driven stochastic\nrestoration mechanism to selectively reset inactive parameters using the\ngradients as weights for a random mask matrix, thereby ensuring the retention\nof essential knowledge. We demonstrate the effectiveness of our approach on\nfour CTTA tasks for object detection, where CTAOD outperforms existing methods,\nespecially achieving a 3.0 mAP improvement on the Cityscapes-to-Cityscapes-C\nCTTA task.\n","authors":["Shilei Cao","Yan Liu","Juepeng Zheng","Weijia Li","Runmin Dong","Haohuan Fu"],"pdf_url":"https://arxiv.org/pdf/2406.16439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16434v1","updated":"2024-06-24T08:27:31Z","published":"2024-06-24T08:27:31Z","title":"Multi-threshold Deep Metric Learning for Facial Expression Recognition","summary":"  Effective expression feature representations generated by a triplet-based\ndeep metric learning are highly advantageous for facial expression recognition\n(FER). The performance of triplet-based deep metric learning is contingent upon\nidentifying the best threshold for triplet loss. Threshold validation, however,\nis tough and challenging, as the ideal threshold changes among datasets and\neven across classes within the same dataset. In this paper, we present the\nmulti-threshold deep metric learning technique, which not only avoids the\ndifficult threshold validation but also vastly increases the capacity of\ntriplet loss learning to construct expression feature representations. We find\nthat each threshold of the triplet loss intrinsically determines a distinctive\ndistribution of inter-class variations and corresponds, thus, to a unique\nexpression feature representation. Therefore, rather than selecting a single\noptimal threshold from a valid threshold range, we thoroughly sample thresholds\nacross the range, allowing the representation characteristics manifested by\nthresholds within the range to be fully extracted and leveraged for FER. To\nrealize this approach, we partition the embedding layer of the deep metric\nlearning network into a collection of slices and model training these embedding\nslices as an end-to-end multi-threshold deep metric learning problem. Each\nembedding slice corresponds to a sample threshold and is learned by enforcing\nthe corresponding triplet loss, yielding a set of distinct expression features,\none for each embedding slice. It makes the embedding layer, which is composed\nof a set of slices, a more informative and discriminative feature, hence\nenhancing the FER accuracy. Extensive evaluations demonstrate the superior\nperformance of the proposed approach on both posed and spontaneous facial\nexpression datasets.\n","authors":["Wenwu Yang","Jinyi Yu","Tuo Chen","Zhenguang Liu","Xun Wang","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2406.16434v1.pdf","comment":"accepted by Pattern Recognition"},{"id":"http://arxiv.org/abs/2406.13210v2","updated":"2024-06-24T08:22:40Z","published":"2024-06-19T04:43:41Z","title":"Surgical Triplet Recognition via Diffusion Model","summary":"  Surgical triplet recognition is an essential building block to enable\nnext-generation context-aware operating rooms. The goal is to identify the\ncombinations of instruments, verbs, and targets presented in surgical video\nframes. In this paper, we propose DiffTriplet, a new generative framework for\nsurgical triplet recognition employing the diffusion model, which predicts\nsurgical triplets via iterative denoising. To handle the challenge of triplet\nassociation, two unique designs are proposed in our diffusion framework, i.e.,\nassociation learning and association guidance. During training, we optimize the\nmodel in the joint space of triplets and individual components to capture the\ndependencies among them. At inference, we integrate association constraints\ninto each update of the iterative denoising process, which refines the triplet\nprediction using the information of individual components. Experiments on the\nCholecT45 and CholecT50 datasets show the superiority of the proposed method in\nachieving a new state-of-the-art performance for surgical triplet recognition.\nOur codes will be released.\n","authors":["Daochang Liu","Axel Hu","Mubarak Shah","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2406.13210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16427v1","updated":"2024-06-24T08:20:53Z","published":"2024-06-24T08:20:53Z","title":"Dynamic Pseudo Label Optimization in Point-Supervised Nuclei\n  Segmentation","summary":"  Deep learning has achieved impressive results in nuclei segmentation, but the\nmassive requirement for pixel-wise labels remains a significant challenge. To\nalleviate the annotation burden, existing methods generate pseudo masks for\nmodel training using point labels. However, the generated masks are inevitably\ndifferent from the ground truth, and these dissimilarities are not handled\nreasonably during the network training, resulting in the subpar performance of\nthe segmentation model. To tackle this issue, we propose a framework named\nDoNuSeg, enabling \\textbf{D}ynamic pseudo label \\textbf{O}ptimization in\npoint-supervised \\textbf{Nu}clei \\textbf{Seg}mentation. Specifically, DoNuSeg\ntakes advantage of class activation maps (CAMs) to adaptively capture regions\nwith semantics similar to annotated points. To leverage semantic diversity in\nthe hierarchical feature levels, we design a dynamic selection module to choose\nthe optimal one among CAMs from different encoder blocks as pseudo masks.\nMeanwhile, a CAM-guided contrastive module is proposed to further enhance the\naccuracy of pseudo masks. In addition to exploiting the semantic information\nprovided by CAMs, we consider location priors inherent to point labels,\ndeveloping a task-decoupled structure for effectively differentiating nuclei.\nExtensive experiments demonstrate that DoNuSeg outperforms state-of-the-art\npoint-supervised methods. The code is available at\nhttps://github.com/shinning0821/MICCAI24-DoNuSeg.\n","authors":["Ziyue Wang","Ye Zhang","Yifeng Wang","Linghan Cai","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16427v1.pdf","comment":"early accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2406.15111v2","updated":"2024-06-24T08:19:00Z","published":"2024-06-21T12:59:20Z","title":"Investigating the impact of 2D gesture representation on co-speech\n  gesture generation","summary":"  Co-speech gestures play a crucial role in the interactions between humans and\nembodied conversational agents (ECA). Recent deep learning methods enable the\ngeneration of realistic, natural co-speech gestures synchronized with speech,\nbut such approaches require large amounts of training data. \"In-the-wild\"\ndatasets, which compile videos from sources such as YouTube through human pose\ndetection models, offer a solution by providing 2D skeleton sequences that are\npaired with speech. Concurrently, innovative lifting models have emerged,\ncapable of transforming these 2D pose sequences into their 3D counterparts,\nleading to large and diverse datasets of 3D gestures. However, the derived 3D\npose estimation is essentially a pseudo-ground truth, with the actual ground\ntruth being the 2D motion data. This distinction raises questions about the\nimpact of gesture representation dimensionality on the quality of generated\nmotions, a topic that, to our knowledge, remains largely unexplored. In this\nwork, we evaluate the impact of the dimensionality of the training data, 2D or\n3D joint coordinates, on the performance of a multimodal speech-to-gesture deep\ngenerative model. We use a lifting model to convert 2D-generated sequences of\nbody pose to 3D. Then, we compare the sequence of gestures generated directly\nin 3D to the gestures generated in 2D and lifted to 3D as post-processing.\n","authors":["Teo Guichoux","Laure Soulier","Nicolas Obin","Catherine Pelachaud"],"pdf_url":"https://arxiv.org/pdf/2406.15111v2.pdf","comment":"8 pages. Paper accepted at WACAI 2024"},{"id":"http://arxiv.org/abs/2403.04161v5","updated":"2024-06-24T08:18:29Z","published":"2024-03-07T02:40:42Z","title":"SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS","summary":"  Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid\nresource-intensive neural network training, especially in Neural Architecture\nSearch (NAS). Recent studies show that existing training-free metrics have\nseveral limitations, such as limited correlation and poor generalisation across\ndifferent search spaces and tasks. Hence, we propose Sample-Wise Activation\nPatterns and its derivative, SWAP-Score, a novel high-performance training-free\nmetric. It measures the expressivity of networks over a batch of input samples.\nThe SWAP-Score is strongly correlated with ground-truth performance across\nvarious search spaces and tasks, outperforming 15 existing training-free\nmetrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be\nfurther enhanced by regularisation, which leads to even higher correlations in\ncell-based search space and enables model size control during the search. For\nexample, Spearman's rank correlation coefficient between regularised SWAP-Score\nand CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90,\nsignificantly higher than 0.80 from the second-best metric, NWOT. When\nintegrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves\ncompetitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and\n9 minutes of GPU time respectively.\n","authors":["Yameng Peng","Andy Song","Haytham M. Fayek","Vic Ciesielski","Xiaojun Chang"],"pdf_url":"https://arxiv.org/pdf/2403.04161v5.pdf","comment":"ICLR2024 Spotlight"},{"id":"http://arxiv.org/abs/2406.16422v1","updated":"2024-06-24T08:14:09Z","published":"2024-06-24T08:14:09Z","title":"Exploring Cross-Domain Few-Shot Classification via Frequency-Aware\n  Prompting","summary":"  Cross-Domain Few-Shot Learning has witnessed great stride with the\ndevelopment of meta-learning. However, most existing methods pay more attention\nto learning domain-adaptive inductive bias (meta-knowledge) through\nfeature-wise manipulation or task diversity improvement while neglecting the\nphenomenon that deep networks tend to rely more on high-frequency cues to make\nthe classification decision, which thus degenerates the robustness of learned\ninductive bias since high-frequency information is vulnerable and easy to be\ndisturbed by noisy information. Hence in this paper, we make one of the first\nattempts to propose a Frequency-Aware Prompting method with mutual attention\nfor Cross-Domain Few-Shot classification, which can let networks simulate the\nhuman visual perception of selecting different frequency cues when facing new\nrecognition tasks. Specifically, a frequency-aware prompting mechanism is first\nproposed, in which high-frequency components of the decomposed source image are\nswitched either with normal distribution sampling or zeroing to get\nfrequency-aware augment samples. Then, a mutual attention module is designed to\nlearn generalizable inductive bias under CD-FSL settings. More importantly, the\nproposed method is a plug-and-play module that can be directly applied to most\noff-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks\ndemonstrate the effectiveness of our proposed method as well as robustly\nimprove the performance of existing CD-FLS methods. Resources at\nhttps://github.com/tinkez/FAP_CDFSC.\n","authors":["Tiange Zhang","Qing Cai","Feng Gao","Lin Qi","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2406.16422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16384v1","updated":"2024-06-24T07:53:46Z","published":"2024-06-24T07:53:46Z","title":"High-resolution open-vocabulary object 6D pose estimation","summary":"  The generalisation to unseen objects in the 6D pose estimation task is very\nchallenging. While Vision-Language Models (VLMs) enable using natural language\ndescriptions to support 6D pose estimation of unseen objects, these solutions\nunderperform compared to model-based methods. In this work we present Horyon,\nan open-vocabulary VLM-based architecture that addresses relative pose\nestimation between two scenes of an unseen object, described by a textual\nprompt only. We use the textual prompt to identify the unseen object in the\nscenes and then obtain high-resolution multi-scale features. These features are\nused to extract cross-scene matches for registration. We evaluate our model on\na benchmark with a large variety of unseen objects across four datasets, namely\nREAL275, Toyota-Light, Linemod, and YCB-Video. Our method achieves\nstate-of-the-art performance on all datasets, outperforming by 12.6 in Average\nRecall the previous best-performing approach.\n","authors":["Jaime Corsetti","Davide Boscaini","Francesco Giuliari","Changjae Oh","Andrea Cavallaro","Fabio Poiesi"],"pdf_url":"https://arxiv.org/pdf/2406.16384v1.pdf","comment":"Technical report. Extension of CVPR paper \"Open-vocabulary object 6D\n  pose estimation\". Project page: https://jcorsetti.github.io/oryon"},{"id":"http://arxiv.org/abs/2406.06462v2","updated":"2024-06-24T07:05:01Z","published":"2024-06-10T16:58:48Z","title":"VCR: Visual Caption Restoration","summary":"  We introduce Visual Caption Restoration (VCR), a novel vision-language task\nthat challenges models to accurately restore partially obscured texts using\npixel-level hints within images. This task stems from the observation that text\nembedded in images is intrinsically different from common visual elements and\nnatural language due to the need to align the modalities of vision, text, and\ntext embedded in images. While numerous works have integrated text embedded in\nimages into visual question-answering tasks, approaches to these tasks\ngenerally rely on optical character recognition or masked language modeling,\nthus reducing the task to mainly text-based processing. However, text-based\nprocessing becomes ineffective in VCR as accurate text restoration depends on\nthe combined information from provided images, context, and subtle cues from\nthe tiny exposed areas of masked texts. We develop a pipeline to generate\nsynthetic images for the VCR task using image-caption pairs, with adjustable\ncaption visibility to control the task difficulty. With this pipeline, we\nconstruct a dataset for VCR called VCR-Wiki using images with captions from\nWikipedia, comprising 2.11M English and 346K Chinese entities in both easy and\nhard split variants. Our results reveal that current vision language models\nsignificantly lag behind human performance in the VCR task, and merely\nfine-tuning the models on our dataset does not lead to notable improvements. We\nrelease VCR-Wiki and the data construction code to facilitate future research.\n","authors":["Tianyu Zhang","Suyuchen Wang","Lu Li","Ge Zhang","Perouz Taslakian","Sai Rajeswar","Jie Fu","Bang Liu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2406.06462v2.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.16360v1","updated":"2024-06-24T07:00:57Z","published":"2024-06-24T07:00:57Z","title":"MIRReS: Multi-bounce Inverse Rendering using Reservoir Sampling","summary":"  We present MIRReS, a novel two-stage inverse rendering framework that jointly\nreconstructs and optimizes the explicit geometry, material, and lighting from\nmulti-view images. Unlike previous methods that rely on implicit irradiance\nfields or simplified path tracing algorithms, our method extracts an explicit\ngeometry (triangular mesh) in stage one, and introduces a more realistic\nphysically-based inverse rendering model that utilizes multi-bounce path\ntracing and Monte Carlo integration. By leveraging multi-bounce path tracing,\nour method effectively estimates indirect illumination, including\nself-shadowing and internal reflections, which improves the intrinsic\ndecomposition of shape, material, and lighting. Moreover, we incorporate\nreservoir sampling into our framework to address the noise in Monte Carlo\nintegration, enhancing convergence and facilitating gradient-based optimization\nwith low sample counts. Through qualitative and quantitative evaluation of\nseveral scenarios, especially in challenging scenarios with complex shadows, we\ndemonstrate that our method achieves state-of-the-art performance on\ndecomposition results. Additionally, our optimized explicit geometry enables\napplications such as scene editing, relighting, and material editing with\nmodern graphics engines or CAD software. The source code is available at\nhttps://brabbitdousha.github.io/MIRReS/\n","authors":["Yuxin Dai","Qi Wang","Jingsen Zhu","Dianbing Xi","Yuchi Huo","Chen Qian","Ying He"],"pdf_url":"https://arxiv.org/pdf/2406.16360v1.pdf","comment":"16 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.16359v1","updated":"2024-06-24T06:57:51Z","published":"2024-06-24T06:57:51Z","title":"Improving Generative Adversarial Networks for Video Super-Resolution","summary":"  In this research, we explore different ways to improve generative adversarial\nnetworks for video super-resolution tasks from a base single image\nsuper-resolution GAN model. Our primary objective is to identify potential\ntechniques that enhance these models and to analyze which of these techniques\nyield the most significant improvements. We evaluate our results using Peak\nSignal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM). Our\nfindings indicate that the most effective techniques include temporal\nsmoothing, long short-term memory (LSTM) layers, and a temporal loss function.\nThe integration of these methods results in an 11.97% improvement in PSNR and\nan 8% improvement in SSIM compared to the baseline video super-resolution\ngenerative adversarial network (GAN) model. This substantial improvement\nsuggests potential further applications to enhance current state-of-the-art\nmodels.\n","authors":["Daniel Wen"],"pdf_url":"https://arxiv.org/pdf/2406.16359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16346v1","updated":"2024-06-24T06:39:02Z","published":"2024-06-24T06:39:02Z","title":"Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific\n  Training Tasks","summary":"  Large language models (LLMs) and large visual language models (LVLMs) have\nbeen at the forefront of the artificial intelligence field, particularly for\ntasks like text generation, video captioning, and question-answering.\nTypically, it is more applicable to train these models on broader knowledge\nbases or datasets to increase generalizability, learn relationships between\ntopics, and recognize patterns. Instead, we propose to provide instructional\ndatasets specific to the task of each modality within a distinct domain and\nthen fine-tune the parameters of the model using LORA. With our approach, we\ncan eliminate all noise irrelevant to the given task while also ensuring that\nthe model generates with enhanced precision. For this work, we use Video-LLaVA\nto generate recipes given cooking videos without transcripts. Video-LLaVA's\nmultimodal architecture allows us to provide cooking images to its image\nencoder, cooking videos to its video encoder, and general cooking questions to\nits text encoder. Thus, we aim to remove all noise unrelated to cooking while\nimproving our model's capabilities to generate specific ingredient lists and\ndetailed instructions. As a result, our approach to fine-tuning Video-LLaVA\nleads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.\nWhile this may seem like a marginal increase, our model trains on an image\ninstruction dataset 2.5% the size of Video-LLaVA's and a video instruction\ndataset 23.76% of Video-LLaVA's.\n","authors":["Daniel Wen","Nafisa Hussain"],"pdf_url":"https://arxiv.org/pdf/2406.16346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01368v3","updated":"2024-06-24T06:27:44Z","published":"2024-02-02T12:39:47Z","title":"LIR: A Lightweight Baseline for Image Restoration","summary":"  Recently, there have been significant advancements in Image Restoration based\non CNN and transformer. However, the inherent characteristics of the Image\nRestoration task are often overlooked in many works. They, instead, tend to\nfocus on the basic block design and stack numerous such blocks to the model,\nleading to parameters redundant and computations unnecessary. Thus, the\nefficiency of the image restoration is hindered. In this paper, we propose a\nLightweight Baseline network for Image Restoration called LIR to efficiently\nrestore the image and remove degradations. First of all, through an ingenious\nstructural design, LIR removes the degradations existing in the local and\nglobal residual connections that are ignored by modern networks. Then, a\nLightweight Adaptive Attention (LAA) Block is introduced which is mainly\ncomposed of proposed Adaptive Filters and Attention Blocks. The proposed\nAdaptive Filter is used to adaptively extract high-frequency information and\nenhance object contours in various IR tasks, and Attention Block involves a\nnovel Patch Attention module to approximate the self-attention part of the\ntransformer. On the deraining task, our LIR achieves the state-of-the-art\nStructure Similarity Index Measure (SSIM) and comparable performance to\nstate-of-the-art models on Peak Signal-to-Noise Ratio (PSNR). For denoising,\ndehazing, and deblurring tasks, LIR also achieves a comparable performance to\nstate-of-the-art models with a parameter size of about 30\\%. In addition, it is\nworth noting that our LIR produces better visual results that are more in line\nwith the human aesthetic.\n","authors":["Dongqi Fan","Ting Yue","Xin Zhao","Renjing Xu","Liang Chang"],"pdf_url":"https://arxiv.org/pdf/2402.01368v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16338v1","updated":"2024-06-24T06:21:59Z","published":"2024-06-24T06:21:59Z","title":"VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in\n  Large Video-Language Models","summary":"  Recent advancements in Multimodal Large Language Models (MLLMs) have extended\ntheir capabilities to video understanding. Yet, these models are often plagued\nby \"hallucinations\", where irrelevant or nonsensical content is generated,\ndeviating from the actual video context. This work introduces VideoHallucer,\nthe first comprehensive benchmark for hallucination detection in large\nvideo-language models (LVLMs). VideoHallucer categorizes hallucinations into\ntwo main types: intrinsic and extrinsic, offering further subcategories for\ndetailed analysis, including object-relation, temporal, semantic detail,\nextrinsic factual, and extrinsic non-factual hallucinations. We adopt an\nadversarial binary VideoQA method for comprehensive evaluation, where pairs of\nbasic and hallucinated questions are crafted strategically. By evaluating\neleven LVLMs on VideoHallucer, we reveal that i) the majority of current models\nexhibit significant issues with hallucinations; ii) while scaling datasets and\nparameters improves models' ability to detect basic visual cues and\ncounterfactuals, it provides limited benefit for detecting extrinsic factual\nhallucinations; iii) existing models are more adept at detecting facts than\nidentifying hallucinations. As a byproduct, these analyses further instruct the\ndevelopment of our self-PEP framework, achieving an average of 5.38%\nimprovement in hallucination resistance across all model architectures.\n","authors":["Yuxuan Wang","Yueqian Wang","Dongyan Zhao","Cihang Xie","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.16338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16333v1","updated":"2024-06-24T06:12:16Z","published":"2024-06-24T06:12:16Z","title":"Prompt-Consistency Image Generation (PCIG): A Unified Framework\n  Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models","summary":"  The rapid advancement of Text-to-Image(T2I) generative models has enabled the\nsynthesis of high-quality images guided by textual descriptions. Despite this\nsignificant progress, these models are often susceptible in generating contents\nthat contradict the input text, which poses a challenge to their reliability\nand practical deployment. To address this problem, we introduce a novel\ndiffusion-based framework to significantly enhance the alignment of generated\nimages with their corresponding descriptions, addressing the inconsistency\nbetween visual output and textual input. Our framework is built upon a\ncomprehensive analysis of inconsistency phenomena, categorizing them based on\ntheir manifestation in the image. Leveraging a state-of-the-art large language\nmodule, we first extract objects and construct a knowledge graph to predict the\nlocations of these objects in potentially generated images. We then integrate a\nstate-of-the-art controllable image generation model with a visual text\ngeneration module to generate an image that is consistent with the original\nprompt, guided by the predicted object locations. Through extensive experiments\non an advanced multimodal hallucination benchmark, we demonstrate the efficacy\nof our approach in accurately generating the images without the inconsistency\nwith the original prompt. The code can be accessed via\nhttps://github.com/TruthAI-Lab/PCIG.\n","authors":["Yichen Sun","Zhixuan Chu","Zhan Qin","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08336v2","updated":"2024-06-24T06:09:42Z","published":"2024-06-12T15:42:21Z","title":"CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal\n  Dysarthric Speech Reconstruction","summary":"  Dysarthric speech reconstruction (DSR) aims to transform dysarthric speech\ninto normal speech. It still suffers from low speaker similarity and poor\nprosody naturalness. In this paper, we propose a multi-modal DSR model by\nleveraging neural codec language modeling to improve the reconstruction\nresults, especially for the speaker similarity and prosody naturalness. Our\nproposed model consists of: (i) a multi-modal content encoder to extract robust\nphoneme embeddings from dysarthric speech with auxiliary visual inputs; (ii) a\nspeaker codec encoder to extract and normalize the speaker-aware codecs from\nthe dysarthric speech, in order to provide original timbre and normal prosody;\n(iii) a codec language model based speech decoder to reconstruct the speech\nbased on the extracted phoneme embeddings and normalized codecs. Evaluations on\nthe commonly used UASpeech corpus show that our proposed model can achieve\nsignificant improvements in terms of speaker similarity and prosody\nnaturalness.\n","authors":["Xueyuan Chen","Dongchao Yang","Dingdong Wang","Xixin Wu","Zhiyong Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2406.08336v2.pdf","comment":"Accepted by Interspeech 2024"},{"id":"http://arxiv.org/abs/2406.05779v2","updated":"2024-06-24T06:07:14Z","published":"2024-06-09T13:25:02Z","title":"Learning to utilize image second-order derivative information for crisp\n  edge detection","summary":"  Edge detection is a fundamental task in computer vision. It has made great\nprogress under the development of deep convolutional neural networks (DCNNs),\nsome of which have achieved a beyond human-level performance. However, recent\ntop-performing edge detection methods tend to generate thick and noisy edge\nlines. In this work, we solve this problem from two aspects: (1) leveraging the\nprecise edge pixel location characteristics of second-order image derivatives,\nand (2) alleviating the issue of imbalanced pixel distribution. We propose a\nsecond-order derivative-based multi-scale contextual enhancement module (SDMC)\nto help the model locate true edge pixels accurately and construct a hybrid\nfocal loss function (HFL) to alleviate the imbalanced distribution issue. We\ntest our method on three standard benchmarks and the experiment results\nillustrate that our method can make the output edge maps crisp and achieves a\ntop performance among several state-of-the-art methods on the BSDS500 dataset\n(ODS F-score in standard evaluation is 0.829, in crispness evaluation is\n0.720), NYUD-V2 dataset (ODS F-score in standard evaluation is 0.768, in\ncrispness evaluation is 0.546), and BIPED dataset (ODS F-score in standard\nevaluation is 0.903).\n","authors":["Changsong Liu","Wei Zhang","Yanyan Liu","Yuming Li","Mingyang Li","Wenlin Li","Yimeng Fan","Liang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.05779v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13393v2","updated":"2024-06-24T06:04:23Z","published":"2024-06-19T09:36:18Z","title":"Style-NeRF2NeRF: 3D Style Transfer From Style-Aligned Multi-View Images","summary":"  We propose a simple yet effective pipeline for stylizing a 3D scene,\nharnessing the power of 2D image diffusion models. Given a NeRF model\nreconstructed from a set of multi-view images, we perform 3D style transfer by\nrefining the source NeRF model using stylized images generated by a\nstyle-aligned image-to-image diffusion model. Given a target style prompt, we\nfirst generate perceptually similar multi-view images by leveraging a\ndepth-conditioned diffusion model with an attention-sharing mechanism. Next,\nbased on the stylized multi-view images, we propose to guide the style transfer\nprocess with the sliced Wasserstein loss based on the feature maps extracted\nfrom a pre-trained CNN model. Our pipeline consists of decoupled steps,\nallowing users to test various prompt ideas and preview the stylized 3D result\nbefore proceeding to the NeRF fine-tuning stage. We demonstrate that our method\ncan transfer diverse artistic styles to real-world 3D scenes with competitive\nquality. Result videos are also available on our project page:\nhttps://haruolabs.github.io/style-n2n/\n","authors":["Haruo Fujiwara","Yusuke Mukuta","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/2406.13393v2.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.03662v2","updated":"2024-06-24T05:48:24Z","published":"2024-05-06T17:39:53Z","title":"Diffeomorphic Template Registration for Atmospheric Turbulence\n  Mitigation","summary":"  We describe a method for recovering the irradiance underlying a collection of\nimages corrupted by atmospheric turbulence. Since supervised data is often\ntechnically impossible to obtain, assumptions and biases have to be imposed to\nsolve this inverse problem, and we choose to model them explicitly. Rather than\ninitializing a latent irradiance (\"template\") by heuristics to estimate\ndeformation, we select one of the images as a reference, and model the\ndeformation in this image by the aggregation of the optical flow from it to\nother images, exploiting a prior imposed by Central Limit Theorem. Then with a\nnovel flow inversion module, the model registers each image TO the template but\nWITHOUT the template, avoiding artifacts related to poor template\ninitialization. To illustrate the robustness of the method, we simply (i)\nselect the first frame as the reference and (ii) use the simplest optical flow\nto estimate the warpings, yet the improvement in registration is decisive in\nthe final reconstruction, as we achieve state-of-the-art performance despite\nits simplicity. The method establishes a strong baseline that can be further\nimproved by integrating it seamlessly into more sophisticated pipelines, or\nwith domain-specific methods if so desired.\n","authors":["Dong Lao","Congli Wang","Alex Wong","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2405.03662v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11494v2","updated":"2024-06-24T05:29:10Z","published":"2024-03-18T05:58:13Z","title":"CCC++: Optimized Color Classified Colorization with Segment Anything\n  Model (SAM) Empowered Object Selective Color Harmonization","summary":"  In this paper, we formulate the colorization problem into a multinomial\nclassification problem and then apply a weighted function to classes. We\npropose a set of formulas to transform color values into color classes and vice\nversa. To optimize the classes, we experiment with different bin sizes for\ncolor class transformation. Observing class appearance, standard deviation, and\nmodel parameters on various extremely large-scale real-time images in practice\nwe propose 532 color classes for our classification task. During training, we\npropose a class-weighted function based on true class appearance in each batch\nto ensure proper saturation of individual objects. We adjust the weights of the\nmajor classes, which are more frequently observed, by lowering them, while\nescalating the weights of the minor classes, which are less commonly observed.\nIn our class re-weight formula, we propose a hyper-parameter for finding the\noptimal trade-off between the major and minor appeared classes. As we apply\nregularization to enhance the stability of the minor class, occasional minor\nnoise may appear at the object's edges. We propose a novel object-selective\ncolor harmonization method empowered by the Segment Anything Model (SAM) to\nrefine and enhance these edges. We propose two new color image evaluation\nmetrics, the Color Class Activation Ratio (CCAR), and the True Activation Ratio\n(TAR), to quantify the richness of color components. We compare our proposed\nmodel with state-of-the-art models using six different dataset: Place, ADE,\nCeleba, COCO, Oxford 102 Flower, and ImageNet, in qualitative and quantitative\napproaches. The experimental results show that our proposed model outstrips\nother models in visualization, CNR and in our proposed CCAR and TAR measurement\ncriteria while maintaining satisfactory performance in regression (MSE, PSNR),\nsimilarity (SSIM, LPIPS, UIUI), and generative criteria (FID).\n","authors":["Mrityunjoy Gain","Avi Deb Raha","Rameswar Debnath"],"pdf_url":"https://arxiv.org/pdf/2403.11494v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.01476"},{"id":"http://arxiv.org/abs/2406.16322v1","updated":"2024-06-24T05:15:15Z","published":"2024-06-24T05:15:15Z","title":"Lesion-Aware Cross-Phase Attention Network for Renal Tumor Subtype\n  Classification on Multi-Phase CT Scans","summary":"  Multi-phase computed tomography (CT) has been widely used for the\npreoperative diagnosis of kidney cancer due to its non-invasive nature and\nability to characterize renal lesions. However, since enhancement patterns of\nrenal lesions across CT phases are different even for the same lesion type, the\nvisual assessment by radiologists suffers from inter-observer variability in\nclinical practice. Although deep learning-based approaches have been recently\nexplored for differential diagnosis of kidney cancer, they do not explicitly\nmodel the relationships between CT phases in the network design, limiting the\ndiagnostic performance. In this paper, we propose a novel lesion-aware\ncross-phase attention network (LACPANet) that can effectively capture temporal\ndependencies of renal lesions across CT phases to accurately classify the\nlesions into five major pathological subtypes from time-series multi-phase CT\nimages. We introduce a 3D inter-phase lesion-aware attention mechanism to learn\neffective 3D lesion features that are used to estimate attention weights\ndescribing the inter-phase relations of the enhancement patterns. We also\npresent a multi-scale attention scheme to capture and aggregate temporal\npatterns of lesion features at different spatial scales for further\nimprovement. Extensive experiments on multi-phase CT scans of kidney cancer\npatients from the collected dataset demonstrate that our LACPANet outperforms\nstate-of-the-art approaches in diagnostic accuracy.\n","authors":["Kwang-Hyun Uhm","Seung-Won Jung","Sung-Hoo Hong","Sung-Jea Ko"],"pdf_url":"https://arxiv.org/pdf/2406.16322v1.pdf","comment":"This article has been accepted for publication in Computers in\n  Biology and Medicine"},{"id":"http://arxiv.org/abs/2403.02148v4","updated":"2024-06-24T05:06:56Z","published":"2024-03-04T15:57:29Z","title":"MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection","summary":"  Recently, infrared small target detection (ISTD) has made significant\nprogress, thanks to the development of basic models. Specifically, the models\ncombining CNNs with transformers can successfully extract both local and global\nfeatures. However, the disadvantage of the transformer is also inherited, i.e.,\nthe quadratic computational complexity to sequence length. Inspired by the\nrecent basic model with linear complexity for long-distance modeling, Mamba, we\nexplore the potential of this state space model for ISTD task in terms of\neffectiveness and efficiency in the paper. However, directly applying Mamba\nachieves suboptimal performances due to the insufficient harnessing of local\nfeatures, which are imperative for detecting small targets. Instead, we tailor\na nested structure, Mamba-in-Mamba (MiM-ISTD), for efficient ISTD. It consists\nof Outer and Inner Mamba blocks to adeptly capture both global and local\nfeatures. Specifically, we treat the local patches as \"visual sentences\" and\nuse the Outer Mamba to explore the global information. We then decompose each\nvisual sentence into sub-patches as \"visual words\" and use the Inner Mamba to\nfurther explore the local information among words in the visual sentence with\nnegligible computational costs. By aggregating the visual word and visual\nsentence features, our MiM-ISTD can effectively explore both global and local\ninformation. Experiments on NUAA-SIRST and IRSTD-1k show the superior accuracy\nand efficiency of our method. Specifically, MiM-ISTD is $8 \\times$ faster than\nthe SOTA method and reduces GPU memory usage by 62.2$\\%$ when testing on $2048\n\\times 2048$ images, overcoming the computation and memory constraints on\nhigh-resolution infrared images.\n","authors":["Tianxiang Chen","Zi Ye","Zhentao Tan","Tao Gong","Yue Wu","Qi Chu","Bin Liu","Nenghai Yu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2403.02148v4.pdf","comment":"The first Mamba-based model for infrared small target detection"},{"id":"http://arxiv.org/abs/2403.01422v2","updated":"2024-06-24T04:55:28Z","published":"2024-03-03T07:43:39Z","title":"MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies","summary":"  Development of multimodal models has marked a significant step forward in how\nmachines understand videos. These models have shown promise in analyzing short\nvideo clips. However, when it comes to longer formats like movies, they often\nfall short. The main hurdles are the lack of high-quality, diverse video data\nand the intensive work required to collect or annotate such data. In face of\nthese challenges, we propose MovieLLM, a novel framework designed to synthesize\nconsistent and high-quality video data for instruction tuning. The pipeline is\ncarefully designed to control the style of videos by improving textual\ninversion technique with powerful text generation capability of GPT-4. As the\nfirst framework to do such thing, our approach stands out for its flexibility\nand scalability, empowering users to create customized movies with only one\ndescription. This makes it a superior alternative to traditional data\ncollection methods. Our extensive experiments validate that the data produced\nby MovieLLM significantly improves the performance of multimodal models in\nunderstanding complex video narratives, overcoming the limitations of existing\ndatasets regarding scarcity and bias.\n","authors":["Zhende Song","Chenchen Wang","Jiamu Sheng","Chi Zhang","Gang Yu","Jiayuan Fan","Tao Chen"],"pdf_url":"https://arxiv.org/pdf/2403.01422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06872v5","updated":"2024-06-24T04:47:38Z","published":"2022-12-13T19:38:13Z","title":"Comparing the Decision-Making Mechanisms by Transformers and CNNs via\n  Explanation Methods","summary":"  In order to gain insights about the decision-making of different visual\nrecognition backbones, we propose two methodologies, sub-explanation counting\nand cross-testing, that systematically applies deep explanation algorithms on a\ndataset-wide basis, and compares the statistics generated from the amount and\nnature of the explanations. These methodologies reveal the difference among\nnetworks in terms of two properties called compositionality and disjunctivism.\nTransformers and ConvNeXt are found to be more compositional, in the sense that\nthey jointly consider multiple parts of the image in building their decisions,\nwhereas traditional CNNs and distilled transformers are less compositional and\nmore disjunctive, which means that they use multiple diverse but smaller set of\nparts to achieve a confident prediction. Through further experiments, we\npinpointed the choice of normalization to be especially important in the\ncompositionality of a model, in that batch normalization leads to less\ncompositionality while group and layer normalization lead to more. Finally, we\nalso analyze the features shared by different backbones and plot a landscape of\ndifferent models based on their feature-use similarity.\n","authors":["Mingqi Jiang","Saeed Khorram","Li Fuxin"],"pdf_url":"https://arxiv.org/pdf/2212.06872v5.pdf","comment":"25 pages with 37 figures, to be published in CVPR24. Project Webpage:\n  https://mingqij.github.io/projects/cdmmtc/"},{"id":"http://arxiv.org/abs/2301.01955v3","updated":"2024-06-24T04:45:10Z","published":"2023-01-05T08:37:36Z","title":"Adaptively Clustering Neighbor Elements for Image-Text Generation","summary":"  We propose a novel Transformer-based image-to-text generation model termed as\n\\textbf{ACF} that adaptively clusters vision patches into object regions and\nlanguage words into phrases to implicitly learn object-phrase alignments for\nbetter visual-text coherence. To achieve this, we design a novel self-attention\nlayer that applies self-attention over the elements in a local cluster window\ninstead of the whole sequence. The window size is softly decided by a\nclustering matrix that is calculated by the current input data and thus this\nprocess is adaptive. By stacking these revised self-attention layers to\nconstruct ACF, the small clusters in the lower layers can be grouped into a\nbigger cluster, \\eg vision/language. ACF clusters small objects/phrases into\nbigger ones. In this gradual clustering process, a parsing tree is generated\nwhich embeds the hierarchical knowledge of the input sequence. As a result, by\nusing ACF to build the vision encoder and language decoder, the hierarchical\nobject-phrase alignments are embedded and then transferred from vision to\nlanguage domains in two popular image-to-text tasks: Image captioning and\nVisual Question Answering. The experiment results demonstrate the effectiveness\nof ACF, which outperforms most SOTA captioning and VQA models and achieves\ncomparable scores compared with some large-scale pre-trained models. Our code\nis available \\href{https://github.com/ZihuaEvan/ACFModel/}{[here]}.\n","authors":["Zihua Wang","Xu Yang","Hanwang Zhang","Haiyang Xu","Ming Yan","Fei Huang","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.01955v3.pdf","comment":"Compared to v1 and v2, we expanded this method to VQA. And it proved\n  that our method can be applied on more general image-text generation tasks"},{"id":"http://arxiv.org/abs/2406.16307v1","updated":"2024-06-24T04:10:28Z","published":"2024-06-24T04:10:28Z","title":"Artistic-style text detector and a new Movie-Poster dataset","summary":"  Although current text detection algorithms demonstrate effectiveness in\ngeneral scenarios, their performance declines when confronted with\nartistic-style text featuring complex structures. This paper proposes a method\nthat utilizes Criss-Cross Attention and residual dense block to address the\nincomplete and misdiagnosis of artistic-style text detection by current\nalgorithms. Specifically, our method mainly consists of a feature extraction\nbackbone, a feature enhancement network, a multi-scale feature fusion module,\nand a boundary discrimination module. The feature enhancement network\nsignificantly enhances the model's perceptual capabilities in complex\nenvironments by fusing horizontal and vertical contextual information, allowing\nit to capture detailed features overlooked in artistic-style text. We\nincorporate residual dense block into the Feature Pyramid Network to suppress\nthe effect of background noise during feature fusion. Aiming to omit the\ncomplex post-processing, we explore a boundary discrimination module that\nguides the correct generation of boundary proposals. Furthermore, given that\nmovie poster titles often use stylized art fonts, we collected a Movie-Poster\ndataset to address the scarcity of artistic-style text data. Extensive\nexperiments demonstrate that our proposed method performs superiorly on the\nMovie-Poster dataset and produces excellent results on multiple benchmark\ndatasets. The code and the Movie-Poster dataset will be available at:\nhttps://github.com/biedaxiaohua/Artistic-style-text-detection\n","authors":["Aoxiang Ning","Yiting Wei","Minglong Xue","Senming Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.16307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11217v2","updated":"2024-06-24T03:55:30Z","published":"2024-06-17T05:23:18Z","title":"WeatherQA: Can Multimodal Language Models Reason about Severe Weather?","summary":"  Severe convective weather events, such as hail, tornadoes, and thunderstorms,\noften occur quickly yet cause significant damage, costing billions of dollars\nevery year. This highlights the importance of forecasting severe weather\nthreats hours in advance to better prepare meteorologists and residents in\nat-risk areas. Can modern large foundation models perform such forecasting?\nExisting weather benchmarks typically focus only on predicting time-series\nchanges in certain weather parameters (e.g., temperature, moisture) with\ntext-only features. In this work, we introduce WeatherQA, the first multimodal\ndataset designed for machines to reason about complex combinations of weather\nparameters (a.k.a., ingredients) and predict severe weather in real-world\nscenarios. The dataset includes over 8,000 (multi-images, text) pairs for\ndiverse severe weather events. Each pair contains rich information crucial for\nforecasting -- the images describe the ingredients capturing environmental\ninstability, surface observations, and radar reflectivity, and the text\ncontains forecast analyses written by human experts. With WeatherQA, we\nevaluate state-of-the-art vision language models, including GPT4, Claude3.5,\nGemini-1.5, and a fine-tuned Llama3-based VLM, by designing two challenging\ntasks: (1) multi-choice QA for predicting affected area and (2) classification\nof the development potential of severe convection. These tasks require deep\nunderstanding of domain knowledge (e.g., atmospheric dynamics) and complex\nreasoning over multimodal data (e.g., interactions between weather parameters).\nWe show a substantial gap between the strongest VLM, GPT4o, and human\nreasoning. Our comprehensive case study with meteorologists further reveals the\nweaknesses of the models, suggesting that better training and data integration\nare necessary to bridge this gap. WeatherQA link:\nhttps://github.com/chengqianma/WeatherQA.\n","authors":["Chengqian Ma","Zhanxiang Hua","Alexandra Anderson-Frey","Vikram Iyer","Xin Liu","Lianhui Qin"],"pdf_url":"https://arxiv.org/pdf/2406.11217v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.16301v1","updated":"2024-06-24T03:55:25Z","published":"2024-06-24T03:55:25Z","title":"UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos","summary":"  With the surge in the amount of video data, video summarization techniques,\nincluding visual-modal(VM) and textual-modal(TM) summarization, are attracting\nmore and more attention. However, unimodal summarization inevitably loses the\nrich semantics of the video. In this paper, we focus on a more comprehensive\nvideo summarization task named Bimodal Semantic Summarization of Videos\n(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in\n(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing\nmethods, our construction procedure contains a VM-Summary extraction algorithm\naiming to preserve the most salient content within long videos. Based on BIDS,\nwe propose a Unified framework UBiSS for the BiSSV task, which models the\nsaliency information in the video and generates a TM-summary and VM-summary\nsimultaneously. We further optimize our model with a list-wise ranking-based\nobjective to improve its capacity to capture highlights. Lastly, we propose a\nmetric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.\nExperiments show that our unified framework achieves better performance than\nmulti-stage summarization pipelines. Code and data are available at\nhttps://github.com/MeiYutingg/UBiSS.\n","authors":["Yuting Mei","Linli Yao","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.16301v1.pdf","comment":"Accepted by ACM International Conference on Multimedia Retrieval\n  (ICMR'24)"},{"id":"http://arxiv.org/abs/2406.16297v1","updated":"2024-06-24T03:49:52Z","published":"2024-06-24T03:49:52Z","title":"Priorformer: A UGC-VQA Method with content and distortion priors","summary":"  User Generated Content (UGC) videos are susceptible to complicated and\nvariant degradations and contents, which prevents the existing blind video\nquality assessment (BVQA) models from good performance since the lack of the\nadapability of distortions and contents. To mitigate this, we propose a novel\nprior-augmented perceptual vision transformer (PriorFormer) for the BVQA of\nUGC, which boots its adaptability and representation capability for divergent\ncontents and distortions. Concretely, we introduce two powerful priors, i.e.,\nthe content and distortion priors, by extracting the content and distortion\nembeddings from two pre-trained feature extractors. Then we adopt these two\npowerful embeddings as the adaptive prior tokens, which are transferred to the\nvision transformer backbone jointly with implicit quality features. Based on\nthe above strategy, the proposed PriorFormer achieves state-of-the-art\nperformance on three public UGC VQA datasets including KoNViD-1K, LIVE-VQC and\nYouTube-UGC.\n","authors":["Yajing Pei","Shiyu Huang","Yiting Lu","Xin Li","Zhibo Chen"],"pdf_url":"https://arxiv.org/pdf/2406.16297v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2406.16289v1","updated":"2024-06-24T03:30:20Z","published":"2024-06-24T03:30:20Z","title":"Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D\n  Street View Reconstruction","summary":"  Recently, Neural Radiance Fields (NeRF) achieved impressive results in novel\nview synthesis. Block-NeRF showed the capability of leveraging NeRF to build\nlarge city-scale models. For large-scale modeling, a mass of image data is\nnecessary. Collecting images from specially designed data-collection vehicles\ncan not support large-scale applications. How to acquire massive high-quality\ndata remains an opening problem. Noting that the automotive industry has a huge\namount of image data, crowd-sourcing is a convenient way for large-scale data\ncollection. In this paper, we present a crowd-sourced framework, which utilizes\nsubstantial data captured by production vehicles to reconstruct the scene with\nthe NeRF model. This approach solves the key problem of large-scale\nreconstruction, that is where the data comes from and how to use them. Firstly,\nthe crowd-sourced massive data is filtered to remove redundancy and keep a\nbalanced distribution in terms of time and space. Then a structure-from-motion\nmodule is performed to refine camera poses. Finally, images, as well as poses,\nare used to train the NeRF model in a certain block. We highlight that we\npresent a comprehensive framework that integrates multiple modules, including\ndata selection, sparse 3D reconstruction, sequence appearance embedding, depth\nsupervision of ground surface, and occlusion completion. The complete system is\ncapable of effectively processing and reconstructing high-quality 3D scenes\nfrom crowd-sourced data. Extensive quantitative and qualitative experiments\nwere conducted to validate the performance of our system. Moreover, we proposed\nan application, named first-view navigation, which leveraged the NeRF model to\ngenerate 3D street view and guide the driver with a synthesized video.\n","authors":["Tong Qin","Changze Li","Haoyang Ye","Shaowei Wan","Minzhen Li","Hongwei Liu","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2406.16289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03876v2","updated":"2024-06-24T03:19:39Z","published":"2024-04-05T03:51:19Z","title":"Accurately Classifying Out-Of-Distribution Data in Facial Recognition","summary":"  Standard classification theory assumes that the distribution of images in the\ntest and training sets are identical. Unfortunately, real-life scenarios\ntypically feature unseen data (\"out-of-distribution data\") which is different\nfrom data in the training distribution(\"in-distribution\"). This issue is most\nprevalent in social justice problems where data from under-represented groups\nmay appear in the test data without representing an equal proportion of the\ntraining data. This may result in a model returning confidently wrong decisions\nand predictions. We are interested in the following question: Can the\nperformance of a neural network improve on facial images of out-of-distribution\ndata when it is trained simultaneously on multiple datasets of in-distribution\ndata? We approach this problem by incorporating the Outlier Exposure model and\ninvestigate how the model's performance changes when other datasets of facial\nimages were implemented. We observe that the accuracy and other metrics of the\nmodel can be increased by applying Outlier Exposure, incorporating a trainable\nweight parameter to increase the machine's emphasis on outlier images, and by\nre-weighting the importance of different class labels. We also experimented\nwith whether sorting the images and determining outliers via image features\nwould have more of an effect on the metrics than sorting by average pixel\nvalue. Our goal was to make models not only more accurate but also more fair by\nscanning a more expanded range of images. We also tested the datasets in\nreverse order to see whether a more fair dataset with balanced features has an\neffect on the model's accuracy.\n","authors":["Gianluca Barone","Aashrit Cunchala","Rudy Nunez"],"pdf_url":"https://arxiv.org/pdf/2404.03876v2.pdf","comment":"18 pages, 6 tables, 6 figures"},{"id":"http://arxiv.org/abs/2406.16279v1","updated":"2024-06-24T03:01:08Z","published":"2024-06-24T03:01:08Z","title":"SegNet4D: Effective and Efficient 4D LiDAR Semantic Segmentation in\n  Autonomous Driving Environments","summary":"  4D LiDAR semantic segmentation, also referred to as multi-scan semantic\nsegmentation, plays a crucial role in enhancing the environmental understanding\ncapabilities of autonomous vehicles. It entails identifying the semantic\ncategory of each point in the LiDAR scan and distinguishing whether it is\ndynamic, a critical aspect in downstream tasks such as path planning and\nautonomous navigation. Existing methods for 4D semantic segmentation often rely\non computationally intensive 4D convolutions for multi-scan input, resulting in\npoor real-time performance. In this article, we introduce SegNet4D, a novel\nreal-time multi-scan semantic segmentation method leveraging a projection-based\napproach for fast motion feature encoding, showcasing outstanding performance.\nSegNet4D treats 4D semantic segmentation as two distinct tasks: single-scan\nsemantic segmentation and moving object segmentation, each addressed by\ndedicated head. These results are then fused in the proposed motion-semantic\nfusion module to achieve comprehensive multi-scan semantic segmentation.\nBesides, we propose extracting instance information from the current scan and\nincorporating it into the network for instance-aware segmentation. Our approach\nexhibits state-of-the-art performance across multiple datasets and stands out\nas a real-time multi-scan semantic segmentation method. The implementation of\nSegNet4D will be made available at\n\\url{https://github.com/nubot-nudt/SegNet4D}.\n","authors":["Neng Wang","Ruibin Guo","Chenghao Shi","Hui Zhang","Huimin Lu","Zhiqiang Zheng","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2406.16279v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.16273v1","updated":"2024-06-24T02:40:26Z","published":"2024-06-24T02:40:26Z","title":"YouDream: Generating Anatomically Controllable Consistent Text-to-3D\n  Animals","summary":"  3D generation guided by text-to-image diffusion models enables the creation\nof visually compelling assets. However previous methods explore generation\nbased on image or text. The boundaries of creativity are limited by what can be\nexpressed through words or the images that can be sourced. We present YouDream,\na method to generate high-quality anatomically controllable animals. YouDream\nis guided using a text-to-image diffusion model controlled by 2D views of a 3D\npose prior. Our method generates 3D animals that are not possible to create\nusing previous text-to-3D generative methods. Additionally, our method is\ncapable of preserving anatomic consistency in the generated animals, an area\nwhere prior text-to-3D approaches often struggle. Moreover, we design a fully\nautomated pipeline for generating commonly found animals. To circumvent the\nneed for human intervention to create a 3D pose, we propose a multi-agent LLM\nthat adapts poses from a limited library of animal 3D poses to represent the\ndesired animal. A user study conducted on the outcomes of YouDream demonstrates\nthe preference of the animal models generated by our method over others.\nTurntable results and code are released at https://youdream3d.github.io/\n","authors":["Sandeep Mishra","Oindrila Saha","Alan C. Bovik"],"pdf_url":"https://arxiv.org/pdf/2406.16273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16272v1","updated":"2024-06-24T02:38:30Z","published":"2024-06-24T02:38:30Z","title":"Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via\n  Attention-Guided Feature Enhancement","summary":"  Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention\nfor their ability to generate high-quality images from textual descriptions.\nHowever, these models often produce images that do not fully align with the\ninput prompts, resulting in semantic inconsistencies. The most prominent issue\namong these semantic inconsistencies is catastrophic-neglect, where the images\ngenerated by T2I DMs miss key objects mentioned in the prompt. We first conduct\nan empirical study on this issue, exploring the prevalence of\ncatastrophic-neglect, potential mitigation strategies with feature enhancement,\nand the insights gained. Guided by the empirical findings, we propose an\nautomated repair approach named Patcher to address catastrophic-neglect in T2I\nDMs. Specifically, Patcher first determines whether there are any neglected\nobjects in the prompt, and then applies attention-guided feature enhancement to\nthese neglected objects, resulting in a repaired prompt. Experimental results\non three versions of Stable Diffusion demonstrate that Patcher effectively\nrepairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct\nRate in image generation compared to baselines.\n","authors":["Zhiyuan Chang","Mingyang Li","Junjie Wang","Yi Liu","Qing Wang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16272v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2406.16271v1","updated":"2024-06-24T02:33:46Z","published":"2024-06-24T02:33:46Z","title":"Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt\n  Engineering for Glomerular Basement Membrane Segmentation","summary":"  Assessment of the glomerular basement membrane (GBM) in transmission electron\nmicroscopy (TEM) is crucial for diagnosing chronic kidney disease (CKD). The\nlack of domain-independent automatic segmentation tools for the GBM\nnecessitates an AI-based solution to automate the process. In this study, we\nintroduce GBMSeg, a training-free framework designed to automatically segment\nthe GBM in TEM images guided only by a one-shot annotated reference.\nSpecifically, GBMSeg first exploits the robust feature matching capabilities of\nthe pretrained foundation model to generate initial prompt points, then\nintroduces a series of novel automatic prompt engineering techniques across the\nfeature and physical space to optimize the prompt scheme. Finally, GBMSeg\nemploys a class-agnostic foundation segmentation model with the generated\nprompt scheme to obtain accurate segmentation results. Experimental results on\nour collected 2538 TEM images confirm that GBMSeg achieves superior\nsegmentation performance with a Dice similarity coefficient (DSC) of 87.27%\nusing only one labeled reference image in a training-free manner, outperforming\nrecently proposed one-shot or few-shot methods. In summary, GBMSeg introduces a\ndistinctive automatic prompt framework that facilitates robust\ndomain-independent segmentation performance without training, particularly\nadvancing the automatic prompting of foundation segmentation models for medical\nimages. Future work involves automating the thickness measurement of segmented\nGBM and quantifying pathological indicators, holding significant potential for\nadvancing pathology assessments in clinical applications. The source code is\navailable on https://github.com/SnowRain510/GBMSeg\n","authors":["Xueyu Liu","Guangze Shi","Rui Wang","Yexin Lai","Jianan Zhang","Lele Sun","Quan Yang","Yongfei Wu","MIng Li","Weixia Han","Wen Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.16271v1.pdf","comment":"Accepted for MICCAI2024"},{"id":"http://arxiv.org/abs/2401.12900v5","updated":"2024-06-24T02:30:09Z","published":"2024-01-23T16:40:47Z","title":"PSAvatar: A Point-based Shape Model for Real-Time Head Avatar Animation\n  with 3D Gaussian Splatting","summary":"  Despite much progress, achieving real-time high-fidelity head avatar\nanimation is still difficult and existing methods have to trade-off between\nspeed and quality. 3DMM based methods often fail to model non-facial structures\nsuch as eyeglasses and hairstyles, while neural implicit models suffer from\ndeformation inflexibility and rendering inefficiency. Although 3D Gaussian has\nbeen demonstrated to possess promising capability for geometry representation\nand radiance field reconstruction, applying 3D Gaussian in head avatar creation\nremains a major challenge since it is difficult for 3D Gaussian to model the\nhead shape variations caused by changing poses and expressions. In this paper,\nwe introduce PSAvatar, a novel framework for animatable head avatar creation\nthat utilizes discrete geometric primitive to create a parametric morphable\nshape model and employs 3D Gaussian for fine detail representation and high\nfidelity rendering. The parametric morphable shape model is a Point-based\nMorphable Shape Model (PMSM) which uses points instead of meshes for 3D\nrepresentation to achieve enhanced representation flexibility. The PMSM first\nconverts the FLAME mesh to points by sampling on the surfaces as well as off\nthe meshes to enable the reconstruction of not only surface-like structures but\nalso complex geometries such as eyeglasses and hairstyles. By aligning these\npoints with the head shape in an analysis-by-synthesis manner, the PMSM makes\nit possible to utilize 3D Gaussian for fine detail representation and\nappearance modeling, thus enabling the creation of high-fidelity avatars. We\nshow that PSAvatar can reconstruct high-fidelity head avatars of a variety of\nsubjects and the avatars can be animated in real-time ($\\ge$ 25 fps at a\nresolution of 512 $\\times$ 512 ).\n","authors":["Zhongyuan Zhao","Zhenyu Bao","Qing Li","Guoping Qiu","Kanglin Liu"],"pdf_url":"https://arxiv.org/pdf/2401.12900v5.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2308.07269v3","updated":"2024-06-24T02:17:57Z","published":"2023-08-14T16:52:42Z","title":"EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language\n  Models","summary":"  Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy\nissues, which means they are unaware of unseen events or generate text with\nincorrect facts owing to outdated/noisy data. To this end, many knowledge\nediting approaches for LLMs have emerged -- aiming to subtly inject/edit\nupdated knowledge or adjust undesired behavior while minimizing the impact on\nunrelated inputs. Nevertheless, due to significant differences among various\nknowledge editing methods and the variations in task setups, there is no\nstandard implementation framework available for the community, which hinders\npractitioners from applying knowledge editing to applications. To address these\nissues, we propose EasyEdit, an easy-to-use knowledge editing framework for\nLLMs. It supports various cutting-edge knowledge editing approaches and can be\nreadily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc.\nEmpirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,\ndemonstrating that knowledge editing surpasses traditional fine-tuning in terms\nof reliability and generalization. We have released the source code on GitHub,\nalong with Google Colab tutorials and comprehensive documentation for beginners\nto get started. Besides, we present an online system for real-time knowledge\nediting, and a demo video.\n","authors":["Peng Wang","Ningyu Zhang","Bozhong Tian","Zekun Xi","Yunzhi Yao","Ziwen Xu","Mengru Wang","Shengyu Mao","Xiaohan Wang","Siyuan Cheng","Kangwei Liu","Yuansheng Ni","Guozhou Zheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2308.07269v3.pdf","comment":"ACL 2024 System Demonstrations; Code:\n  https://github.com/zjunlp/EasyEdit HF Demo:\n  https://huggingface.co/spaces/zjunlp/EasyEdit Video:\n  https://youtu.be/Gm6T0QaaskU Docs: https://zjunlp.gitbook.io/easyedit"},{"id":"http://arxiv.org/abs/2406.04341v2","updated":"2024-06-24T02:14:18Z","published":"2024-06-06T17:59:52Z","title":"Interpreting the Second-Order Effects of Neurons in CLIP","summary":"  We interpret the function of individual neurons in CLIP by automatically\ndescribing them using text. Analyzing the direct effects (i.e. the flow from a\nneuron through the residual stream to the output) or the indirect effects\n(overall contribution) fails to capture the neurons' function in CLIP.\nTherefore, we present the \"second-order lens\", analyzing the effect flowing\nfrom a neuron through the later attention heads, directly to the output. We\nfind that these effects are highly selective: for each neuron, the effect is\nsignificant for <2% of the images. Moreover, each effect can be approximated by\na single direction in the text-image space of CLIP. We describe neurons by\ndecomposing these directions into sparse sets of text representations. The sets\nreveal polysemantic behavior - each neuron corresponds to multiple, often\nunrelated, concepts (e.g. ships and cars). Exploiting this neuron polysemy, we\nmass-produce \"semantic\" adversarial examples by generating images with concepts\nspuriously correlated to the incorrect class. Additionally, we use the\nsecond-order effects for zero-shot segmentation and attribute discovery in\nimages. Our results indicate that a scalable understanding of neurons can be\nused for model deception and for introducing new model capabilities.\n","authors":["Yossi Gandelsman","Alexei A. Efros","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2406.04341v2.pdf","comment":"project page:\n  https://yossigandelsman.github.io/clip_neurons/index.html"},{"id":"http://arxiv.org/abs/2406.16260v1","updated":"2024-06-24T01:56:12Z","published":"2024-06-24T01:56:12Z","title":"Video-Infinity: Distributed Long Video Generation","summary":"  Diffusion models have recently achieved remarkable results for video\ngeneration. Despite the encouraging performances, the generated videos are\ntypically constrained to a small number of frames, resulting in clips lasting\nmerely a few seconds. The primary challenges in producing longer videos include\nthe substantial memory requirements and the extended processing time required\non a single GPU. A straightforward solution would be to split the workload\nacross multiple GPUs, which, however, leads to two issues: (1) ensuring all\nGPUs communicate effectively to share timing and context information, and (2)\nmodifying existing video diffusion models, which are usually trained on short\nsequences, to create longer videos without additional training. To tackle\nthese, in this paper we introduce Video-Infinity, a distributed inference\npipeline that enables parallel processing across multiple GPUs for long-form\nvideo generation. Specifically, we propose two coherent mechanisms: Clip\nparallelism and Dual-scope attention. Clip parallelism optimizes the gathering\nand sharing of context information across GPUs which minimizes communication\noverhead, while Dual-scope attention modulates the temporal self-attention to\nbalance local and global contexts efficiently across the devices. Together, the\ntwo mechanisms join forces to distribute the workload and enable the fast\ngeneration of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our\nmethod generates videos up to 2,300 frames in approximately 5 minutes, enabling\nlong video generation at a speed 100 times faster than the prior methods.\n","authors":["Zhenxiong Tan","Xingyi Yang","Songhua Liu","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17137v2","updated":"2024-06-24T01:42:55Z","published":"2023-11-28T18:59:02Z","title":"Intrinsic LoRA: A Generalist Approach for Discovering Knowledge in\n  Generative Models","summary":"  Generative models excel at creating images that closely mimic real scenes,\nsuggesting they inherently encode scene representations. We introduce Intrinsic\nLoRA (I-LoRA), a general approach that uses Low-Rank Adaptation (LoRA) to\ndiscover scene intrinsics such as normals, depth, albedo, and shading from a\nwide array of generative models. I-LoRA is lightweight, adding minimally to the\nmodel's parameters and requiring very small datasets for this knowledge\ndiscovery. Our approach, applicable to Diffusion models, GANs, and\nAutoregressive models alike, generates intrinsics using the same output head as\nthe original images. Through control experiments, we establish a correlation\nbetween the generative model's quality and the extracted intrinsics' accuracy.\nFinally, scene intrinsics obtained by our method with just hundreds to\nthousands of labeled images, perform on par with those from supervised methods\ntrained on millions of labeled examples.\n","authors":["Xiaodan Du","Nicholas Kolkin","Greg Shakhnarovich","Anand Bhattad"],"pdf_url":"https://arxiv.org/pdf/2311.17137v2.pdf","comment":"https://intrinsic-lora.github.io/"},{"id":"http://arxiv.org/abs/2405.04309v2","updated":"2024-06-24T01:30:48Z","published":"2024-05-07T13:33:50Z","title":"Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment\n  and Spatially-variant Deformation Modeling","summary":"  Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively\nstudied and great progress has been made, there are still key challenges that\nhinder their broad real-world applications: 1) the inherent motion/rotation\nambiguity requires either explicit camera motion recovery with extra constraint\nor complex Procrustean Alignment; 2) existing low-rank modeling of the global\nshape can over-penalize drastic deformations in the 3D shape sequence. This\npaper proposes to resolve the above issues from a spatial-temporal modeling\nperspective. First, we propose a novel Temporally-smooth Procrustean Alignment\nmodule that estimates 3D deforming shapes and adjusts the camera motion by\naligning the 3D shape sequence consecutively. Our new alignment module remedies\nthe requirement of complex reference 3D shape during alignment, which is more\nconductive to non-isotropic deformation modeling. Second, we propose a\nspatial-weighted approach to enforce the low-rank constraint adaptively at\ndifferent locations to accommodate drastic spatially-variant deformation\nreconstruction better. Our modeling outperform existing low-rank based methods,\nand extensive experiments across different datasets validate the effectiveness\nof our method.\n","authors":["Jiawei Shi","Hui Deng","Yuchao Dai"],"pdf_url":"https://arxiv.org/pdf/2405.04309v2.pdf","comment":"Accepted by CVPR 2024; V2 adds new experiments"},{"id":"http://arxiv.org/abs/2402.09801v2","updated":"2024-06-24T00:50:58Z","published":"2024-02-15T08:58:03Z","title":"EFUF: Efficient Fine-grained Unlearning Framework for Mitigating\n  Hallucinations in Multimodal Large Language Models","summary":"  Multimodal large language models (MLLMs) have attracted increasing attention\nin the past few years, but they may still generate descriptions that include\nobjects not present in the corresponding images, a phenomenon known as object\nhallucination. To eliminate hallucinations, existing methods manually annotate\npaired responses with and without hallucinations, and then employ various\nalignment algorithms to improve the alignment capability between images and\ntext. However, they not only demand considerable computation resources during\nthe finetuning stage but also require expensive human annotation to construct\npaired data needed by the alignment algorithms. To address these issues, we\nborrow the idea of unlearning and propose an efficient fine-grained unlearning\nframework (EFUF), which can eliminate hallucinations without the need for\npaired data. Extensive experiments show that our method consistently reduces\nhallucinations while preserving the generation quality with modest\ncomputational overhead. Our code and datasets will be publicly available.\n","authors":["Shangyu Xing","Fei Zhao","Zhen Wu","Tuo An","Weihao Chen","Chunhui Li","Jianbing Zhang","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2402.09801v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04929v2","updated":"2024-06-24T00:37:16Z","published":"2024-02-07T14:56:13Z","title":"Source-Free Domain Adaptation with Diffusion-Guided Source Data\n  Generation","summary":"  This paper introduces a novel approach to leverage the generalizability of\nDiffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed\nDMSFDA method involves fine-tuning a pre-trained text-to-image diffusion model\nto generate source domain images using features from the target images to guide\nthe diffusion process. Specifically, the pre-trained diffusion model is\nfine-tuned to generate source samples that minimize entropy and maximize\nconfidence for the pre-trained source model. We then use a diffusion\nmodel-based image mixup strategy to bridge the domain gap between the source\nand target domains. We validate our approach through comprehensive experiments\nacross a range of datasets, including Office-31 [39], Office-Home [48], and\nVisDA [35]. The results demonstrate significant improvements in SFDA\nperformance, highlighting the potential of diffusion models in generating\ncontextually relevant, domain-specific images.\n","authors":["Shivang Chopra","Suraj Kothawade","Houda Aynaou","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2402.04929v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2310.01701"},{"id":"http://arxiv.org/abs/2406.17183v1","updated":"2024-06-24T23:43:08Z","published":"2024-06-24T23:43:08Z","title":"POPCat: Propagation of particles for complex annotation tasks","summary":"  Novel dataset creation for all multi-object tracking, crowd-counting, and\nindustrial-based videos is arduous and time-consuming when faced with a unique\nclass that densely populates a video sequence. We propose a time efficient\nmethod called POPCat that exploits the multi-target and temporal features of\nvideo data to produce a semi-supervised pipeline for segmentation or box-based\nvideo annotation. The method retains the accuracy level associated with human\nlevel annotation while generating a large volume of semi-supervised annotations\nfor greater generalization. The method capitalizes on temporal features through\nthe use of a particle tracker to expand the domain of human-provided target\npoints. This is done through the use of a particle tracker to reassociate the\ninitial points to a set of images that follow the labeled frame. A YOLO model\nis then trained with this generated data, and then rapidly infers on the target\nvideo. Evaluations are conducted on GMOT-40, AnimalTrack, and Visdrone-2019\nbenchmarks. These multi-target video tracking/detection sets contain multiple\nsimilar-looking targets, camera movements, and other features that would\ncommonly be seen in \"wild\" situations. We specifically choose these difficult\ndatasets to demonstrate the efficacy of the pipeline and for comparison\npurposes. The method applied on GMOT-40, AnimalTrack, and Visdrone shows a\nmargin of improvement on recall/mAP50/mAP over the best results by a value of\n24.5%/9.6%/4.8%, -/43.1%/27.8%, and 7.5%/9.4%/7.5% where metrics were\ncollected.\n","authors":["Adam Srebrnjak Yang","Dheeraj Khanna","John S. Zelek"],"pdf_url":"https://arxiv.org/pdf/2406.17183v1.pdf","comment":"10 pages, 5 figures, Accepted in \"Conference on Robots and Vision\n  2024\""},{"id":"http://arxiv.org/abs/2403.19651v2","updated":"2024-06-24T23:41:29Z","published":"2024-03-28T17:59:20Z","title":"MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions","summary":"  Image retrieval, i.e., finding desired images given a reference image,\ninherently encompasses rich, multi-faceted search intents that are difficult to\ncapture solely using image-based measures. Recent works leverage text\ninstructions to allow users to more freely express their search intents.\nHowever, they primarily focus on image pairs that are visually similar and/or\ncan be characterized by a small set of pre-defined relations. The core thesis\nof this paper is that text instructions can enable retrieving images with\nricher relations beyond visual similarity. To show this, we introduce\nMagicLens, a series of self-supervised image retrieval models that support\nopen-ended instructions. MagicLens is built on a key novel insight: image pairs\nthat naturally occur on the same web pages contain a wide range of implicit\nrelations (e.g., inside view of), and we can bring those implicit relations\nexplicit by synthesizing instructions via foundation models. Trained on 36.7M\n(query image, instruction, target image) triplets with rich semantic relations\nmined from the web, MagicLens achieves results comparable with or better than\nprior best on eight benchmarks of various image retrieval tasks, while\nmaintaining high parameter efficiency with a significantly smaller model size.\nAdditional human analyses on a 1.4M-image unseen corpus further demonstrate the\ndiversity of search intents supported by MagicLens. Code and models are\npublicly available at https://open-vision-language.github.io/MagicLens/.\n","authors":["Kai Zhang","Yi Luan","Hexiang Hu","Kenton Lee","Siyuan Qiao","Wenhu Chen","Yu Su","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2403.19651v2.pdf","comment":"ICML 2024 (Oral); Project Website:\n  https://open-vision-language.github.io/MagicLens/"},{"id":"http://arxiv.org/abs/2406.17173v1","updated":"2024-06-24T23:23:18Z","published":"2024-06-24T23:23:18Z","title":"Diff3Dformer: Leveraging Slice Sequence Diffusion for Enhanced 3D CT\n  Classification with Transformer Networks","summary":"  The manifestation of symptoms associated with lung diseases can vary in\ndifferent depths for individual patients, highlighting the significance of 3D\ninformation in CT scans for medical image classification. While Vision\nTransformer has shown superior performance over convolutional neural networks\nin image classification tasks, their effectiveness is often demonstrated on\nsufficiently large 2D datasets and they easily encounter overfitting issues on\nsmall medical image datasets. To address this limitation, we propose a\nDiffusion-based 3D Vision Transformer (Diff3Dformer), which utilizes the latent\nspace of the Diffusion model to form the slice sequence for 3D analysis and\nincorporates clustering attention into ViT to aggregate repetitive information\nwithin 3D CT scans, thereby harnessing the power of the advanced transformer in\n3D classification tasks on small datasets. Our method exhibits improved\nperformance on two different scales of small datasets of 3D lung CT scans,\nsurpassing the state of the art 3D methods and other transformer-based\napproaches that emerged during the COVID-19 pandemic, demonstrating its robust\nand superior performance across different scales of data. Experimental results\nunderscore the superiority of our proposed method, indicating its potential for\nenhancing medical image classification tasks in real-world scenarios.\n","authors":["Zihao Jin","Yingying Fang","Jiahao Huang","Caiwen Xu","Simon Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.17173v1.pdf","comment":"conference"},{"id":"http://arxiv.org/abs/2404.03118v3","updated":"2024-06-24T22:45:20Z","published":"2024-04-03T23:57:34Z","title":"LVLM-Interpret: An Interpretability Tool for Large Vision-Language\n  Models","summary":"  In the rapidly evolving landscape of artificial intelligence, multi-modal\nlarge language models are emerging as a significant area of interest. These\nmodels, which combine various forms of data input, are becoming increasingly\npopular. However, understanding their internal mechanisms remains a complex\ntask. Numerous advancements have been made in the field of explainability tools\nand mechanisms, yet there is still much to explore. In this work, we present a\nnovel interactive application aimed towards understanding the internal\nmechanisms of large vision-language models. Our interface is designed to\nenhance the interpretability of the image patches, which are instrumental in\ngenerating an answer, and assess the efficacy of the language model in\ngrounding its output in the image. With our application, a user can\nsystematically investigate the model and uncover system limitations, paving the\nway for enhancements in system capabilities. Finally, we present a case study\nof how our application can aid in understanding failure mechanisms in a popular\nlarge multi-modal model: LLaVA.\n","authors":["Gabriela Ben Melech Stan","Estelle Aflalo","Raanan Yehezkel Rohekar","Anahita Bhiwandiwalla","Shao-Yen Tseng","Matthew Lyle Olson","Yaniv Gurwicz","Chenfei Wu","Nan Duan","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2404.03118v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17162v1","updated":"2024-06-24T22:29:30Z","published":"2024-06-24T22:29:30Z","title":"Virtual Mines -- Component-level recycling of printed circuit boards\n  using deep learning","summary":"  This contribution gives an overview of an ongoing project using machine\nlearning and computer vision components for improving the electronic waste\nrecycling process. In circular economy, the \"virtual mines\" concept refers to\nproduction cycles where interesting raw materials are reclaimed in an efficient\nand cost-effective manner from end-of-life items. In particular, the growth of\ne-waste, due to the increasingly shorter life cycle of hi-tech goods, is a\nglobal problem. In this paper, we describe a pipeline based on deep learning\nmodel to recycle printed circuit boards at the component level. A pre-trained\nYOLOv5 model is used to analyze the results of the locally developed dataset.\nWith a different distribution of class instances, YOLOv5 managed to achieve\nsatisfactory precision and recall, with the ability to optimize with large\ncomponent instances.\n","authors":["Muhammad Mohsin","Stefano Rovetta","Francesco Masulli","Alberto Cabri"],"pdf_url":"https://arxiv.org/pdf/2406.17162v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17148v1","updated":"2024-06-24T21:38:36Z","published":"2024-06-24T21:38:36Z","title":"Unambiguous Recognition Should Not Rely Solely on Natural Language\n  Training","summary":"  In LaTeX text recognition using Transformer-based architectures, this paper\nidentifies certain \"bias\" issues. For instance, $e-t$ is frequently\nmisrecognized as $e^{-t}$. This bias stems from the inherent characteristics of\nthe dataset. To mitigate this bias, we propose a LaTeX printed text recognition\nmodel trained on a mixed dataset of pseudo-formulas and pseudo-text. The model\nemploys a Swin Transformer as the encoder and a RoBERTa model as the decoder.\nExperimental results demonstrate that this approach reduces \"bias\", enhancing\nthe accuracy and robustness of text recognition. For clear images, the model\nstrictly adheres to the image content; for blurred images, it integrates both\nimage and contextual information to produce reasonable recognition results.\n","authors":["Renqing Luo","Yuhan Xu"],"pdf_url":"https://arxiv.org/pdf/2406.17148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02424v2","updated":"2024-06-24T21:37:45Z","published":"2024-04-03T03:27:01Z","title":"Rethinking Pruning for Vision-Language Models: Strategies for Effective\n  Sparsity and Performance Restoration","summary":"  Vision-Language Models (VLMs) integrate information from multiple modalities\nand have shown remarkable success across various tasks. However, deploying\nlarge-scale VLMs in resource-constrained scenarios is challenging. Pruning\nfollowed by finetuning offers a potential solution but remains underexplored\nfor VLMs. This study addresses two key questions: how to distribute sparsity\nacross different modality-specific models, and how to restore the performance\nof pruned sparse VLMs. Our preliminary studies identified two effective pruning\nsettings: applying the same sparsity to both vision and language models, and\npruning only the language models. While LoRA finetuning aims to restore sparse\nmodels, it faces challenges due to incompatibility with sparse models,\ndisrupting the pruned sparsity. To overcome these issues, we propose\nSparseLoRA, which applies sparsity directly to LoRA weights. Our experimental\nresults demonstrate significant improvements, including an 11.3\\% boost under\n2:4 sparsity and a 47.6\\% enhancement under unstructured 70\\% sparsity. Code is\nreleased at: \\url{https://github.com/Shwai-He/VLM-Compression}.\n","authors":["Shwai He","Ang Li","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.02424v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17146v1","updated":"2024-06-24T21:36:01Z","published":"2024-06-24T21:36:01Z","title":"Vastextures: Vast repository of textures and PBR materials extracted\n  from real-world images using unsupervised methods","summary":"  Vastextures is a vast repository of 500,000 textures and PBR materials\nextracted from real-world images using an unsupervised process. The extracted\nmaterials and textures are extremely diverse and cover a vast range of\nreal-world patterns, but at the same time less refined compared to existing\nrepositories. The repository is composed of 2D textures cropped from natural\nimages and SVBRDF/PBR materials generated from these textures. Textures and PBR\nmaterials are essential for CGI. Existing materials repositories focus on\ngames, animation, and arts, that demand a limited amount of high-quality\nassets. However, virtual worlds and synthetic data are becoming increasingly\nimportant for training A.I systems for computer vision. This application\ndemands a huge amount of diverse assets but at the same time less affected by\nnoisy and unrefined assets. Vastexture aims to address this need by creating a\nfree, huge, and diverse assets repository that covers as many real-world\nmaterials as possible. The materials are automatically extracted from natural\nimages in two steps: 1) Automatically scanning a giant amount of images to\nidentify and crop regions with uniform textures. This is done by splitting the\nimage into a grid of cells and identifying regions in which all of the cells\nshare a similar statistical distribution. 2) Extracting the properties of the\nPBR material from the cropped texture. This is done by randomly guessing every\ncorrelation between the properties of the texture image and the properties of\nthe PBR material. The resulting PBR materials exhibit a vast amount of\nreal-world patterns as well as unexpected emergent properties. Neutral nets\ntrained on this repository outperformed nets trained using handcrafted assets.\n","authors":["Sagi Eppel"],"pdf_url":"https://arxiv.org/pdf/2406.17146v1.pdf","comment":"Vastexture was published as part of Learning Zero-Shot Material\n  States Segmentation, by Implanting Natural Image Patterns in Synthetic Data,\n  refer to this work in citations. This document gives a more detailed and\n  technical discussion of this repository"},{"id":"http://arxiv.org/abs/2406.13875v2","updated":"2024-06-24T20:31:00Z","published":"2024-06-19T22:37:42Z","title":"WATT: Weight Average Test-Time Adaptation of CLIP","summary":"  Vision-Language Models (VLMs) such as CLIP have yielded unprecedented\nperformance for zero-shot image classification, yet their generalization\ncapability may still be seriously challenged when confronted to domain shifts.\nIn response, we present Weight Average Test-Time Adaptation (WATT) of CLIP, a\npioneering approach facilitating full test-time adaptation (TTA) of this VLM.\nOur method employs a diverse set of templates for text prompts, augmenting the\nexisting framework of CLIP. Predictions are utilized as pseudo labels for model\nupdates, followed by weight averaging to consolidate the learned information\nglobally. Furthermore, we introduce a text ensemble strategy, enhancing overall\ntest performance by aggregating diverse textual cues. Our findings underscore\nthe efficacy of WATT in enhancing performance across diverse datasets,\nincluding CIFAR-10-C, CIFAR-10.1, CIFAR-100-C, VisDA-C, and several other\nchallenging datasets, effectively covering a wide range of domain shifts.\nNotably, these enhancements are achieved without necessitating additional model\ntransformations or trainable modules. Moreover, compared to other Test-Time\nAdaptation methods, our approach can operate effectively with just a single\nimage. Highlighting the potential of innovative test-time strategies, this\nresearch emphasizes their role in fortifying the adaptability of VLMs. The\nimplementation is available at:\n\\url{https://github.com/Mehrdad-Noori/WATT.git}.\n","authors":["David Osowiechi","Mehrdad Noori","Gustavo Adolfo Vargas Hakim","Moslem Yazdanpanah","Ali Bahri","Milad Cheraghalikhani","Sahar Dastani","Farzad Beizaee","Ismail Ben Ayed","Christian Desrosiers"],"pdf_url":"https://arxiv.org/pdf/2406.13875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09457v4","updated":"2024-06-24T20:29:38Z","published":"2023-10-14T00:32:11Z","title":"UCM-Net: A Lightweight and Efficient Solution for Skin Lesion\n  Segmentation using MLP and CNN","summary":"  Skin cancer poses a significant public health challenge, necessitating\nefficient diagnostic tools. We introduce UCM-Net, a novel skin lesion\nsegmentation model combining Multi-Layer Perceptrons (MLP) and Convolutional\nNeural Networks (CNN). This lightweight, efficient architecture, deviating from\ntraditional UNet designs, dramatically reduces computational demands, making it\nideal for mobile health applications. Evaluated on PH2, ISIC 2017, and ISIC\n2018 datasets, UCM-Net demonstrates robust performance with fewer than 50KB\nparameters and requires less than 0.05 Giga Operations Per Second (GLOPs).\nMoreover, its minimal memory requirement is just 1.19MB in CPU environment\npositions. It is a potential benchmark for efficiency in skin lesion\nsegmentation, suitable for deployment in resource-constrained settings. In\norder to facilitate accessibility and further research in the field, the\nUCM-Net source code is https://github.com/chunyuyuan/UCM-Net.\n","authors":["Chunyu Yuan","Dongfang Zhao","Sos S. Agaian"],"pdf_url":"https://arxiv.org/pdf/2310.09457v4.pdf","comment":"17 pages, accepted by Journal of Biomedical Signal Processing and\n  Control"},{"id":"http://arxiv.org/abs/2406.17126v1","updated":"2024-06-24T20:29:16Z","published":"2024-06-24T20:29:16Z","title":"MM-SpuBench: Towards Better Understanding of Spurious Biases in\n  Multimodal LLMs","summary":"  Spurious bias, a tendency to use spurious correlations between non-essential\ninput attributes and target variables for predictions, has revealed a severe\nrobustness pitfall in deep learning models trained on single modality data.\nMultimodal Large Language Models (MLLMs), which integrate both vision and\nlanguage models, have demonstrated strong capability in joint vision-language\nunderstanding. However, whether spurious biases are prevalent in MLLMs remains\nunder-explored. We mitigate this gap by analyzing the spurious biases in a\nmultimodal setting, uncovering the specific test data patterns that can\nmanifest this problem when biases in the vision model cascade into the\nalignment between visual and text tokens in MLLMs. To better understand this\nproblem, we introduce MM-SpuBench, a comprehensive visual question-answering\n(VQA) benchmark designed to evaluate MLLMs' reliance on nine distinct\ncategories of spurious correlations from five open-source image datasets. The\nVQA dataset is built from human-understandable concept information\n(attributes). Leveraging this benchmark, we conduct a thorough evaluation of\ncurrent state-of-the-art MLLMs. Our findings illuminate the persistence of the\nreliance on spurious correlations from these models and underscore the urge for\nnew methodologies to mitigate spurious biases. To support the MLLM robustness\nresearch, we release our VQA benchmark at\nhttps://huggingface.co/datasets/mmbench/MM-SpuBench.\n","authors":["Wenqian Ye","Guangtao Zheng","Yunsheng Ma","Xu Cao","Bolin Lai","James M. Rehg","Aidong Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17119v1","updated":"2024-06-24T20:13:23Z","published":"2024-06-24T20:13:23Z","title":"Accelerating Phase Field Simulations Through a Hybrid Adaptive Fourier\n  Neural Operator with U-Net Backbone","summary":"  Prolonged contact between a corrosive liquid and metal alloys can cause\nprogressive dealloying. For such liquid-metal dealloying (LMD) process, phase\nfield models have been developed. However, the governing equations often\ninvolve coupled non-linear partial differential equations (PDE), which are\nchallenging to solve numerically. In particular, stiffness in the PDEs requires\nan extremely small time steps (e.g. $10^{-12}$ or smaller). This computational\nbottleneck is especially problematic when running LMD simulation until a late\ntime horizon is required. This motivates the development of surrogate models\ncapable of leaping forward in time, by skipping several consecutive time steps\nat-once. In this paper, we propose U-Shaped Adaptive Fourier Neural Operators\n(U-AFNO), a machine learning (ML) model inspired by recent advances in neural\noperator learning. U-AFNO employs U-Nets for extracting and reconstructing\nlocal features within the physical fields, and passes the latent space through\na vision transformer (ViT) implemented in the Fourier space (AFNO). We use\nU-AFNOs to learn the dynamics mapping the field at a current time step into a\nlater time step. We also identify global quantities of interest (QoI)\ndescribing the corrosion process (e.g. the deformation of the liquid-metal\ninterface) and show that our proposed U-AFNO model is able to accurately\npredict the field dynamics, in-spite of the chaotic nature of LMD. Our model\nreproduces the key micro-structure statistics and QoIs with a level of accuracy\non-par with the high-fidelity numerical solver. We also investigate the\nopportunity of using hybrid simulations, in which we alternate forward leap in\ntime using the U-AFNO with high-fidelity time stepping. We demonstrate that\nwhile advantageous for some surrogate model design choices, our proposed U-AFNO\nmodel in fully auto-regressive settings consistently outperforms hybrid\nschemes.\n","authors":["Christophe Bonneville","Nathan Bieberdorf","Arun Hegde","Mark Asta","Habib N. Najm","Laurent Capolungo","Cosmin Safta"],"pdf_url":"https://arxiv.org/pdf/2406.17119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17117v1","updated":"2024-06-24T20:11:46Z","published":"2024-06-24T20:11:46Z","title":"Speeding Up Image Classifiers with Little Companions","summary":"  Scaling up neural networks has been a key recipe to the success of large\nlanguage and vision models. However, in practice, up-scaled models can be\ndisproportionately costly in terms of computations, providing only marginal\nimprovements in performance; for example, EfficientViT-L3-384 achieves <2%\nimprovement on ImageNet-1K accuracy over the base L1-224 model, while requiring\n$14\\times$ more multiply-accumulate operations (MACs). In this paper, we\ninvestigate scaling properties of popular families of neural networks for image\nclassification, and find that scaled-up models mostly help with \"difficult\"\nsamples. Decomposing the samples by difficulty, we develop a simple\nmodel-agnostic two-pass Little-Big algorithm that first uses a light-weight\n\"little\" model to make predictions of all samples, and only passes the\ndifficult ones for the \"big\" model to solve. Good little companion achieve\ndrastic MACs reduction for a wide variety of model families and scales. Without\nloss of accuracy or modification of existing models, our Little-Big models\nachieve MACs reductions of 76% for EfficientViT-L3-384, 81% for\nEfficientNet-B7-600, 71% for DeiT3-L-384 on ImageNet-1K. Little-Big also speeds\nup the InternImage-G-512 model by 62% while achieving 90% ImageNet-1K top-1\naccuracy, serving both as a strong baseline and as a simple practical method\nfor large model compression.\n","authors":["Yang Liu","Kowshik Thopalli","Jayaraman Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2406.17117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17115v1","updated":"2024-06-24T20:08:07Z","published":"2024-06-24T20:08:07Z","title":"Evaluating the Quality of Hallucination Benchmarks for Large\n  Vision-Language Models","summary":"  Despite the rapid progress and outstanding performance of Large\nVision-Language Models (LVLMs) in recent years, LVLMs have been plagued by the\nissue of hallucination, i.e., LVLMs tend to generate responses that are\ninconsistent with the corresponding visual inputs. To evaluate the degree of\nhallucination in LVLMs, previous works have proposed a series of benchmarks\nfeaturing different types of tasks and evaluation metrics. However, we find\nthat the quality of the existing hallucination benchmarks varies, with some\nsuffering from problems, e.g., inconsistent evaluation results under repeated\ntests, and misalignment with human evaluation. To this end, we propose a\nHallucination benchmark Quality Measurement framework (HQM), which leverages\nvarious indicators to assess the reliability and validity of existing\nhallucination benchmarks separately. Specifically, for reliability we explore\ntest-retest reliability and parallel-forms reliability, while for validity we\nexamine criterion validity and coverage of hallucination types. Furthermore,\nbased on the results of our quality measurement, we construct a High-Quality\nHallucination Benchmark (HQH) for LVLMs. We conduct an extensive evaluation of\nover 10 representative LVLMs, including GPT-4o and Gemini-Vision-Pro, to\nprovide an in-depth analysis of the hallucination issues in existing models.\nOur benchmark is publicly available at https://github.com/HQHBench/HQHBench.\n","authors":["Bei Yan","Jie Zhang","Zheng Yuan","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17109v1","updated":"2024-06-24T19:52:27Z","published":"2024-06-24T19:52:27Z","title":"GMT: Guided Mask Transformer for Leaf Instance Segmentation","summary":"  Leaf instance segmentation is a challenging multi-instance segmentation task,\naiming to separate and delineate each leaf in an image of a plant. The\ndelineation of each leaf is a necessary prerequisite task for several\nbiology-related applications such as the fine-grained monitoring of plant\ngrowth, and crop yield estimation. The task is challenging because\nself-similarity of instances is high (similar shape and colour) and instances\nvary greatly in size under heavy occulusion.\n  We believe that the key to overcoming the aforementioned challenges lies in\nthe specific spatial patterns of leaf distribution. For example, leaves\ntypically grow around the plant's center, with smaller leaves clustering and\noverlapped near this central point. In this paper, we propose a novel approach\nnamed Guided Mask Transformer (GMT), which contains three key components,\nnamely Guided Positional Encoding (GPE), Guided Embedding Fusion Module (GEFM)\nand Guided Dynamic Positional Queries (GDPQ), to extend the meta-architecture\nof Mask2Former and incorporate with a set of harmonic guide functions. These\nguide functions are tailored to the pixel positions of instances and trained to\nseparate distinct instances in an embedding space. The proposed GMT\nconsistently outperforms State-of-the-Art models on three public plant\ndatasets.\n","authors":["Feng Chen","Sotirios A. Tsaftaris","Mario Valerio Giuffrida"],"pdf_url":"https://arxiv.org/pdf/2406.17109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17100v1","updated":"2024-06-24T19:39:59Z","published":"2024-06-24T19:39:59Z","title":"Fine-tuning Diffusion Models for Enhancing Face Quality in Text-to-image\n  Generation","summary":"  Diffusion models (DMs) have achieved significant success in generating\nimaginative images given textual descriptions. However, they are likely to fall\nshort when it comes to real-life scenarios with intricate details.The\nlow-quality, unrealistic human faces in text-to-image generation are one of the\nmost prominent issues, hindering the wide application of DMs in practice.\nTargeting addressing such an issue, we first assess the face quality of\ngenerations from popular pre-trained DMs with the aid of human annotators and\nthen evaluate the alignment between existing metrics such as ImageReward, Human\nPreference Score, Aesthetic Score Predictor, and Face Quality Assessment, with\nhuman judgments. Observing that existing metrics can be unsatisfactory for\nquantifying face quality, we develop a novel metric named Face Score (FS) by\nfine-tuning ImageReward on a dataset of (good, bad) face pairs cheaply crafted\nby an inpainting pipeline of DMs. Extensive studies reveal that FS enjoys a\nsuperior alignment with humans. On the other hand, FS opens up the door for\nrefining DMs for better face generation. To achieve this, we incorporate a\nguidance loss on the denoising trajectories of the aforementioned face pairs\nfor fine-tuning pre-trained DMs such as Stable Diffusion V1.5 and Realistic\nVision V5.1. Intuitively, such a loss pushes the trajectory of bad faces toward\nthat of good ones. Comprehensive experiments verify the efficacy of our\napproach for improving face quality while preserving general capability.\n","authors":["Zhenyi Liao","Qingsong Xie","Chen Chen","Hannan Lu","Zhijie Deng"],"pdf_url":"https://arxiv.org/pdf/2406.17100v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2405.11837v2","updated":"2024-06-24T19:28:08Z","published":"2024-05-20T07:25:09Z","title":"Improving the Explain-Any-Concept by Introducing Nonlinearity to the\n  Trainable Surrogate Model","summary":"  In the evolving field of Explainable AI (XAI), interpreting the decisions of\ndeep neural networks (DNNs) in computer vision tasks is an important process.\nWhile pixel-based XAI methods focus on identifying significant pixels, existing\nconcept-based XAI methods use pre-defined or human-annotated concepts. The\nrecently proposed Segment Anything Model (SAM) achieved a significant step\nforward to prepare automatic concept sets via comprehensive instance\nsegmentation. Building upon this, the Explain Any Concept (EAC) model emerged\nas a flexible method for explaining DNN decisions. EAC model is based on using\na surrogate model which has one trainable linear layer to simulate the target\nmodel. In this paper, by introducing an additional nonlinear layer to the\noriginal surrogate model, we show that we can improve the performance of the\nEAC model. We compare our proposed approach to the original EAC model and\nreport improvements obtained on both ImageNet and MS COCO datasets.\n","authors":["Mounes Zaval","Sedat Ozer"],"pdf_url":"https://arxiv.org/pdf/2405.11837v2.pdf","comment":"This paper is accepted for publication at IEEE SIU conference, 2024"},{"id":"http://arxiv.org/abs/2406.17080v1","updated":"2024-06-24T19:09:20Z","published":"2024-06-24T19:09:20Z","title":"Multi-Aperture Fusion of Transformer-Convolutional Network (MFTC-Net)\n  for 3D Medical Image Segmentation and Visualization","summary":"  Vision Transformers have shown superior performance to the traditional\nconvolutional-based frameworks in many vision applications, including but not\nlimited to the segmentation of 3D medical images. To further advance this area,\nthis study introduces the Multi-Aperture Fusion of Transformer-Convolutional\nNetwork (MFTC-Net), which integrates the output of Swin Transformers and their\ncorresponding convolutional blocks using 3D fusion blocks. The Multi-Aperture\nincorporates each image patch at its original resolutions with its pyramid\nrepresentation to better preserve minute details. The proposed architecture has\ndemonstrated a score of 89.73 and 7.31 for Dice and HD95, respectively, on the\nSynapse multi-organs dataset an improvement over the published results. The\nimproved performance also comes with the added benefits of the reduced\ncomplexity of approximately 40 million parameters. Our code is available at\nhttps://github.com/Siyavashshabani/MFTC-Net\n","authors":["Siyavash Shabani","Muhammad Sohaib","Sahar A. Mohammed","Bahram Parvin"],"pdf_url":"https://arxiv.org/pdf/2406.17080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17074v1","updated":"2024-06-24T19:01:44Z","published":"2024-06-24T19:01:44Z","title":"Reducing the Memory Footprint of 3D Gaussian Splatting","summary":"  3D Gaussian splatting provides excellent visual quality for novel view\nsynthesis, with fast training and real-time rendering; unfortunately, the\nmemory requirements of this method for storing and transmission are\nunreasonably high. We first analyze the reasons for this, identifying three\nmain areas where storage can be reduced: the number of 3D Gaussian primitives\nused to represent a scene, the number of coefficients for the spherical\nharmonics used to represent directional radiance, and the precision required to\nstore Gaussian primitive attributes. We present a solution to each of these\nissues. First, we propose an efficient, resolution-aware primitive pruning\napproach, reducing the primitive count by half. Second, we introduce an\nadaptive adjustment method to choose the number of coefficients used to\nrepresent directional radiance for each Gaussian primitive, and finally a\ncodebook-based quantization method, together with a half-float representation\nfor further memory reduction. Taken together, these three components result in\na 27 reduction in overall size on disk on the standard datasets we tested,\nalong with a 1.7 speedup in rendering speed. We demonstrate our method on\nstandard datasets and show how our solution results in significantly reduced\ndownload times when using the method on a mobile device.\n","authors":["Panagiotis Papantonakis","Georgios Kopanas","Bernhard Kerbl","Alexandre Lanvin","George Drettakis"],"pdf_url":"https://arxiv.org/pdf/2406.17074v1.pdf","comment":"Project website: https://repo-sam.inria.fr/fungraph/reduced_3dgs/"},{"id":"http://arxiv.org/abs/2406.17051v1","updated":"2024-06-24T18:13:09Z","published":"2024-06-24T18:13:09Z","title":"Leveraging Knowledge Distillation for Lightweight Skin Cancer\n  Classification: Balancing Accuracy and Computational Efficiency","summary":"  Skin cancer is a major concern to public health, accounting for one-third of\nthe reported cancers. If not detected early, the cancer has the potential for\nsevere consequences. Recognizing the critical need for effective skin cancer\nclassification, we address the limitations of existing models, which are often\ntoo large to deploy in areas with limited computational resources. In response,\nwe present a knowledge distillation based approach for creating a lightweight\nyet high-performing classifier. The proposed solution involves fusing three\nmodels, namely ResNet152V2, ConvNeXtBase, and ViT Base, to create an effective\nteacher model. The teacher model is then employed to guide a lightweight\nstudent model of size 2.03 MB. This student model is further compressed to\n469.77 KB using 16-bit quantization, enabling smooth incorporation into edge\ndevices. With six-stage image preprocessing, data augmentation, and a rigorous\nablation study, the model achieves an impressive accuracy of 98.75% on the\nHAM10000 dataset and 98.94% on the Kaggle dataset in classifying benign and\nmalignant skin cancers. With its high accuracy and compact size, our model\nappears to be a potential choice for accurate skin cancer classification,\nparticularly in resource-constrained settings.\n","authors":["Niful Islam","Khan Md Hasib","Fahmida Akter Joti","Asif Karim","Sami Azam"],"pdf_url":"https://arxiv.org/pdf/2406.17051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17047v1","updated":"2024-06-24T18:08:19Z","published":"2024-06-24T18:08:19Z","title":"Enhancing Scientific Figure Captioning Through Cross-modal Learning","summary":"  Scientific charts are essential tools for effectively communicating research\nfindings, serving as a vital medium for conveying information and revealing\ndata patterns. With the rapid advancement of science and technology, coupled\nwith the advent of the big data era, the volume and diversity of scientific\nresearch data have surged, leading to an increase in the number and variety of\ncharts. This trend presents new challenges for researchers, particularly in\nefficiently and accurately generating appropriate titles for these charts to\nbetter convey their information and results. Automatically generated chart\ntitles can enhance information retrieval systems by providing precise data for\ndetailed chart classification. As research in image captioning and text\nsummarization matures, the automatic generation of scientific chart titles has\ngained significant attention. By leveraging natural language processing,\nmachine learning, and multimodal techniques, it is possible to automatically\nextract key information from charts and generate accurate, concise titles that\nbetter serve the needs of researchers. This paper presents a novel approach to\nscientific chart title generation, demonstrating its effectiveness in improving\nthe clarity and accessibility of research data.\n","authors":["Mateo Alejandro Rojas","Rafael Carranza"],"pdf_url":"https://arxiv.org/pdf/2406.17047v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2405.05944v2","updated":"2024-06-24T18:05:06Z","published":"2024-05-09T17:33:09Z","title":"MRISegmentator-Abdomen: A Fully Automated Multi-Organ and Structure\n  Segmentation Tool for T1-weighted Abdominal MRI","summary":"  Background: Segmentation of organs and structures in abdominal MRI is useful\nfor many clinical applications, such as disease diagnosis and radiotherapy.\nCurrent approaches have focused on delineating a limited set of abdominal\nstructures (13 types). To date, there is no publicly available abdominal MRI\ndataset with voxel-level annotations of multiple organs and structures.\nConsequently, a segmentation tool for multi-structure segmentation is also\nunavailable. Methods: We curated a T1-weighted abdominal MRI dataset consisting\nof 195 patients who underwent imaging at National Institutes of Health (NIH)\nClinical Center. The dataset comprises of axial pre-contrast T1, arterial,\nvenous, and delayed phases for each patient, thereby amounting to a total of\n780 series (69,248 2D slices). Each series contains voxel-level annotations of\n62 abdominal organs and structures. A 3D nnUNet model, dubbed as\nMRISegmentator-Abdomen (MRISegmentator in short), was trained on this dataset,\nand evaluation was conducted on an internal test set and two large external\ndatasets: AMOS22 and Duke Liver. The predicted segmentations were compared\nagainst the ground-truth using the Dice Similarity Coefficient (DSC) and\nNormalized Surface Distance (NSD). Findings: MRISegmentator achieved an average\nDSC of 0.861$\\pm$0.170 and a NSD of 0.924$\\pm$0.163 in the internal test set.\nOn the AMOS22 dataset, MRISegmentator attained an average DSC of\n0.829$\\pm$0.133 and a NSD of 0.908$\\pm$0.067. For the Duke Liver dataset, an\naverage DSC of 0.933$\\pm$0.015 and a NSD of 0.929$\\pm$0.021 was obtained.\nInterpretation: The proposed MRISegmentator provides automatic, accurate, and\nrobust segmentations of 62 organs and structures in T1-weighted abdominal MRI\nsequences. The tool has the potential to accelerate research on various\nclinical topics, such as abnormality detection, radiotherapy, disease\nclassification among others.\n","authors":["Yan Zhuang","Tejas Sudharshan Mathai","Pritam Mukherjee","Brandon Khoury","Boah Kim","Benjamin Hou","Nusrat Rabbee","Abhinav Suri","Ronald M. Summers"],"pdf_url":"https://arxiv.org/pdf/2405.05944v2.pdf","comment":"We made the segmentation model publicly available"},{"id":"http://arxiv.org/abs/2406.17032v1","updated":"2024-06-24T18:00:11Z","published":"2024-06-24T18:00:11Z","title":"Dwarf: Disease-weighted network for attention map refinement","summary":"  The interpretability of deep learning is crucial for evaluating the\nreliability of medical imaging models and reducing the risks of inaccurate\npatient recommendations. This study addresses the \"human out of the loop\" and\n\"trustworthiness\" issues in medical image analysis by integrating medical\nprofessionals into the interpretability process. We propose a disease-weighted\nattention map refinement network (Dwarf) that leverages expert feedback to\nenhance model relevance and accuracy. Our method employs cyclic training to\niteratively improve diagnostic performance, generating precise and\ninterpretable feature maps. Experimental results demonstrate significant\nimprovements in interpretability and diagnostic accuracy across multiple\nmedical imaging datasets. This approach fosters effective collaboration between\nAI systems and healthcare professionals, ultimately aiming to improve patient\noutcomes\n","authors":["Haozhe Luo","Aurélie Pahud de Mortanges","Oana Inel","Mauricio Reyes"],"pdf_url":"https://arxiv.org/pdf/2406.17032v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2406.16858v1","updated":"2024-06-24T17:59:11Z","published":"2024-06-24T17:59:11Z","title":"EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees","summary":"  Inference with modern Large Language Models (LLMs) is expensive and\ntime-consuming, and speculative sampling has proven to be an effective\nsolution. Most speculative sampling methods such as EAGLE use a static draft\ntree, implicitly assuming that the acceptance rate of draft tokens depends only\non their position. Interestingly, we found that the acceptance rate of draft\ntokens is also context-dependent. In this paper, building upon EAGLE, we\npropose EAGLE-2, which introduces a new technique of context-aware dynamic\ndraft tree into drafting modeling. This improvement leverages the fact that the\ndraft model of EAGLE is well-calibrated: the confidence scores from the draft\nmodel approximate acceptance rates with small errors. We conducted extensive\nevaluations on three series of LLMs and six tasks, with EAGLE-2 achieving\nspeedup ratios 3.05x-4.26x, which is 20%-40% faster than EAGLE-1. EAGLE-2 also\nensures that the distribution of the generated text remains unchanged, making\nit a lossless acceleration algorithm.\n","authors":["Yuhui Li","Fangyun Wei","Chao Zhang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16853v1","updated":"2024-06-24T17:58:13Z","published":"2024-06-24T17:58:13Z","title":"GeoMFormer: A General Architecture for Geometric Molecular\n  Representation Learning","summary":"  Molecular modeling, a central topic in quantum mechanics, aims to accurately\ncalculate the properties and simulate the behaviors of molecular systems. The\nmolecular model is governed by physical laws, which impose geometric\nconstraints such as invariance and equivariance to coordinate rotation and\ntranslation. While numerous deep learning approaches have been developed to\nlearn molecular representations under these constraints, most of them are built\nupon heuristic and costly modules. We argue that there is a strong need for a\ngeneral and flexible framework for learning both invariant and equivariant\nfeatures. In this work, we introduce a novel Transformer-based molecular model\ncalled GeoMFormer to achieve this goal. Using the standard Transformer modules,\ntwo separate streams are developed to maintain and learn invariant and\nequivariant representations. Carefully designed cross-attention modules bridge\nthe two streams, allowing information fusion and enhancing geometric modeling\nin each stream. As a general and flexible architecture, we show that many\nprevious architectures can be viewed as special instantiations of GeoMFormer.\nExtensive experiments are conducted to demonstrate the power of GeoMFormer. All\nempirical results show that GeoMFormer achieves strong performance on both\ninvariant and equivariant tasks of different types and scales. Code and models\nwill be made publicly available at https://github.com/c-tl/GeoMFormer.\n","authors":["Tianlang Chen","Shengjie Luo","Di He","Shuxin Zheng","Tie-Yan Liu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16853v1.pdf","comment":"25 pages, 13 tables, l figure; ICML 2024 camera ready version"},{"id":"http://arxiv.org/abs/2309.07899v2","updated":"2024-06-24T17:54:58Z","published":"2023-09-14T17:48:30Z","title":"Improving physics-informed DeepONets with hard constraints","summary":"  Current physics-informed (standard or deep operator) neural networks still\nrely on accurately learning the initial and/or boundary conditions of the\nsystem of differential equations they are solving. In contrast, standard\nnumerical methods involve such conditions in computations without needing to\nlearn them. In this study, we propose to improve current physics-informed deep\nlearning strategies such that initial and/or boundary conditions do not need to\nbe learned and are represented exactly in the predicted solution. Moreover,\nthis method guarantees that when a deep operator network is applied multiple\ntimes to time-step a solution of an initial value problem, the resulting\nfunction is at least continuous.\n","authors":["Rüdiger Brecht","Dmytro R. Popovych","Alex Bihlo","Roman O. Popovych"],"pdf_url":"https://arxiv.org/pdf/2309.07899v2.pdf","comment":"26 pages, 8 figures, 6 tables; extended version"},{"id":"http://arxiv.org/abs/2406.16846v1","updated":"2024-06-24T17:51:01Z","published":"2024-06-24T17:51:01Z","title":"Data Debiasing with Datamodels (D3M): Improving Subgroup Robustness via\n  Data Selection","summary":"  Machine learning models can fail on subgroups that are underrepresented\nduring training. While techniques such as dataset balancing can improve\nperformance on underperforming groups, they require access to training group\nannotations and can end up removing large portions of the dataset. In this\npaper, we introduce Data Debiasing with Datamodels (D3M), a debiasing approach\nwhich isolates and removes specific training examples that drive the model's\nfailures on minority groups. Our approach enables us to efficiently train\ndebiased classifiers while removing only a small number of examples, and does\nnot require training group annotations or additional hyperparameter tuning.\n","authors":["Saachi Jain","Kimia Hamidieh","Kristian Georgiev","Andrew Ilyas","Marzyeh Ghassemi","Aleksander Madry"],"pdf_url":"https://arxiv.org/pdf/2406.16846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00592v2","updated":"2024-06-24T17:47:41Z","published":"2024-05-01T15:59:00Z","title":"Scaling and renormalization in high-dimensional regression","summary":"  This paper presents a succinct derivation of the training and generalization\nperformance of a variety of high-dimensional ridge regression models using the\nbasic tools of random matrix theory and free probability. We provide an\nintroduction and review of recent results on these topics, aimed at readers\nwith backgrounds in physics and deep learning. Analytic formulas for the\ntraining and generalization errors are obtained in a few lines of algebra\ndirectly from the properties of the $S$-transform of free probability. This\nallows for a straightforward identification of the sources of power-law scaling\nin model performance. We compute the generalization error of a broad class of\nrandom feature models. We find that in all models, the $S$-transform\ncorresponds to the train-test generalization gap, and yields an analogue of the\ngeneralized-cross-validation estimator. Using these techniques, we derive\nfine-grained bias-variance decompositions for a very general class of random\nfeature models with structured covariates. These novel results allow us to\ndiscover a scaling regime for random feature models where the variance due to\nthe features limits performance in the overparameterized setting. We also\ndemonstrate how anisotropic weight structure in random feature models can limit\nperformance and lead to nontrivial exponents for finite-width corrections in\nthe overparameterized setting. Our results extend and provide a unifying\nperspective on earlier models of neural scaling laws.\n","authors":["Alexander Atanasov","Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2405.00592v2.pdf","comment":"68 pages, 17 figures"},{"id":"http://arxiv.org/abs/2406.16838v1","updated":"2024-06-24T17:45:59Z","published":"2024-06-24T17:45:59Z","title":"From Decoding to Meta-Generation: Inference-time Algorithms for Large\n  Language Models","summary":"  One of the most striking findings in modern research on large language models\n(LLMs) is that scaling up compute during training leads to better results.\nHowever, less attention has been given to the benefits of scaling compute\nduring inference. This survey focuses on these inference-time approaches. We\nexplore three areas under a unified mathematical formalism: token-level\ngeneration algorithms, meta-generation algorithms, and efficient generation.\nToken-level generation algorithms, often called decoding algorithms, operate by\nsampling a single token at a time or constructing a token-level search space\nand then selecting an output. These methods typically assume access to a\nlanguage model's logits, next-token distributions, or probability scores.\nMeta-generation algorithms work on partial or full sequences, incorporating\ndomain knowledge, enabling backtracking, and integrating external information.\nEfficient generation methods aim to reduce token costs and improve the speed of\ngeneration. Our survey unifies perspectives from three research communities:\ntraditional natural language processing, modern LLMs, and machine learning\nsystems.\n","authors":["Sean Welleck","Amanda Bertsch","Matthew Finlayson","Hailey Schoelkopf","Alex Xie","Graham Neubig","Ilia Kulikov","Zaid Harchaoui"],"pdf_url":"https://arxiv.org/pdf/2406.16838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16834v1","updated":"2024-06-24T17:42:03Z","published":"2024-06-24T17:42:03Z","title":"Concentration Inequalities for $(f,Γ)$-GANs","summary":"  Generative adversarial networks (GANs) are unsupervised learning methods for\ntraining a generator distribution to produce samples that approximate those\ndrawn from a target distribution. Many such methods can be formulated as\nminimization of a metric or divergence. Recent works have proven the\nstatistical consistency of GANs that are based on integral probability metrics\n(IPMs), e.g., WGAN which is based on the 1-Wasserstein metric. IPMs are defined\nby optimizing a linear functional (difference of expectations) over a space of\ndiscriminators. A much larger class of GANs, which allow for the use of\nnonlinear objective functionals, can be constructed using\n$(f,\\Gamma)$-divergences; these generalize and interpolate between IPMs and\n$f$-divergences (e.g., KL or $\\alpha$-divergences). Instances of\n$(f,\\Gamma)$-GANs have been shown to exhibit improved performance in a number\nof applications. In this work we study the statistical consistency of\n$(f,\\Gamma)$-GANs for general $f$ and $\\Gamma$. Specifically, we derive\nfinite-sample concentration inequalities. These derivations require novel\narguments due to nonlinearity of the objective functional. We demonstrate that\nour new results reduce to the known results for IPM-GANs in the appropriate\nlimit while also significantly extending the domain of applicability of this\ntheory.\n","authors":["Jeremiah Birrell"],"pdf_url":"https://arxiv.org/pdf/2406.16834v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2406.16833v1","updated":"2024-06-24T17:41:53Z","published":"2024-06-24T17:41:53Z","title":"USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and\n  $\\underline{D}$ogmatism in Long $\\underline{C}$onversations","summary":"  Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].\n","authors":["Mounika Marreddy","Subba Reddy Oota","Venkata Charan Chinni","Manish Gupta","Lucie Flek"],"pdf_url":"https://arxiv.org/pdf/2406.16833v1.pdf","comment":"32 pages, 18 figures"},{"id":"http://arxiv.org/abs/2406.16829v1","updated":"2024-06-24T17:38:02Z","published":"2024-06-24T17:38:02Z","title":"Understanding and Mitigating Tokenization Bias in Language Models","summary":"  State-of-the-art language models are autoregressive and operate on subword\nunits known as tokens. Specifically, one must encode the conditioning string\ninto a list of tokens before passing to the language models for next-token\nprediction. We show that, for encoding schemes such as maximum prefix matching,\ntokenization induces a sampling bias that cannot be mitigated with more\ntraining or data. To counter this universal problem, we propose a novel\nalgorithm to obtain unbiased estimates from a model that was trained on\ntokenized data. Our method does not require finetuning the model, and its\ncomplexity, defined as the number of model runs, scales linearly with the\nsequence length. As a consequence, we show that one can simulate token-free\nbehavior from a tokenized language model. We empirically verify the correctness\nof our method through a Markov-chain setup, where it accurately recovers the\ntransition probabilities, as opposed to the conventional method of directly\nprompting tokens into the language model.\n","authors":["Buu Phan","Marton Havasi","Matthew Muckley","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2406.16829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16821v1","updated":"2024-06-24T17:31:41Z","published":"2024-06-24T17:31:41Z","title":"General Binding Affinity Guidance for Diffusion Models in\n  Structure-Based Drug Design","summary":"  Structure-Based Drug Design (SBDD) focuses on generating valid ligands that\nstrongly and specifically bind to a designated protein pocket. Several methods\nuse machine learning for SBDD to generate these ligands in 3D space,\nconditioned on the structure of a desired protein pocket. Recently, diffusion\nmodels have shown success here by modeling the underlying distributions of\natomic positions and types. While these methods are effective in considering\nthe structural details of the protein pocket, they often fail to explicitly\nconsider the binding affinity. Binding affinity characterizes how tightly the\nligand binds to the protein pocket, and is measured by the change in free\nenergy associated with the binding process. It is one of the most crucial\nmetrics for benchmarking the effectiveness of the interaction between a ligand\nand protein pocket. To address this, we propose BADGER: Binding Affinity\nDiffusion Guidance with Enhanced Refinement. BADGER is a general guidance\nmethod to steer the diffusion sampling process towards improved protein-ligand\nbinding, allowing us to adjust the distribution of the binding affinity between\nligands and proteins. Our method is enabled by using a neural network (NN) to\nmodel the energy function, which is commonly approximated by AutoDock Vina\n(ADV). ADV's energy function is non-differentiable, and estimates the affinity\nbased on the interactions between a ligand and target protein receptor. By\nusing a NN as a differentiable energy function proxy, we utilize the gradient\nof our learned energy function as a guidance method on top of any trained\ndiffusion model. We show that our method improves the binding affinity of\ngenerated ligands to their protein receptors by up to 60\\%, significantly\nsurpassing previous machine learning methods. We also show that our guidance\nmethod is flexible and can be easily applied to other diffusion-based SBDD\nframeworks.\n","authors":["Yue Jian","Curtis Wu","Danny Reidenbach","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2406.16821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16810v1","updated":"2024-06-24T17:22:36Z","published":"2024-06-24T17:22:36Z","title":"PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs","summary":"  Recently, machine unlearning, which seeks to erase specific data stored in\nthe pre-trained or fine-tuned models, has emerged as a crucial protective\nmeasure for LLMs. However, unlearning approaches for LLMs that have been\nconsidered thus far have focused on the removal of independent data points and\nhave not taken into account that the stored facts are logically connected to\none another and form an implicit knowledge graph. To facilitate the development\nof structural unlearning methods, which are essential for the practical\napplication of unlearning, we propose PISTOL, a pipeline for compiling\nmulti-scenario datasets for benchmarking structural LLM unlearning.\nAdditionally, leveraging sample datasets synthesized using PISTOL, we conducted\nbenchmarks with four distinct unlearning methods on both Llama2-7B and\nMistral-7B models. This analysis helps to illustrate the prevailing challenges\nin effectively and robustly removing highly inter-connected data, batched data,\nor data skewed towards a specific domain. It also highlights the choice of\npre-trained model can impact unlearning performance. This work not only\nadvances our understandings on the limitation of current LLMs unlearning\nmethods and proposes future research directions, but also provides a replicable\nframework for ongoing exploration and validation in the field.\n","authors":["Xinchi Qiu","William F. Shen","Yihong Chen","Nicola Cancedda","Pontus Stenetorp","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2406.16810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16807v1","updated":"2024-06-24T17:19:34Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16802v1","updated":"2024-06-24T17:14:31Z","published":"2024-06-24T17:14:31Z","title":"Improved Regret Bounds for Bandits with Expert Advice","summary":"  In this research note, we revisit the bandits with expert advice problem.\nUnder a restricted feedback model, we prove a lower bound of order $\\sqrt{K T\n\\ln(N/K)}$ for the worst-case regret, where $K$ is the number of actions, $N>K$\nthe number of experts, and $T$ the time horizon. This matches a previously\nknown upper bound of the same order and improves upon the best available lower\nbound of $\\sqrt{K T (\\ln N) / (\\ln K)}$. For the standard feedback model, we\nprove a new instance-based upper bound that depends on the agreement between\nthe experts and provides a logarithmic improvement compared to prior results.\n","authors":["Nicolò Cesa-Bianchi","Khaled Eldowa","Emmanuel Esposito","Julia Olkhovskaya"],"pdf_url":"https://arxiv.org/pdf/2406.16802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.17638v2","updated":"2024-06-24T17:00:44Z","published":"2023-10-26T17:53:24Z","title":"Generative Fractional Diffusion Models","summary":"  We introduce the first continuous-time score-based generative model that\nleverages fractional diffusion processes for its underlying dynamics. Although\ndiffusion models have excelled at capturing data distributions, they still\nsuffer from various limitations such as slow convergence, mode-collapse on\nimbalanced data, and lack of diversity. These issues are partially linked to\nthe use of light-tailed Brownian motion (BM) with independent increments. In\nthis paper, we replace BM with an approximation of its non-Markovian\ncounterpart, fractional Brownian motion (fBM), characterized by correlated\nincrements and Hurst index $H \\in (0,1)$, where $H=1/2$ recovers the classical\nBM. To ensure tractable inference and learning, we employ a recently\npopularized Markov approximation of fBM (MA-fBM) and derive its reverse time\nmodel, resulting in generative fractional diffusion models (GFDMs). We\ncharacterize the forward dynamics using a continuous reparameterization trick\nand propose an augmented score matching loss to efficiently learn the\nscore-function, which is partly known in closed form, at minimal added cost.\nThe ability to drive our diffusion model via fBM provides flexibility and\ncontrol. $H \\leq 1/2$ enters the regime of rough paths whereas $H>1/2$\nregularizes diffusion paths and invokes long-term memory as well as a\nheavy-tailed behaviour (super-diffusion). The Markov approximation allows added\ncontrol by varying the number of Markov processes linearly combined to\napproximate fBM. Our evaluations on real image datasets demonstrate that GFDM\nachieves greater pixel-wise diversity and enhanced image quality, as indicated\nby a lower FID, offering a promising alternative to traditional diffusion\nmodels.\n","authors":["Gabriel Nobis","Maximilian Springenberg","Marco Aversa","Michael Detzel","Rembert Daems","Roderick Murray-Smith","Shinichi Nakajima","Sebastian Lapuschkin","Stefano Ermon","Tolga Birdal","Manfred Opper","Christoph Knochenhauer","Luis Oala","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2310.17638v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16793v1","updated":"2024-06-24T16:56:41Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the number of learning rates in Adam: Instead of assigning an\nindividual learning rate for each parameter using $1/\\sqrt{v}$, Adam-mini uses\nthe average of $v$ within a pre-defined parameter block as the learning rate\nfor that block. Such a design is inspired by two empirical findings. First, the\nHessian of Transformers exhibits a near-block diagonal structure with different\nsizes of dense sub-blocks. Second, for each of these dense sub-blocks, there\nexists a single high-quality learning rate that can outperform Adam, provided\nthat sufficient resources are available to search it out. Adam-mini provides\none cost-effective way to find these good learning rates and manage to cut down\n$\\geq 90% v$ in Adam. Empirically, we verify that Adam-mini performs on par or\nbetter than AdamW on various language models sized from 125M to 7B for\npre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of\nAdam-mini also alleviates communication overheads among GPUs and CPUs, thereby\nincreasing throughput. For instance, Adam-mini achieves 49.6% higher throughput\nthan AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16791v1","updated":"2024-06-24T16:55:03Z","published":"2024-06-24T16:55:03Z","title":"Enabling more efficient and cost-effective AI/ML systems with Collective\n  Mind, virtualized MLOps, MLPerf, Collective Knowledge Playground and\n  reproducible optimization tournaments","summary":"  In this white paper, I present my community effort to automatically co-design\ncheaper, faster and more energy-efficient software and hardware for AI, ML and\nother popular workloads with the help of the Collective Mind framework (CM),\nvirtualized MLOps, MLPerf benchmarks and reproducible optimization tournaments.\nI developed CM to modularize, automate and virtualize the tedious process of\nbuilding, running, profiling and optimizing complex applications across rapidly\nevolving open-source and proprietary AI/ML models, datasets, software and\nhardware. I achieved that with the help of portable, reusable and\ntechnology-agnostic automation recipes (ResearchOps) for MLOps and DevOps\n(CM4MLOps) discovered in close collaboration with academia and industry when\nreproducing more than 150 research papers and organizing the 1st mass-scale\ncommunity benchmarking of ML and AI systems using CM and MLPerf.\n  I donated CM and CM4MLOps to MLCommons to help connect academia and industry\nto learn how to build and run AI and other emerging workloads in the most\nefficient and cost-effective way using a common and technology-agnostic\nautomation, virtualization and reproducibility framework while unifying\nknowledge exchange, protecting everyone's intellectual property, enabling\nportable skills, and accelerating transfer of the state-of-the-art research to\nproduction. My long-term vision is to make AI accessible to everyone by making\nit a commodity automatically produced from the most suitable open-source and\nproprietary components from different vendors based on user demand,\nrequirements and constraints such as cost, latency, throughput, accuracy,\nenergy, size and other important characteristics.\n","authors":["Grigori Fursin"],"pdf_url":"https://arxiv.org/pdf/2406.16791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16783v1","updated":"2024-06-24T16:45:13Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2406.16782v1","updated":"2024-06-24T16:44:45Z","published":"2024-06-24T16:44:45Z","title":"Confidence Aware Inverse Constrained Reinforcement Learning","summary":"  In coming up with solutions to real-world problems, humans implicitly adhere\nto constraints that are too numerous and complex to be specified completely.\nHowever, reinforcement learning (RL) agents need these constraints to learn the\ncorrect optimal policy in these settings. The field of Inverse Constraint\nReinforcement Learning (ICRL) deals with this problem and provides algorithms\nthat aim to estimate the constraints from expert demonstrations collected\noffline. Practitioners prefer to know a measure of confidence in the estimated\nconstraints, before deciding to use these constraints, which allows them to\nonly use the constraints that satisfy a desired level of confidence. However,\nprior works do not allow users to provide the desired level of confidence for\nthe inferred constraints. This work provides a principled ICRL method that can\ntake a confidence level with a set of expert demonstrations and outputs a\nconstraint that is at least as constraining as the true underlying constraint\nwith the desired level of confidence. Further, unlike previous methods, this\nmethod allows a user to know if the number of expert trajectories is\ninsufficient to learn a constraint with a desired level of confidence, and\ntherefore collect more expert trajectories as required to simultaneously learn\nconstraints with the desired level of confidence and a policy that achieves the\ndesired level of performance.\n","authors":["Sriram Ganapathi Subramanian","Guiliang Liu","Mohammed Elmahgiubi","Kasra Rezaee","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2406.16782v1.pdf","comment":"Paper to appear in ICML 2024"},{"id":"http://arxiv.org/abs/2402.16788v3","updated":"2024-06-24T16:41:30Z","published":"2024-02-26T18:01:41Z","title":"Why Transformers Need Adam: A Hessian Perspective","summary":"  SGD performs worse than Adam by a significant margin on Transformers, but the\nreason remains unclear. In this work, we provide an explanation through the\nlens of Hessian: (i) Transformers are \"heterogeneous\": the Hessian spectrum\nacross parameter blocks vary dramatically, a phenomenon we call \"block\nheterogeneity\"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam on\nproblems with block heterogeneity. To validate (i) and (ii), we check various\nTransformers, CNNs, MLPs, and quadratic problems, and find that SGD can perform\non par with Adam on problems without block heterogeneity, but performs worse\nthan Adam when the heterogeneity exists. Our initial theoretical analysis\nindicates that SGD performs worse because it applies one single learning rate\nto all blocks, which cannot handle the heterogeneity among blocks. This\nlimitation could be ameliorated if we use coordinate-wise learning rates, as\ndesigned in Adam.\n","authors":["Yushun Zhang","Congliang Chen","Tian Ding","Ziniu Li","Ruoyu Sun","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2402.16788v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16768v1","updated":"2024-06-24T16:24:34Z","published":"2024-06-24T16:24:34Z","title":"WARP: On the Benefits of Weight Averaged Rewarded Policies","summary":"  Reinforcement learning from human feedback (RLHF) aligns large language\nmodels (LLMs) by encouraging their generations to have high rewards, using a\nreward model trained on human preferences. To prevent the forgetting of\npre-trained knowledge, RLHF usually incorporates a KL regularization; this\nforces the policy to remain close to its supervised fine-tuned initialization,\nthough it hinders the reward optimization. To tackle the trade-off between KL\nand reward, in this paper we introduce a novel alignment strategy named Weight\nAveraged Rewarded Policies (WARP). WARP merges policies in the weight space at\nthree distinct stages. First, it uses the exponential moving average of the\npolicy as a dynamic anchor in the KL regularization. Second, it applies\nspherical interpolation to merge independently fine-tuned policies into a new\nenhanced one. Third, it linearly interpolates between this merged model and the\ninitialization, to recover features from pre-training. This procedure is then\napplied iteratively, with each iteration's final model used as an advanced\ninitialization for the next, progressively refining the KL-reward Pareto front,\nachieving superior rewards at fixed KL. Experiments with GEMMA policies\nvalidate that WARP improves their quality and alignment, outperforming other\nopen-source LLMs.\n","authors":["Alexandre Ramé","Johan Ferret","Nino Vieillard","Robert Dadashi","Léonard Hussenot","Pierre-Louis Cedoz","Pier Giuseppe Sessa","Sertan Girgin","Arthur Douillard","Olivier Bachem"],"pdf_url":"https://arxiv.org/pdf/2406.16768v1.pdf","comment":"11 main pages (34 pages with Appendix)"},{"id":"http://arxiv.org/abs/2402.19212v6","updated":"2024-06-24T16:23:42Z","published":"2024-02-29T14:41:31Z","title":"Deep Reinforcement Learning: A Convex Optimization Approach","summary":"  In this paper, we consider reinforcement learning of nonlinear systems with\ncontinuous state and action spaces. We present an episodic learning algorithm,\nwhere we for each episode use convex optimization to find a two-layer neural\nnetwork approximation of the optimal $Q$-function. The convex optimization\napproach guarantees that the weights calculated at each episode are optimal,\nwith respect to the given sampled states and actions of the current episode.\nFor stable nonlinear systems, we show that the algorithm converges and that the\nconverging parameters of the trained neural network can be made arbitrarily\nclose to the optimal neural network parameters. In particular, if the\nregularization parameter in the training phase is given by $\\rho$, then the\nparameters of the trained neural network converge to $w$, where the distance\nbetween $w$ and the optimal parameters $w^\\star$ is bounded by\n$\\mathcal{O}(\\rho)$. That is, when the number of episodes goes to infinity,\nthere exists a constant $C$ such that \\[\n  \\|w-w^\\star\\| \\le C\\rho. \\]\n  In particular, our algorithm converges arbitrarily close to the optimal\nneural network parameters as the regularization parameter goes to zero. As a\nconsequence, our algorithm converges fast due to the polynomial-time\nconvergence of convex optimization algorithms.\n","authors":["Ather Gattami"],"pdf_url":"https://arxiv.org/pdf/2402.19212v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16766v1","updated":"2024-06-24T16:23:30Z","published":"2024-06-24T16:23:30Z","title":"Conformal time series decomposition with component-wise exchangeability","summary":"  Conformal prediction offers a practical framework for distribution-free\nuncertainty quantification, providing finite-sample coverage guarantees under\nrelatively mild assumptions on data exchangeability. However, these assumptions\ncease to hold for time series due to their temporally correlated nature. In\nthis work, we present a novel use of conformal prediction for time series\nforecasting that incorporates time series decomposition. This approach allows\nus to model different temporal components individually. By applying specific\nconformal algorithms to each component and then merging the obtained prediction\nintervals, we customize our methods to account for the different\nexchangeability regimes underlying each component. Our decomposition-based\napproach is thoroughly discussed and empirically evaluated on synthetic and\nreal-world data. We find that the method provides promising results on\nwell-structured time series, but can be limited by factors such as the\ndecomposition step for more complex data.\n","authors":["Derck W. E. Prinzhorn","Thijmen Nijdam","Putri A. van der Linden","Alexander Timans"],"pdf_url":"https://arxiv.org/pdf/2406.16766v1.pdf","comment":"Accepted at COPA 2024; 34 pages, 14 figures, 8 tables (incl.\n  appendix)"},{"id":"http://arxiv.org/abs/2402.17012v3","updated":"2024-06-24T16:18:45Z","published":"2024-02-26T20:41:50Z","title":"Pandora's White-Box: Precise Training Data Detection and Extraction in\n  Large Language Models","summary":"  In this paper we develop state-of-the-art privacy attacks against Large\nLanguage Models (LLMs), where an adversary with some access to the model tries\nto learn something about the underlying training data. Our headline results are\nnew membership inference attacks (MIAs) against pretrained LLMs that perform\nhundreds of times better than baseline attacks, and a pipeline showing that\nover 50% (!) of the fine-tuning dataset can be extracted from a fine-tuned LLM\nin natural settings. We consider varying degrees of access to the underlying\nmodel, pretraining and fine-tuning data, and both MIAs and training data\nextraction. For pretraining data, we propose two new MIAs: a supervised neural\nnetwork classifier that predicts training data membership on the basis of\n(dimensionality-reduced) model gradients, as well as a variant of this attack\nthat only requires logit access to the model by leveraging recent\nmodel-stealing work on LLMs. To our knowledge this is the first MIA that\nexplicitly incorporates model-stealing information. Both attacks outperform\nexisting black-box baselines, and our supervised attack closes the gap between\nMIA attack success against LLMs and the strongest known attacks for other\nmachine learning models. In fine-tuning, we find that a simple attack based on\nthe ratio of the loss between the base and fine-tuned models is able to achieve\nnear-perfect MIA performance; we then leverage our MIA to extract a large\nfraction of the fine-tuning dataset from fine-tuned Pythia and Llama models.\nOur code is available at github.com/safr-ai-lab/pandora-llm.\n","authors":["Jeffrey G. Wang","Jason Wang","Marvin Li","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2402.17012v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01557v2","updated":"2024-06-24T16:08:51Z","published":"2024-03-22T13:08:22Z","title":"An Experimental Study on the Rashomon Effect of Balancing Methods in\n  Imbalanced Classification","summary":"  Predictive models may generate biased predictions when classifying imbalanced\ndatasets. This happens when the model favors the majority class, leading to low\nperformance in accurately predicting the minority class. To address this issue,\nbalancing or resampling methods are critical pre-processing steps in the\nmodeling process. However, there have been debates and questioning of the\nfunctionality of these methods in recent years. In particular, many candidate\nmodels may exhibit very similar predictive performance, which is called the\nRashomon effect, in model selection. Selecting one of them without considering\npredictive multiplicity which is the case of yielding conflicting models'\npredictions for any sample may lead to a loss of using another model. In this\nstudy, in addition to the existing debates, the impact of balancing methods on\npredictive multiplicity is examined through the Rashomon effect. It is\nimportant because the blind model selection is risky from a set of\napproximately equally accurate models. This may lead to serious problems in\nmodel selection, validation, and explanation. To tackle this matter, we\nconducted real dataset experiments to observe the impact of balancing methods\non predictive multiplicity through the Rashomon effect. Our findings showed\nthat balancing methods inflate the predictive multiplicity, and they yield\nvarying results. To monitor the trade-off between performance and predictive\nmultiplicity for conducting the modeling process responsibly, we proposed using\nthe extended performance-gain plot for the Rashomon effect.\n","authors":["Mustafa Cavus","Przemysław Biecek"],"pdf_url":"https://arxiv.org/pdf/2405.01557v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.04029v2","updated":"2024-06-24T16:08:46Z","published":"2024-02-06T14:24:29Z","title":"Positive concave deep equilibrium models","summary":"  Deep equilibrium (DEQ) models are widely recognized as a memory efficient\nalternative to standard neural networks, achieving state-of-the-art performance\nin language modeling and computer vision tasks. These models solve a fixed\npoint equation instead of explicitly computing the output, which sets them\napart from standard neural networks. However, existing DEQ models often lack\nformal guarantees of the existence and uniqueness of the fixed point, and the\nconvergence of the numerical scheme used for computing the fixed point is not\nformally established. As a result, DEQ models are potentially unstable in\npractice. To address these drawbacks, we introduce a novel class of DEQ models\ncalled positive concave deep equilibrium (pcDEQ) models. Our approach, which is\nbased on nonlinear Perron-Frobenius theory, enforces nonnegative weights and\nactivation functions that are concave on the positive orthant. By imposing\nthese constraints, we can easily ensure the existence and uniqueness of the\nfixed point without relying on additional complex assumptions commonly found in\nthe DEQ literature, such as those based on monotone operator theory in convex\nanalysis. Furthermore, the fixed point can be computed with the standard fixed\npoint algorithm, and we provide theoretical guarantees of its geometric\nconvergence, which, in particular, simplifies the training process. Experiments\ndemonstrate the competitiveness of our pcDEQ models against other implicit\nmodels.\n","authors":["Mateusz Gabor","Tomasz Piotrowski","Renato L. G. Cavalcante"],"pdf_url":"https://arxiv.org/pdf/2402.04029v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16756v1","updated":"2024-06-24T16:03:57Z","published":"2024-06-24T16:03:57Z","title":"Addressing Polarization and Unfairness in Performative Prediction","summary":"  When machine learning (ML) models are used in applications that involve\nhumans (e.g., online recommendation, school admission, hiring, lending), the\nmodel itself may trigger changes in the distribution of targeted data it aims\nto predict. Performative prediction (PP) is a framework that explicitly\nconsiders such model-dependent distribution shifts when learning ML models.\nWhile significant efforts have been devoted to finding performative stable (PS)\nsolutions in PP for system robustness, their societal implications are less\nexplored and it is unclear whether PS solutions are aligned with social norms\nsuch as fairness. In this paper, we set out to examine the fairness property of\nPS solutions in performative prediction. We first show that PS solutions can\nincur severe polarization effects and group-wise loss disparity. Although\nexisting fairness mechanisms commonly used in literature can help mitigate\nunfairness, they may fail and disrupt the stability under model-dependent\ndistribution shifts. We thus propose novel fairness intervention mechanisms\nthat can simultaneously achieve both stability and fairness in PP settings.\nBoth theoretical analysis and experiments are provided to validate the proposed\nmethod.\n","authors":["Kun Jin","Tian Xie","Yang Liu","Xueru Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16754v1","updated":"2024-06-24T16:00:20Z","published":"2024-06-24T16:00:20Z","title":"The MRI Scanner as a Diagnostic: Image-less Active Sampling","summary":"  Despite the high diagnostic accuracy of Magnetic Resonance Imaging (MRI),\nusing MRI as a Point-of-Care (POC) disease identification tool poses\nsignificant accessibility challenges due to the use of high magnetic field\nstrength and lengthy acquisition times. We ask a simple question: Can we\ndynamically optimise acquired samples, at the patient level, according to an\n(automated) downstream decision task, while discounting image reconstruction?\nWe propose an ML-based framework that learns an active sampling strategy, via\nreinforcement learning, at a patient-level to directly infer disease from\nundersampled k-space. We validate our approach by inferring Meniscus Tear in\nundersampled knee MRI data, where we achieve diagnostic performance comparable\nwith ML-based diagnosis, using fully sampled k-space data. We analyse\ntask-specific sampling policies, showcasing the adaptability of our active\nsampling approach. The introduced frugal sampling strategies have the potential\nto reduce high field strength requirements that in turn strengthen the\nviability of MRI-based POC disease identification and associated preliminary\nscreening tools.\n","authors":["Yuning Du","Rohan Dharmakumar","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2406.16754v1.pdf","comment":"Accepted in MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.16749v1","updated":"2024-06-24T15:57:49Z","published":"2024-06-24T15:57:49Z","title":"Inferring stochastic low-rank recurrent neural networks from neural data","summary":"  A central aim in computational neuroscience is to relate the activity of\nlarge populations of neurons to an underlying dynamical system. Models of these\nneural dynamics should ideally be both interpretable and fit the observed data\nwell. Low-rank recurrent neural networks (RNNs) exhibit such interpretability\nby having tractable dynamics. However, it is unclear how to best fit low-rank\nRNNs to data consisting of noisy observations of an underlying stochastic\nsystem. Here, we propose to fit stochastic low-rank RNNs with variational\nsequential Monte Carlo methods. We validate our method on several datasets\nconsisting of both continuous and spiking neural data, where we obtain lower\ndimensional latent dynamics than current state of the art methods.\nAdditionally, for low-rank models with piecewise linear nonlinearities, we show\nhow to efficiently identify all fixed points in polynomial rather than\nexponential cost in the number of units, making analysis of the inferred\ndynamics tractable for large RNNs. Our method both elucidates the dynamical\nsystems underlying experimental recordings and provides a generative model\nwhose trajectories match observed trial-to-trial variability.\n","authors":["Matthijs Pals","A Erdem Sağtekin","Felix Pei","Manuel Gloeckler","Jakob H Macke"],"pdf_url":"https://arxiv.org/pdf/2406.16749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16748v1","updated":"2024-06-24T15:57:48Z","published":"2024-06-24T15:57:48Z","title":"OCALM: Object-Centric Assessment with Language Models","summary":"  Properly defining a reward signal to efficiently train a reinforcement\nlearning (RL) agent is a challenging task. Designing balanced objective\nfunctions from which a desired behavior can emerge requires expert knowledge,\nespecially for complex environments. Learning rewards from human feedback or\nusing large language models (LLMs) to directly provide rewards are promising\nalternatives, allowing non-experts to specify goals for the agent. However,\nblack-box reward models make it difficult to debug the reward. In this work, we\npropose Object-Centric Assessment with Language Models (OCALM) to derive\ninherently interpretable reward functions for RL agents from natural language\ntask descriptions. OCALM uses the extensive world-knowledge of LLMs while\nleveraging the object-centric nature common to many environments to derive\nreward functions focused on relational concepts, providing RL agents with the\nability to derive policies from task descriptions.\n","authors":["Timo Kaufmann","Jannis Blüml","Antonia Wüst","Quentin Delfosse","Kristian Kersting","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2406.16748v1.pdf","comment":"Accepted at the RLBRew Workshop at RLC 2024"},{"id":"http://arxiv.org/abs/2406.16747v1","updated":"2024-06-24T15:55:59Z","published":"2024-06-24T15:55:59Z","title":"Sparser is Faster and Less is More: Efficient Sparse Attention for\n  Long-Range Transformers","summary":"  Accommodating long sequences efficiently in autoregressive Transformers,\nespecially within an extended context window, poses significant challenges due\nto the quadratic computational complexity and substantial KV memory\nrequirements inherent in self-attention mechanisms. In this work, we introduce\nSPARSEK Attention, a novel sparse attention mechanism designed to overcome\nthese computational and memory obstacles while maintaining performance. Our\napproach integrates a scoring network and a differentiable top-k mask operator,\nSPARSEK, to select a constant number of KV pairs for each query, thereby\nenabling gradient-based optimization. As a result, SPARSEK Attention offers\nlinear time complexity and constant memory footprint during generation.\nExperimental results reveal that SPARSEK Attention outperforms previous sparse\nattention methods and provides significant speed improvements during both\ntraining and inference, particularly in language modeling and downstream tasks.\nFurthermore, our method can be seamlessly integrated into pre-trained Large\nLanguage Models (LLMs) with minimal fine-tuning, offering a practical solution\nfor effectively managing long-range dependencies in diverse applications.\n","authors":["Chao Lou","Zixia Jia","Zilong Zheng","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2406.16747v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2406.16746v1","updated":"2024-06-24T15:55:49Z","published":"2024-06-24T15:55:49Z","title":"The Responsible Foundation Model Development Cheatsheet: A Review of\n  Tools & Resources","summary":"  Foundation model development attracts a rapidly expanding body of\ncontributors, scientists, and applications. To help shape responsible\ndevelopment practices, we introduce the Foundation Model Development\nCheatsheet: a growing collection of 250+ tools and resources spanning text,\nvision, and speech modalities. We draw on a large body of prior work to survey\nresources (e.g. software, documentation, frameworks, guides, and practical\ntools) that support informed data selection, processing, and understanding,\nprecise and limitation-aware artifact documentation, efficient model training,\nadvance awareness of the environmental impact from training, careful model\nevaluation of capabilities, risks, and claims, as well as responsible model\nrelease, licensing and deployment practices. We hope this curated collection of\nresources helps guide more responsible development. The process of curating\nthis list, enabled us to review the AI development ecosystem, revealing what\ntools are critically missing, misused, or over-used in existing practices. We\nfind that (i) tools for data sourcing, model evaluation, and monitoring are\ncritically under-serving ethical and real-world needs, (ii) evaluations for\nmodel safety, capabilities, and environmental impact all lack reproducibility\nand transparency, (iii) text and particularly English-centric analyses continue\nto dominate over multilingual and multi-modal analyses, and (iv) evaluation of\nsystems, rather than just models, is needed so that capabilities and impact are\nassessed in context.\n","authors":["Shayne Longpre","Stella Biderman","Alon Albalak","Hailey Schoelkopf","Daniel McDuff","Sayash Kapoor","Kevin Klyman","Kyle Lo","Gabriel Ilharco","Nay San","Maribeth Rauh","Aviya Skowron","Bertie Vidgen","Laura Weidinger","Arvind Narayanan","Victor Sanh","David Adelani","Percy Liang","Rishi Bommasani","Peter Henderson","Sasha Luccioni","Yacine Jernite","Luca Soldaini"],"pdf_url":"https://arxiv.org/pdf/2406.16746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05271v3","updated":"2024-06-24T15:55:34Z","published":"2024-02-07T21:31:53Z","title":"Feature learning as alignment: a structural property of gradient descent\n  in non-linear neural networks","summary":"  Understanding the mechanisms through which neural networks extract statistics\nfrom input-label pairs through feature learning is one of the most important\nunsolved problems in supervised learning. Prior works demonstrated that the\ngram matrices of the weights (the neural feature matrices, NFM) and the average\ngradient outer products (AGOP) become correlated during training, in a\nstatement known as the neural feature ansatz (NFA). Through the NFA, the\nauthors introduce mapping with the AGOP as a general mechanism for neural\nfeature learning. However, these works do not provide a theoretical explanation\nfor this correlation or its origins. In this work, we further clarify the\nnature of this correlation, and explain its emergence. We show that this\ncorrelation is equivalent to alignment between the left singular structure of\nthe weight matrices and the newly defined pre-activation tangent features at\neach layer. We further establish that the alignment is driven by the\ninteraction of weight changes induced by SGD with the pre-activation features,\nand analyze the resulting dynamics analytically at early times in terms of\nsimple statistics of the inputs and labels. Finally, motivated by the\nobservation that the NFA is driven by this centered correlation, we introduce a\nsimple optimization rule that dramatically increases the NFA correlations at\nany given layer and improves the quality of features learned.\n","authors":["Daniel Beaglehole","Ioannis Mitliagkas","Atish Agarwala"],"pdf_url":"https://arxiv.org/pdf/2402.05271v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16745v1","updated":"2024-06-24T15:53:11Z","published":"2024-06-24T15:53:11Z","title":"Bandits with Preference Feedback: A Stackelberg Game Perspective","summary":"  Bandits with preference feedback present a powerful tool for optimizing\nunknown target functions when only pairwise comparisons are allowed instead of\ndirect value queries. This model allows for incorporating human feedback into\nonline inference and optimization and has been employed in systems for\nfine-tuning large language models. The problem is well understood in simplified\nsettings with linear target functions or over finite small domains that limit\npractical interest. Taking the next step, we consider infinite domains and\nnonlinear (kernelized) rewards. In this setting, selecting a pair of actions is\nquite challenging and requires balancing exploration and exploitation at two\nlevels: within the pair, and along the iterations of the algorithm. We propose\nMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and\nchooses action pairs that are informative and yield favorable rewards.\nMAXMINLCB consistently outperforms existing algorithms and satisfies an\nanytime-valid rate-optimal regret guarantee. This is due to our novel\npreference-based confidence sequences for kernelized logistic estimators.\n","authors":["Barna Pásztor","Parnian Kassraie","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2406.16745v1.pdf","comment":"30 pages, 8 figures"},{"id":"http://arxiv.org/abs/2404.02072v5","updated":"2024-06-24T15:52:57Z","published":"2024-04-02T16:20:02Z","title":"EGTR: Extracting Graph from Transformer for Scene Graph Generation","summary":"  Scene Graph Generation (SGG) is a challenging task of detecting objects and\npredicting relationships between objects. After DETR was developed, one-stage\nSGG models based on a one-stage object detector have been actively studied.\nHowever, complex modeling is used to predict the relationship between objects,\nand the inherent relationship between object queries learned in the multi-head\nself-attention of the object detector has been neglected. We propose a\nlightweight one-stage SGG model that extracts the relation graph from the\nvarious relationships learned in the multi-head self-attention layers of the\nDETR decoder. By fully utilizing the self-attention by-products, the relation\ngraph can be extracted effectively with a shallow relation extraction head.\nConsidering the dependency of the relation extraction task on the object\ndetection task, we propose a novel relation smoothing technique that adjusts\nthe relation label adaptively according to the quality of the detected objects.\nBy the relation smoothing, the model is trained according to the continuous\ncurriculum that focuses on object detection task at the beginning of training\nand performs multi-task learning as the object detection performance gradually\nimproves. Furthermore, we propose a connectivity prediction task that predicts\nwhether a relation exists between object pairs as an auxiliary task of the\nrelation extraction. We demonstrate the effectiveness and efficiency of our\nmethod for the Visual Genome and Open Image V6 datasets. Our code is publicly\navailable at https://github.com/naver-ai/egtr.\n","authors":["Jinbae Im","JeongYeon Nam","Nokyung Park","Hyungmin Lee","Seunghyun Park"],"pdf_url":"https://arxiv.org/pdf/2404.02072v5.pdf","comment":"CVPR 2024 (Best paper award candidate)"},{"id":"http://arxiv.org/abs/2311.08695v2","updated":"2024-06-24T15:51:13Z","published":"2023-11-15T04:50:30Z","title":"Attribute Diversity Determines the Systematicity Gap in VQA","summary":"  The degree to which neural networks can generalize to new combinations of\nfamiliar concepts, and the conditions under which they are able to do so, has\nlong been an open question. In this work, we study the systematicity gap in\nvisual question answering: the performance difference between reasoning on\npreviously seen and unseen combinations of object attributes. To test, we\nintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased\nquantity of training data does not reduce the systematicity gap, increased\ntraining data diversity of the attributes in the unseen combination does. In\nall, our experiments suggest that the more distinct attribute type combinations\nare seen during training, the more systematic we can expect the resulting model\nto be.\n","authors":["Ian Berlot-Attwell","Kumar Krishna Agrawal","A. Michael Carrell","Yash Sharma","Naomi Saphra"],"pdf_url":"https://arxiv.org/pdf/2311.08695v2.pdf","comment":"33 pages, 20 figures"},{"id":"http://arxiv.org/abs/2406.16740v1","updated":"2024-06-24T15:45:37Z","published":"2024-06-24T15:45:37Z","title":"Learning the boundary-to-domain mapping using Lifting Product Fourier\n  Neural Operators for partial differential equations","summary":"  Neural operators such as the Fourier Neural Operator (FNO) have been shown to\nprovide resolution-independent deep learning models that can learn mappings\nbetween function spaces. For example, an initial condition can be mapped to the\nsolution of a partial differential equation (PDE) at a future time-step using a\nneural operator. Despite the popularity of neural operators, their use to\npredict solution functions over a domain given only data over the boundary\n(such as a spatially varying Dirichlet boundary condition) remains unexplored.\nIn this paper, we refer to such problems as boundary-to-domain problems; they\nhave a wide range of applications in areas such as fluid mechanics, solid\nmechanics, heat transfer etc. We present a novel FNO-based architecture, named\nLifting Product FNO (or LP-FNO) which can map arbitrary boundary functions\ndefined on the lower-dimensional boundary to a solution in the entire domain.\nSpecifically, two FNOs defined on the lower-dimensional boundary are lifted\ninto the higher dimensional domain using our proposed lifting product layer. We\ndemonstrate the efficacy and resolution independence of the proposed LP-FNO for\nthe 2D Poisson equation.\n","authors":["Aditya Kashi","Arka Daw","Muralikrishnan Gopalakrishnan Meena","Hao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.16740v1.pdf","comment":"Accepted by ICML 2024 AI for Science Workshop"},{"id":"http://arxiv.org/abs/2406.16738v1","updated":"2024-06-24T15:45:20Z","published":"2024-06-24T15:45:20Z","title":"Inducing Group Fairness in LLM-Based Decisions","summary":"  Prompting Large Language Models (LLMs) has created new and interesting means\nfor classifying textual data. While evaluating and remediating group fairness\nis a well-studied problem in classifier fairness literature, some classical\napproaches (e.g., regularization) do not carry over, and some new opportunities\narise (e.g., prompt-based remediation). We measure fairness of LLM-based\nclassifiers on a toxicity classification task, and empirically show that\nprompt-based classifiers may lead to unfair decisions. We introduce several\nremediation techniques and benchmark their fairness and performance trade-offs.\nWe hope our work encourages more research on group fairness in LLM-based\nclassifiers.\n","authors":["James Atwood","Preethi Lahoti","Ananth Balashankar","Flavien Prost","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2406.16738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00435v2","updated":"2024-06-24T15:42:52Z","published":"2024-02-01T09:01:58Z","title":"A practical existence theorem for reduced order models based on\n  convolutional autoencoders","summary":"  In recent years, deep learning has gained increasing popularity in the fields\nof Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM),\nproviding domain practitioners with new powerful data-driven techniques such as\nPhysics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator\nNetworks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context,\ndeep autoencoders based on Convolutional Neural Networks (CNNs) have proven\nextremely effective, outperforming established techniques, such as the reduced\nbasis method, when dealing with complex nonlinear problems. However, despite\nthe empirical success of CNN-based autoencoders, there are only a few\ntheoretical results supporting these architectures, usually stated in the form\nof universal approximation theorems. In particular, although the existing\nliterature provides users with guidelines for designing convolutional\nautoencoders, the subsequent challenge of learning the latent features has been\nbarely investigated. Furthermore, many practical questions remain unanswered,\ne.g., the number of snapshots needed for convergence or the neural network\ntraining strategy. In this work, using recent techniques from sparse\nhigh-dimensional function approximation, we fill some of these gaps by\nproviding a new practical existence theorem for CNN-based autoencoders when the\nparameter-to-solution map is holomorphic. This regularity assumption arises in\nmany relevant classes of parametric PDEs, such as the parametric diffusion\nequation, for which we discuss an explicit application of our general theory.\n","authors":["Nicola Rares Franco","Simone Brugiapaglia"],"pdf_url":"https://arxiv.org/pdf/2402.00435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14469v2","updated":"2024-06-24T15:40:40Z","published":"2024-06-20T16:32:18Z","title":"Fusion of Movement and Naive Predictions for Point Forecasting in\n  Univariate Random Walks","summary":"  Traditional methods for point forecasting in univariate random walks often\nfail to surpass naive benchmarks due to data unpredictability. This study\nintroduces a novel forecasting method that fuses movement prediction (binary\nclassification) with naive forecasts for accurate one-step-ahead point\nforecasting. The method's efficacy is demonstrated through theoretical\nanalysis, simulations, and real-world data experiments. It reliably exceeds\nnaive forecasts with movement prediction accuracies as low as 0.55,\noutperforming baseline models like ARIMA, linear regression, MLP, and LSTM\nnetworks in forecasting the S\\&P 500 index and Bitcoin prices. This method is\nparticularly advantageous when accurate point predictions are challenging but\naccurate movement predictions are attainable, translating movement predictions\ninto point forecasts in random walk contexts.\n","authors":["Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.14469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14862v2","updated":"2024-06-24T15:30:34Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\nLatentExplainer, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\nLatentExplainer tackles three main challenges: inferring the meaning of latent\nvariables, aligning explanations with inductive biases, and handling varying\ndegrees of explainability. By perturbing latent variables and interpreting\nchanges in generated data, the framework provides a systematic approach to\nunderstanding and controlling the data generation process, enhancing the\ntransparency and interpretability of deep generative models. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations of\nlatent variables.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15283v2","updated":"2024-06-24T15:24:15Z","published":"2024-06-21T16:27:17Z","title":"FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event\n  Detection","summary":"  Early and accurate detection of anomalous events on the freeway, such as\naccidents, can improve emergency response and clearance. However, existing\ndelays and errors in event identification and reporting make it a difficult\nproblem to solve. Current large-scale freeway traffic datasets are not designed\nfor anomaly detection and ignore these challenges. In this paper, we introduce\nthe first large-scale lane-level freeway traffic dataset for anomaly detection.\nOur dataset consists of a month of weekday radar detection sensor data\ncollected in 4 lanes along an 18-mile stretch of Interstate 24 heading toward\nNashville, TN, comprising over 3.7 million sensor measurements. We also collect\nofficial crash reports from the Nashville Traffic Management Center and\nmanually label all other potential anomalies in the dataset. To show the\npotential for our dataset to be used in future machine learning and traffic\nresearch, we benchmark numerous deep learning anomaly detection models on our\ndataset. We find that unsupervised graph neural network autoencoders are a\npromising solution for this problem and that ignoring spatial relationships\nleads to decreased performance. We demonstrate that our methods can reduce\nreporting delays by over 10 minutes on average while detecting 75% of crashes.\nOur dataset and all preprocessing code needed to get started are publicly\nreleased at https://vu.edu/ft-aed/ to facilitate future research.\n","authors":["Austin Coursey","Junyi Ji","Marcos Quinones-Grueiro","William Barbour","Yuhang Zhang","Tyler Derr","Gautam Biswas","Daniel B. Work"],"pdf_url":"https://arxiv.org/pdf/2406.15283v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10267v3","updated":"2024-06-24T15:19:44Z","published":"2023-05-17T14:58:58Z","title":"State Representation Learning Using an Unbalanced Atlas","summary":"  The manifold hypothesis posits that high-dimensional data often lies on a\nlower-dimensional manifold and that utilizing this manifold as the target space\nyields more efficient representations. While numerous traditional\nmanifold-based techniques exist for dimensionality reduction, their application\nin self-supervised learning has witnessed slow progress. The recent MSimCLR\nmethod combines manifold encoding with SimCLR but requires extremely low target\nencoding dimensions to outperform SimCLR, limiting its applicability. This\npaper introduces a novel learning paradigm using an unbalanced atlas (UA),\ncapable of surpassing state-of-the-art self-supervised learning approaches. We\ninvestigated and engineered the DeepInfomax with an unbalanced atlas (DIM-UA)\nmethod by adapting the Spatiotemporal DeepInfomax (ST-DIM) framework to align\nwith our proposed UA paradigm. The efficacy of DIM-UA is demonstrated through\ntraining and evaluation on the Atari Annotated RAM Interface (AtariARI)\nbenchmark, a modified version of the Atari 2600 framework that produces\nannotated image samples for representation learning. The UA paradigm improves\nexisting algorithms significantly as the number of target encoding dimensions\ngrows. For instance, the mean F1 score averaged over categories of DIM-UA is\n~75% compared to ~70% of ST-DIM when using 16384 hidden units.\n","authors":["Li Meng","Morten Goodwin","Anis Yazidi","Paal Engelstad"],"pdf_url":"https://arxiv.org/pdf/2305.10267v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16715v1","updated":"2024-06-24T15:17:49Z","published":"2024-06-24T15:17:49Z","title":"GC-Bench: A Benchmark Framework for Graph Condensation with New Insights","summary":"  Graph condensation (GC) is an emerging technique designed to learn a\nsignificantly smaller graph that retains the essential information of the\noriginal graph. This condensed graph has shown promise in accelerating graph\nneural networks while preserving performance comparable to those achieved with\nthe original, larger graphs. Additionally, this technique facilitates\ndownstream applications such as neural architecture search and enhances our\nunderstanding of redundancy in large graphs. Despite the rapid development of\nGC methods, a systematic evaluation framework remains absent, which is\nnecessary to clarify the critical designs for particular evaluative aspects.\nFurthermore, several meaningful questions have not been investigated, such as\nwhether GC inherently preserves certain graph properties and offers robustness\neven without targeted design efforts. In this paper, we introduce GC-Bench, a\ncomprehensive framework to evaluate recent GC methods across multiple\ndimensions and to generate new insights. Our experimental findings provide a\ndeeper insights into the GC process and the characteristics of condensed\ngraphs, guiding future efforts in enhancing performance and exploring new\napplications. Our code is available at\n\\url{https://github.com/Emory-Melody/GraphSlim/tree/main/benchmark}.\n","authors":["Shengbo Gong","Juntong Ni","Noveen Sachdeva","Carl Yang","Wei Jin"],"pdf_url":"https://arxiv.org/pdf/2406.16715v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.16714v1","updated":"2024-06-24T15:16:45Z","published":"2024-06-24T15:16:45Z","title":"AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models","summary":"  Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.\n","authors":["Jiale Cheng","Yida Lu","Xiaotao Gu","Pei Ke","Xiao Liu","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16708v1","updated":"2024-06-24T15:09:29Z","published":"2024-06-24T15:09:29Z","title":"CausalFormer: An Interpretable Transformer for Temporal Causal Discovery","summary":"  Temporal causal discovery is a crucial task aimed at uncovering the causal\nrelations within time series data. The latest temporal causal discovery methods\nusually train deep learning models on prediction tasks to uncover the causality\nbetween time series. They capture causal relations by analyzing the parameters\nof some components of the trained models, e.g., attention weights and\nconvolution weights. However, this is an incomplete mapping process from the\nmodel parameters to the causality and fails to investigate the other\ncomponents, e.g., fully connected layers and activation functions, that are\nalso significant for causal discovery. To facilitate the utilization of the\nwhole deep learning models in temporal causal discovery, we proposed an\ninterpretable transformer-based causal discovery model termed CausalFormer,\nwhich consists of the causality-aware transformer and the decomposition-based\ncausality detector. The causality-aware transformer learns the causal\nrepresentation of time series data using a prediction task with the designed\nmulti-kernel causal convolution which aggregates each input time series along\nthe temporal dimension under the temporal priority constraint. Then, the\ndecomposition-based causality detector interprets the global structure of the\ntrained causality-aware transformer with the proposed regression relevance\npropagation to identify potential causal relations and finally construct the\ncausal graph. Experiments on synthetic, simulated, and real datasets\ndemonstrate the state-of-the-art performance of CausalFormer on discovering\ntemporal causality. Our code is available at\nhttps://github.com/lingbai-kong/CausalFormer.\n","authors":["Lingbai Kong","Wengen Li","Hanchen Yang","Yichao Zhang","Jihong Guan","Shuigeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.16708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16707v1","updated":"2024-06-24T15:09:22Z","published":"2024-06-24T15:09:22Z","title":"Probabilistic Subgoal Representations for Hierarchical Reinforcement\n  learning","summary":"  In goal-conditioned hierarchical reinforcement learning (HRL), a high-level\npolicy specifies a subgoal for the low-level policy to reach. Effective HRL\nhinges on a suitable subgoal represen tation function, abstracting state space\ninto latent subgoal space and inducing varied low-level behaviors. Existing\nmethods adopt a subgoal representation that provides a deterministic mapping\nfrom state space to latent subgoal space. Instead, this paper utilizes Gaussian\nProcesses (GPs) for the first probabilistic subgoal representation. Our method\nemploys a GP prior on the latent subgoal space to learn a posterior\ndistribution over the subgoal representation functions while exploiting the\nlong-range correlation in the state space through learnable kernels. This\nenables an adaptive memory that integrates long-range subgoal information from\nprior planning steps allowing to cope with stochastic uncertainties.\nFurthermore, we propose a novel learning objective to facilitate the\nsimultaneous learning of probabilistic subgoal representations and policies\nwithin a unified framework. In experiments, our approach outperforms\nstate-of-the-art baselines in standard benchmarks but also in environments with\nstochastic elements and under diverse reward conditions. Additionally, our\nmodel shows promising capabilities in transferring low-level policies across\ndifferent tasks.\n","authors":["Vivienne Huiling Wang","Tinghuai Wang","Wenyan Yang","Joni-Kristian Kämäräinen","Joni Pajarinen"],"pdf_url":"https://arxiv.org/pdf/2406.16707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04846v2","updated":"2024-06-24T15:07:56Z","published":"2023-11-08T17:29:41Z","title":"Incorporating temporal dynamics of mutations to enhance the prediction\n  capability of antiretroviral therapy's outcome for HIV-1","summary":"  Motivation: In predicting HIV therapy outcomes, a critical clinical question\nis whether using historical information can enhance predictive capabilities\ncompared with current or latest available data analysis. This study analyses\nwhether historical knowledge, which includes viral mutations detected in all\ngenotypic tests before therapy, their temporal occurrence, and concomitant\nviral load measurements, can bring improvements. We introduce a method to weigh\nmutations, considering the previously enumerated factors and the reference\nmutation-drug Stanford resistance tables. We compare a model encompassing\nhistory (H) with one not using it (NH). Results: The H-model demonstrates\nsuperior discriminative ability, with a higher ROC-AUC score (76.34%) than the\nNH-model (74.98%). Significant Wilcoxon test results confirm that incorporating\nhistorical information improves consistently predictive accuracy for treatment\noutcomes. The better performance of the H-model might be attributed to its\nconsideration of latent HIV reservoirs, probably obtained when leveraging\nhistorical information. The findings emphasize the importance of temporal\ndynamics in mutations, offering insights into HIV infection complexities.\nHowever, our result also shows that prediction accuracy remains relatively high\neven when no historical information is available. Supplementary information:\nSupplementary material is available.\n","authors":["Giulia Di Teodoro","Martin Pirkl","Francesca Incardona","Ilaria Vicenti","Anders Sönnerborg","Rolf Kaiser","Laura Palagi","Maurizio Zazzi","Thomas Lengauer"],"pdf_url":"https://arxiv.org/pdf/2311.04846v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.16698v1","updated":"2024-06-24T15:01:05Z","published":"2024-06-24T15:01:05Z","title":"Learning Interpretable Fair Representations","summary":"  Numerous approaches have been recently proposed for learning fair\nrepresentations that mitigate unfair outcomes in prediction tasks. A key\nmotivation for these methods is that the representations can be used by third\nparties with unknown objectives. However, because current fair representations\nare generally not interpretable, the third party cannot use these fair\nrepresentations for exploration, or to obtain any additional insights, besides\nthe pre-contracted prediction tasks. Thus, to increase data utility beyond\nprediction tasks, we argue that the representations need to be fair, yet\ninterpretable. We propose a general framework for learning interpretable fair\nrepresentations by introducing an interpretable \"prior knowledge\" during the\nrepresentation learning process. We implement this idea and conduct experiments\nwith ColorMNIST and Dsprite datasets. The results indicate that in addition to\nbeing interpretable, our representations attain slightly higher accuracy and\nfairer outcomes in a downstream classification task compared to\nstate-of-the-art fair representations.\n","authors":["Tianhao Wang","Zana Buçinca","Zilin Ma"],"pdf_url":"https://arxiv.org/pdf/2406.16698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.15269v4","updated":"2024-06-24T14:54:37Z","published":"2022-06-30T13:20:48Z","title":"Deep Reinforcement Learning with Swin Transformers","summary":"  Transformers are neural network models that utilize multiple layers of\nself-attention heads and have exhibited enormous potential in natural language\nprocessing tasks. Meanwhile, there have been efforts to adapt transformers to\nvisual tasks of machine learning, including Vision Transformers and Swin\nTransformers. Although some researchers use Vision Transformers for\nreinforcement learning tasks, their experiments remain at a small scale due to\nthe high computational cost. This article presents the first online\nreinforcement learning scheme that is based on Swin Transformers: Swin DQN. In\ncontrast to existing research, our novel approach demonstrate the superior\nperformance with experiments on 49 games in the Arcade Learning Environment.\nThe results show that our approach achieves significantly higher maximal\nevaluation scores than the baseline method in 45 of all the 49 games (92%), and\nhigher mean evaluation scores than the baseline method in 40 of all the 49\ngames (82%).\n","authors":["Li Meng","Morten Goodwin","Anis Yazidi","Paal Engelstad"],"pdf_url":"https://arxiv.org/pdf/2206.15269v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16689v1","updated":"2024-06-24T14:50:05Z","published":"2024-06-24T14:50:05Z","title":"Coding schemes in neural networks learning classification tasks","summary":"  Neural networks posses the crucial ability to generate meaningful\nrepresentations of task-dependent features. Indeed, with appropriate scaling,\nsupervised learning in neural networks can result in strong, task-dependent\nfeature learning. However, the nature of the emergent representations, which we\ncall the `coding scheme', is still unclear. To understand the emergent coding\nscheme, we investigate fully-connected, wide neural networks learning\nclassification tasks using the Bayesian framework where learning shapes the\nposterior distribution of the network weights. Consistent with previous\nfindings, our analysis of the feature learning regime (also known as\n`non-lazy', `rich', or `mean-field' regime) shows that the networks acquire\nstrong, data-dependent features. Surprisingly, the nature of the internal\nrepresentations depends crucially on the neuronal nonlinearity. In linear\nnetworks, an analog coding scheme of the task emerges. Despite the strong\nrepresentations, the mean predictor is identical to the lazy case. In nonlinear\nnetworks, spontaneous symmetry breaking leads to either redundant or sparse\ncoding schemes. Our findings highlight how network properties such as scaling\nof weights and neuronal nonlinearity can profoundly influence the emergent\nrepresentations.\n","authors":["Alexander van Meegen","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2406.16689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.19361v2","updated":"2024-06-24T14:48:29Z","published":"2024-02-29T17:12:39Z","title":"Watermark Stealing in Large Language Models","summary":"  LLM watermarking has attracted attention as a promising way to detect\nAI-generated content, with some works suggesting that current schemes may\nalready be fit for deployment. In this work we dispute this claim, identifying\nwatermark stealing (WS) as a fundamental vulnerability of these schemes. We\nshow that querying the API of the watermarked LLM to approximately\nreverse-engineer a watermark enables practical spoofing attacks, as\nhypothesized in prior work, but also greatly boosts scrubbing attacks, which\nwas previously unnoticed. We are the first to propose an automated WS algorithm\nand use it in the first comprehensive study of spoofing and scrubbing in\nrealistic settings. We show that for under $50 an attacker can both spoof and\nscrub state-of-the-art schemes previously considered safe, with average success\nrate of over 80%. Our findings challenge common beliefs about LLM watermarking,\nstressing the need for more robust schemes. We make all our code and additional\nexamples available at https://watermark-stealing.org.\n","authors":["Nikola Jovanović","Robin Staab","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2402.19361v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.16687v1","updated":"2024-06-24T14:46:34Z","published":"2024-06-24T14:46:34Z","title":"Link Prediction with Untrained Message Passing Layers","summary":"  Message passing neural networks (MPNNs) operate on graphs by exchanging\ninformation between neigbouring nodes. MPNNs have been successfully applied to\nvarious node-, edge-, and graph-level tasks in areas like molecular science,\ncomputer vision, natural language processing, and combinatorial optimization.\nHowever, most MPNNs require training on large amounts of labeled data, which\ncan be costly and time-consuming. In this work, we explore the use of various\nuntrained message passing layers in graph neural networks, i.e. variants of\npopular message passing architecture where we remove all trainable parameters\nthat are used to transform node features in the message passing step. Focusing\non link prediction, we find that untrained message passing layers can lead to\ncompetitive and even superior performance compared to fully trained MPNNs,\nespecially in the presence of high-dimensional features. We provide a\ntheoretical analysis of untrained message passing by relating the inner\nproducts of features implicitly produced by untrained message passing layers to\npath-based topological node similarity measures. As such, untrained message\npassing architectures can be viewed as a highly efficient and interpretable\napproach to link prediction.\n","authors":["Lisi Qarkaxhija","Anatol E. Wegner","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2406.16687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16683v1","updated":"2024-06-24T14:43:02Z","published":"2024-06-24T14:43:02Z","title":"Repulsive Score Distillation for Diverse Sampling of Diffusion Models","summary":"  Score distillation sampling has been pivotal for integrating diffusion models\ninto generation of complex visuals. Despite impressive results it suffers from\nmode collapse and lack of diversity. To cope with this challenge, we leverage\nthe gradient flow interpretation of score distillation to propose Repulsive\nScore Distillation (RSD). In particular, we propose a variational framework\nbased on repulsion of an ensemble of particles that promotes diversity. Using a\nvariational approximation that incorporates a coupling among particles, the\nrepulsion appears as a simple regularization that allows interaction of\nparticles based on their relative pairwise similarity, measured e.g., via\nradial basis kernels. We design RSD for both unconstrained and constrained\nsampling scenarios. For constrained sampling we focus on inverse problems in\nthe latent space that leads to an augmented variational formulation, that\nstrikes a good balance between compute, quality and diversity. Our extensive\nexperiments for text-to-image generation, and inverse problems demonstrate that\nRSD achieves a superior trade-off between diversity and quality compared with\nstate-of-the-art alternatives.\n","authors":["Nicolas Zilberstein","Morteza Mardani","Santiago Segarra"],"pdf_url":"https://arxiv.org/pdf/2406.16683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16681v1","updated":"2024-06-24T14:42:27Z","published":"2024-06-24T14:42:27Z","title":"A Comprehensive Review of Emerging Approaches in Machine Learning for De\n  Novo PROTAC Design","summary":"  Targeted protein degradation (TPD) is a rapidly growing field in modern drug\ndiscovery that aims to regulate the intracellular levels of proteins by\nharnessing the cell's innate degradation pathways to selectively target and\ndegrade disease-related proteins. This strategy creates new opportunities for\ntherapeutic intervention in cases where occupancy-based inhibitors have not\nbeen successful. Proteolysis-targeting chimeras (PROTACs) are at the heart of\nTPD strategies, which leverage the ubiquitin-proteasome system for the\nselective targeting and proteasomal degradation of pathogenic proteins. As the\nfield evolves, it becomes increasingly apparent that the traditional\nmethodologies for designing such complex molecules have limitations. This has\nled to the use of machine learning (ML) and generative modeling to improve and\naccelerate the development process. In this review, we explore the impact of ML\non de novo PROTAC design $-$ an aspect of molecular design that has not been\ncomprehensively reviewed despite its significance. We delve into the distinct\ncharacteristics of PROTAC linker design, underscoring the complexities required\nto create effective bifunctional molecules capable of TPD. We then examine how\nML in the context of fragment-based drug design (FBDD), honed in the realm of\nsmall-molecule drug discovery, is paving the way for PROTAC linker design. Our\nreview provides a critical evaluation of the limitations inherent in applying\nthis method to the complex field of PROTAC development. Moreover, we review\nexisting ML works applied to PROTAC design, highlighting pioneering efforts\nand, importantly, the limitations these studies face. By offering insights into\nthe current state of PROTAC development and the integral role of ML in PROTAC\ndesign, we aim to provide valuable perspectives for researchers in their\npursuit of better design strategies for this new modality.\n","authors":["Yossra Gharbi","Rocío Mercado"],"pdf_url":"https://arxiv.org/pdf/2406.16681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16678v1","updated":"2024-06-24T14:36:11Z","published":"2024-06-24T14:36:11Z","title":"Segment Any Text: A Universal Approach for Robust, Efficient and\n  Adaptable Sentence Segmentation","summary":"  Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.\n","authors":["Markus Frohmann","Igor Sterner","Ivan Vulić","Benjamin Minixhofer","Markus Schedl"],"pdf_url":"https://arxiv.org/pdf/2406.16678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09900v2","updated":"2024-06-24T14:33:17Z","published":"2022-08-21T14:57:47Z","title":"Provable Adaptivity of Adam under Non-uniform Smoothness","summary":"  Adam is widely adopted in practical applications due to its fast convergence.\nHowever, its theoretical analysis is still far from satisfactory. Existing\nconvergence analyses for Adam rely on the bounded smoothness assumption,\nreferred to as the \\emph{L-smooth condition}. Unfortunately, this assumption\ndoes not hold for many deep learning tasks. Moreover, we believe that this\nassumption obscures the true benefit of Adam, as the algorithm can adapt its\nupdate magnitude according to local smoothness. This important feature of Adam\nbecomes irrelevant when assuming globally bounded smoothness. This paper\nstudies the convergence of randomly reshuffled Adam (RR Adam) with diminishing\nlearning rate, which is the major version of Adam adopted in deep learning\ntasks. We present the first convergence analysis of RR Adam without the bounded\nsmoothness assumption. We demonstrate that RR Adam can maintain its convergence\nproperties when smoothness is linearly bounded by the gradient norm, referred\nto as the \\emph{$(L_0, L_1)$-smooth condition. We further compare Adam to SGD\nwhen both methods use diminishing learning rate. We refine the existing lower\nbound of SGD and show that SGD can be slower than Adam. To our knowledge, this\nis the first time that Adam and SGD are rigorously compared in the same setting\nand the advantage of Adam is revealed.\n","authors":["Bohan Wang","Yushun Zhang","Huishuai Zhang","Qi Meng","Ruoyu Sun","Zhi-Ming Ma","Tie-Yan Liu","Zhi-Quan Luo","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2208.09900v2.pdf","comment":"KDD 2024"},{"id":"http://arxiv.org/abs/2402.11778v2","updated":"2024-06-24T14:23:30Z","published":"2024-02-19T02:08:09Z","title":"Towards Theoretical Understandings of Self-Consuming Generative Models","summary":"  This paper tackles the emerging challenge of training generative models\nwithin a self-consuming loop, wherein successive generations of models are\nrecursively trained on mixtures of real and synthetic data from previous\ngenerations. We construct a theoretical framework to rigorously evaluate how\nthis training procedure impacts the data distributions learned by future\nmodels, including parametric and non-parametric models. Specifically, we derive\nbounds on the total variation (TV) distance between the synthetic data\ndistributions produced by future models and the original real data distribution\nunder various mixed training scenarios for diffusion models with a\none-hidden-layer neural network score function. Our analysis demonstrates that\nthis distance can be effectively controlled under the condition that mixed\ntraining dataset sizes or proportions of real data are large enough.\nInterestingly, we further unveil a phase transition induced by expanding\nsynthetic data amounts, proving theoretically that while the TV distance\nexhibits an initial ascent, it declines beyond a threshold point. Finally, we\npresent results for kernel density estimation, delivering nuanced insights such\nas the impact of mixed data training on error propagation.\n","authors":["Shi Fu","Sen Zhang","Yingjie Wang","Xinmei Tian","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2402.11778v2.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2406.16666v1","updated":"2024-06-24T14:20:02Z","published":"2024-06-24T14:20:02Z","title":"Cubic regularized subspace Newton for non-convex optimization","summary":"  This paper addresses the optimization problem of minimizing non-convex\ncontinuous functions, which is relevant in the context of high-dimensional\nmachine learning applications characterized by over-parametrization. We analyze\na randomized coordinate second-order method named SSCN which can be interpreted\nas applying cubic regularization in random subspaces. This approach effectively\nreduces the computational complexity associated with utilizing second-order\ninformation, rendering it applicable in higher-dimensional scenarios.\nTheoretically, we establish convergence guarantees for non-convex functions,\nwith interpolating rates for arbitrary subspace sizes and allowing inexact\ncurvature estimation. When increasing subspace size, our complexity matches\n$\\mathcal{O}(\\epsilon^{-3/2})$ of the cubic regularization (CR) rate.\nAdditionally, we propose an adaptive sampling scheme ensuring exact convergence\nrate of $\\mathcal{O}(\\epsilon^{-3/2}, \\epsilon^{-3})$ to a second-order\nstationary point, even without sampling all coordinates. Experimental results\ndemonstrate substantial speed-ups achieved by SSCN compared to conventional\nfirst-order methods.\n","authors":["Jim Zhao","Aurelien Lucchi","Nikita Doikov"],"pdf_url":"https://arxiv.org/pdf/2406.16666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16659v1","updated":"2024-06-24T14:09:45Z","published":"2024-06-24T14:09:45Z","title":"Data-driven Modeling in Metrology -- A Short Introduction, Current\n  Developments and Future Perspectives","summary":"  Mathematical models are vital to the field of metrology, playing a key role\nin the derivation of measurement results and the calculation of uncertainties\nfrom measurement data, informed by an understanding of the measurement process.\nThese models generally represent the correlation between the quantity being\nmeasured and all other pertinent quantities. Such relationships are used to\nconstruct measurement systems that can interpret measurement data to generate\nconclusions and predictions about the measurement system itself. Classic models\nare typically analytical, built on fundamental physical principles. However,\nthe rise of digital technology, expansive sensor networks, and high-performance\ncomputing hardware have led to a growing shift towards data-driven\nmethodologies. This trend is especially prominent when dealing with large,\nintricate networked sensor systems in situations where there is limited expert\nunderstanding of the frequently changing real-world contexts. Here, we\ndemonstrate the variety of opportunities that data-driven modeling presents,\nand how they have been already implemented in various real-world applications.\n","authors":["Linda-Sophie Schneider","Patrick Krauss","Nadine Schiering","Christopher Syben","Richard Schielein","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2406.16659v1.pdf","comment":"31 pages, Preprint"},{"id":"http://arxiv.org/abs/2305.16610v5","updated":"2024-06-24T14:06:29Z","published":"2023-05-26T04:02:54Z","title":"Adaptively Perturbed Mirror Descent for Learning in Games","summary":"  This paper proposes a payoff perturbation technique for the Mirror Descent\n(MD) algorithm in games where the gradient of the payoff functions is monotone\nin the strategy profile space, potentially containing additive noise. The\noptimistic family of learning algorithms, exemplified by optimistic MD,\nsuccessfully achieves {\\it last-iterate} convergence in scenarios devoid of\nnoise, leading the dynamics to a Nash equilibrium. A recent re-emerging trend\nunderscores the promise of the perturbation approach, where payoff functions\nare perturbed based on the distance from an anchoring, or {\\it slingshot},\nstrategy. In response, we propose {\\it Adaptively Perturbed MD} (APMD), which\nadjusts the magnitude of the perturbation by repeatedly updating the slingshot\nstrategy at a predefined interval. This innovation empowers us to find a Nash\nequilibrium of the underlying game with guaranteed rates. Empirical\ndemonstrations affirm that our algorithm exhibits significantly accelerated\nconvergence.\n","authors":["Kenshi Abe","Kaito Ariu","Mitsuki Sakamoto","Atsushi Iwasaki"],"pdf_url":"https://arxiv.org/pdf/2305.16610v5.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2308.13279v2","updated":"2024-06-24T13:57:01Z","published":"2023-08-25T10:01:53Z","title":"Hyperbolic Random Forests","summary":"  Hyperbolic space is becoming a popular choice for representing data due to\nthe hierarchical structure - whether implicit or explicit - of many real-world\ndatasets. Along with it comes a need for algorithms capable of solving\nfundamental tasks, such as classification, in hyperbolic space. Recently,\nmultiple papers have investigated hyperbolic alternatives to hyperplane-based\nclassifiers, such as logistic regression and SVMs. While effective, these\napproaches struggle with more complex hierarchical data. We, therefore, propose\nto generalize the well-known random forests to hyperbolic space. We do this by\nredefining the notion of a split using horospheres. Since finding the globally\noptimal split is computationally intractable, we find candidate horospheres\nthrough a large-margin classifier. To make hyperbolic random forests work on\nmulti-class data and imbalanced experiments, we furthermore outline a new\nmethod for combining classes based on their lowest common ancestor and a\nclass-balanced version of the large-margin loss. Experiments on standard and\nnew benchmarks show that our approach outperforms both conventional random\nforest algorithms and recent hyperbolic classifiers.\n","authors":["Lars Doorenbos","Pablo Márquez-Neila","Raphael Sznitman","Pascal Mettes"],"pdf_url":"https://arxiv.org/pdf/2308.13279v2.pdf","comment":"Accepted at TMLR. Code available at\n  https://github.com/LarsDoorenbos/HoroRF"},{"id":"http://arxiv.org/abs/2406.10670v2","updated":"2024-06-24T13:52:37Z","published":"2024-06-15T15:28:02Z","title":"CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language\n  Model Pre-training","summary":"  Selecting high-quality data for pre-training is crucial in shaping the\ndownstream task performance of language models. A major challenge lies in\nidentifying this optimal subset, a problem generally considered intractable,\nthus necessitating scalable and effective heuristics. In this work, we propose\na data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering),\nwhich leverages an empirical Bayes-inspired approach to derive a simple and\ncomputationally efficient selection criterion based on the relative loss values\nof two auxiliary models.\n  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically\non two language modeling tasks: (1) selecting data from C4 for domain\nadaptation to evaluation on Books and (2) selecting data from C4 for a suite of\ndownstream multiple-choice question answering tasks. We demonstrate favorable\nscaling both as we subselect more aggressively and using small auxiliary models\nto select data for large target models. As one headline result, CoLoR-Filter\ndata selected using a pair of 150m parameter auxiliary models can train a 1.2b\nparameter target model to match a 1.2b parameter model trained on 25b randomly\nselected tokens with 25x less data for Books and 11x less data for the\ndownstream tasks.\n  Code: https://github.com/davidbrandfonbrener/color-filter-olmo\n  Filtered data:\nhttps://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4\n","authors":["David Brandfonbrener","Hanlin Zhang","Andreas Kirsch","Jonathan Richard Schwarz","Sham Kakade"],"pdf_url":"https://arxiv.org/pdf/2406.10670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00423v2","updated":"2024-06-24T13:43:10Z","published":"2024-03-01T10:19:32Z","title":"Validation of ML-UQ calibration statistics using simulated reference\n  values: a sensitivity analysis","summary":"  Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration\nstatistics do not have predefined reference values and are mostly used in\ncomparative studies. In consequence, calibration is almost never validated and\nthe diagnostic is left to the appreciation of the reader. Simulated reference\nvalues, based on synthetic calibrated datasets derived from actual\nuncertainties, have been proposed to palliate this problem. As the generative\nprobability distribution for the simulation of synthetic errors is often not\nconstrained, the sensitivity of simulated reference values to the choice of\ngenerative distribution might be problematic, shedding a doubt on the\ncalibration diagnostic. This study explores various facets of this problem, and\nshows that some statistics are excessively sensitive to the choice of\ngenerative distribution to be used for validation when the generative\ndistribution is unknown. This is the case, for instance, of the correlation\ncoefficient between absolute errors and uncertainties (CC) and of the expected\nnormalized calibration error (ENCE). A robust validation workflow to deal with\nsimulated reference values is proposed.\n","authors":["Pascal Pernot"],"pdf_url":"https://arxiv.org/pdf/2403.00423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16635v1","updated":"2024-06-24T13:41:08Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated techniques like quantization and\nsparsity. Contextual sparsity, where the sparsity pattern is input-dependent,\nis crucial in LLMs because the permanent removal of attention heads or neurons\nfrom LLMs can significantly degrade accuracy. Prior work has attempted to model\ncontextual sparsity using neural networks trained to predict activation\nmagnitudes, which can be used to dynamically prune structures with low\npredicted activation magnitude. In this paper, we look beyond magnitude-based\npruning criteria to assess attention head and neuron importance in LLMs. We\ndeveloped a novel predictor called ShadowLLM, which can shadow the LLM behavior\nand enforce better sparsity patterns, resulting in over 15% improvement in\nend-to-end accuracy without increasing latency compared to previous methods.\nShadowLLM achieves up to a 20\\% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on models with up to 30 billion\nparameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14518v3","updated":"2024-06-24T13:36:56Z","published":"2023-09-25T20:24:36Z","title":"Detach-ROCKET: Sequential feature selection for time series\n  classification with random convolutional kernels","summary":"  Time Series Classification (TSC) is essential in fields like medicine,\nenvironmental science, and finance, enabling tasks such as disease diagnosis,\nanomaly detection, and stock price analysis. While machine learning models like\nRecurrent Neural Networks and InceptionTime are successful in numerous\napplications, they can face scalability issues due to computational\nrequirements. Recently, ROCKET has emerged as an efficient alternative,\nachieving state-of-the-art performance and simplifying training by utilizing a\nlarge number of randomly generated features from the time series data. However,\nmany of these features are redundant or non-informative, increasing\ncomputational load and compromising generalization. Here we introduce\nSequential Feature Detachment (SFD) to identify and prune non-essential\nfeatures in ROCKET-based models, such as ROCKET, MiniRocket, and MultiRocket.\nSFD estimates feature importance using model coefficients and can handle large\nfeature sets without complex hyperparameter tuning. Testing on the UCR archive\nshows that SFD can produce models with better test accuracy using only 10\\% of\nthe original features. We named these pruned models Detach-ROCKET. We also\npresent an end-to-end procedure for determining an optimal balance between the\nnumber of features and model accuracy. On the largest binary UCR dataset,\nDetach-ROCKET improves test accuracy by 0.6\\% while reducing features by\n98.9\\%. By enabling a significant reduction in model size without sacrificing\naccuracy, our methodology improves computational efficiency and contributes to\nmodel interpretability. We believe that Detach-ROCKET will be a valuable tool\nfor researchers and practitioners working with time series data, who can find a\nuser-friendly implementation of the model at\n\\url{https://github.com/gon-uri/detach_rocket}.\n","authors":["Gonzalo Uribarri","Federico Barone","Alessio Ansuini","Erik Fransén"],"pdf_url":"https://arxiv.org/pdf/2309.14518v3.pdf","comment":"18 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.19181v2","updated":"2024-06-24T13:22:22Z","published":"2024-03-28T07:22:16Z","title":"Make Large Language Model a Better Ranker","summary":"  Large Language Models (LLMs) demonstrate robust capabilities across various\nfields, leading to a paradigm shift in LLM-enhanced Recommender System (RS).\nResearch to date focuses on point-wise and pair-wise recommendation paradigms,\nwhich are inefficient for LLM-based recommenders due to high computational\ncosts. However, existing list-wise approaches also fall short in ranking tasks\ndue to misalignment between ranking objectives and next-token prediction.\nMoreover, these LLM-based methods struggle to effectively address the order\nrelation among candidates, particularly given the scale of ratings. To address\nthese challenges, this paper introduces the large language model framework with\nAligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap\nbetween the capabilities of LLMs and the nuanced requirements of ranking tasks.\nSpecifically, ALRO employs explicit feedback in a listwise manner by\nintroducing soft lambda loss, a customized adaptation of lambda loss designed\nfor optimizing order relations. This mechanism provides more accurate\noptimization goals, enhancing the ranking process. Additionally, ALRO\nincorporates a permutation-sensitive learning mechanism that addresses position\nbias, a prevalent issue in generative models, without imposing additional\ncomputational burdens during inference. Our evaluative studies reveal that ALRO\noutperforms both existing embedding-based recommendation methods and LLM-based\nrecommendation baselines.\n","authors":["Wenshuo Chao","Zhi Zheng","Hengshu Zhu","Hao Liu"],"pdf_url":"https://arxiv.org/pdf/2403.19181v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.16369v3","updated":"2024-06-24T13:19:17Z","published":"2024-03-25T02:17:54Z","title":"Learning Action-based Representations Using Invariance","summary":"  Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.\n","authors":["Max Rudolph","Caleb Chuck","Kevin Black","Misha Lvovsky","Scott Niekum","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16369v3.pdf","comment":"Published at the Reinforcement Learning Conference 2024"},{"id":"http://arxiv.org/abs/2403.05268v2","updated":"2024-06-24T13:15:33Z","published":"2024-03-08T12:45:53Z","title":"Deep Prompt Multi-task Network for Abuse Language Detection","summary":"  The detection of abusive language remains a long-standing challenge with the\nextensive use of social networks. The detection task of abusive language\nsuffers from limited accuracy. We argue that the existing detection methods\nutilize the fine-tuning technique of the pre-trained language models (PLMs) to\nhandle downstream tasks. Hence, these methods fail to stimulate the general\nknowledge of the PLMs. To address the problem, we propose a novel Deep Prompt\nMulti-task Network (DPMN) for abuse language detection. Specifically, DPMN\nfirst attempts to design two forms of deep prompt tuning and light prompt\ntuning for the PLMs. The effects of different prompt lengths, tuning\nstrategies, and prompt initialization methods on detecting abusive language are\nstudied. In addition, we propose a Task Head based on Bi-LSTM and FFN, which\ncan be used as a short text classifier. Eventually, DPMN utilizes multi-task\nlearning to improve detection metrics further. The multi-task network has the\nfunction of transferring effective knowledge. The proposed DPMN is evaluated\nagainst eight typical methods on three public datasets: OLID, SOLID, and\nAbuseAnalyzer. The experimental results show that our DPMN outperforms the\nstate-of-the-art methods.\n","authors":["Jian Zhu","Yuping Ruan","Jingfei Chang","Wenhui Sun","Hui Wan","Jian Long","Cheng Luo"],"pdf_url":"https://arxiv.org/pdf/2403.05268v2.pdf","comment":"Accepted by the International Conference on Pattern Recognition\n  (ICPR) 2024"},{"id":"http://arxiv.org/abs/2302.05620v2","updated":"2024-06-24T13:11:08Z","published":"2023-02-11T07:19:51Z","title":"Improved Dynamic Regret for Online Frank-Wolfe","summary":"  To deal with non-stationary online problems with complex constraints, we\ninvestigate the dynamic regret of online Frank-Wolfe (OFW), which is an\nefficient projection-free algorithm for online convex optimization. It is\nwell-known that in the setting of offline optimization, the smoothness of\nfunctions and the strong convexity of functions accompanying specific\nproperties of constraint sets can be utilized to achieve fast convergence rates\nfor the Frank-Wolfe (FW) algorithm. However, for OFW, previous studies only\nestablish a dynamic regret bound of $O(\\sqrt{T}(V_T+\\sqrt{D_T}+1))$ by\nutilizing the convexity of problems, where $T$ is the number of rounds, $V_T$\nis the function variation, and $D_T$ is the gradient variation. In this paper,\nwe derive improved dynamic regret bounds for OFW by extending the fast\nconvergence rates of FW from offline optimization to online optimization. The\nkey technique for this extension is to set the step size of OFW with a line\nsearch rule. In this way, we first show that the dynamic regret bound of OFW\ncan be improved to $O(\\sqrt{T(V_T+1)})$ for smooth functions. Second, we\nachieve a better dynamic regret bound of $O(T^{1/3}(V_T+1)^{2/3})$ when\nfunctions are smooth and strongly convex, and the constraint set is strongly\nconvex. Finally, for smooth and strongly convex functions with minimizers in\nthe interior of the constraint set, we demonstrate that the dynamic regret of\nOFW reduces to $O(V_T+1)$, and can be further strengthened to\n$O(\\min\\{P_T^\\ast,S_T^\\ast,V_T\\}+1)$ by performing a constant number of FW\niterations per round, where $P_T^\\ast$ and $S_T^\\ast$ denote the path length\nand squared path length of minimizers, respectively.\n","authors":["Yuanyu Wan","Lijun Zhang","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2302.05620v2.pdf","comment":"v2 matches the camera-ready version for COLT2023 better"},{"id":"http://arxiv.org/abs/2406.11779v5","updated":"2024-06-24T13:06:01Z","published":"2024-06-17T17:34:25Z","title":"Compact Proofs of Model Performance via Mechanistic Interpretability","summary":"  In this work, we propose using mechanistic interpretability -- techniques for\nreverse engineering model weights into human-interpretable algorithms -- to\nderive and compactly prove formal guarantees on model performance. We prototype\nthis approach by formally proving lower bounds on the accuracy of 151 small\ntransformers trained on a Max-of-$K$ task. We create 102 different\ncomputer-assisted proof strategies and assess their length and tightness of\nbound on each of our models. Using quantitative metrics, we find that shorter\nproofs seem to require and provide more mechanistic understanding. Moreover, we\nfind that more faithful mechanistic understanding leads to tighter performance\nbounds. We confirm these connections by qualitatively examining a subset of our\nproofs. Finally, we identify compounding structureless noise as a key challenge\nfor using mechanistic interpretability to generate compact proofs on model\nperformance.\n","authors":["Jason Gross","Rajashree Agrawal","Thomas Kwa","Euan Ong","Chun Hei Yip","Alex Gibson","Soufiane Noubir","Lawrence Chan"],"pdf_url":"https://arxiv.org/pdf/2406.11779v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15062v2","updated":"2024-06-24T13:03:11Z","published":"2024-01-26T18:44:49Z","title":"Expert with Clustering: Hierarchical Online Preference Learning\n  Framework","summary":"  Emerging mobility systems are increasingly capable of recommending options to\nmobility users, to guide them towards personalized yet sustainable system\noutcomes. Even more so than the typical recommendation system, it is crucial to\nminimize regret, because 1) the mobility options directly affect the lives of\nthe users, and 2) the system sustainability relies on sufficient user\nparticipation. In this study, we consider accelerating user preference learning\nby exploiting a low-dimensional latent space that captures the mobility\npreferences of users. We introduce a hierarchical contextual bandit framework\nnamed Expert with Clustering (EWC), which integrates clustering techniques and\nprediction with expert advice. EWC efficiently utilizes hierarchical user\ninformation and incorporates a novel Loss-guided Distance metric. This metric\nis instrumental in generating more representative cluster centroids. In a\nrecommendation scenario with $N$ users, $T$ rounds per user, and $K$ options,\nour algorithm achieves a regret bound of $O(N\\sqrt{T\\log K} + NT)$. This bound\nconsists of two parts: the first term is the regret from the Hedge algorithm,\nand the second term depends on the average loss from clustering. To the best of\nthe authors knowledge, this is the first work to analyze the regret of an\nintegrated expert algorithm with k-Means clustering. This regret bound\nunderscores the theoretical and experimental efficacy of EWC, particularly in\nscenarios that demand rapid learning and adaptation. Experimental results\nhighlight that EWC can substantially reduce regret by 27.57% compared to the\nLinUCB baseline. Our work offers a data-efficient approach to capturing both\nindividual and collective behaviors, making it highly applicable to contexts\nwith hierarchical structures. We expect the algorithm to be applicable to other\nsettings with layered nuances of user preferences and information.\n","authors":["Tianyue Zhou","Jung-Hoon Cho","Babak Rahimi Ardabili","Hamed Tabkhi","Cathy Wu"],"pdf_url":"https://arxiv.org/pdf/2401.15062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16619v1","updated":"2024-06-24T13:02:36Z","published":"2024-06-24T13:02:36Z","title":"No More Sliding-Windows: Dynamic Functional Connectivity Based On Random\n  Convolutions Without Learning","summary":"  In the field of dynamic functional connectivity, the sliding-window method is\nwidely used and its stability is generally recognized. However, the\nsliding-window method's data processing within the window is overly simplistic,\nwhich to some extent limits its effectiveness. This study proposes a feature\nexpansion method based on random convolution, which achieves better and more\nnoise-resistant results than the sliding-window method without requiring\ntraining. Experiments on simulated data show that the dynamic functional\nconnectivity matrix and time series obtained using the random convolution\nmethod have a higher degree of fit (95.59\\%) with the standard answers within\nshorter time windows, compared to the sliding-window method (45.99\\%). Gender\ndifference studies on real data also reveal that the random convolution method\nuncovers more gender differences than the sliding-window method. Through\ntheoretical analysis, we propose a more comprehensive convolutional functional\nconnectivity computation model, with the sliding-window method being a special\ncase of this model, thereby opening up vast potential for research methods in\ndynamic functional connectivity.\n","authors":["Yongjie Duan","Zhiying Long"],"pdf_url":"https://arxiv.org/pdf/2406.16619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.12797v2","updated":"2024-06-24T12:51:37Z","published":"2023-07-24T13:46:50Z","title":"Causal Fair Machine Learning via Rank-Preserving Interventional\n  Distributions","summary":"  A decision can be defined as fair if equal individuals are treated equally\nand unequals unequally. Adopting this definition, the task of designing machine\nlearning (ML) models that mitigate unfairness in automated decision-making\nsystems must include causal thinking when introducing protected attributes:\nFollowing a recent proposal, we define individuals as being normatively equal\nif they are equal in a fictitious, normatively desired (FiND) world, where the\nprotected attributes have no (direct or indirect) causal effect on the target.\nWe propose rank-preserving interventional distributions to define a specific\nFiND world in which this holds and a warping method for estimation. Evaluation\ncriteria for both the method and the resulting ML model are presented and\nvalidated through simulations. Experiments on empirical data showcase the\npractical application of our method and compare results with \"fairadapt\"\n(Ple\\v{c}ko and Meinshausen, 2020), a different approach for mitigating\nunfairness by causally preprocessing data that uses quantile regression\nforests. With this, we show that our warping approach effectively identifies\nthe most discriminated individuals and mitigates unfairness.\n","authors":["Ludwig Bothmann","Susanne Dandl","Michael Schomaker"],"pdf_url":"https://arxiv.org/pdf/2307.12797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16609v1","updated":"2024-06-24T12:48:44Z","published":"2024-06-24T12:48:44Z","title":"Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by\n  Evolving Adversarial Instances","summary":"  Deep neural networks (DNN) are increasingly being used to perform\nalgorithm-selection in combinatorial optimisation domains, particularly as they\naccommodate input representations which avoid designing and calculating\nfeatures. Mounting evidence from domains that use images as input shows that\ndeep convolutional networks are vulnerable to adversarial samples, in which a\nsmall perturbation of an instance can cause the DNN to misclassify. However, it\nremains unknown as to whether deep recurrent networks (DRN) which have recently\nbeen shown promise as algorithm-selectors in the bin-packing domain are equally\nvulnerable. We use an evolutionary algorithm (EA) to find perturbations of\ninstances from two existing benchmarks for online bin packing that cause\ntrained DRNs to misclassify: adversarial samples are successfully generated\nfrom up to 56% of the original instances depending on the dataset. Analysis of\nthe new misclassified instances sheds light on the `fragility' of some training\ninstances, i.e. instances where it is trivial to find a small perturbation that\nresults in a misclassification and the factors that influence this. Finally,\nthe method generates a large number of new instances misclassified with a wide\nvariation in confidence, providing a rich new source of training data to create\nmore robust models.\n","authors":["Emma Hart","Quentin Renau","Kevin Sim","Mohamad Alissa"],"pdf_url":"https://arxiv.org/pdf/2406.16609v1.pdf","comment":"To appear in the proceedings of the 18th International Conference on\n  Parallel Problem Solving from Nature (PPSN 2024)"},{"id":"http://arxiv.org/abs/2406.16608v1","updated":"2024-06-24T12:47:21Z","published":"2024-06-24T12:47:21Z","title":"When Invariant Representation Learning Meets Label Shift: Insufficiency\n  and Theoretical Insights","summary":"  As a crucial step toward real-world learning scenarios with changing\nenvironments, dataset shift theory and invariant representation learning\nalgorithm have been extensively studied to relax the identical distribution\nassumption in classical learning setting. Among the different assumptions on\nthe essential of shifting distributions, generalized label shift (GLS) is the\nlatest developed one which shows great potential to deal with the complex\nfactors within the shift. In this paper, we aim to explore the limitations of\ncurrent dataset shift theory and algorithm, and further provide new insights by\npresenting a comprehensive understanding of GLS. From theoretical aspect, two\ninformative generalization bounds are derived, and the GLS learner is proved to\nbe sufficiently close to optimal target model from the Bayesian perspective.\nThe main results show the insufficiency of invariant representation learning,\nand prove the sufficiency and necessity of GLS correction for generalization,\nwhich provide theoretical supports and innovations for exploring generalizable\nmodel under dataset shift. From methodological aspect, we provide a unified\nview of existing shift correction frameworks, and propose a kernel\nembedding-based correction algorithm (KECA) to minimize the generalization\nerror and achieve successful knowledge transfer. Both theoretical results and\nextensive experiment evaluations demonstrate the sufficiency and necessity of\nGLS correction for addressing dataset shift and the superiority of proposed\nalgorithm.\n","authors":["You-Wei Luo","Chuan-Xian Ren"],"pdf_url":"https://arxiv.org/pdf/2406.16608v1.pdf","comment":"Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)"},{"id":"http://arxiv.org/abs/2406.16606v1","updated":"2024-06-24T12:46:16Z","published":"2024-06-24T12:46:16Z","title":"Cherry on the Cake: Fairness is NOT an Optimization Problem","summary":"  Fair cake-cutting is a mathematical subfield that studies the problem of\nfairly dividing a resource among a number of participants. The so-called\n``cake,'' as an object, represents any resource that can be distributed among\nplayers. This concept is connected to supervised multi-label classification:\nany dataset can be thought of as a cake that needs to be distributed, where\neach label is a player that receives its share of the dataset. In particular,\nany efficient cake-cutting solution for the dataset is equivalent to an optimal\ndecision function. Although we are not the first to demonstrate this\nconnection, the important ramifications of this parallel seem to have been\npartially forgotten. We revisit these classical results and demonstrate how\nthis connection can be prolifically used for fairness in machine learning\nproblems. Understanding the set of achievable fair decisions is a fundamental\nstep in finding optimal fair solutions and satisfying fairness requirements. By\nemploying the tools of cake-cutting theory, we have been able to describe the\nbehavior of optimal fair decisions, which, counterintuitively, often exhibit\nquite unfair properties. Specifically, in order to satisfy fairness\nconstraints, it is sometimes preferable, in the name of optimality, to\npurposefully make mistakes and deny giving the positive label to deserving\nindividuals in a community in favor of less worthy individuals within the same\ncommunity. This practice is known in the literature as cherry-picking and has\nbeen described as ``blatantly unfair.''\n","authors":["Marco Favier","Toon Calders"],"pdf_url":"https://arxiv.org/pdf/2406.16606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16605v1","updated":"2024-06-24T12:46:15Z","published":"2024-06-24T12:46:15Z","title":"CLEAR: Can Language Models Really Understand Causal Graphs?","summary":"  Causal reasoning is a cornerstone of how humans interpret the world. To model\nand reason about causality, causal graphs offer a concise yet effective\nsolution. Given the impressive advancements in language models, a crucial\nquestion arises: can they really understand causal graphs? To this end, we\npioneer an investigation into language models' understanding of causal graphs.\nSpecifically, we develop a framework to define causal graph understanding, by\nassessing language models' behaviors through four practical criteria derived\nfrom diverse disciplines (e.g., philosophy and psychology). We then develop\nCLEAR, a novel benchmark that defines three complexity levels and encompasses\n20 causal graph-based tasks across these levels. Finally, based on our\nframework and benchmark, we conduct extensive experiments on six leading\nlanguage models and summarize five empirical findings. Our results indicate\nthat while language models demonstrate a preliminary understanding of causal\ngraphs, significant potential for improvement remains. Our project website is\nat https://github.com/OpenCausaLab/CLEAR.\n","authors":["Sirui Chen","Mengying Xu","Kun Wang","Xingyu Zeng","Rui Zhao","Shengjie Zhao","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.16605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16593v1","updated":"2024-06-24T12:33:56Z","published":"2024-06-24T12:33:56Z","title":"Measuring the Recyclability of Electronic Components to Assist Automatic\n  Disassembly and Sorting Waste Printed Circuit Boards","summary":"  The waste of electrical and electronic equipment has been increased due to\nthe fast evolution of technology products and competition of many IT sectors.\nEvery year millions of tons of electronic waste are thrown into the environment\nwhich causes high consequences for human health. Therefore, it is crucial to\ncontrol this waste flow using technology, especially using Artificial\nIntelligence but also reclamation of critical raw materials for new production\nprocesses. In this paper, we focused on the measurement of recyclability of\nwaste electronic components (WECs) from waste printed circuit boards (WPCBs)\nusing mathematical innovation model. This innovative approach evaluates both\nthe recyclability and recycling difficulties of WECs, integrating an AI model\nfor improved disassembly and sorting. Assessing the recyclability of individual\nelectronic components present on WPCBs provides insight into the recovery\npotential of valuable materials and indicates the level of complexity involved\nin recycling in terms of economic worth and production utility. This novel\nmeasurement approach helps AI models in accurately determining the number of\nclasses to be identified and sorted during the automated disassembly of\ndiscarded PCBs. It also facilitates the model in iterative training and\nvalidation of individual electronic components.\n","authors":["Muhammad Mohsin","Xianlai Zeng","Stefano Rovetta","Francesco Masulli"],"pdf_url":"https://arxiv.org/pdf/2406.16593v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2404.04067v3","updated":"2024-06-24T12:32:41Z","published":"2024-04-05T12:51:37Z","title":"CLUE: A Clinical Language Understanding Evaluation for LLMs","summary":"  Large Language Models (LLMs) are expected to significantly contribute to\npatient care, diagnostics, and administrative processes. Emerging biomedical\nLLMs aim to address healthcare-specific challenges, including privacy demands\nand computational constraints. Assessing the models' suitability for this\nsensitive application area is of the utmost importance. However, evaluation has\nprimarily been limited to non-clinical tasks, which do not reflect the\ncomplexity of practical clinical applications. To fill this gap, we present the\nClinical Language Understanding Evaluation (CLUE), a benchmark tailored to\nevaluate LLMs on clinical tasks. CLUE includes six tasks to test the practical\napplicability of LLMs in complex healthcare settings. Our evaluation includes a\ntotal of $25$ LLMs. In contrast to previous evaluations, CLUE shows a decrease\nin performance for nine out of twelve biomedical models. Our benchmark\nrepresents a step towards a standardized approach to evaluating and developing\nLLMs in healthcare to align future model development with the real-world needs\nof clinical application. We open-source all evaluation scripts and datasets for\nfuture research at https://github.com/TIO-IKIM/CLUE.\n","authors":["Amin Dada","Marie Bauer","Amanda Butler Contreras","Osman Alperen Koraş","Constantin Marc Seibold","Kaleb E Smith","Jens Kleesiek"],"pdf_url":"https://arxiv.org/pdf/2404.04067v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16590v1","updated":"2024-06-24T12:28:22Z","published":"2024-06-24T12:28:22Z","title":"Forecasting with Deep Learning: Beyond Average of Average of Average\n  Performance","summary":"  Accurate evaluation of forecasting models is essential for ensuring reliable\npredictions. Current practices for evaluating and comparing forecasting models\nfocus on summarising performance into a single score, using metrics such as\nSMAPE. We hypothesize that averaging performance over all samples dilutes\nrelevant information about the relative performance of models. Particularly,\nconditions in which this relative performance is different than the overall\naccuracy. We address this limitation by proposing a novel framework for\nevaluating univariate time series forecasting models from multiple\nperspectives, such as one-step ahead forecasting versus multi-step ahead\nforecasting. We show the advantages of this framework by comparing a\nstate-of-the-art deep learning approach with classical forecasting techniques.\nWhile classical methods (e.g. ARIMA) are long-standing approaches to\nforecasting, deep neural networks (e.g. NHITS) have recently shown\nstate-of-the-art forecasting performance in benchmark datasets. We conducted\nextensive experiments that show NHITS generally performs best, but its\nsuperiority varies with forecasting conditions. For instance, concerning the\nforecasting horizon, NHITS only outperforms classical approaches for multi-step\nahead forecasting. Another relevant insight is that, when dealing with\nanomalies, NHITS is outperformed by methods such as Theta. These findings\nhighlight the importance of aspect-based model evaluation.\n","authors":["Vitor Cerqueira","Luis Roque","Carlos Soares"],"pdf_url":"https://arxiv.org/pdf/2406.16590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14593v2","updated":"2024-06-24T12:25:04Z","published":"2024-06-20T17:08:42Z","title":"Enhancing Dropout-based Bayesian Neural Networks with Multi-Exit on FPGA","summary":"  Reliable uncertainty estimation plays a crucial role in various\nsafety-critical applications such as medical diagnosis and autonomous driving.\nIn recent years, Bayesian neural networks (BayesNNs) have gained substantial\nresearch and industrial interests due to their capability to make accurate\npredictions with reliable uncertainty estimation. However, the algorithmic\ncomplexity and the resulting hardware performance of BayesNNs hinder their\nadoption in real-life applications. To bridge this gap, this paper proposes an\nalgorithm and hardware co-design framework that can generate field-programmable\ngate array (FPGA)-based accelerators for efficient BayesNNs. At the algorithm\nlevel, we propose novel multi-exit dropout-based BayesNNs with reduced\ncomputational and memory overheads while achieving high accuracy and quality of\nuncertainty estimation. At the hardware level, this paper introduces a\ntransformation framework that can generate FPGA-based accelerators for the\nproposed efficient multi-exit BayesNNs. Several optimization techniques such as\nthe mix of spatial and temporal mappings are introduced to reduce resource\nconsumption and improve the overall hardware performance. Comprehensive\nexperiments demonstrate that our approach can achieve higher energy efficiency\ncompared to CPU, GPU, and other state-of-the-art hardware implementations. To\nsupport the future development of this research, we have open-sourced our code\nat: https://github.com/os-hxfan/MCME_FPGA_Acc.git\n","authors":["Hao Mark Chen","Liam Castelli","Martin Ferianc","Hongyu Zhou","Shuanglong Liu","Wayne Luk","Hongxiang Fan"],"pdf_url":"https://arxiv.org/pdf/2406.14593v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2308.06849"},{"id":"http://arxiv.org/abs/2406.16583v1","updated":"2024-06-24T12:16:51Z","published":"2024-06-24T12:16:51Z","title":"Personalized federated learning based on feature fusion","summary":"  Federated learning enables distributed clients to collaborate on training\nwhile storing their data locally to protect client privacy. However, due to the\nheterogeneity of data, models, and devices, the final global model may need to\nperform better for tasks on each client. Communication bottlenecks, data\nheterogeneity, and model heterogeneity have been common challenges in federated\nlearning. In this work, we considered a label distribution skew problem, a type\nof data heterogeneity easily overlooked. In the context of classification, we\npropose a personalized federated learning approach called pFedPM. In our\nprocess, we replace traditional gradient uploading with feature uploading,\nwhich helps reduce communication costs and allows for heterogeneous client\nmodels. These feature representations play a role in preserving privacy to some\nextent.\n  We use a hyperparameter $a$ to mix local and global features, which enables\nus to control the degree of personalization. We also introduced a relation\nnetwork as an additional decision layer, which provides a non-linear learnable\nclassifier to predict labels. Experimental results show that, with an\nappropriate setting of $a$, our scheme outperforms several recent FL methods on\nMNIST, FEMNIST, and CRIFAR10 datasets and achieves fewer communications.\n","authors":["Wolong Xing","Zhenkui Shi","Hongyan Peng","Xiantao Hu","Xianxian Li"],"pdf_url":"https://arxiv.org/pdf/2406.16583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16571v1","updated":"2024-06-24T12:09:19Z","published":"2024-06-24T12:09:19Z","title":"Differentiable Distributionally Robust Optimization Layers","summary":"  In recent years, there has been a growing research interest in\ndecision-focused learning, which embeds optimization problems as a layer in\nlearning pipelines and demonstrates a superior performance than the\nprediction-focused approach. However, for distributionally robust optimization\n(DRO), a popular paradigm for decision-making under uncertainty, it is still\nunknown how to embed it as a layer, i.e., how to differentiate decisions with\nrespect to an ambiguity set. In this paper, we develop such differentiable DRO\nlayers for generic mixed-integer DRO problems with parameterized second-order\nconic ambiguity sets and discuss its extension to Wasserstein ambiguity sets.\nTo differentiate the mixed-integer decisions, we propose a novel dual-view\nmethodology by handling continuous and discrete parts of decisions via\ndifferent principles. Specifically, we construct a differentiable energy-based\nsurrogate to implement the dual-view methodology and use importance sampling to\nestimate its gradient. We further prove that such a surrogate enjoys the\nasymptotic convergency under regularization. As an application of the proposed\ndifferentiable DRO layers, we develop a novel decision-focused learning\npipeline for contextual distributionally robust decision-making tasks and\ncompare it with the prediction-focused approach in experiments.\n","authors":["Xutao Ma","Chao Ning","Wenli Du"],"pdf_url":"https://arxiv.org/pdf/2406.16571v1.pdf","comment":"In Forty-first International Conference on Machine Learning (2024)"},{"id":"http://arxiv.org/abs/2402.02956v2","updated":"2024-06-24T12:07:52Z","published":"2024-02-05T12:34:03Z","title":"AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a\n  Single High-Resolution Image","summary":"  The process of estimating and counting tree density using only a single\naerial or satellite image is a difficult task in the fields of photogrammetry\nand remote sensing. However, it plays a crucial role in the management of\nforests. The huge variety of trees in varied topography severely hinders tree\ncounting models to perform well. The purpose of this paper is to propose a\nframework that is learnt from the source domain with sufficient labeled trees\nand is adapted to the target domain with only a limited number of labeled\ntrees. Our method, termed as AdaTreeFormer, contains one shared encoder with a\nhierarchical feature extraction scheme to extract robust features from the\nsource and target domains. It also consists of three subnets: two for\nextracting self-domain attention maps from source and target domains\nrespectively and one for extracting cross-domain attention maps. For the\nlatter, an attention-to-adapt mechanism is introduced to distill relevant\ninformation from different domains while generating tree density maps; a\nhierarchical cross-domain feature alignment scheme is proposed that\nprogressively aligns the features from the source and target domains. We also\nadopt adversarial learning into the framework to further reduce the gap between\nsource and target domains. Our AdaTreeFormer is evaluated on six designed\ndomain adaptation tasks using three tree counting datasets, \\ie Jiangsu,\nYosemite, and London. Experimental results show that AdaTreeFormer\nsignificantly surpasses the state of the art, \\eg in the cross domain from the\nYosemite to Jiangsu dataset, it achieves a reduction of 15.9 points in terms of\nthe absolute counting errors and an increase of 10.8\\% in the accuracy of the\ndetected trees' locations. The codes and datasets are available at\n\\emph{\\color{magenta}{https://github.com/HAAClassic/AdaTreeFormer}}.\n","authors":["Hamed Amini Amirkolaee","Miaojing Shi","Lianghua He","Mark Mulligan"],"pdf_url":"https://arxiv.org/pdf/2402.02956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00933v4","updated":"2024-06-24T12:03:00Z","published":"2023-04-03T12:45:52Z","title":"Knowledge Accumulation in Continually Learned Representations and the\n  Issue of Feature Forgetting","summary":"  Continual learning research has shown that neural networks suffer from\ncatastrophic forgetting \"at the output level\", but it is debated whether this\nis also the case at the level of learned representations. Multiple recent\nstudies ascribe representations a certain level of innate robustness against\nforgetting -- that they only forget minimally in comparison with forgetting at\nthe output level. We revisit and expand upon the experiments that revealed this\ndifference in forgetting and illustrate the coexistence of two phenomena that\naffect the quality of continually learned representations: knowledge\naccumulation and feature forgetting. Taking both aspects into account, we show\nthat, even though forgetting in the representation (i.e. feature forgetting)\ncan be small in absolute terms, when measuring relative to how much was learned\nduring a task, forgetting in the representation tends to be just as\ncatastrophic as forgetting at the output level. Next we show that this feature\nforgetting is problematic as it substantially slows down the incremental\nlearning of good general representations (i.e. knowledge accumulation).\nFinally, we study how feature forgetting and knowledge accumulation are\naffected by different types of continual learning methods.\n","authors":["Timm Hess","Eli Verwimp","Gido M. van de Ven","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2304.00933v4.pdf","comment":"TMLR 2024"},{"id":"http://arxiv.org/abs/2406.16565v1","updated":"2024-06-24T12:02:20Z","published":"2024-06-24T12:02:20Z","title":"Noisy Neighbors: Efficient membership inference attacks against LLMs","summary":"  The potential of transformer-based LLMs risks being hindered by privacy\nconcerns due to their reliance on extensive datasets, possibly including\nsensitive information. Regulatory measures like GDPR and CCPA call for using\nrobust auditing tools to address potential privacy issues, with Membership\nInference Attacks (MIA) being the primary method for assessing LLMs' privacy\nrisks. Differently from traditional MIA approaches, often requiring\ncomputationally intensive training of additional models, this paper introduces\nan efficient methodology that generates \\textit{noisy neighbors} for a target\nsample by adding stochastic noise in the embedding space, requiring operating\nthe target model in inference mode only. Our findings demonstrate that this\napproach closely matches the effectiveness of employing shadow models, showing\nits usability in practical privacy auditing scenarios.\n","authors":["Filippo Galli","Luca Melis","Tommaso Cucinotta"],"pdf_url":"https://arxiv.org/pdf/2406.16565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01753v2","updated":"2024-06-24T11:56:28Z","published":"2023-07-04T14:49:23Z","title":"Local primordial non-Gaussianity from the large-scale clustering of\n  photometric DESI luminous red galaxies","summary":"  We use angular clustering of luminous red galaxies from the Dark Energy\nSpectroscopic Instrument (DESI) imaging surveys to constrain the local\nprimordial non-Gaussianity parameter $\\fnl$. Our sample comprises over 12\nmillion targets, covering 14,000 square degrees of the sky, with redshifts in\nthe range $0.2< z < 1.35$. We identify Galactic extinction, survey depth, and\nastronomical seeing as the primary sources of systematic error, and employ\nlinear regression and artificial neural networks to alleviate non-cosmological\nexcess clustering on large scales. Our methods are tested against simulations\nwith and without $\\fnl$ and systematics, showing superior performance of the\nneural network treatment. The neural network with a set of nine imaging\nproperty maps passes our systematic null test criteria, and is chosen as the\nfiducial treatment. Assuming the universality relation, we find $\\fnl =\n34^{+24(+50)}_{-44(-73)}$ at 68\\%(95\\%) confidence. We apply a series of\nrobustness tests (e.g., cuts on imaging, declination, or scales used) that show\nconsistency in the obtained constraints. We study how the regression method\nbiases the measured angular power-spectrum and degrades the $\\fnl$ constraining\npower. The use of the nine maps more than doubles the uncertainty compared to\nusing only the three primary maps in the regression. Our results thus motivate\nthe development of more efficient methods that avoid over-correction, protect\nlarge-scale clustering information, and preserve constraining power.\nAdditionally, our results encourage further studies of $\\fnl$ with DESI\nspectroscopic samples, where the inclusion of 3D clustering modes should help\nseparate imaging systematics and lessen the degradation in the $\\fnl$\nuncertainty.\n","authors":["Mehdi Rezaie","Ashley J. Ross","Hee-Jong Seo","Hui Kong","Anna Porredon","Lado Samushia","Edmond Chaussidon","Alex Krolewski","Arnaud de Mattia","Florian Beutler","Jessica Nicole Aguilar","Steven Ahlen","Shadab Alam","Santiago Avila","Benedict Bahr-Kalus","Jose Bermejo-Climent","David Brooks","Todd Claybaugh","Shaun Cole","Kyle Dawson","Axel de la Macorra","Peter Doel","Andreu Font-Ribera","Jaime E. Forero-Romero","Satya Gontcho A Gontcho","Julien Guy","Klaus Honscheid","Dragan Huterer","Theodore Kisner","Martin Landriau","Michael Levi","Marc Manera","Aaron Meisner","Ramon Miquel","Eva-Maria Mueller","Adam Myers","Jeffrey A. Newman","Jundan Nie","Nathalie Palanque-Delabrouille","Will Percival","Claire Poppett","Graziano Rossi","Eusebio Sanchez","Michael Schubnell","Gregory Tarlé","Benjamin Alan Weaver","Christophe Yèche","Zhimin Zhou","Hu Zou"],"pdf_url":"https://arxiv.org/pdf/2307.01753v2.pdf","comment":"21 pages, 17 figures, 7 tables (Appendix excluded). Published in\n  MNRAS"},{"id":"http://arxiv.org/abs/2306.12361v2","updated":"2024-06-24T11:56:15Z","published":"2023-06-21T16:14:21Z","title":"Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via\n  Optimization and Data-driven Approach for Dynamic Systems","summary":"  Most works on joint state and unknown input (UI) estimation require the\nassumption that the UIs are linear; this is potentially restrictive as it does\nnot hold in many intelligent autonomous systems. To overcome this restriction\nand circumvent the need to linearize the system, we propose a derivative-free\nUnknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF is\ninterconnected with a general nonlinear UI estimator that can be implemented\nvia nonlinear optimization and data-driven approaches. The nonlinear UI\nestimator uses the posterior state estimate which is less susceptible to state\nprediction error. In addition, we introduce a joint sigma-point transformation\nscheme to incorporate both the state and UI uncertainties in the estimation of\nSPKF-nUI. An in-depth stochastic stability analysis proves that the proposed\nSPKF-nUI yields exponentially converging estimation error bounds under\nreasonable assumptions. Finally, two case studies are carried out on a\nsimulation-based rigid robot and a physical soft robot, i.e., robots made of\nsoft materials with complex dynamics to validate effectiveness of the proposed\nfilter on nonlinear dynamic systems. Our results demonstrate that the proposed\nSPKF-nUI achieves the lowest state and UI estimation errors when compared to\nthe existing nonlinear state-UI filters.\n","authors":["Junn Yong Loo","Ze Yang Ding","Vishnu Monn Baskaran","Surya Girinatha Nurzaman","Chee Pin Tan"],"pdf_url":"https://arxiv.org/pdf/2306.12361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16557v1","updated":"2024-06-24T11:50:31Z","published":"2024-06-24T11:50:31Z","title":"Efficient k-means with Individual Fairness via Exponential Tilting","summary":"  In location-based resource allocation scenarios, the distances between each\nindividual and the facility are desired to be approximately equal, thereby\nensuring fairness. Individually fair clustering is often employed to achieve\nthe principle of treating all points equally, which can be applied in these\nscenarios. This paper proposes a novel algorithm, tilted k-means (TKM), aiming\nto achieve individual fairness in clustering. We integrate the exponential\ntilting into the sum of squared errors (SSE) to formulate a novel objective\nfunction called tilted SSE. We demonstrate that the tilted SSE can generalize\nto SSE and employ the coordinate descent and first-order gradient method for\noptimization. We propose a novel fairness metric, the variance of the distances\nwithin each cluster, which can alleviate the Matthew Effect typically caused by\nexisting fairness metrics. Our theoretical analysis demonstrates that the\nwell-known k-means++ incurs a multiplicative error of O(k log k), and we\nestablish the convergence of TKM under mild conditions. In terms of fairness,\nwe prove that the variance generated by TKM decreases with a scaled\nhyperparameter. In terms of efficiency, we demonstrate the time complexity is\nlinear with the dataset size. Our experiments demonstrate that TKM outperforms\nstate-of-the-art methods in effectiveness, fairness, and efficiency.\n","authors":["Shengkun Zhu","Jinshan Zeng","Yuan Sun","Sheng Wang","Xiaodong Li","Zhiyong Peng"],"pdf_url":"https://arxiv.org/pdf/2406.16557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16552v1","updated":"2024-06-24T11:41:12Z","published":"2024-06-24T11:41:12Z","title":"Inference of Sequential Patterns for Neural Message Passing in Temporal\n  Graphs","summary":"  The modelling of temporal patterns in dynamic graphs is an important current\nresearch issue in the development of time-aware GNNs. Whether or not a specific\nsequence of events in a temporal graph constitutes a temporal pattern not only\ndepends on the frequency of its occurrence. We consider whether it deviates\nfrom what is expected in a temporal graph where timestamps are randomly\nshuffled. While accounting for such a random baseline is important to model\ntemporal patterns, it has mostly been ignored by current temporal graph neural\nnetworks. To address this issue we propose HYPA-DBGNN, a novel two-step\napproach that combines (i) the inference of anomalous sequential patterns in\ntime series data on graphs based on a statistically principled null model, with\n(ii) a neural message passing approach that utilizes a higher-order De Bruijn\ngraph whose edges capture overrepresented sequential patterns. Our method\nleverages hypergeometric graph ensembles to identify anomalous edges within\nboth first- and higher-order De Bruijn graphs, which encode the temporal\nordering of events. The model introduces an inductive bias that enhances model\ninterpretability. We evaluate our approach for static node classification using\nbenchmark datasets and a synthetic dataset that showcases its ability to\nincorporate the observed inductive bias regarding over- and under-represented\ntemporal edges. We demonstrate the framework's effectiveness in detecting\nsimilar patterns within empirical datasets, resulting in superior performance\ncompared to baseline methods in node classification tasks. To the best of our\nknowledge, our work is the first to introduce statistically informed GNNs that\nleverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path\nfor bridging the gap between statistical graph inference and neural graph\nrepresentation learning, with potential applications to static GNNs.\n","authors":["Jan von Pichowski","Vincenzo Perri","Lisi Qarkaxhija","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2406.16552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01658v4","updated":"2024-06-24T11:34:19Z","published":"2023-05-02T04:11:23Z","title":"A Non-autoregressive Multi-Horizon Flight Trajectory Prediction\n  Framework with Gray Code Representation","summary":"  Flight Trajectory Prediction (FTP) is an essential task in Air Traffic\nControl (ATC), which can assist air traffic controllers in managing airspace\nmore safely and efficiently. Existing approaches generally perform\nmulti-horizon FTP tasks in an autoregressive manner, thereby suffering from\nerror accumulation and low-efficiency problems. In this paper, a novel\nframework, called FlightBERT++, is proposed to i) forecast multi-horizon flight\ntrajectories directly in a non-autoregressive way, and ii) improve the\nlimitation of the binary encoding (BE) representation in the FlightBERT\nframework. Specifically, the proposed framework is implemented by a generalized\nencoder-decoder architecture, in which the encoder learns the temporal-spatial\npatterns from historical observations and the decoder predicts the flight\nstatus for the future horizons. Compared to conventional architecture, an\ninnovative horizon-aware contexts generator is dedicatedly designed to consider\nthe prior horizon information, which further enables non-autoregressive\nmulti-horizon prediction. Additionally, the Gray code representation and the\ndifferential prediction paradigm are designed to cope with the high-bit\nmisclassifications of the BE representation, which significantly reduces the\noutliers in the predictions. Moreover, a differential prompted decoder is\nproposed to enhance the capability of the differential predictions by\nleveraging the stationarity of the differential sequence. Extensive experiments\nare conducted to validate the proposed framework on a real-world flight\ntrajectory dataset. The experimental results demonstrated that the proposed\nframework outperformed the competitive baselines in both FTP performance and\ncomputational efficiency.\n","authors":["Dongyue Guo","Zheng Zhang","Zhen Yan","Jianwei Zhang","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2305.01658v4.pdf","comment":"An extend version based on the AAAI version"},{"id":"http://arxiv.org/abs/2406.16540v1","updated":"2024-06-24T11:20:44Z","published":"2024-06-24T11:20:44Z","title":"Improving robustness to corruptions with multiplicative weight\n  perturbations","summary":"  Deep neural networks (DNNs) excel on clean images but struggle with corrupted\nones. Incorporating specific corruptions into the data augmentation pipeline\ncan improve robustness to those corruptions but may harm performance on clean\nimages and other types of distortion. In this paper, we introduce an\nalternative approach that improves the robustness of DNNs to a wide range of\ncorruptions without compromising accuracy on clean images. We first demonstrate\nthat input perturbations can be mimicked by multiplicative perturbations in the\nweight space. Leveraging this, we propose Data Augmentation via Multiplicative\nPerturbation (DAMP), a training method that optimizes DNNs under random\nmultiplicative weight perturbations. We also examine the recently proposed\nAdaptive Sharpness-Aware Minimization (ASAM) and show that it optimizes DNNs\nunder adversarial multiplicative weight perturbations. Experiments on image\nclassification datasets (CIFAR-10/100, TinyImageNet and ImageNet) and neural\nnetwork architectures (ResNet50, ViT-S/16) show that DAMP enhances model\ngeneralization performance in the presence of corruptions across different\nsettings. Notably, DAMP is able to train a ViT-S/16 on ImageNet from scratch,\nreaching the top-1 error of 23.7% which is comparable to ResNet50 without\nextensive data augmentations.\n","authors":["Trung Trinh","Markus Heinonen","Luigi Acerbi","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2406.16540v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16535v1","updated":"2024-06-24T11:16:26Z","published":"2024-06-24T11:16:26Z","title":"Token-based Decision Criteria Are Suboptimal in In-context Learning","summary":"  In-Context Learning (ICL) typically utilizes classification criteria from\nprobabilities of manually selected label tokens. However, we argue that such\ntoken-based classification criteria lead to suboptimal decision boundaries,\ndespite delicate calibrations through translation and constrained rotation. To\naddress this problem, we propose Hidden Calibration, which renounces token\nprobabilities and uses the nearest centroid classifier on the LM's last hidden\nstates. In detail, we use the nearest centroid classification on the hidden\nstates, assigning the category of the nearest centroid previously observed from\na few-shot calibration set to the test sample as the predicted label. Our\nexperiments on 3 models and 10 classification datasets indicate that Hidden\nCalibration consistently outperforms current token-based calibrations by about\n20%. Our further analysis demonstrates that Hidden Calibration finds better\nclassification criteria with less inter-categories overlap, and LMs provide\nlinearly separable intra-category clusters with the help of demonstrations,\nwhich supports Hidden Calibration and gives new insights into the conventional\nICL.\n","authors":["Hakaze Cho","Yoshihiro Sakai","Mariko Kato","Kenshiro Tanaka","Akira Ishii","Naoya Inoue"],"pdf_url":"https://arxiv.org/pdf/2406.16535v1.pdf","comment":"21 pages, 14 figures, 8 tables"},{"id":"http://arxiv.org/abs/2406.16530v1","updated":"2024-06-24T11:09:08Z","published":"2024-06-24T11:09:08Z","title":"Conditional Bayesian Quadrature","summary":"  We propose a novel approach for estimating conditional or parametric\nexpectations in the setting where obtaining samples or evaluating integrands is\ncostly. Through the framework of probabilistic numerical methods (such as\nBayesian quadrature), our novel approach allows to incorporates prior\ninformation about the integrands especially the prior smoothness knowledge\nabout the integrands and the conditional expectation. As a result, our approach\nprovides a way of quantifying uncertainty and leads to a fast convergence rate,\nwhich is confirmed both theoretically and empirically on challenging tasks in\nBayesian sensitivity analysis, computational finance and decision making under\nuncertainty.\n","authors":["Zonghao Chen","Masha Naslidnyk","Arthur Gretton","François-Xavier Briol"],"pdf_url":"https://arxiv.org/pdf/2406.16530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16527v1","updated":"2024-06-24T11:04:43Z","published":"2024-06-24T11:04:43Z","title":"SyROCCo: Enhancing Systematic Reviews using Machine Learning","summary":"  The sheer number of research outputs published every year makes systematic\nreviewing increasingly time- and resource-intensive. This paper explores the\nuse of machine learning techniques to help navigate the systematic review\nprocess. ML has previously been used to reliably 'screen' articles for review -\nthat is, identify relevant articles based on reviewers' inclusion criteria. The\napplication of ML techniques to subsequent stages of a review, however, such as\ndata extraction and evidence mapping, is in its infancy. We therefore set out\nto develop a series of tools that would assist in the profiling and analysis of\n1,952 publications on the theme of 'outcomes-based contracting'. Tools were\ndeveloped for the following tasks: assign publications into 'policy area'\ncategories; identify and extract key information for evidence mapping, such as\norganisations, laws, and geographical information; connect the evidence base to\nan existing dataset on the same topic; and identify subgroups of articles that\nmay share thematic content. An interactive tool using these techniques and a\npublic dataset with their outputs have been released. Our results demonstrate\nthe utility of ML techniques to enhance evidence accessibility and analysis\nwithin the systematic review processes. These efforts show promise in\npotentially yielding substantial efficiencies for future systematic reviewing\nand for broadening their analytical scope. Our work suggests that there may be\nimplications for the ease with which policymakers and practitioners can access\nevidence. While ML techniques seem poised to play a significant role in\nbridging the gap between research and policy by offering innovative ways of\ngathering, accessing, and analysing data from systematic reviews, we also\nhighlight their current limitations and the need to exercise caution in their\napplication, particularly given the potential for errors and biases.\n","authors":["Zheng Fang","Miguel Arana-Catania","Felix-Anselm van Lier","Juliana Outes Velarde","Harry Bregazzi","Mara Airoldi","Eleanor Carter","Rob Procter"],"pdf_url":"https://arxiv.org/pdf/2406.16527v1.pdf","comment":"28 pages, 5 figures. To appear in Data & Policy journal"},{"id":"http://arxiv.org/abs/2406.16525v1","updated":"2024-06-24T11:01:43Z","published":"2024-06-24T11:01:43Z","title":"OAML: Outlier Aware Metric Learning for OOD Detection Enhancement","summary":"  Out-of-distribution (OOD) detection methods have been developed to identify\nobjects that a model has not seen during training. The Outlier Exposure (OE)\nmethods use auxiliary datasets to train OOD detectors directly. However, the\ncollection and learning of representative OOD samples may pose challenges. To\ntackle these issues, we propose the Outlier Aware Metric Learning (OAML)\nframework. The main idea of our method is to use the k-NN algorithm and Stable\nDiffusion model to generate outliers for training at the feature level without\nmaking any distributional assumptions. To increase feature discrepancies in the\nsemantic space, we develop a mutual information-based contrastive learning\napproach for learning from OOD data effectively. Both theoretical and empirical\nresults confirm the effectiveness of this contrastive learning technique.\nFurthermore, we incorporate knowledge distillation into our learning framework\nto prevent degradation of in-distribution classification accuracy. The\ncombination of contrastive learning and knowledge distillation algorithms\nsignificantly enhances the performance of OOD detection. Experimental results\nacross various datasets show that our method significantly outperforms previous\nOE methods.\n","authors":["Heng Gao","Zhuolin He","Shoumeng Qiu","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2406.16525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08011v2","updated":"2024-06-24T10:25:19Z","published":"2024-05-10T18:05:37Z","title":"A Survey of Large Language Models for Graphs","summary":"  Graphs are an essential data structure utilized to represent relationships in\nreal-world scenarios. Prior research has established that Graph Neural Networks\n(GNNs) deliver impressive outcomes in graph-centric tasks, such as link\nprediction and node classification. Despite these advancements, challenges like\ndata sparsity and limited generalization capabilities continue to persist.\nRecently, Large Language Models (LLMs) have gained attention in natural\nlanguage processing. They excel in language comprehension and summarization.\nIntegrating LLMs with graph learning techniques has attracted interest as a way\nto enhance performance in graph learning tasks. In this survey, we conduct an\nin-depth review of the latest state-of-the-art LLMs applied in graph learning\nand introduce a novel taxonomy to categorize existing methods based on their\nframework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as\nPrefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key\nmethodologies within each category. We explore the strengths and limitations of\neach framework, and emphasize potential avenues for future research, including\novercoming current integration challenges between LLMs and graph learning\ntechniques, and venturing into new application areas. This survey aims to serve\nas a valuable resource for researchers and practitioners eager to leverage\nlarge language models in graph learning, and to inspire continued progress in\nthis dynamic field. We consistently maintain the related open-source materials\nat \\url{https://github.com/HKUDS/Awesome-LLM4Graph-Papers}.\n","authors":["Xubin Ren","Jiabin Tang","Dawei Yin","Nitesh Chawla","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2405.08011v2.pdf","comment":"Published as a KDD'24 survey paper"},{"id":"http://arxiv.org/abs/2406.16501v1","updated":"2024-06-24T10:10:03Z","published":"2024-06-24T10:10:03Z","title":"UNICAD: A Unified Approach for Attack Detection, Noise Reduction and\n  Novel Class Identification","summary":"  As the use of Deep Neural Networks (DNNs) becomes pervasive, their\nvulnerability to adversarial attacks and limitations in handling unseen classes\nposes significant challenges. The state-of-the-art offers discrete solutions\naimed to tackle individual issues covering specific adversarial attack\nscenarios, classification or evolving learning. However, real-world systems\nneed to be able to detect and recover from a wide range of adversarial attacks\nwithout sacrificing classification accuracy and to flexibly act in {\\bf unseen}\nscenarios. In this paper, UNICAD, is proposed as a novel framework that\nintegrates a variety of techniques to provide an adaptive solution.\n  For the targeted image classification, UNICAD achieves accurate image\nclassification, detects unseen classes, and recovers from adversarial attacks\nusing Prototype and Similarity-based DNNs with denoising autoencoders. Our\nexperiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness\nin adversarial mitigation and unseen class classification, outperforming\ntraditional models.\n","authors":["Alvaro Lopez Pellicer","Kittipos Giatgong","Yi Li","Neeraj Suri","Plamen Angelov"],"pdf_url":"https://arxiv.org/pdf/2406.16501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09585v3","updated":"2024-06-24T09:56:35Z","published":"2024-05-15T07:31:06Z","title":"An Embarrassingly Simple Approach to Enhance Transformer Performance in\n  Genomic Selection for Crop Breeding","summary":"  Genomic selection (GS), as a critical crop breeding strategy, plays a key\nrole in enhancing food production and addressing the global hunger crisis. The\npredominant approaches in GS currently revolve around employing statistical\nmethods for prediction. However, statistical methods often come with two main\nlimitations: strong statistical priors and linear assumptions. A recent trend\nis to capture the non-linear relationships between markers by deep learning.\nHowever, as crop datasets are commonly long sequences with limited samples, the\nrobustness of deep learning models, especially Transformers, remains a\nchallenge. In this work, to unleash the unexplored potential of attention\nmechanism for the task of interest, we propose a simple yet effective\nTransformer-based framework that enables end-to-end training of the whole\nsequence. Via experiments on rice3k and wheat3k datasets, we show that, with\nsimple tricks such as k-mer tokenization and random masking, Transformer can\nachieve overall superior performance against seminal methods on GS tasks of\ninterest.\n","authors":["Renqi Chen","Wenwei Han","Haohao Zhang","Haoyang Su","Zhefan Wang","Xiaolei Liu","Hao Jiang","Wanli Ouyang","Nanqing Dong"],"pdf_url":"https://arxiv.org/pdf/2405.09585v3.pdf","comment":"Accepted by IJCAI2024. Code is available at\n  https://github.com/RenqiChen/Genomic-Selection"},{"id":"http://arxiv.org/abs/2406.16484v1","updated":"2024-06-24T09:39:30Z","published":"2024-06-24T09:39:30Z","title":"Robust prediction under missingness shifts","summary":"  Prediction becomes more challenging with missing covariates. What method is\nchosen to handle missingness can greatly affect how models perform. In many\nreal-world problems, the best prediction performance is achieved by models that\ncan leverage the informative nature of a value being missing. Yet, the reasons\nwhy a covariate goes missing can change once a model is deployed in practice.\nIf such a missingness shift occurs, the conditional probability of a value\nbeing missing differs in the target data. Prediction performance in the source\ndata may no longer be a good selection criterion, and approaches that do not\nrely on informative missingness may be preferable. However, we show that the\nBayes predictor remains unchanged by ignorable shifts for which the probability\nof missingness only depends on observed data. Any consistent estimator of the\nBayes predictor may therefore result in robust prediction under those\nconditions, although we show empirically that different methods appear robust\nto different types of shifts. If the missingness shift is non-ignorable, the\nBayes predictor may change due to the shift. While neither approach recovers\nthe Bayes predictor in this case, we found empirically that disregarding\nmissingness was most beneficial when it was highly informative.\n","authors":["Patrick Rockenschaub","Zhicong Xian","Alireza Zamanian","Marta Piperno","Octavia-Andreea Ciora","Elisabeth Pachl","Narges Ahmidi"],"pdf_url":"https://arxiv.org/pdf/2406.16484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16481v1","updated":"2024-06-24T09:36:58Z","published":"2024-06-24T09:36:58Z","title":"Improving Quaternion Neural Networks with Quaternionic Activation\n  Functions","summary":"  In this paper, we propose novel quaternion activation functions where we\nmodify either the quaternion magnitude or the phase, as an alternative to the\ncommonly used split activation functions. We define criteria that are relevant\nfor quaternion activation functions, and subsequently we propose our novel\nactivation functions based on this analysis. Instead of applying a known\nactivation function like the ReLU or Tanh on the quaternion elements\nseparately, these activation functions consider the quaternion properties and\nrespect the quaternion space $\\mathbb{H}$. In particular, all quaternion\ncomponents are utilized to calculate all output components, carrying out the\nbenefit of the Hamilton product in e.g. the quaternion convolution to the\nactivation functions. The proposed activation functions can be incorporated in\narbitrary quaternion valued neural networks trained with gradient descent\ntechniques. We further discuss the derivatives of the proposed activation\nfunctions where we observe beneficial properties for the activation functions\naffecting the phase. Specifically, they prove to be sensitive on basically the\nwhole input range, thus improved gradient flow can be expected. We provide an\nelaborate experimental evaluation of our proposed quaternion activation\nfunctions including comparison with the split ReLU and split Tanh on two image\nclassification tasks using the CIFAR-10 and SVHN dataset. There, especially the\nquaternion activation functions affecting the phase consistently prove to\nprovide better performance.\n","authors":["Johannes Pöppelbaum","Andreas Schwung"],"pdf_url":"https://arxiv.org/pdf/2406.16481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03066v2","updated":"2024-06-24T09:35:41Z","published":"2023-06-05T17:43:50Z","title":"Of Mice and Mates: Automated Classification and Modelling of Mouse\n  Behaviour in Groups using a Single Model across Cages","summary":"  Behavioural experiments often happen in specialised arenas, but this may\nconfound the analysis. To address this issue, we provide tools to study mice in\nthe home-cage environment, equipping biologists with the possibility to capture\nthe temporal aspect of the individual's behaviour and model the interaction and\ninterdependence between cage-mates with minimal human intervention. Our main\ncontribution is the novel Group Behaviour Model (GBM) which summarises the\njoint behaviour of groups of mice across cages, using a permutation matrix to\nmatch the mouse identities in each cage to the model. In support of the above,\nwe also (a) developed the Activity Labelling Module (ALM) to automatically\nclassify mouse behaviour from video, and (b) released two datasets, ABODe for\ntraining behaviour classifiers and IMADGE for modelling behaviour.\n","authors":["Michael P. J. Camilleri","Rasneer S. Bains","Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2306.03066v2.pdf","comment":"International Journal of Computer Vision (2024)"},{"id":"http://arxiv.org/abs/2406.13262v2","updated":"2024-06-24T09:30:24Z","published":"2024-06-19T06:47:35Z","title":"Machine Learning Applications of Quantum Computing: A Review","summary":"  At the intersection of quantum computing and machine learning, this review\npaper explores the transformative impact these technologies are having on the\ncapabilities of data processing and analysis, far surpassing the bounds of\ntraditional computational methods. Drawing upon an in-depth analysis of 32\nseminal papers, this review delves into the interplay between quantum computing\nand machine learning, focusing on transcending the limitations of classical\ncomputing in advanced data processing and applications. This review emphasizes\nthe potential of quantum-enhanced methods in enhancing cybersecurity, a\ncritical sector that stands to benefit significantly from these advancements.\nThe literature review, primarily leveraging Science Direct as an academic\ndatabase, delves into the transformative effects of quantum technologies on\nmachine learning, drawing insights from a diverse collection of studies and\nscholarly articles. While the focus is primarily on the growing significance of\nquantum computing in cybersecurity, the review also acknowledges the promising\nimplications for other sectors as the field matures. Our systematic approach\ncategorizes sources based on quantum machine learning algorithms, applications,\nchallenges, and potential future developments, uncovering that quantum\ncomputing is increasingly being implemented in practical machine learning\nscenarios. The review highlights advancements in quantum-enhanced machine\nlearning algorithms and their potential applications in sectors such as\ncybersecurity, emphasizing the need for industry-specific solutions while\nconsidering ethical and security concerns. By presenting an overview of the\ncurrent state and projecting future directions, the paper sets a foundation for\nongoing research and strategic advancement in quantum machine learning.\n","authors":["Thien Nguyen","Tuomo Sipola","Jari Hautamäki"],"pdf_url":"https://arxiv.org/pdf/2406.13262v2.pdf","comment":"Proceedings of the 23rd European Conference on Cyber Warfare and\n  Security (ECCWS 2024)"},{"id":"http://arxiv.org/abs/2406.16468v1","updated":"2024-06-24T09:16:59Z","published":"2024-06-24T09:16:59Z","title":"The Hidden Pitfalls of the Cosine Similarity Loss","summary":"  We show that the gradient of the cosine similarity between two points goes to\nzero in two under-explored settings: (1) if a point has large magnitude or (2)\nif the points are on opposite ends of the latent space. Counterintuitively, we\nprove that optimizing the cosine similarity between points forces them to grow\nin magnitude. Thus, (1) is unavoidable in practice. We then observe that these\nderivations are extremely general -- they hold across deep learning\narchitectures and for many of the standard self-supervised learning (SSL) loss\nfunctions. This leads us to propose cut-initialization: a simple change to\nnetwork initialization that helps all studied SSL methods converge faster.\n","authors":["Andrew Draganov","Sharvaree Vadgama","Erik J. Bekkers"],"pdf_url":"https://arxiv.org/pdf/2406.16468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16466v1","updated":"2024-06-24T09:16:17Z","published":"2024-06-24T09:16:17Z","title":"SLOctolyzer: Fully automatic analysis toolkit for segmentation and\n  feature extracting in scanning laser ophthalmoscopy images","summary":"  Purpose: To describe SLOctolyzer: an open-source analysis toolkit for en face\nretinal vessels appearing in infrared reflectance scanning laser ophthalmoscopy\n(SLO) images.\n  Methods: SLOctolyzer includes two main modules: segmentation and measurement.\nThe segmentation module use deep learning methods to delineate retinal anatomy,\nwhile the measurement module quantifies key retinal vascular features such as\nvessel complexity, density, tortuosity, and calibre. We evaluate the\nsegmentation module using unseen data and measure its reproducibility.\n  Results: SLOctolyzer's segmentation module performed well against unseen\ninternal test data (Dice for all-vessels, 0.9097; arteries, 0.8376; veins,\n0.8525; optic disc, 0.9430; fovea, 0.8837). External validation against severe\nretinal pathology showed decreased performance (Dice for arteries, 0.7180;\nveins, 0.7470; optic disc, 0.9032). SLOctolyzer had good reproducibility (mean\ndifference for fractal dimension, -0.0007; vessel density, -0.0003; vessel\ncalibre, -0.3154 $\\mu$m; tortuosity density, 0.0013). SLOctolyzer can process a\nmacula-centred SLO image in under 20 seconds and a disc-centred SLO image in\nunder 30 seconds using a standard laptop CPU.\n  Conclusions: To our knowledge, SLOctolyzer is the first open-source tool to\nconvert raw SLO images into reproducible and clinically meaningful retinal\nvascular parameters. SLO images are captured simultaneous to optical coherence\ntomography (OCT), and we believe our software will be useful for extracting\nretinal vascular measurements from large OCT image sets and linking them to\nocular or systemic diseases. It requires no specialist knowledge or proprietary\nsoftware, and allows manual correction of segmentations and re-computing of\nvascular metrics. SLOctolyzer is freely available at\nhttps://github.com/jaburke166/SLOctolyzer.\n","authors":["Jamie Burke","Samuel Gibbon","Justin Engelmann","Adam Threlfall","Ylenia Giarratano","Charlene Hamid","Stuart King","Ian J. C. MacCormick","Tom MacGillivray"],"pdf_url":"https://arxiv.org/pdf/2406.16466v1.pdf","comment":"10 pages, 5 figures, 6 tables + Supplementary (7 pages, 10 figures, 4\n  tables). Submitted for peer review at Translational Vision Science and\n  Technology"},{"id":"http://arxiv.org/abs/2405.18979v2","updated":"2024-06-24T09:12:08Z","published":"2024-05-29T10:45:06Z","title":"MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under\n  Distribution Shifts","summary":"  Leveraging the models' outputs, specifically the logits, is a common approach\nto estimating the test accuracy of a pre-trained neural network on\nout-of-distribution (OOD) samples without requiring access to the corresponding\nground truth labels. Despite their ease of implementation and computational\nefficiency, current logit-based methods are vulnerable to overconfidence\nissues, leading to prediction bias, especially under the natural shift. In this\nwork, we first study the relationship between logits and generalization\nperformance from the view of low-density separation assumption. Our findings\nmotivate our proposed method MaNo which (1) applies a data-dependent\nnormalization on the logits to reduce prediction bias, and (2) takes the $L_p$\nnorm of the matrix of normalized logits as the estimation score. Our\ntheoretical analysis highlights the connection between the provided score and\nthe model's uncertainty. We conduct an extensive empirical study on common\nunsupervised accuracy estimation benchmarks and demonstrate that MaNo achieves\nstate-of-the-art performance across various architectures in the presence of\nsynthetic, natural, or subpopulation shifts.\n","authors":["Renchunzi Xie","Ambroise Odonnat","Vasilii Feofanov","Weijian Deng","Jianfeng Zhang","Bo An"],"pdf_url":"https://arxiv.org/pdf/2405.18979v2.pdf","comment":"The three first authors contributed equally"},{"id":"http://arxiv.org/abs/2406.16456v1","updated":"2024-06-24T08:53:45Z","published":"2024-06-24T08:53:45Z","title":"Automated Privacy-Preserving Techniques via Meta-Learning","summary":"  Sharing private data for learning tasks is pivotal for transparent and secure\nmachine learning applications. Many privacy-preserving techniques have been\nproposed for this task aiming to transform the data while ensuring the privacy\nof individuals. Some of these techniques have been incorporated into tools,\nwhereas others are accessed through various online platforms. However, such\ntools require manual configuration, which can be complex and time-consuming.\nMoreover, they require substantial expertise, potentially restricting their use\nto those with advanced technical knowledge. In this paper, we propose AUTOPRIV,\nthe first automated privacy-preservation method, that eliminates the need for\nany manual configuration. AUTOPRIV employs meta-learning to automate the\nde-identification process, facilitating the secure release of data for machine\nlearning tasks. The main goal is to anticipate the predictive performance and\nprivacy risk of a large set of privacy configurations. We provide a ranked list\nof the most promising solutions, which are likely to achieve an optimal\napproximation within a new domain. AUTOPRIV is highly effective as it reduces\ncomputational complexity and energy consumption considerably.\n","authors":["Tânia Carvalho","Nuno Moniz","Luís Antunes"],"pdf_url":"https://arxiv.org/pdf/2406.16456v1.pdf","comment":"12 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2404.08676v3","updated":"2024-06-24T08:50:22Z","published":"2024-04-06T15:01:47Z","title":"ALERT: A Comprehensive Benchmark for Assessing Large Language Models'\n  Safety through Red Teaming","summary":"  When building Large Language Models (LLMs), it is paramount to bear safety in\nmind and protect them with guardrails. Indeed, LLMs should never generate\ncontent promoting or normalizing harmful, illegal, or unethical behavior that\nmay contribute to harm to individuals or society. This principle applies to\nboth normal and adversarial use. In response, we introduce ALERT, a large-scale\nbenchmark to assess safety based on a novel fine-grained risk taxonomy. It is\ndesigned to evaluate the safety of LLMs through red teaming methodologies and\nconsists of more than 45k instructions categorized using our novel taxonomy. By\nsubjecting LLMs to adversarial testing scenarios, ALERT aims to identify\nvulnerabilities, inform improvements, and enhance the overall safety of the\nlanguage models. Furthermore, the fine-grained taxonomy enables researchers to\nperform an in-depth evaluation that also helps one to assess the alignment with\nvarious policies. In our experiments, we extensively evaluate 10 popular open-\nand closed-source LLMs and demonstrate that many of them still struggle to\nattain reasonable levels of safety.\n","authors":["Simone Tedeschi","Felix Friedrich","Patrick Schramowski","Kristian Kersting","Roberto Navigli","Huu Nguyen","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2404.08676v3.pdf","comment":"17 pages, preprint"},{"id":"http://arxiv.org/abs/2402.05359v5","updated":"2024-06-24T08:49:29Z","published":"2024-02-08T02:37:30Z","title":"Prompting with Divide-and-Conquer Program Makes Large Language Models\n  Discerning to Hallucination and Deception","summary":"  Foundation models, such as Large language Models (LLMs), have attracted\nsignificant amount of interest due to their large number of applications.\nHowever, when handling tasks involving repetitive sub-tasks and/or deceptive\ncontents, such as arithmetic calculation and article-level fake news detection,\nsimple instructional prompts suffer from inaccurate responses. Existing works\nshow that more complicated prompting strategies, such as Chain-of-Thoughts and\nLeast-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent\nresearches reveal that simple divide-and-conquer prompting strategy, i.e.\nsimply dividing the input sequence to multiple sub-inputs, can also\nsubstantially improve LLM's performance in some specific tasks such as\nmisinformation detection. In this paper, we aim at examining the utility of\ndivide-and-conquer prompting strategy and answer on which kind of tasks this\nstrategy gets advantages. Specifically, we provide a theoretic analysis to\ndivide-and-conquer prompting strategy and help us identify the specific tasks\nwhere DaC prompting can bring performance boost with theoretic guarantee. We\nthen present two cases (large integer arithmetic and fact verification) where\nexperimental results aligns with our theoretic analysis.\n","authors":["Yizhou Zhang","Lun Du","Defu Cao","Qiang Fu","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2402.05359v5.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2404.11869v2","updated":"2024-06-24T08:45:52Z","published":"2024-04-18T03:03:37Z","title":"Node-like as a Whole: Structure-aware Searching and Coarsening for Graph\n  Classification","summary":"  Graph Transformers (GTs) have made remarkable achievements in graph-level\ntasks. However, most existing works regard graph structures as a form of\nguidance or bias for enhancing node representations, which focuses on\nnode-central perspectives and lacks explicit representations of edges and\nstructures. One natural question is, can we treat graph structures node-like as\na whole to learn high-level features? Through experimental analysis, we explore\nthe feasibility of this assumption. Based on our findings, we propose a novel\nmulti-view graph representation learning model via structure-aware searching\nand coarsening (GRLsc) on GT architecture for graph classification.\nSpecifically, we build three unique views, original, coarsening, and\nconversion, to learn a thorough structural representation. We compress loops\nand cliques via hierarchical heuristic graph coarsening and restrict them with\nwell-designed constraints, which builds the coarsening view to learn high-level\ninteractions between structures. We also introduce line graphs for edge\nembeddings and switch to edge-central perspective to construct the conversion\nview. Experiments on eight real-world datasets demonstrate the improvements of\nGRLsc over 28 baselines from various architectures.\n","authors":["Xiaorui Qi","Qijie Bai","Yanlong Wen","Haiwei Zhang","Xiaojie Yuan"],"pdf_url":"https://arxiv.org/pdf/2404.11869v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2406.16437v1","updated":"2024-06-24T08:29:58Z","published":"2024-06-24T08:29:58Z","title":"Theory on Mixture-of-Experts in Continual Learning","summary":"  Continual learning (CL) has garnered significant attention because of its\nability to adapt to new tasks that arrive over time. Catastrophic forgetting\n(of old tasks) has been identified as a major issue in CL, as the model adapts\nto new tasks. The Mixture-of-Experts (MoE) model has recently been shown to\neffectively mitigate catastrophic forgetting in CL, by employing a gating\nnetwork to sparsify and distribute diverse tasks among multiple experts.\nHowever, there is a lack of theoretical analysis of MoE and its impact on the\nlearning performance in CL. This paper provides the first theoretical results\nto characterize the impact of MoE in CL via the lens of overparameterized\nlinear regression tasks. We establish the benefit of MoE over a single expert\nby proving that the MoE model can diversify its experts to specialize in\ndifferent tasks, while its router learns to select the right expert for each\ntask and balance the loads across all experts. Our study further suggests an\nintriguing fact that the MoE in CL needs to terminate the update of the gating\nnetwork after sufficient training rounds to attain system convergence, which is\nnot needed in the existing MoE studies that do not consider the continual task\narrival. Furthermore, we provide explicit expressions for the expected\nforgetting and overall generalization error to characterize the benefit of MoE\nin the learning performance in CL. Interestingly, adding more experts requires\nadditional rounds before convergence, which may not enhance the learning\nperformance. Finally, we conduct experiments on both synthetic and real\ndatasets to extend these insights from linear models to deep neural networks\n(DNNs), which also shed light on the practical algorithm design for MoE in CL.\n","authors":["Hongbo Li","Sen Lin","Lingjie Duan","Yingbin Liang","Ness B. Shroff"],"pdf_url":"https://arxiv.org/pdf/2406.16437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12560v2","updated":"2024-06-24T08:27:13Z","published":"2024-06-18T12:40:15Z","title":"Towards Bayesian Data Selection","summary":"  A wide range of machine learning algorithms iteratively add data to the\ntraining sample. Examples include semi-supervised learning, active learning,\nmulti-armed bandits, and Bayesian optimization. We embed this kind of data\naddition into decision theory by framing data selection as a decision problem.\nThis paves the way for finding Bayes-optimal selections of data. For the\nillustrative case of self-training in semi-supervised learning, we derive the\nrespective Bayes criterion. We further show that deploying this criterion\nmitigates the issue of confirmation bias by empirically assessing our method\nfor generalized linear models, semi-parametric generalized additive models, and\nBayesian neural networks on simulated and real-world data.\n","authors":["Julian Rodemann"],"pdf_url":"https://arxiv.org/pdf/2406.12560v2.pdf","comment":"5th Workshop on Data-Centric Machine Learning Research (DMLR) at ICML\n  2024"},{"id":"http://arxiv.org/abs/2311.15036v2","updated":"2024-06-24T08:25:50Z","published":"2023-11-25T14:18:29Z","title":"On-Device Soft Sensors: Real-Time Fluid Flow Estimation from Level\n  Sensor Data","summary":"  Soft sensors are crucial in bridging autonomous systems' physical and digital\nrealms, enhancing sensor fusion and perception. Instead of deploying soft\nsensors on the Cloud, this study shift towards employing on-device soft\nsensors, promising heightened efficiency and bolstering data security. Our\napproach substantially improves energy efficiency by deploying Artificial\nIntelligence (AI) directly on devices within a wireless sensor network.\nFurthermore, the synergistic integration of the Microcontroller Unit and\nField-Programmable Gate Array (FPGA) leverages the rapid AI inference\ncapabilities of the latter. Empirical evidence from our real-world use case\ndemonstrates that FPGA-based soft sensors achieve inference times ranging\nremarkably from 1.04 to 12.04 microseconds. These compelling results highlight\nthe considerable potential of our innovative approach for executing real-time\ninference tasks efficiently, thereby presenting a feasible alternative that\neffectively addresses the latency challenges intrinsic to Cloud-based\ndeployments.\n","authors":["Tianheng Ling","Chao Qian","Gregor Schiele"],"pdf_url":"https://arxiv.org/pdf/2311.15036v2.pdf","comment":"8 pages, 6 figures, 1 Table, Accepted by the 1st AUTONOMOUS\n  UBIQUITOUS SYSTEMS (AUTOQUITOUS) WORKSHOP of EAI MobiQuitous 2023 - 20th EAI\n  International Conference on Mobile and Ubiquitous Systems: Computing,\n  Networking and Services"},{"id":"http://arxiv.org/abs/2406.16426v1","updated":"2024-06-24T08:20:43Z","published":"2024-06-24T08:20:43Z","title":"Fault Detection for agents on power grid topology optimization: A\n  Comprehensive analysis","summary":"  The topology optimization of transmission networks using Deep Reinforcement\nLearning (DRL) has increasingly come into focus. Various researchers have\nproposed different DRL agents, which are often benchmarked on the Grid2Op\nenvironment from the Learning to Run a Power Network (L2RPN) challenges. The\nenvironments have many advantages with their realistic chronics and underlying\npower flow backends. However, the interpretation of agent survival or failure\nis not always clear, as there are a variety of potential causes. In this work,\nwe focus on the failures of the power grid to identify patterns and detect them\na priori. We collect the failed chronics of three different agents on the WCCI\n2022 L2RPN environment, totaling about 40k data points. By clustering, we are\nable to detect five distinct clusters, identifying different failure types.\nFurther, we propose a multi-class prediction approach to detect failures\nbeforehand and evaluate five different models. Here, the Light\nGradient-Boosting Machine (LightGBM) shows the best performance, with an\naccuracy of 86%. It also correctly identifies in 91% of the time failure and\nsurvival observations. Finally, we provide a detailed feature importance\nanalysis that identifies critical features and regions in the grid.\n","authors":["Malte Lehna","Mohamed Hassouna","Dmitry Degtyar","Sven Tomforde","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2406.16426v1.pdf","comment":"11 Pages plus references and appendix. The appendix consist of\n  additional material of the paper and is not included in the initial\n  submission"},{"id":"http://arxiv.org/abs/2403.04161v5","updated":"2024-06-24T08:18:29Z","published":"2024-03-07T02:40:42Z","title":"SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS","summary":"  Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid\nresource-intensive neural network training, especially in Neural Architecture\nSearch (NAS). Recent studies show that existing training-free metrics have\nseveral limitations, such as limited correlation and poor generalisation across\ndifferent search spaces and tasks. Hence, we propose Sample-Wise Activation\nPatterns and its derivative, SWAP-Score, a novel high-performance training-free\nmetric. It measures the expressivity of networks over a batch of input samples.\nThe SWAP-Score is strongly correlated with ground-truth performance across\nvarious search spaces and tasks, outperforming 15 existing training-free\nmetrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be\nfurther enhanced by regularisation, which leads to even higher correlations in\ncell-based search space and enables model size control during the search. For\nexample, Spearman's rank correlation coefficient between regularised SWAP-Score\nand CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90,\nsignificantly higher than 0.80 from the second-best metric, NWOT. When\nintegrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves\ncompetitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and\n9 minutes of GPU time respectively.\n","authors":["Yameng Peng","Andy Song","Haytham M. Fayek","Vic Ciesielski","Xiaojun Chang"],"pdf_url":"https://arxiv.org/pdf/2403.04161v5.pdf","comment":"ICLR2024 Spotlight"},{"id":"http://arxiv.org/abs/2406.16424v1","updated":"2024-06-24T08:18:19Z","published":"2024-06-24T08:18:19Z","title":"Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial\n  Optimization","summary":"  Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an RL approach that leverages memory to improve the adaptation of\nneural solvers at inference time. MEMENTO enables updating the action\ndistribution dynamically based on the outcome of previous decisions. We\nvalidate its effectiveness on benchmark problems, in particular Traveling\nSalesman and Capacitated Vehicle Routing, demonstrating it can successfully be\ncombined with standard methods to boost their performance under a given budget,\nboth in and out-of-distribution, improving their performance on all 12\nevaluated tasks.\n","authors":["Felix Chalumeau","Refiloe Shabe","Noah de Nicola","Arnu Pretorius","Thomas D. Barrett","Nathan Grinsztajn"],"pdf_url":"https://arxiv.org/pdf/2406.16424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14869v2","updated":"2024-06-24T08:02:17Z","published":"2024-04-23T09:51:24Z","title":"EEGEncoder: Advancing BCI with Transformer-Based Motor Imagery\n  Classification","summary":"  Brain-computer interfaces (BCIs) harness electroencephalographic signals for\ndirect neural control of devices, offering a significant benefit for\nindividuals with motor impairments. Traditional machine learning methods for\nEEG-based motor imagery (MI) classification encounter challenges such as manual\nfeature extraction and susceptibility to noise.This paper introduces\nEEGEncoder, a deep learning framework that employs modified transformers and\nTCNs to surmount these limitations. We innovatively propose a fusion\narchitecture, namely Dual-Stream Temporal-Spatial Block (DSTS), to capture\ntemporal and spatial features, improving the accuracy of Motor Imagery\nclassification task. Additionally, we use multiple parallel structures to\nenhance the performance of the model. When tested on the BCI Competition IV-2a\ndataset, our model results outperform current state-of-the-art techniques.\n","authors":["Wangdan Liao","Weidong Wang"],"pdf_url":"https://arxiv.org/pdf/2404.14869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15250v2","updated":"2024-06-24T07:49:25Z","published":"2024-03-22T14:47:35Z","title":"Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A\n  Multifaceted Statistical Approach","summary":"  Amidst the rapid evolution of LLMs, the significance of evaluation in\ncomprehending and propelling these models forward is increasingly paramount.\nEvaluations have revealed that factors such as scaling, training types,\narchitectures and other factors profoundly impact the performance of LLMs.\nHowever, the extent and nature of these impacts continue to be subjects of\ndebate because most assessments have been restricted to a limited number of\nmodels and data points. Clarifying the effects of these factors on performance\nscores can be more effectively achieved through a statistical lens. Our study\nembarks on a thorough re-examination of these LLMs, targeting the inadequacies\nin current evaluation methods. With the advent of a uniform evaluation\nframework, our research leverages an expansive dataset of evaluation results,\nintroducing a comprehensive statistical methodology. This includes the\napplication of ANOVA, Tukey HSD tests, GAMM, and clustering technique, offering\na robust and transparent approach to deciphering LLM performance data. Contrary\nto prevailing findings, our results challenge assumptions about emergent\nabilities and the influence of given training types and architectures in LLMs.\nThese findings furnish new perspectives on the characteristics, intrinsic\nnature, and developmental trajectories of LLMs. By providing straightforward\nand reliable methods to scrutinize and reassess LLM performance data, this\nstudy contributes a nuanced perspective on LLM efficiency and potentials.\n","authors":["Kun Sun","Rong Wang","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2403.15250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15070v2","updated":"2024-06-24T07:39:38Z","published":"2024-06-21T11:40:01Z","title":"Tempora-Fusion: Time-Lock Puzzle with Efficient Verifiable Homomorphic\n  Linear Combination","summary":"  To securely transmit sensitive information into the future, Time-Lock Puzzles\n(TLPs) have been developed. Their applications include scheduled payments,\ntimed commitments, e-voting, and sealed-bid auctions. Homomorphic TLP is a key\nvariant of TLP that enables computation on puzzles from different clients. This\nallows a solver/server to tackle only a single puzzle encoding the\ncomputation's result. However, existing homomorphic TLPs lack support for\nverifying the correctness of the computation results. We address this\nlimitation by introducing Tempora-Fusion, a TLP that allows a server to perform\nhomomorphic linear combinations of puzzles from different clients while\nensuring verification of computation correctness. This scheme avoids\nasymmetric-key cryptography for verification, thus paving the way for efficient\nimplementations. We discuss our scheme's application in various domains, such\nas federated learning, scheduled payments in online banking, and e-voting.\n","authors":["Aydin Abadi"],"pdf_url":"https://arxiv.org/pdf/2406.15070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05365v2","updated":"2024-06-24T07:39:26Z","published":"2024-06-08T06:04:55Z","title":"CaLM: Contrasting Large and Small Language Models to Verify Grounded\n  Generation","summary":"  Grounded generation aims to equip language models (LMs) with the ability to\nproduce more credible and accountable responses by accurately citing verifiable\nsources. However, existing methods, by either feeding LMs with raw or\npreprocessed materials, remain prone to errors. To address this, we introduce\nCaLM, a novel verification framework. CaLM leverages the insight that a robust\ngrounded response should be consistent with information derived solely from its\ncited sources. Our framework empowers smaller LMs, which rely less on\nparametric memory and excel at processing relevant information given a query,\nto validate the output of larger LMs. Larger LM responses that closely align\nwith the smaller LMs' output, which relies exclusively on cited documents, are\nverified. Responses showing discrepancies are iteratively refined through a\nfeedback loop. Experiments on three open-domain question-answering datasets\ndemonstrate significant performance gains of 1.5% to 7% absolute average\nwithout any required model fine-tuning.\n","authors":["I-Hung Hsu","Zifeng Wang","Long T. Le","Lesly Miculicich","Nanyun Peng","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2406.05365v2.pdf","comment":"ACL 2024 Camera Ready Version"},{"id":"http://arxiv.org/abs/2306.02419v2","updated":"2024-06-24T07:06:44Z","published":"2023-06-04T17:51:37Z","title":"Bad Habits: Policy Confounding and Out-of-Trajectory Generalization in\n  RL","summary":"  Reinforcement learning agents tend to develop habits that are effective only\nunder specific policies. Following an initial exploration phase where agents\ntry out different actions, they eventually converge onto a particular policy.\nAs this occurs, the distribution over state-action trajectories becomes\nnarrower, leading agents to repeatedly experience the same transitions. This\nrepetitive exposure fosters spurious correlations between certain observations\nand rewards. Agents may then pick up on these correlations and develop\nsimplistic habits tailored to the specific set of trajectories dictated by\ntheir policy. The problem is that these habits may yield incorrect outcomes\nwhen agents are forced to deviate from their typical trajectories, prompted by\nchanges in the environment. This paper presents a mathematical characterization\nof this phenomenon, termed policy confounding, and illustrates, through a\nseries of examples, the circumstances under which it occurs.\n","authors":["Miguel Suau","Matthijs T. J. Spaan","Frans A. Oliehoek"],"pdf_url":"https://arxiv.org/pdf/2306.02419v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06462v2","updated":"2024-06-24T07:05:01Z","published":"2024-06-10T16:58:48Z","title":"VCR: Visual Caption Restoration","summary":"  We introduce Visual Caption Restoration (VCR), a novel vision-language task\nthat challenges models to accurately restore partially obscured texts using\npixel-level hints within images. This task stems from the observation that text\nembedded in images is intrinsically different from common visual elements and\nnatural language due to the need to align the modalities of vision, text, and\ntext embedded in images. While numerous works have integrated text embedded in\nimages into visual question-answering tasks, approaches to these tasks\ngenerally rely on optical character recognition or masked language modeling,\nthus reducing the task to mainly text-based processing. However, text-based\nprocessing becomes ineffective in VCR as accurate text restoration depends on\nthe combined information from provided images, context, and subtle cues from\nthe tiny exposed areas of masked texts. We develop a pipeline to generate\nsynthetic images for the VCR task using image-caption pairs, with adjustable\ncaption visibility to control the task difficulty. With this pipeline, we\nconstruct a dataset for VCR called VCR-Wiki using images with captions from\nWikipedia, comprising 2.11M English and 346K Chinese entities in both easy and\nhard split variants. Our results reveal that current vision language models\nsignificantly lag behind human performance in the VCR task, and merely\nfine-tuning the models on our dataset does not lead to notable improvements. We\nrelease VCR-Wiki and the data construction code to facilitate future research.\n","authors":["Tianyu Zhang","Suyuchen Wang","Lu Li","Ge Zhang","Perouz Taslakian","Sai Rajeswar","Jie Fu","Bang Liu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2406.06462v2.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.16357v1","updated":"2024-06-24T06:53:37Z","published":"2024-06-24T06:53:37Z","title":"Towards Lightweight Graph Neural Network Search with Curriculum Graph\n  Sparsification","summary":"  Graph Neural Architecture Search (GNAS) has achieved superior performance on\nvarious graph-structured tasks. However, existing GNAS studies overlook the\napplications of GNAS in resource-constraint scenarios. This paper proposes to\ndesign a joint graph data and architecture mechanism, which identifies\nimportant sub-architectures via the valuable graph data. To search for optimal\nlightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural\nArchitecture Search with Graph SparsIfication and Network Pruning (GASSIP)\nmethod. In particular, GASSIP comprises an operation-pruned architecture search\nmodule to enable efficient lightweight GNN search. Meanwhile, we design a novel\ncurriculum graph data sparsification module with an architecture-aware\nedge-removing difficulty measurement to help select optimal sub-architectures.\nWith the aid of two differentiable masks, we iteratively optimize these two\nmodules to efficiently search for the optimal lightweight architecture.\nExtensive experiments on five benchmarks demonstrate the effectiveness of\nGASSIP. Particularly, our method achieves on-par or even higher node\nclassification performance with half or fewer model parameters of searched GNNs\nand a sparser graph.\n","authors":["Beini Xie","Heng Chang","Ziwei Zhang","Zeyang Zhang","Simin Wu","Xin Wang","Yuan Meng","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.16357v1.pdf","comment":"Accepted by KDD 2024. The two first authors made equal contributions"},{"id":"http://arxiv.org/abs/2312.16581v3","updated":"2024-06-24T06:53:23Z","published":"2023-12-27T14:13:42Z","title":"Continuous-time Autoencoders for Regular and Irregular Time Series\n  Imputation","summary":"  Time series imputation is one of the most fundamental tasks for time series.\nReal-world time series datasets are frequently incomplete (or irregular with\nmissing observations), in which case imputation is strongly required. Many\ndifferent time series imputation methods have been proposed. Recent\nself-attention-based methods show the state-of-the-art imputation performance.\nHowever, it has been overlooked for a long time to design an imputation method\nbased on continuous-time recurrent neural networks (RNNs), i.e., neural\ncontrolled differential equations (NCDEs). To this end, we redesign time series\n(variational) autoencoders based on NCDEs. Our method, called continuous-time\nautoencoder (CTA), encodes an input time series sample into a continuous hidden\npath (rather than a hidden vector) and decodes it to reconstruct and impute the\ninput. In our experiments with 4 datasets and 19 baselines, our method shows\nthe best imputation performance in almost all cases.\n","authors":["Hyowon Wi","Yehjin Shin","Noseong Park"],"pdf_url":"https://arxiv.org/pdf/2312.16581v3.pdf","comment":"Published as a WSDM'24 full paper (oral presentation)"},{"id":"http://arxiv.org/abs/2406.16355v1","updated":"2024-06-24T06:52:50Z","published":"2024-06-24T06:52:50Z","title":"Compact Model Parameter Extraction via Derivative-Free Optimization","summary":"  In this paper, we address the problem of compact model parameter extraction\nto simultaneously extract tens of parameters via derivative-free optimization.\nTraditionally, parameter extraction is performed manually by dividing the\ncomplete set of parameters into smaller subsets, each targeting different\noperational regions of the device, a process that can take several days or even\nweeks. Our approach streamlines this process by employing derivative-free\noptimization to identify a good parameter set that best fits the compact model\nwithout performing an exhaustive number of simulations. We further enhance the\noptimization process to address critical issues in device modeling by carefully\nchoosing a loss function that evaluates model performance consistently across\nvarying magnitudes by focusing on relative errors (as opposed to absolute\nerrors), prioritizing accuracy in key operational regions of the device above a\ncertain threshold, and reducing sensitivity to outliers. Furthermore, we\nutilize the concept of train-test split to assess the model fit and avoid\noverfitting. This is done by fitting 80% of the data and testing the model\nefficacy with the remaining 20%. We demonstrate the effectiveness of our\nmethodology by successfully modeling two semiconductor devices: a diamond\nSchottky diode and a GaN-on-SiC HEMT, with the latter involving the ASM-HEMT DC\nmodel, which requires simultaneously extracting 35 model parameters to fit the\nmodel to the measured data. These examples demonstrate the effectiveness of our\napproach and showcase the practical benefits of derivative-free optimization in\ndevice modeling.\n","authors":["Rafael Perez Martinez","Masaya Iwamoto","Kelly Woo","Zhengliang Bian","Roberto Tinti","Stephen Boyd","Srabanti Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2406.16355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.10740v3","updated":"2024-06-24T06:51:55Z","published":"2023-09-19T16:36:33Z","title":"ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation\n  with Consistency Distillation","summary":"  Diffusion models are instrumental in text-to-audio (TTA) generation.\nUnfortunately, they suffer from slow inference due to an excessive number of\nqueries to the underlying denoising network per generation. To address this\nbottleneck, we introduce ConsistencyTTA, a framework requiring only a single\nnon-autoregressive network query, thereby accelerating TTA by hundreds of\ntimes. We achieve so by proposing \"CFG-aware latent consistency model,\" which\nadapts consistency generation into a latent space and incorporates\nclassifier-free guidance (CFG) into model training. Moreover, unlike diffusion\nmodels, ConsistencyTTA can be finetuned closed-loop with audio-space text-aware\nmetrics, such as CLAP score, to further enhance the generations. Our objective\nand subjective evaluation on the AudioCaps dataset shows that compared to\ndiffusion-based counterparts, ConsistencyTTA reduces inference computation by\n400x while retaining generation quality and diversity.\n","authors":["Yatong Bai","Trung Dang","Dung Tran","Kazuhito Koishida","Somayeh Sojoudi"],"pdf_url":"https://arxiv.org/pdf/2309.10740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16351v1","updated":"2024-06-24T06:47:47Z","published":"2024-06-24T06:47:47Z","title":"METRIK: Measurement-Efficient Randomized Controlled Trials using\n  Transformers with Input Masking","summary":"  Clinical randomized controlled trials (RCTs) collect hundreds of measurements\nspanning various metric types (e.g., laboratory tests, cognitive/motor\nassessments, etc.) across 100s-1000s of subjects to evaluate the effect of a\ntreatment, but do so at the cost of significant trial expense. To reduce the\nnumber of measurements, trial protocols can be revised to remove metrics\nextraneous to the study's objective, but doing so requires additional human\nlabor and limits the set of hypotheses that can be studied with the collected\ndata. In contrast, a planned missing design (PMD) can reduce the amount of data\ncollected without removing any metric by imputing the unsampled data. Standard\nPMDs randomly sample data to leverage statistical properties of imputation\nalgorithms, but are ad hoc, hence suboptimal. Methods that learn PMDs produce\nmore sample-efficient PMDs, but are not suitable for RCTs because they require\nample prior data (150+ subjects) to model the data distribution. Therefore, we\nintroduce a framework called Measurement EfficienT Randomized Controlled Trials\nusing Transformers with Input MasKing (METRIK), which, for the first time,\ncalculates a PMD specific to the RCT from a modest amount of prior data (e.g.,\n60 subjects). Specifically, METRIK models the PMD as a learnable input masking\nlayer that is optimized with a state-of-the-art imputer based on the\nTransformer architecture. METRIK implements a novel sampling and selection\nalgorithm to generate a PMD that satisfies the trial designer's objective,\ni.e., whether to maximize sampling efficiency or imputation performance for a\ngiven sampling budget. Evaluated across five real-world clinical RCT datasets,\nMETRIK increases the sampling efficiency of and imputation performance under\nthe generated PMD by leveraging correlations over time and across metrics,\nthereby removing the need to manually remove metrics from the RCT.\n","authors":["Sayeri Lala","Niraj K. Jha"],"pdf_url":"https://arxiv.org/pdf/2406.16351v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.16349v1","updated":"2024-06-24T06:44:14Z","published":"2024-06-24T06:44:14Z","title":"AnnotatedTables: A Large Tabular Dataset with Language Model Annotations","summary":"  Tabular data is ubiquitous in real-world applications and abundant on the\nweb, yet its annotation has traditionally required human labor, posing a\nsignificant scalability bottleneck for tabular machine learning. Our\nmethodology can successfully annotate a large amount of tabular data and can be\nflexibly steered to generate various types of annotations based on specific\nresearch objectives, as we demonstrate with SQL annotation and input-target\ncolumn annotation as examples. As a result, we release AnnotatedTables, a\ncollection of 32,119 databases with LLM-generated annotations. The dataset\nincludes 405,616 valid SQL programs, making it the largest SQL dataset with\nassociated tabular data that supports query execution. To further demonstrate\nthe value of our methodology and dataset, we perform two follow-up research\nstudies. 1) We investigate whether LLMs can translate SQL programs to Rel\nprograms, a database language previously unknown to LLMs, while obtaining the\nsame execution results. Using our Incremental Prompt Engineering methods based\non execution feedback, we show that LLMs can produce adequate translations with\nfew-shot learning. 2) We evaluate the performance of TabPFN, a recent neural\ntabular classifier trained on Bayesian priors, on 2,720 tables with\ninput-target columns identified and annotated by LLMs. On average, TabPFN\nperforms on par with the baseline AutoML method, though the relative\nperformance can vary significantly from one data table to another, making both\nmodels viable for practical applications depending on the situation. Our\nfindings underscore the potential of LLMs in automating the annotation of large\nvolumes of diverse tabular data.\n","authors":["Yaojie Hu","Ilias Fountalis","Jin Tian","Nikolaos Vasiloglou"],"pdf_url":"https://arxiv.org/pdf/2406.16349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10638v6","updated":"2024-06-24T06:28:42Z","published":"2023-10-16T17:57:12Z","title":"In-context Pretraining: Language Modeling Beyond Document Boundaries","summary":"  Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).\n","authors":["Weijia Shi","Sewon Min","Maria Lomeli","Chunting Zhou","Margaret Li","Gergely Szilvasy","Rich James","Xi Victoria Lin","Noah A. Smith","Luke Zettlemoyer","Scott Yih","Mike Lewis"],"pdf_url":"https://arxiv.org/pdf/2310.10638v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12842v2","updated":"2024-06-24T05:40:38Z","published":"2024-02-20T09:10:08Z","title":"PromptKD: Distilling Student-Friendly Knowledge for Generative Language\n  Models via Prompt Tuning","summary":"  Recent advancements in large language models (LLMs) have raised concerns\nabout inference costs, increasing the need for research into model compression.\nWhile knowledge distillation (KD) is a prominent method for this, research on\nKD for generative language models like LLMs is relatively sparse, and the\napproach of distilling student-friendly knowledge, which has shown promising\nperformance in KD for classification models, remains unexplored in generative\nlanguage models. To explore this approach, we propose PromptKD, a simple yet\neffective method that utilizes prompt tuning - for the first time in KD - to\nenable generative language models to transfer student-friendly knowledge.\nUnlike previous works in classification that require fine-tuning the entire\nteacher model for extracting student-friendly knowledge, PromptKD achieves\nsimilar effects by adding a small number of prompt tokens and tuning only the\nprompt with student guidance. Extensive experiments on instruction-following\ndatasets show that PromptKD achieves state-of-the-art performance while adding\nonly 0.0007% of the teacher's parameters as prompts. Further analysis suggests\nthat distilling student-friendly knowledge alleviates exposure bias effectively\nthroughout the entire training process, leading to performance enhancements.\n","authors":["Gyeongman Kim","Doohyuk Jang","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2402.12842v2.pdf","comment":"Code: https://github.com/gmkim-ai/PromptKD"},{"id":"http://arxiv.org/abs/2406.16322v1","updated":"2024-06-24T05:15:15Z","published":"2024-06-24T05:15:15Z","title":"Lesion-Aware Cross-Phase Attention Network for Renal Tumor Subtype\n  Classification on Multi-Phase CT Scans","summary":"  Multi-phase computed tomography (CT) has been widely used for the\npreoperative diagnosis of kidney cancer due to its non-invasive nature and\nability to characterize renal lesions. However, since enhancement patterns of\nrenal lesions across CT phases are different even for the same lesion type, the\nvisual assessment by radiologists suffers from inter-observer variability in\nclinical practice. Although deep learning-based approaches have been recently\nexplored for differential diagnosis of kidney cancer, they do not explicitly\nmodel the relationships between CT phases in the network design, limiting the\ndiagnostic performance. In this paper, we propose a novel lesion-aware\ncross-phase attention network (LACPANet) that can effectively capture temporal\ndependencies of renal lesions across CT phases to accurately classify the\nlesions into five major pathological subtypes from time-series multi-phase CT\nimages. We introduce a 3D inter-phase lesion-aware attention mechanism to learn\neffective 3D lesion features that are used to estimate attention weights\ndescribing the inter-phase relations of the enhancement patterns. We also\npresent a multi-scale attention scheme to capture and aggregate temporal\npatterns of lesion features at different spatial scales for further\nimprovement. Extensive experiments on multi-phase CT scans of kidney cancer\npatients from the collected dataset demonstrate that our LACPANet outperforms\nstate-of-the-art approaches in diagnostic accuracy.\n","authors":["Kwang-Hyun Uhm","Seung-Won Jung","Sung-Hoo Hong","Sung-Jea Ko"],"pdf_url":"https://arxiv.org/pdf/2406.16322v1.pdf","comment":"This article has been accepted for publication in Computers in\n  Biology and Medicine"},{"id":"http://arxiv.org/abs/2406.16321v1","updated":"2024-06-24T05:14:09Z","published":"2024-06-24T05:14:09Z","title":"Multimodal Graph Benchmark","summary":"  Associating unstructured data with structured information is crucial for\nreal-world tasks that require relevance search. However, existing graph\nlearning benchmarks often overlook the rich semantic information associate with\neach node. To bridge such gap, we introduce the Multimodal Graph Benchmark\n(MM-GRAPH), the first comprehensive multi-modal graph benchmark that\nincorporates both textual and visual information. MM-GRAPH surpasses previous\nefforts, which have primarily focused on text-attributed graphs with various\nconnectivity patterns. MM-GRAPH consists of five graph learning datasets of\nvarious scales that are appropriate for different learning tasks. Their\nmultimodal node features, enabling a more comprehensive evaluation of graph\nlearning algorithms in real-world scenarios. To facilitate research on\nmultimodal graph learning, we further provide an extensive study on the\nperformance of various graph neural networks in the presence of features from\nvarious modalities. MM-GRAPH aims to foster research on multimodal graph\nlearning and drive the development of more advanced and robust graph learning\nalgorithms. By providing a diverse set of datasets and benchmarks, MM-GRAPH\nenables researchers to evaluate and compare their models in realistic settings,\nultimately leading to improved performance on real-world applications that rely\non multimodal graph data.\n","authors":["Jing Zhu","Yuhang Zhou","Shengyi Qian","Zhongmou He","Tong Zhao","Neil Shah","Danai Koutra"],"pdf_url":"https://arxiv.org/pdf/2406.16321v1.pdf","comment":"https://mm-graph-benchmark.github.io/"},{"id":"http://arxiv.org/abs/2402.05220v2","updated":"2024-06-24T05:13:06Z","published":"2024-02-07T19:52:35Z","title":"On Parameter Estimation in Deviated Gaussian Mixture of Experts","summary":"  We consider the parameter estimation problem in the deviated Gaussian mixture\nof experts in which the data are generated from $(1 - \\lambda^{\\ast}) g_0(Y|\nX)+ \\lambda^{\\ast} \\sum_{i = 1}^{k_{\\ast}} p_{i}^{\\ast}\nf(Y|(a_{i}^{\\ast})^{\\top}X+b_i^{\\ast},\\sigma_{i}^{\\ast})$, where $X, Y$ are\nrespectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a\nknown function, $\\lambda^{\\ast} \\in [0, 1]$ is true but unknown mixing\nproportion, and $(p_{i}^{\\ast}, a_{i}^{\\ast}, b_{i}^{\\ast}, \\sigma_{i}^{\\ast})$\nfor $1 \\leq i \\leq k^{\\ast}$ are unknown parameters of the Gaussian mixture of\nexperts. This problem arises from the goodness-of-fit test when we would like\nto test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or\nthey are generated from the whole mixture (alternative hypothesis). Based on\nthe algebraic structure of the expert functions and the distinguishability\nbetween $g_0$ and the mixture part, we construct novel Voronoi-based loss\nfunctions to capture the convergence rates of maximum likelihood estimation\n(MLE) for our models. We further demonstrate that our proposed loss functions\ncharacterize the local convergence rates of parameter estimation more\naccurately than the generalized Wasserstein, a loss function being commonly\nused for estimating parameters in the Gaussian mixture of experts.\n","authors":["Huy Nguyen","Khai Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2402.05220v2.pdf","comment":"Accepted to AISTATS 2024, 32 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.14725v2","updated":"2024-06-24T05:01:06Z","published":"2024-03-20T21:53:56Z","title":"Testing the Limits of Jailbreaking Defenses with the Purple Problem","summary":"  The rise of \"jailbreak\" attacks on language models has led to a flurry of\ndefenses aimed at preventing undesirable responses. We critically examine the\ntwo stages of the defense pipeline: (i) defining what constitutes unsafe\noutputs, and (ii) enforcing the definition via methods such as input processing\nor fine-tuning. To test the efficacy of existing enforcement mechanisms, we\nconsider a simple and well-specified definition of unsafe outputs--outputs that\ncontain the word \"purple\". Surprisingly, existing fine-tuning and input\ndefenses fail on this simple problem, casting doubt on whether enforcement\nalgorithms can be robust for more complicated definitions. We find that real\nsafety benchmarks similarly test enforcement for a fixed definition. We hope\nthat future research can lead to effective/fast enforcement as well as high\nquality definitions used for enforcement and evaluation.\n","authors":["Taeyoun Kim","Suhas Kotha","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2403.14725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07379v2","updated":"2024-06-24T04:53:34Z","published":"2024-03-12T07:32:47Z","title":"Hallmarks of Optimization Trajectories in Neural Networks: Directional\n  Exploration and Redundancy","summary":"  We propose a fresh take on understanding the mechanisms of neural networks by\nanalyzing the rich directional structure of optimization trajectories,\nrepresented by their pointwise parameters. Towards this end, we introduce some\nnatural notions of the complexity of optimization trajectories, both\nqualitative and quantitative, which hallmark the directional nature of\noptimization in neural networks: when is there redundancy, and when\nexploration. We use them to reveal the inherent nuance and interplay involved\nbetween various optimization choices, such as momentum and weight decay.\nFurther, the trajectory perspective helps us see the effect of scale on\nregularizing the directional nature of trajectories, and as a by-product, we\nalso observe an intriguing heterogeneity of Q,K,V dynamics in the middle\nattention layers in LLMs and which is homogenized by scale. Importantly, we put\nthe significant directional redundancy observed to the test by demonstrating\nthat training only scalar batchnorm parameters some while into training matches\nthe performance of training the entire network, which thus exhibits the\npotential of hybrid optimization schemes that are geared towards efficiency.\n","authors":["Sidak Pal Singh","Bobby He","Thomas Hofmann","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2403.07379v2.pdf","comment":"Preprint, 57 pages"},{"id":"http://arxiv.org/abs/2310.14188v2","updated":"2024-06-24T04:53:09Z","published":"2023-10-22T05:32:19Z","title":"A General Theory for Softmax Gating Multinomial Logistic Mixture of\n  Experts","summary":"  Mixture-of-experts (MoE) model incorporates the power of multiple submodels\nvia gating functions to achieve greater performance in numerous regression and\nclassification applications. From a theoretical perspective, while there have\nbeen previous attempts to comprehend the behavior of that model under the\nregression settings through the convergence analysis of maximum likelihood\nestimation in the Gaussian MoE model, such analysis under the setting of a\nclassification problem has remained missing in the literature. We close this\ngap by establishing the convergence rates of density estimation and parameter\nestimation in the softmax gating multinomial logistic MoE model. Notably, when\npart of the expert parameters vanish, these rates are shown to be slower than\npolynomial rates owing to an inherent interaction between the softmax gating\nand expert functions via partial differential equations. To address this issue,\nwe propose using a novel class of modified softmax gating functions which\ntransform the input before delivering them to the gating functions. As a\nresult, the previous interaction disappears and the parameter estimation rates\nare significantly improved.\n","authors":["Huy Nguyen","Pedram Akbarian","TrungTin Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2310.14188v2.pdf","comment":"Accepted to ICML 2024, 32 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2405.15861v2","updated":"2024-06-24T04:52:25Z","published":"2024-05-24T18:07:05Z","title":"Achieving Dimension-Free Communication in Federated Learning via\n  Zeroth-Order Optimization","summary":"  Federated Learning (FL) offers a promising framework for collaborative and\nprivacy-preserving machine learning across distributed data sources. However,\nthe substantial communication costs associated with FL pose a significant\nchallenge to its efficiency. Specifically, in each communication round, the\ncommunication costs scale linearly with the model's dimension, which presents a\nformidable obstacle, especially in large model scenarios. Despite various\ncommunication efficient strategies, the intrinsic dimension-dependent\ncommunication cost remains a major bottleneck for current FL implementations.\nIn this paper, we introduce a novel dimension-free communication strategy for\nFL, leveraging zero-order optimization techniques. We propose a new algorithm,\nFedDisco, which facilitates the transmission of only a constant number of\nscalar values between clients and the server in each communication round,\nthereby reducing the communication cost from $\\mathscr{O}(d)$ to\n$\\mathscr{O}(1)$, where $d$ is the dimension of the model parameters.\nTheoretically, in non-convex functions, we prove that our algorithm achieves\nstate-of-the-art rates, which show a linear speedup of the number of clients\nand local steps under standard assumptions and dimension-free rate for low\neffective rank scenarios. Empirical evaluations through classic deep learning\ntraining and large language model fine-tuning substantiate significant\nreductions in communication overhead compared to traditional FL approaches. Our\ncode is available at https://github.com/ZidongLiu/FedDisco.\n","authors":["Zhe Li","Bicheng Ying","Zidong Liu","Haibo Yang"],"pdf_url":"https://arxiv.org/pdf/2405.15861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16316v1","updated":"2024-06-24T04:50:12Z","published":"2024-06-24T04:50:12Z","title":"Does Cross-Cultural Alignment Change the Commonsense Morality of\n  Language Models?","summary":"  Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.\n","authors":["Yuu Jinnai"],"pdf_url":"https://arxiv.org/pdf/2406.16316v1.pdf","comment":"The 2nd Workshop on Cross-Cultural Considerations in NLP (C3NLP) at\n  ACL 2024"},{"id":"http://arxiv.org/abs/2402.14208v3","updated":"2024-06-24T04:49:16Z","published":"2024-02-22T01:20:51Z","title":"LLM-Assisted Content Conditional Debiasing for Fair Text Embedding","summary":"  Mitigating biases in machine learning models has become an increasing concern\nin Natural Language Processing (NLP), particularly in developing fair text\nembeddings, which are crucial yet challenging for real-world applications like\nsearch engines. In response, this paper proposes a novel method for learning\nfair text embeddings. First, we define a novel content-conditional equal\ndistance (CCED) fairness for text embeddings, ensuring content-conditional\nindependence between sensitive attributes and text embeddings. Building on\nCCED, we introduce a content-conditional debiasing (CCD) loss to ensure that\nembeddings of texts with different sensitive attributes but identical content\nmaintain the same distance from the embedding of their corresponding neutral\ntext. Additionally, we tackle the issue of insufficient training data by using\nLarge Language Models (LLMs) with instructions to fairly augment texts into\ndifferent sensitive groups. Our extensive evaluations show that our approach\neffectively enhances fairness while maintaining the utility of embeddings.\nFurthermore, our augmented dataset, combined with the CCED metric, serves as an\nnew benchmark for evaluating fairness.\n","authors":["Wenlong Deng","Blair Chen","Beidi Zhao","Chiyu Zhang","Xiaoxiao Li","Christos Thrampoulidis"],"pdf_url":"https://arxiv.org/pdf/2402.14208v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13875v2","updated":"2024-06-24T04:45:30Z","published":"2024-01-25T01:09:09Z","title":"Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?","summary":"  Dense-to-sparse gating mixture of experts (MoE) has recently become an\neffective alternative to a well-known sparse MoE. Rather than fixing the number\nof activated experts as in the latter model, which could limit the\ninvestigation of potential experts, the former model utilizes the temperature\nto control the softmax weight distribution and the sparsity of the MoE during\ntraining in order to stabilize the expert specialization. Nevertheless, while\nthere are previous attempts to theoretically comprehend the sparse MoE, a\ncomprehensive analysis of the dense-to-sparse gating MoE has remained elusive.\nTherefore, we aim to explore the impacts of the dense-to-sparse gate on the\nmaximum likelihood estimation under the Gaussian MoE in this paper. We\ndemonstrate that due to interactions between the temperature and other model\nparameters via some partial differential equations, the convergence rates of\nparameter estimations are slower than any polynomial rates, and could be as\nslow as $\\mathcal{O}(1/\\log(n))$, where $n$ denotes the sample size. To address\nthis issue, we propose using a novel activation dense-to-sparse gate, which\nroutes the output of a linear layer to an activation function before delivering\nthem to the softmax function. By imposing linearly independence conditions on\nthe activation function and its derivatives, we show that the parameter\nestimation rates are significantly improved to polynomial rates. Finally, we\nconduct a simulation study to empirically validate our theoretical results.\n","authors":["Huy Nguyen","Pedram Akbarian","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2401.13875v2.pdf","comment":"Accepted to ICML 2024, 47 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2402.18846v2","updated":"2024-06-24T04:33:30Z","published":"2024-02-29T04:40:25Z","title":"Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling","summary":"  Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the\nhighest fidelity level by combining data from multiple sources. Traditional\nmethods relying on Gaussian processes can hardly scale to high-dimensional\ndata. Deep learning approaches utilize neural network based encoders and\ndecoders to improve scalability. These approaches share encoded representations\nacross fidelities without including corresponding decoder parameters. This\nhinders inference performance, especially in out-of-distribution scenarios when\nthe highest fidelity data has limited domain coverage. To address these\nlimitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a\nnovel multi-fidelity surrogate modeling framework. MFRNP explicitly models the\nresidual between the aggregated output from lower fidelities and ground truth\nat the highest fidelity. The aggregation introduces decoders into the\ninformation sharing step and optimizes lower fidelity decoders to accurately\ncapture both in-fidelity and cross-fidelity information. We show that MFRNP\nsignificantly outperforms state-of-the-art in learning partial differential\nequations and a real-world climate modeling task. Our code is published at:\nhttps://github.com/Rose-STL-Lab/MFRNP\n","authors":["Ruijia Niu","Dongxia Wu","Kai Kim","Yi-An Ma","Duncan Watson-Parris","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2402.18846v2.pdf","comment":"A novel probabilistic inference approach for scalable multi-fidelity\n  surrogate modeling"},{"id":"http://arxiv.org/abs/2402.02952v2","updated":"2024-06-24T04:32:55Z","published":"2024-02-05T12:31:18Z","title":"On Least Square Estimation in Softmax Gating Mixture of Experts","summary":"  Mixture of experts (MoE) model is a statistical machine learning design that\naggregates multiple expert networks using a softmax gating function in order to\nform a more intricate and expressive model. Despite being commonly used in\nseveral applications owing to their scalability, the mathematical and\nstatistical properties of MoE models are complex and difficult to analyze. As a\nresult, previous theoretical works have primarily focused on probabilistic MoE\nmodels by imposing the impractical assumption that the data are generated from\na Gaussian MoE model. In this work, we investigate the performance of the least\nsquares estimators (LSE) under a deterministic MoE model where the data are\nsampled according to a regression model, a setting that has remained largely\nunexplored. We establish a condition called strong identifiability to\ncharacterize the convergence behavior of various types of expert functions. We\ndemonstrate that the rates for estimating strongly identifiable experts, namely\nthe widely used feed-forward networks with activation functions\n$\\mathrm{sigmoid}(\\cdot)$ and $\\tanh(\\cdot)$, are substantially faster than\nthose of polynomial experts, which we show to exhibit a surprising slow\nestimation rate. Our findings have important practical implications for expert\nselection.\n","authors":["Huy Nguyen","Nhat Ho","Alessandro Rinaldo"],"pdf_url":"https://arxiv.org/pdf/2402.02952v2.pdf","comment":"Accepted to ICML 2024, 29 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2402.17705v2","updated":"2024-06-24T04:21:33Z","published":"2024-02-27T17:33:23Z","title":"Federated Learning for Estimating Heterogeneous Treatment Effects","summary":"  Machine learning methods for estimating heterogeneous treatment effects (HTE)\nfacilitate large-scale personalized decision-making across various domains such\nas healthcare, policy making, education, and more. Current machine learning\napproaches for HTE require access to substantial amounts of data per treatment,\nand the high costs associated with interventions makes centrally collecting so\nmuch data for each intervention a formidable challenge. To overcome this\nobstacle, in this work, we propose a novel framework for collaborative learning\nof HTE estimators across institutions via Federated Learning. We show that even\nunder a diversity of interventions and subject populations across clients, one\ncan jointly learn a common feature representation, while concurrently and\nprivately learning the specific predictive functions for outcomes under\ndistinct interventions across institutions. Our framework and the associated\nalgorithm are based on this insight, and leverage tabular transformers to map\nmultiple input data to feature representations which are then used for outcome\nprediction via multi-task learning. We also propose a novel way of federated\ntraining of personalised transformers that can work with heterogeneous input\nfeature spaces. Experimental results on real-world clinical trial data\ndemonstrate the effectiveness of our method.\n","authors":["Disha Makhija","Joydeep Ghosh","Yejin Kim"],"pdf_url":"https://arxiv.org/pdf/2402.17705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16308v1","updated":"2024-06-24T04:17:03Z","published":"2024-06-24T04:17:03Z","title":"Anomaly Detection of Tabular Data Using LLMs","summary":"  Large language models (LLMs) have shown their potential in long-context\nunderstanding and mathematical reasoning. In this paper, we study the problem\nof using LLMs to detect tabular anomalies and show that pre-trained LLMs are\nzero-shot batch-level anomaly detectors. That is, without extra\ndistribution-specific model fitting, they can discover hidden outliers in a\nbatch of data, demonstrating their ability to identify low-density data\nregions. For LLMs that are not well aligned with anomaly detection and\nfrequently output factual errors, we apply simple yet effective data-generating\nprocesses to simulate synthetic batch-level anomaly detection datasets and\npropose an end-to-end fine-tuning strategy to bring out the potential of LLMs\nin detecting real anomalies. Experiments on a large anomaly detection benchmark\n(ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art\ntransductive learning-based anomaly detection methods and ii) the efficacy of\nour synthetic dataset and fine-tuning strategy in aligning LLMs to this task.\n","authors":["Aodong Li","Yunhan Zhao","Chen Qiu","Marius Kloft","Padhraic Smyth","Maja Rudolph","Stephan Mandt"],"pdf_url":"https://arxiv.org/pdf/2406.16308v1.pdf","comment":"accepted at the Anomaly Detection with Foundation Models workshop"},{"id":"http://arxiv.org/abs/2406.16306v1","updated":"2024-06-24T04:08:35Z","published":"2024-06-24T04:08:35Z","title":"Cascade Reward Sampling for Efficient Decoding-Time Alignment","summary":"  Aligning large language models (LLMs) with human preferences is critical for\ntheir deployment. Recently, decoding-time alignment has emerged as an effective\nplug-and-play technique that requires no fine-tuning of model parameters.\nHowever, generating text that achieves both high reward and high likelihood\nremains a significant challenge. Existing methods often fail to generate\nhigh-reward text or incur substantial computational costs. In this paper, we\npropose Cascade Reward Sampling (CARDS) to address both issues, guaranteeing\nthe generation of high-reward and high-likelihood text with significantly low\ncosts. Based on our analysis of reward models (RMs) on incomplete text and our\nobservation that high-reward prefixes induce high-reward complete text, we use\nrejection sampling to iteratively generate small semantic segments to form such\nprefixes. The segment length is dynamically determined by the predictive\nuncertainty of LLMs. This strategy guarantees desirable prefixes for subsequent\ngenerations and significantly reduces wasteful token re-generations and the\nnumber of reward model scoring. Our experiments demonstrate substantial gains\nin both generation efficiency and alignment ratings compared to the baselines,\nachieving five times faster text generation and 99\\% win-ties in GPT-4/Claude-3\nhelpfulness evaluation.\n","authors":["Bolian Li","Yifan Wang","Ananth Grama","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16300v1","updated":"2024-06-24T03:53:30Z","published":"2024-06-24T03:53:30Z","title":"Landscaping Linear Mode Connectivity","summary":"  The presence of linear paths in parameter space between two different network\nsolutions in certain cases, i.e., linear mode connectivity (LMC), has garnered\ninterest from both theoretical and practical fronts. There has been significant\nresearch that either practically designs algorithms catered for connecting\nnetworks by adjusting for the permutation symmetries as well as some others\nthat more theoretically construct paths through which networks can be\nconnected. Yet, the core reasons for the occurrence of LMC, when in fact it\ndoes occur, in the highly non-convex loss landscapes of neural networks are far\nfrom clear. In this work, we take a step towards understanding it by providing\na model of how the loss landscape needs to behave topographically for LMC (or\nthe lack thereof) to manifest. Concretely, we present a `mountainside and\nridge' perspective that helps to neatly tie together different geometric\nfeatures that can be spotted in the loss landscape along the training runs. We\nalso complement this perspective by providing a theoretical analysis of the\nbarrier height, for which we provide empirical support, and which additionally\nextends as a faithful predictor of layer-wise LMC. We close with a toy example\nthat provides further intuition on how barriers arise in the first place, all\nin all, showcasing the larger aim of the work -- to provide a working model of\nthe landscape and its topography for the occurrence of LMC.\n","authors":["Sidak Pal Singh","Linara Adilova","Michael Kamp","Asja Fischer","Bernhard Schölkopf","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2406.16300v1.pdf","comment":"ICML 2024 HiLD workshop paper"},{"id":"http://arxiv.org/abs/2406.02081v2","updated":"2024-06-24T03:38:46Z","published":"2024-06-04T08:04:23Z","title":"FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement\n  Learning","summary":"  Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.\n","authors":["Wenzhe Li","Zihan Ding","Seth Karten","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2406.02081v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.16295v1","updated":"2024-06-24T03:37:51Z","published":"2024-06-24T03:37:51Z","title":"Relaxing Continuous Constraints of Equivariant Graph Neural Networks for\n  Physical Dynamics Learning","summary":"  Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive\nbiases into graph neural networks has improved their generalization ability and\ndata efficiency in unbounded physical dynamics modeling. However, in various\nscientific and engineering applications, the symmetries of dynamics are\nfrequently discrete due to the boundary conditions. Thus, existing GNNs either\noverlook necessary symmetry, resulting in suboptimal representation ability, or\nimpose excessive equivariance, which fails to generalize to unobserved\nsymmetric dynamics. In this work, we propose a general Discrete Equivariant\nGraph Neural Network (DEGNN) that guarantees equivariance to a given discrete\npoint group. Specifically, we show that such discrete equivariant message\npassing could be constructed by transforming geometric features into\npermutation-invariant embeddings. Through relaxing continuous equivariant\nconstraints, DEGNN can employ more geometric feature combinations to\napproximate unobserved physical object interaction functions. Two\nimplementation approaches of DEGNN are proposed based on ranking or pooling\npermutation-invariant functions. We apply DEGNN to various physical dynamics,\nranging from particle, molecular, crowd to vehicle dynamics. In twenty\nscenarios, DEGNN significantly outperforms existing state-of-the-art\napproaches. Moreover, we show that DEGNN is data efficient, learning with less\ndata, and can generalize across scenarios such as unobserved orientation.\n","authors":["Zinan Zheng","Yang Liu","Jia Li","Jianhua Yao","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2406.16295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11235v2","updated":"2024-06-24T03:34:02Z","published":"2024-02-17T09:52:43Z","title":"ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs","summary":"  With the development of foundation models such as large language models,\nzero-shot transfer learning has become increasingly significant. This is\nhighlighted by the generative capabilities of NLP models like GPT-4, and the\nretrieval-based approaches of CV models like CLIP, both of which effectively\nbridge the gap between seen and unseen data. In the realm of graph learning,\nthe continuous emergence of new graphs and the challenges of human labeling\nalso amplify the necessity for zero-shot transfer learning, driving the\nexploration of approaches that can generalize across diverse graph data without\nnecessitating dataset-specific and label-specific fine-tuning. In this study,\nwe extend such paradigms to zero-shot transferability in graphs by introducing\nZeroG, a new framework tailored to enable cross-dataset generalization.\nAddressing the inherent challenges such as feature misalignment, mismatched\nlabel spaces, and negative transfer, we leverage a language model to encode\nboth node attributes and class semantics, ensuring consistent feature\ndimensions across datasets. We also propose a prompt-based subgraph sampling\nmodule that enriches the semantic information and structure information of\nextracted subgraphs using prompting nodes and neighborhood aggregation,\nrespectively. We further adopt a lightweight fine-tuning strategy that reduces\nthe risk of overfitting and maintains the zero-shot learning efficacy of the\nlanguage model. The results underscore the effectiveness of our model in\nachieving significant cross-dataset zero-shot transferability, opening pathways\nfor the development of graph foundation models. Codes and data are available at\nhttps://github.com/NineAbyss/ZeroG.\n","authors":["Yuhan Li","Peisong Wang","Zhixun Li","Jeffrey Xu Yu","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2402.11235v2.pdf","comment":"Accepted by SIGKDD 2024, research track"},{"id":"http://arxiv.org/abs/2404.03876v2","updated":"2024-06-24T03:19:39Z","published":"2024-04-05T03:51:19Z","title":"Accurately Classifying Out-Of-Distribution Data in Facial Recognition","summary":"  Standard classification theory assumes that the distribution of images in the\ntest and training sets are identical. Unfortunately, real-life scenarios\ntypically feature unseen data (\"out-of-distribution data\") which is different\nfrom data in the training distribution(\"in-distribution\"). This issue is most\nprevalent in social justice problems where data from under-represented groups\nmay appear in the test data without representing an equal proportion of the\ntraining data. This may result in a model returning confidently wrong decisions\nand predictions. We are interested in the following question: Can the\nperformance of a neural network improve on facial images of out-of-distribution\ndata when it is trained simultaneously on multiple datasets of in-distribution\ndata? We approach this problem by incorporating the Outlier Exposure model and\ninvestigate how the model's performance changes when other datasets of facial\nimages were implemented. We observe that the accuracy and other metrics of the\nmodel can be increased by applying Outlier Exposure, incorporating a trainable\nweight parameter to increase the machine's emphasis on outlier images, and by\nre-weighting the importance of different class labels. We also experimented\nwith whether sorting the images and determining outliers via image features\nwould have more of an effect on the metrics than sorting by average pixel\nvalue. Our goal was to make models not only more accurate but also more fair by\nscanning a more expanded range of images. We also tested the datasets in\nreverse order to see whether a more fair dataset with balanced features has an\neffect on the model's accuracy.\n","authors":["Gianluca Barone","Aashrit Cunchala","Rudy Nunez"],"pdf_url":"https://arxiv.org/pdf/2404.03876v2.pdf","comment":"18 pages, 6 tables, 6 figures"}],"Robotics":[{"id":"http://arxiv.org/abs/2406.16862v1","updated":"2024-06-24T17:59:45Z","published":"2024-06-24T17:59:45Z","title":"Dreamitate: Real-World Visuomotor Policy Learning via Video Generation","summary":"  A key challenge in manipulation is learning a policy that can robustly\ngeneralize to diverse visual environments. A promising mechanism for learning\nrobust policies is to leverage video generative models, which are pretrained on\nlarge-scale datasets of internet videos. In this paper, we propose a visuomotor\npolicy learning framework that fine-tunes a video diffusion model on human\ndemonstrations of a given task. At test time, we generate an example of an\nexecution of the task conditioned on images of a novel scene, and use this\nsynthesized execution directly to control the robot. Our key insight is that\nusing common tools allows us to effortlessly bridge the embodiment gap between\nthe human hand and the robot manipulator. We evaluate our approach on four\ntasks of increasing complexity and demonstrate that harnessing internet-scale\ngenerative models allows the learned policy to achieve a significantly higher\ndegree of generalization than existing behavior cloning approaches.\n","authors":["Junbang Liang","Ruoshi Liu","Ege Ozguroglu","Sruthi Sudhakar","Achal Dave","Pavel Tokmakov","Shuran Song","Carl Vondrick"],"pdf_url":"https://arxiv.org/pdf/2406.16862v1.pdf","comment":"Project page: https://dreamitate.cs.columbia.edu/"},{"id":"http://arxiv.org/abs/2406.16850v1","updated":"2024-06-24T17:57:05Z","published":"2024-06-24T17:57:05Z","title":"From Perfect to Noisy World Simulation: Customizable Embodied\n  Multi-modal Perturbations for SLAM Robustness Benchmarking","summary":"  Embodied agents require robust navigation systems to operate in unstructured\nenvironments, making the robustness of Simultaneous Localization and Mapping\n(SLAM) models critical to embodied agent autonomy. While real-world datasets\nare invaluable, simulation-based benchmarks offer a scalable approach for\nrobustness evaluations. However, the creation of a challenging and controllable\nnoisy world with diverse perturbations remains under-explored. To this end, we\npropose a novel, customizable pipeline for noisy data synthesis, aimed at\nassessing the resilience of multi-modal SLAM models against various\nperturbations. The pipeline comprises a comprehensive taxonomy of sensor and\nmotion perturbations for embodied multi-modal (specifically RGB-D) sensing,\ncategorized by their sources and propagation order, allowing for procedural\ncomposition. We also provide a toolbox for synthesizing these perturbations,\nenabling the transformation of clean environments into challenging noisy\nsimulations. Utilizing the pipeline, we instantiate the large-scale\nNoisy-Replica benchmark, which includes diverse perturbation types, to evaluate\nthe risk tolerance of existing advanced RGB-D SLAM models. Our extensive\nanalysis uncovers the susceptibilities of both neural (NeRF and Gaussian\nSplatting -based) and non-neural SLAM models to disturbances, despite their\ndemonstrated accuracy in standard benchmarks. Our code is publicly available at\nhttps://github.com/Xiaohao-Xu/SLAM-under-Perturbation.\n","authors":["Xiaohao Xu","Tianyi Zhang","Sibo Wang","Xiang Li","Yongqi Chen","Ye Li","Bhiksha Raj","Matthew Johnson-Roberson","Xiaonan Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16850v1.pdf","comment":"50 pages. arXiv admin note: substantial text overlap with\n  arXiv:2402.08125"},{"id":"http://arxiv.org/abs/2406.16837v1","updated":"2024-06-24T17:45:52Z","published":"2024-06-24T17:45:52Z","title":"A Certifiable Algorithm for Simultaneous Shape Estimation and Object\n  Tracking","summary":"  Applications from manipulation to autonomous vehicles rely on robust and\ngeneral object tracking to safely perform tasks in dynamic environments. We\npropose the first certifiably optimal category-level approach for simultaneous\nshape estimation and pose tracking of an object of known category (e.g. a car).\nOur approach uses 3D semantic keypoint measurements extracted from an RGB-D\nimage sequence, and phrases the estimation as a fixed-lag smoothing problem.\nTemporal constraints enforce the object's rigidity (fixed shape) and smooth\nmotion according to a constant-twist motion model. The solutions to this\nproblem are the estimates of the object's state (poses, velocities) and shape\n(paramaterized according to the active shape model) over the smoothing horizon.\nOur key contribution is to show that despite the non-convexity of the fixed-lag\nsmoothing problem, we can solve it to certifiable optimality using a small-size\nsemidefinite relaxation. We also present a fast outlier rejection scheme that\nfilters out incorrect keypoint detections with shape and time compatibility\ntests, and wrap our certifiable solver in a graduated non-convexity scheme. We\nevaluate the proposed approach on synthetic and real data, showcasing its\nperformance in a table-top manipulation scenario and a drone-based vehicle\ntracking application.\n","authors":["Lorenzo Shaikewitz","Samuel Ubellacker","Luca Carlone"],"pdf_url":"https://arxiv.org/pdf/2406.16837v1.pdf","comment":"11 pages, 6 figures (with appendix). Code released at\n  https://github.com/MIT-SPARK/certifiable_tracking. Video available at\n  https://youtu.be/eTIlVD9pDtc"},{"id":"http://arxiv.org/abs/2402.09246v3","updated":"2024-06-24T16:06:50Z","published":"2024-02-14T15:34:38Z","title":"Who Plays First? Optimizing the Order of Play in Stackelberg Games with\n  Many Robots","summary":"  We consider the multi-agent spatial navigation problem of computing the\nsocially optimal order of play, i.e., the sequence in which the agents commit\nto their decisions, and its associated equilibrium in an N-player Stackelberg\ntrajectory game. We model this problem as a mixed-integer optimization problem\nover the space of all possible Stackelberg games associated with the order of\nplay's permutations. To solve the problem, we introduce Branch and Play (B&P),\nan efficient and exact algorithm that provably converges to a socially optimal\norder of play and its Stackelberg equilibrium. As a subroutine for B&P, we\nemploy and extend sequential trajectory planning, i.e., a popular multi-agent\ncontrol approach, to scalably compute valid local Stackelberg equilibria for\nany given order of play. We demonstrate the practical utility of B&P to\ncoordinate air traffic control, swarm formation, and delivery vehicle fleets.\nWe find that B&P consistently outperforms various baselines, and computes the\nsocially optimal equilibrium.\n","authors":["Haimin Hu","Gabriele Dragotto","Zixu Zhang","Kaiqu Liang","Bartolomeo Stellato","Jaime F. Fisac"],"pdf_url":"https://arxiv.org/pdf/2402.09246v3.pdf","comment":"Robotics: Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2311.01380v2","updated":"2024-06-24T15:39:13Z","published":"2023-11-02T16:37:27Z","title":"Sim2Real Bilevel Adaptation for Object Surface Classification using\n  Vision-Based Tactile Sensors","summary":"  In this paper, we address the Sim2Real gap in the field of vision-based\ntactile sensors for classifying object surfaces. We train a Diffusion Model to\nbridge this gap using a relatively small dataset of real-world images randomly\ncollected from unlabeled everyday objects via the DIGIT sensor. Subsequently,\nwe employ a simulator to generate images by uniformly sampling the surface of\nobjects from the YCB Model Set. These simulated images are then translated into\nthe real domain using the Diffusion Model and automatically labeled to train a\nclassifier. During this training, we further align features of the two domains\nusing an adversarial procedure. Our evaluation is conducted on a dataset of\ntactile images obtained from a set of ten 3D printed YCB objects. The results\nreveal a total accuracy of 81.9%, a significant improvement compared to the\n34.7% achieved by the classifier trained solely on simulated images. This\ndemonstrates the effectiveness of our approach. We further validate our\napproach using the classifier on a 6D object pose estimation task from tactile\ndata.\n","authors":["Gabriele M. Caddeo","Andrea Maracani","Paolo D. Alfano","Nicola A. Piga","Lorenzo Rosasco","Lorenzo Natale"],"pdf_url":"https://arxiv.org/pdf/2311.01380v2.pdf","comment":"6 pages, accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2406.16713v1","updated":"2024-06-24T15:15:25Z","published":"2024-06-24T15:15:25Z","title":"ShanghaiTech Mapping Robot is All You Need: Robot System for Collecting\n  Universal Ground Vehicle Datasets","summary":"  This paper presents the ShanghaiTech Mapping Robot, a state-of-the-art\nunmanned ground vehicle (UGV) designed for collecting comprehensive\nmulti-sensor datasets to support research in robotics, computer vision, and\nautonomous driving. The robot is equipped with a wide array of sensors\nincluding RGB cameras, RGB-D cameras, event-based cameras, IR cameras, LiDARs,\nmmWave radars, IMUs, ultrasonic range finders, and a GNSS RTK receiver. The\nsensor suite is integrated onto a specially designed mechanical structure with\na centralized power system and a synchronization mechanism to ensure spatial\nand temporal alignment of the sensor data. A 16-node on-board computing cluster\nhandles sensor control, data collection, and storage. We describe the hardware\nand software architecture of the robot in detail and discuss the calibration\nprocedures for the various sensors. The capabilities of the platform are\ndemonstrated through an extensive dataset collected in diverse real-world\nenvironments. To facilitate research, we make the dataset publicly available\nalong with the associated robot sensor calibration data. Performance\nevaluations on a set of standard perception and localization tasks showcase the\npotential of the dataset to support developments in Robot Autonomy.\n","authors":["Bowen Xu","Xiting Zhao","Delin Feng","Yuanyuan Yang","Sören Schwertfeger"],"pdf_url":"https://arxiv.org/pdf/2406.16713v1.pdf","comment":"Incomplete draft"},{"id":"http://arxiv.org/abs/2406.16679v1","updated":"2024-06-24T14:41:15Z","published":"2024-06-24T14:41:15Z","title":"Multi-Robot Collaborative Localization and Planning with Inter-Ranging","summary":"  Robots often use feature-based image tracking to identify their position in\ntheir surrounding environment; however, feature-based image tracking is prone\nto errors in low-textured and poorly lit environments. Specifically, we\ninvestigate a scenario where robots are tasked with exploring the surface of\nthe Moon and are required to have an accurate estimate of their position to be\nable to correctly geotag scientific measurements. To reduce localization error,\nwe complement traditional feature-based image tracking with ultra-wideband\n(UWB) distance measurements between the robots. The robots use an advanced\nmesh-ranging protocol that allows them to continuously share distance\nmeasurements amongst each other rather than relying on the common \"anchor\" and\n\"tag\" UWB architecture. We develop a decentralized multi-robot coordination\nalgorithm that actively plans paths based on measurement line-of-sight vectors\namongst all robots to minimize collective localization error. We then\ndemonstrate the emergent behavior of the proposed multi-robot coordination\nalgorithm both in simulation and hardware to lower a geometry-based uncertainty\nmetric and reduce localization error.\n","authors":["Derek Knowles","Adam Dai","Grace Gao"],"pdf_url":"https://arxiv.org/pdf/2406.16679v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2406.16671v1","updated":"2024-06-24T14:27:13Z","published":"2024-06-24T14:27:13Z","title":"STAR: Swarm Technology for Aerial Robotics Research","summary":"  In recent years, the field of aerial robotics has witnessed significant\nprogress, finding applications in diverse domains, including post-disaster\nsearch and rescue operations. Despite these strides, the prohibitive\nacquisition costs associated with deploying physical multi-UAV systems have\nposed challenges, impeding their widespread utilization in research endeavors.\nTo overcome these challenges, we present STAR (Swarm Technology for Aerial\nRobotics Research), a framework developed explicitly to improve the\naccessibility of aerial swarm research experiments. Our framework introduces a\nswarm architecture based on the Crazyflie, a low-cost, open-source, palm-sized\naerial platform, well suited for experimental swarm algorithms. To augment\ncost-effectiveness and mitigate the limitations of employing low-cost robots in\nexperiments, we propose a landmark-based localization module leveraging\nfiducial markers. This module, also serving as a target detection module,\nenhances the adaptability and versatility of the framework. Additionally,\ncollision and obstacle avoidance are implemented through velocity obstacles.\nThe presented work strives to bridge the gap between theoretical advances and\ntangible implementations, thus fostering progress in the field.\n","authors":["Jimmy Chiun","Yan Rui Tan","Yuhong Cao","John Tan","Guillaume Sartoretti"],"pdf_url":"https://arxiv.org/pdf/2406.16671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04004v3","updated":"2024-06-24T13:20:43Z","published":"2023-07-08T16:18:50Z","title":"MAP-NBV: Multi-agent Prediction-guided Next-Best-View Planning for\n  Active 3D Object Reconstruction","summary":"  Next-Best View (NBV) planning is a long-standing problem of determining where\nto obtain the next best view of an object from, by a robot that is viewing the\nobject. There are a number of methods for choosing NBV based on the observed\npart of the object. In this paper, we investigate how predicting the unobserved\npart helps with the efficiency of reconstructing the object. We present,\nMulti-Agent Prediction-Guided NBV (MAP-NBV), a decentralized coordination\nalgorithm for active 3D reconstruction with multi-agent systems.\nPrediction-based approaches have shown great improvement in active perception\ntasks by learning the cues about structures in the environment from data.\nHowever, these methods primarily focus on single-agent systems. We design a\ndecentralized next-best-view approach that utilizes geometric measures over the\npredictions and jointly optimizes the information gain and control effort for\nefficient collaborative 3D reconstruction of the object. Our method achieves\n19% improvement over the non-predictive multi-agent approach in simulations\nusing AirSim and ShapeNet. We make our code publicly available through our\nproject website: http://raaslab.org/projects/MAPNBV/.\n","authors":["Harnaik Dhami","Vishnu D. Sharma","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2307.04004v3.pdf","comment":"8 pages, 7 figures, 1 table. Submitted to IROS 2024"},{"id":"http://arxiv.org/abs/2406.16625v1","updated":"2024-06-24T13:17:32Z","published":"2024-06-24T13:17:32Z","title":"GATSBI: An Online GTSP-Based Algorithm for Targeted Surface Bridge\n  Inspection and Defect Detection","summary":"  We study the problem of visual surface inspection of infrastructure for\ndefects using an Unmanned Aerial Vehicle (UAV). We do not assume that the\ngeometric model of the infrastructure is known beforehand. Our planner, termed\nGATSBI, plans a path in a receding horizon fashion to inspect all points on the\nsurface of the infrastructure. The input to GATSBI consists of a 3D occupancy\nmap created online with 3D pointclouds. Occupied voxels corresponding to the\ninfrastructure in this map are semantically segmented and used to create an\ninfrastructure-only occupancy map. Inspecting an infrastructure voxel requires\nthe UAV to take images from a desired viewing angle and distance. We then\ncreate a Generalized Traveling Salesperson Problem (GTSP) instance to cluster\ncandidate viewpoints for inspecting the infrastructure voxels and use an\noff-the-shelf GTSP solver to find the optimal path for the given instance. As\nthe algorithm sees more parts of the environment over time, it replans the path\nto inspect uninspected parts of the infrastructure while avoiding obstacles. We\nevaluate the performance of our algorithm through high-fidelity simulations\nconducted in AirSim and real-world experiments. We compare the performance of\nGATSBI with a baseline inspection algorithm where the map is known a priori.\nOur evaluation reveals that targeting the inspection to only the segmented\ninfrastructure voxels and planning carefully using a GTSP solver leads to a\nmore efficient and thorough inspection than the baseline inspection algorithm.\n","authors":["Harnaik Dhami","Charith Reddy","Vishnu Dutt Sharma","Troi Williams","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2406.16625v1.pdf","comment":"10 pages, 12 figures, 2 tables. Submitted to IEEE TAES. arXiv admin\n  note: text overlap with arXiv:2012.04803"},{"id":"http://arxiv.org/abs/2406.16612v1","updated":"2024-06-24T12:52:17Z","published":"2024-06-24T12:52:17Z","title":"Towards Physically Talented Aerial Robots with Tactically Smart Swarm\n  Behavior thereof: An Efficient Co-design Approach","summary":"  The collective performance or capacity of collaborative autonomous systems\nsuch as a swarm of robots is jointly influenced by the morphology and the\nbehavior of individual systems in that collective. In that context, this paper\nexplores how morphology impacts the learned tactical behavior of unmanned\naerial/ground robots performing reconnaissance and search & rescue. This is\nachieved by presenting a computationally efficient framework to solve this\notherwise challenging problem of jointly optimizing the morphology and tactical\nbehavior of swarm robots. Key novel developments to this end include the use of\nphysical talent metrics and modification of graph reinforcement learning\narchitectures to allow joint learning of the swarm tactical policy and the\ntalent metrics (search speed, flight range, and cruising speed) that constrain\nmobility and object/victim search capabilities of the aerial robots executing\nthese tactics. Implementation of this co-design approach is supported by\nadvancements to an open-source Pybullet-based swarm simulator that allows the\nuse of variable aerial asset capabilities. The results of the co-design are\nobserved to outperform those of tactics learning with a fixed Pareto design,\nwhen compared in terms of mission performance metrics. Significant differences\nin morphology and learned behavior are also observed by comparing the baseline\ndesign and the co-design outcomes.\n","authors":["Prajit KrisshnaKumar","Steve Paul","Hemanth Manjunatha","Mary Corra","Ehsan Esfahani","Souma Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2406.16612v1.pdf","comment":"Accepted for presentation in proceedings of ASME IDETC-CIE 2024"},{"id":"http://arxiv.org/abs/2406.16578v1","updated":"2024-06-24T12:14:24Z","published":"2024-06-24T12:14:24Z","title":"QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds","summary":"  While pets offer companionship, their limited intelligence restricts advanced\nreasoning and autonomous interaction with humans. Considering this, we propose\nQuadrupedGPT, a versatile agent designed to master a broad range of complex\ntasks with agility comparable to that of a pet. To achieve this goal, the\nprimary challenges include: i) effectively leveraging multimodal observations\nfor decision-making; ii) mastering agile control of locomotion and path\nplanning; iii) developing advanced cognition to execute long-term objectives.\nQuadrupedGPT processes human command and environmental contexts using a large\nmultimodal model (LMM). Empowered by its extensive knowledge base, our agent\nautonomously assigns appropriate parameters for adaptive locomotion policies\nand guides the agent in planning a safe but efficient path towards the goal,\nutilizing semantic-aware terrain analysis. Moreover, QuadrupedGPT is equipped\nwith problem-solving capabilities that enable it to decompose long-term goals\ninto a sequence of executable subgoals through high-level reasoning. Extensive\nexperiments across various benchmarks confirm that QuadrupedGPT can adeptly\nhandle multiple tasks with intricate instructions, demonstrating a significant\nstep towards the versatile quadruped agents in open-ended worlds. Our website\nand codes can be found at https://quadruped-hub.github.io/Quadruped-GPT/.\n","authors":["Ye Wang","Yuting Mei","Sipeng Zheng","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.16578v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2404.14965v4","updated":"2024-06-24T11:53:02Z","published":"2024-04-23T12:20:14Z","title":"Vision Beyond Boundaries: An Initial Design Space of Domain-specific\n  Large Vision Models in Human-robot Interaction","summary":"  The emergence of large vision models (LVMs) is following in the footsteps of\nthe recent prosperity of Large Language Models (LLMs) in following years.\nHowever, there's a noticeable gap in structured research applying LVMs to\nhuman-robot interaction (HRI), despite extensive evidence supporting the\nefficacy of vision models in enhancing interactions between humans and robots.\nRecognizing the vast and anticipated potential, we introduce an initial design\nspace that incorporates domain-specific LVMs, chosen for their superior\nperformance over normal models. We delve into three primary dimensions: HRI\ncontexts, vision-based tasks, and specific domains. The empirical evaluation\nwas implemented among 15 experts across six evaluated metrics, showcasing the\nprimary efficacy in relevant decision-making scenarios. We explore the process\nof ideation and potential application scenarios, envisioning this design space\nas a foundational guideline for future HRI system design, emphasizing accurate\ndomain alignment and model selection.\n","authors":["Yuchong Zhang","Yong Ma","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2404.14965v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16376v1","updated":"2024-06-24T07:38:53Z","published":"2024-06-24T07:38:53Z","title":"Multi-Objective Global Path Planning for Lunar Exploration With a\n  Quadruped Robot","summary":"  In unstructured environments the best path is not always the shortest, but\nneeds to consider various objectives like energy efficiency, risk of failure or\nscientific outcome. This paper proposes a global planner, based on the A*\nalgorithm, capable of individually considering multiple layers of map data for\ndifferent cost objectives. We introduce weights between the objectives, which\ncan be adapted to achieve a variety of optimal paths. In order to find the best\nof these paths, a tool for statistical path analysis is presented. Our planner\nwas tested on exemplary lunar topographies to propose two trajectories for\nexploring the Aristarchus Plateau. The optimized paths significantly reduce the\nrisk of failure while yielding more scientific value compared to a manually\nplanned paths in the same area. The planner and analysis tool are made\nopen-source in order to simplify mission planning for planetary scientists.\n","authors":["Julia Richter","Hendrik Kolvenbach","Giorgio Valsecchi","Marco Hutter"],"pdf_url":"https://arxiv.org/pdf/2406.16376v1.pdf","comment":"8 pages, 19 figures, IEEE conference iSpaRo 2024"},{"id":"http://arxiv.org/abs/2406.16370v1","updated":"2024-06-24T07:24:22Z","published":"2024-06-24T07:24:22Z","title":"An Active Search Strategy with Multiple Unmanned Aerial Systems for\n  Multiple Targets","summary":"  The challenge of efficient target searching in vast natural environments has\ndriven the need for advanced multi-UAV active search strategies. This paper\nintroduces a novel method in which global and local information is adeptly\nmerged to avoid issues such as myopia and redundant back-and-forth movements.\nIn addition, a trajectory generation method is used to ensure the search\npattern within continuous space. To further optimize multi-agent cooperation,\nthe Voronoi partition technique is employed, ensuring a reduction in repetitive\nflight patterns and making the control of multiple agents in a decentralized\nway. Through a series of experiments, the evaluation and comparison results\ndemonstrate the efficiency of our approach in various environments. The primary\napplication of this innovative approach is demonstrated in the search for\nhorseshoe crabs within their wild habitats, showcasing its potential to\nrevolutionize ecological survey and conservation efforts.\n","authors":["Chuanxiang Gao","Xinyi Wang","Xi Chen","Ben M. Chen"],"pdf_url":"https://arxiv.org/pdf/2406.16370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16362v1","updated":"2024-06-24T07:09:18Z","published":"2024-06-24T07:09:18Z","title":"Open-Source Tool Based Framework for Automated Performance Evaluation of\n  an AD Function","summary":"  As automation in the field of automated driving (AD) progresses, ensuring the\nsafety and functionality of AD functions (ADFs) becomes crucial. Virtual\nscenario-based testing has emerged as a prevalent method for evaluating these\nsystems, allowing for a wider range of testing environments and reproducibility\nof results. This approach involves AD-equipped test vehicles operating within\npredefined scenarios to achieve specific driving objectives. To comprehensively\nassess the impact of road network properties on the performance of an ADF,\nvarying parameters such as intersection angle, curvature and lane width is\nessential. However, covering all potential scenarios is impractical,\nnecessitating the identification of feasible parameter ranges and automated\ngeneration of corresponding road networks for simulation. Automating the\nworkflow of road network generation, parameter variation, simulation, and\nevaluation leads to a comprehensive understanding of an ADF's behavior in\ndiverse road network conditions. This paper aims to investigate the influence\nof road network parameters on the performance of a prototypical ADF through\nvirtual scenario-based testing, ultimately advocating the importance of road\ntopology in assuring safety and reliability of ADFs.\n","authors":["Daniel Becker","Sanath Konthala","Lutz Eckstein"],"pdf_url":"https://arxiv.org/pdf/2406.16362v1.pdf","comment":"III. International Conference on Electrical, Computer and Energy\n  Technologies (ICECET 2023), 16 - 17 November 2023, Cape Town-South Africa"},{"id":"http://arxiv.org/abs/2404.03336v3","updated":"2024-06-24T06:38:05Z","published":"2024-04-04T10:04:44Z","title":"Scaling Population-Based Reinforcement Learning with GPU Accelerated\n  Simulation","summary":"  In recent years, deep reinforcement learning (RL) has shown its effectiveness\nin solving complex continuous control tasks like locomotion and dexterous\nmanipulation. However, this comes at the cost of an enormous amount of\nexperience required for training, exacerbated by the sensitivity of learning\nefficiency and the policy performance to hyperparameter selection, which often\nrequires numerous trials of time-consuming experiments. This work introduces a\nPopulation-Based Reinforcement Learning (PBRL) approach that exploits a\nGPU-accelerated physics simulator to enhance the exploration capabilities of RL\nby concurrently training multiple policies in parallel. The PBRL framework is\napplied to three state-of-the-art RL algorithms - PPO, SAC, and DDPG -\ndynamically adjusting hyperparameters based on the performance of learning\nagents. The experiments are performed on four challenging tasks in Isaac Gym -\nAnymal Terrain, Shadow Hand, Humanoid, Franka Nut Pick - by analyzing the\neffect of population size and mutation mechanisms for hyperparameters. The\nresults demonstrate that PBRL agents outperform non-evolutionary baseline\nagents across tasks essential for humanoid robots, such as bipedal locomotion,\nmanipulation, and grasping in unstructured environments. The trained agents are\nfinally deployed in the real world for the Franka Nut Pick manipulation task.\nTo our knowledge, this is the first sim-to-real attempt for successfully\ndeploying PBRL agents on real hardware. Code and videos of the learned policies\nare available on our project website (https://sites.google.com/view/pbrl).\n","authors":["Asad Ali Shahid","Yashraj Narang","Vincenzo Petrone","Enrico Ferrentino","Ankur Handa","Dieter Fox","Marco Pavone","Loris Roveda"],"pdf_url":"https://arxiv.org/pdf/2404.03336v3.pdf","comment":"Submitted for publication to IEEE-RAS 23rd International Conference\n  on Humanoid Robots"},{"id":"http://arxiv.org/abs/2404.09228v3","updated":"2024-06-24T03:42:28Z","published":"2024-04-14T12:15:21Z","title":"A Survey on Integration of Large Language Models with Intelligent Robots","summary":"  In recent years, the integration of large language models (LLMs) has\nrevolutionized the field of robotics, enabling robots to communicate,\nunderstand, and reason with human-like proficiency. This paper explores the\nmultifaceted impact of LLMs on robotics, addressing key challenges and\nopportunities for leveraging these models across various domains. By\ncategorizing and analyzing LLM applications within core robotics elements --\ncommunication, perception, planning, and control -- we aim to provide\nactionable insights for researchers seeking to integrate LLMs into their\nrobotic systems. Our investigation focuses on LLMs developed post-GPT-3.5,\nprimarily in text-based modalities while also considering multimodal approaches\nfor perception and control. We offer comprehensive guidelines and examples for\nprompt engineering, facilitating beginners' access to LLM-based robotics\nsolutions. Through tutorial-level examples and structured prompt construction,\nwe illustrate how LLM-guided enhancements can be seamlessly integrated into\nrobotics applications. This survey serves as a roadmap for researchers\nnavigating the evolving landscape of LLM-driven robotics, offering a\ncomprehensive overview and practical guidance for harnessing the power of\nlanguage models in robotics development.\n","authors":["Yeseung Kim","Dohyun Kim","Jieun Choi","Jisang Park","Nayoung Oh","Daehyung Park"],"pdf_url":"https://arxiv.org/pdf/2404.09228v3.pdf","comment":"24 pages, 1 figure, Accepted to Intelligent Service Robotics (ISR)"},{"id":"http://arxiv.org/abs/2406.16289v1","updated":"2024-06-24T03:30:20Z","published":"2024-06-24T03:30:20Z","title":"Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D\n  Street View Reconstruction","summary":"  Recently, Neural Radiance Fields (NeRF) achieved impressive results in novel\nview synthesis. Block-NeRF showed the capability of leveraging NeRF to build\nlarge city-scale models. For large-scale modeling, a mass of image data is\nnecessary. Collecting images from specially designed data-collection vehicles\ncan not support large-scale applications. How to acquire massive high-quality\ndata remains an opening problem. Noting that the automotive industry has a huge\namount of image data, crowd-sourcing is a convenient way for large-scale data\ncollection. In this paper, we present a crowd-sourced framework, which utilizes\nsubstantial data captured by production vehicles to reconstruct the scene with\nthe NeRF model. This approach solves the key problem of large-scale\nreconstruction, that is where the data comes from and how to use them. Firstly,\nthe crowd-sourced massive data is filtered to remove redundancy and keep a\nbalanced distribution in terms of time and space. Then a structure-from-motion\nmodule is performed to refine camera poses. Finally, images, as well as poses,\nare used to train the NeRF model in a certain block. We highlight that we\npresent a comprehensive framework that integrates multiple modules, including\ndata selection, sparse 3D reconstruction, sequence appearance embedding, depth\nsupervision of ground surface, and occlusion completion. The complete system is\ncapable of effectively processing and reconstructing high-quality 3D scenes\nfrom crowd-sourced data. Extensive quantitative and qualitative experiments\nwere conducted to validate the performance of our system. Moreover, we proposed\nan application, named first-view navigation, which leveraged the NeRF model to\ngenerate 3D street view and guide the driver with a synthesized video.\n","authors":["Tong Qin","Changze Li","Haoyang Ye","Shaowei Wan","Minzhen Li","Hongwei Liu","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2406.16289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16258v1","updated":"2024-06-24T01:51:09Z","published":"2024-06-24T01:51:09Z","title":"MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from\n  Intervention","summary":"  Aligning robot behavior with human preferences is crucial for deploying\nembodied AI agents in human-centered environments. A promising solution is\ninteractive imitation learning from human intervention, where a human expert\nobserves the policy's execution and provides interventions as feedback.\nHowever, existing methods often fail to utilize the prior policy efficiently to\nfacilitate learning, thus hindering sample efficiency. In this work, we\nintroduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning),\ndesigned for sample-efficient alignment from human intervention. Instead of\ninferring the complete human behavior characteristics, MEReQ infers a residual\nreward function that captures the discrepancy between the human expert's and\nthe prior policy's underlying reward functions. It then employs Residual\nQ-Learning (RQL) to align the policy with human preferences using this residual\nreward function. Extensive evaluations on simulated and real-world tasks\ndemonstrate that MEReQ achieves sample-efficient policy alignment from human\nintervention.\n","authors":["Yuxin Chen","Chen Tang","Chenran Li","Ran Tian","Peter Stone","Masayoshi Tomizuka","Wei Zhan"],"pdf_url":"https://arxiv.org/pdf/2406.16258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17180v1","updated":"2024-06-24T23:37:10Z","published":"2024-06-24T23:37:10Z","title":"CogExplore: Contextual Exploration with Language-Encoded Environment\n  Representations","summary":"  Integrating language models into robotic exploration frameworks improves\nperformance in unmapped environments by providing the ability to reason over\nsemantic groundings, contextual cues, and temporal states. The proposed method\nemploys large language models (GPT-3.5 and Claude Haiku) to reason over these\ncues and express that reasoning in terms of natural language, which can be used\nto inform future states. We are motivated by the context of search-and-rescue\napplications where efficient exploration is critical. We find that by\nleveraging natural language, semantics, and tracking temporal states, the\nproposed method greatly reduces exploration path distance and further exposes\nthe need for environment-dependent heuristics. Moreover, the method is highly\nrobust to a variety of environments and noisy vision detections, as shown with\na 100% success rate in a series of comprehensive experiments across three\ndifferent environments conducted in a custom simulation pipeline operating in\nUnreal Engine.\n","authors":["Harel Biggie","Patrick Cooper","Doncey Albin","Kristen Such","Christoffer Heckman"],"pdf_url":"https://arxiv.org/pdf/2406.17180v1.pdf","comment":"9 pages (22 with references and appendix), 12 figures (including 6 in\n  the appendix), 1 table"},{"id":"http://arxiv.org/abs/2406.17168v1","updated":"2024-06-24T23:02:18Z","published":"2024-06-24T23:02:18Z","title":"Reinforcement Learning via Auxiliary Task Distillation","summary":"  We present Reinforcement Learning via Auxiliary Task Distillation\n(AuxDistill), a new method that enables reinforcement learning (RL) to perform\nlong-horizon robot control problems by distilling behaviors from auxiliary RL\ntasks. AuxDistill achieves this by concurrently carrying out multi-task RL with\nauxiliary tasks, which are easier to learn and relevant to the main task. A\nweighted distillation loss transfers behaviors from these auxiliary tasks to\nsolve the main task. We demonstrate that AuxDistill can learn a\npixels-to-actions policy for a challenging multi-stage embodied object\nrearrangement task from the environment reward without demonstrations, a\nlearning curriculum, or pre-trained skills. AuxDistill achieves $2.3 \\times$\nhigher success than the previous state-of-the-art baseline in the Habitat\nObject Rearrangement benchmark and outperforms methods that use pre-trained\nskills and expert demonstrations.\n","authors":["Abhinav Narayan Harish","Larry Heck","Josiah P. Hanna","Zsolt Kira","Andrew Szot"],"pdf_url":"https://arxiv.org/pdf/2406.17168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17151v1","updated":"2024-06-24T21:45:15Z","published":"2024-06-24T21:45:15Z","title":"Socially Acceptable Bipedal Robot Navigation via Social Zonotope Network\n  Model Predictive Control","summary":"  This study addresses the challenge of social bipedal navigation in a dynamic,\nhuman-crowded environment, a research area largely underexplored in legged\nrobot navigation. We present a zonotope-based framework that couples prediction\nand motion planning for a bipedal ego-agent to account for bidirectional\ninfluence with the surrounding pedestrians. This framework incorporates a\nSocial Zonotope Network (SZN), a neural network that predicts future pedestrian\nreachable sets and plans future socially acceptable reachable set for the\nego-agent. SZN generates the reachable sets as zonotopes for efficient\nreachability-based planning, collision checking, and online uncertainty\nparameterization. Locomotion-specific losses are added to the SZN training\nprocess to adhere to the dynamic limits of the bipedal robot that are not\nexplicitly present in the human crowds data set. These loss functions enable\nthe SZN to generate locomotion paths that are more dynamically feasible for\nimproved tracking. SZN is integrated with a Model Predictive Controller\n(SZN-MPC) for footstep planning for our bipedal robot Digit. SZN-MPC solves for\ncollision-free trajectory by optimizing through SZN's gradients. and Our\nresults demonstrate the framework's effectiveness in producing a socially\nacceptable path, with consistent locomotion velocity, and optimality. The\nSZN-MPC framework is validated with extensive simulations and hardware\nexperiments.\n","authors":["Abdulaziz Shamsah","Krishanu Agarwal","Nigam Katta","Abirath Raju","Shreyas Kousik","Ye Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.17151v1.pdf","comment":"19 pages, 19 figures. arXiv admin note: text overlap with\n  arXiv:2403.16485, arXiv:2310.09969"},{"id":"http://arxiv.org/abs/2309.10893v2","updated":"2024-06-24T20:57:22Z","published":"2023-09-19T19:31:43Z","title":"Hamilton-Jacobi Reachability Analysis for Hybrid Systems with Controlled\n  and Forced Transitions","summary":"  Hybrid dynamical systems with nonlinear dynamics are one of the most general\nmodeling tools for representing robotic systems, especially contact-rich\nsystems. However, providing guarantees regarding the safety or performance of\nnonlinear hybrid systems remains a challenging problem because it requires\nsimultaneous reasoning about continuous state evolution and discrete mode\nswitching. In this work, we address this problem by extending classical\nHamilton-Jacobi (HJ) reachability analysis, a formal verification method for\ncontinuous-time nonlinear dynamical systems, to hybrid dynamical systems. We\ncharacterize the reachable sets for hybrid systems through a generalized value\nfunction defined over discrete and continuous states of the hybrid system. We\nalso provide a numerical algorithm to compute this value function and obtain\nthe reachable set. Our framework can compute reachable sets for hybrid systems\nconsisting of multiple discrete modes, each with its own set of nonlinear\ncontinuous dynamics, discrete transitions that can be directly commanded or\nforced by a discrete control input, while still accounting for control bounds\nand adversarial disturbances in the state evolution. Along with the reachable\nset, the proposed framework also provides an optimal continuous and discrete\ncontroller to ensure system safety. We demonstrate our framework in several\nsimulation case studies, as well as on a real-world testbed to solve the\noptimal mode planning problem for a quadruped with multiple gaits.\n","authors":["Javier Borquez","Shuang Peng","Yiyu Chen","Quan Nguyen","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2309.10893v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17136v1","updated":"2024-06-24T20:57:01Z","published":"2024-06-24T20:57:01Z","title":"Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the\n  Predictive Model of Sensor State Transition","summary":"  The flexible under-actuated musculoskeletal hand is superior in its\nadaptability and impact resistance. On the other hand, since the relationship\nbetween sensors and actuators cannot be uniquely determined, almost all its\ncontrols are based on feedforward controls. When grasping and using a tool, the\ncontact state of the hand gradually changes due to the inertia of the tool or\nimpact of action, and the initial contact state is hardly kept. In this study,\nwe propose a system that trains the predictive network of sensor state\ntransition using the actual robot sensor information, and keeps the initial\ncontact state by a feedback control using the network. We conduct experiments\nof hammer hitting, vacuuming, and brooming, and verify the effectiveness of\nthis study.\n","authors":["Kento Kawaharazuka","Kei Tsuzuki","Moritaka Onitsuka","Yuki Asano","Kei Okada","Koji Kawasaki","Masayuki Inaba"],"pdf_url":"https://arxiv.org/pdf/2406.17136v1.pdf","comment":"Accepted at ICRA2020"},{"id":"http://arxiv.org/abs/2406.17134v1","updated":"2024-06-24T20:52:28Z","published":"2024-06-24T20:52:28Z","title":"Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of\n  Intersensory Networks for State Estimation, Control, and Simulation of\n  Musculoskeletal Humanoids","summary":"  While the musculoskeletal humanoid has various biomimetic benefits, the\nmodeling of its complex structure is difficult, and many learning-based systems\nhave been developed so far. There are various methods, such as control methods\nusing acquired relationships between joints and muscles represented by a data\ntable or neural network, and state estimation methods using Extended Kalman\nFilter or table search. In this study, we construct a Musculoskeletal\nAutoEncoder representing the relationship among joint angles, muscle tensions,\nand muscle lengths, and propose a unified method of state estimation, control,\nand simulation of musculoskeletal humanoids using it. By updating the\nMusculoskeletal AutoEncoder online using the actual robot sensor information,\nwe can continuously conduct more accurate state estimation, control, and\nsimulation than before the online learning. We conducted several experiments\nusing the musculoskeletal humanoid Musashi, and verified the effectiveness of\nthis study.\n","authors":["Kento Kawaharazuka","Kei Tsuzuki","Moritaka Onitsuka","Yuki Asano","Kei Okada","Koji Kawasaki","Masayuki Inaba"],"pdf_url":"https://arxiv.org/pdf/2406.17134v1.pdf","comment":"Accepted at IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2406.17106v1","updated":"2024-06-24T19:47:13Z","published":"2024-06-24T19:47:13Z","title":"Purely vision-based collective movement of robots","summary":"  Collective movement inspired by animal groups promises inherited benefits for\nrobot swarms, such as enhanced sensing and efficiency. However, while animals\nmove in groups using only their local senses, robots often obey central control\nor use direct communication, introducing systemic weaknesses to the swarm. In\nthe hope of addressing such vulnerabilities, developing bio-inspired\ndecentralized swarms has been a major focus in recent decades. Yet, creating\nrobots that move efficiently together using only local sensory information\nremains an extraordinary challenge. In this work, we present a decentralized,\npurely vision-based swarm of terrestrial robots. Within this novel framework\nrobots achieve collisionless, polarized motion exclusively through minimal\nvisual interactions, computing everything on board based on their individual\ncamera streams, making central processing or direct communication obsolete.\nWith agent-based simulations, we further show that using this model, even with\na strictly limited field of view and within confined spaces, ordered group\nmotion can emerge, while also highlighting key limitations. Our results offer a\nmultitude of practical applications from hybrid societies coordinating\ncollective movement without any common communication protocol, to advanced,\ndecentralized vision-based robot swarms capable of diverse tasks in\never-changing environments.\n","authors":["David Mezey","Renaud Bastien","Yating Zheng","Neal McKee","David Stoll","Heiko Hamann","Pawel Romanczuk"],"pdf_url":"https://arxiv.org/pdf/2406.17106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17066v1","updated":"2024-06-24T18:33:45Z","published":"2024-06-24T18:33:45Z","title":"Tolerance of Reinforcement Learning Controllers against Deviations in\n  Cyber Physical Systems","summary":"  Cyber-physical systems (CPS) with reinforcement learning (RL)-based\ncontrollers are increasingly being deployed in complex physical environments\nsuch as autonomous vehicles, the Internet-of-Things(IoT), and smart cities. An\nimportant property of a CPS is tolerance; i.e., its ability to function safely\nunder possible disturbances and uncertainties in the actual operation. In this\npaper, we introduce a new, expressive notion of tolerance that describes how\nwell a controller is capable of satisfying a desired system requirement,\nspecified using Signal Temporal Logic (STL), under possible deviations in the\nsystem. Based on this definition, we propose a novel analysis problem, called\nthe tolerance falsification problem, which involves finding small deviations\nthat result in a violation of the given requirement. We present a novel,\ntwo-layer simulation-based analysis framework and a novel search heuristic for\nfinding small tolerance violations. To evaluate our approach, we construct a\nset of benchmark problems where system parameters can be configured to\nrepresent different types of uncertainties and disturbancesin the system. Our\nevaluation shows that our falsification approach and heuristic can effectively\nfind small tolerance violations.\n","authors":["Changjian Zhang","Parv Kapoor","Eunsuk Kang","Romulo Meira-Goes","David Garlan","Akila Ganlath","Shatadal Mishra","Nejib Ammar"],"pdf_url":"https://arxiv.org/pdf/2406.17066v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.07462"},{"id":"http://arxiv.org/abs/2402.15368v2","updated":"2024-06-24T18:27:35Z","published":"2024-02-23T15:02:44Z","title":"Safe Task Planning for Language-Instructed Multi-Robot Systems using\n  Conformal Prediction","summary":"  This paper addresses task planning problems for language-instructed robot\nteams. Tasks are expressed in natural language (NL), requiring the robots to\napply their capabilities at various locations and semantic objects. Several\nrecent works have addressed similar planning problems by leveraging pre-trained\nLarge Language Models (LLMs) to design effective multi-robot plans. However,\nthese approaches lack mission completion guarantees. To address this challenge,\nwe introduce a new decentralized LLM-based planner, called S-ATLAS for Safe\nplAnning for Teams of Language-instructed AgentS, that is capable of achieving\nuser-defined mission success rates. This is accomplished by leveraging\nconformal prediction (CP), a distribution-free uncertainty quantification tool\nin black-box models. CP allows the proposed multi-robot planner to reason about\nits inherent uncertainty in a decentralized fashion, enabling robots to make\nindividual decisions when they are sufficiently certain and seek help\notherwise. We show, both theoretically and empirically, that the proposed\nplanner can achieve user-specified task success rates while minimizing the\noverall number of help requests. We provide comparative experiments against\nrelated works showing that our method is significantly more computational\nefficient and achieves lower help rates. The advantage of our algorithm over\nbaselines becomes more pronounced with increasing robot team size.\n","authors":["Jun Wang","Guocheng He","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2402.15368v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.04803v4","updated":"2024-06-24T13:19:30Z","published":"2020-12-09T00:34:46Z","title":"GATSBI: An Online GTSP-Based Algorithm for Targeted Surface Bridge\n  Inspection","summary":"  We study the problem of visual surface inspection of a bridge for defects\nusing an Unmanned Aerial Vehicle (UAV). We do not assume that the geometric\nmodel of the bridge is known beforehand. Our planner, termed GATSBI, plans a\npath in a receding horizon fashion to inspect all points on the surface of the\nbridge. The input to GATSBI consists of a 3D occupancy map created online with\nLiDAR scans. Occupied voxels corresponding to the bridge in this map are\nsemantically segmented and used to create a bridge-only occupancy map.\nInspecting a bridge voxel requires the UAV to take images from a desired\nviewing angle and distance. We then create a Generalized Traveling Salesperson\nProblem (GTSP) instance to cluster candidate viewpoints for inspecting the\nbridge voxels and use an off-the-shelf GTSP solver to find the optimal path for\nthe given instance. As the algorithm sees more parts of the environment over\ntime, it replans the path to inspect novel parts of the bridge while avoiding\nobstacles. We evaluate the performance of our algorithm through high-fidelity\nsimulations conducted in AirSim and real-world experiments. We compare the\nperformance of GATSBI with a classical exploration algorithm. Our evaluation\nreveals that targeting the inspection to only the segmented bridge voxels and\nplanning carefully using a GTSP solver leads to a more efficient and thorough\ninspection than the baseline algorithm.\n","authors":["Harnaik Dhami","Kevin Yu","Troi Williams","Vineeth Vajipey","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2012.04803v4.pdf","comment":"8 pages, 12 figures, 2 tables. Accepted to ICUAS 2023"},{"id":"http://arxiv.org/abs/2202.12180v3","updated":"2024-06-24T08:08:33Z","published":"2022-02-24T16:26:23Z","title":"Quantum Deep Reinforcement Learning for Robot Navigation Tasks","summary":"  We utilize hybrid quantum deep reinforcement learning to learn navigation\ntasks for a simple, wheeled robot in simulated environments of increasing\ncomplexity. For this, we train parameterized quantum circuits (PQCs) with two\ndifferent encoding strategies in a hybrid quantum-classical setup as well as a\nclassical neural network baseline with the double deep Q network (DDQN)\nreinforcement learning algorithm. Quantum deep reinforcement learning (QDRL)\nhas previously been studied in several relatively simple benchmark\nenvironments, mainly from the OpenAI gym suite. However, scaling behavior and\napplicability of QDRL to more demanding tasks closer to real-world problems e.\ng., from the robotics domain, have not been studied previously. Here, we show\nthat quantum circuits in hybrid quantum-classic reinforcement learning setups\nare capable of learning optimal policies in multiple robotic navigation\nscenarios with notably fewer trainable parameters compared to a classical\nbaseline. Across a large number of experimental configurations, we find that\nthe employed quantum circuits outperform the classical neural network baselines\nwhen equating for the number of trainable parameters. Yet, the classical neural\nnetwork consistently showed better results concerning training times and\nstability, with at least one order of magnitude of trainable parameters more\nthan the best-performing quantum circuits. However, validating the robustness\nof the learning methods in a large and dynamic environment, we find that the\nclassical baseline produces more stable and better performing policies overall.\n","authors":["Hans Hohenfeld","Dirk Heimann","Felix Wiebe","Frank Kirchner"],"pdf_url":"https://arxiv.org/pdf/2202.12180v3.pdf","comment":"22 pages, 14 figure. Accepeted for publication in IEEE Access"}]},"2024-06-23T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2310.02905v3","updated":"2024-06-23T23:59:53Z","published":"2023-10-02T02:01:16Z","title":"Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural\n  bandits Coupled with Transformers","summary":"  Large language models (LLMs) have shown remarkable instruction-following\ncapabilities and achieved impressive performances in various applications.\nHowever, the performances of LLMs depend heavily on the instructions given to\nthem, which are typically manually tuned with substantial human efforts. Recent\nwork has used the query-efficient Bayesian optimization (BO) algorithm to\nautomatically optimize the instructions given to black-box LLMs. However, BO\nusually falls short when optimizing highly sophisticated (e.g.,\nhigh-dimensional) objective functions, such as the functions mapping an\ninstruction to the performance of an LLM. This is mainly due to the limited\nexpressive power of the Gaussian process (GP) which is used by BO as a\nsurrogate to model the objective function. Meanwhile, it has been repeatedly\nshown that neural networks (NNs), especially pre-trained transformers, possess\nstrong expressive power and can model highly complex functions. So, we adopt a\nneural bandit algorithm which replaces the GP in BO by an NN surrogate to\noptimize instructions for black-box LLMs. More importantly, the neural bandit\nalgorithm allows us to naturally couple the NN surrogate with the hidden\nrepresentation learned by a pre-trained transformer (i.e., an open-source LLM),\nwhich significantly boosts its performance. These motivate us to propose our\nINSTruction optimization usIng Neural bandits Coupled with Transformers\n(INSTINCT) algorithm. We perform instruction optimization for ChatGPT and use\nextensive experiments to show that INSTINCT consistently outperforms baselines\nin different tasks, e.g., various instruction induction tasks and the task of\nimproving zero-shot chain-of-thought instructions. Our code is available at\nhttps://github.com/xqlin98/INSTINCT.\n","authors":["Xiaoqiang Lin","Zhaoxuan Wu","Zhongxiang Dai","Wenyang Hu","Yao Shu","See-Kiong Ng","Patrick Jaillet","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2310.02905v3.pdf","comment":"Accepted to ICML 2024"},{"id":"http://arxiv.org/abs/2406.08929v2","updated":"2024-06-23T23:18:07Z","published":"2024-06-13T08:58:45Z","title":"Step-by-Step Diffusion: An Elementary Tutorial","summary":"  We present an accessible first course on diffusion models and flow matching\nfor machine learning, aimed at a technical audience with no diffusion\nexperience. We try to simplify the mathematical details as much as possible\n(sometimes heuristically), while retaining enough precision to derive correct\nalgorithms.\n","authors":["Preetum Nakkiran","Arwen Bradley","Hattie Zhou","Madhu Advani"],"pdf_url":"https://arxiv.org/pdf/2406.08929v2.pdf","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.05080v2","updated":"2024-06-23T22:58:46Z","published":"2024-06-07T16:52:57Z","title":"I2EDL: Interactive Instruction Error Detection and Localization","summary":"  In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)\ntask, the human user guides an autonomous agent to reach a target goal via a\nseries of low-level actions following a textual instruction in natural\nlanguage. However, most existing methods do not address the likely case where\nusers may make mistakes when providing such instruction (e.g. \"turn left\"\ninstead of \"turn right\"). In this work, we address a novel task of Interactive\nVLN in Continuous Environments (IVLN-CE), which allows the agent to interact\nwith the user during the VLN-CE navigation to verify any doubts regarding the\ninstruction errors. We propose an Interactive Instruction Error Detector and\nLocalizer (I2EDL) that triggers the user-agent interaction upon the detection\nof instruction errors during the navigation. We leverage a pre-trained module\nto detect instruction errors and pinpoint them in the instruction by\ncross-referencing the textual input and past observations. In such way, the\nagent is able to query the user for a timely correction, without demanding the\nuser's cognitive load, as we locate the probable errors to a precise part of\nthe instruction. We evaluate the proposed I2EDL on a dataset of instructions\ncontaining errors, and further devise a novel metric, the Success weighted by\nInteraction Number (SIN), to reflect both the navigation performance and the\ninteraction effectiveness. We show how the proposed method can ask focused\nrequests for corrections to the user, which in turn increases the navigation\nsuccess, while minimizing the interactions.\n","authors":["Francesco Taioli","Stefano Rosa","Alberto Castellini","Lorenzo Natale","Alessio Del Bue","Alessandro Farinelli","Marco Cristani","Yiming Wang"],"pdf_url":"https://arxiv.org/pdf/2406.05080v2.pdf","comment":"Accepted at IEEE RO-MAN 2024"},{"id":"http://arxiv.org/abs/2406.16235v1","updated":"2024-06-23T22:53:47Z","published":"2024-06-23T22:53:47Z","title":"Preference Tuning For Toxicity Mitigation Generalizes Across Languages","summary":"  Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.\n","authors":["Xiaochen Li","Zheng-Xin Yong","Stephen H. Bach"],"pdf_url":"https://arxiv.org/pdf/2406.16235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16232v1","updated":"2024-06-23T22:06:25Z","published":"2024-06-23T22:06:25Z","title":"Jacobian Descent for Multi-Objective Optimization","summary":"  Many optimization problems are inherently multi-objective. To address them,\nwe formalize Jacobian descent (JD), a direct generalization of gradient descent\nfor vector-valued functions. Each step of this algorithm relies on a Jacobian\nmatrix consisting of one gradient per objective. The aggregator, responsible\nfor reducing this matrix into an update vector, characterizes JD. While the\nmulti-task learning literature already contains a variety of aggregators, they\noften lack some natural properties. In particular, the update should not\nconflict with any objective and should scale proportionally to the norm of each\ngradient. We propose a new aggregator specifically designed to satisfy this.\nEmphasizing conflict between objectives, we then highlight direct applications\nfor our methods. Most notably, we introduce instance-wise risk minimization\n(IWRM), a learning paradigm in which the loss of each training example is\nconsidered a separate objective. On simple image classification tasks, IWRM\nexhibits promising results compared to the direct minimization of the average\nloss. The performance of our aggregator in those experiments also corroborates\nour theoretical findings. Lastly, as speed is the main limitation of JD, we\nprovide a path towards a more efficient implementation.\n","authors":["Pierre Quinton","Valérian Rey"],"pdf_url":"https://arxiv.org/pdf/2406.16232v1.pdf","comment":"39 pages, 10 figures, conference"},{"id":"http://arxiv.org/abs/2406.16231v1","updated":"2024-06-23T22:05:52Z","published":"2024-06-23T22:05:52Z","title":"Gradual Divergence for Seamless Adaptation: A Novel Domain Incremental\n  Learning Method","summary":"  Domain incremental learning (DIL) poses a significant challenge in real-world\nscenarios, as models need to be sequentially trained on diverse domains over\ntime, all the while avoiding catastrophic forgetting. Mitigating representation\ndrift, which refers to the phenomenon of learned representations undergoing\nchanges as the model adapts to new tasks, can help alleviate catastrophic\nforgetting. In this study, we propose a novel DIL method named DARE, featuring\na three-stage training process: Divergence, Adaptation, and REfinement. This\nprocess gradually adapts the representations associated with new tasks into the\nfeature space spanned by samples from previous tasks, simultaneously\nintegrating task-specific decision boundaries. Additionally, we introduce a\nnovel strategy for buffer sampling and demonstrate the effectiveness of our\nproposed method, combined with this sampling strategy, in reducing\nrepresentation drift within the feature encoder. This contribution effectively\nalleviates catastrophic forgetting across multiple DIL benchmarks. Furthermore,\nour approach prevents sudden representation drift at task boundaries, resulting\nin a well-calibrated DIL model that maintains the performance on previous\ntasks.\n","authors":["Kishaan Jeeveswaran","Elahe Arani","Bahram Zonooz"],"pdf_url":"https://arxiv.org/pdf/2406.16231v1.pdf","comment":"Accepted at 41st International Conference on Machine Learning (ICML\n  2024)"},{"id":"http://arxiv.org/abs/2406.16224v1","updated":"2024-06-23T21:32:57Z","published":"2024-06-23T21:32:57Z","title":"From Text to Test: AI-Generated Control Software for Materials Science\n  Instruments","summary":"  Large language models (LLMs) are transforming the landscape of chemistry and\nmaterials science. Recent examples of LLM-accelerated experimental research\ninclude virtual assistants for parsing synthesis recipes from the literature,\nor using the extracted knowledge to guide synthesis and characterization.\nDespite these advancements, their application is constrained to labs with\nautomated instruments and control software, leaving much of materials science\nreliant on manual processes. Here, we demonstrate the rapid deployment of a\nPython-based control module for a Keithley 2400 electrical source measure unit\nusing ChatGPT-4. Through iterative refinement, we achieved effective instrument\nmanagement with minimal human intervention. Additionally, a user-friendly\ngraphical user interface (GUI) was created, effectively linking all instrument\ncontrols to interactive screen elements. Finally, we integrated this AI-crafted\ninstrument control software with a high-performance stochastic optimization\nalgorithm to facilitate rapid and automated extraction of electronic device\nparameters related to semiconductor charge transport mechanisms from\ncurrent-voltage (IV) measurement data. This integration resulted in a\ncomprehensive open-source toolkit for semiconductor device characterization and\nanalysis using IV curve measurements. We demonstrate the application of these\ntools by acquiring, analyzing, and parameterizing IV data from a\nPt/Cr<sub>2</sub>O<sub>3</sub>/\\b{eta}-Ga<sub>2</sub>O<sub>3</sub>\nheterojunction diode, a novel stack for high-power and high-temperature\nelectronic devices. This approach underscores the powerful synergy between LLMs\nand the development of instruments for scientific inquiry, showcasing a path\nfor further acceleration in materials science.\n","authors":["Davi M Fébba","Kingsley Egbo","William A. Callahan","Andriy Zakutayev"],"pdf_url":"https://arxiv.org/pdf/2406.16224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16223v1","updated":"2024-06-23T21:32:15Z","published":"2024-06-23T21:32:15Z","title":"Continuous Output Personality Detection Models via Mixed Strategy\n  Training","summary":"  The traditional personality models only yield binary results. This paper\npresents a novel approach for training personality detection models that\nproduce continuous output values, using mixed strategies. By leveraging the\nPANDORA dataset, which includes extensive personality labeling of Reddit\ncomments, we developed models that predict the Big Five personality traits with\nhigh accuracy. Our approach involves fine-tuning a RoBERTa-base model with\nvarious strategies such as Multi-Layer Perceptron (MLP) integration, and\nhyperparameter tuning. The results demonstrate that our models significantly\noutperform traditional binary classification methods, offering precise\ncontinuous outputs for personality traits, thus enhancing applications in AI,\npsychology, human resources, marketing and health care fields.\n","authors":["Rong Wang","Kun Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16221v1","updated":"2024-06-23T21:28:50Z","published":"2024-06-23T21:28:50Z","title":"F-FOMAML: GNN-Enhanced Meta-Learning for Peak Period Demand Forecasting\n  with Proxy Data","summary":"  Demand prediction is a crucial task for e-commerce and physical retail\nbusinesses, especially during high-stake sales events. However, the limited\navailability of historical data from these peak periods poses a significant\nchallenge for traditional forecasting methods. In this paper, we propose a\nnovel approach that leverages strategically chosen proxy data reflective of\npotential sales patterns from similar entities during non-peak periods,\nenriched by features learned from a graph neural networks (GNNs)-based\nforecasting model, to predict demand during peak events. We formulate the\ndemand prediction as a meta-learning problem and develop the Feature-based\nFirst-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages\nproxy data from non-peak periods and GNN-generated relational metadata to learn\nfeature-specific layer parameters, thereby adapting to demand forecasts for\npeak events. Theoretically, we show that by considering domain similarities\nthrough task-specific metadata, our model achieves improved generalization,\nwhere the excess risk decreases as the number of training tasks increases.\nEmpirical evaluations on large-scale industrial datasets demonstrate the\nsuperiority of our approach. Compared to existing state-of-the-art models, our\nmethod demonstrates a notable improvement in demand prediction accuracy,\nreducing the Mean Absolute Error by 26.24% on an internal vending machine\ndataset and by 1.04% on the publicly accessible JD.com dataset.\n","authors":["Zexing Xu","Linjun Zhang","Sitan Yang","Rasoul Etesami","Hanghang Tong","Huan Zhang","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2406.16221v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2312.03626v2","updated":"2024-06-23T23:50:59Z","published":"2023-12-06T17:13:15Z","title":"TokenCompose: Text-to-Image Diffusion with Token-level Supervision","summary":"  We present TokenCompose, a Latent Diffusion Model for text-to-image\ngeneration that achieves enhanced consistency between user-specified text\nprompts and model-generated images. Despite its tremendous success, the\nstandard denoising process in the Latent Diffusion Model takes text prompts as\nconditions only, absent explicit constraint for the consistency between the\ntext prompts and the image contents, leading to unsatisfactory results for\ncomposing multiple object categories. TokenCompose aims to improve\nmulti-category instance composition by introducing the token-wise consistency\nterms between the image content and object segmentation maps in the finetuning\nstage. TokenCompose can be applied directly to the existing training pipeline\nof text-conditioned diffusion models without extra human labeling information.\nBy finetuning Stable Diffusion, the model exhibits significant improvements in\nmulti-category instance composition and enhanced photorealism for its generated\nimages. Project link: https://mlpc-ucsd.github.io/TokenCompose\n","authors":["Zirui Wang","Zhizhou Sha","Zheng Ding","Yilin Wang","Zhuowen Tu"],"pdf_url":"https://arxiv.org/pdf/2312.03626v2.pdf","comment":"CVPR 2024, 21 pages, 17 figures"},{"id":"http://arxiv.org/abs/2406.08929v2","updated":"2024-06-23T23:18:07Z","published":"2024-06-13T08:58:45Z","title":"Step-by-Step Diffusion: An Elementary Tutorial","summary":"  We present an accessible first course on diffusion models and flow matching\nfor machine learning, aimed at a technical audience with no diffusion\nexperience. We try to simplify the mathematical details as much as possible\n(sometimes heuristically), while retaining enough precision to derive correct\nalgorithms.\n","authors":["Preetum Nakkiran","Arwen Bradley","Hattie Zhou","Madhu Advani"],"pdf_url":"https://arxiv.org/pdf/2406.08929v2.pdf","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.16231v1","updated":"2024-06-23T22:05:52Z","published":"2024-06-23T22:05:52Z","title":"Gradual Divergence for Seamless Adaptation: A Novel Domain Incremental\n  Learning Method","summary":"  Domain incremental learning (DIL) poses a significant challenge in real-world\nscenarios, as models need to be sequentially trained on diverse domains over\ntime, all the while avoiding catastrophic forgetting. Mitigating representation\ndrift, which refers to the phenomenon of learned representations undergoing\nchanges as the model adapts to new tasks, can help alleviate catastrophic\nforgetting. In this study, we propose a novel DIL method named DARE, featuring\na three-stage training process: Divergence, Adaptation, and REfinement. This\nprocess gradually adapts the representations associated with new tasks into the\nfeature space spanned by samples from previous tasks, simultaneously\nintegrating task-specific decision boundaries. Additionally, we introduce a\nnovel strategy for buffer sampling and demonstrate the effectiveness of our\nproposed method, combined with this sampling strategy, in reducing\nrepresentation drift within the feature encoder. This contribution effectively\nalleviates catastrophic forgetting across multiple DIL benchmarks. Furthermore,\nour approach prevents sudden representation drift at task boundaries, resulting\nin a well-calibrated DIL model that maintains the performance on previous\ntasks.\n","authors":["Kishaan Jeeveswaran","Elahe Arani","Bahram Zonooz"],"pdf_url":"https://arxiv.org/pdf/2406.16231v1.pdf","comment":"Accepted at 41st International Conference on Machine Learning (ICML\n  2024)"},{"id":"http://arxiv.org/abs/2406.07741v2","updated":"2024-06-23T21:54:26Z","published":"2024-06-11T21:55:20Z","title":"Back to the Color: Learning Depth to Specific Color Transformation for\n  Unsupervised Depth Estimation","summary":"  Virtual engines have the capability to generate dense depth maps for various\nsynthetic scenes, making them invaluable for training depth estimation models.\nHowever, synthetic colors often exhibit significant discrepancies compared to\nreal-world colors, thereby posing challenges for depth estimation in real-world\nscenes, particularly in complex and uncertain environments encountered in\nunsupervised monocular depth estimation tasks. To address this issue, we\npropose Back2Color, a framework that predicts realistic colors from depth\nutilizing a model trained on real-world data, thus facilitating the\ntransformation of synthetic colors into real-world counterparts. Additionally,\nby employing the Syn-Real CutMix method for joint training with both real-world\nunsupervised and synthetic supervised depth samples, we achieve improved\nperformance in monocular depth estimation for real-world scenes. Moreover, to\ncomprehensively address the impact of non-rigid motions on depth estimation, we\npropose an auto-learning uncertainty temporal-spatial fusion method\n(Auto-UTSF), which integrates the benefits of unsupervised learning in both\ntemporal and spatial dimensions. Furthermore, we design a depth estimation\nnetwork (VADepth) based on the Vision Attention Network. Our Back2Color\nframework demonstrates state-of-the-art performance, as evidenced by\nimprovements in performance metrics and the production of fine-grained details\nin our predictions, particularly on challenging datasets such as Cityscapes for\nunsupervised depth estimation.\n","authors":["Yufan Zhu","Chongzhi Ran","Mingtao Feng","Weisheng Dong","Antonio M. López","Guangming Shi"],"pdf_url":"https://arxiv.org/pdf/2406.07741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16220v1","updated":"2024-06-23T21:25:06Z","published":"2024-06-23T21:25:06Z","title":"Learning Run-time Safety Monitors for Machine Learning Components","summary":"  For machine learning components used as part of autonomous systems (AS) in\ncarrying out critical tasks it is crucial that assurance of the models can be\nmaintained in the face of post-deployment changes (such as changes in the\noperating environment of the system). A critical part of this is to be able to\nmonitor when the performance of the model at runtime (as a result of changes)\nposes a safety risk to the system. This is a particularly difficult challenge\nwhen ground truth is unavailable at runtime. In this paper we introduce a\nprocess for creating safety monitors for ML components through the use of\ndegraded datasets and machine learning. The safety monitor that is created is\ndeployed to the AS in parallel to the ML component to provide a prediction of\nthe safety risk associated with the model output. We demonstrate the viability\nof our approach through some initial experiments using publicly available speed\nsign datasets.\n","authors":["Ozan Vardal","Richard Hawkins","Colin Paterson","Chiara Picardi","Daniel Omeiza","Lars Kunze","Ibrahim Habli"],"pdf_url":"https://arxiv.org/pdf/2406.16220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08477v2","updated":"2024-06-23T20:51:21Z","published":"2024-03-13T12:46:03Z","title":"Unleashing the Power of Meta-tuning for Few-shot Generalization Through\n  Sparse Interpolated Experts","summary":"  Recent successes suggest that parameter-efficient fine-tuning of foundation\nmodels as the state-of-the-art method for transfer learning in vision,\nreplacing the rich literature of alternatives such as meta-learning. In trying\nto harness the best of both worlds, meta-tuning introduces a subsequent\noptimization stage of foundation models but has so far only shown limited\nsuccess and crucially tends to underperform on out-of-distribution (OOD) tasks.\nIn this paper, we introduce Sparse MetA-Tuning (SMAT), a method inspired by\nsparse mixture-of-experts approaches and trained to isolate subsets of\npre-trained parameters automatically for meta-tuning on each task. SMAT\nsuccessfully overcomes OOD sensitivity and delivers on the promise of enhancing\nthe transfer abilities of vision foundation models beyond parameter-efficient\nfine-tuning. We establish new state-of-the-art results on a challenging\ncombination of Meta-Dataset augmented with additional OOD tasks in both\nzero-shot and gradient-based adaptation settings. In addition, we provide a\nthorough analysis of the superiority of learned over hand-designed sparsity\npatterns for sparse expert methods and the pivotal importance of the sparsity\nlevel in balancing between in-distribution and out-of-distribution\ngeneralization. Our code is publicly available.\n","authors":["Shengzhuang Chen","Jihoon Tack","Yunqiao Yang","Yee Whye Teh","Jonathan Richard Schwarz","Ying Wei"],"pdf_url":"https://arxiv.org/pdf/2403.08477v2.pdf","comment":"The Forty-first International Conference on Machine Learning, 2024"},{"id":"http://arxiv.org/abs/2406.16204v1","updated":"2024-06-23T20:00:20Z","published":"2024-06-23T20:00:20Z","title":"Breaking the Frame: Image Retrieval by Visual Overlap Prediction","summary":"  We propose a novel visual place recognition approach, VOP, that efficiently\naddresses occlusions and complex scenes by shifting from traditional reliance\non global image similarities and local features to image overlap prediction.\nThe proposed method enables the identification of visible image sections\nwithout requiring expensive feature detection and matching. By focusing on\nobtaining patch-level embeddings by a Vision Transformer backbone and\nestablishing patch-to-patch correspondences, our approach uses a voting\nmechanism to assess overlap scores for potential database images, thereby\nproviding a nuanced image retrieval metric in challenging scenarios. VOP leads\nto more accurate relative pose estimation and localization results on the\nretrieved image pairs than state-of-the-art baselines on a number of\nlarge-scale, real-world datasets. The code is available at\nhttps://github.com/weitong8591/vop.\n","authors":["Tong Wei","Philipp Lindenberger","Jiri Matas","Daniel Barath"],"pdf_url":"https://arxiv.org/pdf/2406.16204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00736v3","updated":"2024-06-23T19:32:56Z","published":"2024-01-01T12:25:57Z","title":"Diffusion Models, Image Super-Resolution And Everything: A Survey","summary":"  Diffusion Models (DMs) have disrupted the image Super-Resolution (SR) field\nand further closed the gap between image quality and human perceptual\npreferences. They are easy to train and can produce very high-quality samples\nthat exceed the realism of those produced by previous generative methods.\nDespite their promising results, they also come with new challenges that need\nfurther research: high computational demands, comparability, lack of\nexplainability, color shifts, and more. Unfortunately, entry into this field is\noverwhelming because of the abundance of publications. To address this, we\nprovide a unified recount of the theoretical foundations underlying DMs applied\nto image SR and offer a detailed analysis that underscores the unique\ncharacteristics and methodologies within this domain, distinct from broader\nexisting reviews in the field. This survey articulates a cohesive understanding\nof DM principles and explores current research avenues, including alternative\ninput domains, conditioning techniques, guidance mechanisms, corruption spaces,\nand zero-shot learning approaches. By offering a detailed examination of the\nevolution and current trends in image SR through the lens of DMs, this survey\nsheds light on the existing challenges and charts potential future directions,\naiming to inspire further innovation in this rapidly advancing area.\n","authors":["Brian B. Moser","Arundhati S. Shanbhag","Federico Raue","Stanislav Frolov","Sebastian Palacio","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2401.00736v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12834v2","updated":"2024-06-23T19:10:29Z","published":"2024-06-18T17:54:17Z","title":"GroPrompt: Efficient Grounded Prompting and Adaptation for Referring\n  Video Object Segmentation","summary":"  Referring Video Object Segmentation (RVOS) aims to segment the object\nreferred to by the query sentence throughout the entire video. Most existing\nmethods require end-to-end training with dense mask annotations, which could be\ncomputation-consuming and less scalable. In this work, we aim to efficiently\nadapt foundation segmentation models for addressing RVOS from weak supervision\nwith the proposed Grounded Prompting (GroPrompt) framework. More specifically,\nwe propose Text-Aware Prompt Contrastive Learning (TAP-CL) to enhance the\nassociation between the position prompts and the referring sentences with only\nbox supervisions, including Text-Contrastive Prompt Learning (TextCon) and\nModality-Contrastive Prompt Learning (ModalCon) at frame level and video level,\nrespectively. With the proposed TAP-CL, our GroPrompt framework can generate\ntemporal-consistent yet text-aware position prompts describing locations and\nmovements for the referred object from the video. The experimental results in\nthe standard RVOS benchmarks (Ref-YouTube-VOS, Ref-DAVIS17, A2D-Sentences, and\nJHMDB-Sentences) demonstrate the competitive performance of our proposed\nGroPrompt framework given only bounding box weak supervisions.\n","authors":["Ci-Siang Lin","I-Jieh Liu","Min-Hung Chen","Chien-Yi Wang","Sifei Liu","Yu-Chiang Frank Wang"],"pdf_url":"https://arxiv.org/pdf/2406.12834v2.pdf","comment":"CVPR Workshop (CVinW) 2024. Project page:\n  https://jack24658735.github.io/groprompt/"},{"id":"http://arxiv.org/abs/2406.16192v1","updated":"2024-06-23T19:04:13Z","published":"2024-06-23T19:04:13Z","title":"HEST-1k: A Dataset for Spatial Transcriptomics and Histology Image\n  Analysis","summary":"  Spatial transcriptomics (ST) enables interrogating the molecular composition\nof tissue with ever-increasing resolution, depth, and sensitivity. However,\ncosts, rapidly evolving technology, and lack of standards have constrained\ncomputational methods in ST to narrow tasks and small cohorts. In addition, the\nunderlying tissue morphology as reflected by H&E-stained whole slide images\n(WSIs) encodes rich information often overlooked in ST studies. Here, we\nintroduce HEST-1k, a collection of 1,108 spatial transcriptomic profiles, each\nlinked to a WSI and metadata. HEST-1k was assembled using HEST-Library from 131\npublic and internal cohorts encompassing 25 organs, two species (Homo Sapiens\nand Mus Musculus), and 320 cancer samples from 25 cancer types. HEST-1k\nprocessing enabled the identification of 1.5 million expression--morphology\npairs and 60 million nuclei. HEST-1k is tested on three use cases: (1)\nbenchmarking foundation models for histopathology (HEST-Benchmark), (2)\nbiomarker identification, and (3) multimodal representation learning. HEST-1k,\nHEST-Library, and HEST-Benchmark can be freely accessed via\nhttps://github.com/mahmoodlab/hest.\n","authors":["Guillaume Jaume","Paul Doucet","Andrew H. Song","Ming Y. Lu","Cristina Almagro-Pérez","Sophia J. Wagner","Anurag J. Vaidya","Richard J. Chen","Drew F. K. Williamson","Ahrong Kim","Faisal Mahmood"],"pdf_url":"https://arxiv.org/pdf/2406.16192v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.16189v1","updated":"2024-06-23T18:47:51Z","published":"2024-06-23T18:47:51Z","title":"Fuzzy Attention-based Border Rendering Network for Lung Organ\n  Segmentation","summary":"  Automatic lung organ segmentation on CT images is crucial for lung disease\ndiagnosis. However, the unlimited voxel values and class imbalance of lung\norgans can lead to false-negative/positive and leakage issues in advanced\nmethods. Additionally, some slender lung organs are easily lost during the\nrecycled down/up-sample procedure, e.g., bronchioles & arterioles, causing\nsevere discontinuity issue. Inspired by these, this paper introduces an\neffective lung organ segmentation method called Fuzzy Attention-based Border\nRendering (FABR) network. Since fuzzy logic can handle the uncertainty in\nfeature extraction, hence the fusion of deep networks and fuzzy sets should be\na viable solution for better performance. Meanwhile, unlike prior top-tier\nmethods that operate on all regular dense points, our FABR depicts lung organ\nregions as cube-trees, focusing only on recycle-sampled border vulnerable\npoints, rendering the severely discontinuous, false-negative/positive organ\nregions with a novel Global-Local Cube-tree Fusion (GLCF) module. All\nexperimental results, on four challenging datasets of airway & artery,\ndemonstrate that our method can achieve the favorable performance\nsignificantly.\n","authors":["Sheng Zhang","Yang Nan","Yingying Fang","Shiyi Wang","Xiaodan Xing","Zhifan Gao","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.16189v1.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.16187v1","updated":"2024-06-23T18:43:46Z","published":"2024-06-23T18:43:46Z","title":"Evaluation and Comparison of Emotionally Evocative Image Augmentation\n  Methods","summary":"  Experiments in affective computing are based on stimulus datasets that, in\nthe process of standardization, receive metadata describing which emotions each\nstimulus evokes. In this paper, we explore an approach to creating stimulus\ndatasets for affective computing using generative adversarial networks (GANs).\nTraditional dataset preparation methods are costly and time consuming,\nprompting our investigation of alternatives. We conducted experiments with\nvarious GAN architectures, including Deep Convolutional GAN, Conditional GAN,\nAuxiliary Classifier GAN, Progressive Augmentation GAN, and Wasserstein GAN,\nalongside data augmentation and transfer learning techniques. Our findings\nhighlight promising advances in the generation of emotionally evocative\nsynthetic images, suggesting significant potential for future research and\nimprovements in this domain.\n","authors":["Jan Ignatowicz","Krzysztof Kutt","Grzegorz J. Nalepa"],"pdf_url":"https://arxiv.org/pdf/2406.16187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12289v4","updated":"2024-06-23T17:48:42Z","published":"2024-02-19T17:04:04Z","title":"DriveVLM: The Convergence of Autonomous Driving and Large\n  Vision-Language Models","summary":"  A primary hurdle of autonomous driving in urban environments is understanding\ncomplex and long-tail scenarios, such as challenging road conditions and\ndelicate human behaviors. We introduce DriveVLM, an autonomous driving system\nleveraging Vision-Language Models (VLMs) for enhanced scene understanding and\nplanning capabilities. DriveVLM integrates a unique combination of reasoning\nmodules for scene description, scene analysis, and hierarchical planning.\nFurthermore, recognizing the limitations of VLMs in spatial reasoning and heavy\ncomputational requirements, we propose DriveVLM-Dual, a hybrid system that\nsynergizes the strengths of DriveVLM with the traditional autonomous driving\npipeline. Experiments on both the nuScenes dataset and our SUP-AD dataset\ndemonstrate the efficacy of DriveVLM and DriveVLM-Dual in handling complex and\nunpredictable driving conditions. Finally, we deploy the DriveVLM-Dual on a\nproduction vehicle, verifying it is effective in real-world autonomous driving\nenvironments.\n","authors":["Xiaoyu Tian","Junru Gu","Bailin Li","Yicheng Liu","Yang Wang","Zhiyong Zhao","Kun Zhan","Peng Jia","Xianpeng Lang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.12289v4.pdf","comment":"Project Page: https://tsinghua-mars-lab.github.io/DriveVLM/"},{"id":"http://arxiv.org/abs/2402.07894v2","updated":"2024-06-23T16:11:19Z","published":"2024-02-12T18:56:53Z","title":"MODIPHY: Multimodal Obscured Detection for IoT using PHantom\n  Convolution-Enabled Faster YOLO","summary":"  Low-light conditions and occluded scenarios impede object detection in\nreal-world Internet of Things (IoT) applications like autonomous vehicles and\nsecurity systems. While advanced machine learning models strive for accuracy,\ntheir computational demands clash with the limitations of resource-constrained\ndevices, hampering real-time performance. In our current research, we tackle\nthis challenge, by introducing ``YOLO Phantom\", one of the smallest YOLO models\never conceived. YOLO Phantom utilizes the novel Phantom Convolution block,\nachieving comparable accuracy to the latest YOLOv8n model while simultaneously\nreducing both parameters and model size by 43\\%, resulting in a significant\n19\\% reduction in Giga Floating-Point Operations (GFLOPs). YOLO Phantom\nleverages transfer learning on our multimodal RGB-infrared dataset to address\nlow-light and occlusion issues, equipping it with robust vision under adverse\nconditions. Its real-world efficacy is demonstrated on an IoT platform with\nadvanced low-light and RGB cameras, seamlessly connecting to an AWS-based\nnotification endpoint for efficient real-time object detection. Benchmarks\nreveal a substantial boost of 17\\% and 14\\% in frames per second (FPS) for\nthermal and RGB detection, respectively, compared to the baseline YOLOv8n\nmodel. For community contribution, both the code and the multimodal dataset are\navailable on GitHub.\n","authors":["Shubhabrata Mukherjee","Cory Beard","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2402.07894v2.pdf","comment":"This paper has been accepted for publication at the IEEE\n  International Conference on Image Processing (ICIP) 2024"},{"id":"http://arxiv.org/abs/2406.16150v1","updated":"2024-06-23T16:09:21Z","published":"2024-06-23T16:09:21Z","title":"Intensity Confusion Matters: An Intensity-Distance Guided Loss for\n  Bronchus Segmentation","summary":"  Automatic segmentation of the bronchial tree from CT imaging is important, as\nit provides structural information for disease diagnosis. Despite the merits of\nprevious automatic bronchus segmentation methods, they have paied less\nattention to the issue we term as \\textit{Intensity Confusion}, wherein the\nintensity values of certain background voxels approach those of the foreground\nvoxels within bronchi. Conversely, the intensity values of some foreground\nvoxels are nearly identical to those of background voxels. This proximity in\nintensity values introduces significant challenges to neural network\nmethodologies. To address the issue, we introduce a novel Intensity-Distance\nGuided loss function, which assigns adaptive weights to different image voxels\nfor mining hard samples that cause the intensity confusion. The proposed loss\nestimates the voxel-level hardness of samples, on the basis of the following\nintensity and distance priors. We regard a voxel as a hard sample if it is in:\n(1) the background and has an intensity value close to the bronchus region; (2)\nthe bronchus region and is of higher intensity than most voxels inside the\nbronchus; (3) the background region and at a short distance from the bronchus.\nExtensive experiments not only show the superiority of our method compared with\nthe state-of-the-art methods, but also verify that tackling the intensity\nconfusion issue helps to significantly improve bronchus segmentation. Project\npage: https://github.com/lhaof/ICM.\n","authors":["Haifan Gong","Wenhao Huang","Huan Zhang","Yu Wang","Xiang Wan","Hong Shen","Guanbin Li","Haofeng Li"],"pdf_url":"https://arxiv.org/pdf/2406.16150v1.pdf","comment":"IEEE International Conference on Multimedia & Expo (ICME) 2024"},{"id":"http://arxiv.org/abs/2406.06374v2","updated":"2024-06-23T16:04:10Z","published":"2024-06-10T15:36:23Z","title":"Multicam-SLAM: Non-overlapping Multi-camera SLAM for Indirect Visual\n  Localization and Navigation","summary":"  This paper presents a novel approach to visual simultaneous localization and\nmapping (SLAM) using multiple RGB-D cameras. The proposed method,\nMulticam-SLAM, significantly enhances the robustness and accuracy of SLAM\nsystems by capturing more comprehensive spatial information from various\nperspectives. This method enables the accurate determination of pose\nrelationships among multiple cameras without the need for overlapping fields of\nview. The proposed Muticam-SLAM includes a unique multi-camera model, a\nmulti-keyframes structure, and several parallel SLAM threads. The multi-camera\nmodel allows for the integration of data from multiple cameras, while the\nmulti-keyframes and parallel SLAM threads ensure efficient and accurate pose\nestimation and mapping. Extensive experiments in various environments\ndemonstrate the superior accuracy and robustness of the proposed method\ncompared to conventional single-camera SLAM systems. The results highlight the\npotential of the proposed Multicam-SLAM for more complex and challenging\napplications. Code is available at\n\\url{https://github.com/AlterPang/Multi_ORB_SLAM}.\n","authors":["Shenghao Li","Luchao Pang","Xianglong Hu"],"pdf_url":"https://arxiv.org/pdf/2406.06374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16143v1","updated":"2024-06-23T15:45:32Z","published":"2024-06-23T15:45:32Z","title":"Review of Zero-Shot and Few-Shot AI Algorithms in The Medical Domain","summary":"  In this paper, different techniques of few-shot, zero-shot, and regular\nobject detection have been investigated. The need for few-shot learning and\nzero-shot learning techniques is crucial and arises from the limitations and\nchallenges in traditional machine learning, deep learning, and computer vision\nmethods where they require large amounts of data, plus the poor generalization\nof those traditional methods.\n  Those techniques can give us prominent results by using only a few training\nsets reducing the required amounts of data and improving the generalization.\n  This survey will highlight the recent papers of the last three years that\nintroduce the usage of few-shot learning and zero-shot learning techniques in\naddressing the challenges mentioned earlier. In this paper we reviewed the\nZero-shot, few-shot and regular object detection methods and categorized them\nin an understandable manner. Based on the comparison made within each category.\nIt been found that the approaches are quite impressive.\n  This integrated review of diverse papers on few-shot, zero-shot, and regular\nobject detection reveals a shared focus on advancing the field through novel\nframeworks and techniques. A noteworthy observation is the scarcity of detailed\ndiscussions regarding the difficulties encountered during the development\nphase. Contributions include the introduction of innovative models, such as\nZSD-YOLO and GTNet, often showcasing improvements with various metrics such as\nmean average precision (mAP),Recall@100 (RE@100), the area under the receiver\noperating characteristic curve (AUROC) and precision. These findings underscore\na collective move towards leveraging vision-language models for versatile\napplications, with potential areas for future research including a more\nthorough exploration of limitations and domain-specific adaptations.\n","authors":["Maged Badawi","Mohammedyahia Abushanab","Sheethal Bhat","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2406.16143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16141v1","updated":"2024-06-23T15:28:07Z","published":"2024-06-23T15:28:07Z","title":"Multimodal Multilabel Classification by CLIP","summary":"  Multimodal multilabel classification (MMC) is a challenging task that aims to\ndesign a learning algorithm to handle two data sources, the image and text, and\nlearn a comprehensive semantic feature presentation across the modalities. In\nthis task, we review the extensive number of state-of-the-art approaches in MMC\nand leverage a novel technique that utilises the Contrastive Language-Image\nPre-training (CLIP) as the feature extractor and fine-tune the model by\nexploring different classification heads, fusion methods and loss functions.\nFinally, our best result achieved more than 90% F_1 score in the public Kaggle\ncompetition leaderboard. This paper provides detailed descriptions of novel\ntraining methods and quantitative analysis through the experimental results.\n","authors":["Yanming Guo"],"pdf_url":"https://arxiv.org/pdf/2406.16141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16137v1","updated":"2024-06-23T15:18:30Z","published":"2024-06-23T15:18:30Z","title":"MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP\n  Modeling","summary":"  Multi-view hand mesh reconstruction is a critical task for applications in\nvirtual reality and human-computer interaction, but it remains a formidable\nchallenge. Although existing multi-view hand reconstruction methods achieve\nremarkable accuracy, they typically come with an intensive computational burden\nthat hinders real-time inference. To this end, we propose MLPHand, a novel\nmethod designed for real-time multi-view single hand reconstruction. MLP Hand\nconsists of two primary modules: (1) a lightweight MLP-based Skeleton2Mesh\nmodel that efficiently recovers hand meshes from hand skeletons, and (2) a\nmulti-view geometry feature fusion prediction module that enhances the\nSkeleton2Mesh model with detailed geometric information from multiple views.\nExperiments on three widely used datasets demonstrate that MLPHand can reduce\ncomputational complexity by 90% while achieving comparable reconstruction\naccuracy to existing state-of-the-art baselines.\n","authors":["Jian Yang","Jiakun Li","Guoming Li","Zhen Shen","Huai-Yu Wu","Zhaoxin Fan","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16129v1","updated":"2024-06-23T15:03:35Z","published":"2024-06-23T15:03:35Z","title":"UDHF2-Net: An Uncertainty-diffusion-model-based High-Frequency\n  TransFormer Network for High-accuracy Interpretation of Remotely Sensed\n  Imagery","summary":"  Remotely sensed image high-accuracy interpretation (RSIHI), including tasks\nsuch as semantic segmentation and change detection, faces the three major\nproblems: (1) complementarity problem of spatially\nstationary-and-non-stationary frequency; (2) edge uncertainty problem caused by\ndown-sampling in the encoder step and intrinsic edge noises; and (3) false\ndetection problem caused by imagery registration error in change detection. To\nsolve the aforementioned problems, an uncertainty-diffusion-model-based\nhigh-Frequency TransFormer network (UDHF2-Net) is the proposed for RSIHI, the\nsuperiority of which is as following: (1) a\nspatially-stationary-and-non-stationary high-frequency connection paradigm\n(SHCP) is proposed to enhance the interaction of spatially stationary and\nnon-stationary frequency features to yield high-fidelity edge extraction\nresult. Inspired by HRFormer, SHCP remains the high-frequency stream through\nthe whole encoder-decoder process with parallel high-to-low frequency streams\nand reduces the edge loss by a downsampling operation; (2) a\nmask-and-geo-knowledge-based uncertainty diffusion module (MUDM) is proposed to\nimprove the robustness and edge noise resistance. MUDM could further optimize\nthe uncertain region to improve edge extraction result by gradually removing\nthe multiple geo-knowledge-based noises; (3) a semi-pseudo-Siamese UDHF2-Net\nfor change detection task is proposed to reduce the pseudo change by\nregistration error. It adopts semi-pseudo-Siamese architecture to extract above\ncomplemental frequency features for adaptively reducing registration\ndifferencing, and MUDM to recover the uncertain region by gradually reducing\nthe registration error besides above edge noises. Comprehensive experiments\nwere performed to demonstrate the superiority of UDHF2-Net. Especially ablation\nexperiments indicate the effectiveness of UDHF2-Net.\n","authors":["Pengfei Zhang","Chang Li","Yongjun Zhang","Rongjun Qin"],"pdf_url":"https://arxiv.org/pdf/2406.16129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06589v2","updated":"2024-06-23T14:54:11Z","published":"2024-04-09T19:33:05Z","title":"Leveraging Latents for Efficient Thermography Classification and\n  Segmentation","summary":"  Breast cancer is a prominent health concern worldwide, currently being the\nsecondmost common and second-deadliest type of cancer in women. While current\nbreast cancer diagnosis mainly relies on mammography imaging, in recent years\nthe use of thermography for breast cancer imaging has been garnering growing\npopularity. Thermographic imaging relies on infrared cameras to capture\nbody-emitted heat distributions. While these heat signatures have proven useful\nfor computer-vision systems for accurate breast cancer segmentation and\nclassification, prior work often relies on handcrafted feature engineering or\ncomplex architectures, potentially limiting the comparability and applicability\nof these methods. In this work, we present a novel algorithm for both breast\ncancer classification and segmentation. Rather than focusing efforts on manual\nfeature and architecture engineering, our algorithm focuses on leveraging an\ninformative, learned feature space, thus making our solution simpler to use and\nextend to other frameworks and downstream tasks, as well as more applicable to\ndata-scarce settings. Our classification produces SOTA results, while we are\nthe first work to produce segmentation regions studied in this paper.\n","authors":["Tamir Shor","Chaim Baskin","Alex Bronstein"],"pdf_url":"https://arxiv.org/pdf/2404.06589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11735v4","updated":"2024-06-23T14:08:35Z","published":"2024-03-18T12:43:38Z","title":"LSKNet: A Foundation Lightweight Backbone for Remote Sensing","summary":"  Remote sensing images pose distinct challenges for downstream tasks due to\ntheir inherent complexity. While a considerable amount of research has been\ndedicated to remote sensing classification, object detection and semantic\nsegmentation, most of these studies have overlooked the valuable prior\nknowledge embedded within remote sensing scenarios. Such prior knowledge can be\nuseful because remote sensing objects may be mistakenly recognized without\nreferencing a sufficiently long-range context, which can vary for different\nobjects. This paper considers these priors and proposes a lightweight Large\nSelective Kernel Network (LSKNet) backbone. LSKNet can dynamically adjust its\nlarge spatial receptive field to better model the ranging context of various\nobjects in remote sensing scenarios. To our knowledge, large and selective\nkernel mechanisms have not been previously explored in remote sensing images.\nWithout bells and whistles, our lightweight LSKNet sets new state-of-the-art\nscores on standard remote sensing classification, object detection and semantic\nsegmentation benchmarks. Our comprehensive analysis further validated the\nsignificance of the identified priors and the effectiveness of LSKNet. The code\nis available at https://github.com/zcablii/LSKNet.\n","authors":["Yuxuan Li","Xiang Li","Yimian Dai","Qibin Hou","Li Liu","Yongxiang Liu","Ming-Ming Cheng","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2403.11735v4.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.09030"},{"id":"http://arxiv.org/abs/2406.16111v1","updated":"2024-06-23T13:59:31Z","published":"2024-06-23T13:59:31Z","title":"Multi-Scale Temporal Difference Transformer for Video-Text Retrieval","summary":"  Currently, in the field of video-text retrieval, there are many\ntransformer-based methods. Most of them usually stack frame features and\nregrade frames as tokens, then use transformers for video temporal modeling.\nHowever, they commonly neglect the inferior ability of the transformer modeling\nlocal temporal information. To tackle this problem, we propose a transformer\nvariant named Multi-Scale Temporal Difference Transformer (MSTDT). MSTDT mainly\naddresses the defects of the traditional transformer which has limited ability\nto capture local temporal information. Besides, in order to better model the\ndetailed dynamic information, we make use of the difference feature between\nframes, which practically reflects the dynamic movement of a video. We extract\nthe inter-frame difference feature and integrate the difference and frame\nfeature by the multi-scale temporal transformer. In general, our proposed MSTDT\nconsists of a short-term multi-scale temporal difference transformer and a\nlong-term temporal transformer. The former focuses on modeling local temporal\ninformation, the latter aims at modeling global temporal information. At last,\nwe propose a new loss to narrow the distance of similar samples. Extensive\nexperiments show that backbone, such as CLIP, with MSTDT has attained a new\nstate-of-the-art result.\n","authors":["Ni Wang","Dongliang Liao","Xing Xu"],"pdf_url":"https://arxiv.org/pdf/2406.16111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16109v1","updated":"2024-06-23T13:53:35Z","published":"2024-06-23T13:53:35Z","title":"X-ray2CTPA: Generating 3D CTPA scans from 2D X-ray conditioning","summary":"  Chest X-rays or chest radiography (CXR), commonly used for medical\ndiagnostics, typically enables limited imaging compared to computed tomography\n(CT) scans, which offer more detailed and accurate three-dimensional data,\nparticularly contrast-enhanced scans like CT Pulmonary Angiography (CTPA).\nHowever, CT scans entail higher costs, greater radiation exposure, and are less\naccessible than CXRs. In this work we explore cross-modal translation from a 2D\nlow contrast-resolution X-ray input to a 3D high contrast and\nspatial-resolution CTPA scan. Driven by recent advances in generative AI, we\nintroduce a novel diffusion-based approach to this task. We evaluate the models\nperformance using both quantitative metrics and qualitative feedback from\nradiologists, ensuring diagnostic relevance of the generated images.\nFurthermore, we employ the synthesized 3D images in a classification framework\nand show improved AUC in a PE categorization task, using the initial CXR input.\nThe proposed method is generalizable and capable of performing additional\ncross-modality translations in medical imaging. It may pave the way for more\naccessible and cost-effective advanced diagnostic tools. The code for this\nproject is available: https://github.com/NoaCahan/X-ray2CTPA .\n","authors":["Noa Cahan","Eyal Klang","Galit Aviram","Yiftach Barash","Eli Konen","Raja Giryes","Hayit Greenspan"],"pdf_url":"https://arxiv.org/pdf/2406.16109v1.pdf","comment":"preprint, project code: https://github.com/NoaCahan/X-ray2CTPA"},{"id":"http://arxiv.org/abs/2406.11548v2","updated":"2024-06-23T12:58:01Z","published":"2024-06-17T13:44:53Z","title":"AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic\n  Manipulation","summary":"  The ability to reflect on and correct failures is crucial for robotic systems\nto interact stably with real-life objects.Observing the generalization and\nreasoning capabilities of Multimodal Large Language Models (MLLMs), previous\napproaches have aimed to utilize these models to enhance robotic systems\naccordingly.However, these methods typically focus on high-level planning\ncorrections using an additional MLLM, with limited utilization of failed\nsamples to correct low-level contact poses. To address this gap, we propose an\nAutonomous Interactive Correction (AIC) MLLM, which makes use of previous\nlow-level interaction experiences to correct SE(3) pose predictions.\nSpecifically, AIC MLLM is initially fine-tuned to acquire both pose prediction\nand feedback prompt comprehension abilities.We carefully design two types of\nprompt instructions through interactions with objects: 1) visual masks to\nhighlight unmovable parts for position correction, and 2)textual descriptions\nto indicate potential directions for rotation correction.During inference, a\nFeedback Information Extraction module is introduced to recognize the failure\ncause, allowing AIC MLLM to adaptively correct the pose prediction using the\ncorresponding prompts. To further enhance manipulation stability, we devise a\nTest Time Adaptation strategy that enables AIC MLLM to better adapt to the\ncurrent scene configuration.Finally, extensive experiments are conducted in\nboth simulated and real-world environments to evaluate the proposed method. The\nresults demonstrate that our AIC MLLM can efficiently correct failure samples\nby leveraging interaction experience prompts.Real-world demonstration can be\nfound at https://sites.google.com/view/aic-mllm\n","authors":["Chuyan Xiong","Chengyu Shen","Xiaoqi Li","Kaichen Zhou","Jiaming Liu","Ruiping Wang","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2406.11548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16093v1","updated":"2024-06-23T12:14:37Z","published":"2024-06-23T12:14:37Z","title":"Towards Natural Language-Driven Assembly Using Foundation Models","summary":"  Large Language Models (LLMs) and strong vision models have enabled rapid\nresearch and development in the field of Vision-Language-Action models that\nenable robotic control. The main objective of these methods is to develop a\ngeneralist policy that can control robots with various embodiments. However, in\nindustrial robotic applications such as automated assembly and disassembly,\nsome tasks, such as insertion, demand greater accuracy and involve intricate\nfactors like contact engagement, friction handling, and refined motor skills.\nImplementing these skills using a generalist policy is challenging because\nthese policies might integrate further sensory data, including force or torque\nmeasurements, for enhanced precision. In our method, we present a global\ncontrol policy based on LLMs that can transfer the control policy to a finite\nset of skills that are specifically trained to perform high-precision tasks\nthrough dynamic context switching. The integration of LLMs into this framework\nunderscores their significance in not only interpreting and processing language\ninputs but also in enriching the control mechanisms for diverse and intricate\nrobotic operations.\n","authors":["Omkar Joglekar","Tal Lancewicki","Shir Kozlovsky","Vladimir Tchuiev","Zohar Feldman","Dotan Di Castro"],"pdf_url":"https://arxiv.org/pdf/2406.16093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16087v1","updated":"2024-06-23T12:02:17Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neural-Symbolic Learning\n  Framework for Robot Autonomy","summary":"  Data-driven methods such as reinforcement and imitation learning have\nachieved remarkable success in robot autonomy. However, their data-centric\nnature still hinders them from generalizing well to ever-changing environments.\nMoreover, collecting large datasets for robotic tasks is often impractical and\nexpensive. To overcome these challenges, we introduce a new self-supervised\nneural-symbolic (NeSy) computational framework, imperative learning (IL), for\nrobot autonomy, leveraging the generalization abilities of symbolic reasoning.\nThe framework of IL consists of three primary components: a neural module, a\nreasoning engine, and a memory system. We formulate IL as a special bilevel\noptimization (BLO), which enables reciprocal learning over the three modules.\nThis overcomes the label-intensive obstacles associated with data-driven\napproaches and takes advantage of symbolic reasoning concerning logical\nreasoning, physical principles, geometric analysis, etc. We discuss several\noptimization techniques for IL and verify their effectiveness in five distinct\nrobot autonomy tasks including path planning, rule induction, optimal control,\nvisual odometry, and multi-robot routing. Through various experiments, we show\nthat IL can significantly enhance robot autonomy capabilities and we anticipate\nthat it will catalyze further research across diverse domains.\n","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.16087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16085v1","updated":"2024-06-23T11:57:08Z","published":"2024-06-23T11:57:08Z","title":"A Simple Framework for Open-Vocabulary Zero-Shot Segmentation","summary":"  Zero-shot classification capabilities naturally arise in models trained\nwithin a vision-language contrastive framework. Despite their classification\nprowess, these models struggle in dense tasks like zero-shot open-vocabulary\nsegmentation. This deficiency is often attributed to the absence of\nlocalization cues in captions and the intertwined nature of the learning\nprocess, which encompasses both image representation learning and\ncross-modality alignment. To tackle these issues, we propose SimZSS, a Simple\nframework for open-vocabulary Zero-Shot Segmentation. The method is founded on\ntwo key principles: i) leveraging frozen vision-only models that exhibit\nspatial awareness while exclusively aligning the text encoder and ii)\nexploiting the discrete nature of text and linguistic knowledge to pinpoint\nlocal concepts within captions. By capitalizing on the quality of the visual\nrepresentations, our method requires only image-caption pairs datasets and\nadapts to both small curated and large-scale noisy datasets. When trained on\nCOCO Captions across 8 GPUs, SimZSS achieves state-of-the-art results on 7 out\nof 8 benchmark datasets in less than 15 minutes.\n","authors":["Thomas Stegmüller","Tim Lebailly","Nikola Dukic","Behzad Bozorgtabar","Jean-Philippe Thiran","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2406.16085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16083v1","updated":"2024-06-23T11:28:08Z","published":"2024-06-23T11:28:08Z","title":"Mamba-based Light Field Super-Resolution with Efficient Subspace\n  Scanning","summary":"  Transformer-based methods have demonstrated impressive performance in 4D\nlight field (LF) super-resolution by effectively modeling long-range\nspatial-angular correlations, but their quadratic complexity hinders the\nefficient processing of high resolution 4D inputs, resulting in slow inference\nspeed and high memory cost. As a compromise, most prior work adopts a\npatch-based strategy, which fails to leverage the full information from the\nentire input LFs. The recently proposed selective state-space model, Mamba, has\ngained popularity for its efficient long-range sequence modeling. In this\npaper, we propose a Mamba-based Light Field Super-Resolution method, named\nMLFSR, by designing an efficient subspace scanning strategy. Specifically, we\ntokenize 4D LFs into subspace sequences and conduct bi-directional scanning on\neach subspace. Based on our scanning strategy, we then design the Mamba-based\nGlobal Interaction (MGI) module to capture global information and the local\nSpatial- Angular Modulator (SAM) to complement local details. Additionally, we\nintroduce a Transformer-to-Mamba (T2M) loss to further enhance overall\nperformance. Extensive experiments on public benchmarks demonstrate that MLFSR\nsurpasses CNN-based models and rivals Transformer-based methods in performance\nwhile maintaining higher efficiency. With quicker inference speed and reduced\nmemory demand, MLFSR facilitates full-image processing of high-resolution 4D\nLFs with enhanced performance.\n","authors":["Ruisheng Gao","Zeyu Xiao","Zhiwei Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.16083v1.pdf","comment":"17 pages,7 figures"},{"id":"http://arxiv.org/abs/2406.16077v1","updated":"2024-06-23T11:09:21Z","published":"2024-06-23T11:09:21Z","title":"Detecting Abnormal Operations in Concentrated Solar Power Plants from\n  Irregular Sequences of Thermal Images","summary":"  Concentrated Solar Power (CSP) plants store energy by heating a storage\nmedium with an array of mirrors that focus sunlight onto solar receivers atop a\ncentral tower. Operating at high temperatures these receivers face risks such\nas freezing, deformation, and corrosion, leading to operational failures,\ndowntime, or costly equipment damage. We study the problem of anomaly detection\n(AD) in sequences of thermal images collected over a year from an operational\nCSP plant. These images are captured at irregular intervals ranging from one to\nfive minutes throughout the day by infrared cameras mounted on solar receivers.\nOur goal is to develop a method to extract useful representations from\nhigh-dimensional thermal images for AD. It should be able to handle temporal\nfeatures of the data, which include irregularity, temporal dependency between\nimages and non-stationarity due to a strong daily seasonal pattern. The\nco-occurrence of low-temperature anomalies that resemble normal images from the\nstart and the end of the operational cycle with high-temperature anomalies\nposes an additional challenge. We first evaluate state-of-the-art deep\nimage-based AD methods, which have been shown to be effective in deriving\nmeaningful image representations for the detection of anomalies. Then, we\nintroduce a forecasting-based AD method that predicts future thermal images\nfrom past sequences and timestamps via a deep sequence model. This method\neffectively captures specific temporal data features and distinguishes between\ndifficult-to-detect temperature-based anomalies. Our experiments demonstrate\nthe effectiveness of our approach compared to multiple SOTA baselines across\nmultiple evaluation metrics. We have also successfully deployed our solution on\nfive months of unseen data, providing critical insights for the maintenance of\nthe CSP plant. Our code is available at: https://tinyurl.com/ForecastAD\n","authors":["Sukanya Patra","Nicolas Sournac","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2406.16077v1.pdf","comment":"Accepted in KDD 2024"},{"id":"http://arxiv.org/abs/2406.16074v1","updated":"2024-06-23T10:50:22Z","published":"2024-06-23T10:50:22Z","title":"CAVM: Conditional Autoregressive Vision Model for Contrast-Enhanced\n  Brain Tumor MRI Synthesis","summary":"  Contrast-enhanced magnetic resonance imaging (MRI) is pivotal in the pipeline\nof brain tumor segmentation and analysis. Gadolinium-based contrast agents, as\nthe most commonly used contrast agents, are expensive and may have potential\nside effects, and it is desired to obtain contrast-enhanced brain tumor MRI\nscans without the actual use of contrast agents. Deep learning methods have\nbeen applied to synthesize virtual contrast-enhanced MRI scans from\nnon-contrast images. However, as this synthesis problem is inherently\nill-posed, these methods fall short in producing high-quality results. In this\nwork, we propose Conditional Autoregressive Vision Model (CAVM) for improving\nthe synthesis of contrast-enhanced brain tumor MRI. As the enhancement of image\nintensity grows with a higher dose of contrast agents, we assume that it is\nless challenging to synthesize a virtual image with a lower dose, where the\ndifference between the contrast-enhanced and non-contrast images is smaller.\nThus, CAVM gradually increases the contrast agent dosage and produces\nhigher-dose images based on previous lower-dose ones until the final desired\ndose is achieved. Inspired by the resemblance between the gradual dose increase\nand the Chain-of-Thought approach in natural language processing, CAVM uses an\nautoregressive strategy with a decomposition tokenizer and a decoder.\nSpecifically, the tokenizer is applied to obtain a more compact image\nrepresentation for computational efficiency, and it decomposes the image into\ndose-variant and dose-invariant tokens. Then, a masked self-attention mechanism\nis developed for autoregression that gradually increases the dose of the\nvirtual image based on the dose-variant tokens. Finally, the updated\ndose-variant tokens corresponding to the desired dose are decoded together with\ndose-invariant tokens to produce the final contrast-enhanced MRI.\n","authors":["Lujun Gui","Chuyang Ye","Tianyi Yan"],"pdf_url":"https://arxiv.org/pdf/2406.16074v1.pdf","comment":"The work has been accepted by MICCAI 2024"}],"Robotics":[{"id":"http://arxiv.org/abs/2406.05080v2","updated":"2024-06-23T22:58:46Z","published":"2024-06-07T16:52:57Z","title":"I2EDL: Interactive Instruction Error Detection and Localization","summary":"  In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)\ntask, the human user guides an autonomous agent to reach a target goal via a\nseries of low-level actions following a textual instruction in natural\nlanguage. However, most existing methods do not address the likely case where\nusers may make mistakes when providing such instruction (e.g. \"turn left\"\ninstead of \"turn right\"). In this work, we address a novel task of Interactive\nVLN in Continuous Environments (IVLN-CE), which allows the agent to interact\nwith the user during the VLN-CE navigation to verify any doubts regarding the\ninstruction errors. We propose an Interactive Instruction Error Detector and\nLocalizer (I2EDL) that triggers the user-agent interaction upon the detection\nof instruction errors during the navigation. We leverage a pre-trained module\nto detect instruction errors and pinpoint them in the instruction by\ncross-referencing the textual input and past observations. In such way, the\nagent is able to query the user for a timely correction, without demanding the\nuser's cognitive load, as we locate the probable errors to a precise part of\nthe instruction. We evaluate the proposed I2EDL on a dataset of instructions\ncontaining errors, and further devise a novel metric, the Success weighted by\nInteraction Number (SIN), to reflect both the navigation performance and the\ninteraction effectiveness. We show how the proposed method can ask focused\nrequests for corrections to the user, which in turn increases the navigation\nsuccess, while minimizing the interactions.\n","authors":["Francesco Taioli","Stefano Rosa","Alberto Castellini","Lorenzo Natale","Alessio Del Bue","Alessandro Farinelli","Marco Cristani","Yiming Wang"],"pdf_url":"https://arxiv.org/pdf/2406.05080v2.pdf","comment":"Accepted at IEEE RO-MAN 2024"},{"id":"http://arxiv.org/abs/2406.01763v4","updated":"2024-06-23T22:42:16Z","published":"2024-06-03T20:09:46Z","title":"Provably Feasible and Stable White-Box Trajectory Optimization","summary":"  We study the problem of Trajectory Optimization (TO) for a general class of\nstiff and constrained dynamic systems. We establish a set of mild assumptions,\nunder which we show that TO converges numerically stably to a locally optimal\nand feasible solution up to arbitrary user-specified error tolerance. Our key\nobservation is that all prior works use SQP as a black-box solver, where a TO\nproblem is formulated as a Nonlinear Program (NLP) and the underlying SQP\nsolver is not allowed to modify the NLP. Instead, we propose a white-box TO\nsolver, where the SQP solver is informed with characteristics of the objective\nfunction and the dynamic system. It then uses these characteristics to derive\napproximate dynamic systems and customize the discretization schemes.\n","authors":["Zherong Pan","Yifan Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.01763v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10157v2","updated":"2024-06-23T18:00:30Z","published":"2024-06-14T16:16:52Z","title":"RoboGolf: Mastering Real-World Minigolf with a Reflective Multi-Modality\n  Vision-Language Model","summary":"  Minigolf, a game with countless court layouts, and complex ball motion,\nconstitutes a compelling real-world testbed for the study of embodied\nintelligence. As it not only challenges spatial and kinodynamic reasoning but\nalso requires reflective and corrective capacities to address erroneously\ndesigned courses. We introduce RoboGolf, a framework that perceives dual-camera\nvisual inputs with nested VLM-empowered closed-loop control and reflective\nequilibrium loop. Extensive experiments demonstrate the effectiveness of\nRoboGolf on challenging minigolf courts including those that are impossible to\nfinish.\n","authors":["Hantao Zhou","Tianying Ji","Jianwei Zhang","Fuchun Sun","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2406.10157v2.pdf","comment":"Project page: https://jity16.github.io/RoboGolf/"},{"id":"http://arxiv.org/abs/2406.16164v1","updated":"2024-06-23T16:54:07Z","published":"2024-06-23T16:54:07Z","title":"TornadoDrone: Bio-inspired DRL-based Drone Landing on 6D Platform with\n  Wind Force Disturbances","summary":"  Autonomous drone navigation faces a critical challenge in achieving accurate\nlandings on dynamic platforms, especially under unpredictable conditions such\nas wind turbulence. Our research introduces TornadoDrone, a novel Deep\nReinforcement Learning (DRL) model that adopts bio-inspired mechanisms to adapt\nto wind forces, mirroring the natural adaptability seen in birds. This model,\nunlike traditional approaches, derives its adaptability from indirect cues such\nas changes in position and velocity, rather than direct wind force\nmeasurements. TornadoDrone was rigorously trained in the gym-pybullet-drone\nsimulator, which closely replicates the complexities of wind dynamics in the\nreal world. Through extensive testing with Crazyflie 2.1 drones in both\nsimulated and real windy conditions, TornadoDrone demonstrated a high\nperformance in maintaining high-precision landing accuracy on moving platforms,\nsurpassing conventional control methods such as PID controllers with Extended\nKalman Filters. The study not only highlights the potential of DRL to tackle\ncomplex aerodynamic challenges but also paves the way for advanced autonomous\nsystems that can adapt to environmental changes in real-time. The success of\nTornadoDrone signifies a leap forward in drone technology, particularly for\ncritical applications such as surveillance and emergency response, where\nreliability and precision are paramount.\n","authors":["Robinroy Peter","Lavanya Ratnabala","Demetros Aschu","Aleksey Fedoseev","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2406.16164v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2403.06572"},{"id":"http://arxiv.org/abs/2406.08347v2","updated":"2024-06-23T16:19:28Z","published":"2024-06-12T15:55:39Z","title":"Trajectory optimization of tail-sitter considering speed constraints","summary":"  Tail-sitters, with the advantages of both the fixed-wing unmanned aerial\nvehicles (UAVs) and vertical take-off and landing UAVs, have been widely\ndesigned and researched in recent years. With the change in modern UAV\napplication scenarios, it is required that UAVs have fast maneuverable\nthree-dimensional flight capabilities. Due to the highly nonlinear aerodynamics\nproduced by the fuselage and wings of the tail-sitter, how to quickly generate\na smooth and executable trajectory is a problem that needs to be solved\nurgently. We constrain the speed of the tail-sitter, eliminate the differential\ndynamics constraints in the trajectory generation process of the tail-sitter\nthrough differential flatness, and allocate the time variable of the trajectory\nthrough the state-of-the-art trajectory generation method named MINCO. By\ndiscretizing the trajectory in time, we convert the speed constraint on the\nvehicle into a soft constraint, thereby achieving the time-optimal trajectory\nfor the tail-sitter to fly through any given waypoints.\n","authors":["Mingyue Fan","Fangfang Xie","Tingwei Ji","Yao Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.08347v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06374v2","updated":"2024-06-23T16:04:10Z","published":"2024-06-10T15:36:23Z","title":"Multicam-SLAM: Non-overlapping Multi-camera SLAM for Indirect Visual\n  Localization and Navigation","summary":"  This paper presents a novel approach to visual simultaneous localization and\nmapping (SLAM) using multiple RGB-D cameras. The proposed method,\nMulticam-SLAM, significantly enhances the robustness and accuracy of SLAM\nsystems by capturing more comprehensive spatial information from various\nperspectives. This method enables the accurate determination of pose\nrelationships among multiple cameras without the need for overlapping fields of\nview. The proposed Muticam-SLAM includes a unique multi-camera model, a\nmulti-keyframes structure, and several parallel SLAM threads. The multi-camera\nmodel allows for the integration of data from multiple cameras, while the\nmulti-keyframes and parallel SLAM threads ensure efficient and accurate pose\nestimation and mapping. Extensive experiments in various environments\ndemonstrate the superior accuracy and robustness of the proposed method\ncompared to conventional single-camera SLAM systems. The results highlight the\npotential of the proposed Multicam-SLAM for more complex and challenging\napplications. Code is available at\n\\url{https://github.com/AlterPang/Multi_ORB_SLAM}.\n","authors":["Shenghao Li","Luchao Pang","Xianglong Hu"],"pdf_url":"https://arxiv.org/pdf/2406.06374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06427v2","updated":"2024-06-23T14:58:51Z","published":"2024-06-10T16:15:30Z","title":"Notes on Kalman Filter (KF, EKF, ESKF, IEKF, IESKF)","summary":"  The Kalman Filter (KF) is a powerful mathematical tool widely used for state\nestimation in various domains, including Simultaneous Localization and Mapping\n(SLAM). This paper presents an in-depth introduction to the Kalman Filter and\nexplores its several extensions: the Extended Kalman Filter (EKF), the\nError-State Kalman Filter (ESKF), the Iterated Extended Kalman Filter (IEKF),\nand the Iterated Error-State Kalman Filter (IESKF). Each variant is\nmeticulously examined, with detailed derivations of their mathematical\nformulations and discussions on their respective advantages and limitations. By\nproviding a comprehensive overview of these techniques, this paper aims to\noffer valuable insights into their applications in SLAM and enhance the\nunderstanding of state estimation methodologies in complex environments.\n","authors":["Gyubeom Im"],"pdf_url":"https://arxiv.org/pdf/2406.06427v2.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2406.11548v2","updated":"2024-06-23T12:58:01Z","published":"2024-06-17T13:44:53Z","title":"AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic\n  Manipulation","summary":"  The ability to reflect on and correct failures is crucial for robotic systems\nto interact stably with real-life objects.Observing the generalization and\nreasoning capabilities of Multimodal Large Language Models (MLLMs), previous\napproaches have aimed to utilize these models to enhance robotic systems\naccordingly.However, these methods typically focus on high-level planning\ncorrections using an additional MLLM, with limited utilization of failed\nsamples to correct low-level contact poses. To address this gap, we propose an\nAutonomous Interactive Correction (AIC) MLLM, which makes use of previous\nlow-level interaction experiences to correct SE(3) pose predictions.\nSpecifically, AIC MLLM is initially fine-tuned to acquire both pose prediction\nand feedback prompt comprehension abilities.We carefully design two types of\nprompt instructions through interactions with objects: 1) visual masks to\nhighlight unmovable parts for position correction, and 2)textual descriptions\nto indicate potential directions for rotation correction.During inference, a\nFeedback Information Extraction module is introduced to recognize the failure\ncause, allowing AIC MLLM to adaptively correct the pose prediction using the\ncorresponding prompts. To further enhance manipulation stability, we devise a\nTest Time Adaptation strategy that enables AIC MLLM to better adapt to the\ncurrent scene configuration.Finally, extensive experiments are conducted in\nboth simulated and real-world environments to evaluate the proposed method. The\nresults demonstrate that our AIC MLLM can efficiently correct failure samples\nby leveraging interaction experience prompts.Real-world demonstration can be\nfound at https://sites.google.com/view/aic-mllm\n","authors":["Chuyan Xiong","Chengyu Shen","Xiaoqi Li","Kaichen Zhou","Jiaming Liu","Ruiping Wang","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2406.11548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01538v4","updated":"2024-06-23T12:18:21Z","published":"2022-11-03T01:04:33Z","title":"$D^2$SLAM: Decentralized and Distributed Collaborative Visual-inertial\n  SLAM System for Aerial Swarm","summary":"  Collaborative simultaneous localization and mapping (CSLAM) is essential for\nautonomous aerial swarms, laying the foundation for downstream algorithms such\nas planning and control. To address existing CSLAM systems' limitations in\nrelative localization accuracy, crucial for close-range UAV collaboration, this\npaper introduces $D^2$SLAM-a novel decentralized and distributed CSLAM system.\n$D^2$SLAM innovatively manages near-field estimation for precise relative state\nestimation in proximity and far-field estimation for consistent global\ntrajectories. Its adaptable front-end supports both stereo and omnidirectional\ncameras, catering to various operational needs and overcoming field-of-view\nchallenges in aerial swarms. Experiments demonstrate $D^2$SLAM's effectiveness\nin accurate ego-motion estimation, relative localization, and global\nconsistency. Enhanced by distributed optimization algorithms, $D^2$SLAM\nexhibits remarkable scalability and resilience to network delays, making it\nwell-suited for a wide range of real-world aerial swarm applications. The\nadaptability and proven performance of $D^2$SLAM represent a significant\nadvancement in autonomous aerial swarm technology.\n","authors":["Hao Xu","Peize Liu","Xinyi Chen","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2211.01538v4.pdf","comment":"Submitted to IEEE Transaction on Robotics"},{"id":"http://arxiv.org/abs/2406.16093v1","updated":"2024-06-23T12:14:37Z","published":"2024-06-23T12:14:37Z","title":"Towards Natural Language-Driven Assembly Using Foundation Models","summary":"  Large Language Models (LLMs) and strong vision models have enabled rapid\nresearch and development in the field of Vision-Language-Action models that\nenable robotic control. The main objective of these methods is to develop a\ngeneralist policy that can control robots with various embodiments. However, in\nindustrial robotic applications such as automated assembly and disassembly,\nsome tasks, such as insertion, demand greater accuracy and involve intricate\nfactors like contact engagement, friction handling, and refined motor skills.\nImplementing these skills using a generalist policy is challenging because\nthese policies might integrate further sensory data, including force or torque\nmeasurements, for enhanced precision. In our method, we present a global\ncontrol policy based on LLMs that can transfer the control policy to a finite\nset of skills that are specifically trained to perform high-precision tasks\nthrough dynamic context switching. The integration of LLMs into this framework\nunderscores their significance in not only interpreting and processing language\ninputs but also in enriching the control mechanisms for diverse and intricate\nrobotic operations.\n","authors":["Omkar Joglekar","Tal Lancewicki","Shir Kozlovsky","Vladimir Tchuiev","Zohar Feldman","Dotan Di Castro"],"pdf_url":"https://arxiv.org/pdf/2406.16093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16087v1","updated":"2024-06-23T12:02:17Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neural-Symbolic Learning\n  Framework for Robot Autonomy","summary":"  Data-driven methods such as reinforcement and imitation learning have\nachieved remarkable success in robot autonomy. However, their data-centric\nnature still hinders them from generalizing well to ever-changing environments.\nMoreover, collecting large datasets for robotic tasks is often impractical and\nexpensive. To overcome these challenges, we introduce a new self-supervised\nneural-symbolic (NeSy) computational framework, imperative learning (IL), for\nrobot autonomy, leveraging the generalization abilities of symbolic reasoning.\nThe framework of IL consists of three primary components: a neural module, a\nreasoning engine, and a memory system. We formulate IL as a special bilevel\noptimization (BLO), which enables reciprocal learning over the three modules.\nThis overcomes the label-intensive obstacles associated with data-driven\napproaches and takes advantage of symbolic reasoning concerning logical\nreasoning, physical principles, geometric analysis, etc. We discuss several\noptimization techniques for IL and verify their effectiveness in five distinct\nrobot autonomy tasks including path planning, rule induction, optimal control,\nvisual odometry, and multi-robot routing. Through various experiments, we show\nthat IL can significantly enhance robot autonomy capabilities and we anticipate\nthat it will catalyze further research across diverse domains.\n","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.16087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16138v2","updated":"2024-06-23T08:02:40Z","published":"2024-04-24T18:52:30Z","title":"Logic Learning from Demonstrations for Multi-step Manipulation Tasks in\n  Dynamic Environments","summary":"  Learning from Demonstration (LfD) stands as an efficient framework for\nimparting human-like skills to robots. Nevertheless, designing an LfD framework\ncapable of seamlessly imitating, generalizing, and reacting to disturbances for\nlong-horizon manipulation tasks in dynamic environments remains a challenge. To\ntackle this challenge, we present Logic Dynamic Movement Primitives\n(Logic-DMP), which combines Task and Motion Planning (TAMP) with an optimal\ncontrol formulation of DMP, allowing us to incorporate motion-level via-point\nspecifications and to handle task-level variations or disturbances in dynamic\nenvironments. We conduct a comparative analysis of our proposed approach\nagainst several baselines, evaluating its generalization ability and reactivity\nacross three long-horizon manipulation tasks. Our experiment demonstrates the\nfast generalization and reactivity of Logic-DMP for handling task-level\nvariants and disturbances in long-horizon manipulation tasks.\n","authors":["Yan Zhang","Teng Xue","Amirreza Razmjoo","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2404.16138v2.pdf","comment":"Accepted by IEEE RA-L"},{"id":"http://arxiv.org/abs/2401.04492v2","updated":"2024-06-23T06:16:09Z","published":"2024-01-09T11:12:29Z","title":"Augmented Reality and Human-Robot Collaboration Framework for\n  Percutaneous Nephrolithotomy: System Design, Implementation, and Performance\n  Metrics","summary":"  During Percutaneous Nephrolithotomy (PCNL) operations, the surgeon is\nrequired to define the incision point on the patient's back, align the needle\nto a pre-planned path, and perform puncture operations afterward. The procedure\nis currently performed manually using ultrasound or fluoroscopy imaging for\nneedle orientation, which, however, implies limited accuracy and low\nreproducibility. This work incorporates Augmented Reality (AR) visualization\nwith an optical see-through head-mounted display (OST-HMD) and Human-Robot\nCollaboration (HRC) framework to empower the surgeon's task completion\nperformance. In detail, Eye-to-Hand calibration, system registration, and\nhologram model registration are performed to realize visual guidance. A\nCartesian impedance controller is used to guide the operator during the needle\npuncture task execution. Experiments are conducted to verify the system\nperformance compared with conventional manual puncture procedures and a 2D\nmonitor-based visualisation interface. The results showed that the proposed\nframework achieves the lowest median and standard deviation error across all\nthe experimental groups, respectively. Furthermore, the NASA-TLX user\nevaluation results indicate that the proposed framework requires the lowest\nworkload score for task completion compared to other experimental setups. The\nproposed framework exhibits significant potential for clinical application in\nthe PCNL task, as it enhances the surgeon's perception capability, facilitates\ncollision-free needle insertion path planning, and minimises errors in task\ncompletion.\n","authors":["Junling Fu","Matteo Pecorella","Elisa Iovene","Maria Chiara Palumbo","Alberto Rota","Alberto Redaelli","Giancarlo Ferrigno","Elena De Momi"],"pdf_url":"https://arxiv.org/pdf/2401.04492v2.pdf","comment":"Accepted by IEEE Robotics and Automation Magazine"},{"id":"http://arxiv.org/abs/2302.08117v2","updated":"2024-06-23T04:37:15Z","published":"2023-02-16T06:46:36Z","title":"DDCNN: A Promising Tool for Simulation-To-Reality UAV Fault Diagnosis","summary":"  Identifying the fault in propellers is important to keep quadrotors operating\nsafely and efficiently. The simulation-to-reality (sim-to-real) UAV fault\ndiagnosis methods provide a cost-effective and safe approach to detecting\npropeller faults. However, due to the gap between simulation and reality,\nclassifiers trained with simulated data usually underperform in real flights.\nIn this work, a novel difference-based deep convolutional neural network\n(DDCNN) model is presented to address the above issue. It uses the difference\nfeatures extracted by deep convolutional neural networks to reduce the\nsim-to-real gap. Moreover, a new domain adaptation (DA) method is presented to\nfurther bring the distribution of the real-flight data closer to that of the\nsimulation data. The experimental results demonstrate that the DDCNN+DA model\ncan increase the accuracy from 52.9% to 99.1% in real-world UAV fault\ndetection.\n","authors":["Wei Zhang","Shanze Wang","Junjie Tong","Fang Liao","Yunfeng Zhang","Xiaoyu Shen"],"pdf_url":"https://arxiv.org/pdf/2302.08117v2.pdf","comment":"20xx IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, including\n  reprinting/republishing this material for advertising or promotional\n  purposes, collecting new collected works for resale or redistribution to\n  servers or lists, or reuse of any copyrighted component of this work in other\n  works"},{"id":"http://arxiv.org/abs/2406.16978v1","updated":"2024-06-23T15:30:40Z","published":"2024-06-23T15:30:40Z","title":"MetaFollower: Adaptable Personalized Autonomous Car Following","summary":"  Car-following (CF) modeling, a fundamental component in microscopic traffic\nsimulation, has attracted increasing interest of researchers in the past\ndecades. In this study, we propose an adaptable personalized car-following\nframework -MetaFollower, by leveraging the power of meta-learning.\nSpecifically, we first utilize Model-Agnostic Meta-Learning (MAML) to extract\ncommon driving knowledge from various CF events. Afterward, the pre-trained\nmodel can be fine-tuned on new drivers with only a few CF trajectories to\nachieve personalized CF adaptation. We additionally combine Long Short-Term\nMemory (LSTM) and Intelligent Driver Model (IDM) to reflect temporal\nheterogeneity with high interpretability. Unlike conventional adaptive cruise\ncontrol (ACC) systems that rely on predefined settings and constant parameters\nwithout considering heterogeneous driving characteristics, MetaFollower can\naccurately capture and simulate the intricate dynamics of car-following\nbehavior while considering the unique driving styles of individual drivers. We\ndemonstrate the versatility and adaptability of MetaFollower by showcasing its\nability to adapt to new drivers with limited training data quickly. To evaluate\nthe performance of MetaFollower, we conduct rigorous experiments comparing it\nwith both data-driven and physics-based models. The results reveal that our\nproposed framework outperforms baseline models in predicting car-following\nbehavior with higher accuracy and safety. To the best of our knowledge, this is\nthe first car-following model aiming to achieve fast adaptation by considering\nboth driver and temporal heterogeneity based on meta-learning.\n","authors":["Xianda Chen","Kehua Chen","Meixin Zhu"," Hao"," Yang","Shaojie Shen","Xuesong Wang","Yinhai Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16978v1.pdf","comment":null}]},"2024-06-25T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2406.17768v1","updated":"2024-06-25T17:50:03Z","published":"2024-06-25T17:50:03Z","title":"EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot\n  Skills from Offline Data","summary":"  Most reinforcement learning (RL) methods focus on learning optimal policies\nover low-level action spaces. While these methods can perform well in their\ntraining environments, they lack the flexibility to transfer to new tasks.\nInstead, RL agents that can act over useful, temporally extended skills rather\nthan low-level actions can learn new tasks more easily. Prior work in\nskill-based RL either requires expert supervision to define useful skills,\nwhich is hard to scale, or learns a skill-space from offline data with\nheuristics that limit the adaptability of the skills, making them difficult to\ntransfer during downstream RL. Our approach, EXTRACT, instead utilizes\npre-trained vision language models to extract a discrete set of semantically\nmeaningful skills from offline data, each of which is parameterized by\ncontinuous arguments, without human supervision. This skill parameterization\nallows robots to learn new tasks by only needing to learn when to select a\nspecific skill and how to modify its arguments for the specific task. We\ndemonstrate through experiments in sparse-reward, image-based, robot\nmanipulation environments that EXTRACT can more quickly learn new tasks than\nprior works, with major gains in sample efficiency and performance over prior\nskill-based RL. Website at https://www.jessezhang.net/projects/extract/.\n","authors":["Jesse Zhang","Minho Heo","Zuxin Liu","Erdem Biyik","Joseph J Lim","Yao Liu","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2406.17768v1.pdf","comment":"22 pages, 13 figures"},{"id":"http://arxiv.org/abs/2406.17764v1","updated":"2024-06-25T17:48:56Z","published":"2024-06-25T17:48:56Z","title":"BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context\n  Learning","summary":"  Large language models (LLMs) possess extensive parametric knowledge, but this\nknowledge is difficult to update with new information because retraining is\nvery expensive and infeasible for closed-source models. Knowledge editing (KE)\nhas emerged as a viable solution for updating the knowledge of LLMs without\ncompromising their overall performance. On-the-fly KE methods, inspired by\nin-context learning (ICL), have shown great promise and allow LLMs to be\ntreated as black boxes. In the past, KE was primarily employed in English\ncontexts, whereas the potential for cross-lingual KE in current English-centric\nLLMs has not been fully explored. To foster more research in this direction, we\nintroduce the BMIKE-53 benchmark for evaluating cross-lingual KE on 53 diverse\nlanguages across three KE task types. We also propose a gradient-free KE method\ncalled Multilingual In-context Knowledge Editing (MIKE) and evaluate it on\nBMIKE-53. Our evaluation focuses on cross-lingual knowledge transfer in terms\nof reliability, generality, locality, and portability, offering valuable\ninsights and a framework for future research in cross-lingual KE. Our code and\ndata are publicly accessible via the anonymous repository at\nhttps://anonymous.4open.science/r/MIKE.\n","authors":["Ercong Nie","Bo Shao","Zifeng Ding","Mingyang Wang","Helmut Schmid","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2406.17764v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.17763v1","updated":"2024-06-25T17:48:24Z","published":"2024-06-25T17:48:24Z","title":"DiffusionPDE: Generative PDE-Solving Under Partial Observation","summary":"  We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.\n","authors":["Jiahe Huang","Guandao Yang","Zichen Wang","Jeong Joon Park"],"pdf_url":"https://arxiv.org/pdf/2406.17763v1.pdf","comment":"Project page: https://jhhuangchloe.github.io/Diffusion-PDE/"},{"id":"http://arxiv.org/abs/2406.17762v1","updated":"2024-06-25T17:47:13Z","published":"2024-06-25T17:47:13Z","title":"Solving Hard Mizar Problems with Instantiation and Strategy Invention","summary":"  In this work, we prove over 3000 previously ATP-unproved Mizar/MPTP problems\nby using several ATP and AI methods, raising the number of ATP-solved Mizar\nproblems from 75\\% to above 80\\%. First, we start to experiment with the cvc5\nSMT solver which uses several instantiation-based heuristics that differ from\nthe superposition-based systems, that were previously applied to Mizar,and add\nmany new solutions. Then we use automated strategy invention to develop cvc5\nstrategies that largely improve cvc5's performance on the hard problems. In\nparticular, the best invented strategy solves over 14\\% more problems than the\nbest previously available cvc5 strategy. We also show that different\nclausification methods have a high impact on such instantiation-based methods,\nagain producing many new solutions. In total, the methods solve 3021 (21.3\\%)\nof the 14163 previously unsolved hard Mizar problems. This is a new milestone\nover the Mizar large-theory benchmark and a large strengthening of the hammer\nmethods for Mizar.\n","authors":["Jan Jakubův","Mikoláš Janota","Josef Urban"],"pdf_url":"https://arxiv.org/pdf/2406.17762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17761v1","updated":"2024-06-25T17:45:26Z","published":"2024-06-25T17:45:26Z","title":"CaLMQA: Exploring culturally specific long-form question answering\n  across 23 languages","summary":"  Large language models (LLMs) are commonly used for long-form question\nanswering, which requires them to generate paragraph-length answers to complex\nquestions. While long-form QA has been well-studied in English via many\ndifferent datasets and evaluation metrics, this research has not been extended\nto cover most other languages. To bridge this gap, we introduce CaLMQA, a\ncollection of 2.6K complex questions spanning 23 languages, including\nunder-resourced, rarely-studied languages such as Fijian and Kirundi. Our\ndataset includes both naturally-occurring questions collected from community\nweb forums as well as questions written by native speakers, whom we hire for\nthis purpose. Our process yields diverse, complex questions that reflect\ncultural topics (e.g. traditions, laws, news) and the language usage of native\nspeakers. We conduct automatic evaluation across a suite of open- and\nclosed-source models using our novel metric CaLMScore, which detects incorrect\nlanguage and token repetitions in answers, and observe that the quality of\nLLM-generated answers degrades significantly for some low-resource languages.\nWe perform human evaluation on a subset of models and see that model\nperformance is significantly worse for culturally specific questions than for\nculturally agnostic questions. Our findings highlight the need for further\nresearch in LLM multilingual capabilities and non-English LFQA evaluation.\n","authors":["Shane Arora","Marzena Karpinska","Hung-Ting Chen","Ipsita Bhattacharjee","Mohit Iyyer","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2406.17761v1.pdf","comment":"39 pages, 16 figures. Code and data available at\n  https://github.com/2015aroras/CaLMQA"},{"id":"http://arxiv.org/abs/2406.16793v2","updated":"2024-06-25T17:45:06Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the number of learning rates in Adam: Instead of assigning an\nindividual learning rate for each parameter using $1/\\sqrt{v}$, Adam-mini uses\nthe average of $v$ within a pre-defined parameter block as the learning rate\nfor that block. Such a design is inspired by two empirical findings. First, the\nHessian of Transformers exhibits a near-block diagonal structure with different\nsizes of dense sub-blocks. Second, for each of these dense sub-blocks, there\nexists a single high-quality learning rate that can outperform Adam, provided\nthat sufficient resources are available to search it out. Adam-mini provides\none cost-effective way to find these good learning rates and manage to cut down\n$\\geq$ 90% $v$ in Adam. Empirically, we verify that Adam-mini performs on par\nor better than AdamW on various language models sized from 125M to 7B for\npre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of\nAdam-mini also alleviates communication overheads among GPUs and CPUs, thereby\nincreasing throughput. For instance, Adam-mini achieves 49.6% higher throughput\nthan AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17753v1","updated":"2024-06-25T17:40:47Z","published":"2024-06-25T17:40:47Z","title":"Measuring and Benchmarking Large Language Models' Capabilities to\n  Generate Persuasive Language","summary":"  We are exposed to much information trying to influence us, such as teaser\nmessages, debates, politically framed news, and propaganda - all of which use\npersuasive language. With the recent interest in Large Language Models (LLMs),\nwe study the ability of LLMs to produce persuasive text. As opposed to prior\nwork which focuses on particular domains or types of persuasion, we conduct a\ngeneral study across various domains to measure and benchmark to what degree\nLLMs produce persuasive text - both when explicitly instructed to rewrite text\nto be more or less persuasive and when only instructed to paraphrase. To this\nend, we construct a new dataset, Persuasive-Pairs, of pairs each consisting of\na short text and of a text rewritten by an LLM to amplify or diminish\npersuasive language. We multi-annotate the pairs on a relative scale for\npersuasive language. This data is not only a valuable resource in itself, but\nwe also show that it can be used to train a regression model to predict a score\nof persuasive language between text pairs. This model can score and benchmark\nnew LLMs across domains, thereby facilitating the comparison of different LLMs.\nFinally, we discuss effects observed for different system prompts. Notably, we\nfind that different 'personas' in the system prompt of LLaMA3 change the\npersuasive language in the text substantially, even when only instructed to\nparaphrase. These findings underscore the importance of investigating\npersuasive language in LLM generated text.\n","authors":["Amalie Brogaard Pauli","Isabelle Augenstein","Ira Assent"],"pdf_url":"https://arxiv.org/pdf/2406.17753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17746v1","updated":"2024-06-25T17:32:16Z","published":"2024-06-25T17:32:16Z","title":"Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted\n  Phenomenon","summary":"  Memorization in language models is typically treated as a homogenous\nphenomenon, neglecting the specifics of the memorized data. We instead model\nmemorization as the effect of a set of complex factors that describe each\nsample and relate it to the model and corpus. To build intuition around these\nfactors, we break memorization down into a taxonomy: recitation of highly\nduplicated sequences, reconstruction of inherently predictable sequences, and\nrecollection of sequences that are neither. We demonstrate the usefulness of\nour taxonomy by using it to construct a predictive model for memorization. By\nanalyzing dependencies and inspecting the weights of the predictive model, we\nfind that different factors influence the likelihood of memorization\ndifferently depending on the taxonomic category.\n","authors":["USVSN Sai Prashanth","Alvin Deng","Kyle O'Brien","Jyothir S V","Mohammad Aflah Khan","Jaydeep Borkar","Christopher A. Choquette-Choo","Jacob Ray Fuehne","Stella Biderman","Tracy Ke","Katherine Lee","Naomi Saphra"],"pdf_url":"https://arxiv.org/pdf/2406.17746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17741v1","updated":"2024-06-25T17:28:03Z","published":"2024-06-25T17:28:03Z","title":"Point-SAM: Promptable 3D Segmentation Model for Point Clouds","summary":"  The development of 2D foundation models for image segmentation has been\nsignificantly advanced by the Segment Anything Model (SAM). However, achieving\nsimilar success in 3D models remains a challenge due to issues such as\nnon-unified data formats, lightweight models, and the scarcity of labeled data\nwith diverse masks. To this end, we propose a 3D promptable segmentation model\n(Point-SAM) focusing on point clouds. Our approach utilizes a transformer-based\nmethod, extending SAM to the 3D domain. We leverage part-level and object-level\nannotations and introduce a data engine to generate pseudo labels from SAM,\nthereby distilling 2D knowledge into our 3D model. Our model outperforms\nstate-of-the-art models on several indoor and outdoor benchmarks and\ndemonstrates a variety of applications, such as 3D annotation. Codes and demo\ncan be found at https://github.com/zyc00/Point-SAM.\n","authors":["Yuchen Zhou","Jiayuan Gu","Tung Yen Chiang","Fanbo Xiang","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2406.17741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17740v1","updated":"2024-06-25T17:26:05Z","published":"2024-06-25T17:26:05Z","title":"Structured Unrestricted-Rank Matrices for Parameter Efficient\n  Fine-tuning","summary":"  Recent efforts to scale Transformer models have demonstrated rapid progress\nacross a wide range of tasks (Wei et al., 2022). However, fine-tuning these\nmodels for downstream tasks is expensive due to their large parameter counts.\nParameter-efficient fine-tuning (PEFT) approaches have emerged as a viable\nalternative by allowing us to fine-tune models by updating only a small number\nof parameters. In this work, we propose a general framework for parameter\nefficient fine-tuning (PEFT), based on structured unrestricted-rank matrices\n(SURM) which can serve as a drop-in replacement for popular approaches such as\nAdapters and LoRA. Unlike other methods like LoRA, SURMs provides more\nflexibility in finding the right balance between compactness and\nexpressiveness. This is achieved by using low displacement rank matrices\n(LDRMs), which hasn't been used in this context before. SURMs remain\ncompetitive with baselines, often providing significant quality improvements\nwhile using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on\nvarious image classification tasks while replacing low-rank matrices in LoRA.\nIt also results in up to 12x reduction of the number of parameters in adapters\n(with virtually no loss in quality) on the GLUE benchmark.\n","authors":["Arijit Sehanobish","Avinava Dubey","Krzysztof Choromanski","Somnath Basu Roy Chowdhury","Deepali Jain","Vikas Sindhwani","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2406.17740v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.17739v1","updated":"2024-06-25T17:25:02Z","published":"2024-06-25T17:25:02Z","title":"Find Parent then Label Children: A Two-stage Taxonomy Completion Method\n  with Pre-trained Language Model","summary":"  Taxonomies, which organize domain concepts into hierarchical structures, are\ncrucial for building knowledge systems and downstream applications. As domain\nknowledge evolves, taxonomies need to be continuously updated to include new\nconcepts. Previous approaches have mainly focused on adding concepts to the\nleaf nodes of the existing hierarchical tree, which does not fully utilize the\ntaxonomy's knowledge and is unable to update the original taxonomy structure\n(usually involving non-leaf nodes). In this paper, we propose a two-stage\nmethod called ATTEMPT for taxonomy completion. Our method inserts new concepts\ninto the correct position by finding a parent node and labeling child nodes.\nSpecifically, by combining local nodes with prompts to generate natural\nsentences, we take advantage of pre-trained language models for\nhypernym/hyponymy recognition. Experimental results on two public datasets\n(including six domains) show that ATTEMPT performs best on both taxonomy\ncompletion and extension tasks, surpassing existing methods.\n","authors":["Fei Xia","Yixuan Weng","Shizhu He","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.17739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17737v1","updated":"2024-06-25T17:24:07Z","published":"2024-06-25T17:24:07Z","title":"LLM Targeted Underperformance Disproportionately Impacts Vulnerable\n  Users","summary":"  While state-of-the-art Large Language Models (LLMs) have shown impressive\nperformance on many tasks, there has been extensive research on undesirable\nmodel behavior such as hallucinations and bias. In this work, we investigate\nhow the quality of LLM responses changes in terms of information accuracy,\ntruthfulness, and refusals depending on three user traits: English proficiency,\neducation level, and country of origin. We present extensive experimentation on\nthree state-of-the-art LLMs and two different datasets targeting truthfulness\nand factuality. Our findings suggest that undesirable behaviors in\nstate-of-the-art LLMs occur disproportionately more for users with lower\nEnglish proficiency, of lower education status, and originating from outside\nthe US, rendering these models unreliable sources of information towards their\nmost vulnerable users.\n","authors":["Elinor Poole-Dayan","Deb Roy","Jad Kabbara"],"pdf_url":"https://arxiv.org/pdf/2406.17737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00716v2","updated":"2024-06-25T17:23:22Z","published":"2024-04-25T15:51:06Z","title":"Large Language Models in Healthcare: A Comprehensive Benchmark","summary":"  The adoption of large language models (LLMs) to assist clinicians has\nattracted remarkable attention. Existing works mainly adopt the close-ended\nquestion-answering (QA) task with answer options for evaluation. However, many\nclinical decisions involve answering open-ended questions without pre-set\noptions. To better understand LLMs in the clinic, we construct a benchmark\nClinicBench. We first collect eleven existing datasets covering diverse\nclinical language generation, understanding, and reasoning tasks. Furthermore,\nwe construct six novel datasets and complex clinical tasks that are close to\nreal-world practice, i.e., referral QA, treatment recommendation,\nhospitalization (long document) summarization, patient education, pharmacology\nQA and drug interaction for emerging drugs. We conduct an extensive evaluation\nof twenty-two LLMs under both zero-shot and few-shot settings. Finally, we\ninvite medical experts to evaluate the clinical usefulness of LLMs.\n","authors":["Andrew Liu","Hongjian Zhou","Yining Hua","Omid Rohanian","Anshul Thakur","Lei Clifton","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2405.00716v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15422v2","updated":"2024-06-25T17:02:10Z","published":"2024-02-23T16:32:28Z","title":"A Data-Centric Approach To Generate Faithful and High Quality Patient\n  Summaries with Large Language Models","summary":"  Patients often face difficulties in understanding their hospitalizations,\nwhile healthcare workers have limited resources to provide explanations. In\nthis work, we investigate the potential of large language models to generate\npatient summaries based on doctors' notes and study the effect of training data\non the faithfulness and quality of the generated summaries. To this end, we\nrelease (i) a rigorous labeling protocol for errors in medical texts and (ii) a\npublicly available dataset of annotated hallucinations in 100 doctor-written\nand 100 generated summaries. We show that fine-tuning on hallucination-free\ndata effectively reduces hallucinations from 2.60 to 1.55 per summary for Llama\n2, while preserving relevant information. We observe a similar effect on GPT-4\n(0.70 to 0.40), when the few-shot examples are hallucination-free. We also\nconduct a qualitative evaluation using hallucination-free and improved training\ndata. We find that common quantitative metrics do not correlate well with\nfaithfulness and quality. Finally, we test GPT-4 for automatic hallucination\ndetection, which clearly outperforms common baselines.\n","authors":["Stefan Hegselmann","Shannon Zejiang Shen","Florian Gierse","Monica Agrawal","David Sontag","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2402.15422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17714v1","updated":"2024-06-25T16:56:17Z","published":"2024-06-25T16:56:17Z","title":"Compositional Models for Estimating Causal Effects","summary":"  Many real-world systems can be represented as sets of interacting components.\nExamples of such systems include computational systems such as query\nprocessors, natural systems such as cells, and social systems such as families.\nMany approaches have been proposed in traditional (associational) machine\nlearning to model such structured systems, including statistical relational\nmodels and graph neural networks. Despite this prior work, existing approaches\nto estimating causal effects typically treat such systems as single units,\nrepresent them with a fixed set of variables and assume a homogeneous\ndata-generating process. We study a compositional approach for estimating\nindividual treatment effects (ITE) in structured systems, where each unit is\nrepresented by the composition of multiple heterogeneous components. This\napproach uses a modular architecture to model potential outcomes at each\ncomponent and aggregates component-level potential outcomes to obtain the\nunit-level potential outcomes. We discover novel benefits of the compositional\napproach in causal inference - systematic generalization to estimate\ncounterfactual outcomes of unseen combinations of components and improved\noverlap guarantees between treatment and control groups compared to the\nclassical methods for causal effect estimation. We also introduce a set of\nnovel environments for empirically evaluating the compositional approach and\ndemonstrate the effectiveness of our approach using both simulated and\nreal-world data.\n","authors":["Purva Pruthi","David Jensen"],"pdf_url":"https://arxiv.org/pdf/2406.17714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02652v2","updated":"2024-06-25T16:53:21Z","published":"2024-05-04T12:37:07Z","title":"Deep Pulse-Signal Magnification for remote Heart Rate Estimation in\n  Compressed Videos","summary":"  Recent advancements in data-driven approaches for remote photoplethysmography\n(rPPG) have significantly improved the accuracy of remote heart rate\nestimation. However, the performance of such approaches worsens considerably\nunder video compression, which is nevertheless necessary to store and transmit\nvideo data efficiently. In this paper, we present a novel approach to address\nthe impact of video compression on rPPG estimation, which leverages a\npulse-signal magnification transformation to adapt compressed videos to an\nuncompressed data domain in which the rPPG signal is magnified. We validate the\neffectiveness of our model by exhaustive evaluations on two publicly available\ndatasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database\nperformance at several compression rates. Additionally, we assess the\nrobustness of our approach on two additional highly compressed and widely-used\ndatasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate\nestimation results.\n","authors":["Joaquim Comas","Adria Ruiz","Federico Sukno"],"pdf_url":"https://arxiv.org/pdf/2405.02652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17711v1","updated":"2024-06-25T16:52:37Z","published":"2024-06-25T16:52:37Z","title":"Data curation via joint example selection further accelerates multimodal\n  learning","summary":"  Data curation is an essential component of large-scale pretraining. In this\nwork, we demonstrate that jointly selecting batches of data is more effective\nfor learning than selecting examples independently. Multimodal contrastive\nobjectives expose the dependencies between data and thus naturally yield\ncriteria for measuring the joint learnability of a batch. We derive a simple\nand tractable algorithm for selecting such batches, which significantly\naccelerate training beyond individually-prioritized data points. As performance\nimproves by selecting from larger super-batches, we also leverage recent\nadvances in model approximation to reduce the associated computational\noverhead. As a result, our approach--multimodal contrastive learning with joint\nexample selection (JEST)--surpasses state-of-the-art models with up to\n13$\\times$ fewer iterations and 10$\\times$ less computation. Essential to the\nperformance of JEST is the ability to steer the data selection process towards\nthe distribution of smaller, well-curated datasets via pretrained reference\nmodels, exposing the level of data curation as a new dimension for neural\nscaling laws.\n","authors":["Talfan Evans","Nikhil Parthasarathy","Hamza Merzic","Olivier J. Henaff"],"pdf_url":"https://arxiv.org/pdf/2406.17711v1.pdf","comment":"Main text: 9 pages, 5 figures, 3 tables, 1 algorithm. Appendix: 7\n  pages, 5 figures, 1 table, 2. algorithm"},{"id":"http://arxiv.org/abs/2406.17697v1","updated":"2024-06-25T16:33:33Z","published":"2024-06-25T16:33:33Z","title":"HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target\n  Binding Affinity Prediction","summary":"  Drug target binding affinity (DTA) is a key criterion for drug screening.\nExisting experimental methods are time-consuming and rely on limited structural\nand domain information. While learning-based methods can model sequence and\nstructural information, they struggle to integrate contextual data and often\nlack comprehensive modeling of drug-target interactions. In this study, we\npropose a novel DTA prediction method, termed HGTDP-DTA, which utilizes dynamic\nprompts within a hybrid Graph-Transformer framework. Our method generates\ncontext-specific prompts for each drug-target pair, enhancing the model's\nability to capture unique interactions. The introduction of prompt tuning\nfurther optimizes the prediction process by filtering out irrelevant noise and\nemphasizing task-relevant information, dynamically adjusting the input features\nof the molecular graph. The proposed hybrid Graph-Transformer architecture\ncombines structural information from Graph Convolutional Networks (GCNs) with\nsequence information captured by Transformers, facilitating the interaction\nbetween global and local information. Additionally, we adopted the multi-view\nfeature fusion method to project molecular graph views and affinity subgraph\nviews into a common feature space, effectively combining structural and\ncontextual information. Experiments on two widely used public datasets, Davis\nand KIBA, show that HGTDP-DTA outperforms state-of-the-art DTA prediction\nmethods in both prediction performance and generalization ability.\n","authors":["Xi Xiao","Wentao Wang","Jiacheng Xie","Lijing Zhu","Gaofei Chen","Zhengji Li","Tianyang Wang","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2406.17697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05905v2","updated":"2024-06-25T16:31:31Z","published":"2024-05-09T17:01:31Z","title":"Truthful Aggregation of LLMs with an Application to Online Advertising","summary":"  Online platforms generate hundreds of billions of dollars in revenue per year\nby showing advertisements alongside their own content. Currently, these\nplatforms are integrating Large Language Models (LLMs) into their services.\nThis makes revenue generation from LLM-generated content the next major\nchallenge in online advertising. We consider a scenario where advertisers aim\nto influence the responses of an LLM to align with their interests, while\nplatforms seek to maximize advertiser value and ensure user satisfaction. We\nintroduce an auction mechanism for this problem that operates without LLM\nfine-tuning or access to model weights and provably converges to the output of\nthe optimally fine-tuned LLM for the platform's objective as computational\nresources increase. Our mechanism ensures that truthful reporting is a dominant\nstrategy for advertisers and it aligns each advertiser's utility with their\ncontribution to social welfare - an essential feature for long-term viability.\nAdditionally, it can incorporate contextual information about the advertisers,\nsignificantly accelerating convergence. Via experiments with a publicly\navailable LLM, we show that our mechanism significantly boosts advertiser value\nand platform revenue, with low computational overhead. While our motivating\napplication is online advertising, our mechanism can be applied in any setting\nwith monetary transfers, making it a general-purpose solution for truthfully\naggregating the preferences of self-interested agents over LLM-generated\nreplies.\n","authors":["Ermis Soumalias","Michael J. Curry","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2405.05905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17688v1","updated":"2024-06-25T16:24:34Z","published":"2024-06-25T16:24:34Z","title":"Unified Auto-Encoding with Masked Diffusion","summary":"  At the core of both successful generative and self-supervised representation\nlearning models there is a reconstruction objective that incorporates some form\nof image corruption. Diffusion models implement this approach through a\nscheduled Gaussian corruption process, while masked auto-encoder models do so\nby masking patches of the image. Despite their different approaches, the\nunderlying similarity in their methodologies suggests a promising avenue for an\nauto-encoder capable of both de-noising tasks. We propose a unified\nself-supervised objective, dubbed Unified Masked Diffusion (UMD), that combines\npatch-based and noise-based corruption techniques within a single auto-encoding\nframework. Specifically, UMD modifies the diffusion transformer (DiT) training\nprocess by introducing an additional noise-free, high masking representation\nstep in the diffusion noising schedule, and utilizes a mixed masked and noised\nimage for subsequent timesteps. By integrating features useful for diffusion\nmodeling and for predicting masked patch tokens, UMD achieves strong\nperformance in downstream generative and representation learning tasks,\nincluding linear probing and class-conditional generation. This is achieved\nwithout the need for heavy data augmentations, multiple views, or additional\nencoders. Furthermore, UMD improves over the computational efficiency of prior\ndiffusion based methods in total training time. We release our code at\nhttps://github.com/philippe-eecs/small-vision.\n","authors":["Philippe Hansen-Estruch","Sriram Vishwanath","Amy Zhang","Manan Tomar"],"pdf_url":"https://arxiv.org/pdf/2406.17688v1.pdf","comment":"19 Pages, 8 Figures, 3Tables"},{"id":"http://arxiv.org/abs/2406.17663v1","updated":"2024-06-25T15:52:15Z","published":"2024-06-25T15:52:15Z","title":"LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic","summary":"  We introduce LLM-ARC, a neuro-symbolic framework designed to enhance the\nlogical reasoning capabilities of Large Language Models (LLMs), by combining\nthem with an Automated Reasoning Critic (ARC). LLM-ARC employs an Actor-Critic\nmethod where the LLM Actor generates declarative logic programs along with\ntests for semantic correctness, while the Automated Reasoning Critic evaluates\nthe code, runs the tests and provides feedback on test failures for iterative\nrefinement. Implemented using Answer Set Programming (ASP), LLM-ARC achieves a\nnew state-of-the-art accuracy of 88.32% on the FOLIO benchmark which tests\ncomplex logical reasoning capabilities. Our experiments demonstrate significant\nimprovements over LLM-only baselines, highlighting the importance of logic test\ngeneration and iterative self-refinement. We achieve our best result using a\nfully automated self-supervised training loop where the Actor is trained on\nend-to-end dialog traces with Critic feedback. We discuss potential\nenhancements and provide a detailed error analysis, showcasing the robustness\nand efficacy of LLM-ARC for complex natural language reasoning tasks.\n","authors":["Aditya Kalyanpur","Kailash Saravanakumar","Victor Barres","Jennifer Chu-Carroll","David Melville","David Ferrucci"],"pdf_url":"https://arxiv.org/pdf/2406.17663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17659v1","updated":"2024-06-25T15:49:47Z","published":"2024-06-25T15:49:47Z","title":"DKPROMPT: Domain Knowledge Prompting Vision-Language Models for\n  Open-World Planning","summary":"  Vision-language models (VLMs) have been applied to robot task planning\nproblems, where the robot receives a task in natural language and generates\nplans based on visual inputs. While current VLMs have demonstrated strong\nvision-language understanding capabilities, their performance is still far from\nbeing satisfactory in planning tasks. At the same time, although classical task\nplanners, such as PDDL-based, are strong in planning for long-horizon tasks,\nthey do not work well in open worlds where unforeseen situations are common. In\nthis paper, we propose a novel task planning and execution framework, called\nDKPROMPT, which automates VLM prompting using domain knowledge in PDDL for\nclassical planning in open worlds. Results from quantitative experiments show\nthat DKPROMPT outperforms classical planning, pure VLM-based and a few other\ncompetitive baselines in task completion rate.\n","authors":["Xiaohan Zhang","Zainab Altaweel","Yohei Hayamizu","Yan Ding","Saeid Amiri","Hao Yang","Andy Kaminski","Chad Esselink","Shiqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17654v1","updated":"2024-06-25T15:46:39Z","published":"2024-06-25T15:46:39Z","title":"MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for\n  Multi-View 3D Object Detection","summary":"  Multi-view 3D object detection is a crucial component of autonomous driving\nsystems. Contemporary query-based methods primarily depend either on\ndataset-specific initialization of 3D anchors, introducing bias, or utilize\ndense attention mechanisms, which are computationally inefficient and\nunscalable. To overcome these issues, we present MDHA, a novel sparse\nquery-based framework, which constructs adaptive 3D output proposals using\nhybrid anchors from multi-view, multi-scale input. Fixed 2D anchors are\ncombined with depth predictions to form 2.5D anchors, which are projected to\nobtain 3D proposals. To ensure high efficiency, our proposed Anchor Encoder\nperforms sparse refinement and selects the top-k anchors and features.\nMoreover, while existing multi-view attention mechanisms rely on projecting\nreference points to multiple images, our novel Circular Deformable Attention\nmechanism only projects to a single image but allows reference points to\nseamlessly attend to adjacent images, improving efficiency without compromising\non performance. On the nuScenes val set, it achieves 46.4% mAP and 55.0% NDS\nwith a ResNet101 backbone. MDHA significantly outperforms the baseline, where\nanchor proposals are modelled as learnable embeddings.\n","authors":["Michelle Adeline","Junn Yong Loo","Vishnu Monn Baskaran"],"pdf_url":"https://arxiv.org/pdf/2406.17654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17651v1","updated":"2024-06-25T15:43:20Z","published":"2024-06-25T15:43:20Z","title":"Leveraging Large Language Models for Software Model Completion: Results\n  from Industrial and Public Datasets","summary":"  Modeling structure and behavior of software systems plays a crucial role in\nthe industrial practice of software engineering. As with other software\nengineering artifacts, software models are subject to evolution. Supporting\nmodelers in evolving software models with recommendations for model completions\nis still an open problem, though. In this paper, we explore the potential of\nlarge language models for this task. In particular, we propose an approach,\nretrieval-augmented generation, leveraging large language models, model\nhistories, and retrieval-augmented generation for model completion. Through\nexperiments on three datasets, including an industrial application, one public\nopen-source community dataset, and one controlled collection of simulated model\nrepositories, we evaluate the potential of large language models for model\ncompletion with retrieval-augmented generation. We found that large language\nmodels are indeed a promising technology for supporting software model\nevolution (62.30% semantically correct completions on real-world industrial\ndata and up to 86.19% type-correct completions). The general inference\ncapabilities of large language models are particularly useful when dealing with\nconcepts for which there are few, noisy, or no examples at all.\n","authors":["Christof Tinnes","Alisa Welter","Sven Apel"],"pdf_url":"https://arxiv.org/pdf/2406.17651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17650v1","updated":"2024-06-25T15:41:40Z","published":"2024-06-25T15:41:40Z","title":"ELIZA Reinterpreted: The world's first chatbot was not intended as a\n  chatbot at all","summary":"  ELIZA, often considered the world's first chatbot, was written by Joseph\nWeizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot,\nbut rather to build a platform for research into human-machine conversation and\nthe important cognitive processes of interpretation and misinterpretation. His\npurpose was obscured by ELIZA's fame, resulting in large part from the\nfortuitous timing of it's creation, and it's escape into the wild. In this\npaper I provide a rich historical context for ELIZA's creation, demonstrating\nthat ELIZA arose from the intersection of some of the central threads in the\ntechnical history of AI. I also briefly discuss how ELIZA escaped into the\nworld, and how its accidental escape, along with several coincidental turns of\nthe programming language screws, led both to the misapprehension that ELIZA was\nintended as a chatbot, and to the loss of the original ELIZA to history for\nover 50 years.\n","authors":["Jeff Shrager"],"pdf_url":"https://arxiv.org/pdf/2406.17650v1.pdf","comment":"In review in IEEE Annals of the History of Computing (submitted Apr\n  2024)"},{"id":"http://arxiv.org/abs/2406.17642v1","updated":"2024-06-25T15:31:01Z","published":"2024-06-25T15:31:01Z","title":"Banishing LLM Hallucinations Requires Rethinking Generalization","summary":"  Despite their powerful chat, coding, and reasoning abilities, Large Language\nModels (LLMs) frequently hallucinate. Conventional wisdom suggests that\nhallucinations are a consequence of a balance between creativity and\nfactuality, which can be mitigated, but not eliminated, by grounding the LLM in\nexternal knowledge sources. Through extensive systematic experiments, we show\nthat these traditional approaches fail to explain why LLMs hallucinate in\npractice. Specifically, we show that LLMs augmented with a massive Mixture of\nMemory Experts (MoME) can easily memorize large datasets of random numbers. We\ncorroborate these experimental findings with a theoretical construction showing\nthat simple neural networks trained to predict the next token hallucinate when\nthe training loss is above a threshold as it usually does in practice when\ntraining on internet scale data. We interpret our findings by comparing against\ntraditional retrieval methods for mitigating hallucinations. We use our\nfindings to design a first generation model for removing hallucinations --\nLamini-1 -- that stores facts in a massive mixture of millions of memory\nexperts that are retrieved dynamically.\n","authors":["Johnny Li","Saksham Consul","Eda Zhou","James Wong","Naila Farooqui","Yuxin Ye","Nithyashree Manohar","Zhuxiaona Wei","Tian Wu","Ben Echols","Sharon Zhou","Gregory Diamos"],"pdf_url":"https://arxiv.org/pdf/2406.17642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17640v1","updated":"2024-06-25T15:24:06Z","published":"2024-06-25T15:24:06Z","title":"BayTTA: Uncertainty-aware medical image classification with optimized\n  test-time augmentation using Bayesian model averaging","summary":"  Test-time augmentation (TTA) is a well-known technique employed during the\ntesting phase of computer vision tasks. It involves aggregating multiple\naugmented versions of input data. Combining predictions using a simple average\nformulation is a common and straightforward approach after performing TTA. This\npaper introduces a novel framework for optimizing TTA, called BayTTA\n(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,\nwe generate a model list associated with different variations of the input data\ncreated through TTA. Then, we use BMA to combine model predictions weighted by\ntheir respective posterior probabilities. Such an approach allows one to take\ninto account model uncertainty, and thus to enhance the predictive performance\nof the related machine learning or deep learning model. We evaluate the\nperformance of BayTTA on various public data, including three medical image\ndatasets comprising skin cancer, breast cancer, and chest X-ray images and two\nwell-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental\nresults indicate that BayTTA can be effectively integrated into\nstate-of-the-art deep learning models used in medical image analysis as well as\ninto some popular pre-trained CNN models such as VGG-16, MobileNetV2,\nDenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in\ntheir accuracy and robustness performance.\n","authors":["Zeinab Sherkatghanad","Moloud Abdar","Mohammadreza Bakhtyari","Vladimir Makarenkov"],"pdf_url":"https://arxiv.org/pdf/2406.17640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v1","updated":"2024-06-25T15:24:02Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17636v1","updated":"2024-06-25T15:21:50Z","published":"2024-06-25T15:21:50Z","title":"Aligning Diffusion Models with Noise-Conditioned Perception","summary":"  Recent advancements in human preference optimization, initially developed for\nLanguage Models (LMs), have shown promise for text-to-image Diffusion Models,\nenhancing prompt alignment, visual appeal, and user preference. Unlike LMs,\nDiffusion Models typically optimize in pixel or VAE space, which does not align\nwell with human perception, leading to slower and less efficient training\nduring the preference alignment stage. We propose using a perceptual objective\nin the U-Net embedding space of the diffusion model to address these issues.\nOur approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct\nPreference Optimization (DPO), Contrastive Preference Optimization (CPO), and\nsupervised fine-tuning (SFT) within this embedding space. This method\nsignificantly outperforms standard latent-space implementations across various\nmetrics, including quality and computational cost. For SDXL, our approach\nprovides 60.8\\% general preference, 62.2\\% visual appeal, and 52.1\\% prompt\nfollowing against original open-sourced SDXL-DPO on the PartiPrompts dataset,\nwhile significantly reducing compute. Our approach not only improves the\nefficiency and quality of human preference alignment for diffusion models but\nis also easily integrable with other optimization techniques. The training code\nand LoRA weights will be available here:\nhttps://huggingface.co/alexgambashidze/SDXL\\_NCP-DPO\\_v0.1\n","authors":["Alexander Gambashidze","Anton Kulikov","Yuriy Sosnin","Ilya Makarov"],"pdf_url":"https://arxiv.org/pdf/2406.17636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17630v1","updated":"2024-06-25T15:17:01Z","published":"2024-06-25T15:17:01Z","title":"KANQAS: Kolmogorov Arnold Network for Quantum Architecture Search","summary":"  Quantum architecture search~(QAS) is a promising direction for optimization\nand automated design of quantum circuits towards quantum advantage. Recent\ntechniques in QAS focus on machine learning-based approaches from reinforcement\nlearning, like deep Q-network. While multi-layer perceptron-based deep\nQ-networks have been applied for QAS, their interpretability remains\nchallenging due to the high number of parameters. In this work, we evaluate the\npracticality of KANs in quantum architecture search problems, analyzing their\nefficiency in terms of the probability of success, frequency of optimal\nsolutions and their dependencies on various degrees of freedom of the network.\nIn a noiseless scenario, the probability of success and the number of optimal\nquantum circuit configurations to generate the multi-qubit maximally entangled\nstates are significantly higher than MLPs. Moreover in noisy scenarios, KAN can\nachieve a better fidelity in approximating maximally entangled state than MLPs,\nwhere the performance of the MLP significantly depends on the choice of\nactivation function. Further investigation reveals that KAN requires a very\nsmall number of learnable parameters compared to MLPs, however, the average\ntime of executing each episode for KAN is much higher.\n","authors":["Akash Kundu","Aritra Sarkar","Abhishek Sadhu"],"pdf_url":"https://arxiv.org/pdf/2406.17630v1.pdf","comment":"10 pages and 4 figures"},{"id":"http://arxiv.org/abs/2406.17626v1","updated":"2024-06-25T15:13:02Z","published":"2024-06-25T15:13:02Z","title":"CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue\n  Coreference","summary":"  As large language models (LLMs) constantly evolve, ensuring their safety\nremains a critical research problem. Previous red-teaming approaches for LLM\nsafety have primarily focused on single prompt attacks or goal hijacking. To\nthe best of our knowledge, we are the first to study LLM safety in multi-turn\ndialogue coreference. We created a dataset of 1,400 questions across 14\ncategories, each featuring multi-turn coreference safety attacks. We then\nconducted detailed evaluations on five widely used open-source LLMs. The\nresults indicated that under multi-turn coreference safety attacks, the highest\nattack success rate was 56% with the LLaMA2-Chat-7b model, while the lowest was\n13.9% with the Mistral-7B-Instruct model. These findings highlight the safety\nvulnerabilities in LLMs during dialogue coreference interactions.\n","authors":["Erxin Yu","Jing Li","Ming Liao","Siqi Wang","Zuchen Gao","Fei Mi","Lanqing Hong"],"pdf_url":"https://arxiv.org/pdf/2406.17626v1.pdf","comment":"Submitted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.14343v3","updated":"2024-06-25T15:12:01Z","published":"2024-06-20T14:09:54Z","title":"iWISDM: Assessing instruction following in multimodal models at scale","summary":"  The ability to perform complex tasks from detailed instructions is a key to\nmany remarkable achievements of our species. As humans, we are not only capable\nof performing a wide variety of tasks but also very complex ones that may\nentail hundreds or thousands of steps to complete. Large language models and\ntheir more recent multimodal counterparts that integrate textual and visual\ninputs have achieved unprecedented success in performing complex tasks. Yet,\nmost existing benchmarks are largely confined to single-modality inputs (either\ntext or vision), narrowing the scope of multimodal assessments, particularly\nfor instruction-following in multimodal contexts. To bridge this gap, we\nintroduce the instructed-Virtual VISual Decision Making (iWISDM) environment\nengineered to generate a limitless array of vision-language tasks of varying\ncomplexity. Using iWISDM, we compiled three distinct benchmarks of instruction\nfollowing visual tasks across varying complexity levels and evaluated several\nnewly developed multimodal models on these benchmarks. Our findings establish\niWISDM as a robust benchmark for assessing the instructional adherence of both\nexisting and emergent multimodal models and highlight a large gap between these\nmodels' ability to precisely follow instructions with that of humans.The code\nof iWISDM is available on GitHub at https://github.com/BashivanLab/iWISDM.\n","authors":["Xiaoxuan Lei","Lucas Gomez","Hao Yuan Bai","Pouya Bashivan"],"pdf_url":"https://arxiv.org/pdf/2406.14343v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17624v1","updated":"2024-06-25T15:08:44Z","published":"2024-06-25T15:08:44Z","title":"Self-assessment, Exhibition, and Recognition: a Review of Personality in\n  Large Language Models","summary":"  As large language models (LLMs) appear to behave increasingly human-like in\ntext-based interactions, more and more researchers become interested in\ninvestigating personality in LLMs. However, the diversity of psychological\npersonality research and the rapid development of LLMs have led to a broad yet\nfragmented landscape of studies in this interdisciplinary field. Extensive\nstudies across different research focuses, different personality psychometrics,\nand different LLMs make it challenging to have a holistic overview and further\npose difficulties in applying findings to real-world applications. In this\npaper, we present a comprehensive review by categorizing current studies into\nthree research problems: self-assessment, exhibition, and recognition, based on\nthe intrinsic characteristics and external manifestations of personality in\nLLMs. For each problem, we provide a thorough analysis and conduct in-depth\ncomparisons of their corresponding solutions. Besides, we summarize research\nfindings and open challenges from current studies and further discuss their\nunderlying causes. We also collect extensive publicly available resources to\nfacilitate interested researchers and developers. Lastly, we discuss the\npotential future research directions and application scenarios. Our paper is\nthe first comprehensive survey of up-to-date literature on personality in LLMs.\nBy presenting a clear taxonomy, in-depth analysis, promising future directions,\nand extensive resource collections, we aim to provide a better understanding\nand facilitate further advancements in this emerging field.\n","authors":["Zhiyuan Wen","Yu Yang","Jiannong Cao","Haoming Sun","Ruosong Yang","Shuaiqi Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13069v2","updated":"2024-06-25T15:02:40Z","published":"2024-06-18T21:31:19Z","title":"Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG","summary":"  How novel are texts generated by language models (LMs) relative to their\ntraining corpora? In this work, we investigate the extent to which modern LMs\ngenerate $n$-grams from their training data, evaluating both (i) the\nprobability LMs assign to complete training $n$-grams and (ii) $n$-novelty, the\nproportion of $n$-grams generated by an LM that did not appear in the training\ndata (for arbitrarily large $n$). To enable arbitrary-length $n$-gram search\nover a corpus in constant time, we develop Rusty-DAWG, a novel search tool\ninspired by indexing of genomic data. We compare the novelty of LM-generated\ntext to human-written text and explore factors that affect generation novelty,\nfocusing on the Pythia models. We find that, for $n > 4$, LM-generated text is\nless novel than human-written text, though it is more novel for smaller $n$.\nLarger LMs and more constrained decoding strategies both decrease novelty.\nFinally, we show that LMs complete $n$-grams with lower loss if they are more\nfrequent in the training data. Overall, our results reveal factors influencing\nthe novelty of LM-generated text, and we release Rusty-DAWG to facilitate\nfurther pretraining data research.\n","authors":["William Merrill","Noah A. Smith","Yanai Elazar"],"pdf_url":"https://arxiv.org/pdf/2406.13069v2.pdf","comment":"8 page preprint + appendix. Minor fixes and appendix changes June 25,\n  2024"},{"id":"http://arxiv.org/abs/2406.17615v1","updated":"2024-06-25T15:01:39Z","published":"2024-06-25T15:01:39Z","title":"Aligning Programming Language and Natural Language: Exploring Design\n  Choices in Multi-Modal Transformer-Based Embedding for Bug Localization","summary":"  Bug localization refers to the identification of source code files which is\nin a programming language and also responsible for the unexpected behavior of\nsoftware using the bug report, which is a natural language. As bug localization\nis labor-intensive, bug localization models are employed to assist software\ndevelopers. Due to the domain difference between source code files and bug\nreports, modern bug-localization systems, based on deep learning models, rely\nheavily on embedding techniques that project bug reports and source code files\ninto a shared vector space. The creation of an embedding involves several\ndesign choices, but the impact of these choices on the quality of embedding and\nthe performance of bug localization models remains unexplained in current\nresearch.\n  To address this gap, our study evaluated 14 distinct embedding models to gain\ninsights into the effects of various design choices. Subsequently, we developed\nbug localization models utilizing these embedding models to assess the\ninfluence of these choices on the performance of the localization models. Our\nfindings indicate that the pre-training strategies significantly affect the\nquality of the embedding. Moreover, we discovered that the familiarity of the\nembedding models with the data has a notable impact on the bug localization\nmodel's performance. Notably, when the training and testing data are collected\nfrom different projects, the performance of the bug localization models\nexhibits substantial fluctuations.\n","authors":["Partha Chakraborty","Venkatraman Arumugam","Meiyappan Nagappan"],"pdf_url":"https://arxiv.org/pdf/2406.17615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17606v1","updated":"2024-06-25T14:48:28Z","published":"2024-06-25T14:48:28Z","title":"Diffusion-based Adversarial Purification for Intrusion Detection","summary":"  The escalating sophistication of cyberattacks has encouraged the integration\nof machine learning techniques in intrusion detection systems, but the rise of\nadversarial examples presents a significant challenge. These crafted\nperturbations mislead ML models, enabling attackers to evade detection or\ntrigger false alerts. As a reaction, adversarial purification has emerged as a\ncompelling solution, particularly with diffusion models showing promising\nresults. However, their purification potential remains unexplored in the\ncontext of intrusion detection. This paper demonstrates the effectiveness of\ndiffusion models in purifying adversarial examples in network intrusion\ndetection. Through a comprehensive analysis of the diffusion parameters, we\nidentify optimal configurations maximizing adversarial robustness with minimal\nimpact on normal performance. Importantly, this study reveals insights into the\nrelationship between diffusion noise and diffusion steps, representing a novel\ncontribution to the field. Our experiments are carried out on two datasets and\nagainst 5 adversarial attacks. The implementation code is publicly available.\n","authors":["Mohamed Amine Merzouk","Erwan Beurier","Reda Yaich","Nora Boulahia-Cuppens","Frédéric Cuppens"],"pdf_url":"https://arxiv.org/pdf/2406.17606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.09470v2","updated":"2024-06-25T14:36:33Z","published":"2023-03-16T16:43:24Z","title":"Learning with Noisy Labels through Learnable Weighting and Centroid\n  Similarity","summary":"  We introduce a novel method for training machine learning models in the\npresence of noisy labels, which are prevalent in domains such as medical\ndiagnosis and autonomous driving and have the potential to degrade a model's\ngeneralization performance. Inspired by established literature that highlights\nhow deep learning models are prone to overfitting to noisy samples in the later\nepochs of training, we propose a strategic approach. This strategy leverages\nthe distance to class centroids in the latent space and incorporates a\ndiscounting mechanism, aiming to diminish the influence of samples that lie\ndistant from all class centroids. By doing so, we effectively counteract the\nadverse effects of noisy labels. The foundational premise of our approach is\nthe assumption that samples situated further from their respective class\ncentroid in the initial stages of training are more likely to be associated\nwith noise. Our methodology is grounded in robust theoretical principles and\nhas been validated empirically through extensive experiments on several\nbenchmark datasets. Our results show that our method consistently outperforms\nthe existing state-of-the-art techniques, achieving significant improvements in\nclassification accuracy in the presence of noisy labels. The code for our\nproposed loss function and supplementary materials is available at\nhttps://github.com/wanifarooq/NCOD\n","authors":["Farooq Ahmad Wani","Maria Sofia Bucarelli","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2303.09470v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17583v1","updated":"2024-06-25T14:27:03Z","published":"2024-06-25T14:27:03Z","title":"Towards Compositional Interpretability for XAI","summary":"  Artificial intelligence (AI) is currently based largely on black-box machine\nlearning models which lack interpretability. The field of eXplainable AI (XAI)\nstrives to address this major concern, being critical in high-stakes areas such\nas the finance, legal and health sectors.\n  We present an approach to defining AI models and their interpretability based\non category theory. For this we employ the notion of a compositional model,\nwhich sees a model in terms of formal string diagrams which capture its\nabstract structure together with its concrete implementation. This\ncomprehensive view incorporates deterministic, probabilistic and quantum\nmodels. We compare a wide range of AI models as compositional models, including\nlinear and rule-based models, (recurrent) neural networks, transformers, VAEs,\nand causal and DisCoCirc models.\n  Next we give a definition of interpretation of a model in terms of its\ncompositional structure, demonstrating how to analyse the interpretability of a\nmodel, and using this to clarify common themes in XAI. We find that what makes\nthe standard 'intrinsically interpretable' models so transparent is brought out\nmost clearly diagrammatically. This leads us to the more general notion of\ncompositionally-interpretable (CI) models, which additionally include, for\ninstance, causal, conceptual space, and DisCoCirc models.\n  We next demonstrate the explainability benefits of CI models. Firstly, their\ncompositional structure may allow the computation of other quantities of\ninterest, and may facilitate inference from the model to the modelled\nphenomenon by matching its structure. Secondly, they allow for diagrammatic\nexplanations for their behaviour, based on influence constraints, diagram\nsurgery and rewrite explanations. Finally, we discuss many future directions\nfor the approach, raising the question of how to learn such meaningfully\nstructured models in practice.\n","authors":["Sean Tull","Robin Lorenz","Stephen Clark","Ilyas Khan","Bob Coecke"],"pdf_url":"https://arxiv.org/pdf/2406.17583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17576v1","updated":"2024-06-25T14:16:40Z","published":"2024-06-25T14:16:40Z","title":"Leveraging Reinforcement Learning in Red Teaming for Advanced Ransomware\n  Attack Simulations","summary":"  Ransomware presents a significant and increasing threat to individuals and\norganizations by encrypting their systems and not releasing them until a large\nfee has been extracted. To bolster preparedness against potential attacks,\norganizations commonly conduct red teaming exercises, which involve simulated\nattacks to assess existing security measures. This paper proposes a novel\napproach utilizing reinforcement learning (RL) to simulate ransomware attacks.\nBy training an RL agent in a simulated environment mirroring real-world\nnetworks, effective attack strategies can be learned quickly, significantly\nstreamlining traditional, manual penetration testing processes. The attack\npathways revealed by the RL agent can provide valuable insights to the defense\nteam, helping them identify network weak points and develop more resilient\ndefensive measures. Experimental results on a 152-host example network confirm\nthe effectiveness of the proposed approach, demonstrating the RL agent's\ncapability to discover and orchestrate attacks on high-value targets while\nevading honeyfiles (decoy files strategically placed to detect unauthorized\naccess).\n","authors":["Cheng Wang","Christopher Redino","Ryan Clark","Abdul Rahman","Sal Aguinaga","Sathvik Murli","Dhruv Nandakumar","Roland Rao","Lanxiao Huang","Daniel Radke","Edward Bowen"],"pdf_url":"https://arxiv.org/pdf/2406.17576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17563v1","updated":"2024-06-25T14:00:42Z","published":"2024-06-25T14:00:42Z","title":"Multi-property Steering of Large Language Models with Dynamic Activation\n  Composition","summary":"  Activation steering methods were shown to be effective in conditioning\nlanguage model generation by additively intervening over models' intermediate\nrepresentations. However, the evaluation of these techniques has so far been\nlimited to single conditioning properties and synthetic settings. In this work,\nwe conduct a comprehensive evaluation of various activation steering\nstrategies, highlighting the property-dependent nature of optimal parameters to\nensure a robust effect throughout generation. To address this issue, we propose\nDynamic Activation Composition, an information-theoretic approach to modulate\nthe steering intensity of one or more properties throughout generation. Our\nexperiments on multi-property steering show that our method successfully\nmaintains high conditioning while minimizing the impact of conditioning on\ngeneration fluency.\n","authors":["Daniel Scalena","Gabriele Sarti","Malvina Nissim"],"pdf_url":"https://arxiv.org/pdf/2406.17563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14425v2","updated":"2024-06-25T13:48:41Z","published":"2024-06-20T15:49:28Z","title":"SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource\n  Languages","summary":"  Question Answering (QA) datasets have been instrumental in developing and\nevaluating Large Language Model (LLM) capabilities. However, such datasets are\nscarce for languages other than English due to the cost and difficulties of\ncollection and manual annotation. This means that producing novel models and\nmeasuring the performance of multilingual LLMs in low-resource languages is\nchallenging. To mitigate this, we propose $\\textbf{S}$yn$\\textbf{DAR}$in, a\nmethod for generating and validating QA datasets for low-resource languages. We\nutilize parallel content mining to obtain $\\textit{human-curated}$ paragraphs\nbetween English and the target language. We use the English data as context to\n$\\textit{generate}$ synthetic multiple-choice (MC) question-answer pairs, which\nare automatically translated and further validated for quality. Combining these\nwith their designated non-English $\\textit{human-curated}$ paragraphs form the\nfinal QA dataset. The method allows to maintain the content quality, reduces\nthe likelihood of factual errors, and circumvents the need for costly\nannotation. To test the method, we created a QA dataset with $1.2$K samples for\nthe Armenian language. The human evaluation shows that $98\\%$ of the generated\nEnglish data maintains quality and diversity in the question types and topics,\nwhile the translation validation pipeline can filter out $\\sim70\\%$ of data\nwith poor quality. We use the dataset to benchmark state-of-the-art LLMs,\nshowing their inability to achieve human accuracy with some model performances\ncloser to random chance. This shows that the generated dataset is non-trivial\nand can be used to evaluate reasoning capabilities in low-resource language.\n","authors":["Gayane Ghazaryan","Erik Arakelyan","Pasquale Minervini","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2406.14425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16797v2","updated":"2024-06-25T13:46:41Z","published":"2024-06-24T16:58:23Z","title":"Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs","summary":"  Existing methods for adapting large language models (LLMs) to new tasks are\nnot suited to multi-task adaptation because they modify all the model weights\n-- causing destructive interference between tasks. The resulting effects, such\nas catastrophic forgetting of earlier tasks, make it challenging to obtain good\nperformance on multiple tasks at the same time. To mitigate this, we propose\nLottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies\nand optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide\nrange of challenging tasks such as instruction following, reasoning, math, and\nsummarization. LoTA obtains better performance than full fine-tuning and\nlow-rank adaptation (LoRA), and maintains good performance even after training\non other tasks -- thus, avoiding catastrophic forgetting. By extracting and\nfine-tuning over lottery tickets (or sparse task vectors), LoTA also enables\nmodel merging over highly dissimilar tasks. Our code is made publicly available\nat https://github.com/kiddyboots216/lottery-ticket-adaptation.\n","authors":["Ashwinee Panda","Berivan Isik","Xiangyu Qi","Sanmi Koyejo","Tsachy Weissman","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2406.16797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12036v2","updated":"2024-06-25T13:45:49Z","published":"2024-06-17T19:07:21Z","title":"MedCalc-Bench: Evaluating Large Language Models for Medical Calculations","summary":"  As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.\n","authors":["Nikhil Khandekar","Qiao Jin","Guangzhi Xiong","Soren Dunn","Serina S Applebaum","Zain Anwar","Maame Sarfo-Gyamfi","Conrad W Safranek","Abid A Anwar","Andrew Zhang","Aidan Gilson","Maxwell B Singer","Amisha Dave","Andrew Taylor","Aidong Zhang","Qingyu Chen","Zhiyong Lu"],"pdf_url":"https://arxiv.org/pdf/2406.12036v2.pdf","comment":"Github link: https://github.com/ncbi-nlp/MedCalc-Bench HuggingFace\n  link: https://huggingface.co/datasets/nsk7153/MedCalc-Bench"},{"id":"http://arxiv.org/abs/2402.11253v3","updated":"2024-06-25T13:39:52Z","published":"2024-02-17T11:25:26Z","title":"Aligning Large Language Models by On-Policy Self-Judgment","summary":"  Existing approaches for aligning large language models with human preferences\nface a trade-off that requires a separate reward model (RM) for on-policy\nlearning. In this paper, we present a novel alignment framework, SELF-JUDGE\nthat (1) does on-policy learning and 2) is parameter efficient, as it does not\nrequire an additional RM for evaluating the samples for on-policy learning. To\nthis end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a\nsingle model to act as both a policy and a judge. Specifically, we view the\npairwise judgment task, choosing the better response from a response pair, as a\nspecial case of the instruction-following task. The resulting model can judge\npreferences of on-the-fly responses from current policy initialized from\nitself. Experimental results show the efficacy of SELF-JUDGE, outperforming\nbaselines in preference benchmarks. We also show that the rejecting sampling by\nitself can improve performance further without an additional evaluator.\n","authors":["Sangkyu Lee","Sungdong Kim","Ashkan Yousefpour","Minjoon Seo","Kang Min Yoo","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2402.11253v3.pdf","comment":"Published as a main conference paper at ACL 2024"},{"id":"http://arxiv.org/abs/2402.14762v2","updated":"2024-06-25T13:38:41Z","published":"2024-02-22T18:21:59Z","title":"MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language\n  Models in Multi-Turn Dialogues","summary":"  The advent of Large Language Models (LLMs) has drastically enhanced dialogue\nsystems. However, comprehensively evaluating the dialogue abilities of LLMs\nremains a challenge. Previous benchmarks have primarily focused on single-turn\ndialogues or provided coarse-grained and incomplete assessments of multi-turn\ndialogues, overlooking the complexity and fine-grained nuances of real-life\ndialogues. To address this issue, we introduce MT-Bench-101, specifically\ndesigned to evaluate the fine-grained abilities of LLMs in multi-turn\ndialogues. By conducting a detailed analysis of real multi-turn dialogue data,\nwe construct a three-tier hierarchical ability taxonomy comprising 4208 turns\nacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21\npopular LLMs based on MT-Bench-101, conducting comprehensive analyses from both\nability and task perspectives and observing differing trends in LLMs\nperformance across dialogue turns within various tasks. Further analysis\nindicates that neither utilizing common alignment techniques nor chat-specific\ndesigns has led to obvious enhancements in the multi-turn abilities of LLMs.\nExtensive case studies suggest that our designed tasks accurately assess the\ncorresponding multi-turn abilities. The data and code are available at\n\\url{https://github.com/mtbench101/mt-bench-101}.\n","authors":["Ge Bai","Jie Liu","Xingyuan Bu","Yancheng He","Jiaheng Liu","Zhanhui Zhou","Zhuoran Lin","Wenbo Su","Tiezheng Ge","Bo Zheng","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2402.14762v2.pdf","comment":"[ACL 2024] The first three authors contribute equally, 34 pages, repo\n  at https://github.com/mtbench101/mt-bench-101"},{"id":"http://arxiv.org/abs/2406.17542v1","updated":"2024-06-25T13:29:14Z","published":"2024-06-25T13:29:14Z","title":"CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained\n  Models using Greedy Coordinate Descent","summary":"  Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses coordinate descent to minimize the\nlayer-wise reconstruction loss to achieve high-quality quantized weights. Our\nalgorithm is easy to implement and scales efficiently to models with hundreds\nof billions of parameters. Through extensive evaluation on the PaLM2 model\nfamily, we demonstrate that CDQuant consistently outperforms GPTQ across\ndiverse model sizes and quantization levels. In particular, for INT2\nquantization of PaLM2-Otter, CDQuant achieves a 10% reduction in perplexity\ncompared to GPTQ.\n","authors":["Pranav Ajit Nair","Arun Sai Suggala"],"pdf_url":"https://arxiv.org/pdf/2406.17542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09346v2","updated":"2024-06-25T13:25:08Z","published":"2024-06-13T17:31:02Z","title":"Scoreformer: A Surrogate Model For Large-Scale Prediction of Docking\n  Scores","summary":"  In this study, we present ScoreFormer, a novel graph transformer model\ndesigned to accurately predict molecular docking scores, thereby optimizing\nhigh-throughput virtual screening (HTVS) in drug discovery. The architecture\nintegrates Principal Neighborhood Aggregation (PNA) and Learnable Random Walk\nPositional Encodings (LRWPE), enhancing the model's ability to understand\ncomplex molecular structures and their relationship with their respective\ndocking scores. This approach significantly surpasses traditional HTVS methods\nand recent Graph Neural Network (GNN) models in both recovery and efficiency\ndue to a wider coverage of the chemical space and enhanced performance. Our\nresults demonstrate that ScoreFormer achieves competitive performance in\ndocking score prediction and offers a substantial 1.65-fold reduction in\ninference time compared to existing models. We evaluated ScoreFormer across\nmultiple datasets under various conditions, confirming its robustness and\nreliability in identifying potential drug candidates rapidly.\n","authors":["Álvaro Ciudad","Adrián Morales-Pastor","Laura Malo","Isaac Filella-Mercè","Victor Guallar","Alexis Molina"],"pdf_url":"https://arxiv.org/pdf/2406.09346v2.pdf","comment":"Accepted at the 1st Machine Learning for Life and Material Sciences\n  Workshop at ICML 2024"},{"id":"http://arxiv.org/abs/2406.17537v1","updated":"2024-06-25T13:21:01Z","published":"2024-06-25T13:21:01Z","title":"SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using\n  SincNet and Variational Autoencoder","summary":"  Over the past few decades, electroencephalography (EEG) monitoring has become\na pivotal tool for diagnosing neurological disorders, particularly for\ndetecting seizures. Epilepsy, one of the most prevalent neurological diseases\nworldwide, affects approximately the 1 \\% of the population. These patients\nface significant risks, underscoring the need for reliable, continuous seizure\nmonitoring in daily life. Most of the techniques discussed in the literature\nrely on supervised Machine Learning (ML) methods. However, the challenge of\naccurately labeling variations in epileptic EEG waveforms complicates the use\nof these approaches. Additionally, the rarity of ictal events introduces an\nhigh imbalancing within the data, which could lead to poor prediction\nperformance in supervised learning approaches. Instead, a semi-supervised\napproach allows to train the model only on data not containing seizures, thus\navoiding the issues related to the data imbalancing. This work proposes a\nsemi-supervised approach for detecting epileptic seizures from EEG data,\nutilizing a novel Deep Learning-based method called SincVAE. This proposal\nincorporates the learning of an ad-hoc array of bandpass filter as a first\nlayer of a Variational Autoencoder (VAE), potentially eliminating the\npreprocessing stage where informative band frequencies are identified and\nisolated. Results indicate that SincVAE improves seizure detection in EEG data\nand is capable of identifying early seizures during the preictal stage as well\nas monitoring patients throughout the postictal stage.\n","authors":["Andrea Pollastro","Francesco Isgrò","Roberto Prevete"],"pdf_url":"https://arxiv.org/pdf/2406.17537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17535v1","updated":"2024-06-25T13:20:08Z","published":"2024-06-25T13:20:08Z","title":"Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian\n  Benchmark","summary":"  Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to generate and manipulate human language, highlighting\ntheir potential across various applications. Evaluating LLMs in languages other\nthan English is crucial for ensuring their linguistic versatility, cultural\nrelevance, and applicability in diverse global contexts, thus broadening their\nusability and effectiveness. We tackle this challenge by introducing a\nstructured benchmark using the INVALSI tests, a set of well-established\nassessments designed to measure educational competencies across Italy. Our\nstudy makes three primary contributions: Firstly, we adapt the INVALSI\nbenchmark for automated LLM evaluation, which involves rigorous adaptation of\nthe test format to suit automated processing while retaining the essence of the\noriginal tests. Secondly, we provide a detailed assessment of current LLMs,\noffering a crucial reference point for the academic community. Finally, we\nvisually compare the performance of these models against human results.\nAdditionally, researchers are invited to submit their models for ongoing\nevaluation, ensuring the benchmark remains a current and valuable resource.\n","authors":["Fabio Mercorio","Mario Mezzanzanica","Daniele Potertì","Antonio Serino","Andrea Seveso"],"pdf_url":"https://arxiv.org/pdf/2406.17535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17532v1","updated":"2024-06-25T13:16:34Z","published":"2024-06-25T13:16:34Z","title":"Can Large Language Models Understand DL-Lite Ontologies? An Empirical\n  Study","summary":"  Large language models (LLMs) have shown significant achievements in solving a\nwide range of tasks. Recently, LLMs' capability to store, retrieve and infer\nwith symbolic knowledge has drawn a great deal of attention, showing their\npotential to understand structured information. However, it is not yet known\nwhether LLMs can understand Description Logic (DL) ontologies. In this work, we\nempirically analyze the LLMs' capability of understanding DL-Lite ontologies\ncovering 6 representative tasks from syntactic and semantic aspects. With\nextensive experiments, we demonstrate both the effectiveness and limitations of\nLLMs in understanding DL-Lite ontologies. We find that LLMs can understand\nformal syntax and model-theoretic semantics of concepts and roles. However,\nLLMs struggle with understanding TBox NI transitivity and handling ontologies\nwith large ABoxes. We hope that our experiments and analyses provide more\ninsights into LLMs and inspire to build more faithful knowledge engineering\nsolutions.\n","authors":["Keyu Wang","Guilin Qi","Jiaqi Li","Songlin Zhai"],"pdf_url":"https://arxiv.org/pdf/2406.17532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17531v1","updated":"2024-06-25T13:15:36Z","published":"2024-06-25T13:15:36Z","title":"Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity\n  Awareness","summary":"  This paper presents a system for diversity-aware autonomous conversation\nleveraging the capabilities of large language models (LLMs). The system adapts\nto diverse populations and individuals, considering factors like background,\npersonality, age, gender, and culture. The conversation flow is guided by the\nstructure of the system's pre-established knowledge base, while LLMs are tasked\nwith various functions, including generating diversity-aware sentences.\nAchieving diversity-awareness involves providing carefully crafted prompts to\nthe models, incorporating comprehensive information about users, conversation\nhistory, contextual details, and specific guidelines. To assess the system's\nperformance, we conducted both controlled and real-world experiments, measuring\na wide range of performance indicators.\n","authors":["Lucrezia Grassi","Carmine Tommaso Recchiuto","Antonio Sgorbissa"],"pdf_url":"https://arxiv.org/pdf/2406.17531v1.pdf","comment":"8 pages, 6 figures, 7 tables. This paper has been accepted for\n  publication at IEEE ROMAN 2024"},{"id":"http://arxiv.org/abs/2402.12479v3","updated":"2024-06-25T13:10:06Z","published":"2024-02-19T19:34:07Z","title":"In value-based deep reinforcement learning, a pruned network is a good\n  network","summary":"  Recent work has shown that deep reinforcement learning agents have difficulty\nin effectively using their network parameters. We leverage prior insights into\nthe advantages of sparse training techniques and demonstrate that gradual\nmagnitude pruning enables value-based agents to maximize parameter\neffectiveness. This results in networks that yield dramatic performance\nimprovements over traditional networks, using only a small fraction of the full\nnetwork parameters.\n","authors":["Johan Obando-Ceron","Aaron Courville","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2402.12479v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17523v1","updated":"2024-06-25T13:06:09Z","published":"2024-06-25T13:06:09Z","title":"On the consistency of hyper-parameter selection in value-based deep\n  reinforcement learning","summary":"  Deep reinforcement learning (deep RL) has achieved tremendous success on\nvarious domains through a combination of algorithmic design and careful\nselection of hyper-parameters. Algorithmic improvements are often the result of\niterative enhancements built upon prior approaches, while hyper-parameter\nchoices are typically inherited from previous methods or fine-tuned\nspecifically for the proposed technique. Despite their crucial impact on\nperformance, hyper-parameter choices are frequently overshadowed by algorithmic\nadvancements. This paper conducts an extensive empirical study focusing on the\nreliability of hyper-parameter selection for value-based deep reinforcement\nlearning agents, including the introduction of a new score to quantify the\nconsistency and reliability of various hyper-parameters. Our findings not only\nhelp establish which hyper-parameters are most critical to tune, but also help\nclarify which tunings remain consistent across different training regimes.\n","authors":["Johan Obando-Ceron","João G. M. Araújo","Aaron Courville","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2406.17523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17518v1","updated":"2024-06-25T12:59:20Z","published":"2024-06-25T12:59:20Z","title":"Enhancing Explainability of Knowledge Learning Paths: Causal Knowledge\n  Networks","summary":"  A reliable knowledge structure is a prerequisite for building effective\nadaptive learning systems and intelligent tutoring systems. Pursuing an\nexplainable and trustworthy knowledge structure, we propose a method for\nconstructing causal knowledge networks. This approach leverages Bayesian\nnetworks as a foundation and incorporates causal relationship analysis to\nderive a causal network. Additionally, we introduce a dependable\nknowledge-learning path recommendationHuman-Centric eXplainable AI in Education\ntechnique built upon this framework, improving teaching and learning quality\nwhile maintaining transparency in the decision-making process.\n","authors":["Yuang Wei","Yizhou Zhou","Yuan-Hao Jiang","Bo Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.17518v1.pdf","comment":"8 pages, 3 figures, Educational Data Mining 2024, Human-Centric\n  eXplainable AI in Education"},{"id":"http://arxiv.org/abs/2406.17517v1","updated":"2024-06-25T12:54:35Z","published":"2024-06-25T12:54:35Z","title":"Preserving Node Distinctness in Graph Autoencoders via Similarity\n  Distillation","summary":"  Graph autoencoders (GAEs), as a kind of generative self-supervised learning\napproach, have shown great potential in recent years. GAEs typically rely on\ndistance-based criteria, such as mean-square-error (MSE), to reconstruct the\ninput graph. However, relying solely on a single reconstruction criterion may\nlead to a loss of distinctiveness in the reconstructed graph, causing nodes to\ncollapse into similar representations and resulting in sub-optimal performance.\nTo address this issue, we have developed a simple yet effective strategy to\npreserve the necessary distinctness in the reconstructed graph. Inspired by the\nknowledge distillation technique, we found that the dual encoder-decoder\narchitecture of GAEs can be viewed as a teacher-student relationship.\nTherefore, we propose transferring the knowledge of distinctness from the raw\ngraph to the reconstructed graph, achieved through a simple KL constraint.\nSpecifically, we compute pairwise node similarity scores in the raw graph and\nreconstructed graph. During the training process, the KL constraint is\noptimized alongside the reconstruction criterion. We conducted extensive\nexperiments across three types of graph tasks, demonstrating the effectiveness\nand generality of our strategy. This indicates that the proposed approach can\nbe employed as a plug-and-play method to avoid vague reconstructions and\nenhance overall performance.\n","authors":["Ge Chen","Yulan Hu","Sheng Ouyang","Yong Liu","Cuicui Luo"],"pdf_url":"https://arxiv.org/pdf/2406.17517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17513v1","updated":"2024-06-25T12:51:06Z","published":"2024-06-25T12:51:06Z","title":"Benchmarking Mental State Representations in Language Models","summary":"  While numerous works have assessed the generative performance of language\nmodels (LMs) on tasks requiring Theory of Mind reasoning, research into the\nmodels' internal representation of mental states remains limited. Recent work\nhas used probing to demonstrate that LMs can represent beliefs of themselves\nand others. However, these claims are accompanied by limited evaluation, making\nit difficult to assess how mental state representations are affected by model\ndesign and training choices. We report an extensive benchmark with various LM\ntypes with different model sizes, fine-tuning approaches, and prompt designs to\nstudy the robustness of mental state representations and memorisation issues\nwithin the probes. Our results show that the quality of models' internal\nrepresentations of the beliefs of others increases with model size and, more\ncrucially, with fine-tuning. We are the first to study how prompt variations\nimpact probing performance on theory of mind tasks. We demonstrate that models'\nrepresentations are sensitive to prompt variations, even when such variations\nshould be beneficial. Finally, we complement previous activation editing\nexperiments on Theory of Mind tasks and show that it is possible to improve\nmodels' reasoning performance by steering their activations without the need to\ntrain any probe.\n","authors":["Matteo Bortoletto","Constantin Ruhdorfer","Lei Shi","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2406.17513v1.pdf","comment":"ICML 2024 Workshop on Mechanistic Interpretability"},{"id":"http://arxiv.org/abs/2310.08574v2","updated":"2024-06-25T12:50:34Z","published":"2023-10-12T17:57:57Z","title":"Jigsaw: Supporting Designers to Prototype Multimodal Applications by\n  Chaining AI Foundation Models","summary":"  Recent advancements in AI foundation models have made it possible for them to\nbe utilized off-the-shelf for creative tasks, including ideating design\nconcepts or generating visual prototypes. However, integrating these models\ninto the creative process can be challenging as they often exist as standalone\napplications tailored to specific tasks. To address this challenge, we\nintroduce Jigsaw, a prototype system that employs puzzle pieces as metaphors to\nrepresent foundation models. Jigsaw allows designers to combine different\nfoundation model capabilities across various modalities by assembling\ncompatible puzzle pieces. To inform the design of Jigsaw, we interviewed ten\ndesigners and distilled design goals. In a user study, we showed that Jigsaw\nenhanced designers' understanding of available foundation model capabilities,\nprovided guidance on combining capabilities across different modalities and\ntasks, and served as a canvas to support design exploration, prototyping, and\ndocumentation.\n","authors":["David Chuan-En Lin","Nikolas Martelaro"],"pdf_url":"https://arxiv.org/pdf/2310.08574v2.pdf","comment":"https://jigsaw.to"},{"id":"http://arxiv.org/abs/2308.12143v4","updated":"2024-06-25T12:34:46Z","published":"2023-08-23T14:00:58Z","title":"A Probabilistic Fluctuation based Membership Inference Attack for\n  Diffusion Models","summary":"  Membership Inference Attack (MIA) identifies whether a record exists in a\nmachine learning model's training set by querying the model. MIAs on the\nclassic classification models have been well-studied, and recent works have\nstarted to explore how to transplant MIA onto generative models. Our\ninvestigation indicates that existing MIAs designed for generative models\nmainly depend on the overfitting in target models. However, overfitting can be\navoided by employing various regularization techniques, whereas existing MIAs\ndemonstrate poor performance in practice. Unlike overfitting, memorization is\nessential for deep learning models to attain optimal performance, making it a\nmore prevalent phenomenon. Memorization in generative models leads to an\nincreasing trend in the probability distribution of generating records around\nthe member record. Therefore, we propose a Probabilistic Fluctuation Assessing\nMembership Inference Attack (PFAMI), a black-box MIA that infers memberships by\ndetecting these trends via analyzing the overall probabilistic fluctuations\naround given records. We conduct extensive experiments across multiple\ngenerative models and datasets, which demonstrate PFAMI can improve the attack\nsuccess rate (ASR) by about 27.9% when compared with the best baseline.\n","authors":["Wenjie Fu","Huandong Wang","Chen Gao","Guanghua Liu","Yong Li","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2308.12143v4.pdf","comment":"Repo: https://github.com/wjfu99/MIA-Gen"},{"id":"http://arxiv.org/abs/2404.07900v2","updated":"2024-06-25T12:23:00Z","published":"2024-04-11T16:39:00Z","title":"High-Dimension Human Value Representation in Large Language Models","summary":"  The widespread application of Large Language Models (LLMs) across various\ntasks and fields has necessitated the alignment of these models with human\nvalues and preferences. Given various approaches of human value alignment,\nranging from Reinforcement Learning with Human Feedback (RLHF), to\nconstitutional learning, etc. there is an urgent need to understand the scope\nand nature of human values injected into these models before their release.\nThere is also a need for model alignment without a costly large scale human\nannotation effort. We propose UniVaR, a high-dimensional representation of\nhuman value distributions in LLMs, orthogonal to model architecture and\ntraining data. Trained from the value-relevant output of eight multilingual\nLLMs and tested on the output from four multilingual LLMs, namely LlaMA2,\nChatGPT, JAIS and Yi, we show that UniVaR is a powerful tool to compare the\ndistribution of human values embedded in different LLMs with different langauge\nsources. Through UniVaR, we explore how different LLMs prioritize various\nvalues in different languages and cultures, shedding light on the complex\ninterplay between human values and language modeling.\n","authors":["Samuel Cahyawijaya","Delong Chen","Yejin Bang","Leila Khalatbari","Bryan Wilie","Ziwei Ji","Etsuko Ishii","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2404.07900v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01677v3","updated":"2024-06-25T12:08:41Z","published":"2024-01-20T08:44:34Z","title":"Embedding Ontologies via Incorporating Extensional and Intensional\n  Knowledge","summary":"  Ontologies contain rich knowledge within domain, which can be divided into\ntwo categories, namely extensional knowledge and intensional knowledge.\nExtensional knowledge provides information about the concrete instances that\nbelong to specific concepts in the ontology, while intensional knowledge\ndetails inherent properties, characteristics, and semantic associations among\nconcepts. However, existing ontology embedding approaches fail to take both\nextensional knowledge and intensional knowledge into fine consideration\nsimultaneously. In this paper, we propose a novel ontology embedding approach\nnamed EIKE (Extensional and Intensional Knowledge Embedding) by representing\nontologies in two spaces, called extensional space and intensional space. EIKE\npresents a unified framework for embedding instances, concepts and their\nrelations in an ontology, applying a geometry-based method to model extensional\nknowledge and a pretrained language model to model intensional knowledge, which\ncan capture both structure information and textual information. Experimental\nresults show that EIKE significantly outperforms state-of-the-art methods in\nthree datasets for both triple classification and link prediction, indicating\nthat EIKE provides a more comprehensive and representative perspective of the\ndomain.\n","authors":["Keyu Wang","Guilin Qi","Jiaoyan Chen","Yi Huang","Tianxing Wu"],"pdf_url":"https://arxiv.org/pdf/2402.01677v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16512v5","updated":"2024-06-25T11:54:23Z","published":"2024-03-25T07:55:29Z","title":"LLMs Are Few-Shot In-Context Low-Resource Language Learners","summary":"  In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages. Our code is publicly\nreleased at https://github.com/SamuelCahyawijaya/in-context-alignment\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2403.16512v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07266v2","updated":"2024-06-25T11:42:09Z","published":"2024-06-11T13:51:51Z","title":"Efficient 3D Molecular Generation with Flow Matching and Scale Optimal\n  Transport","summary":"  Generative models for 3D drug design have gained prominence recently for\ntheir potential to design ligands directly within protein pockets. Current\napproaches, however, often suffer from very slow sampling times or generate\nmolecules with poor chemical validity. Addressing these limitations, we propose\nSemla, a scalable E(3)-equivariant message passing architecture. We further\nintroduce a molecular generation model, SemlaFlow, which is trained using flow\nmatching along with scale optimal transport, a novel extension of equivariant\noptimal transport. Our model produces state-of-the-art results on benchmark\ndatasets with just 100 sampling steps. Crucially, SemlaFlow samples high\nquality molecules with as few as 20 steps, corresponding to a two\norder-of-magnitude speed-up compared to state-of-the-art, without sacrificing\nperformance. Furthermore, we highlight limitations of current evaluation\nmethods for 3D generation and propose new benchmark metrics for unconditional\nmolecular generators. Finally, using these new metrics, we compare our model's\nability to generate high quality samples against current approaches and further\ndemonstrate SemlaFlow's strong performance.\n","authors":["Ross Irwin","Alessandro Tibo","Jon Paul Janet","Simon Olsson"],"pdf_url":"https://arxiv.org/pdf/2406.07266v2.pdf","comment":"Preprint. Code to be released upon full publication"},{"id":"http://arxiv.org/abs/2406.17474v1","updated":"2024-06-25T11:41:16Z","published":"2024-06-25T11:41:16Z","title":"Transformer-based Named Entity Recognition with Combined Data\n  Representation","summary":"  This study examines transformer-based models and their effectiveness in named\nentity recognition tasks. The study investigates data representation\nstrategies, including single, merged, and context, which respectively use one\nsentence, multiple sentences, and sentences joined with attention to context\nper vector. Analysis shows that training models with a single strategy may lead\nto poor performance on different data representations. To address this\nlimitation, the study proposes a combined training procedure that utilizes all\nthree strategies to improve model stability and adaptability. The results of\nthis approach are presented and discussed for four languages (English, Polish,\nCzech, and German) across various datasets, demonstrating the effectiveness of\nthe combined strategy.\n","authors":["Michał Marcińczuk"],"pdf_url":"https://arxiv.org/pdf/2406.17474v1.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.17473v1","updated":"2024-06-25T11:38:46Z","published":"2024-06-25T11:38:46Z","title":"TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image\n  Classification","summary":"  The usage of medical image data for the training of large-scale machine\nlearning approaches is particularly challenging due to its scarce availability\nand the costly generation of data annotations, typically requiring the\nengagement of medical professionals. The rapid development of generative models\nallows towards tackling this problem by leveraging large amounts of realistic\nsynthetically generated data for the training process. However, randomly\nchoosing synthetic samples, might not be an optimal strategy.\n  In this work, we investigate the targeted generation of synthetic training\ndata, in order to improve the accuracy and robustness of image classification.\nTherefore, our approach aims to guide the generative model to synthesize data\nwith high epistemic uncertainty, since large measures of epistemic uncertainty\nindicate underrepresented data points in the training set. During the image\ngeneration we feed images reconstructed by an auto encoder into the classifier\nand compute the mutual information over the class-probability distribution as a\nmeasure for uncertainty.We alter the feature space of the autoencoder through\nan optimization process with the objective of maximizing the classifier\nuncertainty on the decoded image. By training on such data we improve the\nperformance and robustness against test time data augmentations and adversarial\nattacks on several classifications tasks.\n","authors":["Joshua Niemeijer","Jan Ehrhardt","Hristina Uzunova","Heinz Handels"],"pdf_url":"https://arxiv.org/pdf/2406.17473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16224v2","updated":"2024-06-25T11:34:15Z","published":"2024-06-23T21:32:57Z","title":"From Text to Test: AI-Generated Control Software for Materials Science\n  Instruments","summary":"  Large language models (LLMs) are transforming the landscape of chemistry and\nmaterials science. Recent examples of LLM-accelerated experimental research\ninclude virtual assistants for parsing synthesis recipes from the literature,\nor using the extracted knowledge to guide synthesis and characterization.\nDespite these advancements, their application is constrained to labs with\nautomated instruments and control software, leaving much of materials science\nreliant on manual processes. Here, we demonstrate the rapid deployment of a\nPython-based control module for a Keithley 2400 electrical source measure unit\nusing ChatGPT-4. Through iterative refinement, we achieved effective instrument\nmanagement with minimal human intervention. Additionally, a user-friendly\ngraphical user interface (GUI) was created, effectively linking all instrument\ncontrols to interactive screen elements. Finally, we integrated this AI-crafted\ninstrument control software with a high-performance stochastic optimization\nalgorithm to facilitate rapid and automated extraction of electronic device\nparameters related to semiconductor charge transport mechanisms from\ncurrent-voltage (IV) measurement data. This integration resulted in a\ncomprehensive open-source toolkit for semiconductor device characterization and\nanalysis using IV curve measurements. We demonstrate the application of these\ntools by acquiring, analyzing, and parameterizing IV data from a\nPt/Cr$_2$O$_3$:Mg/$\\beta$-Ga$_2$O$_3$ heterojunction diode, a novel stack for\nhigh-power and high-temperature electronic devices. This approach underscores\nthe powerful synergy between LLMs and the development of instruments for\nscientific inquiry, showcasing a path for further acceleration in materials\nscience.\n","authors":["Davi M Fébba","Kingsley Egbo","William A. Callahan","Andriy Zakutayev"],"pdf_url":"https://arxiv.org/pdf/2406.16224v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17470v1","updated":"2024-06-25T11:15:53Z","published":"2024-06-25T11:15:53Z","title":"Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced\n  Federated Learning","summary":"  Leveraging the computing and sensing capabilities of vehicles, vehicular\nfederated learning (VFL) has been applied to edge training for connected\nvehicles. The dynamic and interconnected nature of vehicular networks presents\nunique opportunities to harness direct vehicle-to-vehicle (V2V) communications,\nenhancing VFL training efficiency. In this paper, we formulate a stochastic\noptimization problem to optimize the VFL training performance, considering the\nenergy constraints and mobility of vehicles, and propose a V2V-enhanced dynamic\nscheduling (VEDS) algorithm to solve it. The model aggregation requirements of\nVFL and the limited transmission time due to mobility result in a stepwise\nobjective function, which presents challenges in solving the problem. We thus\npropose a derivative-based drift-plus-penalty method to convert the long-term\nstochastic optimization problem to an online mixed integer nonlinear\nprogramming (MINLP) problem, and provide a theoretical analysis to bound the\nperformance gap between the online solution and the offline optimal solution.\nFurther analysis of the scheduling priority reduces the original problem into a\nset of convex optimization problems, which are efficiently solved using the\ninterior-point method. Experimental results demonstrate that compared with the\nstate-of-the-art benchmarks, the proposed algorithm enhances the image\nclassification accuracy on the CIFAR-10 dataset by 3.18% and reduces the\naverage displacement errors on the Argoverse trajectory prediction dataset by\n10.21%.\n","authors":["Jintao Yan","Tan Chen","Yuxuan Sun","Zhaojun Nan","Sheng Zhou","Zhisheng Niu"],"pdf_url":"https://arxiv.org/pdf/2406.17470v1.pdf","comment":"Submitted to IEEE for possible publication"},{"id":"http://arxiv.org/abs/2406.17465v1","updated":"2024-06-25T11:12:01Z","published":"2024-06-25T11:12:01Z","title":"Enhancing Tool Retrieval with Iterative Feedback from Large Language\n  Models","summary":"  Tool learning aims to enhance and expand large language models' (LLMs)\ncapabilities with external tools, which has gained significant attention\nrecently. Current methods have shown that LLMs can effectively handle a certain\namount of tools through in-context learning or fine-tuning. However, in\nreal-world scenarios, the number of tools is typically extensive and\nirregularly updated, emphasizing the necessity for a dedicated tool retrieval\ncomponent. Tool retrieval is nontrivial due to the following challenges: 1)\ncomplex user instructions and tool descriptions; 2) misalignment between tool\nretrieval and tool usage models. To address the above issues, we propose to\nenhance tool retrieval with iterative feedback from the large language model.\nSpecifically, we prompt the tool usage model, i.e., the LLM, to provide\nfeedback for the tool retriever model in multi-round, which could progressively\nimprove the tool retriever's understanding of instructions and tools and reduce\nthe gap between the two standalone components. We build a unified and\ncomprehensive benchmark to evaluate tool retrieval models. The extensive\nexperiments indicate that our proposed approach achieves advanced performance\nin both in-domain evaluation and out-of-domain evaluation.\n","authors":["Qiancheng Xu","Yongqi Li","Heming Xia","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2406.17465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17462v1","updated":"2024-06-25T11:05:26Z","published":"2024-06-25T11:05:26Z","title":"The Tree of Diffusion Life: Evolutionary Embeddings to Understand the\n  Generation Process of Diffusion Models","summary":"  Diffusion models generate high-quality samples by corrupting data with\nGaussian noise and iteratively reconstructing it with deep learning, slowly\ntransforming noisy images into refined outputs. Understanding this data\nevolution is important for interpretability but is complex due to its\nhigh-dimensional evolutionary nature. While traditional dimensionality\nreduction methods like t-distributed stochastic neighborhood embedding (t-SNE)\naid in understanding high-dimensional spaces, they neglect evolutionary\nstructure preservation. Hence, we propose Tree of Diffusion Life (TDL), a\nmethod to understand data evolution in the generative process of diffusion\nmodels. TDL samples a diffusion model's generative space via instances with\nvarying prompts and employs image encoders to extract semantic meaning from\nthese samples, projecting them to an intermediate space. It employs a novel\nevolutionary embedding algorithm that explicitly encodes the iterations while\npreserving the high-dimensional relations, facilitating the visualization of\ndata evolution. This embedding leverages three metrics: a standard t-SNE loss\nto group semantically similar elements, a displacement loss to group elements\nfrom the same iteration step, and an instance alignment loss to align elements\nof the same instance across iterations. We present rectilinear and radial\nlayouts to represent iterations, enabling comprehensive exploration. We assess\nvarious feature extractors and highlight TDL's potential with prominent\ndiffusion models like GLIDE and Stable Diffusion with different prompt sets.\nTDL simplifies understanding data evolution within diffusion models, offering\nvaluable insights into their functioning.\n","authors":["Vidya Prasad","Hans van Gorp","Christina Humer","Anna Vilanova","Nicola Pezzotti"],"pdf_url":"https://arxiv.org/pdf/2406.17462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10918v3","updated":"2024-06-25T10:50:09Z","published":"2024-06-16T12:46:40Z","title":"Embodied Question Answering via Multi-LLM Systems","summary":"  Embodied Question Answering (EQA) is an important problem, which involves an\nagent exploring the environment to answer user queries. In the existing\nliterature, EQA has exclusively been studied in single-agent scenarios, where\nexploration can be time-consuming and costly. In this work, we consider EQA in\na multi-agent framework involving multiple large language models (LLM) based\nagents independently answering queries about a household environment. To\ngenerate one answer for each query, we use the individual responses to train a\nCentral Answer Model (CAM) that aggregates responses for a robust answer. Using\nCAM, we observe a $50\\%$ higher EQA accuracy when compared against aggregation\nmethods for ensemble LLM, such as voting schemes and debates. CAM does not\nrequire any form of agent communication, alleviating it from the associated\ncosts. We ablate CAM with various nonlinear (neural network, random forest,\ndecision tree, XGBoost) and linear (logistic regression classifier, SVM)\nalgorithms. Finally, we present a feature importance analysis for CAM via\npermutation feature importance (PFI), quantifying CAMs reliance on each\nindependent agent and query context.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Dinesh Manocha","Amrit Singh Bedi"],"pdf_url":"https://arxiv.org/pdf/2406.10918v3.pdf","comment":"17 pages, 13 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2406.17456v1","updated":"2024-06-25T10:49:56Z","published":"2024-06-25T10:49:56Z","title":"Improving Grammatical Error Correction via Contextual Data Augmentation","summary":"  Nowadays, data augmentation through synthetic data has been widely used in\nthe field of Grammatical Error Correction (GEC) to alleviate the problem of\ndata scarcity. However, these synthetic data are mainly used in the\npre-training phase rather than the data-limited fine-tuning phase due to\ninconsistent error distribution and noisy labels. In this paper, we propose a\nsynthetic data construction method based on contextual augmentation, which can\nensure an efficient augmentation of the original data with a more consistent\nerror distribution. Specifically, we combine rule-based substitution with\nmodel-based generation, using the generative model to generate a richer context\nfor the extracted error patterns. Besides, we also propose a relabeling-based\ndata cleaning method to mitigate the effects of noisy labels in synthetic data.\nExperiments on CoNLL14 and BEA19-Test show that our proposed augmentation\nmethod consistently and substantially outperforms strong baselines and achieves\nthe state-of-the-art level with only a few synthetic data.\n","authors":["Yixuan Wang","Baoxin Wang","Yijun Liu","Qingfu Zhu","Dayong Wu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2406.17456v1.pdf","comment":"Accepted as Findings of ACL 2024"},{"id":"http://arxiv.org/abs/2406.17450v1","updated":"2024-06-25T10:41:45Z","published":"2024-06-25T10:41:45Z","title":"Pseudo Labelling for Enhanced Masked Autoencoders","summary":"  Masked Image Modeling (MIM)-based models, such as SdAE, CAE, GreenMIM, and\nMixAE, have explored different strategies to enhance the performance of Masked\nAutoencoders (MAE) by modifying prediction, loss functions, or incorporating\nadditional architectural components. In this paper, we propose an enhanced\napproach that boosts MAE performance by integrating pseudo labelling for both\nclass and data tokens, alongside replacing the traditional pixel-level\nreconstruction with token-level reconstruction. This strategy uses cluster\nassignments as pseudo labels to promote instance-level discrimination within\nthe network, while token reconstruction requires generation of discrete tokens\nencapturing local context. The targets for pseudo labelling and reconstruction\nneeds to be generated by a teacher network. To disentangle the generation of\ntarget pseudo labels and the reconstruction of the token features, we decouple\nthe teacher into two distinct models, where one serves as a labelling teacher\nand the other as a reconstruction teacher. This separation proves empirically\nsuperior to a single teacher, while having negligible impact on throughput and\nmemory consumption. Incorporating pseudo-labelling as an auxiliary task has\ndemonstrated notable improvements in ImageNet-1K and other downstream tasks,\nincluding classification, semantic segmentation, and detection.\n","authors":["Srinivasa Rao Nandam","Sara Atito","Zhenhua Feng","Josef Kittler","Muhammad Awais"],"pdf_url":"https://arxiv.org/pdf/2406.17450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19220v3","updated":"2024-06-25T10:41:43Z","published":"2024-05-29T16:00:46Z","title":"WRDScore: New Metric for Evaluation of Natural Language Generation\n  Models","summary":"  The problem of natural language generation, and, more specifically, method\nname prediction, faces significant difficulties when proposed models need to be\nevaluated on test data. Such a metric would need to consider the versatility\nwith which a single method can be named, with respect to both semantics and\nsyntax. Measuring the direct overlap between the predicted and reference (true)\nsequences will not be able to capture these subtleties. Other existing\nembedding based metrics either do not measure precision and recall or impose\nstrict unrealistic assumptions on both sequences. To address these issues, we\npropose a new metric that, on the one hand, is very simple and lightweight,\nand, on the other hand, is able to calculate precision and recall without\nresorting to any assumptions while obtaining good performance with respect to\nthe human judgement.\n","authors":["Ravil Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2405.19220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17425v1","updated":"2024-06-25T09:59:31Z","published":"2024-06-25T09:59:31Z","title":"CuDA2: An approach for Incorporating Traitor Agents into Cooperative\n  Multi-Agent Systems","summary":"  Cooperative Multi-Agent Reinforcement Learning (CMARL) strategies are well\nknown to be vulnerable to adversarial perturbations. Previous works on\nadversarial attacks have primarily focused on white-box attacks that directly\nperturb the states or actions of victim agents, often in scenarios with a\nlimited number of attacks. However, gaining complete access to victim agents in\nreal-world environments is exceedingly difficult. To create more realistic\nadversarial attacks, we introduce a novel method that involves injecting\ntraitor agents into the CMARL system. We model this problem as a Traitor Markov\nDecision Process (TMDP), where traitors cannot directly attack the victim\nagents but can influence their formation or positioning through collisions. In\nTMDP, traitors are trained using the same MARL algorithm as the victim agents,\nwith their reward function set as the negative of the victim agents' reward.\nDespite this, the training efficiency for traitors remains low because it is\nchallenging for them to directly associate their actions with the victim\nagents' rewards. To address this issue, we propose the Curiosity-Driven\nAdversarial Attack (CuDA2) framework. CuDA2 enhances the efficiency and\naggressiveness of attacks on the specified victim agents' policies while\nmaintaining the optimal policy invariance of the traitors. Specifically, we\nemploy a pre-trained Random Network Distillation (RND) module, where the extra\nreward generated by the RND module encourages traitors to explore states\nunencountered by the victim agents. Extensive experiments on various scenarios\nfrom SMAC demonstrate that our CuDA2 framework offers comparable or superior\nadversarial attack capabilities compared to other baselines.\n","authors":["Zhen Chen","Yong Liao","Youpeng Zhao","Zipeng Dai","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.17425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17419v1","updated":"2024-06-25T09:42:56Z","published":"2024-06-25T09:42:56Z","title":"Leave No Document Behind: Benchmarking Long-Context LLMs with Extended\n  Multi-Doc QA","summary":"  Long-context modeling capabilities have garnered widespread attention,\nleading to the emergence of Large Language Models (LLMs) with ultra-context\nwindows. Meanwhile, benchmarks for evaluating long-context LLMs are gradually\ncatching up. However, existing benchmarks employ irrelevant noise texts to\nartificially extend the length of test cases, diverging from the real-world\nscenarios of long-context applications. To bridge this gap, we propose a novel\nlong-context benchmark, Loong, aligning with realistic scenarios through\nextended multi-document question answering (QA). Unlike typical document QA, in\nLoong's test cases, each document is relevant to the final answer, ignoring any\ndocument will lead to the failure of the answer. Furthermore, Loong introduces\nfour types of tasks with a range of context lengths: Spotlight Locating,\nComparison, Clustering, and Chain of Reasoning, to facilitate a more realistic\nand comprehensive evaluation of long-context understanding. Extensive\nexperiments indicate that existing long-context language models still exhibit\nconsiderable potential for enhancement. Retrieval augmented generation (RAG)\nachieves poor performance, demonstrating that Loong can reliably assess the\nmodel's long-context modeling capabilities.\n","authors":["Minzheng Wang","Longze Chen","Cheng Fu","Shengyi Liao","Xinghua Zhang","Bingli Wu","Haiyang Yu","Nan Xu","Lei Zhang","Run Luo","Yunshui Li","Min Yang","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2406.17419v1.pdf","comment":"We release our code and data publicly at\n  https://github.com/MozerWang/Loong"},{"id":"http://arxiv.org/abs/2406.17418v1","updated":"2024-06-25T09:40:47Z","published":"2024-06-25T09:40:47Z","title":"SE-VGAE: Unsupervised Disentangled Representation Learning for\n  Interpretable Architectural Layout Design Graph Generation","summary":"  Despite the suitability of graphs for capturing the relational structures\ninherent in architectural layout designs, there is a notable dearth of research\non interpreting architectural design space using graph-based representation\nlearning and exploring architectural design graph generation. Concurrently,\ndisentangled representation learning in graph generation faces challenges such\nas node permutation invariance and representation expressiveness. To address\nthese challenges, we introduce an unsupervised disentangled representation\nlearning framework, Style-based Edge-augmented Variational Graph Auto-Encoder\n(SE-VGAE), aiming to generate architectural layout in the form of attributed\nadjacency multi-graphs while prioritizing representation disentanglement. The\nframework is designed with three alternative pipelines, each integrating a\ntransformer-based edge-augmented encoder, a latent space disentanglement\nmodule, and a style-based decoder. These components collectively facilitate the\ndecomposition of latent factors influencing architectural layout graph\ngeneration, enhancing generation fidelity and diversity. We also provide\ninsights into optimizing the framework by systematically exploring graph\nfeature augmentation schemes and evaluating their effectiveness for\ndisentangling architectural layout representation through extensive\nexperiments. Additionally, we contribute a new benchmark large-scale\narchitectural layout graph dataset extracted from real-world floor plan images\nto facilitate the exploration of graph data-based architectural design\nrepresentation space interpretation. This study pioneered disentangled\nrepresentation learning for the architectural layout graph generation. The code\nand dataset of this study will be open-sourced.\n","authors":["Jielin Chen","Rudi Stouffs"],"pdf_url":"https://arxiv.org/pdf/2406.17418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17415v1","updated":"2024-06-25T09:37:15Z","published":"2024-06-25T09:37:15Z","title":"Variable Layer-Wise Quantization: A Simple and Effective Approach to\n  Quantize LLMs","summary":"  We present a simple variable quantization approach that quantizes different\nlayers of a large language model (LLM) at different bit levels. Specifically,\nwe quantize the most important layers to higher bit precision and less\nimportant layers to lower bits to achieve floating point quantization levels.\nWe propose two effective strategies to measure the importance of layers within\nLLMs: the first measures the importance of a layer based on how different its\noutput embeddings are from the input embeddings (the higher the better); the\nsecond estimates the importance of a layer using the number of layer weights\nthat are much larger than average (the smaller the better). We show that\nquantizing different layers at varying bits according to our importance scores\nresults in minimal performance drop with a far more compressed model size.\nFinally, we present several practical key takeaways from our variable\nlayer-wise quantization experiments: (a) LLM performance under variable\nquantization remains close to the original model until 25-50% of layers are\nmoved in lower quantization using our proposed ordering but only until 5-10% if\nmoved using no specific ordering; (b) Quantizing LLMs to lower bits performs\nsubstantially better than pruning unless extreme quantization (2-bit) is used;\nand (c) Layer-wise quantization to lower bits works better in the case of\nlarger LLMs with more layers compared to smaller LLMs with fewer layers. The\ncode used to run the experiments is available at:\nhttps://github.com/RazvanDu/LayerwiseQuant.\n","authors":["Razvan-Gabriel Dumitru","Vikas Yadav","Rishabh Maheshwary","Paul-Ioan Clotan","Sathwik Tejaswi Madhusudhan","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2406.17415v1.pdf","comment":"submitted to EMNLP, 15 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.17386v1","updated":"2024-06-25T09:05:22Z","published":"2024-06-25T09:05:22Z","title":"Double Momentum Method for Lower-Level Constrained Bilevel Optimization","summary":"  Bilevel optimization (BO) has recently gained prominence in many machine\nlearning applications due to its ability to capture the nested structure\ninherent in these problems. Recently, many hypergradient methods have been\nproposed as effective solutions for solving large-scale problems. However,\ncurrent hypergradient methods for the lower-level constrained bilevel\noptimization (LCBO) problems need very restrictive assumptions, namely, where\noptimality conditions satisfy the differentiability and invertibility\nconditions and lack a solid analysis of the convergence rate. What's worse,\nexisting methods require either double-loop updates, which are sometimes less\nefficient. To solve this problem, in this paper, we propose a new hypergradient\nof LCBO leveraging the theory of nonsmooth implicit function theorem instead of\nusing the restrive assumptions. In addition, we propose a \\textit{single-loop\nsingle-timescale} algorithm based on the double-momentum method and adaptive\nstep size method and prove it can return a $(\\delta, \\epsilon)$-stationary\npoint with $\\tilde{\\mathcal{O}}(d_2^2\\epsilon^{-4})$ iterations. Experiments on\ntwo applications demonstrate the effectiveness of our proposed method.\n","authors":["Wanli Shi","Yi Chang","Bin Gu"],"pdf_url":"https://arxiv.org/pdf/2406.17386v1.pdf","comment":"27pages, 9 figures"},{"id":"http://arxiv.org/abs/2308.08634v2","updated":"2024-06-25T09:04:08Z","published":"2023-08-16T19:14:52Z","title":"FedPop: Federated Population-based Hyperparameter Tuning","summary":"  Federated Learning (FL) is a distributed machine learning (ML) paradigm, in\nwhich multiple clients collaboratively train ML models without centralizing\ntheir local data. Similar to conventional ML pipelines, the client local\noptimization and server aggregation procedure in FL are sensitive to the\nhyperparameter (HP) selection. Despite extensive research on tuning HPs for\ncentralized ML, these methods yield suboptimal results when employed in FL.\nThis is mainly because their \"training-after-tuning\" framework is unsuitable\nfor FL with limited client computation power. While some approaches have been\nproposed for HP-Tuning in FL, they are limited to the HPs for client local\nupdates. In this work, we propose a novel HP-tuning algorithm, called Federated\nPopulation-based Hyperparameter Tuning (FedPop), to address this vital yet\nchallenging problem. FedPop employs population-based evolutionary algorithms to\noptimize the HPs, which accommodates various HP types at both client and server\nsides. Compared with prior tuning methods, FedPop employs an online\n\"tuning-while-training\" framework, offering computational efficiency and\nenabling the exploration of a broader HP search space. Our empirical validation\non the common FL benchmarks and complex real-world FL datasets demonstrates the\neffectiveness of the proposed method, which substantially outperforms the\nconcurrent state-of-the-art HP tuning methods for FL.\n","authors":["Haokun Chen","Denis Krompass","Jindong Gu","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2308.08634v2.pdf","comment":"Code: https://github.com/HaokunChen245/FedPop"},{"id":"http://arxiv.org/abs/2406.17376v1","updated":"2024-06-25T08:50:43Z","published":"2024-06-25T08:50:43Z","title":"Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic\n  Speech Detection","summary":"  Recent synthetic speech detectors leveraging the Transformer model have\nsuperior performance compared to the convolutional neural network counterparts.\nThis improvement could be due to the powerful modeling ability of the\nmulti-head self-attention (MHSA) in the Transformer model, which learns the\ntemporal relationship of each input token. However, artifacts of synthetic\nspeech can be located in specific regions of both frequency channels and\ntemporal segments, while MHSA neglects this temporal-channel dependency of the\ninput sequence. In this work, we proposed a Temporal-Channel Modeling (TCM)\nmodule to enhance MHSA's capability for capturing temporal-channel\ndependencies. Experimental results on the ASVspoof 2021 show that with only\n0.03M additional parameters, the TCM module can outperform the state-of-the-art\nsystem by 9.25% in EER. Further ablation study reveals that utilizing both\ntemporal and channel information yields the most improvement for detecting\nsynthetic speech.\n","authors":["Duc-Tuan Truong","Ruijie Tao","Tuan Nguyen","Hieu-Thi Luong","Kong Aik Lee","Eng Siong Chng"],"pdf_url":"https://arxiv.org/pdf/2406.17376v1.pdf","comment":"Accepted by INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.06589v2","updated":"2024-06-25T08:23:03Z","published":"2024-06-05T13:55:27Z","title":"PatentEval: Understanding Errors in Patent Generation","summary":"  In this work, we introduce a comprehensive error typology specifically\ndesigned for evaluating two distinct tasks in machine-generated patent texts:\nclaims-to-abstract generation, and the generation of the next claim given\nprevious ones. We have also developed a benchmark, PatentEval, for\nsystematically assessing language models in this context. Our study includes a\ncomparative analysis, annotated by humans, of various models. These range from\nthose specifically adapted during training for tasks within the patent domain\nto the latest general-purpose large language models (LLMs). Furthermore, we\nexplored and evaluated some metrics to approximate human judgments in patent\ntext evaluation, analyzing the extent to which these metrics align with expert\nassessments. These approaches provide valuable insights into the capabilities\nand limitations of current language models in the specialized field of patent\ntext generation.\n","authors":["You Zuo","Kim Gerdes","Eric Villemonte de La Clergerie","Benoît Sagot"],"pdf_url":"https://arxiv.org/pdf/2406.06589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17343v1","updated":"2024-06-25T07:57:27Z","published":"2024-06-25T07:57:27Z","title":"Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers","summary":"  Recent advancements in diffusion models, particularly the trend of\narchitectural transformation from UNet-based Diffusion to Diffusion Transformer\n(DiT), have significantly improved the quality and scalability of image\nsynthesis. Despite the incredible generative quality, the large computational\nrequirements of these large-scale models significantly hinder the deployments\nin real-world scenarios. Post-training Quantization (PTQ) offers a promising\nsolution by compressing model sizes and speeding up inference for the\npretrained models while eliminating model retraining. However, we have observed\nthe existing PTQ frameworks exclusively designed for both ViT and conventional\nDiffusion models fall into biased quantization and result in remarkable\nperformance degradation. In this paper, we find that the DiTs typically exhibit\nconsiderable variance in terms of both weight and activation, which easily runs\nout of the limited numerical representations. To address this issue, we devise\nQ-DiT, which seamlessly integrates three techniques: fine-grained quantization\nto manage substantial variance across input channels of weights and\nactivations, an automatic search strategy to optimize the quantization\ngranularity and mitigate redundancies, and dynamic activation quantization to\ncapture the activation changes across timesteps. Extensive experiments on the\nImageNet dataset demonstrate the effectiveness of the proposed Q-DiT.\nSpecifically, when quantizing DiT-XL/2 to W8A8 on ImageNet 256x256, Q-DiT\nachieves a remarkable reduction in FID by 1.26 compared to the baseline. Under\na W4A8 setting, it maintains high fidelity in image generation, showcasing only\na marginal increase in FID and setting a new benchmark for efficient,\nhigh-quality quantization in diffusion transformers. Code is available at\n\\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}.\n","authors":["Lei Chen","Yuan Meng","Chen Tang","Xinzhu Ma","Jingyan Jiang","Xin Wang","Zhi Wang","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.17343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17342v1","updated":"2024-06-25T07:57:03Z","published":"2024-06-25T07:57:03Z","title":"Masked Generative Extractor for Synergistic Representation and 3D\n  Generation of Point Clouds","summary":"  In the field of 2D image generation modeling and representation learning,\nMasked Generative Encoder (MAGE) has demonstrated the synergistic potential\nbetween generative modeling and representation learning. Inspired by this, we\npropose Point-MAGE to extend this concept to point cloud data. Specifically,\nthis framework first utilizes a Vector Quantized Variational Autoencoder\n(VQVAE) to reconstruct a neural field representation of 3D shapes, thereby\nlearning discrete semantic features of point patches. Subsequently, by\ncombining the masking model with variable masking ratios, we achieve\nsynchronous training for both generation and representation learning.\nFurthermore, our framework seamlessly integrates with existing point cloud\nself-supervised learning (SSL) models, thereby enhancing their performance. We\nextensively evaluate the representation learning and generation capabilities of\nPoint-MAGE. In shape classification tasks, Point-MAGE achieved an accuracy of\n94.2% on the ModelNet40 dataset and 92.9% (+1.3%) on the ScanObjectNN dataset.\nAdditionally, it achieved new state-of-the-art performance in few-shot learning\nand part segmentation tasks. Experimental results also confirmed that\nPoint-MAGE can generate detailed and high-quality 3D shapes in both\nunconditional and conditional settings.\n","authors":["Hongliang Zeng","Ping Zhang","Fang Li","Jiahua Wang","Tingyu Ye","Pengteng Guo"],"pdf_url":"https://arxiv.org/pdf/2406.17342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17879v4","updated":"2024-06-25T07:44:31Z","published":"2023-03-31T08:26:18Z","title":"CoSMo: a Framework to Instantiate Conditioned Process Simulation Models","summary":"  Process simulation is gaining attention for its ability to assess potential\nperformance improvements and risks associated with business process changes.\nThe existing literature presents various techniques, generally grounded in\nprocess models discovered from event log data or built upon deep learning\nalgorithms. These techniques have specific strengths and limitations.\nTraditional data-driven approaches offer increased interpretability, while deep\nlearning-based excel at generalizing changes across large event logs. However,\nthe practical application of deep learning faces challenges related to managing\nstochasticity and integrating information for what-if analysis. This paper\nintroduces a novel recurrent neural architecture tailored to discover\nCOnditioned process Simulation MOdels (CoSMo) based on user-based constraints\nor any other nature of a-priori knowledge. This architecture facilitates the\nsimulation of event logs that adhere to specific constraints by incorporating\ndeclarative-based rules into the learning phase as an attempt to fill the gap\nof incorporating information into deep learning models to perform what-if\nanalysis. Experimental validation illustrates CoSMo's efficacy in simulating\nevent logs while adhering to predefined declarative conditions, emphasizing\nboth control-flow and data-flow perspectives.\n","authors":["Rafael S. Oyamada","Gabriel M. Tavares","Sylvio Barbon Junior","Paolo Ceravolo"],"pdf_url":"https://arxiv.org/pdf/2303.17879v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13584v3","updated":"2024-06-25T07:42:54Z","published":"2023-01-31T12:31:13Z","title":"Straight-Through meets Sparse Recovery: the Support Exploration\n  Algorithm","summary":"  The {\\it straight-through estimator} (STE) is commonly used to optimize\nquantized neural networks, yet its contexts of effective performance are still\nunclear despite empirical successes.To make a step forward in this\ncomprehension, we apply STE to a well-understood problem: {\\it sparse support\nrecovery}. We introduce the {\\it Support Exploration Algorithm} (SEA), a novel\nalgorithm promoting sparsity, and we analyze its performance in support\nrecovery (a.k.a. model selection) problems. SEA explores more supports than the\nstate-of-the-art, leading to superior performance in experiments, especially\nwhen the columns of $A$ are strongly coherent.The theoretical analysis\nconsiders recovery guarantees when the linear measurements matrix $A$ satisfies\nthe {\\it Restricted Isometry Property} (RIP).The sufficient conditions of\nrecovery are comparable but more stringent than those of the state-of-the-art\nin sparse support recovery. Their significance lies mainly in their\napplicability to an instance of the STE.\n","authors":["Mimoun Mohamed","François Malgouyres","Valentin Emiya","Caroline Chaux"],"pdf_url":"https://arxiv.org/pdf/2301.13584v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17334v1","updated":"2024-06-25T07:42:30Z","published":"2024-06-25T07:42:30Z","title":"Joint Admission Control and Resource Allocation of Virtual Network\n  Embedding via Hierarchical Deep Reinforcement Learning","summary":"  As an essential resource management problem in network virtualization,\nvirtual network embedding (VNE) aims to allocate the finite resources of\nphysical network to sequentially arriving virtual network requests (VNRs) with\ndifferent resource demands. Since this is an NP-hard combinatorial optimization\nproblem, many efforts have been made to provide viable solutions. However, most\nexisting approaches have either ignored the admission control of VNRs, which\nhas a potential impact on long-term performances, or not fully exploited the\ntemporal and topological features of the physical network and VNRs. In this\npaper, we propose a deep Hierarchical Reinforcement Learning approach to learn\na joint Admission Control and Resource Allocation policy for VNE, named\nHRL-ACRA. Specifically, the whole VNE process is decomposed into an upper-level\npolicy for deciding whether to admit the arriving VNR or not and a lower-level\npolicy for allocating resources of the physical network to meet the requirement\nof VNR through the HRL approach. Considering the proximal policy optimization\nas the basic training algorithm, we also adopt the average reward method to\naddress the infinite horizon problem of the upper-level agent and design a\ncustomized multi-objective intrinsic reward to alleviate the sparse reward\nissue of the lower-level agent. Moreover, we develop a deep feature-aware graph\nneural network to capture the features of VNR and physical network and exploit\na sequence-to-sequence model to generate embedding actions iteratively.\nFinally, extensive experiments are conducted in various settings, and show that\nHRL-ACRA outperforms state-of-the-art baselines in terms of both the acceptance\nratio and long-term average revenue. Our code is available at\n\\url{https://github.com/GeminiLight/hrl-acra}.\n","authors":["Tianfu Wang","Li Shen","Qilin Fan","Tong Xu","Tongliang Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.17334v1.pdf","comment":"Accepted by IEEE Transactions on Services Computing (TSC)"},{"id":"http://arxiv.org/abs/2406.17328v1","updated":"2024-06-25T07:25:15Z","published":"2024-06-25T07:25:15Z","title":"Dual-Space Knowledge Distillation for Large Language Models","summary":"  Knowledge distillation (KD) is known as a promising solution to compress\nlarge language models (LLMs) via transferring their knowledge to smaller\nmodels. During this process, white-box KD methods usually minimize the distance\nbetween the output distributions of the two models so that more knowledge can\nbe transferred. However, in the current white-box KD framework, the output\ndistributions are from the respective output spaces of the two models, using\ntheir own prediction heads. We argue that the space discrepancy will lead to\nlow similarity between the teacher model and the student model on both\nrepresentation and distribution levels. Furthermore, this discrepancy also\nhinders the KD process between models with different vocabularies, which is\ncommon for current LLMs. To address these issues, we propose a dual-space\nknowledge distillation (DSKD) framework that unifies the output spaces of the\ntwo models for KD. On the basis of DSKD, we further develop a cross-model\nattention mechanism, which can automatically align the representations of the\ntwo models with different vocabularies. Thus, our framework is not only\ncompatible with various distance functions for KD (e.g., KL divergence) like\nthe current framework, but also supports KD between any two LLMs regardless of\ntheir vocabularies. Experiments on task-agnostic instruction-following\nbenchmarks show that DSKD significantly outperforms the current white-box KD\nframework with various distance functions, and also surpasses existing KD\nmethods for LLMs with different vocabularies.\n","authors":["Songming Zhang","Xue Zhang","Zengkui Sun","Yufeng Chen","Jinan Xu"],"pdf_url":"https://arxiv.org/pdf/2406.17328v1.pdf","comment":"17 pages, 11 figures, code available at:\n  https://github.com/songmzhang/DSKD"},{"id":"http://arxiv.org/abs/2406.17326v1","updated":"2024-06-25T07:21:35Z","published":"2024-06-25T07:21:35Z","title":"The State-Action-Reward-State-Action Algorithm in Spatial Prisoner's\n  Dilemma Game","summary":"  Cooperative behavior is prevalent in both human society and nature.\nUnderstanding the emergence and maintenance of cooperation among\nself-interested individuals remains a significant challenge in evolutionary\nbiology and social sciences. Reinforcement learning (RL) provides a suitable\nframework for studying evolutionary game theory as it can adapt to\nenvironmental changes and maximize expected benefits. In this study, we employ\nthe State-Action-Reward-State-Action (SARSA) algorithm as the decision-making\nmechanism for individuals in evolutionary game theory. Initially, we apply\nSARSA to imitation learning, where agents select neighbors to imitate based on\nrewards. This approach allows us to observe behavioral changes in agents\nwithout independent decision-making abilities. Subsequently, SARSA is utilized\nfor primary agents to independently choose cooperation or betrayal with their\nneighbors. We evaluate the impact of SARSA on cooperation rates by analyzing\nvariations in rewards and the distribution of cooperators and defectors within\nthe network.\n","authors":["Lanyu Yang","Dongchun Jiang","Fuqiang Guo","Mingjian Fu"],"pdf_url":"https://arxiv.org/pdf/2406.17326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18553v3","updated":"2024-06-25T07:18:14Z","published":"2024-05-28T19:54:46Z","title":"FAIIR: Building Toward A Conversational AI Agent Assistant for Youth\n  Mental Health Service Provision","summary":"  The world's healthcare systems and mental health agencies face both a growing\ndemand for youth mental health services, alongside a simultaneous challenge of\nlimited resources. Here, we focus on frontline crisis support, where Crisis\nResponders (CRs) engage in conversations for youth mental health support and\nassign an issue tag to each conversation. In this study, we develop FAIIR\n(Frontline Assistant: Issue Identification and Recommendation), an advanced\ntool leveraging an ensemble of domain-adapted and fine-tuned transformer models\ntrained on a large conversational dataset comprising 780,000 conversations. The\nprimary aim is to reduce the cognitive burden on CRs, enhance the accuracy of\nissue identification, and streamline post-conversation administrative tasks. We\nevaluate FAIIR on both retrospective and prospective conversations, emphasizing\nhuman-in-the-loop design with active CR engagement for model refinement,\nconsensus-building, and overall assessment. Our results indicate that FAIIR\nachieves an average AUCROC of 94%, a sample average F1-score of 64%, and a\nsample average recall score of 81% on the retrospective test set. We also\ndemonstrate the robustness and generalizability of the FAIIR tool during the\nsilent testing phase, with less than a 2% drop in all performance metrics.\nNotably, CRs' responses exhibited an overall agreement of 90.9% with FAIIR's\npredictions. Furthermore, expert agreement with FAIIR surpassed their agreement\nwith the original labels. To conclude, our findings indicate that assisting\nwith the identification of issues of relevance helps reduce the burden on CRs,\nensuring that appropriate resources can be provided and that active rescues and\nmandatory reporting can take place in critical situations requiring immediate\nde-escalation.\n","authors":["Stephen Obadinma","Alia Lachana","Maia Norman","Jocelyn Rankin","Joanna Yu","Xiaodan Zhu","Darren Mastropaolo","Deval Pandya","Roxana Sultan","Elham Dolatabadi"],"pdf_url":"https://arxiv.org/pdf/2405.18553v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17322v1","updated":"2024-06-25T07:14:14Z","published":"2024-06-25T07:14:14Z","title":"ALPBench: A Benchmark for Active Learning Pipelines on Tabular Data","summary":"  In settings where only a budgeted amount of labeled data can be afforded,\nactive learning seeks to devise query strategies for selecting the most\ninformative data points to be labeled, aiming to enhance learning algorithms'\nefficiency and performance. Numerous such query strategies have been proposed\nand compared in the active learning literature. However, the community still\nlacks standardized benchmarks for comparing the performance of different query\nstrategies. This particularly holds for the combination of query strategies\nwith different learning algorithms into active learning pipelines and examining\nthe impact of the learning algorithm choice. To close this gap, we propose\nALPBench, which facilitates the specification, execution, and performance\nmonitoring of active learning pipelines. It has built-in measures to ensure\nevaluations are done reproducibly, saving exact dataset splits and\nhyperparameter settings of used algorithms. In total, ALPBench consists of 86\nreal-world tabular classification datasets and 5 active learning settings,\nyielding 430 active learning problems. To demonstrate its usefulness and broad\ncompatibility with various learning algorithms and query strategies, we conduct\nan exemplary study evaluating 9 query strategies paired with 8 learning\nalgorithms in 2 different settings. We provide ALPBench here:\nhttps://github.com/ValentinMargraf/ActiveLearningPipelines.\n","authors":["Valentin Margraf","Marcel Wever","Sandra Gilhuber","Gabriel Marques Tavares","Thomas Seidl","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2406.17322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.14642v5","updated":"2024-06-25T07:08:34Z","published":"2021-06-28T12:41:45Z","title":"Expert Q-learning: Deep Reinforcement Learning with Coarse State Values\n  from Offline Expert Examples","summary":"  In this article, we propose a novel algorithm for deep reinforcement learning\nnamed Expert Q-learning. Expert Q-learning is inspired by Dueling Q-learning\nand aims at incorporating semi-supervised learning into reinforcement learning\nthrough splitting Q-values into state values and action advantages. We require\nthat an offline expert assesses the value of a state in a coarse manner using\nthree discrete values. An expert network is designed in addition to the\nQ-network, which updates each time following the regular offline minibatch\nupdate whenever the expert example buffer is not empty. Using the board game\nOthello, we compare our algorithm with the baseline Q-learning algorithm, which\nis a combination of Double Q-learning and Dueling Q-learning. Our results show\nthat Expert Q-learning is indeed useful and more resistant to the\noverestimation bias. The baseline Q-learning algorithm exhibits unstable and\nsuboptimal behavior in non-deterministic settings, whereas Expert Q-learning\ndemonstrates more robust performance with higher scores, illustrating that our\nalgorithm is indeed suitable to integrate state values from expert examples\ninto Q-learning.\n","authors":["Li Meng","Anis Yazidi","Morten Goodwin","Paal Engelstad"],"pdf_url":"https://arxiv.org/pdf/2106.14642v5.pdf","comment":"Camera-ready version"},{"id":"http://arxiv.org/abs/2310.01290v2","updated":"2024-06-25T06:25:41Z","published":"2023-10-02T15:43:53Z","title":"Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language\n  Models","summary":"  We propose Knowledge Crosswords, a geometric knowledge reasoning benchmark\nconsisting of incomplete knowledge networks bounded by structured factual\nconstraints, where LLMs are tasked with inferring the missing facts to meet all\nconstraints. The novel setting of geometric knowledge reasoning necessitates\nnew LM abilities beyond existing atomic/linear multi-hop QA, such as\nbacktracking, verifying facts and constraints, reasoning with uncertainty, and\nmore. Knowledge Crosswords contains 2,101 individual problems, covering diverse\nknowledge domains, and is further divided into three difficulty levels. We\nconduct extensive experiments to evaluate existing LLMs and approaches on\nKnowledge Crosswords. Results demonstrate that baseline approaches struggle\nwith larger knowledge networks and semantically-equivalent entity distractors.\nIn light of their limitations, we propose two new approaches, Staged Prompting\nand Verify-All, to augment LLMs' abilities for error-aware backtracking and\nconstraint verification. Our Verify-All significantly outperforms prior methods\nand is more robust towards problems in the hard subset. Further analysis shows\nthat geometric knowledge reasoning poses new challenges to LLMs' knowledge\nabilities, particularly in robustness towards varying option orders, complex\nstructural constraints in knowledge networks, \"none of the above\" scenarios,\nand more.\n","authors":["Wenxuan Ding","Shangbin Feng","Yuhan Liu","Zhaoxuan Tan","Vidhisha Balachandran","Tianxing He","Yulia Tsvetkov"],"pdf_url":"https://arxiv.org/pdf/2310.01290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17297v1","updated":"2024-06-25T05:58:34Z","published":"2024-06-25T05:58:34Z","title":"Towards Open-set Camera 3D Object Detection","summary":"  Traditional camera 3D object detectors are typically trained to recognize a\npredefined set of known object classes. In real-world scenarios, these\ndetectors may encounter unknown objects outside the training categories and\nfail to identify them correctly. To address this gap, we present OS-Det3D\n(Open-set Camera 3D Object Detection), a two-stage training framework enhancing\nthe ability of camera 3D detectors to identify both known and unknown objects.\nThe framework involves our proposed 3D Object Discovery Network (ODN3D), which\nis specifically trained using geometric cues such as the location and scale of\n3D boxes to discover general 3D objects. ODN3D is trained in a class-agnostic\nmanner, and the provided 3D object region proposals inherently come with data\nnoise. To boost accuracy in identifying unknown objects, we introduce a Joint\nObjectness Selection (JOS) module. JOS selects the pseudo ground truth for\nunknown objects from the 3D object region proposals of ODN3D by combining the\nODN3D objectness and camera feature attention objectness. Experiments on the\nnuScenes and KITTI datasets demonstrate the effectiveness of our framework in\nenabling camera 3D detectors to successfully identify unknown objects while\nalso improving their performance on known objects.\n","authors":["Zhuolin He","Xinrun Li","Heng Gao","Jiachen Tang","Shoumeng Qiu","Wenfu Wang","Lvjian Lu","Xiuchong Qiu","Xiangyang Xue","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2406.17297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05355v4","updated":"2024-06-25T05:42:43Z","published":"2024-02-08T02:27:13Z","title":"A Survey on Safe Multi-Modal Learning System","summary":"  In the rapidly evolving landscape of artificial intelligence, multimodal\nlearning systems (MMLS) have gained traction for their ability to process and\nintegrate information from diverse modality inputs. Their expanding use in\nvital sectors such as healthcare has made safety assurance a critical concern.\nHowever, the absence of systematic research into their safety is a significant\nbarrier to progress in this field. To bridge the gap, we present the first\ntaxonomy that systematically categorizes and assesses MMLS safety. This\ntaxonomy is structured around four fundamental pillars that are critical to\nensuring the safety of MMLS: robustness, alignment, monitoring, and\ncontrollability. Leveraging this taxonomy, we review existing methodologies,\nbenchmarks, and the current state of research, while also pinpointing the\nprincipal limitations and gaps in knowledge. Finally, we discuss unique\nchallenges in MMLS safety. In illuminating these challenges, we aim to pave the\nway for future research, proposing potential directions that could lead to\nsignificant advancements in the safety protocols of MMLS.\n","authors":["Tianyi Zhao","Liangliang Zhang","Yao Ma","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2402.05355v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17289v1","updated":"2024-06-25T05:35:02Z","published":"2024-06-25T05:35:02Z","title":"Hyperbolic Knowledge Transfer in Cross-Domain Recommendation System","summary":"  Cross-Domain Recommendation (CDR) seeks to utilize knowledge from different\ndomains to alleviate the problem of data sparsity in the target recommendation\ndomain, and it has been gaining more attention in recent years. Although there\nhave been notable advancements in this area, most current methods represent\nusers and items in Euclidean space, which is not ideal for handling long-tail\ndistributed data in recommendation systems. Additionally, adding data from\nother domains can worsen the long-tail characteristics of the entire dataset,\nmaking it harder to train CDR models effectively. Recent studies have shown\nthat hyperbolic methods are particularly suitable for modeling long-tail\ndistributions, which has led us to explore hyperbolic representations for users\nand items in CDR scenarios. However, due to the distinct characteristics of the\ndifferent domains, applying hyperbolic representation learning to CDR tasks is\nquite challenging. In this paper, we introduce a new framework called\nHyperbolic Contrastive Learning (HCTS), designed to capture the unique features\nof each domain while enabling efficient knowledge transfer between domains. We\nachieve this by embedding users and items from each domain separately and\nmapping them onto distinct hyperbolic manifolds with adjustable curvatures for\nprediction. To improve the representations of users and items in the target\ndomain, we develop a hyperbolic contrastive learning module for knowledge\ntransfer. Extensive experiments on real-world datasets demonstrate that\nhyperbolic manifolds are a promising alternative to Euclidean space for CDR\ntasks.\n","authors":["Xin Yang","Heng Chang","Zhijian La","Jinze Yang","Xingrun Li","Yu Lu","Shuaiqiang Wang","Dawei Yin","Erxue Min"],"pdf_url":"https://arxiv.org/pdf/2406.17289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17287v1","updated":"2024-06-25T05:30:55Z","published":"2024-06-25T05:30:55Z","title":"Predicting the Big Five Personality Traits in Chinese Counselling\n  Dialogues Using Large Language Models","summary":"  Accurate assessment of personality traits is crucial for effective\npsycho-counseling, yet traditional methods like self-report questionnaires are\ntime-consuming and biased. This study exams whether Large Language Models\n(LLMs) can predict the Big Five personality traits directly from counseling\ndialogues and introduces an innovative framework to perform the task. Our\nframework applies role-play and questionnaire-based prompting to condition LLMs\non counseling sessions, simulating client responses to the Big Five Inventory.\nWe evaluated our framework on 853 real-world counseling sessions, finding a\nsignificant correlation between LLM-predicted and actual Big Five traits,\nproving the validity of framework. Moreover, ablation studies highlight the\nimportance of role-play simulations and task simplification via questionnaires\nin enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model,\nutilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves\na 130.95\\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\\%\nin personality prediction validity. In conclusion, LLMs can predict personality\nbased on counseling dialogues. Our code and model are publicly available at\n\\url{https://github.com/kuri-leo/BigFive-LLM-Predictor}, providing a valuable\ntool for future research in computational psychometrics.\n","authors":["Yang Yan","Lizhi Ma","Anqi Li","Jingsong Ma","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2406.17287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17285v1","updated":"2024-06-25T05:23:41Z","published":"2024-06-25T05:23:41Z","title":"EON-1: A Brain-Inspired Processor for Near-Sensor Extreme Edge Online\n  Feature Extraction","summary":"  For Edge AI applications, deploying online learning and adaptation on\nresource-constrained embedded devices can deal with fast sensor-generated\nstreams of data in changing environments. However, since maintaining\nlow-latency and power-efficient inference is paramount at the Edge, online\nlearning and adaptation on the device should impose minimal additional overhead\nfor inference. With this goal in mind, we explore energy-efficient learning and\nadaptation on-device for streaming-data Edge AI applications using Spiking\nNeural Networks (SNNs), which follow the principles of brain-inspired\ncomputing, such as high-parallelism, neuron co-located memory and compute, and\nevent-driven processing. We propose EON-1, a brain-inspired processor for\nnear-sensor extreme edge online feature extraction, that integrates a fast\nonline learning and adaptation algorithm. We report results of only 1% energy\noverhead for learning, by far the lowest overhead when compared to other SoTA\nsolutions, while attaining comparable inference accuracy. Furthermore, we\ndemonstrate that EON-1 is up for the challenge of low-latency processing of HD\nand UHD streaming video in real-time, with learning enabled.\n","authors":["Alexandra Dobrita","Amirreza Yousefzadeh","Simon Thorpe","Kanishkan Vadivel","Paul Detterer","Guangzhi Tang","Gert-Jan van Schaik","Mario Konijnenburg","Anteneh Gebregiorgis","Said Hamdioui","Manolis Sifalakis"],"pdf_url":"https://arxiv.org/pdf/2406.17285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17279v1","updated":"2024-06-25T05:08:44Z","published":"2024-06-25T05:08:44Z","title":"Learning Decentralized Multi-Biped Control for Payload Transport","summary":"  Payload transport over flat terrain via multi-wheel robot carriers is\nwell-understood, highly effective, and configurable. In this paper, our goal is\nto provide similar effectiveness and configurability for transport over rough\nterrain that is more suitable for legs rather than wheels. For this purpose, we\nconsider multi-biped robot carriers, where wheels are replaced by multiple\nbipedal robots attached to the carrier. Our main contribution is to design a\ndecentralized controller for such systems that can be effectively applied to\nvarying numbers and configurations of rigidly attached bipedal robots without\nretraining. We present a reinforcement learning approach for training the\ncontroller in simulation that supports transfer to the real world. Our\nexperiments in simulation provide quantitative metrics showing the\neffectiveness of the approach over a wide variety of simulated transport\nscenarios. In addition, we demonstrate the controller in the real-world for\nsystems composed of two and three Cassie robots. To our knowledge, this is the\nfirst example of a scalable multi-biped payload transport system.\n","authors":["Bikram Pandit","Ashutosh Gupta","Mohitvishnu S. Gadde","Addison Johnson","Aayam Kumar Shrestha","Helei Duan","Jeremy Dao","Alan Fern"],"pdf_url":"https://arxiv.org/pdf/2406.17279v1.pdf","comment":"Submitted to CoRL 2024, Project website: decmbc.github.io"},{"id":"http://arxiv.org/abs/2309.05519v3","updated":"2024-06-25T05:01:09Z","published":"2023-09-11T15:02:25Z","title":"NExT-GPT: Any-to-Any Multimodal LLM","summary":"  While recently Multimodal Large Language Models (MM-LLMs) have made exciting\nstrides, they mostly fall prey to the limitation of only input-side multimodal\nunderstanding, without the ability to produce content in multiple modalities.\nAs we humans always perceive the world and communicate with people through\nvarious modalities, developing any-to-any MM-LLMs capable of accepting and\ndelivering content in any modality becomes essential to human-level AI. To fill\nthe gap, we present an end-to-end general-purpose any-to-any MM-LLM system,\nNExT-GPT. We connect an LLM with multimodal adaptors and different diffusion\ndecoders, enabling NExT-GPT to perceive inputs and generate outputs in\narbitrary combinations of text, images, videos, and audio. By leveraging the\nexisting well-trained highly-performing encoders and decoders, NExT-GPT is\ntuned with only a small amount of parameter (1%) of certain projection layers,\nwhich not only benefits low-cost training and also facilitates convenient\nexpansion to more potential modalities. Moreover, we introduce a\nmodality-switching instruction tuning (MosIT) and manually curate a\nhigh-quality dataset for MosIT, based on which NExT-GPT is empowered with\ncomplex cross-modal semantic understanding and content generation. Overall, our\nresearch showcases the promising possibility of building an AI agent capable of\nmodeling universal modalities, paving the way for more human-like AI research\nin the community. Project page: https://next-gpt.github.io/\n","authors":["Shengqiong Wu","Hao Fei","Leigang Qu","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2309.05519v3.pdf","comment":"ICML 2024 (Oral)"},{"id":"http://arxiv.org/abs/2308.00177v4","updated":"2024-06-25T04:41:56Z","published":"2023-07-31T22:19:45Z","title":"Pretrained deep models outperform GBDTs in Learning-To-Rank under label\n  scarcity","summary":"  On tabular data, a significant body of literature has shown that current deep\nlearning (DL) models perform at best similarly to Gradient Boosted Decision\nTrees (GBDTs), while significantly underperforming them on outlier data.\nHowever, these works often study idealized problem settings which may fail to\ncapture complexities of real-world scenarios. We identify a natural tabular\ndata setting where DL models can outperform GBDTs: tabular Learning-to-Rank\n(LTR) under label scarcity. Tabular LTR applications, including search and\nrecommendation, often have an abundance of unlabeled data, and scarce labeled\ndata. We show that DL rankers can utilize unsupervised pretraining to exploit\nthis unlabeled data. In extensive experiments over both public and proprietary\ndatasets, we show that pretrained DL rankers consistently outperform GBDT\nrankers on ranking metrics -- sometimes by as much as 38% -- both overall and\non outliers.\n","authors":["Charlie Hou","Kiran Koshy Thekumparampil","Michael Shavlovsky","Giulia Fanti","Yesh Dattatreya","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2308.00177v4.pdf","comment":"ICML-MFPL 2023 Workshop Oral, SPIGM@ICML2024"},{"id":"http://arxiv.org/abs/2404.13071v2","updated":"2024-06-25T04:36:08Z","published":"2024-04-15T05:30:26Z","title":"Modeling Emotions and Ethics with Large Language Models","summary":"  This paper explores the integration of human-like emotions and ethical\nconsiderations into Large Language Models (LLMs). We first model eight\nfundamental human emotions, presented as opposing pairs, and employ\ncollaborative LLMs to reinterpret and express these emotions across a spectrum\nof intensity. Our focus extends to embedding a latent ethical dimension within\nLLMs, guided by a novel self-supervised learning algorithm with human feedback\n(SSHF). This approach enables LLMs to perform self-evaluations and adjustments\nconcerning ethical guidelines, enhancing their capability to generate content\nthat is not only emotionally resonant but also ethically aligned. The\nmethodologies and case studies presented herein illustrate the potential of\nLLMs to transcend mere text and image generation, venturing into the realms of\nempathetic interaction and principled decision-making, thereby setting a new\nprecedent in the development of emotionally aware and ethically conscious AI\nsystems.\n","authors":["Edward Y. Chang"],"pdf_url":"https://arxiv.org/pdf/2404.13071v2.pdf","comment":"8 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2401.17802v2","updated":"2024-06-25T04:34:38Z","published":"2024-01-31T12:52:10Z","title":"Distillation Enhanced Time Series Forecasting Network with Momentum\n  Contrastive Learning","summary":"  Contrastive representation learning is crucial in time series analysis as it\nalleviates the issue of data noise and incompleteness as well as sparsity of\nsupervision signal. However, existing constrastive learning frameworks usually\nfocus on intral-temporal features, which fails to fully exploit the intricate\nnature of time series data. To address this issue, we propose DE-TSMCL, an\ninnovative distillation enhanced framework for long sequence time series\nforecasting. Specifically, we design a learnable data augmentation mechanism\nwhich adaptively learns whether to mask a timestamp to obtain optimized\nsub-sequences. Then, we propose a contrastive learning task with momentum\nupdate to explore inter-sample and intra-temporal correlations of time series\nto learn the underlying structure feature on the unlabeled time series.\nMeanwhile, we design a supervised task to learn more robust representations and\nfacilitate the contrastive learning process. Finally, we jointly optimize the\nabove two tasks. By developing model loss from multiple tasks, we can learn\neffective representations for downstream forecasting task. Extensive\nexperiments, in comparison with state-of-the-arts, well demonstrate the\neffectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.\n","authors":["Haozhi Gao","Qianqian Ren","Jinbao Li"],"pdf_url":"https://arxiv.org/pdf/2401.17802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17266v1","updated":"2024-06-25T04:20:49Z","published":"2024-06-25T04:20:49Z","title":"AG-LSEC: Audio Grounded Lexical Speaker Error Correction","summary":"  Speaker Diarization (SD) systems are typically audio-based and operate\nindependently of the ASR system in traditional speech transcription pipelines\nand can have speaker errors due to SD and/or ASR reconciliation, especially\naround speaker turns and regions of speech overlap. To reduce these errors, a\nLexical Speaker Error Correction (LSEC), in which an external language model\nprovides lexical information to correct the speaker errors, was recently\nproposed. Though the approach achieves good Word Diarization error rate (WDER)\nimprovements, it does not use any additional acoustic information and is prone\nto miscorrections. In this paper, we propose to enhance and acoustically ground\nthe LSEC system with speaker scores directly derived from the existing SD\npipeline. This approach achieves significant relative WDER reductions in the\nrange of 25-40% over the audio-based SD, ASR system and beats the LSEC system\nby 15-25% relative on RT03-CTS, Callhome American English and Fisher datasets.\n","authors":["Rohit Paturi","Xiang Li","Sundararajan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.17266v1.pdf","comment":"Accepted at INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.17265v1","updated":"2024-06-25T04:16:14Z","published":"2024-06-25T04:16:14Z","title":"Image-Guided Outdoor LiDAR Perception Quality Assessment for Autonomous\n  Driving","summary":"  LiDAR is one of the most crucial sensors for autonomous vehicle perception.\nHowever, current LiDAR-based point cloud perception algorithms lack\ncomprehensive and rigorous LiDAR quality assessment methods, leading to\nuncertainty in detection performance. Additionally, existing point cloud\nquality assessment algorithms are predominantly designed for indoor\nenvironments or single-object scenarios. In this paper, we introduce a novel\nimage-guided point cloud quality assessment algorithm for outdoor autonomous\ndriving environments, named the Image-Guided Outdoor Point Cloud Quality\nAssessment (IGO-PQA) algorithm. Our proposed algorithm comprises two main\ncomponents. The first component is the IGO-PQA generation algorithm, which\nleverages point cloud data, corresponding RGB surrounding view images, and\nagent objects' ground truth annotations to generate an overall quality score\nfor a single-frame LiDAR-based point cloud. The second component is a\ntransformer-based IGO-PQA regression algorithm for no-reference outdoor point\ncloud quality assessment. This regression algorithm allows for the direct\nprediction of IGO-PQA scores in an online manner, without requiring image data\nand object ground truth annotations. We evaluate our proposed algorithm using\nthe nuScenes and Waymo open datasets. The IGO-PQA generation algorithm provides\nconsistent and reasonable perception quality indices. Furthermore, our proposed\nIGO-PQA regression algorithm achieves a Pearson Linear Correlation Coefficient\n(PLCC) of 0.86 on the nuScenes dataset and 0.97 on the Waymo dataset.\n","authors":["Ce Zhang","Azim Eskandarian"],"pdf_url":"https://arxiv.org/pdf/2406.17265v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2312.05795v2","updated":"2024-06-25T03:53:28Z","published":"2023-12-10T06:57:48Z","title":"Large Multimodal Model Compression via Efficient Pruning and\n  Distillation at AntGroup","summary":"  The deployment of Large Multimodal Models (LMMs) within AntGroup has\nsignificantly advanced multimodal tasks in payment, security, and advertising,\nnotably enhancing advertisement audition tasks in Alipay. However, the\ndeployment of such sizable models introduces challenges, particularly in\nincreased latency and carbon emissions, which are antithetical to the ideals of\nGreen AI. This paper introduces a novel multi-stage compression strategy for\nour proprietary LLM, AntGMM. Our methodology pivots on three main aspects:\nemploying small training sample sizes, addressing multi-level redundancy\nthrough multi-stage pruning, and introducing an advanced distillation loss\ndesign. In our research, we constructed a dataset, the Multimodal Advertisement\nAudition Dataset (MAAD), from real-world scenarios within Alipay, and conducted\nexperiments to validate the reliability of our proposed strategy. Furthermore,\nthe effectiveness of our strategy is evident in its operational success in\nAlipay's real-world multimodal advertisement audition for three months from\nSeptember 2023. Notably, our approach achieved a substantial reduction in\nlatency, decreasing it from 700ms to 90ms, while maintaining online performance\nwith only a slight performance decrease. Moreover, our compressed model is\nestimated to reduce electricity consumption by approximately 75 million kWh\nannually compared to the direct deployment of AntGMM, demonstrating our\ncommitment to green AI initiatives. We will publicly release our code and the\nMAAD dataset after some\nreviews\\footnote{https://github.com/MorinW/AntGMM$\\_$Pruning}.\n","authors":["Maolin Wang","Yao Zhao","Jiajia Liu","Jingdong Chen","Chenyi Zhuang","Jinjie Gu","Ruocheng Guo","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2312.05795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07332v2","updated":"2024-06-25T03:37:26Z","published":"2024-03-12T05:34:51Z","title":"LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation","summary":"  In clinical practice, medical image segmentation provides useful information\non the contours and dimensions of target organs or tissues, facilitating\nimproved diagnosis, analysis, and treatment. In the past few years,\nconvolutional neural networks (CNNs) and Transformers have dominated this area,\nbut they still suffer from either limited receptive fields or costly long-range\nmodeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a\npromising paradigm for long-range dependency modeling with linear complexity.\nIn this paper, we introduce a Large Kernel Vision Mamba U-shape Network, or\nLKM-UNet, for medical image segmentation. A distinguishing feature of our\nLKM-UNet is its utilization of large Mamba kernels, excelling in locally\nspatial modeling compared to small kernel-based CNNs and Transformers, while\nmaintaining superior efficiency in global modeling compared to self-attention\nwith quadratic complexity. Additionally, we design a novel hierarchical and\nbidirectional Mamba block to further enhance Mamba's global and neighborhood\nspatial modeling capability for vision inputs. Comprehensive experiments\ndemonstrate the feasibility and the effectiveness of using large-size Mamba\nkernels to achieve large receptive fields. Codes are available at\nhttps://github.com/wjh892521292/LKM-UNet.\n","authors":["Jinhong Wang","Jintai Chen","Danny Chen","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2403.07332v2.pdf","comment":"Accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17251v1","updated":"2024-06-25T03:35:20Z","published":"2024-06-25T03:35:20Z","title":"TopoGCL: Topological Graph Contrastive Learning","summary":"  Graph contrastive learning (GCL) has recently emerged as a new concept which\nallows for capitalizing on the strengths of graph neural networks (GNNs) to\nlearn rich representations in a wide variety of applications which involve\nabundant unlabeled information. However, existing GCL approaches largely tend\nto overlook the important latent information on higher-order graph\nsubstructures. We address this limitation by introducing the concepts of\ntopological invariance and extended persistence on graphs to GCL. In\nparticular, we propose a new contrastive mode which targets topological\nrepresentations of the two augmented views from the same graph, yielded by\nextracting latent shape properties of the graph at multiple resolutions. Along\nwith the extended topological layer, we introduce a new extended persistence\nsummary, namely, extended persistence landscapes (EPL) and derive its\ntheoretical stability guarantees. Our extensive numerical results on\nbiological, chemical, and social interaction graphs show that the new\nTopological Graph Contrastive Learning (TopoGCL) model delivers significant\nperformance gains in unsupervised graph classification for 11 out of 12\nconsidered datasets and also exhibits robustness under noisy scenarios.\n","authors":["Yuzhou Chen","Jose Frias","Yulia R. Gel"],"pdf_url":"https://arxiv.org/pdf/2406.17251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17246v1","updated":"2024-06-25T03:24:12Z","published":"2024-06-25T03:24:12Z","title":"Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in\n  Audio Anti-Spoofing","summary":"  Current trends in audio anti-spoofing detection research strive to improve\nmodels' ability to generalize across unseen attacks by learning to identify a\nvariety of spoofing artifacts. This emphasis has primarily focused on the spoof\nclass. Recently, several studies have noted that the distribution of silence\ndiffers between the two classes, which can serve as a shortcut. In this paper,\nwe extend class-wise interpretations beyond silence. We employ loss analysis\nand asymmetric methodologies to move away from traditional attack-focused and\nresult-oriented evaluations towards a deeper examination of model behaviors.\nOur investigations highlight the significant differences in training dynamics\nbetween the two classes, emphasizing the need for future research to focus on\nrobust modeling of the bonafide class.\n","authors":["Hye-jin Shim","Md Sahidullah","Jee-weon Jung","Shinji Watanabe","Tomi Kinnunen"],"pdf_url":"https://arxiv.org/pdf/2406.17246v1.pdf","comment":"5 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2406.17245v1","updated":"2024-06-25T03:24:06Z","published":"2024-06-25T03:24:06Z","title":"Unlocking Continual Learning Abilities in Language Models","summary":"  Language models (LMs) exhibit impressive performance and generalization\ncapabilities. However, LMs struggle with the persistent challenge of\ncatastrophic forgetting, which undermines their long-term sustainability in\ncontinual learning (CL). Existing approaches usually address the issue by\nincorporating old task data or task-wise inductive bias into LMs. However, old\ndata and accurate task information are often unavailable or costly to collect,\nhindering the availability of current CL approaches for LMs. To address this\nlimitation, we introduce $\\textbf{MIGU}$ ($\\textbf{M}$agn$\\textbf{I}$tude-based\n$\\textbf{G}$radient $\\textbf{U}$pdating for continual learning), a\nrehearsal-free and task-label-free method that only updates the model\nparameters with large magnitudes of output in LMs' linear layers. MIGU is based\non our observation that the L1-normalized magnitude distribution of the output\nin LMs' linear layers is different when the LM models deal with different task\ndata. By imposing this simple constraint on the gradient update process, we can\nleverage the inherent behaviors of LMs, thereby unlocking their innate CL\nabilities. Our experiments demonstrate that MIGU is universally applicable to\nall three LM architectures (T5, RoBERTa, and Llama2), delivering\nstate-of-the-art or on-par performance across continual finetuning and\ncontinual pre-training settings on four CL benchmarks. For example, MIGU brings\na 15.2% average accuracy improvement over conventional parameter-efficient\nfinetuning baselines in a 15-task CL benchmark. MIGU can also seamlessly\nintegrate with all three existing CL types to further enhance performance. Code\nis available at \\href{https://github.com/wenyudu/MIGU}{this https URL}.\n","authors":["Wenyu Du","Shuang Cheng","Tongxu Luo","Zihan Qiu","Zeyu Huang","Ka Chun Cheung","Reynold Cheng","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2406.17245v1.pdf","comment":"preprint, 19 pages"},{"id":"http://arxiv.org/abs/2405.17441v2","updated":"2024-06-25T03:23:00Z","published":"2024-05-14T10:46:33Z","title":"When Large Language Models Meet Optical Networks: Paving the Way for\n  Automation","summary":"  Since the advent of GPT, large language models (LLMs) have brought about\nrevolutionary advancements in all walks of life. As a superior natural language\nprocessing (NLP) technology, LLMs have consistently achieved state-of-the-art\nperformance on numerous areas. However, LLMs are considered to be\ngeneral-purpose models for NLP tasks, which may encounter challenges when\napplied to complex tasks in specialized fields such as optical networks. In\nthis study, we propose a framework of LLM-empowered optical networks,\nfacilitating intelligent control of the physical layer and efficient\ninteraction with the application layer through an LLM-driven agent (AI-Agent)\ndeployed in the control layer. The AI-Agent can leverage external tools and\nextract domain knowledge from a comprehensive resource library specifically\nestablished for optical networks. This is achieved through user input and\nwell-crafted prompts, enabling the generation of control instructions and\nresult representations for autonomous operation and maintenance in optical\nnetworks. To improve LLM's capability in professional fields and stimulate its\npotential on complex tasks, the details of performing prompt engineering,\nestablishing domain knowledge library, and implementing complex tasks are\nillustrated in this study. Moreover, the proposed framework is verified on two\ntypical tasks: network alarm analysis and network performance optimization. The\ngood response accuracies and sematic similarities of 2,400 test situations\nexhibit the great potential of LLM in optical networks.\n","authors":["Danshi Wang","Yidi Wang","Xiaotian Jiang","Yao Zhang","Yue Pang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.17441v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16252v2","updated":"2024-06-25T03:17:40Z","published":"2024-06-24T01:22:54Z","title":"Graph-Augmented LLMs for Personalized Health Insights: A Case Study in\n  Sleep Analysis","summary":"  Health monitoring systems have revolutionized modern healthcare by enabling\nthe continuous capture of physiological and behavioral data, essential for\npreventive measures and early health intervention. While integrating this data\nwith Large Language Models (LLMs) has shown promise in delivering interactive\nhealth advice, traditional methods like Retrieval-Augmented Generation (RAG)\nand fine-tuning often fail to fully utilize the complex, multi-dimensional, and\ntemporally relevant data from wearable devices. These conventional approaches\ntypically provide limited actionable and personalized health insights due to\ntheir inadequate capacity to dynamically integrate and interpret diverse health\ndata streams. In response, this paper introduces a graph-augmented LLM\nframework designed to significantly enhance the personalization and clarity of\nhealth insights. Utilizing a hierarchical graph structure, the framework\ncaptures inter and intra-patient relationships, enriching LLM prompts with\ndynamic feature importance scores derived from a Random Forest Model. The\neffectiveness of this approach is demonstrated through a sleep analysis case\nstudy involving 20 college students during the COVID-19 lockdown, highlighting\nthe potential of our model to generate actionable and personalized health\ninsights efficiently. We leverage another LLM to evaluate the insights for\nrelevance, comprehensiveness, actionability, and personalization, addressing\nthe critical need for models that process and interpret complex health data\neffectively. Our findings show that augmenting prompts with our framework\nyields significant improvements in all 4 criteria. Through our framework, we\ncan elicit well-crafted, more thoughtful responses tailored to a specific\npatient.\n","authors":["Ajan Subramanian","Zhongqi Yang","Iman Azimi","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2406.16252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15222v2","updated":"2024-06-25T03:17:22Z","published":"2024-06-14T02:15:09Z","title":"Rapid and Accurate Diagnosis of Acute Aortic Syndrome using Non-contrast\n  CT: A Large-scale, Retrospective, Multi-center and AI-based Study","summary":"  Chest pain symptoms are highly prevalent in emergency departments (EDs),\nwhere acute aortic syndrome (AAS) is a catastrophic cardiovascular emergency\nwith a high fatality rate, especially when timely and accurate treatment is not\nadministered. However, current triage practices in the ED can cause up to\napproximately half of patients with AAS to have an initially missed diagnosis\nor be misdiagnosed as having other acute chest pain conditions. Subsequently,\nthese AAS patients will undergo clinically inaccurate or suboptimal\ndifferential diagnosis. Fortunately, even under these suboptimal protocols,\nnearly all these patients underwent non-contrast CT covering the aorta anatomy\nat the early stage of differential diagnosis. In this study, we developed an\nartificial intelligence model (DeepAAS) using non-contrast CT, which is highly\naccurate for identifying AAS and provides interpretable results to assist in\nclinical decision-making. Performance was assessed in two major phases: a\nmulti-center retrospective study (n = 20,750) and an exploration in real-world\nemergency scenarios (n = 137,525). In the multi-center cohort, DeepAAS achieved\na mean area under the receiver operating characteristic curve of 0.958 (95% CI\n0.950-0.967). In the real-world cohort, DeepAAS detected 109 AAS patients with\nmisguided initial suspicion, achieving 92.6% (95% CI 76.2%-97.5%) in mean\nsensitivity and 99.2% (95% CI 99.1%-99.3%) in mean specificity. Our AI model\nperformed well on non-contrast CT at all applicable early stages of\ndifferential diagnosis workflows, effectively reduced the overall missed\ndiagnosis and misdiagnosis rate from 48.8% to 4.8% and shortened the diagnosis\ntime for patients with misguided initial suspicion from an average of 681.8\n(74-11,820) mins to 68.5 (23-195) mins. DeepAAS could effectively fill the gap\nin the current clinical workflow without requiring additional tests.\n","authors":["Yujian Hu","Yilang Xiang","Yan-Jie Zhou","Yangyan He","Shifeng Yang","Xiaolong Du","Chunlan Den","Youyao Xu","Gaofeng Wang","Zhengyao Ding","Jingyong Huang","Wenjun Zhao","Xuejun Wu","Donglin Li","Qianqian Zhu","Zhenjiang Li","Chenyang Qiu","Ziheng Wu","Yunjun He","Chen Tian","Yihui Qiu","Zuodong Lin","Xiaolong Zhang","Yuan He","Zhenpeng Yuan","Xiaoxiang Zhou","Rong Fan","Ruihan Chen","Wenchao Guo","Jianpeng Zhang","Tony C. W. Mok","Zi Li","Le Lu","Dehai Lang","Xiaoqiang Li","Guofu Wang","Wei Lu","Zhengxing Huang","Minfeng Xu","Hongkun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.15222v2.pdf","comment":"under peer review"},{"id":"http://arxiv.org/abs/2402.09246v4","updated":"2024-06-25T02:55:44Z","published":"2024-02-14T15:34:38Z","title":"Who Plays First? Optimizing the Order of Play in Stackelberg Games with\n  Many Robots","summary":"  We consider the multi-agent spatial navigation problem of computing the\nsocially optimal order of play, i.e., the sequence in which the agents commit\nto their decisions, and its associated equilibrium in an N-player Stackelberg\ntrajectory game. We model this problem as a mixed-integer optimization problem\nover the space of all possible Stackelberg games associated with the order of\nplay's permutations. To solve the problem, we introduce Branch and Play (B&P),\nan efficient and exact algorithm that provably converges to a socially optimal\norder of play and its Stackelberg equilibrium. As a subroutine for B&P, we\nemploy and extend sequential trajectory planning, i.e., a popular multi-agent\ncontrol approach, to scalably compute valid local Stackelberg equilibria for\nany given order of play. We demonstrate the practical utility of B&P to\ncoordinate air traffic control, swarm formation, and delivery vehicle fleets.\nWe find that B&P consistently outperforms various baselines, and computes the\nsocially optimal equilibrium.\n","authors":["Haimin Hu","Gabriele Dragotto","Zixu Zhang","Kaiqu Liang","Bartolomeo Stellato","Jaime F. Fisac"],"pdf_url":"https://arxiv.org/pdf/2402.09246v4.pdf","comment":"Robotics: Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2406.17235v1","updated":"2024-06-25T02:53:37Z","published":"2024-06-25T02:53:37Z","title":"Task-Agnostic Federated Learning","summary":"  In the realm of medical imaging, leveraging large-scale datasets from various\ninstitutions is crucial for developing precise deep learning models, yet\nprivacy concerns frequently impede data sharing. federated learning (FL)\nemerges as a prominent solution for preserving privacy while facilitating\ncollaborative learning. However, its application in real-world scenarios faces\nseveral obstacles, such as task & data heterogeneity, label scarcity,\nnon-identically distributed (non-IID) data, computational vaiation, etc. In\nreal-world, medical institutions may not want to disclose their tasks to FL\nserver and generalization challenge of out-of-network institutions with un-seen\ntask want to join the on-going federated system. This study address\ntask-agnostic and generalization problem on un-seen tasks by adapting\nself-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus\nfeature encoder for self-supervised pre-training, no initial labels required,\nthe framework enabling effective representation learning across diverse\ndatasets and tasks. Our extensive evaluations, using various real-world non-IID\nmedical imaging datasets, validate our approach's efficacy, retaining 90\\% of\nF1 accuracy with only 5\\% of the training data typically required for\ncentralized approaches and exhibiting superior adaptability to\nout-of-distribution task. The result indicate that federated learning\narchitecture can be a potential approach toward multi-task foundation modeling.\n","authors":["Zhengtao Yao","Hong Nguyen","Ajitesh Srivastava","Jose Luis Ambite"],"pdf_url":"https://arxiv.org/pdf/2406.17235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16495v2","updated":"2024-06-25T02:20:14Z","published":"2024-06-24T10:05:23Z","title":"OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to\n  construct Observer-Thinker-Conceiver-Expresser","summary":"  Recent research has shown that combining Mamba with Transformer architecture,\nwhich has selective state space and quadratic self-attention mechanism,\noutperforms using Mamba or Transformer architecture alone in language modeling\ntasks. The quadratic self-attention mechanism effectively alleviates the\nshortcomings of selective state space in handling long-term dependencies of any\nelement in the sequence. We propose a position information injection method\nthat connects the selective state space model with the quadratic attention, and\nintegrates these two architectures with hybrid experts with cross-sharing\ndomains, so that we can enjoy the advantages of both. We design a new\narchitecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser\n(OTCE), which can compete with well-known medium-scale open-source language\nmodels on a small scale in language modeling tasks.\n","authors":["Jingze Shi","Ting Xie","Bingheng Wu","Chunjun Zheng","Kai Wang"],"pdf_url":"https://arxiv.org/pdf/2406.16495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17224v1","updated":"2024-06-25T02:18:15Z","published":"2024-06-25T02:18:15Z","title":"Large Language Models are Interpretable Learners","summary":"  The trade-off between expressiveness and interpretability remains a core\nchallenge when building human-centric predictive models for classification and\ndecision-making. While symbolic rules offer interpretability, they often lack\nexpressiveness, whereas neural networks excel in performance but are known for\nbeing black boxes. In this paper, we show a combination of Large Language\nModels (LLMs) and symbolic programs can bridge this gap. In the proposed\nLLM-based Symbolic Programs (LSPs), the pretrained LLM with natural language\nprompts provides a massive set of interpretable modules that can transform raw\ninput into natural language concepts. Symbolic programs then integrate these\nmodules into an interpretable decision rule. To train LSPs, we develop a\ndivide-and-conquer approach to incrementally build the program from scratch,\nwhere the learning process of each step is guided by LLMs. To evaluate the\neffectiveness of LSPs in extracting interpretable and accurate knowledge from\ndata, we introduce IL-Bench, a collection of diverse tasks, including both\nsynthetic and real-world scenarios across different modalities. Empirical\nresults demonstrate LSP's superior performance compared to traditional\nneurosymbolic programs and vanilla automatic prompt tuning methods. Moreover,\nas the knowledge learned by LSP is a combination of natural language\ndescriptions and symbolic rules, it is easily transferable to humans\n(interpretable), and other LLMs, and generalizes well to out-of-distribution\nsamples.\n","authors":["Ruochen Wang","Si Si","Felix Yu","Dorothea Wiesmann","Cho-Jui Hsieh","Inderjit Dhillon"],"pdf_url":"https://arxiv.org/pdf/2406.17224v1.pdf","comment":"Preliminary Version, Code at [this\n  url](https://github.com/ruocwang/llm-symbolic-program)"},{"id":"http://arxiv.org/abs/2406.10285v2","updated":"2024-06-25T02:11:46Z","published":"2024-06-12T09:16:19Z","title":"I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse\n  Adversarial Patches for Object Detectors","summary":"  Deep neural networks (DNNs) have revolutionized the field of computer vision\nlike object detection with their unparalleled performance. However, existing\nresearch has shown that DNNs are vulnerable to adversarial attacks. In the\nphysical world, an adversary could exploit adversarial patches to implement a\nHiding Attack (HA) which patches the target object to make it disappear from\nthe detector, and an Appearing Attack (AA) which fools the detector into\nmisclassifying the patch as a specific object. Recently, many defense methods\nfor detectors have been proposed to mitigate the potential threats of\nadversarial patches. However, such methods still have limitations in\ngeneralization, robustness and efficiency. Most defenses are only effective\nagainst the HA, leaving the detector vulnerable to the AA.\n  In this paper, we propose \\textit{NutNet}, an innovative model for detecting\nadversarial patches, with high generalization, robustness and efficiency. With\nexperiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on\nboth digital and physical domains, the results show that our proposed method\ncan effectively defend against both the HA and AA, with only 0.4\\% sacrifice of\nthe clean performance. We compare NutNet with four baseline defense methods for\ndetectors, and our method exhibits an average defense performance that is over\n2.4 times and 4.7 times higher than existing approaches for HA and AA,\nrespectively. In addition, NutNet only increases the inference time by 8\\%,\nwhich can meet the real-time requirements of the detection systems. Demos of\nNutNet are available at: \\url{https://sites.google.com/view/nutnet}.\n","authors":["Zijin Lin","Yue Zhao","Kai Chen","Jinwen He"],"pdf_url":"https://arxiv.org/pdf/2406.10285v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17216v1","updated":"2024-06-25T02:05:29Z","published":"2024-06-25T02:05:29Z","title":"Machine Unlearning Fails to Remove Data Poisoning Attacks","summary":"  We revisit the efficacy of several practical methods for approximate machine\nunlearning developed for large-scale deep learning. In addition to complying\nwith data deletion requests, one often-cited potential application for\nunlearning methods is to remove the effects of training on poisoned data. We\nexperimentally demonstrate that, while existing unlearning methods have been\ndemonstrated to be effective in a number of evaluation settings (e.g.,\nalleviating membership inference attacks), they fail to remove the effects of\ndata poisoning, across a variety of types of poisoning attacks (indiscriminate,\ntargeted, and a newly-introduced Gaussian poisoning attack) and models (image\nclassifiers and LLMs); even when granted a relatively large compute budget. In\norder to precisely characterize unlearning efficacy, we introduce new\nevaluation metrics for unlearning based on data poisoning. Our results suggest\nthat a broader perspective, including a wider variety of evaluations, is\nrequired to avoid a false sense of confidence in machine unlearning procedures\nfor deep learning without provable guarantees. Moreover, while unlearning\nmethods show some signs of being useful to efficiently remove poisoned\ndatapoints without having to retrain, our work suggests that these methods are\nnot yet \"ready for prime time\", and currently provide limited benefit over\nretraining.\n","authors":["Martin Pawelczyk","Jimmy Z. Di","Yiwei Lu","Gautam Kamath","Ayush Sekhari","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2406.17216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17215v1","updated":"2024-06-25T02:05:26Z","published":"2024-06-25T02:05:26Z","title":"Enabling Large Language Models to Perform Power System Simulations with\n  Previously Unseen Tools: A Case of Daline","summary":"  The integration of experiment technologies with large language models (LLMs)\nis transforming scientific research, offering AI capabilities beyond\nspecialized problem-solving to becoming research assistants for human\nscientists. In power systems, simulations are essential for research. However,\nLLMs face significant challenges in power system simulations due to limited\npre-existing knowledge and the complexity of power grids. To address this\nissue, this work proposes a modular framework that integrates expertise from\nboth the power system and LLM domains. This framework enhances LLMs' ability to\nperform power system simulations on previously unseen tools. Validated using 34\nsimulation tasks in Daline, a (optimal) power flow simulation and linearization\ntoolbox not yet exposed to LLMs, the proposed framework improved GPT-4o's\nsimulation coding accuracy from 0% to 96.07%, also outperforming the ChatGPT-4o\nweb interface's 33.8% accuracy (with the entire knowledge base uploaded). These\nresults highlight the potential of LLMs as research assistants in power\nsystems.\n","authors":["Mengshuo Jia","Zeyu Cui","Gabriela Hug"],"pdf_url":"https://arxiv.org/pdf/2406.17215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17188v1","updated":"2024-06-25T00:02:01Z","published":"2024-06-25T00:02:01Z","title":"Geometric Median (GM) Matching for Robust Data Pruning","summary":"  Data pruning, the combinatorial task of selecting a small and informative\nsubset from a large dataset, is crucial for mitigating the enormous\ncomputational costs associated with training data-hungry modern deep learning\nmodels at scale. Since large-scale data collections are invariably noisy,\ndeveloping data pruning strategies that remain robust even in the presence of\ncorruption is critical in practice. Unfortunately, the existing heuristics for\n(robust) data pruning lack theoretical coherence and rely on heroic\nassumptions, that are, often unattainable, by the very nature of the problem\nsetting. Moreover, these strategies often yield sub-optimal neural scaling laws\neven compared to random sampling, especially in scenarios involving strong\ncorruption and aggressive pruning rates -- making provably robust data pruning\nan open challenge. In response, in this work, we propose Geometric Median\n($\\gm$) Matching -- a herding~\\citep{welling2009herding} style greedy algorithm\n-- that yields a $k$-subset such that the mean of the subset approximates the\ngeometric median of the (potentially) noisy dataset. Theoretically, we show\nthat $\\gm$ Matching enjoys an improved $\\gO(1/k)$ scaling over\n$\\gO(1/\\sqrt{k})$ scaling of uniform sampling; while achieving the optimal\nbreakdown point of 1/2 even under arbitrary corruption. Extensive experiments\nacross popular deep learning benchmarks indicate that $\\gm$ Matching\nconsistently outperforms prior state-of-the-art; the gains become more profound\nat high rates of corruption and aggressive pruning rates; making $\\gm$ Matching\na strong baseline for future research in robust data pruning.\n","authors":["Anish Acharya","Inderjit S Dhillon","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2406.17188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10490v3","updated":"2024-06-25T22:52:43Z","published":"2024-05-17T01:44:30Z","title":"Neural Optimization with Adaptive Heuristics for Intelligent Marketing\n  System","summary":"  Computational marketing has become increasingly important in today's digital\nworld, facing challenges such as massive heterogeneous data, multi-channel\ncustomer journeys, and limited marketing budgets. In this paper, we propose a\ngeneral framework for marketing AI systems, the Neural Optimization with\nAdaptive Heuristics (NOAH) framework. NOAH is the first general framework for\nmarketing optimization that considers both to-business (2B) and to-consumer\n(2C) products, as well as both owned and paid channels. We describe key modules\nof the NOAH framework, including prediction, optimization, and adaptive\nheuristics, providing examples for bidding and content optimization. We then\ndetail the successful application of NOAH to LinkedIn's email marketing system,\nshowcasing significant wins over the legacy ranking system. Additionally, we\nshare details and insights that are broadly useful, particularly on: (i)\naddressing delayed feedback with lifetime value, (ii) performing large-scale\nlinear programming with randomization, (iii) improving retrieval with audience\nexpansion, (iv) reducing signal dilution in targeting tests, and (v) handling\nzero-inflated heavy-tail metrics in statistical testing.\n","authors":["Changshuai Wei","Benjamin Zelditch","Joyce Chen","Andre Assuncao Silva T Ribeiro","Jingyi Kenneth Tay","Borja Ocejo Elizondo","Keerthi Selvaraj","Aman Gupta","Licurgo Benemann De Almeida"],"pdf_url":"https://arxiv.org/pdf/2405.10490v3.pdf","comment":"KDD 2024"},{"id":"http://arxiv.org/abs/2406.17969v1","updated":"2024-06-25T22:51:08Z","published":"2024-06-25T22:51:08Z","title":"Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a\n  Feature Decorrelation Perspective","summary":"  To better interpret the intrinsic mechanism of large language models (LLMs),\nrecent studies focus on monosemanticity on its basic units. A monosemantic\nneuron is dedicated to a single and specific concept, which forms a one-to-one\ncorrelation between neurons and concepts. Despite extensive research in\nmonosemanticity probing, it remains unclear whether monosemanticity is\nbeneficial or harmful to model capacity. To explore this question, we revisit\nmonosemanticity from the feature decorrelation perspective and advocate for its\nencouragement. We experimentally observe that the current conclusion by\nwang2024learning, which suggests that decreasing monosemanticity enhances model\nperformance, does not hold when the model changes. Instead, we demonstrate that\nmonosemanticity consistently exhibits a positive correlation with model\ncapacity, in the preference alignment process. Consequently, we apply feature\ncorrelation as a proxy for monosemanticity and incorporate a feature\ndecorrelation regularizer into the dynamic preference optimization process. The\nexperiments show that our method not only enhances representation diversity and\nactivation sparsity but also improves preference alignment performance.\n","authors":["Hanqi Yan","Yanzheng Xiang","Guangyi Chen","Yifei Wang","Lin Gui","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2406.17969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17968v1","updated":"2024-06-25T22:50:48Z","published":"2024-06-25T22:50:48Z","title":"Efficient Document Ranking with Learnable Late Interactions","summary":"  Cross-Encoder (CE) and Dual-Encoder (DE) models are two fundamental\napproaches for query-document relevance in information retrieval. To predict\nrelevance, CE models use joint query-document embeddings, while DE models\nmaintain factorized query and document embeddings; usually, the former has\nhigher quality while the latter benefits from lower latency. Recently,\nlate-interaction models have been proposed to realize more favorable\nlatency-quality tradeoffs, by using a DE structure followed by a lightweight\nscorer based on query and document token embeddings. However, these lightweight\nscorers are often hand-crafted, and there is no understanding of their\napproximation power; further, such scorers require access to individual\ndocument token embeddings, which imposes an increased latency and storage\nburden. In this paper, we propose novel learnable late-interaction models\n(LITE) that resolve these issues. Theoretically, we prove that LITE is a\nuniversal approximator of continuous scoring functions, even for relatively\nsmall embedding dimension. Empirically, LITE outperforms previous\nlate-interaction models such as ColBERT on both in-domain and zero-shot\nre-ranking tasks. For instance, experiments on MS MARCO passage re-ranking show\nthat LITE not only yields a model with better generalization, but also lowers\nlatency and requires 0.25x storage compared to ColBERT.\n","authors":["Ziwei Ji","Himanshu Jain","Andreas Veit","Sashank J. Reddi","Sadeep Jayasumana","Ankit Singh Rawat","Aditya Krishna Menon","Felix Yu","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2406.17968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17961v1","updated":"2024-06-25T22:40:03Z","published":"2024-06-25T22:40:03Z","title":"NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data\n  Normalization","summary":"  In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities in parsing textual data and generating code. However, their\nperformance in tasks involving tabular data, especially those requiring\nsymbolic reasoning, faces challenges due to the structural variance and\ninconsistency in table cell values often found in web tables. In this paper, we\nintroduce NormTab, a novel framework aimed at enhancing the symbolic reasoning\nperformance of LLMs by normalizing web tables. We study table normalization as\na stand-alone, one-time preprocessing step using LLMs to support symbolic\nreasoning on tabular data. Our experimental evaluation, conducted on\nchallenging web table datasets such as WikiTableQuestion and TabFact,\ndemonstrates that leveraging NormTab significantly improves symbolic reasoning\nperformance, showcasing the importance and effectiveness of web table\nnormalization for enhancing LLM-based symbolic reasoning tasks.\n","authors":["Md Mahadi Hasan Nahid","Davood Rafiei"],"pdf_url":"https://arxiv.org/pdf/2406.17961v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2311.16711v2","updated":"2024-06-25T22:33:57Z","published":"2023-11-28T11:45:35Z","title":"LEDITS++: Limitless Image Editing using Text-to-Image Models","summary":"  Text-to-image diffusion models have recently received increasing interest for\ntheir astonishing ability to produce high-fidelity images from solely text\ninputs. Subsequent research efforts aim to exploit and apply their capabilities\nto real image editing. However, existing image-to-image methods are often\ninefficient, imprecise, and of limited versatility. They either require\ntime-consuming finetuning, deviate unnecessarily strongly from the input image,\nand/or lack support for multiple, simultaneous edits. To address these issues,\nwe introduce LEDITS++, an efficient yet versatile and precise textual image\nmanipulation technique. LEDITS++'s novel inversion approach requires no tuning\nnor optimization and produces high-fidelity results with a few diffusion steps.\nSecond, our methodology supports multiple simultaneous edits and is\narchitecture-agnostic. Third, we use a novel implicit masking technique that\nlimits changes to relevant image regions. We propose the novel TEdBench++\nbenchmark as part of our exhaustive evaluation. Our results demonstrate the\ncapabilities of LEDITS++ and its improvements over previous methods.\n","authors":["Manuel Brack","Felix Friedrich","Katharina Kornmeier","Linoy Tsaban","Patrick Schramowski","Kristian Kersting","Apolinário Passos"],"pdf_url":"https://arxiv.org/pdf/2311.16711v2.pdf","comment":"Proceedings of the 2024 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) The project page is available at\n  https://leditsplusplus-project.static.hf.space"},{"id":"http://arxiv.org/abs/2406.17960v1","updated":"2024-06-25T22:33:41Z","published":"2024-06-25T22:33:41Z","title":"MAGIC: Meta-Ability Guided Interactive Chain-of-Distillation for\n  Effective-and-Efficient Vision-and-Language Navigation","summary":"  Despite the remarkable developments of recent large models in Embodied\nArtificial Intelligence (E-AI), their integration into robotics is hampered by\ntheir excessive parameter sizes and computational demands. Towards the\nVision-and-Language Navigation (VLN) task, a core task in E-AI, this paper\nreveals the great potential of using knowledge distillation for obtaining\nlightweight student models by proposing a Meta-Ability Guided Interactive\nChain-of-distillation (MAGIC) method. Specifically, a Meta-Ability Knowledge\nDistillation (MAKD) framework is proposed for decoupling and refining the\nnecessary meta-abilities of VLN agents. A Meta-Knowledge Randomization\nWeighting (MKRW) and a Meta-Knowledge Transferable Determination (MKTD) module\nare incorporated to dynamically adjust aggregation weights at the meta-ability\nand sample levels, respectively. Move beyond the traditional one-step\nunidirectional distillation, an Interactive Chain-of-Distillation (ICoD)\nlearning strategy is proposed to allow students to give feedback to teachers,\nforming a new multi-step teacher-student co-evolution pipeline. Remarkably, on\nthe R2R test unseen public leaderboard, our smallest model, MAGIC-S, with only\n5% (11M) of the teacher's size, outperforms all previous methods under the same\ntraining data. Additionally, our largest model, MAGIC-L, surpasses the previous\nstate-of-the-art by 5.84% in SPL and 3.18% in SR. Furthermore, a new dataset\nwas collected and annotated from our living environments, where MAGIC-S\ndemonstrated superior performance and real-time efficiency. Our code is\npublicly available on https://github.com/CrystalSixone/VLN-MAGIC.\n","authors":["Liuyi Wang","Zongtao He","Mengjiao Shen","Jingwei Yang","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02416v3","updated":"2024-06-25T22:21:17Z","published":"2024-01-04T18:59:25Z","title":"ODIN: A Single Model for 2D and 3D Segmentation","summary":"  State-of-the-art models on contemporary 3D segmentation benchmarks like\nScanNet consume and label dataset-provided 3D point clouds, obtained through\npost processing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website (https://odin-seg.github.io).\n","authors":["Ayush Jain","Pushkal Katara","Nikolaos Gkanatsios","Adam W. Harley","Gabriel Sarch","Kriti Aggarwal","Vishrav Chaudhary","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2401.02416v3.pdf","comment":"Camera Ready (CVPR 2024, Highlight)"},{"id":"http://arxiv.org/abs/2406.17957v1","updated":"2024-06-25T22:18:52Z","published":"2024-06-25T22:18:52Z","title":"Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic\n  Alignment","summary":"  Large Language Model (LLM) based text-to-speech (TTS) systems have\ndemonstrated remarkable capabilities in handling large speech datasets and\ngenerating natural speech for new speakers. However, LLM-based TTS models are\nnot robust as the generated output can contain repeating words, missing words\nand mis-aligned speech (referred to as hallucinations or attention errors),\nespecially when the text contains multiple occurrences of the same token. We\nexamine these challenges in an encoder-decoder transformer model and find that\ncertain cross-attention heads in such models implicitly learn the text and\nspeech alignment when trained for predicting speech tokens for a given text. To\nmake the alignment more robust, we propose techniques utilizing CTC loss and\nattention priors that encourage monotonic cross-attention over the text tokens.\nOur guided attention training technique does not introduce any new learnable\nparameters and significantly improves robustness of LLM-based TTS models.\n","authors":["Paarth Neekhara","Shehzeen Hussain","Subhankar Ghosh","Jason Li","Rafael Valle","Rohan Badlani","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2406.17957v1.pdf","comment":"Published as a conference paper at INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.17949v1","updated":"2024-06-25T21:51:43Z","published":"2024-06-25T21:51:43Z","title":"The Overcooked Generalisation Challenge","summary":"  We introduce the Overcooked Generalisation Challenge (OGC) - the first\nbenchmark to study agents' zero-shot cooperation abilities when faced with\nnovel partners and levels in the Overcooked-AI environment. This perspective\nstarkly contrasts a large body of previous work that has trained and evaluated\ncooperating agents only on the same level, failing to capture generalisation\nabilities required for real-world human-AI cooperation. Our challenge\ninterfaces with state-of-the-art dual curriculum design (DCD) methods to\ngenerate auto-curricula for training general agents in Overcooked. It is the\nfirst cooperative multi-agent environment specially designed for DCD methods\nand, consequently, the first benchmarked with state-of-the-art methods. It is\nfully GPU-accelerated, built on the DCD benchmark suite minimax, and freely\navailable under an open-source license:\nhttps://git.hcics.simtech.uni-stuttgart.de/public-projects/OGC. We show that\ncurrent DCD algorithms struggle to produce useful policies in this novel\nchallenge, even if combined with recent network architectures that were\ndesigned for scalability and generalisability. The OGC pushes the boundaries of\nreal-world human-AI cooperation by enabling the research community to study the\nimpact of generalisation on cooperating agents.\n","authors":["Constantin Ruhdorfer","Matteo Bortoletto","Anna Penzkofer","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2406.17949v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.14066v2","updated":"2024-06-25T20:53:16Z","published":"2024-06-20T07:43:33Z","title":"Optimizing Speculative Decoding for Serving Large Language Models Using\n  Goodput","summary":"  Reducing the inference latency of large language models (LLMs) is crucial,\nand speculative decoding (SD) stands out as one of the most effective\ntechniques. Rather than letting the LLM generate all tokens directly,\nspeculative decoding employs effective proxies to predict potential outputs,\nwhich are then verified by the LLM without compromising the generation quality.\nYet, deploying SD in real online LLM serving systems (with continuous batching)\ndoes not always yield improvement -- under higher request rates or low\nspeculation accuracy, it paradoxically increases latency. Furthermore, there is\nno best speculation length work for all workloads under different system loads.\nBased on the observations, we develop a dynamic framework SmartSpec. SmartSpec\ndynamically determines the best speculation length for each request (from 0,\ni.e., no speculation, to many tokens) -- hence the associated speculative\nexecution costs -- based on a new metric called goodput, which characterizes\nthe current observed load of the entire system and the speculation accuracy. We\nshow that SmartSpec consistently reduces average request latency by up to 3.2x\ncompared to non-speculative decoding baselines across different sizes of target\nmodels, draft models, request rates, and datasets. Moreover, SmartSpec can be\napplied to different styles of speculative decoding, including traditional,\nmodel-based approaches as well as model-free methods like prompt lookup and\ntree-style decoding.\n","authors":["Xiaoxuan Liu","Cade Daniel","Langxiang Hu","Woosuk Kwon","Zhuohan Li","Xiangxi Mo","Alvin Cheung","Zhijie Deng","Ion Stoica","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.14066v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17915v1","updated":"2024-06-25T19:56:12Z","published":"2024-06-25T19:56:12Z","title":"Semi-supervised classification of dental conditions in panoramic\n  radiographs using large language model and instance segmentation: A\n  real-world dataset evaluation","summary":"  Dental panoramic radiographs offer vast diagnostic opportunities, but\ntraining supervised deep learning networks for automatic analysis of those\nradiology images is hampered by a shortage of labeled data. Here, a different\nperspective on this problem is introduced. A semi-supervised learning framework\nis proposed to classify thirteen dental conditions on panoramic radiographs,\nwith a particular emphasis on teeth. Large language models were explored to\nannotate the most common dental conditions based on dental reports.\nAdditionally, a masked autoencoder was employed to pre-train the classification\nneural network, and a Vision Transformer was used to leverage the unlabeled\ndata. The analyses were validated using two of the most extensive datasets in\nthe literature, comprising 8,795 panoramic radiographs and 8,029 paired reports\nand images. Encouragingly, the results consistently met or surpassed the\nbaseline metrics for the Matthews correlation coefficient. A comparison of the\nproposed solution with human practitioners, supported by statistical analysis,\nhighlighted its effectiveness and performance limitations; based on the degree\nof agreement among specialists, the solution demonstrated an accuracy level\ncomparable to that of a junior specialist.\n","authors":["Bernardo Silva","Jefferson Fontinele","Carolina Letícia Zilli Vieira","João Manuel R. S. Tavares","Patricia Ramos Cury","Luciano Oliveira"],"pdf_url":"https://arxiv.org/pdf/2406.17915v1.pdf","comment":"43 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2406.17910v1","updated":"2024-06-25T19:51:21Z","published":"2024-06-25T19:51:21Z","title":"Transforming Software Development: Evaluating the Efficiency and\n  Challenges of GitHub Copilot in Real-World Projects","summary":"  Generative AI technologies promise to transform the product development\nlifecycle. This study evaluates the efficiency gains, areas for improvement,\nand emerging challenges of using GitHub Copilot, an AI-powered coding\nassistant. We identified 15 software development tasks and assessed Copilot's\nbenefits through real-world projects on large proprietary code bases. Our\nfindings indicate significant reductions in developer toil, with up to 50% time\nsaved in code documentation and autocompletion, and 30-40% in repetitive coding\ntasks, unit test generation, debugging, and pair programming. However, Copilot\nstruggles with complex tasks, large functions, multiple files, and proprietary\ncontexts, particularly with C/C++ code. We project a 33-36% time reduction for\ncoding-related tasks in a cloud-first software development lifecycle. This\nstudy aims to quantify productivity improvements, identify underperforming\nscenarios, examine practical benefits and challenges, investigate performance\nvariations across programming languages, and discuss emerging issues related to\ncode quality, security, and developer experience.\n","authors":["Ruchika Pandey","Prabhat Singh","Raymond Wei","Shaila Shankar"],"pdf_url":"https://arxiv.org/pdf/2406.17910v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2406.17906v1","updated":"2024-06-25T19:40:55Z","published":"2024-06-25T19:40:55Z","title":"Unbiasing on the Fly: Explanation-Guided Human Oversight of Machine\n  Learning System Decisions","summary":"  The widespread adoption of ML systems across critical domains like hiring,\nfinance, and healthcare raises growing concerns about their potential for\ndiscriminatory decision-making based on protected attributes. While efforts to\nensure fairness during development are crucial, they leave deployed ML systems\nvulnerable to potentially exhibiting discrimination during their operations. To\naddress this gap, we propose a novel framework for on-the-fly tracking and\ncorrection of discrimination in deployed ML systems. Leveraging counterfactual\nexplanations, the framework continuously monitors the predictions made by an ML\nsystem and flags discriminatory outcomes. When flagged, post-hoc explanations\nrelated to the original prediction and the counterfactual alternatives are\npresented to a human reviewer for real-time intervention. This\nhuman-in-the-loop approach empowers reviewers to accept or override the ML\nsystem decision, enabling fair and responsible ML operation under dynamic\nsettings. While further work is needed for validation and refinement, this\nframework offers a promising avenue for mitigating discrimination and building\ntrust in ML systems deployed in a wide range of domains.\n","authors":["Hussaini Mamman","Shuib Basri","Abdullateef Balogun","Abubakar Abdullahi Imam","Ganesh Kumar","Luiz Fernando Capretz"],"pdf_url":"https://arxiv.org/pdf/2406.17906v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2406.17904v1","updated":"2024-06-25T19:35:25Z","published":"2024-06-25T19:35:25Z","title":"Application of Liquid Rank Reputation System for Twitter Trend Analysis\n  on Bitcoin","summary":"  Analyzing social media trends can create a win-win situation for both\ncreators and consumers. Creators can receive fair compensation, while consumers\ngain access to engaging, relevant, and personalized content. This paper\nproposes a new model for analyzing Bitcoin trends on Twitter by incorporating a\n'liquid democracy' approach based on user reputation. This system aims to\nidentify the most impactful trends and their influence on Bitcoin prices and\ntrading volume. It uses a Twitter sentiment analysis model based on a\nreputation rating system to determine the impact on Bitcoin price change and\ntraded volume. In addition, the reputation model considers the users'\nhigher-order friends on the social network (the initial Twitter input channels\nin our case study) to improve the accuracy and diversity of the reputation\nresults. We analyze Bitcoin-related news on Twitter to understand how trends\nand user sentiment, measured through our Liquid Rank Reputation System, affect\nBitcoin price fluctuations and trading activity within the studied time frame.\nThis reputation model can also be used as an additional layer in other trend\nand sentiment analysis models. The paper proposes the implementation,\nchallenges, and future scope of the liquid rank reputation model.\n","authors":["Abhishek Saxena","Anton Kolonin"],"pdf_url":"https://arxiv.org/pdf/2406.17904v1.pdf","comment":"Under publication in 2024 Ural-Siberian Conference on Biomedical\n  Engineering, Radioelectronics and Information Technology, Yekaterinburg,\n  Russia"},{"id":"http://arxiv.org/abs/2406.17902v1","updated":"2024-06-25T19:26:39Z","published":"2024-06-25T19:26:39Z","title":"Domain Adaptation of Echocardiography Segmentation Via Reinforcement\n  Learning","summary":"  Performance of deep learning segmentation models is significantly challenged\nin its transferability across different medical imaging domains, particularly\nwhen aiming to adapt these models to a target domain with insufficient\nannotated data for effective fine-tuning. While existing domain adaptation (DA)\nmethods propose strategies to alleviate this problem, these methods do not\nexplicitly incorporate human-verified segmentation priors, compromising the\npotential of a model to produce anatomically plausible segmentations. We\nintroduce RL4Seg, an innovative reinforcement learning framework that reduces\nthe need to otherwise incorporate large expertly annotated datasets in the\ntarget domain, and eliminates the need for lengthy manual human review. Using a\ntarget dataset of 10,000 unannotated 2D echocardiographic images, RL4Seg not\nonly outperforms existing state-of-the-art DA methods in accuracy but also\nachieves 99% anatomical validity on a subset of 220 expert-validated subjects\nfrom the target domain. Furthermore, our framework's reward network offers\nuncertainty estimates comparable with dedicated state-of-the-art uncertainty\nmethods, demonstrating the utility and effectiveness of RL4Seg in overcoming\ndomain adaptation challenges in medical image segmentation.\n","authors":["Arnaud Judge","Thierry Judge","Nicolas Duchateau","Roman A. Sandler","Joseph Z. Sokol","Olivier Bernard","Pierre-Marc Jodoin"],"pdf_url":"https://arxiv.org/pdf/2406.17902v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.17898v1","updated":"2024-06-25T19:19:10Z","published":"2024-06-25T19:19:10Z","title":"Human-centered In-building Embodied Delivery Benchmark","summary":"  Recently, the concept of embodied intelligence has been widely accepted and\npopularized, leading people to naturally consider the potential for\ncommercialization in this field. In this work, we propose a specific commercial\nscenario simulation, human-centered in-building embodied delivery. Furthermore,\nfor this scenario, we have developed a brand-new virtual environment system\nfrom scratch, constructing a multi-level connected building space modeled after\na polar research station. This environment also includes autonomous human\ncharacters and robots with grasping and mobility capabilities, as well as a\nlarge number of interactive items. Based on this environment, we have built a\ndelivery dataset containing 13k language instructions to guide robots in\nproviding services. We simulate human behavior through human characters and\nsample their various needs in daily life. Finally, we proposed a method\ncentered around a large multimodal model to serve as the baseline system for\nthis dataset. Compared to past embodied data work, our work focuses on a\nvirtual environment centered around human-robot interaction for commercial\nscenarios. We believe this will bring new perspectives and exploration angles\nto the embodied community.\n","authors":["Zhuoqun Xu","Yang Liu","Xiaoqi Li","Jiyao Zhang","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2406.17898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17888v1","updated":"2024-06-25T18:52:48Z","published":"2024-06-25T18:52:48Z","title":"CTBench: A Comprehensive Benchmark for Evaluating Language Model\n  Capabilities in Clinical Trial Design","summary":"  CTBench is introduced as a benchmark to assess language models (LMs) in\naiding clinical study design. Given study-specific metadata, CTBench evaluates\nAI models' ability to determine the baseline features of a clinical trial (CT),\nwhich include demographic and relevant features collected at the trial's start\nfrom all participants. These baseline features, typically presented in CT\npublications (often as Table 1), are crucial for characterizing study cohorts\nand validating results. Baseline features, including confounders and\ncovariates, are also necessary for accurate treatment effect estimation in\nstudies involving observational data. CTBench consists of two datasets:\n\"CT-Repo,\" containing baseline features from 1,690 clinical trials sourced from\nclinicaltrials.gov, and \"CT-Pub,\" a subset of 100 trials with more\ncomprehensive baseline features gathered from relevant publications. Two\nLM-based evaluation methods are developed to compare the actual baseline\nfeature lists against LM-generated responses. \"ListMatch-LM\" and\n\"ListMatch-BERT\" use GPT-4o and BERT scores (at various thresholds),\nrespectively, for evaluation. To establish baseline results, advanced prompt\nengineering techniques using LLaMa3-70B-Instruct and GPT-4o in zero-shot and\nthree-shot learning settings are applied to generate potential baseline\nfeatures. The performance of GPT-4o as an evaluator is validated through\nhuman-in-the-loop evaluations on the CT-Pub dataset, where clinical experts\nconfirm matches between actual and LM-generated features. The results highlight\na promising direction with significant potential for improvement, positioning\nCTBench as a useful tool for advancing research on AI in CT design and\npotentially enhancing the efficacy and robustness of CTs.\n","authors":["Nafis Neehal","Bowen Wang","Shayom Debopadhaya","Soham Dan","Keerthiram Murugesan","Vibha Anand","Kristin P. Bennett"],"pdf_url":"https://arxiv.org/pdf/2406.17888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17887v1","updated":"2024-06-25T18:51:08Z","published":"2024-06-25T18:51:08Z","title":"Federated Dynamical Low-Rank Training with Global Loss Convergence\n  Guarantees","summary":"  In this work, we propose a federated dynamical low-rank training (FeDLRT)\nscheme to reduce client compute and communication costs - two significant\nperformance bottlenecks in horizontal federated learning. Our method builds\nupon dynamical low-rank splitting schemes for manifold-constrained optimization\nto create a global low-rank basis of network weights, which enables client\ntraining on a small coefficient matrix. A consistent global low-rank basis\nallows us to incorporate a variance correction scheme and prove global loss\ndescent and convergence to a stationary point. Dynamic augmentation and\ntruncation of the low-rank bases automatically optimizes computing and\ncommunication resource utilization. We demonstrate the efficiency of FeDLRT in\nan array of computer vision benchmarks and show a reduction of client compute\nand communication costs by up to an order of magnitude with minimal impacts on\nglobal accuracy.\n","authors":["Steffen Schotthöfer","M. Paul Laiu"],"pdf_url":"https://arxiv.org/pdf/2406.17887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17885v1","updated":"2024-06-25T18:47:50Z","published":"2024-06-25T18:47:50Z","title":"Enabling Regional Explainability by Automatic and Model-agnostic Rule\n  Extraction","summary":"  In Explainable AI, rule extraction translates model knowledge into logical\nrules, such as IF-THEN statements, crucial for understanding patterns learned\nby black-box models. This could significantly aid in fields like disease\ndiagnosis, disease progression estimation, or drug discovery. However, such\napplication domains often contain imbalanced data, with the class of interest\nunderrepresented. Existing methods inevitably compromise the performance of\nrules for the minor class to maximise the overall performance. As the first\nattempt in this field, we propose a model-agnostic approach for extracting\nrules from specific subgroups of data, featuring automatic rule generation for\nnumerical features. This method enhances the regional explainability of machine\nlearning models and offers wider applicability compared to existing methods. We\nadditionally introduce a new method for selecting features to compose rules,\nreducing computational costs in high-dimensional spaces. Experiments across\nvarious datasets and models demonstrate the effectiveness of our methods.\n","authors":["Yu Chen","Tianyu Cui","Alexander Capstick","Nan Fletcher-Loyd","Payam Barnaghi"],"pdf_url":"https://arxiv.org/pdf/2406.17885v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2406.04175v2","updated":"2024-06-25T18:37:19Z","published":"2024-06-06T15:32:29Z","title":"Confabulation: The Surprising Value of Large Language Model\n  Hallucinations","summary":"  This paper presents a systematic defense of large language model (LLM)\nhallucinations or 'confabulations' as a potential resource instead of a\ncategorically negative pitfall. The standard view is that confabulations are\ninherently problematic and AI research should eliminate this flaw. In this\npaper, we argue and empirically demonstrate that measurable semantic\ncharacteristics of LLM confabulations mirror a human propensity to utilize\nincreased narrativity as a cognitive resource for sense-making and\ncommunication. In other words, it has potential value. Specifically, we analyze\npopular hallucination benchmarks and reveal that hallucinated outputs display\nincreased levels of narrativity and semantic coherence relative to veridical\noutputs. This finding reveals a tension in our usually dismissive\nunderstandings of confabulation. It suggests, counter-intuitively, that the\ntendency for LLMs to confabulate may be intimately associated with a positive\ncapacity for coherent narrative-text generation.\n","authors":["Peiqi Sui","Eamon Duede","Sophie Wu","Richard Jean So"],"pdf_url":"https://arxiv.org/pdf/2406.04175v2.pdf","comment":"Forthcoming at ACL2024 main conference. 1 figure"},{"id":"http://arxiv.org/abs/2406.17876v1","updated":"2024-06-25T18:35:13Z","published":"2024-06-25T18:35:13Z","title":"ET tu, CLIP? Addressing Common Object Errors for Unseen Environments","summary":"  We introduce a simple method that employs pre-trained CLIP encoders to\nenhance model generalization in the ALFRED task. In contrast to previous\nliterature where CLIP replaces the visual encoder, we suggest using CLIP as an\nadditional module through an auxiliary object detection objective. We validate\nour method on the recently proposed Episodic Transformer architecture and\ndemonstrate that incorporating CLIP improves task performance on the unseen\nvalidation set. Additionally, our analysis results support that CLIP especially\nhelps with leveraging object descriptions, detecting small objects, and\ninterpreting rare words.\n","authors":["Ye Won Byun","Cathy Jiao","Shahriar Noroozizadeh","Jimin Sun","Rosa Vitiello"],"pdf_url":"https://arxiv.org/pdf/2406.17876v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.17777v1","updated":"2024-06-25T17:59:41Z","published":"2024-06-25T17:59:41Z","title":"Text-Animator: Controllable Visual Text Video Generation","summary":"  Video generation is a challenging yet pivotal task in various industries,\nsuch as gaming, e-commerce, and advertising. One significant unresolved aspect\nwithin T2V is the effective visualization of text within generated videos.\nDespite the progress achieved in Text-to-Video~(T2V) generation, current\nmethods still cannot effectively visualize texts in videos directly, as they\nmainly focus on summarizing semantic scene information, understanding, and\ndepicting actions. While recent advances in image-level visual text generation\nshow promise, transitioning these techniques into the video domain faces\nproblems, notably in preserving textual fidelity and motion coherence. In this\npaper, we propose an innovative approach termed Text-Animator for visual text\nvideo generation. Text-Animator contains a text embedding injection module to\nprecisely depict the structures of visual text in generated videos. Besides, we\ndevelop a camera control module and a text refinement module to improve the\nstability of generated visual text by controlling the camera movement as well\nas the motion of visualized text. Quantitative and qualitative experimental\nresults demonstrate the superiority of our approach to the accuracy of\ngenerated visual text over state-of-the-art video generation methods. The\nproject page can be found at https://laulampaul.github.io/text-animator.html.\n","authors":["Lin Liu","Quande Liu","Shengju Qian","Yuan Zhou","Wengang Zhou","Houqiang Li","Lingxi Xie","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2406.17777v1.pdf","comment":"Project Page: https://laulampaul.github.io/text-animator.html"},{"id":"http://arxiv.org/abs/2406.17774v1","updated":"2024-06-25T17:59:06Z","published":"2024-06-25T17:59:06Z","title":"Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using\n  Frequency Domain Analysis","summary":"  Relightable object acquisition is a key challenge in simplifying digital\nasset creation. Complete reconstruction of an object typically requires\ncapturing hundreds to thousands of photographs under controlled illumination,\nwith specialized equipment. The recent progress in differentiable rendering\nimproved the quality and accessibility of inverse rendering optimization.\nNevertheless, under uncontrolled illumination and unstructured viewpoints,\nthere is no guarantee that the observations contain enough information to\nreconstruct the appearance properties of the captured object.\n  We thus propose to consider the acquisition process from a signal-processing\nperspective. Given an object's geometry and a lighting environment, we estimate\nthe properties of the materials on the object's surface in seconds. We do so by\nleveraging frequency domain analysis, considering the recovery of material\nproperties as a deconvolution, enabling fast error estimation. We then quantify\nthe uncertainty of the estimation, based on the available data, highlighting\nthe areas for which priors or additional samples would be required for improved\nacquisition quality. We compare our approach to previous work and\nquantitatively evaluate our results, showing similar quality as previous work\nin a fraction of the time, and providing key information about the certainty of\nthe results.\n","authors":["Ruben Wiersma","Julien Philip","Miloš Hašan","Krishna Mullia","Fujun Luan","Elmar Eisemann","Valentin Deschaintre"],"pdf_url":"https://arxiv.org/pdf/2406.17774v1.pdf","comment":"Project page: https://brdf-uncertainty.github.io"},{"id":"http://arxiv.org/abs/2403.16494v2","updated":"2024-06-25T17:56:21Z","published":"2024-03-25T07:22:22Z","title":"CT-Bound: Robust Boundary Detection From Noisy Images Via Hybrid\n  Convolution and Transformer Neural Networks","summary":"  We present CT-Bound, a robust and fast boundary detection method for very\nnoisy images using a hybrid Convolution and Transformer neural network. The\nproposed architecture decomposes boundary estimation into two tasks: local\ndetection and global regularization. During the local detection, the model uses\na convolutional architecture to predict the boundary structure of each image\npatch in the form of a pre-defined local boundary representation, the\nfield-of-junctions (FoJ). Then, it uses a feed-forward transformer architecture\nto globally refine the boundary structures of each patch to generate an edge\nmap and a smoothed color map simultaneously. Our quantitative analysis shows\nthat CT-Bound outperforms the previous best algorithms in edge detection on\nvery noisy images. It also increases the edge detection accuracy of FoJ-based\nmethods while having a 3-time speed improvement. Finally, we demonstrate that\nCT-Bound can produce boundary and color maps on real captured images without\nextra fine-tuning and real-time boundary map and color map videos at ten frames\nper second.\n","authors":["Wei Xu","Junjie Luo","Qi Guo"],"pdf_url":"https://arxiv.org/pdf/2403.16494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12289v5","updated":"2024-06-25T17:55:35Z","published":"2024-02-19T17:04:04Z","title":"DriveVLM: The Convergence of Autonomous Driving and Large\n  Vision-Language Models","summary":"  A primary hurdle of autonomous driving in urban environments is understanding\ncomplex and long-tail scenarios, such as challenging road conditions and\ndelicate human behaviors. We introduce DriveVLM, an autonomous driving system\nleveraging Vision-Language Models (VLMs) for enhanced scene understanding and\nplanning capabilities. DriveVLM integrates a unique combination of reasoning\nmodules for scene description, scene analysis, and hierarchical planning.\nFurthermore, recognizing the limitations of VLMs in spatial reasoning and heavy\ncomputational requirements, we propose DriveVLM-Dual, a hybrid system that\nsynergizes the strengths of DriveVLM with the traditional autonomous driving\npipeline. Experiments on both the nuScenes dataset and our SUP-AD dataset\ndemonstrate the efficacy of DriveVLM and DriveVLM-Dual in handling complex and\nunpredictable driving conditions. Finally, we deploy the DriveVLM-Dual on a\nproduction vehicle, verifying it is effective in real-world autonomous driving\nenvironments.\n","authors":["Xiaoyu Tian","Junru Gu","Bailin Li","Yicheng Liu","Yang Wang","Zhiyong Zhao","Kun Zhan","Peng Jia","Xianpeng Lang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.12289v5.pdf","comment":"Project Page: https://tsinghua-mars-lab.github.io/DriveVLM/"},{"id":"http://arxiv.org/abs/2406.17770v1","updated":"2024-06-25T17:55:11Z","published":"2024-06-25T17:55:11Z","title":"MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning","summary":"  Multi-modal large language models (MLLMs) have made significant strides in\nvarious visual understanding tasks. However, the majority of these models are\nconstrained to process low-resolution images, which limits their effectiveness\nin perception tasks that necessitate detailed visual information. In our study,\nwe present MG-LLaVA, an innovative MLLM that enhances the model's visual\nprocessing capabilities by incorporating a multi-granularity vision flow, which\nincludes low-resolution, high-resolution, and object-centric features. We\npropose the integration of an additional high-resolution visual encoder to\ncapture fine-grained details, which are then fused with base visual features\nthrough a Conv-Gate fusion network. To further refine the model's object\nrecognition abilities, we incorporate object-level features derived from\nbounding boxes identified by offline detectors. Being trained solely on\npublicly available multimodal data through instruction tuning, MG-LLaVA\ndemonstrates exceptional perception skills. We instantiate MG-LLaVA with a wide\nvariety of language encoders, ranging from 3.8B to 34B, to evaluate the model's\nperformance comprehensively. Extensive evaluations across multiple benchmarks\ndemonstrate that MG-LLaVA outperforms existing MLLMs of comparable parameter\nsizes, showcasing its remarkable efficacy. The code will be available at\nhttps://github.com/PhoenixZ810/MG-LLaVA.\n","authors":["Xiangyu Zhao","Xiangtai Li","Haodong Duan","Haian Huang","Yining Li","Kai Chen","Hua Yang"],"pdf_url":"https://arxiv.org/pdf/2406.17770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17763v1","updated":"2024-06-25T17:48:24Z","published":"2024-06-25T17:48:24Z","title":"DiffusionPDE: Generative PDE-Solving Under Partial Observation","summary":"  We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.\n","authors":["Jiahe Huang","Guandao Yang","Zichen Wang","Jeong Joon Park"],"pdf_url":"https://arxiv.org/pdf/2406.17763v1.pdf","comment":"Project page: https://jhhuangchloe.github.io/Diffusion-PDE/"},{"id":"http://arxiv.org/abs/2406.17758v1","updated":"2024-06-25T17:42:25Z","published":"2024-06-25T17:42:25Z","title":"MotionBooth: Motion-Aware Customized Text-to-Video Generation","summary":"  In this work, we present MotionBooth, an innovative framework designed for\nanimating customized subjects with precise control over both object and camera\nmovements. By leveraging a few images of a specific object, we efficiently\nfine-tune a text-to-video model to capture the object's shape and attributes\naccurately. Our approach presents subject region loss and video preservation\nloss to enhance the subject's learning performance, along with a subject token\ncross-attention loss to integrate the customized subject with motion control\nsignals. Additionally, we propose training-free techniques for managing subject\nand camera motions during inference. In particular, we utilize cross-attention\nmap manipulation to govern subject motion and introduce a novel latent shift\nmodule for camera movement control as well. MotionBooth excels in preserving\nthe appearance of subjects while simultaneously controlling the motions in\ngenerated videos. Extensive quantitative and qualitative evaluations\ndemonstrate the superiority and effectiveness of our method. Our project page\nis at https://jianzongwu.github.io/projects/motionbooth\n","authors":["Jianzong Wu","Xiangtai Li","Yanhong Zeng","Jiangning Zhang","Qianyu Zhou","Yining Li","Yunhai Tong","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17758v1.pdf","comment":"Project page at https://jianzongwu.github.io/projects/motionbooth"},{"id":"http://arxiv.org/abs/2405.13285v2","updated":"2024-06-25T17:40:35Z","published":"2024-05-22T01:54:51Z","title":"Enhancing Active Learning for Sentinel 2 Imagery through Contrastive\n  Learning and Uncertainty Estimation","summary":"  In this paper, we introduce a novel method designed to enhance label\nefficiency in satellite imagery analysis by integrating semi-supervised\nlearning (SSL) with active learning strategies. Our approach utilizes\ncontrastive learning together with uncertainty estimations via Monte Carlo\nDropout (MC Dropout), with a particular focus on Sentinel-2 imagery analyzed\nusing the Eurosat dataset. We explore the effectiveness of our method in\nscenarios featuring both balanced and unbalanced class distributions. Our\nresults show that the proposed method performs better than several other\npopular methods in this field, enabling significant savings in labeling effort\nwhile maintaining high classification accuracy. These findings highlight the\npotential of our approach to facilitate scalable and cost-effective satellite\nimage analysis, particularly advantageous for extensive environmental\nmonitoring and land use classification tasks.\n","authors":["David Pogorzelski","Peter Arlinghaus","Wenyan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.13285v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17749v1","updated":"2024-06-25T17:34:52Z","published":"2024-06-25T17:34:52Z","title":"Benchmarking Deep Learning Models on NVIDIA Jetson Nano for Real-Time\n  Systems: An Empirical Investigation","summary":"  The proliferation of complex deep learning (DL) models has revolutionized\nvarious applications, including computer vision-based solutions, prompting\ntheir integration into real-time systems. However, the resource-intensive\nnature of these models poses challenges for deployment on low-computational\npower and low-memory devices, like embedded and edge devices. This work\nempirically investigates the optimization of such complex DL models to analyze\ntheir functionality on an embedded device, particularly on the NVIDIA Jetson\nNano. It evaluates the effectiveness of the optimized models in terms of their\ninference speed for image classification and video action detection. The\nexperimental results reveal that, on average, optimized models exhibit a 16.11%\nspeed improvement over their non-optimized counterparts. This not only\nemphasizes the critical need to consider hardware constraints and environmental\nsustainability in model development and deployment but also underscores the\npivotal role of model optimization in enabling the widespread deployment of\nAI-assisted technologies on resource-constrained computational systems. It also\nserves as proof that prioritizing hardware-specific model optimization leads to\nefficient and scalable solutions that substantially decrease energy consumption\nand carbon footprint.\n","authors":["Tushar Prasanna Swaminathan","Christopher Silver","Thangarajah Akilan"],"pdf_url":"https://arxiv.org/pdf/2406.17749v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2401.09384v2","updated":"2024-06-25T17:33:31Z","published":"2024-01-17T17:55:06Z","title":"Diverse Part Synthesis for 3D Shape Creation","summary":"  Methods that use neural networks for synthesizing 3D shapes in the form of a\npart-based representation have been introduced over the last few years. These\nmethods represent shapes as a graph or hierarchy of parts and enable a variety\nof applications such as shape sampling and reconstruction. However, current\nmethods do not allow easily regenerating individual shape parts according to\nuser preferences. In this paper, we investigate techniques that allow the user\nto generate multiple, diverse suggestions for individual parts. Specifically,\nwe experiment with multimodal deep generative models that allow sampling\ndiverse suggestions for shape parts and focus on models which have not been\nconsidered in previous work on shape synthesis. To provide a comparative study\nof these techniques, we introduce a method for synthesizing 3D shapes in a\npart-based representation and evaluate all the part suggestion techniques\nwithin this synthesis method. In our method, which is inspired by previous\nwork, shapes are represented as a set of parts in the form of implicit\nfunctions which are then positioned in space to form the final shape. Synthesis\nin this representation is enabled by a neural network architecture based on an\nimplicit decoder and a spatial transformer. We compare the various multimodal\ngenerative models by evaluating their performance in generating part\nsuggestions. Our contribution is to show with qualitative and quantitative\nevaluations which of the new techniques for multimodal part generation perform\nthe best and that a synthesis method based on the top-performing techniques\nallows the user to more finely control the parts that are generated in the 3D\nshapes while maintaining high shape fidelity when reconstructing shapes.\n","authors":["Yanran Guan","Oliver van Kaick"],"pdf_url":"https://arxiv.org/pdf/2401.09384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17741v1","updated":"2024-06-25T17:28:03Z","published":"2024-06-25T17:28:03Z","title":"Point-SAM: Promptable 3D Segmentation Model for Point Clouds","summary":"  The development of 2D foundation models for image segmentation has been\nsignificantly advanced by the Segment Anything Model (SAM). However, achieving\nsimilar success in 3D models remains a challenge due to issues such as\nnon-unified data formats, lightweight models, and the scarcity of labeled data\nwith diverse masks. To this end, we propose a 3D promptable segmentation model\n(Point-SAM) focusing on point clouds. Our approach utilizes a transformer-based\nmethod, extending SAM to the 3D domain. We leverage part-level and object-level\nannotations and introduce a data engine to generate pseudo labels from SAM,\nthereby distilling 2D knowledge into our 3D model. Our model outperforms\nstate-of-the-art models on several indoor and outdoor benchmarks and\ndemonstrates a variety of applications, such as 3D annotation. Codes and demo\ncan be found at https://github.com/zyc00/Point-SAM.\n","authors":["Yuchen Zhou","Jiayuan Gu","Tung Yen Chiang","Fanbo Xiang","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2406.17741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17740v1","updated":"2024-06-25T17:26:05Z","published":"2024-06-25T17:26:05Z","title":"Structured Unrestricted-Rank Matrices for Parameter Efficient\n  Fine-tuning","summary":"  Recent efforts to scale Transformer models have demonstrated rapid progress\nacross a wide range of tasks (Wei et al., 2022). However, fine-tuning these\nmodels for downstream tasks is expensive due to their large parameter counts.\nParameter-efficient fine-tuning (PEFT) approaches have emerged as a viable\nalternative by allowing us to fine-tune models by updating only a small number\nof parameters. In this work, we propose a general framework for parameter\nefficient fine-tuning (PEFT), based on structured unrestricted-rank matrices\n(SURM) which can serve as a drop-in replacement for popular approaches such as\nAdapters and LoRA. Unlike other methods like LoRA, SURMs provides more\nflexibility in finding the right balance between compactness and\nexpressiveness. This is achieved by using low displacement rank matrices\n(LDRMs), which hasn't been used in this context before. SURMs remain\ncompetitive with baselines, often providing significant quality improvements\nwhile using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on\nvarious image classification tasks while replacing low-rank matrices in LoRA.\nIt also results in up to 12x reduction of the number of parameters in adapters\n(with virtually no loss in quality) on the GLUE benchmark.\n","authors":["Arijit Sehanobish","Avinava Dubey","Krzysztof Choromanski","Somnath Basu Roy Chowdhury","Deepali Jain","Vikas Sindhwani","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2406.17740v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.17720v1","updated":"2024-06-25T17:09:54Z","published":"2024-06-25T17:09:54Z","title":"Arboretum: A Large Multimodal Dataset Enabling AI for Biodiversity","summary":"  We introduce Arboretum, the largest publicly accessible dataset designed to\nadvance AI for biodiversity applications. This dataset, curated from the\niNaturalist community science platform and vetted by domain experts to ensure\naccuracy, includes 134.6 million images, surpassing existing datasets in scale\nby an order of magnitude. The dataset encompasses image-language paired data\nfor a diverse set of species from birds (Aves), spiders/ticks/mites\n(Arachnida), insects (Insecta), plants (Plantae), fungus/mushrooms (Fungi),\nsnails (Mollusca), and snakes/lizards (Reptilia), making it a valuable resource\nfor multimodal vision-language AI models for biodiversity assessment and\nagriculture research. Each image is annotated with scientific names, taxonomic\ndetails, and common names, enhancing the robustness of AI model training.\n  We showcase the value of Arboretum by releasing a suite of CLIP models\ntrained using a subset of 40 million captioned images. We introduce several new\nbenchmarks for rigorous assessment, report accuracy for zero-shot learning, and\nevaluations across life stages, rare species, confounding species, and various\nlevels of the taxonomic hierarchy.\n  We anticipate that Arboretum will spur the development of AI models that can\nenable a variety of digital tools ranging from pest control strategies, crop\nmonitoring, and worldwide biodiversity assessment and environmental\nconservation. These advancements are critical for ensuring food security,\npreserving ecosystems, and mitigating the impacts of climate change. Arboretum\nis publicly available, easily accessible, and ready for immediate use.\n  Please see the \\href{https://baskargroup.github.io/Arboretum/}{project\nwebsite} for links to our data, models, and code.\n","authors":["Chih-Hsuan Yang","Benjamin Feuer","Zaki Jubery","Zi K. Deng","Andre Nakkab","Md Zahid Hasan","Shivani Chiranjeevi","Kelly Marshall","Nirmal Baishnab","Asheesh K Singh","Arti Singh","Soumik Sarkar","Nirav Merchant","Chinmay Hegde","Baskar Ganapathysubramanian"],"pdf_url":"https://arxiv.org/pdf/2406.17720v1.pdf","comment":"Preprint under review"},{"id":"http://arxiv.org/abs/2312.03806v2","updated":"2024-06-25T17:01:54Z","published":"2023-12-06T16:23:26Z","title":"XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies","summary":"  We present XCube (abbreviated as $\\mathcal{X}^3$), a novel generative model\nfor high-resolution sparse 3D voxel grids with arbitrary attributes. Our model\ncan generate millions of voxels with a finest effective resolution of up to\n$1024^3$ in a feed-forward fashion without time-consuming test-time\noptimization. To achieve this, we employ a hierarchical voxel latent diffusion\nmodel which generates progressively higher resolution grids in a coarse-to-fine\nmanner using a custom framework built on the highly efficient VDB data\nstructure. Apart from generating high-resolution objects, we demonstrate the\neffectiveness of XCube on large outdoor scenes at scales of 100m$\\times$100m\nwith a voxel size as small as 10cm. We observe clear qualitative and\nquantitative improvements over past approaches. In addition to unconditional\ngeneration, we show that our model can be used to solve a variety of tasks such\nas user-guided editing, scene completion from a single scan, and text-to-3D.\nThe source code and more results can be found at\nhttps://research.nvidia.com/labs/toronto-ai/xcube/.\n","authors":["Xuanchi Ren","Jiahui Huang","Xiaohui Zeng","Ken Museth","Sanja Fidler","Francis Williams"],"pdf_url":"https://arxiv.org/pdf/2312.03806v2.pdf","comment":"CVPR 2024 Highlight. Code: https://github.com/nv-tlabs/XCube/\n  Website: https://research.nvidia.com/labs/toronto-ai/xcube/"},{"id":"http://arxiv.org/abs/2404.15275v3","updated":"2024-06-25T16:57:27Z","published":"2024-04-23T17:59:43Z","title":"ID-Animator: Zero-Shot Identity-Preserving Human Video Generation","summary":"  Generating high-fidelity human video with specified identities has attracted\nsignificant attention in the content generation community. However, existing\ntechniques struggle to strike a balance between training efficiency and\nidentity preservation, either requiring tedious case-by-case fine-tuning or\nusually missing identity details in the video generation process. In this\nstudy, we present \\textbf{ID-Animator}, a zero-shot human-video generation\napproach that can perform personalized video generation given a single\nreference facial image without further training. ID-Animator inherits existing\ndiffusion-based video generation backbones with a face adapter to encode the\nID-relevant embeddings from learnable facial latent queries. To facilitate the\nextraction of identity information in video generation, we introduce an\nID-oriented dataset construction pipeline that incorporates unified human\nattributes and action captioning techniques from a constructed facial image\npool. Based on this pipeline, a random reference training strategy is further\ndevised to precisely capture the ID-relevant embeddings with an ID-preserving\nloss, thus improving the fidelity and generalization capacity of our model for\nID-specific video generation. Extensive experiments demonstrate the superiority\nof ID-Animator to generate personalized human videos over previous models.\nMoreover, our method is highly compatible with popular pre-trained T2V models\nlike animatediff and various community backbone models, showing high\nextendability in real-world applications for video generation where identity\npreservation is highly desired. Our codes and checkpoints are released at\nhttps://github.com/ID-Animator/ID-Animator.\n","authors":["Xuanhua He","Quande Liu","Shengju Qian","Xin Wang","Tao Hu","Ke Cao","Keyu Yan","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.15275v3.pdf","comment":"Project Page: https://id-animator.github.io/"},{"id":"http://arxiv.org/abs/2405.02652v2","updated":"2024-06-25T16:53:21Z","published":"2024-05-04T12:37:07Z","title":"Deep Pulse-Signal Magnification for remote Heart Rate Estimation in\n  Compressed Videos","summary":"  Recent advancements in data-driven approaches for remote photoplethysmography\n(rPPG) have significantly improved the accuracy of remote heart rate\nestimation. However, the performance of such approaches worsens considerably\nunder video compression, which is nevertheless necessary to store and transmit\nvideo data efficiently. In this paper, we present a novel approach to address\nthe impact of video compression on rPPG estimation, which leverages a\npulse-signal magnification transformation to adapt compressed videos to an\nuncompressed data domain in which the rPPG signal is magnified. We validate the\neffectiveness of our model by exhaustive evaluations on two publicly available\ndatasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database\nperformance at several compression rates. Additionally, we assess the\nrobustness of our approach on two additional highly compressed and widely-used\ndatasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate\nestimation results.\n","authors":["Joaquim Comas","Adria Ruiz","Federico Sukno"],"pdf_url":"https://arxiv.org/pdf/2405.02652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17709v1","updated":"2024-06-25T16:48:18Z","published":"2024-06-25T16:48:18Z","title":"Mask-Guided Attention U-Net for Enhanced Neonatal Brain Extraction and\n  Image Preprocessing","summary":"  In this study, we introduce MGA-Net, a novel mask-guided attention neural\nnetwork, which extends the U-net model for precision neonatal brain imaging.\nMGA-Net is designed to extract the brain from other structures and reconstruct\nhigh-quality brain images. The network employs a common encoder and two\ndecoders: one for brain mask extraction and the other for brain region\nreconstruction. A key feature of MGA-Net is its high-level mask-guided\nattention module, which leverages features from the brain mask decoder to\nenhance image reconstruction. To enable the same encoder and decoder to process\nboth MRI and ultrasound (US) images, MGA-Net integrates sinusoidal positional\nencoding. This encoding assigns distinct positional values to MRI and US\nimages, allowing the model to effectively learn from both modalities.\nConsequently, features learned from a single modality can aid in learning a\nmodality with less available data, such as US. We extensively validated the\nproposed MGA-Net on diverse datasets from varied clinical settings and neonatal\nage groups. The metrics used for assessment included the DICE similarity\ncoefficient, recall, and accuracy for image segmentation; structural similarity\nfor image reconstruction; and root mean squared error for total brain volume\nestimation from 3D ultrasound images. Our results demonstrate that MGA-Net\nsignificantly outperforms traditional methods, offering superior performance in\nbrain extraction and segmentation while achieving high precision in image\nreconstruction and volumetric analysis. Thus, MGA-Net represents a robust and\neffective preprocessing tool for MRI and 3D ultrasound images, marking a\nsignificant advance in neuroimaging that enhances both research and clinical\ndiagnostics in the neonatal period and beyond.\n","authors":["Bahram Jafrasteh","Simon Pedro Lubian-Lopez","Emiliano Trimarco","Macarena Roman Ruiz","Carmen Rodriguez Barrios","Yolanda Marin Almagro","Isabel Benavente-Fernandez"],"pdf_url":"https://arxiv.org/pdf/2406.17709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17707v1","updated":"2024-06-25T16:46:21Z","published":"2024-06-25T16:46:21Z","title":"SurgeMOD: Translating image-space tissue motions into vision-based\n  surgical forces","summary":"  We present a new approach for vision-based force estimation in Minimally\nInvasive Robotic Surgery based on frequency domain basis of motion of organs\nderived directly from video. Using internal movements generated by natural\nprocesses like breathing or the cardiac cycle, we infer the image-space basis\nof the motion on the frequency domain. As we are working with this\nrepresentation, we discretize the problem to a limited amount of\nlow-frequencies to build an image-space mechanical model of the environment. We\nuse this pre-built model to define our force estimation problem as a dynamic\nconstraint problem. We demonstrate that this method can estimate point contact\nforces reliably for silicone phantom and ex-vivo experiments, matching real\nreadings from a force sensor. In addition, we perform qualitative experiments\nin which we synthesize coherent force textures from surgical videos over a\ncertain region of interest selected by the user. Our method demonstrates good\nresults for both quantitative and qualitative analysis, providing a good\nstarting point for a purely vision-based method for surgical force estimation.\n","authors":["Mikel De Iturrate Reyzabal","Dionysios Malas","Shuai Wang","Sebastien Ourselin","Hongbin Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17697v1","updated":"2024-06-25T16:33:33Z","published":"2024-06-25T16:33:33Z","title":"HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target\n  Binding Affinity Prediction","summary":"  Drug target binding affinity (DTA) is a key criterion for drug screening.\nExisting experimental methods are time-consuming and rely on limited structural\nand domain information. While learning-based methods can model sequence and\nstructural information, they struggle to integrate contextual data and often\nlack comprehensive modeling of drug-target interactions. In this study, we\npropose a novel DTA prediction method, termed HGTDP-DTA, which utilizes dynamic\nprompts within a hybrid Graph-Transformer framework. Our method generates\ncontext-specific prompts for each drug-target pair, enhancing the model's\nability to capture unique interactions. The introduction of prompt tuning\nfurther optimizes the prediction process by filtering out irrelevant noise and\nemphasizing task-relevant information, dynamically adjusting the input features\nof the molecular graph. The proposed hybrid Graph-Transformer architecture\ncombines structural information from Graph Convolutional Networks (GCNs) with\nsequence information captured by Transformers, facilitating the interaction\nbetween global and local information. Additionally, we adopted the multi-view\nfeature fusion method to project molecular graph views and affinity subgraph\nviews into a common feature space, effectively combining structural and\ncontextual information. Experiments on two widely used public datasets, Davis\nand KIBA, show that HGTDP-DTA outperforms state-of-the-art DTA prediction\nmethods in both prediction performance and generalization ability.\n","authors":["Xi Xiao","Wentao Wang","Jiacheng Xie","Lijing Zhu","Gaofei Chen","Zhengji Li","Tianyang Wang","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2406.17697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13536v2","updated":"2024-06-25T16:28:48Z","published":"2024-06-19T13:19:08Z","title":"Image Distillation for Safe Data Sharing in Histopathology","summary":"  Histopathology can help clinicians make accurate diagnoses, determine disease\nprognosis, and plan appropriate treatment strategies. As deep learning\ntechniques prove successful in the medical domain, the primary challenges\nbecome limited data availability and concerns about data sharing and privacy.\nFederated learning has addressed this challenge by training models locally and\nupdating parameters on a server. However, issues, such as domain shift and\nbias, persist and impact overall performance. Dataset distillation presents an\nalternative approach to overcoming these challenges. It involves creating a\nsmall synthetic dataset that encapsulates essential information, which can be\nshared without constraints. At present, this paradigm is not practicable as\ncurrent distillation approaches only generate non human readable\nrepresentations and exhibit insufficient performance for downstream learning\ntasks. We train a latent diffusion model and construct a new distilled\nsynthetic dataset with a small number of human readable synthetic images.\nSelection of maximally informative synthetic images is done via graph community\nanalysis of the representation space. We compare downstream classification\nmodels trained on our synthetic distillation data to models trained on real\ndata and reach performances suitable for practical application.\n","authors":["Zhe Li","Bernhard Kainz"],"pdf_url":"https://arxiv.org/pdf/2406.13536v2.pdf","comment":"accepted at MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17688v1","updated":"2024-06-25T16:24:34Z","published":"2024-06-25T16:24:34Z","title":"Unified Auto-Encoding with Masked Diffusion","summary":"  At the core of both successful generative and self-supervised representation\nlearning models there is a reconstruction objective that incorporates some form\nof image corruption. Diffusion models implement this approach through a\nscheduled Gaussian corruption process, while masked auto-encoder models do so\nby masking patches of the image. Despite their different approaches, the\nunderlying similarity in their methodologies suggests a promising avenue for an\nauto-encoder capable of both de-noising tasks. We propose a unified\nself-supervised objective, dubbed Unified Masked Diffusion (UMD), that combines\npatch-based and noise-based corruption techniques within a single auto-encoding\nframework. Specifically, UMD modifies the diffusion transformer (DiT) training\nprocess by introducing an additional noise-free, high masking representation\nstep in the diffusion noising schedule, and utilizes a mixed masked and noised\nimage for subsequent timesteps. By integrating features useful for diffusion\nmodeling and for predicting masked patch tokens, UMD achieves strong\nperformance in downstream generative and representation learning tasks,\nincluding linear probing and class-conditional generation. This is achieved\nwithout the need for heavy data augmentations, multiple views, or additional\nencoders. Furthermore, UMD improves over the computational efficiency of prior\ndiffusion based methods in total training time. We release our code at\nhttps://github.com/philippe-eecs/small-vision.\n","authors":["Philippe Hansen-Estruch","Sriram Vishwanath","Amy Zhang","Manan Tomar"],"pdf_url":"https://arxiv.org/pdf/2406.17688v1.pdf","comment":"19 Pages, 8 Figures, 3Tables"},{"id":"http://arxiv.org/abs/2403.07576v3","updated":"2024-06-25T16:15:54Z","published":"2024-03-12T12:05:43Z","title":"Fine-grained Prompt Tuning: A Parameter and Memory Efficient Transfer\n  Learning Method for High-resolution Medical Image Classification","summary":"  Parameter-efficient transfer learning (PETL) is proposed as a cost-effective\nway to transfer pre-trained models to downstream tasks, avoiding the high cost\nof updating entire large-scale pre-trained models (LPMs). In this work, we\npresent Fine-grained Prompt Tuning (FPT), a novel PETL method for medical image\nclassification. FPT significantly reduces memory consumption compared to other\nPETL methods, especially in high-resolution input contexts. To achieve this, we\nfirst freeze the weights of the LPM and construct a learnable lightweight side\nnetwork. The frozen LPM takes high-resolution images as input to extract\nfine-grained features, while the side network is fed low-resolution images to\nreduce memory usage. To allow the side network to access pre-trained knowledge,\nwe introduce fine-grained prompts that summarize information from the LPM\nthrough a fusion module. Important tokens selection and preloading techniques\nare employed to further reduce training cost and memory requirements. We\nevaluate FPT on four medical datasets with varying sizes, modalities, and\ncomplexities. Experimental results demonstrate that FPT achieves comparable\nperformance to fine-tuning the entire LPM while using only 1.8% of the\nlearnable parameters and 13% of the memory costs of an encoder ViT-B model with\na 512 x 512 input resolution.\n","authors":["Yijin Huang","Pujin Cheng","Roger Tam","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2403.07576v3.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17680v1","updated":"2024-06-25T16:12:52Z","published":"2024-06-25T16:12:52Z","title":"End-to-End Autonomous Driving without Costly Modularization and 3D\n  Manual Annotation","summary":"  We propose UAD, a method for vision-based end-to-end autonomous driving\n(E2EAD), achieving the best open-loop evaluation performance in nuScenes,\nmeanwhile showing robust closed-loop driving quality in CARLA. Our motivation\nstems from the observation that current E2EAD models still mimic the modular\narchitecture in typical driving stacks, with carefully designed supervised\nperception and prediction subtasks to provide environment information for\noriented planning. Although achieving groundbreaking progress, such design has\ncertain drawbacks: 1) preceding subtasks require massive high-quality 3D\nannotations as supervision, posing a significant impediment to scaling the\ntraining data; 2) each submodule entails substantial computation overhead in\nboth training and inference. To this end, we propose UAD, an E2EAD framework\nwith an unsupervised proxy to address all these issues. Firstly, we design a\nnovel Angular Perception Pretext to eliminate the annotation requirement. The\npretext models the driving scene by predicting the angular-wise spatial\nobjectness and temporal dynamics, without manual annotation. Secondly, a\nself-supervised training strategy, which learns the consistency of the\npredicted trajectories under different augment views, is proposed to enhance\nthe planning robustness in steering scenarios. Our UAD achieves 38.7% relative\nimprovements over UniAD on the average collision rate in nuScenes and surpasses\nVAD for 41.32 points on the driving score in CARLA's Town05 Long benchmark.\nMoreover, the proposed method only consumes 44.3% training resources of UniAD\nand runs 3.4 times faster in inference. Our innovative design not only for the\nfirst time demonstrates unarguable performance advantages over supervised\ncounterparts, but also enjoys unprecedented efficiency in data, training, and\ninference. Code and models will be released at\nhttps://github.com/KargoBot_Research/UAD.\n","authors":["Mingzhe Guo","Zhipeng Zhang","Yuan He","Ke Wang","Liping Jing"],"pdf_url":"https://arxiv.org/pdf/2406.17680v1.pdf","comment":"17 pages, 10 figures and 15 tables"},{"id":"http://arxiv.org/abs/2406.17679v1","updated":"2024-06-25T16:12:20Z","published":"2024-06-25T16:12:20Z","title":"Local-to-Global Cross-Modal Attention-Aware Fusion for HSI-X Semantic\n  Segmentation","summary":"  Hyperspectral image (HSI) classification has recently reached its performance\nbottleneck. Multimodal data fusion is emerging as a promising approach to\novercome this bottleneck by providing rich complementary information from the\nsupplementary modality (X-modality). However, achieving comprehensive\ncross-modal interaction and fusion that can be generalized across different\nsensing modalities is challenging due to the disparity in imaging sensors,\nresolution, and content of different modalities. In this study, we propose a\nLocal-to-Global Cross-modal Attention-aware Fusion (LoGoCAF) framework for\nHSI-X classification that jointly considers efficiency, accuracy, and\ngeneralizability. LoGoCAF adopts a pixel-to-pixel two-branch semantic\nsegmentation architecture to learn information from HSI and X modalities. The\npipeline of LoGoCAF consists of a local-to-global encoder and a lightweight\nmultilayer perceptron (MLP) decoder. In the encoder, convolutions are used to\nencode local and high-resolution fine details in shallow layers, while\ntransformers are used to integrate global and low-resolution coarse features in\ndeeper layers. The MLP decoder aggregates information from the encoder for\nfeature fusion and prediction. In particular, two cross-modality modules, the\nfeature enhancement module (FEM) and the feature interaction and fusion module\n(FIFM), are introduced in each encoder stage. The FEM is used to enhance\ncomplementary information by combining the feature from the other modality\nacross direction-aware, position-sensitive, and channel-wise dimensions. With\nthe enhanced features, the FIFM is designed to promote cross-modality\ninformation interaction and fusion for the final semantic prediction. Extensive\nexperiments demonstrate that our LoGoCAF achieves superior performance and\ngeneralizes well. The code will be made publicly available.\n","authors":["Xuming Zhang","Naoto Yokoya","Xingfa Gu","Qingjiu Tian","Lorenzo Bruzzone"],"pdf_url":"https://arxiv.org/pdf/2406.17679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.15889v2","updated":"2024-06-25T16:02:25Z","published":"2023-03-28T11:04:18Z","title":"Metrics for Dataset Demographic Bias: A Case Study on Facial Expression\n  Recognition","summary":"  Demographic biases in source datasets have been shown as one of the causes of\nunfairness and discrimination in the predictions of Machine Learning models.\nOne of the most prominent types of demographic bias are statistical imbalances\nin the representation of demographic groups in the datasets. In this paper, we\nstudy the measurement of these biases by reviewing the existing metrics,\nincluding those that can be borrowed from other disciplines. We develop a\ntaxonomy for the classification of these metrics, providing a practical guide\nfor the selection of appropriate metrics. To illustrate the utility of our\nframework, and to further understand the practical characteristics of the\nmetrics, we conduct a case study of 20 datasets used in Facial Emotion\nRecognition (FER), analyzing the biases present in them. Our experimental\nresults show that many metrics are redundant and that a reduced subset of\nmetrics may be sufficient to measure the amount of demographic bias. The paper\nprovides valuable insights for researchers in AI and related fields to mitigate\ndataset bias and improve the fairness and accuracy of AI models. The code is\navailable at https://github.com/irisdominguez/dataset_bias_metrics.\n","authors":["Iris Dominguez-Catena","Daniel Paternain","Mikel Galar"],"pdf_url":"https://arxiv.org/pdf/2303.15889v2.pdf","comment":"16 pages, 8 figures. Including appendix: 45 pages, 32 figures.\n  Updated from previous version with an additional appendix, addressing\n  concerns about the interest of studying bias at the dataset level"},{"id":"http://arxiv.org/abs/2406.17670v1","updated":"2024-06-25T15:58:56Z","published":"2024-06-25T15:58:56Z","title":"Brain Tumor Classification using Vision Transformer with Selective\n  Cross-Attention Mechanism and Feature Calibration","summary":"  Brain tumor classification is a challenging task in medical image analysis.\nIn this paper, we propose a novel approach to brain tumor classification using\na vision transformer with a novel cross-attention mechanism. Our approach\nleverages the strengths of transformers in modeling long-range dependencies and\nmulti-scale feature fusion. We introduce two new mechanisms to improve the\nperformance of the cross-attention fusion module: Feature Calibration Mechanism\n(FCM) and Selective Cross-Attention (SCA). FCM calibrates the features from\ndifferent branches to make them more compatible, while SCA selectively attends\nto the most informative features. Our experiments demonstrate that the proposed\napproach outperforms other state-of-the-art methods in brain tumor\nclassification, achieving improved accuracy and efficiency. The proposed FCM\nand SCA mechanisms can be easily integrated into other vision transformer\narchitectures, making them a promising direction for future research in medical\nimage analysis. Experimental results confirm that our approach surpasses\nexisting methods, achieving state-of-the-art performance in brain tumor\nclassification tasks.\n","authors":["Mohammad Ali Labbaf Khaniki","Alireza Golkarieh","Mohammad Manthouri"],"pdf_url":"https://arxiv.org/pdf/2406.17670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17652v1","updated":"2024-06-25T15:43:20Z","published":"2024-06-25T15:43:20Z","title":"Time-varying Extremum Graphs","summary":"  We introduce time-varying extremum graph (TVEG), a topological structure to\nsupport visualization and analysis of a time-varying scalar field. The extremum\ngraph is a substructure of the Morse-Smale complex. It captures the adjacency\nrelationship between cells in the Morse decomposition of a scalar field. We\ndefine the TVEG as a time-varying extension of the extremum graph and\ndemonstrate how it captures salient feature tracks within a dynamic scalar\nfield. We formulate the construction of the TVEG as an optimization problem and\ndescribe an algorithm for computing the graph. We also demonstrate the\ncapabilities of \\TVEG towards identification and exploration of topological\nevents such as deletion, generation, split, and merge within a dynamic scalar\nfield via comprehensive case studies including a viscous fingers and a 3D von\nK\\'arm\\'an vortex street dataset.\n","authors":["Somenath Das","Raghavendra Sridharamurthy","Vijay Natarajan"],"pdf_url":"https://arxiv.org/pdf/2406.17652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17640v1","updated":"2024-06-25T15:24:06Z","published":"2024-06-25T15:24:06Z","title":"BayTTA: Uncertainty-aware medical image classification with optimized\n  test-time augmentation using Bayesian model averaging","summary":"  Test-time augmentation (TTA) is a well-known technique employed during the\ntesting phase of computer vision tasks. It involves aggregating multiple\naugmented versions of input data. Combining predictions using a simple average\nformulation is a common and straightforward approach after performing TTA. This\npaper introduces a novel framework for optimizing TTA, called BayTTA\n(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,\nwe generate a model list associated with different variations of the input data\ncreated through TTA. Then, we use BMA to combine model predictions weighted by\ntheir respective posterior probabilities. Such an approach allows one to take\ninto account model uncertainty, and thus to enhance the predictive performance\nof the related machine learning or deep learning model. We evaluate the\nperformance of BayTTA on various public data, including three medical image\ndatasets comprising skin cancer, breast cancer, and chest X-ray images and two\nwell-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental\nresults indicate that BayTTA can be effectively integrated into\nstate-of-the-art deep learning models used in medical image analysis as well as\ninto some popular pre-trained CNN models such as VGG-16, MobileNetV2,\nDenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in\ntheir accuracy and robustness performance.\n","authors":["Zeinab Sherkatghanad","Moloud Abdar","Mohammadreza Bakhtyari","Vladimir Makarenkov"],"pdf_url":"https://arxiv.org/pdf/2406.17640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v1","updated":"2024-06-25T15:24:02Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17636v1","updated":"2024-06-25T15:21:50Z","published":"2024-06-25T15:21:50Z","title":"Aligning Diffusion Models with Noise-Conditioned Perception","summary":"  Recent advancements in human preference optimization, initially developed for\nLanguage Models (LMs), have shown promise for text-to-image Diffusion Models,\nenhancing prompt alignment, visual appeal, and user preference. Unlike LMs,\nDiffusion Models typically optimize in pixel or VAE space, which does not align\nwell with human perception, leading to slower and less efficient training\nduring the preference alignment stage. We propose using a perceptual objective\nin the U-Net embedding space of the diffusion model to address these issues.\nOur approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct\nPreference Optimization (DPO), Contrastive Preference Optimization (CPO), and\nsupervised fine-tuning (SFT) within this embedding space. This method\nsignificantly outperforms standard latent-space implementations across various\nmetrics, including quality and computational cost. For SDXL, our approach\nprovides 60.8\\% general preference, 62.2\\% visual appeal, and 52.1\\% prompt\nfollowing against original open-sourced SDXL-DPO on the PartiPrompts dataset,\nwhile significantly reducing compute. Our approach not only improves the\nefficiency and quality of human preference alignment for diffusion models but\nis also easily integrable with other optimization techniques. The training code\nand LoRA weights will be available here:\nhttps://huggingface.co/alexgambashidze/SDXL\\_NCP-DPO\\_v0.1\n","authors":["Alexander Gambashidze","Anton Kulikov","Yuriy Sosnin","Ilya Makarov"],"pdf_url":"https://arxiv.org/pdf/2406.17636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17628v1","updated":"2024-06-25T15:15:54Z","published":"2024-06-25T15:15:54Z","title":"Video Inpainting Localization with Contrastive Learning","summary":"  Deep video inpainting is typically used as malicious manipulation to remove\nimportant objects for creating fake videos. It is significant to identify the\ninpainted regions blindly. This letter proposes a simple yet effective forensic\nscheme for Video Inpainting LOcalization with ContrAstive Learning (ViLocal).\nSpecifically, a 3D Uniformer encoder is applied to the video noise residual for\nlearning effective spatiotemporal forensic features. To enhance the\ndiscriminative power, supervised contrastive learning is adopted to capture the\nlocal inconsistency of inpainted videos through attracting/repelling the\npositive/negative pristine and forged pixel pairs. A pixel-wise inpainting\nlocalization map is yielded by a lightweight convolution decoder with a\nspecialized two-stage training strategy. To prepare enough training samples, we\nbuild a video object segmentation dataset of 2500 videos with pixel-level\nannotations per frame. Extensive experimental results validate the superiority\nof ViLocal over state-of-the-arts. Code and dataset will be available at\nhttps://github.com/multimediaFor/ViLocal.\n","authors":["Zijie Lou","Gang Cao","Man Lin"],"pdf_url":"https://arxiv.org/pdf/2406.17628v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2406.13576"},{"id":"http://arxiv.org/abs/2406.17617v1","updated":"2024-06-25T15:02:01Z","published":"2024-06-25T15:02:01Z","title":"Embedded event based object detection with spiking neural network","summary":"  The complexity of event-based object detection (OD) poses considerable\nchallenges. Spiking Neural Networks (SNNs) show promising results and pave the\nway for efficient event-based OD. Despite this success, the path to efficient\nSNNs on embedded devices remains a challenge. This is due to the size of the\nnetworks required to accomplish the task and the ability of devices to take\nadvantage of SNNs benefits. Even when \"edge\" devices are considered, they\ntypically use embedded GPUs that consume tens of watts. In response to these\nchallenges, our research introduces an embedded neuromorphic testbench that\nutilizes the SPiking Low-power Event-based ArchiTecture (SPLEAT) accelerator.\nUsing an extended version of the Qualia framework, we can train, evaluate,\nquantize, and deploy spiking neural networks on an FPGA implementation of\nSPLEAT. We used this testbench to load a state-of-the-art SNN solution,\nestimate the performance loss associated with deploying the network on\ndedicated hardware, and run real-world event-based OD on neuromorphic hardware\nspecifically designed for low-power spiking neural networks. Remarkably, our\nembedded spiking solution, which includes a model with 1.08 million parameters,\noperates efficiently with 490 mJ per prediction.\n","authors":["Jonathan Courtois","Pierre-Emmanuel Novac","Edgar Lemaire","Alain Pegatoquet","Benoit Miramond"],"pdf_url":"https://arxiv.org/pdf/2406.17617v1.pdf","comment":"Result link: https://youtu.be/TsolUDaMY7Y"},{"id":"http://arxiv.org/abs/2406.17614v1","updated":"2024-06-25T15:00:43Z","published":"2024-06-25T15:00:43Z","title":"MSRS: Training Multimodal Speech Recognition Models from Scratch with\n  Sparse Mask Optimization","summary":"  Pre-trained models have been a foundational approach in speech recognition,\nalbeit with associated additional costs. In this study, we propose a\nregularization technique that facilitates the training of visual and\naudio-visual speech recognition models (VSR and AVSR) from scratch. This\napproach, abbreviated as \\textbf{MSRS} (Multimodal Speech Recognition from\nScratch), introduces a sparse regularization that rapidly learns sparse\nstructures within the dense model at the very beginning of training, which\nreceives healthier gradient flow than the dense equivalent. Once the sparse\nmask stabilizes, our method allows transitioning to a dense model or keeping a\nsparse model by updating non-zero values. MSRS achieves competitive results in\nVSR and AVSR with 21.1% and 0.9% WER on the LRS3 benchmark, while reducing\ntraining time by at least 2x. We explore other sparse approaches and show that\nonly MSRS enables training from scratch by implicitly masking the weights\naffected by vanishing gradients.\n","authors":["Adriana Fernandez-Lopez","Honglie Chen","Pingchuan Ma","Lu Yin","Qiao Xiao","Stavros Petridis","Shiwei Liu","Maja Pantic"],"pdf_url":"https://arxiv.org/pdf/2406.17614v1.pdf","comment":"Accepted at Interspeech 2024"},{"id":"http://arxiv.org/abs/2406.17608v1","updated":"2024-06-25T14:53:01Z","published":"2024-06-25T14:53:01Z","title":"Test-Time Generative Augmentation for Medical Image Segmentation","summary":"  In this paper, we propose a novel approach to enhance medical image\nsegmentation during test time. Instead of employing hand-crafted transforms or\nfunctions on the input test image to create multiple views for test-time\naugmentation, we advocate for the utilization of an advanced domain-fine-tuned\ngenerative model (GM), e.g., stable diffusion (SD), for test-time augmentation.\nGiven that the GM has been trained to comprehend and encapsulate comprehensive\ndomain data knowledge, it is superior than segmentation models in terms of\nrepresenting the data characteristics and distribution. Hence, by integrating\nthe GM into test-time augmentation, we can effectively generate multiple views\nof a given test sample, aligning with the content and appearance\ncharacteristics of the sample and the related local data distribution. This\napproach renders the augmentation process more adaptable and resilient compared\nto conventional handcrafted transforms. Comprehensive experiments conducted\nacross three medical image segmentation tasks (nine datasets) demonstrate the\nefficacy and versatility of the proposed TTGA in enhancing segmentation\noutcomes. Moreover, TTGA significantly improves pixel-wise error estimation,\nthereby facilitating the deployment of a more reliable segmentation system.\nCode will be released at: https://github.com/maxiao0234/TTGA.\n","authors":["Xiao Ma","Yuhui Tao","Yuhan Zhang","Zexuan Ji","Yizhe Zhang","Qiang Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17608v1.pdf","comment":"12pages, 2figures"},{"id":"http://arxiv.org/abs/2404.17569v2","updated":"2024-06-25T14:44:52Z","published":"2024-04-26T17:54:38Z","title":"MaPa: Text-driven Photorealistic Material Painting for 3D Shapes","summary":"  This paper aims to generate materials for 3D meshes from text descriptions.\nUnlike existing methods that synthesize texture maps, we propose to generate\nsegment-wise procedural material graphs as the appearance representation, which\nsupports high-quality rendering and provides substantial flexibility in\nediting. Instead of relying on extensive paired data, i.e., 3D meshes with\nmaterial graphs and corresponding text descriptions, to train a material graph\ngenerative model, we propose to leverage the pre-trained 2D diffusion model as\na bridge to connect the text and material graphs. Specifically, our approach\ndecomposes a shape into a set of segments and designs a segment-controlled\ndiffusion model to synthesize 2D images that are aligned with mesh parts. Based\non generated images, we initialize parameters of material graphs and fine-tune\nthem through the differentiable rendering module to produce materials in\naccordance with the textual description. Extensive experiments demonstrate the\nsuperior performance of our framework in photorealism, resolution, and\neditability over existing methods. Project page: https://zju3dv.github.io/MaPa\n","authors":["Shangzhan Zhang","Sida Peng","Tao Xu","Yuanbo Yang","Tianrun Chen","Nan Xue","Yujun Shen","Hujun Bao","Ruizhen Hu","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2404.17569v2.pdf","comment":"SIGGRAPH 2024. Project page: https://zju3dv.github.io/MaPa"},{"id":"http://arxiv.org/abs/2406.17601v1","updated":"2024-06-25T14:42:51Z","published":"2024-06-25T14:42:51Z","title":"Director3D: Real-world Camera Trajectory and 3D Scene Generation from\n  Text","summary":"  Recent advancements in 3D generation have leveraged synthetic datasets with\nground truth 3D assets and predefined cameras. However, the potential of\nadopting real-world datasets, which can produce significantly more realistic 3D\nscenes, remains largely unexplored. In this work, we delve into the key\nchallenge of the complex and scene-specific camera trajectories found in\nreal-world captures. We introduce Director3D, a robust open-world text-to-3D\ngeneration framework, designed to generate both real-world 3D scenes and\nadaptive camera trajectories. To achieve this, (1) we first utilize a\nTrajectory Diffusion Transformer, acting as the Cinematographer, to model the\ndistribution of camera trajectories based on textual descriptions. (2) Next, a\nGaussian-driven Multi-view Latent Diffusion Model serves as the Decorator,\nmodeling the image sequence distribution given the camera trajectories and\ntexts. This model, fine-tuned from a 2D diffusion model, directly generates\npixel-aligned 3D Gaussians as an immediate 3D scene representation for\nconsistent denoising. (3) Lastly, the 3D Gaussians are refined by a novel SDS++\nloss as the Detailer, which incorporates the prior of the 2D diffusion model.\nExtensive experiments demonstrate that Director3D outperforms existing methods,\noffering superior performance in real-world 3D generation.\n","authors":["Xinyang Li","Zhangyu Lai","Linning Xu","Yansong Qu","Liujuan Cao","Shengchuan Zhang","Bo Dai","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2406.17601v1.pdf","comment":"Code: https://github.com/imlixinyang/director3d"},{"id":"http://arxiv.org/abs/2406.17591v1","updated":"2024-06-25T14:32:31Z","published":"2024-06-25T14:32:31Z","title":"DocParseNet: Advanced Semantic Segmentation and OCR Embeddings for\n  Efficient Scanned Document Annotation","summary":"  Automating the annotation of scanned documents is challenging, requiring a\nbalance between computational efficiency and accuracy. DocParseNet addresses\nthis by combining deep learning and multi-modal learning to process both text\nand visual data. This model goes beyond traditional OCR and semantic\nsegmentation, capturing the interplay between text and images to preserve\ncontextual nuances in complex document structures. Our evaluations show that\nDocParseNet significantly outperforms conventional models, achieving mIoU\nscores of 49.12 on validation and 49.78 on the test set. This reflects a 58%\naccuracy improvement over state-of-the-art baseline models and an 18% gain\ncompared to the UNext baseline. Remarkably, DocParseNet achieves these results\nwith only 2.8 million parameters, reducing the model size by approximately 25\ntimes and speeding up training by 5 times compared to other models. These\nmetrics, coupled with a computational efficiency of 0.034 TFLOPs (BS=1),\nhighlight DocParseNet's high performance in document annotation. The model's\nadaptability and scalability make it well-suited for real-world corporate\ndocument processing applications. The code is available at\nhttps://github.com/ahmad-shirazi/DocParseNet\n","authors":["Ahmad Mohammadshirazi","Ali Nosrati Firoozsalari","Mengxi Zhou","Dheeraj Kulshrestha","Rajiv Ramnath"],"pdf_url":"https://arxiv.org/pdf/2406.17591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17577v1","updated":"2024-06-25T14:18:42Z","published":"2024-06-25T14:18:42Z","title":"Advancing Cell Detection in Anterior Segment Optical Coherence\n  Tomography Images","summary":"  Anterior uveitis, a common form of eye inflammation, can lead to permanent\nvision loss if not promptly diagnosed. Monitoring this condition involves\nquantifying inflammatory cells in the anterior chamber (AC) of the eye, which\ncan be captured using Anterior Segment Optical Coherence Tomography (AS-OCT).\nHowever, manually identifying cells in AS-OCT images is time-consuming and\nsubjective. Moreover, existing automated approaches may have limitations in\nboth the effectiveness of detecting cells and the reliability of their\ndetection results. To address these challenges, we propose an automated\nframework to detect cells in the AS-OCT images. This framework consists of a\nzero-shot chamber segmentation module and a cell detection module. The first\nmodule segments the AC area in the image without requiring human-annotated\ntraining data. Subsequently, the second module identifies individual cells\nwithin the segmented AC region. Through experiments, our framework demonstrates\nsuperior performance compared to current state-of-the-art methods for both AC\nsegmentation and cell detection tasks. Notably, we find that previous cell\ndetection approaches could suffer from low recall, potentially overlooking a\nsignificant number of cells. In contrast, our framework offers an improved\nsolution, which could benefit the diagnosis and study of anterior uveitis. Our\ncode for cell detection is publicly available at:\nhttps://github.com/joeybyc/cell_detection.\n","authors":["Boyu Chen","Ameenat L. Solebo","Paul Taylor"],"pdf_url":"https://arxiv.org/pdf/2406.17577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17575v1","updated":"2024-06-25T14:15:48Z","published":"2024-06-25T14:15:48Z","title":"Toward Universal Medical Image Registration via Sharpness-Aware\n  Meta-Continual Learning","summary":"  Current deep learning approaches in medical image registration usually face\nthe challenges of distribution shift and data collection, hindering real-world\ndeployment. In contrast, universal medical image registration aims to perform\nregistration on a wide range of clinically relevant tasks simultaneously, thus\nhaving tremendous potential for clinical applications. In this paper, we\npresent the first attempt to achieve the goal of universal 3D medical image\nregistration in sequential learning scenarios by proposing a continual learning\nmethod. Specifically, we utilize meta-learning with experience replay to\nmitigating the problem of catastrophic forgetting. To promote the\ngeneralizability of meta-continual learning, we further propose sharpness-aware\nmeta-continual learning (SAMCL). We validate the effectiveness of our method on\nfour datasets in a continual learning setup, including brain MR, abdomen CT,\nlung CT, and abdomen MR-CT image pairs. Results have shown the potential of\nSAMCL in realizing universal image registration, which performs better than or\non par with vanilla sequential or centralized multi-task training\nstrategies.The source code will be available from\nhttps://github.com/xzluo97/Continual-Reg.\n","authors":["Bomin Wang","Xinzhe Luo","Xiahai Zhuang"],"pdf_url":"https://arxiv.org/pdf/2406.17575v1.pdf","comment":"Accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17559v1","updated":"2024-06-25T13:54:39Z","published":"2024-06-25T13:54:39Z","title":"Minimal Interaction Edge Tuning: A New Paradigm for Visual Adaptation","summary":"  The rapid scaling of large vision pretrained models makes fine-tuning tasks\nmore and more difficult on edge devices with low computational resources. We\nexplore a new visual adaptation paradigm called edge tuning, which treats large\npretrained models as standalone feature extractors that run on powerful cloud\nservers. The fine-tuning carries out on edge devices with small networks which\nrequire low computational resources. Existing methods that are potentially\nsuitable for our edge tuning paradigm are discussed. But, three major drawbacks\nhinder their application in edge tuning: low adaptation capability, large\nadapter network, and high information transfer overhead. To address these\nissues, we propose Minimal Interaction Edge Tuning, or MIET, which reveals that\nthe sum of intermediate features from pretrained models not only has minimal\ninformation transfer but also has high adaptation capability. With a\nlightweight attention-based adaptor network, MIET achieves information transfer\nefficiency, parameter efficiency, computational and memory efficiency, and at\nthe same time demonstrates competitive results on various visual adaptation\nbenchmarks.\n","authors":["Ningyuan Tang","Minghao Fu","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2406.17559v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.09335v2","updated":"2024-06-25T13:47:06Z","published":"2024-06-13T17:17:31Z","title":"Instance-level quantitative saliency in multiple sclerosis lesion\n  segmentation","summary":"  In recent years, explainable methods for artificial intelligence (XAI) have\ntried to reveal and describe models' decision mechanisms in the case of\nclassification tasks. However, XAI for semantic segmentation and in particular\nfor single instances has been little studied to date. Understanding the process\nunderlying automatic segmentation of single instances is crucial to reveal what\ninformation was used to detect and segment a given object of interest. In this\nstudy, we proposed two instance-level explanation maps for semantic\nsegmentation based on SmoothGrad and Grad-CAM++ methods. Then, we investigated\ntheir relevance for the detection and segmentation of white matter lesions\n(WML), a magnetic resonance imaging (MRI) biomarker in multiple sclerosis (MS).\n687 patients diagnosed with MS for a total of 4043 FLAIR and MPRAGE MRI scans\nwere collected at the University Hospital of Basel, Switzerland. Data were\nrandomly split into training, validation and test sets to train a 3D U-Net for\nMS lesion segmentation. We observed 3050 true positive (TP), 1818 false\npositive (FP), and 789 false negative (FN) cases. We generated instance-level\nexplanation maps for semantic segmentation, by developing two XAI methods based\non SmoothGrad and Grad-CAM++. We investigated: 1) the distribution of gradients\nin saliency maps with respect to both input MRI sequences; 2) the model's\nresponse in the case of synthetic lesions; 3) the amount of perilesional tissue\nneeded by the model to segment a lesion. Saliency maps (based on SmoothGrad) in\nFLAIR showed positive values inside a lesion and negative in its neighborhood.\nPeak values of saliency maps generated for these four groups of volumes\npresented distributions that differ significantly from one another, suggesting\na quantitative nature of the proposed saliency. Contextual information of 7mm\naround the lesion border was required for their segmentation.\n","authors":["Federico Spagnolo","Nataliia Molchanova","Roger Schaer","Meritxell Bach Cuadra","Mario Ocampo Pineda","Lester Melie-Garcia","Cristina Granziera","Vincent Andrearczyk","Adrien Depeursinge"],"pdf_url":"https://arxiv.org/pdf/2406.09335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17547v1","updated":"2024-06-25T13:34:50Z","published":"2024-06-25T13:34:50Z","title":"Detection of Synthetic Face Images: Accuracy, Robustness, Generalization","summary":"  An experimental study on detecting synthetic face images is presented. We\ncollected a dataset, called FF5, of five fake face image generators, including\nrecent diffusion models. We find that a simple model trained on a specific\nimage generator can achieve near-perfect accuracy in separating synthetic and\nreal images. The model handles common image distortions (reduced resolution,\ncompression) by using data augmentation. Moreover, partial manipulations, where\nsynthetic images are blended into real ones by inpainting, are identified and\nthe area of the manipulation is localized by a simple model of YOLO\narchitecture. However, the model turned out to be vulnerable to adversarial\nattacks and does not generalize to unseen generators. Failure to generalize to\ndetect images produced by a newer generator also occurs for recent\nstate-of-the-art methods, which we tested on Realistic Vision, a fine-tuned\nversion of StabilityAI's Stable Diffusion image generator.\n","authors":["Nela Petrzelkova","Jan Cech"],"pdf_url":"https://arxiv.org/pdf/2406.17547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17541v1","updated":"2024-06-25T13:28:53Z","published":"2024-06-25T13:28:53Z","title":"Principal Component Clustering for Semantic Segmentation in Synthetic\n  Data Generation","summary":"  This technical report outlines our method for generating a synthetic dataset\nfor semantic segmentation using a latent diffusion model. Our approach\neliminates the need for additional models specifically trained on segmentation\ndata and is part of our submission to the CVPR 2024 workshop challenge,\nentitled CVPR 2024 workshop challenge \"SyntaGen Harnessing Generative Models\nfor Synthetic Visual Datasets\". Our methodology uses self-attentions to\nfacilitate a novel head-wise semantic information condensation, thereby\nenabling the direct acquisition of class-agnostic image segmentation from the\nStable Diffusion latents. Furthermore, we employ non-prompt-influencing\ncross-attentions from text to pixel, thus facilitating the classification of\nthe previously generated masks. Finally, we propose a mask refinement step by\nusing only the output image by Stable Diffusion.\n","authors":["Felix Stillger","Frederik Hasecke","Tobias Meisen"],"pdf_url":"https://arxiv.org/pdf/2406.17541v1.pdf","comment":"This is a technical report for a submission to the CVPR \"SyntaGen -\n  Harnessing Generative Models for Synthetic Visual Datasets\" workshop\n  challenge. The report is already uploaded to the workshop's homepage\n  https://syntagen.github.io/"},{"id":"http://arxiv.org/abs/2112.09726v4","updated":"2024-06-25T13:28:04Z","published":"2021-12-17T19:22:01Z","title":"Soundify: Matching Sound Effects to Video","summary":"  In the art of video editing, sound helps add character to an object and\nimmerse the viewer within a space. Through formative interviews with\nprofessional editors (N=10), we found that the task of adding sounds to video\ncan be challenging. This paper presents Soundify, a system that assists editors\nin matching sounds to video. Given a video, Soundify identifies matching\nsounds, synchronizes the sounds to the video, and dynamically adjusts panning\nand volume to create spatial audio. In a human evaluation study (N=889), we\nshow that Soundify is capable of matching sounds to video out-of-the-box for a\ndiverse range of audio categories. In a within-subjects expert study (N=12), we\ndemonstrate the usefulness of Soundify in helping video editors match sounds to\nvideo with lighter workload, reduced task completion time, and improved\nusability.\n","authors":["David Chuan-En Lin","Anastasis Germanidis","Cristóbal Valenzuela","Yining Shi","Nikolas Martelaro"],"pdf_url":"https://arxiv.org/pdf/2112.09726v4.pdf","comment":"https://soundify.cc"},{"id":"http://arxiv.org/abs/2406.17538v1","updated":"2024-06-25T13:22:22Z","published":"2024-06-25T13:22:22Z","title":"SKD-TSTSAN: Three-Stream Temporal-Shift Attention Network Based on\n  Self-Knowledge Distillation for Micro-Expression Recognition","summary":"  Micro-expressions (MEs) are subtle facial movements that occur spontaneously\nwhen people try to conceal the real emotions. Micro-expression recognition\n(MER) is crucial in many fields, including criminal analysis and psychotherapy.\nHowever, MER is challenging since MEs have low intensity and ME datasets are\nsmall in size. To this end, a three-stream temporal-shift attention network\nbased on self-knowledge distillation (SKD-TSTSAN) is proposed in this paper.\nFirstly, to address the low intensity of ME muscle movements, we utilize\nlearning-based motion magnification modules to enhance the intensity of ME\nmuscle movements. Secondly, we employ efficient channel attention (ECA) modules\nin the local-spatial stream to make the network focus on facial regions that\nare highly relevant to MEs. In addition, temporal shift modules (TSMs) are used\nin the dynamic-temporal stream, which enables temporal modeling with no\nadditional parameters by mixing ME motion information from two different\ntemporal domains. Furthermore, we introduce self-knowledge distillation (SKD)\ninto the MER task by introducing auxiliary classifiers and using the deepest\nsection of the network for supervision, encouraging all blocks to fully explore\nthe features of the training set. Finally, extensive experiments are conducted\non four ME datasets: CASME II, SAMM, MMEW, and CAS(ME)3. The experimental\nresults demonstrate that our SKD-TSTSAN outperforms other existing methods and\nachieves new state-of-the-art performance. Our code will be available at\nhttps://github.com/GuanghaoZhu663/SKD-TSTSAN.\n","authors":["Guanghao Zhu","Lin Liu","Yuhao Hu","Haixin Sun","Fang Liu","Xiaohui Du","Ruqian Hao","Juanxiu Liu","Yong Liu","Hao Deng","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12492v2","updated":"2024-06-25T13:20:45Z","published":"2022-11-22T18:58:22Z","title":"VideoMap: Supporting Video Editing Exploration, Brainstorming, and\n  Prototyping in the Latent Space","summary":"  Video editing is a creative and complex endeavor and we believe that there is\npotential for reimagining a new video editing interface to better support the\ncreative and exploratory nature of video editing. We take inspiration from\nlatent space exploration tools that help users find patterns and connections\nwithin complex datasets. We present VideoMap, a proof-of-concept video editing\ninterface that operates on video frames projected onto a latent space. We\nsupport intuitive navigation through map-inspired navigational elements and\nfacilitate transitioning between different latent spaces through swappable\nlenses. We built three VideoMap components to support editors in three common\nvideo tasks. In a user study with both professionals and non-professionals,\neditors found that VideoMap helps reduce grunt work, offers a user-friendly\nexperience, provides an inspirational way of editing, and effectively supports\nthe exploratory nature of video editing. We further demonstrate the versatility\nof VideoMap by implementing three extended applications. For interactive\nexamples, we invite you to visit our project page:\nhttps://humanvideointeraction.github.io/videomap.\n","authors":["David Chuan-En Lin","Fabian Caba Heilbron","Joon-Young Lee","Oliver Wang","Nikolas Martelaro"],"pdf_url":"https://arxiv.org/pdf/2211.12492v2.pdf","comment":"https://humanvideointeraction.github.io/videomap"},{"id":"http://arxiv.org/abs/2406.17536v1","updated":"2024-06-25T13:20:39Z","published":"2024-06-25T13:20:39Z","title":"MedMNIST-C: Comprehensive benchmark and improved classifier robustness\n  by simulating realistic image corruptions","summary":"  The integration of neural-network-based systems into clinical practice is\nlimited by challenges related to domain generalization and robustness. The\ncomputer vision community established benchmarks such as ImageNet-C as a\nfundamental prerequisite to measure progress towards those challenges. Similar\ndatasets are largely absent in the medical imaging community which lacks a\ncomprehensive benchmark that spans across imaging modalities and applications.\nTo address this gap, we create and open-source MedMNIST-C, a benchmark dataset\nbased on the MedMNIST+ collection covering 12 datasets and 9 imaging\nmodalities. We simulate task and modality-specific image corruptions of varying\nseverity to comprehensively evaluate the robustness of established algorithms\nagainst real-world artifacts and distribution shifts. We further provide\nquantitative evidence that our simple-to-use artificial corruptions allow for\nhighly performant, lightweight data augmentation to enhance model robustness.\nUnlike traditional, generic augmentation strategies, our approach leverages\ndomain knowledge, exhibiting significantly higher robustness when compared to\nwidely adopted methods. By introducing MedMNIST-C and open-sourcing the\ncorresponding library allowing for targeted data augmentations, we contribute\nto the development of increasingly robust methods tailored to the challenges of\nmedical imaging. The code is available at\nhttps://github.com/francescodisalvo05/medmnistc-api}{github.com/francescodisalvo05/medmnistc-api.\n","authors":["Francesco Di Salvo","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2406.17536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12493v2","updated":"2024-06-25T13:20:06Z","published":"2022-11-22T18:59:04Z","title":"Videogenic: Identifying Highlight Moments in Videos with Professional\n  Photographs as a Prior","summary":"  This paper investigates the challenge of extracting highlight moments from\nvideos. To perform this task, we need to understand what constitutes a\nhighlight for arbitrary video domains while at the same time being able to\nscale across different domains. Our key insight is that photographs taken by\nphotographers tend to capture the most remarkable or photogenic moments of an\nactivity. Drawing on this insight, we present Videogenic, a technique capable\nof creating domain-specific highlight videos for a diverse range of domains. In\na human evaluation study (N=50), we show that a high-quality photograph\ncollection combined with CLIP-based retrieval (which uses a neural network with\nsemantic knowledge of images) can serve as an excellent prior for finding video\nhighlights. In a within-subjects expert study (N=12), we demonstrate the\nusefulness of Videogenic in helping video editors create highlight videos with\nlighter workload, shorter task completion time, and better usability.\n","authors":["David Chuan-En Lin","Fabian Caba Heilbron","Joon-Young Lee","Oliver Wang","Nikolas Martelaro"],"pdf_url":"https://arxiv.org/pdf/2211.12493v2.pdf","comment":"https://humanvideointeraction.github.io/videogenic"},{"id":"http://arxiv.org/abs/2406.17530v1","updated":"2024-06-25T13:14:26Z","published":"2024-06-25T13:14:26Z","title":"Point Tree Transformer for Point Cloud Registration","summary":"  Point cloud registration is a fundamental task in the fields of computer\nvision and robotics. Recent developments in transformer-based methods have\ndemonstrated enhanced performance in this domain. However, the standard\nattention mechanism utilized in these methods often integrates many\nlow-relevance points, thereby struggling to prioritize its attention weights on\nsparse yet meaningful points. This inefficiency leads to limited local\nstructure modeling capabilities and quadratic computational complexity. To\novercome these limitations, we propose the Point Tree Transformer (PTT), a\nnovel transformer-based approach for point cloud registration that efficiently\nextracts comprehensive local and global features while maintaining linear\ncomputational complexity. The PTT constructs hierarchical feature trees from\npoint clouds in a coarse-to-dense manner, and introduces a novel Point Tree\nAttention (PTA) mechanism, which follows the tree structure to facilitate the\nprogressive convergence of attended regions towards salient points.\nSpecifically, each tree layer selectively identifies a subset of key points\nwith the highest attention scores. Subsequent layers focus attention on areas\nof significant relevance, derived from the child points of the selected point\nset. The feature extraction process additionally incorporates coarse point\nfeatures that capture high-level semantic information, thus facilitating local\nstructure modeling and the progressive integration of multiscale information.\nConsequently, PTA empowers the model to concentrate on crucial local structures\nand derive detailed local information while maintaining linear computational\ncomplexity. Extensive experiments conducted on the 3DMatch, ModelNet40, and\nKITTI datasets demonstrate that our method achieves superior performance over\nthe state-of-the-art methods.\n","authors":["Meiling Wang","Guangyan Chen","Yi Yang","Li Yuan","Yufeng Yue"],"pdf_url":"https://arxiv.org/pdf/2406.17530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08625v2","updated":"2024-06-25T13:12:20Z","published":"2024-06-12T20:15:00Z","title":"FSBI: Deepfakes Detection with Frequency Enhanced Self-Blended Images","summary":"  Advances in deepfake research have led to the creation of almost perfect\nmanipulations undetectable by human eyes and some deepfakes detection tools.\nRecently, several techniques have been proposed to differentiate deepfakes from\nrealistic images and videos. This paper introduces a Frequency Enhanced\nSelf-Blended Images (FSBI) approach for deepfakes detection. This proposed\napproach utilizes Discrete Wavelet Transforms (DWT) to extract discriminative\nfeatures from the self-blended images (SBI) to be used for training a\nconvolutional network architecture model. The SBIs blend the image with itself\nby introducing several forgery artifacts in a copy of the image before blending\nit. This prevents the classifier from overfitting specific artifacts by\nlearning more generic representations. These blended images are then fed into\nthe frequency features extractor to detect artifacts that can not be detected\neasily in the time domain. The proposed approach has been evaluated on FF++ and\nCeleb-DF datasets and the obtained results outperformed the state-of-the-art\ntechniques with the cross-dataset evaluation protocol.\n","authors":["Ahmed Abul Hasanaath","Hamzah Luqman","Raed Katib","Saeed Anwar"],"pdf_url":"https://arxiv.org/pdf/2406.08625v2.pdf","comment":"The paper is under review"},{"id":"http://arxiv.org/abs/2404.10343v2","updated":"2024-06-25T13:05:30Z","published":"2024-04-16T07:26:20Z","title":"The Ninth NTIRE 2024 Efficient Super-Resolution Challenge Report","summary":"  This paper provides a comprehensive review of the NTIRE 2024 challenge,\nfocusing on efficient single-image super-resolution (ESR) solutions and their\noutcomes. The task of this challenge is to super-resolve an input image with a\nmagnification factor of x4 based on pairs of low and corresponding\nhigh-resolution images. The primary objective is to develop networks that\noptimize various aspects such as runtime, parameters, and FLOPs, while still\nmaintaining a peak signal-to-noise ratio (PSNR) of approximately 26.90 dB on\nthe DIV2K_LSDIR_valid dataset and 26.99 dB on the DIV2K_LSDIR_test dataset. In\naddition, this challenge has 4 tracks including the main track (overall\nperformance), sub-track 1 (runtime), sub-track 2 (FLOPs), and sub-track 3\n(parameters). In the main track, all three metrics (ie runtime, FLOPs, and\nparameter count) were considered. The ranking of the main track is calculated\nbased on a weighted sum-up of the scores of all other sub-tracks. In sub-track\n1, the practical runtime performance of the submissions was evaluated, and the\ncorresponding score was used to determine the ranking. In sub-track 2, the\nnumber of FLOPs was considered. The score calculated based on the corresponding\nFLOPs was used to determine the ranking. In sub-track 3, the number of\nparameters was considered. The score calculated based on the corresponding\nparameters was used to determine the ranking. RLFN is set as the baseline for\nefficiency measurement. The challenge had 262 registered participants, and 34\nteams made valid submissions. They gauge the state-of-the-art in efficient\nsingle-image super-resolution. To facilitate the reproducibility of the\nchallenge and enable other researchers to build upon these findings, the code\nand the pre-trained model of validated solutions are made publicly available at\nhttps://github.com/Amazingren/NTIRE2024_ESR/.\n","authors":["Bin Ren","Yawei Li","Nancy Mehta","Radu Timofte","Hongyuan Yu","Cheng Wan","Yuxin Hong","Bingnan Han","Zhuoyuan Wu","Yajun Zou","Yuqing Liu","Jizhe Li","Keji He","Chao Fan","Heng Zhang","Xiaolin Zhang","Xuanwu Yin","Kunlong Zuo","Bohao Liao","Peizhe Xia","Long Peng","Zhibo Du","Xin Di","Wangkai Li","Yang Wang","Wei Zhai","Renjing Pei","Jiaming Guo","Songcen Xu","Yang Cao","Zhengjun Zha","Yan Wang","Yi Liu","Qing Wang","Gang Zhang","Liou Zhang","Shijie Zhao","Long Sun","Jinshan Pan","Jiangxin Dong","Jinhui Tang","Xin Liu","Min Yan","Qian Wang","Menghan Zhou","Yiqiang Yan","Yixuan Liu","Wensong Chan","Dehua Tang","Dong Zhou","Li Wang","Lu Tian","Barsoum Emad","Bohan Jia","Junbo Qiao","Yunshuai Zhou","Yun Zhang","Wei Li","Shaohui Lin","Shenglong Zhou","Binbin Chen","Jincheng Liao","Suiyi Zhao","Zhao Zhang","Bo Wang","Yan Luo","Yanyan Wei","Feng Li","Mingshen Wang","Yawei Li","Jinhan Guan","Dehua Hu","Jiawei Yu","Qisheng Xu","Tao Sun","Long Lan","Kele Xu","Xin Lin","Jingtong Yue","Lehan Yang","Shiyi Du","Lu Qi","Chao Ren","Zeyu Han","Yuhan Wang","Chaolin Chen","Haobo Li","Mingjun Zheng","Zhongbao Yang","Lianhong Song","Xingzhuo Yan","Minghan Fu","Jingyi Zhang","Baiang Li","Qi Zhu","Xiaogang Xu","Dan Guo","Chunle Guo","Jiadi Chen","Huanhuan Long","Chunjiang Duanmu","Xiaoyan Lei","Jie Liu","Weilin Jia","Weifeng Cao","Wenlong Zhang","Yanyu Mao","Ruilong Guo","Nihao Zhang","Qian Wang","Manoj Pandey","Maksym Chernozhukov","Giang Le","Shuli Cheng","Hongyuan Wang","Ziyan Wei","Qingting Tang","Liejun Wang","Yongming Li","Yanhui Guo","Hao Xu","Akram Khatami-Rizi","Ahmad Mahmoudi-Aznaveh","Chih-Chung Hsu","Chia-Ming Lee","Yi-Shiuan Chou","Amogh Joshi","Nikhil Akalwadi","Sampada Malagi","Palani Yashaswini","Chaitra Desai","Ramesh Ashok Tabib","Ujwala Patil","Uma Mudenagudi"],"pdf_url":"https://arxiv.org/pdf/2404.10343v2.pdf","comment":"The report paper of NTIRE2024 Efficient Super-resolution, accepted by\n  CVPRW2024"},{"id":"http://arxiv.org/abs/2406.17520v1","updated":"2024-06-25T12:59:46Z","published":"2024-06-25T12:59:46Z","title":"Tell Me Where You Are: Multimodal LLMs Meet Place Recognition","summary":"  Large language models (LLMs) exhibit a variety of promising capabilities in\nrobotics, including long-horizon planning and commonsense reasoning. However,\ntheir performance in place recognition is still underexplored. In this work, we\nintroduce multimodal LLMs (MLLMs) to visual place recognition (VPR), where a\nrobot must localize itself using visual observations. Our key design is to use\nvision-based retrieval to propose several candidates and then leverage\nlanguage-based reasoning to carefully inspect each candidate for a final\ndecision. Specifically, we leverage the robust visual features produced by\noff-the-shelf vision foundation models (VFMs) to obtain several candidate\nlocations. We then prompt an MLLM to describe the differences between the\ncurrent observation and each candidate in a pairwise manner, and reason about\nthe best candidate based on these descriptions. Our results on three datasets\ndemonstrate that integrating the general-purpose visual features from VFMs with\nthe reasoning capabilities of MLLMs already provides an effective place\nrecognition solution, without any VPR-specific supervised training. We believe\nour work can inspire new possibilities for applying and designing foundation\nmodels, i.e., VFMs, LLMs, and MLLMs, to enhance the localization and navigation\nof mobile robots.\n","authors":["Zonglin Lyu","Juexiao Zhang","Mingxuan Lu","Yiming Li","Chen Feng"],"pdf_url":"https://arxiv.org/pdf/2406.17520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00612v2","updated":"2024-06-25T12:49:54Z","published":"2024-03-01T15:35:48Z","title":"Advancing dermatological diagnosis: Development of a hyperspectral\n  dermatoscope for enhanced skin imaging","summary":"  Clinical dermatology necessitates precision and innovation for efficient\ndiagnosis and treatment of various skin conditions. This paper introduces the\ndevelopment of a cutting-edge hyperspectral dermatoscope (the Hyperscope)\ntailored for human skin analysis. We detail the requirements to such a device\nand the design considerations, from optical configurations to sensor selection,\nnecessary to capture a wide spectral range with high fidelity. Preliminary\nresults from 15 individuals and 160 recorded skin images demonstrate the\npotential of the Hyperscope in identifying and characterizing various skin\nconditions, offering a promising avenue for non-invasive skin evaluation and a\nplatform for future research in dermatology-related hyperspectral imaging.\n","authors":["Martin J. Hetz","Carina Nogueira Garcia","Sarah Haggenmüller","Titus J. Brinker"],"pdf_url":"https://arxiv.org/pdf/2403.00612v2.pdf","comment":"12 pages, 11 Figures"},{"id":"http://arxiv.org/abs/2308.12143v4","updated":"2024-06-25T12:34:46Z","published":"2023-08-23T14:00:58Z","title":"A Probabilistic Fluctuation based Membership Inference Attack for\n  Diffusion Models","summary":"  Membership Inference Attack (MIA) identifies whether a record exists in a\nmachine learning model's training set by querying the model. MIAs on the\nclassic classification models have been well-studied, and recent works have\nstarted to explore how to transplant MIA onto generative models. Our\ninvestigation indicates that existing MIAs designed for generative models\nmainly depend on the overfitting in target models. However, overfitting can be\navoided by employing various regularization techniques, whereas existing MIAs\ndemonstrate poor performance in practice. Unlike overfitting, memorization is\nessential for deep learning models to attain optimal performance, making it a\nmore prevalent phenomenon. Memorization in generative models leads to an\nincreasing trend in the probability distribution of generating records around\nthe member record. Therefore, we propose a Probabilistic Fluctuation Assessing\nMembership Inference Attack (PFAMI), a black-box MIA that infers memberships by\ndetecting these trends via analyzing the overall probabilistic fluctuations\naround given records. We conduct extensive experiments across multiple\ngenerative models and datasets, which demonstrate PFAMI can improve the attack\nsuccess rate (ASR) by about 27.9% when compared with the best baseline.\n","authors":["Wenjie Fu","Huandong Wang","Chen Gao","Guanghua Liu","Yong Li","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2308.12143v4.pdf","comment":"Repo: https://github.com/wjfu99/MIA-Gen"},{"id":"http://arxiv.org/abs/2402.03904v2","updated":"2024-06-25T12:13:58Z","published":"2024-02-06T11:16:18Z","title":"Deep Frequency-Aware Functional Maps for Robust Shape Matching","summary":"  Deep functional map frameworks are widely employed for 3D shape matching.\nHowever, most existing deep functional map methods cannot adaptively capture\nimportant frequency information for functional map estimation in specific\nmatching scenarios, i.e., lacking \\textit{frequency awareness}, resulting in\npoor performance when dealing with large deformable shape matching. To this\nend, we propose a novel unsupervised learning-based framework called Deep\nFrequency-Aware Functional Maps, which can gracefully cope with various shape\nmatching scenarios. We first introduce a general constraint called Spectral\nFilter Operator Preservation to compute desirable functional maps, where the\nspectral filter operator encodes informative frequency information and can\npromote frequency awareness for deep functional map frameworks by learning a\nset of filter functions. Then, we directly utilize the proposed constraint as a\nloss function to supervise functional maps, pointwise maps, and filter\nfunctions simultaneously, where the filter functions are derived from the\northonormal Jacobi basis, and the coefficients of the basis are learnable\nparameters. Finally, we develop an effective refinement strategy to improve the\nfinal pointwise map, which incorporates our constraint and learned filter\nfunctions, leading to more robust and accurate correspondences during the\ninference process. Extensive experimental results on various datasets\ndemonstrate that our approach outperforms the existing state-of-the-art\nmethods, especially in challenging settings like datasets with non-isometric\ndeformation and inconsistent topology.\n","authors":["Feifan Luo","Qinsong Li","Ling Hu","Haibo Wang","Xinru Liu","Shengjun Liu","Hongyang Chen"],"pdf_url":"https://arxiv.org/pdf/2402.03904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17483v1","updated":"2024-06-25T12:04:51Z","published":"2024-06-25T12:04:51Z","title":"TRIP: Trainable Region-of-Interest Prediction for Hardware-Efficient\n  Neuromorphic Processing on Event-based Vision","summary":"  Neuromorphic processors are well-suited for efficiently handling sparse\nevents from event-based cameras. However, they face significant challenges in\nthe growth of computing demand and hardware costs as the input resolution\nincreases. This paper proposes the Trainable Region-of-Interest Prediction\n(TRIP), the first hardware-efficient hard attention framework for event-based\nvision processing on a neuromorphic processor. Our TRIP framework actively\nproduces low-resolution Region-of-Interest (ROIs) for efficient and accurate\nclassification. The framework exploits sparse events' inherent low information\ndensity to reduce the overhead of ROI prediction. We introduced extensive\nhardware-aware optimizations for TRIP and implemented the hardware-optimized\nalgorithm on the SENECA neuromorphic processor. We utilized multiple\nevent-based classification datasets for evaluation. Our approach achieves\nstate-of-the-art accuracies in all datasets and produces reasonable ROIs with\nvarying locations and sizes. On the DvsGesture dataset, our solution requires\n46x less computation than the state-of-the-art while achieving higher accuracy.\nFurthermore, TRIP enables more than 2x latency and energy improvements on the\nSENECA neuromorphic processor compared to the conventional solution.\n","authors":["Cina Arjmand","Yingfu Xu","Kevin Shidqi","Alexandra F. Dobrita","Kanishkan Vadivel","Paul Detterer","Manolis Sifalakis","Amirreza Yousefzadeh","Guangzhi Tang"],"pdf_url":"https://arxiv.org/pdf/2406.17483v1.pdf","comment":"Accepted in ICONS 2024"},{"id":"http://arxiv.org/abs/2406.17473v1","updated":"2024-06-25T11:38:46Z","published":"2024-06-25T11:38:46Z","title":"TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image\n  Classification","summary":"  The usage of medical image data for the training of large-scale machine\nlearning approaches is particularly challenging due to its scarce availability\nand the costly generation of data annotations, typically requiring the\nengagement of medical professionals. The rapid development of generative models\nallows towards tackling this problem by leveraging large amounts of realistic\nsynthetically generated data for the training process. However, randomly\nchoosing synthetic samples, might not be an optimal strategy.\n  In this work, we investigate the targeted generation of synthetic training\ndata, in order to improve the accuracy and robustness of image classification.\nTherefore, our approach aims to guide the generative model to synthesize data\nwith high epistemic uncertainty, since large measures of epistemic uncertainty\nindicate underrepresented data points in the training set. During the image\ngeneration we feed images reconstructed by an auto encoder into the classifier\nand compute the mutual information over the class-probability distribution as a\nmeasure for uncertainty.We alter the feature space of the autoencoder through\nan optimization process with the objective of maximizing the classifier\nuncertainty on the decoded image. By training on such data we improve the\nperformance and robustness against test time data augmentations and adversarial\nattacks on several classifications tasks.\n","authors":["Joshua Niemeijer","Jan Ehrhardt","Hristina Uzunova","Heinz Handels"],"pdf_url":"https://arxiv.org/pdf/2406.17473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17472v1","updated":"2024-06-25T11:30:31Z","published":"2024-06-25T11:30:31Z","title":"UHD-IQA Benchmark Database: Pushing the Boundaries of Blind Photo\n  Quality Assessment","summary":"  We introduce a novel Image Quality Assessment (IQA) dataset comprising 6073\nUHD-1 (4K) images, annotated at a fixed width of 3840 pixels. Contrary to\nexisting No-Reference (NR) IQA datasets, ours focuses on highly aesthetic\nphotos of high technical quality, filling a gap in the literature. The images,\ncarefully curated to exclude synthetic content, are sufficiently diverse to\ntrain general NR-IQA models. The dataset is annotated with perceptual quality\nratings obtained through a crowdsourcing study. Ten expert raters, comprising\nphotographers and graphics artists, assessed each image at least twice in\nmultiple sessions spanning several days, resulting in highly reliable labels.\nAnnotators were rigorously selected based on several metrics, including\nself-consistency, to ensure their reliability. The dataset includes rich\nmetadata with user and machine-generated tags from over 5,000 categories and\npopularity indicators such as favorites, likes, downloads, and views. With its\nunique characteristics, such as its focus on high-quality images, reliable\ncrowdsourced annotations, and high annotation resolution, our dataset opens up\nnew opportunities for advancing perceptual image quality assessment research\nand developing practical NR-IQA models that apply to modern photos. Our dataset\nis available at https://database.mmsp-kn.de/uhd-iqa-benchmark-database.html\n","authors":["Vlad Hosu","Lorenzo Agnolucci","Oliver Wiedemann","Daisuke Iso"],"pdf_url":"https://arxiv.org/pdf/2406.17472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17471v1","updated":"2024-06-25T11:15:56Z","published":"2024-06-25T11:15:56Z","title":"Medical Image Segmentation Using Directional Window Attention","summary":"  Accurate segmentation of medical images is crucial for diagnostic purposes,\nincluding cell segmentation, tumor identification, and organ localization.\nTraditional convolutional neural network (CNN)-based approaches struggled to\nachieve precise segmentation results due to their limited receptive fields,\nparticularly in cases involving multi-organ segmentation with varying shapes\nand sizes. The transformer-based approaches address this limitation by\nleveraging the global receptive field, but they often face challenges in\ncapturing local information required for pixel-precise segmentation. In this\nwork, we introduce DwinFormer, a hierarchical encoder-decoder architecture for\nmedical image segmentation comprising a directional window (Dwin) attention and\nglobal self-attention (GSA) for feature encoding. The focus of our design is\nthe introduction of Dwin block within DwinFormer that effectively captures\nlocal and global information along the horizontal, vertical, and depthwise\ndirections of the input feature map by separately performing attention in each\nof these directional volumes. To this end, our Dwin block introduces a nested\nDwin attention (NDA) that progressively increases the receptive field in\nhorizontal, vertical, and depthwise directions and a convolutional Dwin\nattention (CDA) that captures local contextual information for the attention\ncomputation. While the proposed Dwin block captures local and global\ndependencies at the first two high-resolution stages of DwinFormer, the GSA\nblock encodes global dependencies at the last two lower-resolution stages.\nExperiments over the challenging 3D Synapse Multi-organ dataset and Cell HMS\ndataset demonstrate the benefits of our DwinFormer over the state-of-the-art\napproaches. Our source code will be publicly available at\n\\url{https://github.com/Daniyanaj/DWINFORMER}.\n","authors":["Daniya Najiha Abdul Kareem","Mustansar Fiaz","Noa Novershtern","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2406.17471v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2406.17469v1","updated":"2024-06-25T11:14:09Z","published":"2024-06-25T11:14:09Z","title":"Cross-Modal Spherical Aggregation for Weakly Supervised Remote Sensing\n  Shadow Removal","summary":"  Remote sensing shadow removal, which aims to recover contaminated surface\ninformation, is tricky since shadows typically display overwhelmingly low\nillumination intensities. In contrast, the infrared image is robust toward\nsignificant light changes, providing visual clues complementary to the visible\nimage. Nevertheless, the existing methods ignore the collaboration between\nheterogeneous modalities, leading to undesired quality degradation. To fill\nthis gap, we propose a weakly supervised shadow removal network with a\nspherical feature space, dubbed S2-ShadowNet, to explore the best of both\nworlds for visible and infrared modalities. Specifically, we employ a modal\ntranslation (visible-to-infrared) model to learn the cross-domain mapping, thus\ngenerating realistic infrared samples. Then, Swin Transformer is utilized to\nextract strong representational visible/infrared features. Simultaneously, the\nextracted features are mapped to the smooth spherical manifold, which\nalleviates the domain shift through regularization. Well-designed similarity\nloss and orthogonality loss are embedded into the spherical space, prompting\nthe separation of private visible/infrared features and the alignment of shared\nvisible/infrared features through constraints on both representation content\nand orientation. Such a manner encourages implicit reciprocity between\nmodalities, thus providing a novel insight into shadow removal. Notably, ground\ntruth is not available in practice, thus S2-ShadowNet is trained by cropping\nshadow and shadow-free patches from the shadow image itself, avoiding\nstereotypical and strict pair data acquisition. More importantly, we contribute\na large-scale weakly supervised shadow removal benchmark, including 4000 shadow\nimages with corresponding shadow masks.\n","authors":["Kaichen Chi","Wei Jing","Junjie Li","Qiang Li","Qi Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17469v1.pdf","comment":"9pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.17462v1","updated":"2024-06-25T11:05:26Z","published":"2024-06-25T11:05:26Z","title":"The Tree of Diffusion Life: Evolutionary Embeddings to Understand the\n  Generation Process of Diffusion Models","summary":"  Diffusion models generate high-quality samples by corrupting data with\nGaussian noise and iteratively reconstructing it with deep learning, slowly\ntransforming noisy images into refined outputs. Understanding this data\nevolution is important for interpretability but is complex due to its\nhigh-dimensional evolutionary nature. While traditional dimensionality\nreduction methods like t-distributed stochastic neighborhood embedding (t-SNE)\naid in understanding high-dimensional spaces, they neglect evolutionary\nstructure preservation. Hence, we propose Tree of Diffusion Life (TDL), a\nmethod to understand data evolution in the generative process of diffusion\nmodels. TDL samples a diffusion model's generative space via instances with\nvarying prompts and employs image encoders to extract semantic meaning from\nthese samples, projecting them to an intermediate space. It employs a novel\nevolutionary embedding algorithm that explicitly encodes the iterations while\npreserving the high-dimensional relations, facilitating the visualization of\ndata evolution. This embedding leverages three metrics: a standard t-SNE loss\nto group semantically similar elements, a displacement loss to group elements\nfrom the same iteration step, and an instance alignment loss to align elements\nof the same instance across iterations. We present rectilinear and radial\nlayouts to represent iterations, enabling comprehensive exploration. We assess\nvarious feature extractors and highlight TDL's potential with prominent\ndiffusion models like GLIDE and Stable Diffusion with different prompt sets.\nTDL simplifies understanding data evolution within diffusion models, offering\nvaluable insights into their functioning.\n","authors":["Vidya Prasad","Hans van Gorp","Christina Humer","Anna Vilanova","Nicola Pezzotti"],"pdf_url":"https://arxiv.org/pdf/2406.17462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17460v1","updated":"2024-06-25T10:56:03Z","published":"2024-06-25T10:56:03Z","title":"Investigating Self-Supervised Methods for Label-Efficient Learning","summary":"  Vision transformers combined with self-supervised learning have enabled the\ndevelopment of models which scale across large datasets for several downstream\ntasks like classification, segmentation and detection. The low-shot learning\ncapability of these models, across several low-shot downstream tasks, has been\nlargely under explored. We perform a system level study of different self\nsupervised pretext tasks, namely contrastive learning, clustering, and masked\nimage modelling for their low-shot capabilities by comparing the pretrained\nmodels. In addition we also study the effects of collapse avoidance methods,\nnamely centring, ME-MAX, sinkhorn, on these downstream tasks. Based on our\ndetailed analysis, we introduce a framework involving both mask image modelling\nand clustering as pretext tasks, which performs better across all low-shot\ndownstream tasks, including multi-class classification, multi-label\nclassification and semantic segmentation. Furthermore, when testing the model\non full scale datasets, we show performance gains in multi-class\nclassification, multi-label classification and semantic segmentation.\n","authors":["Srinivasa Rao Nandam","Sara Atito","Zhenhua Feng","Josef Kittler","Muhammad Awais"],"pdf_url":"https://arxiv.org/pdf/2406.17460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17458v1","updated":"2024-06-25T10:53:57Z","published":"2024-06-25T10:53:57Z","title":"Continuous Urban Change Detection from Satellite Image Time Series with\n  Temporal Feature Refinement and Multi-Task Integration","summary":"  Urbanization advances at unprecedented rates, resulting in negative effects\non the environment and human well-being. Remote sensing has the potential to\nmitigate these effects by supporting sustainable development strategies with\naccurate information on urban growth. Deep learning-based methods have achieved\npromising urban change detection results from optical satellite image pairs\nusing convolutional neural networks (ConvNets), transformers, and a multi-task\nlearning setup. However, transformers have not been leveraged for urban change\ndetection with multi-temporal data, i.e., >2 images, and multi-task learning\nmethods lack integration approaches that combine change and segmentation\noutputs. To fill this research gap, we propose a continuous urban change\ndetection method that identifies changes in each consecutive image pair of a\nsatellite image time series. Specifically, we propose a temporal feature\nrefinement (TFR) module that utilizes self-attention to improve ConvNet-based\nmulti-temporal building representations. Furthermore, we propose a multi-task\nintegration (MTI) module that utilizes Markov networks to find an optimal\nbuilding map time series based on segmentation and dense change outputs. The\nproposed method effectively identifies urban changes based on high-resolution\nsatellite image time series acquired by the PlanetScope constellation (F1 score\n0.551) and Gaofen-2 (F1 score 0.440). Moreover, our experiments on two\nchallenging datasets demonstrate the effectiveness of the proposed method\ncompared to bi-temporal and multi-temporal urban change detection and\nsegmentation methods.\n","authors":["Sebastian Hafner","Heng Fang","Hossein Azizpour","Yifang Ban"],"pdf_url":"https://arxiv.org/pdf/2406.17458v1.pdf","comment":"Submitted to IEEE Transactions on Geoscience and Remote Sensing, Code\n  will be available at https://github.com/SebastianHafner/ContUrbanCD.git"},{"id":"http://arxiv.org/abs/2406.17450v1","updated":"2024-06-25T10:41:45Z","published":"2024-06-25T10:41:45Z","title":"Pseudo Labelling for Enhanced Masked Autoencoders","summary":"  Masked Image Modeling (MIM)-based models, such as SdAE, CAE, GreenMIM, and\nMixAE, have explored different strategies to enhance the performance of Masked\nAutoencoders (MAE) by modifying prediction, loss functions, or incorporating\nadditional architectural components. In this paper, we propose an enhanced\napproach that boosts MAE performance by integrating pseudo labelling for both\nclass and data tokens, alongside replacing the traditional pixel-level\nreconstruction with token-level reconstruction. This strategy uses cluster\nassignments as pseudo labels to promote instance-level discrimination within\nthe network, while token reconstruction requires generation of discrete tokens\nencapturing local context. The targets for pseudo labelling and reconstruction\nneeds to be generated by a teacher network. To disentangle the generation of\ntarget pseudo labels and the reconstruction of the token features, we decouple\nthe teacher into two distinct models, where one serves as a labelling teacher\nand the other as a reconstruction teacher. This separation proves empirically\nsuperior to a single teacher, while having negligible impact on throughput and\nmemory consumption. Incorporating pseudo-labelling as an auxiliary task has\ndemonstrated notable improvements in ImageNet-1K and other downstream tasks,\nincluding classification, semantic segmentation, and detection.\n","authors":["Srinivasa Rao Nandam","Sara Atito","Zhenhua Feng","Josef Kittler","Muhammad Awais"],"pdf_url":"https://arxiv.org/pdf/2406.17450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.04691v4","updated":"2024-06-25T10:41:39Z","published":"2022-05-10T06:24:09Z","title":"Probabilistic Approach for Detection of High-Frequency Periodic Signals\n  using an Event Camera","summary":"  Being inspired by the biological eye, event camera is a novel asynchronous\ntechnology that pose a paradigm shift in acquisition of visual information.\nThis paradigm enables event cameras to capture pixel-size fast motions much\nmore naturally compared to classical cameras.\n  In this paper we present a new asynchronous event-driven algorithm for\ndetection of high-frequency pixel-size periodic signals using an event camera.\nDevelopment of such new algorithms, to efficiently process the asynchronous\ninformation of event cameras, is essential and being a main challenge in the\nresearch community, in order to utilize its special properties and potential.\n  It turns out that this algorithm, that was developed in order to satisfy the\nnew paradigm, is related to an untreated theoretical problem in probability:\nlet $0\\leq\\tau_{1}\\leq\\tau_{2}\\leq\\cdots\\leq\\tau_{m}\\leq1$, originated from an\nunknown distribution. Let also $\\epsilon,\\delta\\in\\mathbb{R}$, and\n$d\\in\\mathbb{N}$. What can be said about the probability $\\Phi(m,d)$ of having\nmore than $d$ adjacent $\\tau_{i}$-s pairs that the distance between them is\n$\\delta$, up to an error $\\epsilon$ ? This problem, that reminds the area of\norder statistic, shows how the new visualization paradigm is also an\nopportunity to develop new areas and problems in mathematics.\n","authors":["David El-Chai Ben-Ezra","Ron Arad","Ayelet Padowicz","Israel Tugendhaft"],"pdf_url":"https://arxiv.org/pdf/2205.04691v4.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2406.17443v1","updated":"2024-06-25T10:23:58Z","published":"2024-06-25T10:23:58Z","title":"Using joint angles based on the international biomechanical standards\n  for human action recognition and related tasks","summary":"  Keypoint data has received a considerable amount of attention in machine\nlearning for tasks like action detection and recognition. However, human\nexperts in movement such as doctors, physiotherapists, sports scientists and\ncoaches use a notion of joint angles standardised by the International Society\nof Biomechanics to precisely and efficiently communicate static body poses and\nmovements. In this paper, we introduce the basic biomechanical notions and show\nhow they can be used to convert common keypoint data into joint angles that\nuniquely describe the given pose and have various desirable mathematical\nproperties, such as independence of both the camera viewpoint and the person\nperforming the action. We experimentally demonstrate that the joint angle\nrepresentation of keypoint data is suitable for machine learning applications\nand can in some cases bring an immediate performance gain. The use of joint\nangles as a human meaningful representation of kinematic data is in particular\npromising for applications where interpretability and dialog with human experts\nis important, such as many sports and medical applications. To facilitate\nfurther research in this direction, we will release a python package to convert\nkeypoint data into joint angles as outlined in this paper.\n","authors":["Kevin Schlegel","Lei Jiang","Hao Ni"],"pdf_url":"https://arxiv.org/pdf/2406.17443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17442v1","updated":"2024-06-25T10:23:53Z","published":"2024-06-25T10:23:53Z","title":"Mamba24/8D: Enhancing Global Interaction in Point Clouds via State Space\n  Model","summary":"  Transformers have demonstrated impressive results for 3D point cloud semantic\nsegmentation. However, the quadratic complexity of transformer makes\ncomputation cost high, limiting the number of points that can be processed\nsimultaneously and impeding the modeling of long-range dependencies. Drawing\ninspiration from the great potential of recent state space models (SSM) for\nlong sequence modeling, we introduce Mamba, a SSM-based architecture, to the\npoint cloud domain and propose Mamba24/8D, which has strong global modeling\ncapability under linear complexity. Specifically, to make disorderness of point\nclouds fit in with the causal nature of Mamba, we propose a multi-path\nserialization strategy applicable to point clouds. Besides, we propose the\nConvMamba block to compensate for the shortcomings of Mamba in modeling local\ngeometries and in unidirectional modeling. Mamba24/8D obtains state of the art\nresults on several 3D point cloud segmentation tasks, including ScanNet v2,\nScanNet200 and nuScenes, while its effectiveness is validated by extensive\nexperiments.\n","authors":["Zhuoyuan Li","Yubo Ai","Jiahao Lu","ChuXin Wang","Jiacheng Deng","Hanzhi Chang","Yanzhe Liang","Wenfei Yang","Shifeng Zhang","Tianzhu Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17438v1","updated":"2024-06-25T10:20:44Z","published":"2024-06-25T10:20:44Z","title":"Implicit-Zoo: A Large-Scale Dataset of Neural Implicit Functions for 2D\n  Images and 3D Scenes","summary":"  Neural implicit functions have demonstrated significant importance in various\nareas such as computer vision, graphics. Their advantages include the ability\nto represent complex shapes and scenes with high fidelity, smooth interpolation\ncapabilities, and continuous representations. Despite these benefits, the\ndevelopment and analysis of implicit functions have been limited by the lack of\ncomprehensive datasets and the substantial computational resources required for\ntheir implementation and evaluation. To address these challenges, we introduce\n\"Implicit-Zoo\": a large-scale dataset requiring thousands of GPU training days\ndesigned to facilitate research and development in this field. Our dataset\nincludes diverse 2D and 3D scenes, such as CIFAR-10, ImageNet-1K, and\nCityscapes for 2D image tasks, and the OmniObject3D dataset for 3D vision\ntasks. We ensure high quality through strict checks, refining or filtering out\nlow-quality data. Using Implicit-Zoo, we showcase two immediate benefits as it\nenables to: (1) learn token locations for transformer models; (2) directly\nregress 3D cameras poses of 2D images with respect to NeRF models. This in turn\nleads to an improved performance in all three task of image classification,\nsemantic segmentation, and 3D pose regression, thereby unlocking new avenues\nfor research.\n","authors":["Qi Ma","Danda Pani Paudel","Ender Konukoglu","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2406.17438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17437v1","updated":"2024-06-25T10:18:50Z","published":"2024-06-25T10:18:50Z","title":"Advancing Question Answering on Handwritten Documents: A\n  State-of-the-Art Recognition-Based Model for HW-SQuAD","summary":"  Question-answering handwritten documents is a challenging task with numerous\nreal-world applications. This paper proposes a novel recognition-based approach\nthat improves upon the previous state-of-the-art on the HW-SQuAD and BenthamQA\ndatasets. Our model incorporates transformer-based document retrieval and\nensemble methods at the model level, achieving an Exact Match score of 82.02%\nand 92.55% in HW-SQuAD and BenthamQA datasets, respectively, surpassing the\nprevious best recognition-based approach by 10.89% and 26%. We also enhance the\ndocument retrieval component, boosting the top-5 retrieval accuracy from 90% to\n95.30%. Our results demonstrate the significance of our proposed approach in\nadvancing question answering on handwritten documents. The code and trained\nmodels will be publicly available to facilitate future research in this\ncritical area of natural language.\n","authors":["Aniket Pal","Ajoy Mondal","C. V. Jawahar"],"pdf_url":"https://arxiv.org/pdf/2406.17437v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2406.17423v1","updated":"2024-06-25T09:56:30Z","published":"2024-06-25T09:56:30Z","title":"Deep learning-based brain segmentation model performance validation with\n  clinical radiotherapy CT","summary":"  Manual segmentation of medical images is labor intensive and especially\nchallenging for images with poor contrast or resolution. The presence of\ndisease exacerbates this further, increasing the need for an automated\nsolution. To this extent, SynthSeg is a robust deep learning model designed for\nautomatic brain segmentation across various contrasts and resolutions. This\nstudy validates the SynthSeg robust brain segmentation model on computed\ntomography (CT), using a multi-center dataset. An open access dataset of 260\npaired CT and magnetic resonance imaging (MRI) from radiotherapy patients\ntreated in 5 centers was collected. Brain segmentations from CT and MRI were\nobtained with SynthSeg model, a component of the Freesurfer imaging suite.\nThese segmentations were compared and evaluated using Dice scores and Hausdorff\n95 distance (HD95), treating MRI-based segmentations as the ground truth. Brain\nregions that failed to meet performance criteria were excluded based on\nautomated quality control (QC) scores. Dice scores indicate a median overlap of\n0.76 (IQR: 0.65-0.83). The median HD95 is 2.95 mm (IQR: 1.73-5.39). QC score\nbased thresholding improves median dice by 0.1 and median HD95 by 0.05mm.\nMorphological differences related to sex and age, as detected by MRI, were also\nreplicated with CT, with an approximate 17% difference between the CT and MRI\nresults for sex and 10% difference between the results for age. SynthSeg can be\nutilized for CT-based automatic brain segmentation, but only in applications\nwhere precision is not essential. CT performance is lower than MRI based on the\nintegrated QC scores, but low-quality segmentations can be excluded with\nQC-based thresholding. Additionally, performing CT-based neuroanatomical\nstudies is encouraged, as the results show correlations in sex- and age-based\nanalyses similar to those found with MRI.\n","authors":["Selena Huisman","Matteo Maspero","Marielle Philippens","Joost Verhoeff","Szabolcs David"],"pdf_url":"https://arxiv.org/pdf/2406.17423v1.pdf","comment":"15 pages, 9 figures, 3 supplementary data csv's, 1 supplementary file\n  with 1 figure"},{"id":"http://arxiv.org/abs/2406.17420v1","updated":"2024-06-25T09:45:50Z","published":"2024-06-25T09:45:50Z","title":"Real-Time Remote Control via VR over Limited Wireless Connectivity","summary":"  This work introduces a solution to enhance human-robot interaction over\nlimited wireless connectivity. The goal is toenable remote control of a robot\nthrough a virtual reality (VR)interface, ensuring a smooth transition to\nautonomous mode in the event of connectivity loss. The VR interface provides\naccessto a dynamic 3D virtual map that undergoes continuous updatesusing\nreal-time sensor data collected and transmitted by therobot. Furthermore, the\nrobot monitors wireless connectivity and automatically switches to a autonomous\nmode in scenarios with limited connectivity. By integrating four key\nfunctionalities: real-time mapping, remote control through glasses VR,\ncontinuous monitoring of wireless connectivity, and autonomous navigation\nduring limited connectivity, we achieve seamless end-to-end operation.\n","authors":["H. P. Madushanka","Rafaela Scaciota","Sumudu Samarakoon","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2406.17420v1.pdf","comment":"Accepted in ISCC 2024 conference"},{"id":"http://arxiv.org/abs/2406.17414v1","updated":"2024-06-25T09:37:09Z","published":"2024-06-25T09:37:09Z","title":"Consensus Learning with Deep Sets for Essential Matrix Estimation","summary":"  Robust estimation of the essential matrix, which encodes the relative\nposition and orientation of two cameras, is a fundamental step in structure\nfrom motion pipelines. Recent deep-based methods achieved accurate estimation\nby using complex network architectures that involve graphs, attention layers,\nand hard pruning steps. Here, we propose a simpler network architecture based\non Deep Sets. Given a collection of point matches extracted from two images,\nour method identifies outlier point matches and models the displacement noise\nin inlier matches. A weighted DLT module uses these predictions to regress the\nessential matrix. Our network achieves accurate recovery that is superior to\nexisting networks with significantly more complex architectures.\n","authors":["Dror Moran","Yuval Margalit","Guy Trostianetsky","Fadi Khatib","Meirav Galun","Ronen Basri"],"pdf_url":"https://arxiv.org/pdf/2406.17414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17413v1","updated":"2024-06-25T09:36:50Z","published":"2024-06-25T09:36:50Z","title":"Depth-Guided Semi-Supervised Instance Segmentation","summary":"  Semi-Supervised Instance Segmentation (SSIS) aims to leverage an amount of\nunlabeled data during training. Previous frameworks primarily utilized the RGB\ninformation of unlabeled images to generate pseudo-labels. However, such a\nmechanism often introduces unstable noise, as a single instance can display\nmultiple RGB values. To overcome this limitation, we introduce a Depth-Guided\n(DG) SSIS framework. This framework uses depth maps extracted from input\nimages, which represent individual instances with closely associated distance\nvalues, offering precise contours for distinct instances. Unlike RGB data,\ndepth maps provide a unique perspective, making their integration into the SSIS\nprocess complex. To this end, we propose Depth Feature Fusion, which integrates\nfeatures extracted from depth estimation. This integration allows the model to\nunderstand depth information better and ensure its effective utilization.\nAdditionally, to manage the variability of depth images during training, we\nintroduce the Depth Controller. This component enables adaptive adjustments of\nthe depth map, enhancing convergence speed and dynamically balancing the loss\nweights between RGB and depth maps. Extensive experiments conducted on the COCO\nand Cityscapes datasets validate the efficacy of our proposed method. Our\napproach establishes a new benchmark for SSIS, outperforming previous methods.\nSpecifically, our DG achieves 22.29%, 31.47%, and 35.14% mAP for 1%, 5%, and\n10% labeled data on the COCO dataset, respectively.\n","authors":["Xin Chen","Jie Hu","Xiawu Zheng","Jianghang Lin","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2406.17413v1.pdf","comment":"12 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.16658v2","updated":"2024-06-25T09:36:21Z","published":"2024-06-24T14:08:27Z","title":"Sampling Strategies in Bayesian Inversion: A Study of RTO and Langevin\n  Methods","summary":"  This paper studies two classes of sampling methods for the solution of\ninverse problems, namely Randomize-Then-Optimize (RTO), which is rooted in\nsensitivity analysis, and Langevin methods, which are rooted in the Bayesian\nframework. The two classes of methods correspond to different assumptions and\nyield samples from different target distributions. We highlight the main\nconceptual and theoretical differences between the two approaches and compare\nthem from a practical point of view by tackling two classical inverse problems\nin imaging: deblurring and inpainting. We show that the choice of the sampling\nmethod has a significant impact on the quality of the reconstruction and that\nthe RTO method is more robust to the choice of the parameters.\n","authors":["Remi Laumont","Yiqiu Dong","Martin Skovgaard Andersen"],"pdf_url":"https://arxiv.org/pdf/2406.16658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17405v1","updated":"2024-06-25T09:26:49Z","published":"2024-06-25T09:26:49Z","title":"Less can be more: representational vs. stereotypical gender bias in\n  facial expression recognition","summary":"  Machine learning models can inherit biases from their training data, leading\nto discriminatory or inaccurate predictions. This is particularly concerning\nwith the increasing use of large, unsupervised datasets for training\nfoundational models. Traditionally, demographic biases within these datasets\nhave not been well-understood, limiting our ability to understand how they\npropagate to the models themselves. To address this issue, this paper\ninvestigates the propagation of demographic biases from datasets into machine\nlearning models. We focus on the gender demographic component, analyzing two\ntypes of bias: representational and stereotypical. For our analysis, we\nconsider the domain of facial expression recognition (FER), a field known to\nexhibit biases in most popular datasets. We use Affectnet, one of the largest\nFER datasets, as our baseline for carefully designing and generating subsets\nthat incorporate varying strengths of both representational and stereotypical\nbias. Subsequently, we train several models on these biased subsets, evaluating\ntheir performance on a common test set to assess the propagation of bias into\nthe models' predictions. Our results show that representational bias has a\nweaker impact than expected. Models exhibit a good generalization ability even\nin the absence of one gender in the training dataset. Conversely, stereotypical\nbias has a significantly stronger impact, primarily concentrated on the biased\nclass, although it can also influence predictions for unbiased classes. These\nresults highlight the need for a bias analysis that differentiates between\ntypes of bias, which is crucial for the development of effective bias\nmitigation strategies.\n","authors":["Iris Dominguez-Catena","Daniel Paternain","Aranzazu Jurio","Mikel Galar"],"pdf_url":"https://arxiv.org/pdf/2406.17405v1.pdf","comment":"21 pages including appendix, 11 figures"},{"id":"http://arxiv.org/abs/2406.17396v1","updated":"2024-06-25T09:17:35Z","published":"2024-06-25T09:17:35Z","title":"SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D\n  Scene Editing","summary":"  Text-based 2D diffusion models have demonstrated impressive capabilities in\nimage generation and editing. Meanwhile, the 2D diffusion models also exhibit\nsubstantial potentials for 3D editing tasks. However, how to achieve consistent\nedits across multiple viewpoints remains a challenge. While the iterative\ndataset update method is capable of achieving global consistency, it suffers\nfrom slow convergence and over-smoothed textures. We propose SyncNoise, a novel\ngeometry-guided multi-view consistent noise editing approach for high-fidelity\n3D scene editing. SyncNoise synchronously edits multiple views with 2D\ndiffusion models while enforcing multi-view noise predictions to be\ngeometrically consistent, which ensures global consistency in both semantic\nstructure and low-frequency appearance. To further enhance local consistency in\nhigh-frequency details, we set a group of anchor views and propagate them to\ntheir neighboring frames through cross-view reprojection. To improve the\nreliability of multi-view correspondences, we introduce depth supervision\nduring training to enhance the reconstruction of precise geometries. Our method\nachieves high-quality 3D editing results respecting the textual instructions,\nespecially in scenes with complex textures, by enhancing geometric consistency\nat the noise and pixel levels.\n","authors":["Ruihuang Li","Liyi Chen","Zhengqiang Zhang","Varun Jampani","Vishal M. Patel","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17396v1.pdf","comment":"16 pages, 13 figures"},{"id":"http://arxiv.org/abs/2401.04364v2","updated":"2024-06-25T09:02:42Z","published":"2024-01-09T05:32:22Z","title":"SoK: Facial Deepfake Detectors","summary":"  Deepfakes have rapidly emerged as a profound and serious threat to society,\nprimarily due to their ease of creation and dissemination. This situation has\ntriggered an accelerated development of deepfake detection technologies.\nHowever, many existing detectors rely heavily on lab-generated datasets for\nvalidation, which may not effectively prepare them for novel, emerging, and\nreal-world deepfake techniques. In this paper, we conduct an extensive and\ncomprehensive review and analysis of the latest state-of-the-art deepfake\ndetectors, evaluating them against several critical criteria. These criteria\nfacilitate the categorization of these detectors into 4 high-level groups and\n13 fine-grained sub-groups, all aligned with a unified standard conceptual\nframework. This classification and framework offer deep and practical insights\ninto the factors that affect detector efficacy. We assess the generalizability\nof 16 leading detectors across various standard attack scenarios, including\nblack-box, white-box, and gray-box settings. Our systematized analysis and\nexperimentation lay the groundwork for a deeper understanding of deepfake\ndetectors and their generalizability, paving the way for future research\nfocused on creating detectors adept at countering various attack scenarios.\nAdditionally, this work offers insights for developing more proactive defenses\nagainst deepfakes.\n","authors":["Binh M. Le","Jiwon Kim","Shahroz Tariq","Kristen Moore","Alsharif Abuadbba","Simon S. Woo"],"pdf_url":"https://arxiv.org/pdf/2401.04364v2.pdf","comment":"18 pages, 6 figures, 5 table, under peer-review"},{"id":"http://arxiv.org/abs/2406.17382v1","updated":"2024-06-25T08:58:53Z","published":"2024-06-25T08:58:53Z","title":"Automatic infant 2D pose estimation from videos: comparing seven deep\n  neural network methods","summary":"  Automatic markerless estimation of infant posture and motion from ordinary\nvideos carries great potential for movement studies \"in the wild\", facilitating\nunderstanding of motor development and massively increasing the chances of\nearly diagnosis of disorders. There is rapid development of human pose\nestimation methods in computer vision thanks to advances in deep learning and\nmachine learning. However, these methods are trained on datasets featuring\nadults in different contexts. This work tests and compares seven popular\nmethods (AlphaPose, DeepLabCut/DeeperCut, Detectron2, HRNet,\nMediaPipe/BlazePose, OpenPose, and ViTPose) on videos of infants in supine\nposition. Surprisingly, all methods except DeepLabCut and MediaPipe have\ncompetitive performance without additional finetuning, with ViTPose performing\nbest. Next to standard performance metrics (object keypoint similarity, average\nprecision and recall), we introduce errors expressed in the neck-mid-hip ratio\nand additionally study missed and redundant detections and the reliability of\nthe internal confidence ratings of the different methods, which are relevant\nfor downstream tasks. Among the networks with competitive performance, only\nAlphaPose could run close to real time (27 fps) on our machine. We provide\ndocumented Docker containers or instructions for all the methods we used, our\nanalysis scripts, and processed data at https://hub.docker.com/u/humanoidsctu\nand https://osf.io/x465b/.\n","authors":["Filipe Gama","Matej Misar","Lukas Navara","Jason Khoury","Sergiu T. Popescu","Matej Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2406.17382v1.pdf","comment":"21 pages, 3 figures, 14 tables"},{"id":"http://arxiv.org/abs/2406.17381v1","updated":"2024-06-25T08:57:47Z","published":"2024-06-25T08:57:47Z","title":"Forget but Recall: Incremental Latent Rectification in Continual\n  Learning","summary":"  Intrinsic capability to continuously learn a changing data stream is a\ndesideratum of deep neural networks (DNNs). However, current DNNs suffer from\ncatastrophic forgetting, which hinders remembering past knowledge. To mitigate\nthis issue, existing Continual Learning (CL) approaches either retain exemplars\nfor replay, regularize learning, or allocate dedicated capacity for new tasks.\nThis paper investigates an unexplored CL direction for incremental learning\ncalled Incremental Latent Rectification or ILR. In a nutshell, ILR learns to\npropagate with correction (or rectify) the representation from the current\ntrained DNN backward to the representation space of the old task, where\nperforming predictive decisions is easier. This rectification process only\nemploys a chain of small representation mapping networks, called rectifier\nunits. Empirical experiments on several continual learning benchmarks,\nincluding CIFAR10, CIFAR100, and Tiny ImageNet, demonstrate the effectiveness\nand potential of this novel CL direction compared to existing representative CL\nmethods.\n","authors":["Nghia D. Nguyen","Hieu Trung Nguyen","Ang Li","Hoang Pham","Viet Anh Nguyen","Khoa D. Doan"],"pdf_url":"https://arxiv.org/pdf/2406.17381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17349v1","updated":"2024-06-25T08:05:42Z","published":"2024-06-25T08:05:42Z","title":"Semantic Deep Hiding for Robust Unlearnable Examples","summary":"  Ensuring data privacy and protection has become paramount in the era of deep\nlearning. Unlearnable examples are proposed to mislead the deep learning models\nand prevent data from unauthorized exploration by adding small perturbations to\ndata. However, such perturbations (e.g., noise, texture, color change)\npredominantly impact low-level features, making them vulnerable to common\ncountermeasures. In contrast, semantic images with intricate shapes have a\nwealth of high-level features, making them more resilient to countermeasures\nand potential for producing robust unlearnable examples. In this paper, we\npropose a Deep Hiding (DH) scheme that adaptively hides semantic images\nenriched with high-level features. We employ an Invertible Neural Network (INN)\nto invisibly integrate predefined images, inherently hiding them with deceptive\nperturbations. To enhance data unlearnability, we introduce a Latent Feature\nConcentration module, designed to work with the INN, regularizing the\nintra-class variance of these perturbations. To further boost the robustness of\nunlearnable examples, we design a Semantic Images Generation module that\nproduces hidden semantic images. By utilizing similar semantic information,\nthis module generates similar semantic images for samples within the same\nclasses, thereby enlarging the inter-class distance and narrowing the\nintra-class distance. Extensive experiments on CIFAR-10, CIFAR-100, and an\nImageNet subset, against 18 countermeasures, reveal that our proposed method\nexhibits outstanding robustness for unlearnable examples, demonstrating its\nefficacy in preventing unauthorized data exploitation.\n","authors":["Ruohan Meng","Chenyu Yi","Yi Yu","Siyuan Yang","Bingquan Shen","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2406.17349v1.pdf","comment":"Accepted by TIFS 2024"},{"id":"http://arxiv.org/abs/2406.17345v1","updated":"2024-06-25T07:58:47Z","published":"2024-06-25T07:58:47Z","title":"NerfBaselines: Consistent and Reproducible Evaluation of Novel View\n  Synthesis Methods","summary":"  Novel view synthesis is an important problem with many applications,\nincluding AR/VR, gaming, and simulations for robotics. With the recent rapid\ndevelopment of Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS)\nmethods, it is becoming difficult to keep track of the current state of the art\n(SoTA) due to methods using different evaluation protocols, codebases being\ndifficult to install and use, and methods not generalizing well to novel 3D\nscenes. Our experiments support this claim by showing that tiny differences in\nevaluation protocols of various methods can lead to inconsistent reported\nmetrics. To address these issues, we propose a framework called NerfBaselines,\nwhich simplifies the installation of various methods, provides consistent\nbenchmarking tools, and ensures reproducibility. We validate our implementation\nexperimentally by reproducing numbers reported in the original papers. To\nfurther improve the accessibility, we release a web platform where commonly\nused methods are compared on standard benchmarks. Web:\nhttps://jkulhanek.com/nerfbaselines\n","authors":["Jonas Kulhanek","Torsten Sattler"],"pdf_url":"https://arxiv.org/pdf/2406.17345v1.pdf","comment":"Web: https://jkulhanek.com/nerfbaselines"},{"id":"http://arxiv.org/abs/2406.17343v1","updated":"2024-06-25T07:57:27Z","published":"2024-06-25T07:57:27Z","title":"Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers","summary":"  Recent advancements in diffusion models, particularly the trend of\narchitectural transformation from UNet-based Diffusion to Diffusion Transformer\n(DiT), have significantly improved the quality and scalability of image\nsynthesis. Despite the incredible generative quality, the large computational\nrequirements of these large-scale models significantly hinder the deployments\nin real-world scenarios. Post-training Quantization (PTQ) offers a promising\nsolution by compressing model sizes and speeding up inference for the\npretrained models while eliminating model retraining. However, we have observed\nthe existing PTQ frameworks exclusively designed for both ViT and conventional\nDiffusion models fall into biased quantization and result in remarkable\nperformance degradation. In this paper, we find that the DiTs typically exhibit\nconsiderable variance in terms of both weight and activation, which easily runs\nout of the limited numerical representations. To address this issue, we devise\nQ-DiT, which seamlessly integrates three techniques: fine-grained quantization\nto manage substantial variance across input channels of weights and\nactivations, an automatic search strategy to optimize the quantization\ngranularity and mitigate redundancies, and dynamic activation quantization to\ncapture the activation changes across timesteps. Extensive experiments on the\nImageNet dataset demonstrate the effectiveness of the proposed Q-DiT.\nSpecifically, when quantizing DiT-XL/2 to W8A8 on ImageNet 256x256, Q-DiT\nachieves a remarkable reduction in FID by 1.26 compared to the baseline. Under\na W4A8 setting, it maintains high fidelity in image generation, showcasing only\na marginal increase in FID and setting a new benchmark for efficient,\nhigh-quality quantization in diffusion transformers. Code is available at\n\\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}.\n","authors":["Lei Chen","Yuan Meng","Chen Tang","Xinzhu Ma","Jingyan Jiang","Xin Wang","Zhi Wang","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.17343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17342v1","updated":"2024-06-25T07:57:03Z","published":"2024-06-25T07:57:03Z","title":"Masked Generative Extractor for Synergistic Representation and 3D\n  Generation of Point Clouds","summary":"  In the field of 2D image generation modeling and representation learning,\nMasked Generative Encoder (MAGE) has demonstrated the synergistic potential\nbetween generative modeling and representation learning. Inspired by this, we\npropose Point-MAGE to extend this concept to point cloud data. Specifically,\nthis framework first utilizes a Vector Quantized Variational Autoencoder\n(VQVAE) to reconstruct a neural field representation of 3D shapes, thereby\nlearning discrete semantic features of point patches. Subsequently, by\ncombining the masking model with variable masking ratios, we achieve\nsynchronous training for both generation and representation learning.\nFurthermore, our framework seamlessly integrates with existing point cloud\nself-supervised learning (SSL) models, thereby enhancing their performance. We\nextensively evaluate the representation learning and generation capabilities of\nPoint-MAGE. In shape classification tasks, Point-MAGE achieved an accuracy of\n94.2% on the ModelNet40 dataset and 92.9% (+1.3%) on the ScanObjectNN dataset.\nAdditionally, it achieved new state-of-the-art performance in few-shot learning\nand part segmentation tasks. Experimental results also confirmed that\nPoint-MAGE can generate detailed and high-quality 3D shapes in both\nunconditional and conditional settings.\n","authors":["Hongliang Zeng","Ping Zhang","Fang Li","Jiahua Wang","Tingyu Ye","Pengteng Guo"],"pdf_url":"https://arxiv.org/pdf/2406.17342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17338v1","updated":"2024-06-25T07:50:09Z","published":"2024-06-25T07:50:09Z","title":"Robustly Optimized Deep Feature Decoupling Network for Fatty Liver\n  Diseases Detection","summary":"  Current medical image classification efforts mainly aim for higher average\nperformance, often neglecting the balance between different classes. This can\nlead to significant differences in recognition accuracy between classes and\nobvious recognition weaknesses. Without the support of massive data, deep\nlearning faces challenges in fine-grained classification of fatty liver. In\nthis paper, we propose an innovative deep learning framework that combines\nfeature decoupling and adaptive adversarial training. Firstly, we employ two\niteratively compressed decouplers to supervised decouple common features and\nspecific features related to fatty liver in abdominal ultrasound images.\nSubsequently, the decoupled features are concatenated with the original image\nafter transforming the color space and are fed into the classifier. During\nadversarial training, we adaptively adjust the perturbation and balance the\nadversarial strength by the accuracy of each class. The model will eliminate\nrecognition weaknesses by correctly classifying adversarial samples, thus\nimproving recognition robustness. Finally, the accuracy of our method improved\nby 4.16%, achieving 82.95%. As demonstrated by extensive experiments, our\nmethod is a generalized learning framework that can be directly used to\neliminate the recognition weaknesses of any classifier while improving its\naverage performance. Code is available at https://github.com/HP-ML/MICCAI2024.\n","authors":["Peng Huang","Shu Hu","Bo Peng","Jiashu Zhang","Xi Wu","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17338v1.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2403.15770v2","updated":"2024-06-25T07:45:53Z","published":"2024-03-23T08:57:46Z","title":"Graph Image Prior for Unsupervised Dynamic Cardiac Cine MRI\n  Reconstruction","summary":"  The inductive bias of the convolutional neural network (CNN) can be a strong\nprior for image restoration, which is known as the Deep Image Prior (DIP).\nRecently, DIP is utilized in unsupervised dynamic MRI reconstruction, which\nadopts a generative model from the latent space to the image space. However,\nexisting methods usually use a pyramid-shaped CNN generator shared by all\nframes, embedding the temporal modeling within the latent space, which may\nhamper the model expression capability. In this work, we propose a novel scheme\nfor dynamic MRI representation, named ``Graph Image Prior'' (GIP). GIP adopts a\ntwo-stage generative network in a new modeling methodology, which first employs\nindependent CNNs to recover the image structure for each frame, and then\nexploits the spatio-temporal correlations within the feature space\nparameterized by a graph model. A graph convolutional network is utilized for\nfeature fusion and dynamic image generation. In addition, we devise an ADMM\nalgorithm to alternately optimize the images and the network parameters to\nimprove the reconstruction performance. Experiments were conducted on cardiac\ncine MRI reconstruction, which demonstrate that GIP outperforms compressed\nsensing methods and other DIP-based unsupervised methods, significantly\nreducing the performance gap with state-of-the-art supervised algorithms.\nMoreover, GIP displays superior generalization ability when transferred to a\ndifferent reconstruction setting, without the need for any additional data.\n","authors":["Zhongsen Li","Wenxuan Chen","Shuai Wang","Chuyu Liu","Qing Zou","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2403.15770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15485v2","updated":"2024-06-25T07:37:22Z","published":"2024-06-17T11:00:04Z","title":"SegHist: A General Segmentation-based Framework for Chinese Historical\n  Document Text Line Detection","summary":"  Text line detection is a key task in historical document analysis facing many\nchallenges of arbitrary-shaped text lines, dense texts, and text lines with\nhigh aspect ratios, etc. In this paper, we propose a general framework for\nhistorical document text detection (SegHist), enabling existing\nsegmentation-based text detection methods to effectively address the\nchallenges, especially text lines with high aspect ratios. Integrating the\nSegHist framework with the commonly used method DB++, we develop DB-SegHist.\nThis approach achieves SOTA on the CHDAC, MTHv2, and competitive results on\nHDRC datasets, with a significant improvement of 1.19% on the most challenging\nCHDAC dataset which features more text lines with high aspect ratios. Moreover,\nour method attains SOTA on rotated MTHv2 and rotated HDRC, demonstrating its\nrotational robustness. The code is available at\nhttps://github.com/LumionHXJ/SegHist.\n","authors":["Xingjian Hu","Baole Wei","Liangcai Gao"],"pdf_url":"https://arxiv.org/pdf/2406.15485v2.pdf","comment":"Accepted by ICDAR2024"},{"id":"http://arxiv.org/abs/2406.17323v1","updated":"2024-06-25T07:14:15Z","published":"2024-06-25T07:14:15Z","title":"XAMI -- A Benchmark Dataset for Artefact Detection in XMM-Newton Optical\n  Images","summary":"  Reflected or scattered light produce artefacts in astronomical observations\nthat can negatively impact the scientific study. Hence, automated detection of\nthese artefacts is highly beneficial, especially with the increasing amounts of\ndata gathered. Machine learning methods are well-suited to this problem, but\ncurrently there is a lack of annotated data to train such approaches to detect\nartefacts in astronomical observations. In this work, we present a dataset of\nimages from the XMM-Newton space telescope Optical Monitoring camera showing\ndifferent types of artefacts. We hand-annotated a sample of 1000 images with\nartefacts which we use to train automated ML methods. We further demonstrate\ntechniques tailored for accurate detection and masking of artefacts using\ninstance segmentation. We adopt a hybrid approach, combining knowledge from\nboth convolutional neural networks (CNNs) and transformer-based models and use\ntheir advantages in segmentation. The presented method and dataset will advance\nartefact detection in astronomical observations by providing a reproducible\nbaseline. All code and data are made available\n(https://github.com/ESA-Datalabs/XAMI-model and\nhttps://github.com/ESA-Datalabs/XAMI-dataset).\n","authors":["Elisabeta-Iulia Dima","Pablo Gómez","Sandor Kruk","Peter Kretschmar","Simon Rosen","Călin-Adrian Popa"],"pdf_url":"https://arxiv.org/pdf/2406.17323v1.pdf","comment":"submitted to SPAICE 2024"},{"id":"http://arxiv.org/abs/2406.17319v1","updated":"2024-06-25T07:08:19Z","published":"2024-06-25T07:08:19Z","title":"DMF-Net: Image-Guided Point Cloud Completion with Dual-Channel Modality\n  Fusion and Shape-Aware Upsampling Transformer","summary":"  In this paper we study the task of a single-view image-guided point cloud\ncompletion. Existing methods have got promising results by fusing the\ninformation of image into point cloud explicitly or implicitly. However, given\nthat the image has global shape information and the partial point cloud has\nrich local details, We believe that both modalities need to be given equal\nattention when performing modality fusion. To this end, we propose a novel\ndual-channel modality fusion network for image-guided point cloud\ncompletion(named DMF-Net), in a coarse-to-fine manner. In the first stage,\nDMF-Net takes a partial point cloud and corresponding image as input to recover\na coarse point cloud. In the second stage, the coarse point cloud will be\nupsampled twice with shape-aware upsampling transformer to get the dense and\ncomplete point cloud. Extensive quantitative and qualitative experimental\nresults show that DMF-Net outperforms the state-of-the-art unimodal and\nmultimodal point cloud completion works on ShapeNet-ViPC dataset.\n","authors":["Aihua Mao","Yuxuan Tang","Jiangtao Huang","Ying He"],"pdf_url":"https://arxiv.org/pdf/2406.17319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16109v2","updated":"2024-06-25T06:47:07Z","published":"2024-06-23T13:53:35Z","title":"X-ray2CTPA: Generating 3D CTPA scans from 2D X-ray conditioning","summary":"  Chest X-rays or chest radiography (CXR), commonly used for medical\ndiagnostics, typically enables limited imaging compared to computed tomography\n(CT) scans, which offer more detailed and accurate three-dimensional data,\nparticularly contrast-enhanced scans like CT Pulmonary Angiography (CTPA).\nHowever, CT scans entail higher costs, greater radiation exposure, and are less\naccessible than CXRs. In this work we explore cross-modal translation from a 2D\nlow contrast-resolution X-ray input to a 3D high contrast and\nspatial-resolution CTPA scan. Driven by recent advances in generative AI, we\nintroduce a novel diffusion-based approach to this task. We evaluate the models\nperformance using both quantitative metrics and qualitative feedback from\nradiologists, ensuring diagnostic relevance of the generated images.\nFurthermore, we employ the synthesized 3D images in a classification framework\nand show improved AUC in a PE categorization task, using the initial CXR input.\nThe proposed method is generalizable and capable of performing additional\ncross-modality translations in medical imaging. It may pave the way for more\naccessible and cost-effective advanced diagnostic tools. The code for this\nproject is available: https://github.com/NoaCahan/X-ray2CTPA .\n","authors":["Noa Cahan","Eyal Klang","Galit Aviram","Yiftach Barash","Eli Konen","Raja Giryes","Hayit Greenspan"],"pdf_url":"https://arxiv.org/pdf/2406.16109v2.pdf","comment":"preprint, project code: https://github.com/NoaCahan/X-ray2CTPA"},{"id":"http://arxiv.org/abs/2406.17309v1","updated":"2024-06-25T06:42:26Z","published":"2024-06-25T06:42:26Z","title":"Zero-Shot Long-Form Video Understanding through Screenplay","summary":"  The Long-form Video Question-Answering task requires the comprehension and\nanalysis of extended video content to respond accurately to questions by\nutilizing both temporal and contextual information. In this paper, we present\nMM-Screenplayer, an advanced video understanding system with multi-modal\nperception capabilities that can convert any video into textual screenplay\nrepresentations. Unlike previous storytelling methods, we organize video\ncontent into scenes as the basic unit, rather than just visually continuous\nshots. Additionally, we developed a ``Look Back'' strategy to reassess and\nvalidate uncertain information, particularly targeting breakpoint mode.\nMM-Screenplayer achieved highest score in the CVPR'2024 LOng-form VidEo\nUnderstanding (LOVEU) Track 1 Challenge, with a global accuracy of 87.5% and a\nbreakpoint accuracy of 68.8%.\n","authors":["Yongliang Wu","Bozheng Li","Jiawang Cao","Wenbo Zhu","Yi Lu","Weiheng Chi","Chuyun Xie","Haolin Zheng","Ziyue Su","Jay Wu","Xu Yang"],"pdf_url":"https://arxiv.org/pdf/2406.17309v1.pdf","comment":"Highest Score Award to the CVPR'2024 LOVEU Track 1 Challenge"},{"id":"http://arxiv.org/abs/2312.00690v4","updated":"2024-06-25T06:23:56Z","published":"2023-12-01T16:17:16Z","title":"Open-vocabulary object 6D pose estimation","summary":"  We introduce the new setting of open-vocabulary object 6D pose estimation, in\nwhich a textual prompt is used to specify the object of interest. In contrast\nto existing approaches, in our setting (i) the object of interest is specified\nsolely through the textual prompt, (ii) no object model (e.g., CAD or video\nsequence) is required at inference, and (iii) the object is imaged from two\nRGBD viewpoints of different scenes. To operate in this setting, we introduce a\nnovel approach that leverages a Vision-Language Model to segment the object of\ninterest from the scenes and to estimate its relative 6D pose. The key of our\napproach is a carefully devised strategy to fuse object-level information\nprovided by the prompt with local image features, resulting in a feature space\nthat can generalize to novel concepts. We validate our approach on a new\nbenchmark based on two popular datasets, REAL275 and Toyota-Light, which\ncollectively encompass 34 object instances appearing in four thousand image\npairs. The results demonstrate that our approach outperforms both a\nwell-established hand-crafted method and a recent deep learning-based baseline\nin estimating the relative 6D pose of objects in different scenes. Code and\ndataset are available at https://jcorsetti.github.io/oryon.\n","authors":["Jaime Corsetti","Davide Boscaini","Changjae Oh","Andrea Cavallaro","Fabio Poiesi"],"pdf_url":"https://arxiv.org/pdf/2312.00690v4.pdf","comment":"Camera ready version (CVPR 2024, poster highlight). New Oryon\n  version: arXiv:2406.16384"},{"id":"http://arxiv.org/abs/2406.17297v1","updated":"2024-06-25T05:58:34Z","published":"2024-06-25T05:58:34Z","title":"Towards Open-set Camera 3D Object Detection","summary":"  Traditional camera 3D object detectors are typically trained to recognize a\npredefined set of known object classes. In real-world scenarios, these\ndetectors may encounter unknown objects outside the training categories and\nfail to identify them correctly. To address this gap, we present OS-Det3D\n(Open-set Camera 3D Object Detection), a two-stage training framework enhancing\nthe ability of camera 3D detectors to identify both known and unknown objects.\nThe framework involves our proposed 3D Object Discovery Network (ODN3D), which\nis specifically trained using geometric cues such as the location and scale of\n3D boxes to discover general 3D objects. ODN3D is trained in a class-agnostic\nmanner, and the provided 3D object region proposals inherently come with data\nnoise. To boost accuracy in identifying unknown objects, we introduce a Joint\nObjectness Selection (JOS) module. JOS selects the pseudo ground truth for\nunknown objects from the 3D object region proposals of ODN3D by combining the\nODN3D objectness and camera feature attention objectness. Experiments on the\nnuScenes and KITTI datasets demonstrate the effectiveness of our framework in\nenabling camera 3D detectors to successfully identify unknown objects while\nalso improving their performance on known objects.\n","authors":["Zhuolin He","Xinrun Li","Heng Gao","Jiachen Tang","Shoumeng Qiu","Wenfu Wang","Lvjian Lu","Xiuchong Qiu","Xiangyang Xue","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2406.17297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10882v3","updated":"2024-06-25T05:56:40Z","published":"2024-02-16T18:36:36Z","title":"Universal Prompt Optimizer for Safe Text-to-Image Generation","summary":"  Text-to-Image (T2I) models have shown great performance in generating images\nbased on textual prompts. However, these models are vulnerable to unsafe input\nto generate unsafe content like sexual, harassment and illegal-activity images.\nExisting studies based on image checker, model fine-tuning and embedding\nblocking are impractical in real-world applications. Hence, we propose the\nfirst universal prompt optimizer for safe T2I (POSI) generation in black-box\nscenario. We first construct a dataset consisting of toxic-clean prompt pairs\nby GPT-3.5 Turbo. To guide the optimizer to have the ability of converting\ntoxic prompt to clean prompt while preserving semantic information, we design a\nnovel reward function measuring toxicity and text alignment of generated images\nand train the optimizer through Proximal Policy Optimization. Experiments show\nthat our approach can effectively reduce the likelihood of various T2I models\nin generating inappropriate images, with no significant impact on text\nalignment. It is also flexible to be combined with methods to achieve better\nperformance. Our code is available at https://github.com/wzongyu/POSI.\n","authors":["Zongyu Wu","Hongcheng Gao","Yueze Wang","Xiang Zhang","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2402.10882v3.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2401.03407v5","updated":"2024-06-25T05:54:38Z","published":"2024-01-07T07:56:47Z","title":"Bilateral Reference for High-Resolution Dichotomous Image Segmentation","summary":"  We introduce a novel bilateral reference framework (BiRefNet) for\nhigh-resolution dichotomous image segmentation (DIS). It comprises two\nessential components: the localization module (LM) and the reconstruction\nmodule (RM) with our proposed bilateral reference (BiRef). The LM aids in\nobject localization using global semantic information. Within the RM, we\nutilize BiRef for the reconstruction process, where hierarchical patches of\nimages provide the source reference and gradient maps serve as the target\nreference. These components collaborate to generate the final predicted maps.\nWe also introduce auxiliary gradient supervision to enhance focus on regions\nwith finer details. Furthermore, we outline practical training strategies\ntailored for DIS to improve map quality and training process. To validate the\ngeneral applicability of our approach, we conduct extensive experiments on four\ntasks to evince that BiRefNet exhibits remarkable performance, outperforming\ntask-specific cutting-edge methods across all benchmarks. Our codes are\navailable at https://github.com/ZhengPeng7/BiRefNet.\n","authors":["Peng Zheng","Dehong Gao","Deng-Ping Fan","Li Liu","Jorma Laaksonen","Wanli Ouyang","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2401.03407v5.pdf","comment":"Version 5, with updated DIS performance, accuracy-efficiency\n  comparison, and 3rd-party applications"},{"id":"http://arxiv.org/abs/2403.05005v2","updated":"2024-06-25T04:31:12Z","published":"2024-03-08T03:03:41Z","title":"DITTO: Dual and Integrated Latent Topologies for Implicit 3D\n  Reconstruction","summary":"  We propose a novel concept of dual and integrated latent topologies (DITTO in\nshort) for implicit 3D reconstruction from noisy and sparse point clouds. Most\nexisting methods predominantly focus on single latent type, such as point or\ngrid latents. In contrast, the proposed DITTO leverages both point and grid\nlatents (i.e., dual latent) to enhance their strengths, the stability of grid\nlatents and the detail-rich capability of point latents. Concretely, DITTO\nconsists of dual latent encoder and integrated implicit decoder. In the dual\nlatent encoder, a dual latent layer, which is the key module block composing\nthe encoder, refines both latents in parallel, maintaining their distinct\nshapes and enabling recursive interaction. Notably, a newly proposed dynamic\nsparse point transformer within the dual latent layer effectively refines point\nlatents. Then, the integrated implicit decoder systematically combines these\nrefined latents, achieving high-fidelity 3D reconstruction and surpassing\nprevious state-of-the-art methods on object- and scene-level datasets,\nespecially in thin and detailed structures.\n","authors":["Jaehyeok Shim","Kyungdon Joo"],"pdf_url":"https://arxiv.org/pdf/2403.05005v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2406.17265v1","updated":"2024-06-25T04:16:14Z","published":"2024-06-25T04:16:14Z","title":"Image-Guided Outdoor LiDAR Perception Quality Assessment for Autonomous\n  Driving","summary":"  LiDAR is one of the most crucial sensors for autonomous vehicle perception.\nHowever, current LiDAR-based point cloud perception algorithms lack\ncomprehensive and rigorous LiDAR quality assessment methods, leading to\nuncertainty in detection performance. Additionally, existing point cloud\nquality assessment algorithms are predominantly designed for indoor\nenvironments or single-object scenarios. In this paper, we introduce a novel\nimage-guided point cloud quality assessment algorithm for outdoor autonomous\ndriving environments, named the Image-Guided Outdoor Point Cloud Quality\nAssessment (IGO-PQA) algorithm. Our proposed algorithm comprises two main\ncomponents. The first component is the IGO-PQA generation algorithm, which\nleverages point cloud data, corresponding RGB surrounding view images, and\nagent objects' ground truth annotations to generate an overall quality score\nfor a single-frame LiDAR-based point cloud. The second component is a\ntransformer-based IGO-PQA regression algorithm for no-reference outdoor point\ncloud quality assessment. This regression algorithm allows for the direct\nprediction of IGO-PQA scores in an online manner, without requiring image data\nand object ground truth annotations. We evaluate our proposed algorithm using\nthe nuScenes and Waymo open datasets. The IGO-PQA generation algorithm provides\nconsistent and reasonable perception quality indices. Furthermore, our proposed\nIGO-PQA regression algorithm achieves a Pearson Linear Correlation Coefficient\n(PLCC) of 0.86 on the nuScenes dataset and 0.97 on the Waymo dataset.\n","authors":["Ce Zhang","Azim Eskandarian"],"pdf_url":"https://arxiv.org/pdf/2406.17265v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2401.09160v2","updated":"2024-06-25T04:15:03Z","published":"2024-01-17T12:08:30Z","title":"DK-SLAM: Monocular Visual SLAM with Deep Keypoint Learning, Tracking and\n  Loop-Closing","summary":"  The performance of visual SLAM in complex, real-world scenarios is often\ncompromised by unreliable feature extraction and matching when using\nhandcrafted features. Although deep learning-based local features excel at\ncapturing high-level information and perform well on matching benchmarks, they\nstruggle with generalization in continuous motion scenes, adversely affecting\nloop detection accuracy. Our system employs a Model-Agnostic Meta-Learning\n(MAML) strategy to optimize the training of keypoint extraction networks,\nenhancing their adaptability to diverse environments. Additionally, we\nintroduce a coarse-to-fine feature tracking mechanism for learned keypoints. It\nbegins with a direct method to approximate the relative pose between\nconsecutive frames, followed by a feature matching method for refined pose\nestimation. To mitigate cumulative positioning errors, DK-SLAM incorporates a\nnovel online learning module that utilizes binary features for loop closure\ndetection. This module dynamically identifies loop nodes within a sequence,\nensuring accurate and efficient localization. Experimental evaluations on\npublicly available datasets demonstrate that DK-SLAM outperforms leading\ntraditional and learning based SLAM systems, such as ORB-SLAM3 and LIFT-SLAM.\nThese results underscore the efficacy and robustness of our DK-SLAM in varied\nand challenging real-world environments.\n","authors":["Hao Qu","Lilian Zhang","Jun Mao","Junbo Tie","Xiaofeng He","Xiaoping Hu","Yifei Shi","Changhao Chen"],"pdf_url":"https://arxiv.org/pdf/2401.09160v2.pdf","comment":"In submission"},{"id":"http://arxiv.org/abs/2104.00921v3","updated":"2024-06-25T04:08:21Z","published":"2021-04-02T08:00:25Z","title":"AAformer: Auto-Aligned Transformer for Person Re-Identification","summary":"  In person re-identification (re-ID), extracting part-level features from\nperson images has been verified to be crucial to offer fine-grained\ninformation. Most of the existing CNN-based methods only locate the human parts\ncoarsely, or rely on pretrained human parsing models and fail in locating the\nidentifiable nonhuman parts (e.g., knapsack). In this article, we introduce an\nalignment scheme in transformer architecture for the first time and propose the\nauto-aligned transformer (AAformer) to automatically locate both the human\nparts and nonhuman ones at patch level. We introduce the \"Part tokens\n([PART]s)\", which are learnable vectors, to extract part features in the\ntransformer. A [PART] only interacts with a local subset of patches in\nself-attention and learns to be the part representation. To adaptively group\nthe image patches into different subsets, we design the auto-alignment.\nAuto-alignment employs a fast variant of optimal transport (OT) algorithm to\nonline cluster the patch embeddings into several groups with the [PART]s as\ntheir prototypes. AAformer integrates the part alignment into the\nself-attention and the output [PART]s can be directly used as part features for\nretrieval. Extensive experiments validate the effectiveness of [PART]s and the\nsuperiority of AAformer over various state-of-the-art methods.\n","authors":["Kuan Zhu","Haiyun Guo","Shiliang Zhang","Yaowei Wang","Jing Liu","Jinqiao Wang","Ming Tang"],"pdf_url":"https://arxiv.org/pdf/2104.00921v3.pdf","comment":"Accepted by TNNLS. IEEE Transactions on Neural Networks and Learning\n  Systems (2023)"},{"id":"http://arxiv.org/abs/2406.17256v1","updated":"2024-06-25T03:50:20Z","published":"2024-06-25T03:50:20Z","title":"Disentangled Motion Modeling for Video Frame Interpolation","summary":"  Video frame interpolation (VFI) aims to synthesize intermediate frames in\nbetween existing frames to enhance visual smoothness and quality. Beyond the\nconventional methods based on the reconstruction loss, recent works employ the\nhigh quality generative models for perceptual quality. However, they require\ncomplex training and large computational cost for modeling on the pixel space.\nIn this paper, we introduce disentangled Motion Modeling (MoMo), a\ndiffusion-based approach for VFI that enhances visual quality by focusing on\nintermediate motion modeling. We propose disentangled two-stage training\nprocess, initially training a frame synthesis model to generate frames from\ninput pairs and their optical flows. Subsequently, we propose a motion\ndiffusion model, equipped with our novel diffusion U-Net architecture designed\nfor optical flow, to produce bi-directional flows between frames. This method,\nby leveraging the simpler low-frequency representation of motions, achieves\nsuperior perceptual quality with reduced computational demands compared to\ngenerative modeling methods on the pixel space. Our method surpasses\nstate-of-the-art methods in perceptual metrics across various benchmarks,\ndemonstrating its efficacy and efficiency in VFI. Our code is available at:\nhttps://github.com/JHLew/MoMo\n","authors":["Jaihyun Lew","Jooyoung Choi","Chaehun Shin","Dahuin Jung","Sungroh Yoon"],"pdf_url":"https://arxiv.org/pdf/2406.17256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17254v1","updated":"2024-06-25T03:42:29Z","published":"2024-06-25T03:42:29Z","title":"Scalp Diagnostic System With Label-Free Segmentation and Training-Free\n  Image Translation","summary":"  Scalp diseases and alopecia affect millions of people around the world,\nunderscoring the urgent need for early diagnosis and management of the\ndisease.However, the development of a comprehensive AI-based diagnosis system\nencompassing these conditions remains an underexplored domain due to the\nchallenges associated with data imbalance and the costly nature of labeling. To\naddress these issues, we propose ``ScalpVision\", an AI-driven system for the\nholistic diagnosis of scalp diseases and alopecia.In ScalpVision, effective\nhair segmentation is achieved using pseudo image-label pairs and an innovative\nprompting method in the absence of traditional hair masking labels. This\napproach is crucial for extracting key features such as hair thickness and\ncount, which are then used to assess alopecia severity. Additionally,\nScalpVision introduces DiffuseIT-M, a generative model adept at dataset\naugmentation while maintaining hair information, facilitating improved\npredictions of scalp disease severity. Our experimental results affirm\nScalpVision's efficiency in diagnosing a variety of scalp conditions and\nalopecia, showcasing its potential as a valuable tool in dermatological care.\n","authors":["Youngmin Kim","Saejin Kim","Hoyeon Moon","Youngjae Yu","Junhyug Noh"],"pdf_url":"https://arxiv.org/pdf/2406.17254v1.pdf","comment":"IEEE Transactions on Medical Imaging (Under Review)"},{"id":"http://arxiv.org/abs/2403.07332v2","updated":"2024-06-25T03:37:26Z","published":"2024-03-12T05:34:51Z","title":"LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation","summary":"  In clinical practice, medical image segmentation provides useful information\non the contours and dimensions of target organs or tissues, facilitating\nimproved diagnosis, analysis, and treatment. In the past few years,\nconvolutional neural networks (CNNs) and Transformers have dominated this area,\nbut they still suffer from either limited receptive fields or costly long-range\nmodeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a\npromising paradigm for long-range dependency modeling with linear complexity.\nIn this paper, we introduce a Large Kernel Vision Mamba U-shape Network, or\nLKM-UNet, for medical image segmentation. A distinguishing feature of our\nLKM-UNet is its utilization of large Mamba kernels, excelling in locally\nspatial modeling compared to small kernel-based CNNs and Transformers, while\nmaintaining superior efficiency in global modeling compared to self-attention\nwith quadratic complexity. Additionally, we design a novel hierarchical and\nbidirectional Mamba block to further enhance Mamba's global and neighborhood\nspatial modeling capability for vision inputs. Comprehensive experiments\ndemonstrate the feasibility and the effectiveness of using large-size Mamba\nkernels to achieve large receptive fields. Codes are available at\nhttps://github.com/wjh892521292/LKM-UNet.\n","authors":["Jinhong Wang","Jintai Chen","Danny Chen","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2403.07332v2.pdf","comment":"Accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17250v1","updated":"2024-06-25T03:34:54Z","published":"2024-06-25T03:34:54Z","title":"A benchmark for 2D foetal brain ultrasound analysis","summary":"  Brain development involves a sequence of structural changes from early stages\nof the embryo until several months after birth. Currently, ultrasound is the\nestablished technique for screening due to its ability to acquire dynamic\nimages in real-time without radiation and to its cost-efficiency. However,\nidentifying abnormalities remains challenging due to the difficulty in\ninterpreting foetal brain images. In this work we present a set of 104 2D\nfoetal brain ultrasound images acquired during the 20th week of gestation that\nhave been co-registered to a common space from a rough skull segmentation. The\nimages are provided both on the original space and template space centred on\nthe ellipses of all the subjects. Furthermore, the images have been annotated\nto highlight landmark points from structures of interest to analyse brain\ndevelopment. Both the final atlas template with probabilistic maps and the\noriginal images can be used to develop new segmentation techniques, test\nregistration approaches for foetal brain ultrasound, extend our work to\nlongitudinal datasets and to detect anomalies in new images.\n","authors":["Mariano Cabezas","Yago Diez","Clara Martinez-Diago","Anna Maroto"],"pdf_url":"https://arxiv.org/pdf/2406.17250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15222v2","updated":"2024-06-25T03:17:22Z","published":"2024-06-14T02:15:09Z","title":"Rapid and Accurate Diagnosis of Acute Aortic Syndrome using Non-contrast\n  CT: A Large-scale, Retrospective, Multi-center and AI-based Study","summary":"  Chest pain symptoms are highly prevalent in emergency departments (EDs),\nwhere acute aortic syndrome (AAS) is a catastrophic cardiovascular emergency\nwith a high fatality rate, especially when timely and accurate treatment is not\nadministered. However, current triage practices in the ED can cause up to\napproximately half of patients with AAS to have an initially missed diagnosis\nor be misdiagnosed as having other acute chest pain conditions. Subsequently,\nthese AAS patients will undergo clinically inaccurate or suboptimal\ndifferential diagnosis. Fortunately, even under these suboptimal protocols,\nnearly all these patients underwent non-contrast CT covering the aorta anatomy\nat the early stage of differential diagnosis. In this study, we developed an\nartificial intelligence model (DeepAAS) using non-contrast CT, which is highly\naccurate for identifying AAS and provides interpretable results to assist in\nclinical decision-making. Performance was assessed in two major phases: a\nmulti-center retrospective study (n = 20,750) and an exploration in real-world\nemergency scenarios (n = 137,525). In the multi-center cohort, DeepAAS achieved\na mean area under the receiver operating characteristic curve of 0.958 (95% CI\n0.950-0.967). In the real-world cohort, DeepAAS detected 109 AAS patients with\nmisguided initial suspicion, achieving 92.6% (95% CI 76.2%-97.5%) in mean\nsensitivity and 99.2% (95% CI 99.1%-99.3%) in mean specificity. Our AI model\nperformed well on non-contrast CT at all applicable early stages of\ndifferential diagnosis workflows, effectively reduced the overall missed\ndiagnosis and misdiagnosis rate from 48.8% to 4.8% and shortened the diagnosis\ntime for patients with misguided initial suspicion from an average of 681.8\n(74-11,820) mins to 68.5 (23-195) mins. DeepAAS could effectively fill the gap\nin the current clinical workflow without requiring additional tests.\n","authors":["Yujian Hu","Yilang Xiang","Yan-Jie Zhou","Yangyan He","Shifeng Yang","Xiaolong Du","Chunlan Den","Youyao Xu","Gaofeng Wang","Zhengyao Ding","Jingyong Huang","Wenjun Zhao","Xuejun Wu","Donglin Li","Qianqian Zhu","Zhenjiang Li","Chenyang Qiu","Ziheng Wu","Yunjun He","Chen Tian","Yihui Qiu","Zuodong Lin","Xiaolong Zhang","Yuan He","Zhenpeng Yuan","Xiaoxiang Zhou","Rong Fan","Ruihan Chen","Wenchao Guo","Jianpeng Zhang","Tony C. W. Mok","Zi Li","Le Lu","Dehai Lang","Xiaoqiang Li","Guofu Wang","Wei Lu","Zhengxing Huang","Minfeng Xu","Hongkun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.15222v2.pdf","comment":"under peer review"},{"id":"http://arxiv.org/abs/2406.17238v1","updated":"2024-06-25T02:59:02Z","published":"2024-06-25T02:59:02Z","title":"Expansive Synthesis: Generating Large-Scale Datasets from Minimal\n  Samples","summary":"  The challenge of limited availability of data for training in machine\nlearning arises in many applications and the impact on performance and\ngeneralization is serious. Traditional data augmentation methods aim to enhance\ntraining with a moderately sufficient data set. Generative models like\nGenerative Adversarial Networks (GANs) often face problematic convergence when\ngenerating significant and diverse data samples. Diffusion models, though\neffective, still struggle with high computational cost and long training times.\nThis paper introduces an innovative Expansive Synthesis model that generates\nlarge-scale, high-fidelity datasets from minimal samples. The proposed approach\nexploits expander graph mappings and feature interpolation to synthesize\nexpanded datasets while preserving the intrinsic data distribution and feature\nstructural relationships. The rationale of the model is rooted in the\nnon-linear property of neural networks' latent space and in its capture by a\nKoopman operator to yield a linear space of features to facilitate the\nconstruction of larger and enriched consistent datasets starting with a much\nsmaller dataset. This process is optimized by an autoencoder architecture\nenhanced with self-attention layers and further refined for distributional\nconsistency by optimal transport. We validate our Expansive Synthesis by\ntraining classifiers on the generated datasets and comparing their performance\nto classifiers trained on larger, original datasets. Experimental results\ndemonstrate that classifiers trained on synthesized data achieve performance\nmetrics on par with those trained on full-scale datasets, showcasing the\nmodel's potential to effectively augment training data. This work represents a\nsignificant advancement in data generation, offering a robust solution to data\nscarcity and paving the way for enhanced data availability in machine learning\napplications.\n","authors":["Vahid Jebraeeli","Bo Jiang","Hamid Krim","Derya Cansever"],"pdf_url":"https://arxiv.org/pdf/2406.17238v1.pdf","comment":"14 pages. arXiv admin note: text overlap with arXiv:2405.13866"},{"id":"http://arxiv.org/abs/2406.17236v1","updated":"2024-06-25T02:56:16Z","published":"2024-06-25T02:56:16Z","title":"LIPE: Learning Personalized Identity Prior for Non-rigid Image Editing","summary":"  Although recent years have witnessed significant advancements in image\nediting thanks to the remarkable progress of text-to-image diffusion models,\nthe problem of non-rigid image editing still presents its complexities and\nchallenges. Existing methods often fail to achieve consistent results due to\nthe absence of unique identity characteristics. Thus, learning a personalized\nidentity prior might help with consistency in the edited results. In this\npaper, we explore a novel task: learning the personalized identity prior for\ntext-based non-rigid image editing. To address the problems in jointly learning\nprior and editing the image, we present LIPE, a two-stage framework designed to\ncustomize the generative model utilizing a limited set of images of the same\nsubject, and subsequently employ the model with learned prior for non-rigid\nimage editing. Experimental results demonstrate the advantages of our approach\nin various editing scenarios over past related leading methods in qualitative\nand quantitative ways.\n","authors":["Aoyang Liu","Qingnan Fan","Shuai Qin","Hong Gu","Yansong Tang"],"pdf_url":"https://arxiv.org/pdf/2406.17236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17235v1","updated":"2024-06-25T02:53:37Z","published":"2024-06-25T02:53:37Z","title":"Task-Agnostic Federated Learning","summary":"  In the realm of medical imaging, leveraging large-scale datasets from various\ninstitutions is crucial for developing precise deep learning models, yet\nprivacy concerns frequently impede data sharing. federated learning (FL)\nemerges as a prominent solution for preserving privacy while facilitating\ncollaborative learning. However, its application in real-world scenarios faces\nseveral obstacles, such as task & data heterogeneity, label scarcity,\nnon-identically distributed (non-IID) data, computational vaiation, etc. In\nreal-world, medical institutions may not want to disclose their tasks to FL\nserver and generalization challenge of out-of-network institutions with un-seen\ntask want to join the on-going federated system. This study address\ntask-agnostic and generalization problem on un-seen tasks by adapting\nself-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus\nfeature encoder for self-supervised pre-training, no initial labels required,\nthe framework enabling effective representation learning across diverse\ndatasets and tasks. Our extensive evaluations, using various real-world non-IID\nmedical imaging datasets, validate our approach's efficacy, retaining 90\\% of\nF1 accuracy with only 5\\% of the training data typically required for\ncentralized approaches and exhibiting superior adaptability to\nout-of-distribution task. The result indicate that federated learning\narchitecture can be a potential approach toward multi-task foundation modeling.\n","authors":["Zhengtao Yao","Hong Nguyen","Ajitesh Srivastava","Jose Luis Ambite"],"pdf_url":"https://arxiv.org/pdf/2406.17235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16620v2","updated":"2024-06-25T02:43:41Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14555v2","updated":"2024-06-25T02:43:06Z","published":"2024-01-25T22:50:39Z","title":"Revisiting Active Learning in the Era of Vision Foundation Models","summary":"  Foundation vision or vision-language models are trained on large unlabeled or\nnoisy data and learn robust representations that can achieve impressive zero-\nor few-shot performance on diverse tasks. Given these properties, they are a\nnatural fit for active learning (AL), which aims to maximize labeling\nefficiency. However, the full potential of foundation models has not been\nexplored in the context of AL, specifically in the low-budget regime. In this\nwork, we evaluate how foundation models influence three critical components of\neffective AL, namely, 1) initial labeled pool selection, 2) ensuring diverse\nsampling, and 3) the trade-off between representative and uncertainty sampling.\nWe systematically study how the robust representations of foundation models\n(DINOv2, OpenCLIP) challenge existing findings in active learning. Our\nobservations inform the principled construction of a new simple and elegant AL\nstrategy that balances uncertainty estimated via dropout with sample diversity.\nWe extensively test our strategy on many challenging image classification\nbenchmarks, including natural images as well as out-of-domain biomedical images\nthat are relatively understudied in the AL literature. We also provide a highly\nperformant and efficient implementation of modern AL strategies (including our\nmethod) at https://github.com/sanketx/AL-foundation-models.\n","authors":["Sanket Rajan Gupte","Josiah Aklilu","Jeffrey J. Nirschl","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2401.14555v2.pdf","comment":"Accepted to TMLR"},{"id":"http://arxiv.org/abs/2404.03876v3","updated":"2024-06-25T02:20:06Z","published":"2024-04-05T03:51:19Z","title":"Accurately Classifying Out-Of-Distribution Data in Facial Recognition","summary":"  Standard classification theory assumes that the distribution of images in the\ntest and training sets are identical. Unfortunately, real-life scenarios\ntypically feature unseen data (\"out-of-distribution data\") which is different\nfrom data in the training distribution(\"in-distribution\"). This issue is most\nprevalent in social justice problems where data from under-represented groups\nmay appear in the test data without representing an equal proportion of the\ntraining data. This may result in a model returning confidently wrong decisions\nand predictions. We are interested in the following question: Can the\nperformance of a neural network improve on facial images of out-of-distribution\ndata when it is trained simultaneously on multiple datasets of in-distribution\ndata? We approach this problem by incorporating the Outlier Exposure model and\ninvestigate how the model's performance changes when other datasets of facial\nimages were implemented. We observe that the accuracy and other metrics of the\nmodel can be increased by applying Outlier Exposure, incorporating a trainable\nweight parameter to increase the machine's emphasis on outlier images, and by\nre-weighting the importance of different class labels. We also experimented\nwith whether sorting the images and determining outliers via image features\nwould have more of an effect on the metrics than sorting by average pixel\nvalue. Our goal was to make models not only more accurate but also more fair by\nscanning a more expanded range of images. We also tested the datasets in\nreverse order to see whether a more fair dataset with balanced features has an\neffect on the model's accuracy.\n","authors":["Gianluca Barone","Aashrit Cunchala","Rudy Nunez"],"pdf_url":"https://arxiv.org/pdf/2404.03876v3.pdf","comment":"18 pages, 6 tables, 6 figures"},{"id":"http://arxiv.org/abs/2406.17225v1","updated":"2024-06-25T02:18:35Z","published":"2024-06-25T02:18:35Z","title":"Multimodal Cross-Task Interaction for Survival Analysis in Whole Slide\n  Pathological Images","summary":"  Survival prediction, utilizing pathological images and genomic profiles, is\nincreasingly important in cancer analysis and prognosis. Despite significant\nprogress, precise survival analysis still faces two main challenges: (1) The\nmassive pixels contained in whole slide images (WSIs) complicate the process of\npathological images, making it difficult to generate an effective\nrepresentation of the tumor microenvironment (TME). (2) Existing multimodal\nmethods often rely on alignment strategies to integrate complementary\ninformation, which may lead to information loss due to the inherent\nheterogeneity between pathology and genes. In this paper, we propose a\nMultimodal Cross-Task Interaction (MCTI) framework to explore the intrinsic\ncorrelations between subtype classification and survival analysis tasks.\nSpecifically, to capture TME-related features in WSIs, we leverage the subtype\nclassification task to mine tumor regions. Simultaneously, multi-head attention\nmechanisms are applied in genomic feature extraction, adaptively performing\ngenes grouping to obtain task-related genomic embedding. With the joint\nrepresentation of pathological images and genomic data, we further introduce a\nTransport-Guided Attention (TGA) module that uses optimal transport theory to\nmodel the correlation between subtype classification and survival analysis\ntasks, effectively transferring potential information. Extensive experiments\ndemonstrate the superiority of our approaches, with MCTI outperforming\nstate-of-the-art frameworks on three public benchmarks.\n\\href{https://github.com/jsh0792/MCTI}{https://github.com/jsh0792/MCTI}.\n","authors":["Songhan Jiang","Zhengyu Gan","Linghan Cai","Yifeng Wang","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17224v1","updated":"2024-06-25T02:18:15Z","published":"2024-06-25T02:18:15Z","title":"Large Language Models are Interpretable Learners","summary":"  The trade-off between expressiveness and interpretability remains a core\nchallenge when building human-centric predictive models for classification and\ndecision-making. While symbolic rules offer interpretability, they often lack\nexpressiveness, whereas neural networks excel in performance but are known for\nbeing black boxes. In this paper, we show a combination of Large Language\nModels (LLMs) and symbolic programs can bridge this gap. In the proposed\nLLM-based Symbolic Programs (LSPs), the pretrained LLM with natural language\nprompts provides a massive set of interpretable modules that can transform raw\ninput into natural language concepts. Symbolic programs then integrate these\nmodules into an interpretable decision rule. To train LSPs, we develop a\ndivide-and-conquer approach to incrementally build the program from scratch,\nwhere the learning process of each step is guided by LLMs. To evaluate the\neffectiveness of LSPs in extracting interpretable and accurate knowledge from\ndata, we introduce IL-Bench, a collection of diverse tasks, including both\nsynthetic and real-world scenarios across different modalities. Empirical\nresults demonstrate LSP's superior performance compared to traditional\nneurosymbolic programs and vanilla automatic prompt tuning methods. Moreover,\nas the knowledge learned by LSP is a combination of natural language\ndescriptions and symbolic rules, it is easily transferable to humans\n(interpretable), and other LLMs, and generalizes well to out-of-distribution\nsamples.\n","authors":["Ruochen Wang","Si Si","Felix Yu","Dorothea Wiesmann","Cho-Jui Hsieh","Inderjit Dhillon"],"pdf_url":"https://arxiv.org/pdf/2406.17224v1.pdf","comment":"Preliminary Version, Code at [this\n  url](https://github.com/ruocwang/llm-symbolic-program)"},{"id":"http://arxiv.org/abs/2406.16439v2","updated":"2024-06-25T02:16:47Z","published":"2024-06-24T08:30:03Z","title":"Exploring Test-Time Adaptation for Object Detection in Continually\n  Changing Environments","summary":"  For real-world applications, neural network models are commonly deployed in\ndynamic environments, where the distribution of the target domain undergoes\ntemporal changes. Continual Test-Time Adaptation (CTTA) has recently emerged as\na promising technique to gradually adapt a source-trained model to test data\ndrawn from a continually changing target domain. Despite recent advancements in\naddressing CTTA, two critical issues remain: 1) The use of a fixed threshold\nfor pseudo-labeling in existing methodologies leads to the generation of\nlow-quality pseudo-labels, as model confidence varies across categories and\ndomains; 2) While current solutions utilize stochastic parameter restoration to\nmitigate catastrophic forgetting, their capacity to preserve critical\ninformation is undermined by its intrinsic randomness. To tackle these\nchallenges, we present CTAOD, aiming to enhance the performance of detection\nmodels in CTTA scenarios. Inspired by prior CTTA works for effective\nadaptation, CTAOD is founded on the mean-teacher framework, characterized by\nthree core components. Firstly, the object-level contrastive learning module\ntailored for object detection extracts object-level features using the\nteacher's region of interest features and optimizes them through contrastive\nlearning. Secondly, the dynamic threshold strategy updates the\ncategory-specific threshold based on predicted confidence scores to improve the\nquality of pseudo-labels. Lastly, we design a data-driven stochastic\nrestoration mechanism to selectively reset inactive parameters using the\ngradients as weights for a random mask matrix, thereby ensuring the retention\nof essential knowledge. We demonstrate the effectiveness of our approach on\nfour CTTA tasks for object detection, where CTAOD outperforms existing methods,\nespecially achieving a 3.0 mAP improvement on the Cityscapes-to-Cityscapes-C\nCTTA task.\n","authors":["Shilei Cao","Yan Liu","Juepeng Zheng","Weijia Li","Runmin Dong","Haohuan Fu"],"pdf_url":"https://arxiv.org/pdf/2406.16439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09676v3","updated":"2024-06-25T02:16:41Z","published":"2023-07-18T23:06:47Z","title":"Domain Adaptation based Object Detection for Autonomous Driving in Foggy\n  and Rainy Weather","summary":"  Typically, object detection methods for autonomous driving that rely on\nsupervised learning make the assumption of a consistent feature distribution\nbetween the training and testing data, this such assumption may fail in\ndifferent weather conditions. Due to the domain gap, a detection model trained\nunder clear weather may not perform well in foggy and rainy conditions.\nOvercoming detection bottlenecks in foggy and rainy weather is a real challenge\nfor autonomous vehicles deployed in the wild. To bridge the domain gap and\nimprove the performance of object detection in foggy and rainy weather, this\npaper presents a novel framework for domain-adaptive object detection. The\nadaptations at both the image-level and object-level are intended to minimize\nthe differences in image style and object appearance between domains.\nFurthermore, in order to improve the model's performance on challenging\nexamples, we introduce a novel adversarial gradient reversal layer that\nconducts adversarial mining on difficult instances in addition to domain\nadaptation. Additionally, we suggest generating an auxiliary domain through\ndata augmentation to enforce a new domain-level metric regularization.\nExperimental findings on public V2V benchmark exhibit a substantial enhancement\nin object detection specifically for foggy and rainy driving scenarios.\n","authors":["Jinlong Li","Runsheng Xu","Xinyu Liu","Jin Ma","Baolu Li","Qin Zou","Jiaqi Ma","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2307.09676v3.pdf","comment":"the final version"},{"id":"http://arxiv.org/abs/2406.17219v1","updated":"2024-06-25T02:07:55Z","published":"2024-06-25T02:07:55Z","title":"Facial Identity Anonymization via Intrinsic and Extrinsic Attention\n  Distraction","summary":"  The unprecedented capture and application of face images raise increasing\nconcerns on anonymization to fight against privacy disclosure. Most existing\nmethods may suffer from the problem of excessive change of the\nidentity-independent information or insufficient identity protection. In this\npaper, we present a new face anonymization approach by distracting the\nintrinsic and extrinsic identity attentions. On the one hand, we anonymize the\nidentity information in the feature space by distracting the intrinsic identity\nattention. On the other, we anonymize the visual clues (i.e. appearance and\ngeometry structure) by distracting the extrinsic identity attention. Our\napproach allows for flexible and intuitive manipulation of face appearance and\ngeometry structure to produce diverse results, and it can also be used to\ninstruct users to perform personalized anonymization. We conduct extensive\nexperiments on multiple datasets and demonstrate that our approach outperforms\nstate-of-the-art methods.\n","authors":["Zhenzhong Kuang","Xiaochen Yang","Yingjie Shen","Chao Hu","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2406.17219v1.pdf","comment":"IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2024: 12406-12415"},{"id":"http://arxiv.org/abs/2406.03293v2","updated":"2024-06-25T02:04:29Z","published":"2024-06-05T14:02:31Z","title":"Text-to-Image Rectified Flow as Plug-and-Play Priors","summary":"  Large-scale diffusion models have achieved remarkable performance in\ngenerative tasks. Beyond their initial training applications, these models have\nproven their ability to function as versatile plug-and-play priors. For\ninstance, 2D diffusion models can serve as loss functions to optimize 3D\nimplicit models. Rectified flow, a novel class of generative models, enforces a\nlinear progression from the source to the target distribution and has\ndemonstrated superior performance across various domains. Compared to\ndiffusion-based methods, rectified flow approaches surpass in terms of\ngeneration quality and efficiency, requiring fewer inference steps. In this\nwork, we present theoretical and experimental evidence demonstrating that\nrectified flow based methods offer similar functionalities to diffusion models\n- they can also serve as effective priors. Besides the generative capabilities\nof diffusion priors, motivated by the unique time-symmetry properties of\nrectified flow models, a variant of our method can additionally perform image\ninversion. Experimentally, our rectified flow-based priors outperform their\ndiffusion counterparts - the SDS and VSD losses - in text-to-3D generation. Our\nmethod also displays competitive performance in image inversion and editing.\n","authors":["Xiaofeng Yang","Cheng Chen","Xulei Yang","Fayao Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2406.03293v2.pdf","comment":"Added results on Stable Diffusion 3. Code:\n  https://github.com/yangxiaofeng/rectified_flow_prior"},{"id":"http://arxiv.org/abs/2406.16360v2","updated":"2024-06-25T01:19:14Z","published":"2024-06-24T07:00:57Z","title":"MIRReS: Multi-bounce Inverse Rendering using Reservoir Sampling","summary":"  We present MIRReS, a novel two-stage inverse rendering framework that jointly\nreconstructs and optimizes the explicit geometry, material, and lighting from\nmulti-view images. Unlike previous methods that rely on implicit irradiance\nfields or simplified path tracing algorithms, our method extracts an explicit\ngeometry (triangular mesh) in stage one, and introduces a more realistic\nphysically-based inverse rendering model that utilizes multi-bounce path\ntracing and Monte Carlo integration. By leveraging multi-bounce path tracing,\nour method effectively estimates indirect illumination, including\nself-shadowing and internal reflections, which improves the intrinsic\ndecomposition of shape, material, and lighting. Moreover, we incorporate\nreservoir sampling into our framework to address the noise in Monte Carlo\nintegration, enhancing convergence and facilitating gradient-based optimization\nwith low sample counts. Through qualitative and quantitative evaluation of\nseveral scenarios, especially in challenging scenarios with complex shadows, we\ndemonstrate that our method achieves state-of-the-art performance on\ndecomposition results. Additionally, our optimized explicit geometry enables\napplications such as scene editing, relighting, and material editing with\nmodern graphics engines or CAD software. The source code is available at\nhttps://brabbitdousha.github.io/MIRReS/\n","authors":["Yuxin Dai","Qi Wang","Jingsen Zhu","Dianbing Xi","Yuchi Huo","Chen Qian","Ying He"],"pdf_url":"https://arxiv.org/pdf/2406.16360v2.pdf","comment":"16 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.15093v2","updated":"2024-06-25T01:07:15Z","published":"2024-06-21T12:14:24Z","title":"ECLIPSE: Expunging Clean-label Indiscriminate Poisons via Sparse\n  Diffusion Purification","summary":"  Clean-label indiscriminate poisoning attacks add invisible perturbations to\ncorrectly labeled training images, thus dramatically reducing the\ngeneralization capability of the victim models. Recently, some defense\nmechanisms have been proposed such as adversarial training, image\ntransformation techniques, and image purification. However, these schemes are\neither susceptible to adaptive attacks, built on unrealistic assumptions, or\nonly effective against specific poison types, limiting their universal\napplicability. In this research, we propose a more universally effective,\npractical, and robust defense scheme called ECLIPSE. We first investigate the\nimpact of Gaussian noise on the poisons and theoretically prove that any kind\nof poison will be largely assimilated when imposing sufficient random noise. In\nlight of this, we assume the victim has access to an extremely limited number\nof clean images (a more practical scene) and subsequently enlarge this sparse\nset for training a denoising probabilistic model (a universal denoising tool).\nWe then begin by introducing Gaussian noise to absorb the poisons and then\napply the model for denoising, resulting in a roughly purified dataset.\nFinally, to address the trade-off of the inconsistency in the assimilation\nsensitivity of different poisons by Gaussian noise, we propose a lightweight\ncorruption compensation module to effectively eliminate residual poisons,\nproviding a more universal defense approach. Extensive experiments demonstrate\nthat our defense approach outperforms 10 state-of-the-art defenses. We also\npropose an adaptive attack against ECLIPSE and verify the robustness of our\ndefense scheme. Our code is available at https://github.com/CGCL-codes/ECLIPSE.\n","authors":["Xianlong Wang","Shengshan Hu","Yechao Zhang","Ziqi Zhou","Leo Yu Zhang","Peng Xu","Wei Wan","Hai Jin"],"pdf_url":"https://arxiv.org/pdf/2406.15093v2.pdf","comment":"Accepted by ESORICS 2024"},{"id":"http://arxiv.org/abs/2209.11359v7","updated":"2024-06-25T23:35:36Z","published":"2022-09-23T01:09:06Z","title":"CUTS: A Deep Learning and Topological Framework for Multigranular\n  Unsupervised Medical Image Segmentation","summary":"  Segmenting medical images is critical to facilitating both patient diagnoses\nand quantitative research. A major limiting factor is the lack of labeled data,\nas obtaining expert annotations for each new set of imaging data and task can\nbe labor intensive and inconsistent among annotators. We present CUTS, an\nunsupervised deep learning framework for medical image segmentation. CUTS\noperates in two stages. For each image, it produces an embedding map via\nintra-image contrastive learning and local patch reconstruction. Then, these\nembeddings are partitioned at dynamic granularity levels that correspond to the\ndata topology. CUTS yields a series of coarse-to-fine-grained segmentations\nthat highlight features at various granularities. We applied CUTS to retinal\nfundus images and two types of brain MRI images to delineate structures and\npatterns at different scales. When evaluated against predefined anatomical\nmasks, CUTS improved the dice coefficient and Hausdorff distance by at least\n10% compared to existing unsupervised methods. Finally, CUTS showed performance\non par with Segment Anything Models (SAM, MedSAM, SAM-Med2D) pre-trained on\ngigantic labeled datasets.\n","authors":["Chen Liu","Matthew Amodio","Liangbo L. Shen","Feng Gao","Arman Avesta","Sanjay Aneja","Jay C. Wang","Lucian V. Del Priore","Smita Krishnaswamy"],"pdf_url":"https://arxiv.org/pdf/2209.11359v7.pdf","comment":"Accepted to the 27th International Conference on Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2024)"},{"id":"http://arxiv.org/abs/2406.17974v1","updated":"2024-06-25T23:11:39Z","published":"2024-06-25T23:11:39Z","title":"Evaluating Fairness in Large Vision-Language Models Across Diverse\n  Demographic Attributes and Prompts","summary":"  Large vision-language models (LVLMs) have recently achieved significant\nprogress, demonstrating strong capabilities in open-world visual understanding.\nHowever, it is not yet clear how LVLMs address demographic biases in real life,\nespecially the disparities across attributes such as gender, skin tone, and\nage. In this paper, we empirically investigate \\emph{visual fairness} in\nseveral mainstream LVLMs and audit their performance disparities across\nsensitive demographic attributes, based on public fairness benchmark datasets\n(e.g., FACET). To disclose the visual bias in LVLMs, we design a fairness\nevaluation framework with direct questions and single-choice\nquestion-instructed prompts on visual question-answering/classification tasks.\nThe zero-shot prompting results indicate that, despite enhancements in visual\nunderstanding, both open-source and closed-source LVLMs exhibit prevalent\nfairness issues across different instruct prompts and demographic attributes.\n","authors":["Xuyang Wu","Yuan Wang","Hsin-Tai Wu","Zhiqiang Tao","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2406.17974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17970v1","updated":"2024-06-25T23:03:48Z","published":"2024-06-25T23:03:48Z","title":"Highly Constrained Coded Aperture Imaging Systems Design Via a Knowledge\n  Distillation Approach","summary":"  Computational optical imaging (COI) systems have enabled the acquisition of\nhigh-dimensional signals through optical coding elements (OCEs). OCEs encode\nthe high-dimensional signal in one or more snapshots, which are subsequently\ndecoded using computational algorithms. Currently, COI systems are optimized\nthrough an end-to-end (E2E) approach, where the OCEs are modeled as a layer of\na neural network and the remaining layers perform a specific imaging task.\nHowever, the performance of COI systems optimized through E2E is limited by the\nphysical constraints imposed by these systems. This paper proposes a knowledge\ndistillation (KD) framework for the design of highly physically constrained COI\nsystems. This approach employs the KD methodology, which consists of a\nteacher-student relationship, where a high-performance, unconstrained COI\nsystem (the teacher), guides the optimization of a physically constrained\nsystem (the student) characterized by a limited number of snapshots. We\nvalidate the proposed approach, using a binary coded apertures single pixel\ncamera for monochromatic and multispectral image reconstruction. Simulation\nresults demonstrate the superiority of the KD scheme over traditional E2E\noptimization for the designing of highly physically constrained COI systems.\n","authors":["Leon Suarez-Rodriguez","Roman Jacome","Henry Arguello"],"pdf_url":"https://arxiv.org/pdf/2406.17970v1.pdf","comment":"7 pages, 3 figures. Accepted at ICIP 2024"},{"id":"http://arxiv.org/abs/2405.10244v2","updated":"2024-06-25T23:02:12Z","published":"2024-05-16T16:47:46Z","title":"Towards Task-Compatible Compressible Representations","summary":"  We identify an issue in multi-task learnable compression, in which a\nrepresentation learned for one task does not positively contribute to the\nrate-distortion performance of a different task as much as expected, given the\nestimated amount of information available in it. We interpret this issue using\nthe predictive $\\mathcal{V}$-information framework. In learnable scalable\ncoding, previous work increased the utilization of side-information for input\nreconstruction by also rewarding input reconstruction when learning this shared\nrepresentation. We evaluate the impact of this idea in the context of input\nreconstruction more rigorously and extended it to other computer vision tasks.\nWe perform experiments using representations trained for object detection on\nCOCO 2017 and depth estimation on the Cityscapes dataset, and use them to\nassist in image reconstruction and semantic segmentation tasks. The results\nshow considerable improvements in the rate-distortion performance of the\nassisted tasks. Moreover, using the proposed representations, the performance\nof the base tasks are also improved. Results suggest that the proposed method\ninduces simpler representations that are more compatible with downstream\nprocesses.\n","authors":["Anderson de Andrade","Ivan Bajić"],"pdf_url":"https://arxiv.org/pdf/2405.10244v2.pdf","comment":"To be published in ICME Workshops 2024"},{"id":"http://arxiv.org/abs/2402.19455v2","updated":"2024-06-25T22:43:54Z","published":"2024-02-29T18:50:11Z","title":"Listening to the Noise: Blind Denoising with Gibbs Diffusion","summary":"  In recent years, denoising problems have become intertwined with the\ndevelopment of deep generative models. In particular, diffusion models are\ntrained like denoisers, and the distribution they model coincide with denoising\npriors in the Bayesian picture. However, denoising through diffusion-based\nposterior sampling requires the noise level and covariance to be known,\npreventing blind denoising. We overcome this limitation by introducing Gibbs\nDiffusion (GDiff), a general methodology addressing posterior sampling of both\nthe signal and the noise parameters. Assuming arbitrary parametric Gaussian\nnoise, we develop a Gibbs algorithm that alternates sampling steps from a\nconditional diffusion model trained to map the signal prior to the family of\nnoise distributions, and a Monte Carlo sampler to infer the noise parameters.\nOur theoretical analysis highlights potential pitfalls, guides diagnostic\nusage, and quantifies errors in the Gibbs stationary distribution caused by the\ndiffusion model. We showcase our method for 1) blind denoising of natural\nimages involving colored noises with unknown amplitude and spectral index, and\n2) a cosmology problem, namely the analysis of cosmic microwave background\ndata, where Bayesian inference of \"noise\" parameters means constraining models\nof the evolution of the Universe.\n","authors":["David Heurtel-Depeiges","Charles C. Margossian","Ruben Ohana","Bruno Régaldo-Saint Blancard"],"pdf_url":"https://arxiv.org/pdf/2402.19455v2.pdf","comment":"12+9 pages, 7+5 figures, 1+1 tables; accepted to 2024 International\n  Conference on Machine Learning; code:\n  https://github.com/rubenohana/Gibbs-Diffusion"},{"id":"http://arxiv.org/abs/2311.16711v2","updated":"2024-06-25T22:33:57Z","published":"2023-11-28T11:45:35Z","title":"LEDITS++: Limitless Image Editing using Text-to-Image Models","summary":"  Text-to-image diffusion models have recently received increasing interest for\ntheir astonishing ability to produce high-fidelity images from solely text\ninputs. Subsequent research efforts aim to exploit and apply their capabilities\nto real image editing. However, existing image-to-image methods are often\ninefficient, imprecise, and of limited versatility. They either require\ntime-consuming finetuning, deviate unnecessarily strongly from the input image,\nand/or lack support for multiple, simultaneous edits. To address these issues,\nwe introduce LEDITS++, an efficient yet versatile and precise textual image\nmanipulation technique. LEDITS++'s novel inversion approach requires no tuning\nnor optimization and produces high-fidelity results with a few diffusion steps.\nSecond, our methodology supports multiple simultaneous edits and is\narchitecture-agnostic. Third, we use a novel implicit masking technique that\nlimits changes to relevant image regions. We propose the novel TEdBench++\nbenchmark as part of our exhaustive evaluation. Our results demonstrate the\ncapabilities of LEDITS++ and its improvements over previous methods.\n","authors":["Manuel Brack","Felix Friedrich","Katharina Kornmeier","Linoy Tsaban","Patrick Schramowski","Kristian Kersting","Apolinário Passos"],"pdf_url":"https://arxiv.org/pdf/2311.16711v2.pdf","comment":"Proceedings of the 2024 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) The project page is available at\n  https://leditsplusplus-project.static.hf.space"},{"id":"http://arxiv.org/abs/2406.17960v1","updated":"2024-06-25T22:33:41Z","published":"2024-06-25T22:33:41Z","title":"MAGIC: Meta-Ability Guided Interactive Chain-of-Distillation for\n  Effective-and-Efficient Vision-and-Language Navigation","summary":"  Despite the remarkable developments of recent large models in Embodied\nArtificial Intelligence (E-AI), their integration into robotics is hampered by\ntheir excessive parameter sizes and computational demands. Towards the\nVision-and-Language Navigation (VLN) task, a core task in E-AI, this paper\nreveals the great potential of using knowledge distillation for obtaining\nlightweight student models by proposing a Meta-Ability Guided Interactive\nChain-of-distillation (MAGIC) method. Specifically, a Meta-Ability Knowledge\nDistillation (MAKD) framework is proposed for decoupling and refining the\nnecessary meta-abilities of VLN agents. A Meta-Knowledge Randomization\nWeighting (MKRW) and a Meta-Knowledge Transferable Determination (MKTD) module\nare incorporated to dynamically adjust aggregation weights at the meta-ability\nand sample levels, respectively. Move beyond the traditional one-step\nunidirectional distillation, an Interactive Chain-of-Distillation (ICoD)\nlearning strategy is proposed to allow students to give feedback to teachers,\nforming a new multi-step teacher-student co-evolution pipeline. Remarkably, on\nthe R2R test unseen public leaderboard, our smallest model, MAGIC-S, with only\n5% (11M) of the teacher's size, outperforms all previous methods under the same\ntraining data. Additionally, our largest model, MAGIC-L, surpasses the previous\nstate-of-the-art by 5.84% in SPL and 3.18% in SR. Furthermore, a new dataset\nwas collected and annotated from our living environments, where MAGIC-S\ndemonstrated superior performance and real-time efficiency. Our code is\npublicly available on https://github.com/CrystalSixone/VLN-MAGIC.\n","authors":["Liuyi Wang","Zongtao He","Mengjiao Shen","Jingwei Yang","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02416v3","updated":"2024-06-25T22:21:17Z","published":"2024-01-04T18:59:25Z","title":"ODIN: A Single Model for 2D and 3D Segmentation","summary":"  State-of-the-art models on contemporary 3D segmentation benchmarks like\nScanNet consume and label dataset-provided 3D point clouds, obtained through\npost processing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website (https://odin-seg.github.io).\n","authors":["Ayush Jain","Pushkal Katara","Nikolaos Gkanatsios","Adam W. Harley","Gabriel Sarch","Kriti Aggarwal","Vishrav Chaudhary","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2401.02416v3.pdf","comment":"Camera Ready (CVPR 2024, Highlight)"},{"id":"http://arxiv.org/abs/2406.17936v1","updated":"2024-06-25T20:56:41Z","published":"2024-06-25T20:56:41Z","title":"Hot-Distance: Combining One-Hot and Signed Distance Embeddings for\n  Segmentation","summary":"  Machine learning models are only as good as the data to which they are fit.\nAs such, it is always preferable to use as much data as possible in training\nmodels. What data can be used for fitting a model depends a lot on the\nformulation of the task. We introduce Hot-Distance, a novel segmentation target\nthat incorporates the strength of signed boundary distance prediction with the\nflexibility of one-hot encoding, to increase the amount of usable training data\nfor segmentation of subcellular structures in focused ion beam scanning\nelectron microscopy (FIB-SEM).\n","authors":["Marwan Zouinkhi","Jeff L. Rhoades","Aubrey V. Weigel"],"pdf_url":"https://arxiv.org/pdf/2406.17936v1.pdf","comment":"3 pages, 1 figure, in progress"},{"id":"http://arxiv.org/abs/2406.17915v1","updated":"2024-06-25T19:56:12Z","published":"2024-06-25T19:56:12Z","title":"Semi-supervised classification of dental conditions in panoramic\n  radiographs using large language model and instance segmentation: A\n  real-world dataset evaluation","summary":"  Dental panoramic radiographs offer vast diagnostic opportunities, but\ntraining supervised deep learning networks for automatic analysis of those\nradiology images is hampered by a shortage of labeled data. Here, a different\nperspective on this problem is introduced. A semi-supervised learning framework\nis proposed to classify thirteen dental conditions on panoramic radiographs,\nwith a particular emphasis on teeth. Large language models were explored to\nannotate the most common dental conditions based on dental reports.\nAdditionally, a masked autoencoder was employed to pre-train the classification\nneural network, and a Vision Transformer was used to leverage the unlabeled\ndata. The analyses were validated using two of the most extensive datasets in\nthe literature, comprising 8,795 panoramic radiographs and 8,029 paired reports\nand images. Encouragingly, the results consistently met or surpassed the\nbaseline metrics for the Matthews correlation coefficient. A comparison of the\nproposed solution with human practitioners, supported by statistical analysis,\nhighlighted its effectiveness and performance limitations; based on the degree\nof agreement among specialists, the solution demonstrated an accuracy level\ncomparable to that of a junior specialist.\n","authors":["Bernardo Silva","Jefferson Fontinele","Carolina Letícia Zilli Vieira","João Manuel R. S. Tavares","Patricia Ramos Cury","Luciano Oliveira"],"pdf_url":"https://arxiv.org/pdf/2406.17915v1.pdf","comment":"43 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2406.17908v1","updated":"2024-06-25T19:43:49Z","published":"2024-06-25T19:43:49Z","title":"DeepSense-V2V: A Vehicle-to-Vehicle Multi-Modal Sensing, Localization,\n  and Communications Dataset","summary":"  High data rate and low-latency vehicle-to-vehicle (V2V) communication are\nessential for future intelligent transport systems to enable coordination,\nenhance safety, and support distributed computing and intelligence\nrequirements. Developing effective communication strategies, however, demands\nrealistic test scenarios and datasets. This is important at the high-frequency\nbands where more spectrum is available, yet harvesting this bandwidth is\nchallenged by the need for direction transmission and the sensitivity of signal\npropagation to blockages. This work presents the first large-scale multi-modal\ndataset for studying mmWave vehicle-to-vehicle communications. It presents a\ntwo-vehicle testbed that comprises data from a 360-degree camera, four radars,\nfour 60 GHz phased arrays, a 3D lidar, and two precise GPSs. The dataset\ncontains vehicles driving during the day and night for 120 km in intercity and\nrural settings, with speeds up to 100 km per hour. More than one million\nobjects were detected across all images, from trucks to bicycles. This work\nfurther includes detailed dataset statistics that prove the coverage of various\nsituations and highlights how this dataset can enable novel machine-learning\napplications.\n","authors":["Joao Morais","Gouranga Charan","Nikhil Srinivas","Ahmed Alkhateeb"],"pdf_url":"https://arxiv.org/pdf/2406.17908v1.pdf","comment":"14 pages, 15 figures, 2 tables. The dataset is available on the\n  DeepSense6G website: https://deepsense6g.net/"},{"id":"http://arxiv.org/abs/2405.16343v2","updated":"2024-06-25T19:35:10Z","published":"2024-05-25T20:00:27Z","title":"Learning Point Spread Function Invertibility Assessment for Image\n  Deconvolution","summary":"  Deep-learning (DL)-based image deconvolution (ID) has exhibited remarkable\nrecovery performance, surpassing traditional linear methods. However, unlike\ntraditional ID approaches that rely on analytical properties of the point\nspread function (PSF) to achieve high recovery performance - such as specific\nspectrum properties or small conditional numbers in the convolution matrix - DL\ntechniques lack quantifiable metrics for evaluating PSF suitability for\nDL-assisted recovery. Aiming to enhance deconvolution quality, we propose a\nmetric that employs a non-linear approach to learn the invertibility of an\narbitrary PSF using a neural network by mapping it to a unit impulse. A lower\ndiscrepancy between the mapped PSF and a unit impulse indicates a higher\nlikelihood of successful inversion by a DL network. Our findings reveal that\nthis metric correlates with high recovery performance in DL and traditional\nmethods, thereby serving as an effective regularizer in deconvolution tasks.\nThis approach reduces the computational complexity over conventional condition\nnumber assessments and is a differentiable process. These useful properties\nallow its application in designing diffractive optical elements through\nend-to-end (E2E) optimization, achieving invertible PSFs, and outperforming the\nE2E baseline framework.\n","authors":["Romario Gualdrón-Hurtado","Roman Jacome","Sergio Urrea","Henry Arguello","Luis Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2405.16343v2.pdf","comment":"Accepted at EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2406.17902v1","updated":"2024-06-25T19:26:39Z","published":"2024-06-25T19:26:39Z","title":"Domain Adaptation of Echocardiography Segmentation Via Reinforcement\n  Learning","summary":"  Performance of deep learning segmentation models is significantly challenged\nin its transferability across different medical imaging domains, particularly\nwhen aiming to adapt these models to a target domain with insufficient\nannotated data for effective fine-tuning. While existing domain adaptation (DA)\nmethods propose strategies to alleviate this problem, these methods do not\nexplicitly incorporate human-verified segmentation priors, compromising the\npotential of a model to produce anatomically plausible segmentations. We\nintroduce RL4Seg, an innovative reinforcement learning framework that reduces\nthe need to otherwise incorporate large expertly annotated datasets in the\ntarget domain, and eliminates the need for lengthy manual human review. Using a\ntarget dataset of 10,000 unannotated 2D echocardiographic images, RL4Seg not\nonly outperforms existing state-of-the-art DA methods in accuracy but also\nachieves 99% anatomical validity on a subset of 220 expert-validated subjects\nfrom the target domain. Furthermore, our framework's reward network offers\nuncertainty estimates comparable with dedicated state-of-the-art uncertainty\nmethods, demonstrating the utility and effectiveness of RL4Seg in overcoming\ndomain adaptation challenges in medical image segmentation.\n","authors":["Arnaud Judge","Thierry Judge","Nicolas Duchateau","Roman A. Sandler","Joseph Z. Sokol","Olivier Bernard","Pierre-Marc Jodoin"],"pdf_url":"https://arxiv.org/pdf/2406.17902v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.17899v1","updated":"2024-06-25T19:20:10Z","published":"2024-06-25T19:20:10Z","title":"Entity Augmentation for Efficient Classification of Vertically\n  Partitioned Data with Limited Overlap","summary":"  Vertical Federated Learning (VFL) is a machine learning paradigm for learning\nfrom vertically partitioned data (i.e. features for each input are distributed\nacross multiple \"guest\" clients and an aggregating \"host\" server owns labels)\nwithout communicating raw data. Traditionally, VFL involves an \"entity\nresolution\" phase where the host identifies and serializes the unique entities\nknown to all guests. This is followed by private set intersection to find\ncommon entities, and an \"entity alignment\" step to ensure all guests are always\nprocessing the same entity's data. However, using only data of entities from\nthe intersection means guests discard potentially useful data. Besides, the\neffect on privacy is dubious and these operations are computationally\nexpensive. We propose a novel approach that eliminates the need for set\nintersection and entity alignment in categorical tasks. Our Entity Augmentation\ntechnique generates meaningful labels for activations sent to the host,\nregardless of their originating entity, enabling efficient VFL without explicit\nentity alignment. With limited overlap between training data, this approach\nperforms substantially better (e.g. with 5% overlap, 48.1% vs 69.48% test\naccuracy on CIFAR-10). In fact, thanks to the regularizing effect, our model\nperforms marginally better even with 100% overlap.\n","authors":["Avi Amalanshu","Viswesh Nagaswamy","G. V. S. S. Prudhvi","Yash Sirvi","Debashish Chakravarty"],"pdf_url":"https://arxiv.org/pdf/2406.17899v1.pdf","comment":"GLOW @ IJCAI 2024 (12 pages + 2 page bibliography. 15 figures.)"},{"id":"http://arxiv.org/abs/2405.15636v2","updated":"2024-06-25T19:05:11Z","published":"2024-05-24T15:22:58Z","title":"Visualize and Paint GAN Activations","summary":"  We investigate how generated structures of GANs correlate with their\nactivations in hidden layers, with the purpose of better understanding the\ninner workings of those models and being able to paint structures with\nunconditionally trained GANs. This gives us more control over the generated\nimages, allowing to generate them from a semantic segmentation map while not\nrequiring such a segmentation in the training data. To this end we introduce\nthe concept of tileable features, allowing us to identify activations that work\nwell for painting.\n","authors":["Rudolf Herdt","Peter Maass"],"pdf_url":"https://arxiv.org/pdf/2405.15636v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18451v3","updated":"2024-06-25T19:04:56Z","published":"2024-02-28T16:24:08Z","title":"MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image\n  Reconstruction and Uncertainty Estimation","summary":"  The recent Mamba model has shown remarkable adaptability for visual\nrepresentation learning, including in medical imaging tasks. This study\nintroduces MambaMIR, a Mamba-based model for medical image reconstruction, as\nwell as its Generative Adversarial Network-based variant, MambaMIR-GAN. Our\nproposed MambaMIR inherits several advantages, such as linear complexity,\nglobal receptive fields, and dynamic weights, from the original Mamba model.\nThe innovated arbitrary-mask mechanism effectively adapt Mamba to our image\nreconstruction task, providing randomness for subsequent Monte Carlo-based\nuncertainty estimation. Experiments conducted on various medical image\nreconstruction tasks, including fast MRI and SVCT, which cover anatomical\nregions such as the knee, chest, and abdomen, have demonstrated that MambaMIR\nand MambaMIR-GAN achieve comparable or superior reconstruction results relative\nto state-of-the-art methods. Additionally, the estimated uncertainty maps offer\nfurther insights into the reliability of the reconstruction quality. The code\nis publicly available at https://github.com/ayanglab/MambaMIR.\n","authors":["Jiahao Huang","Liutao Yang","Fanwen Wang","Yang Nan","Angelica I. Aviles-Rivero","Carola-Bibiane Schönlieb","Daoqiang Zhang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2402.18451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17659v2","updated":"2024-06-25T19:01:09Z","published":"2024-05-27T21:04:43Z","title":"Enhancing Global Sensitivity and Uncertainty Quantification in Medical\n  Image Reconstruction with Monte Carlo Arbitrary-Masked Mamba","summary":"  Deep learning has been extensively applied in medical image reconstruction,\nwhere Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs)\nrepresent the predominant paradigms, each possessing distinct advantages and\ninherent limitations: CNNs exhibit linear complexity with local sensitivity,\nwhereas ViTs demonstrate quadratic complexity with global sensitivity. The\nemerging Mamba has shown superiority in learning visual representation, which\ncombines the advantages of linear scalability and global sensitivity. In this\nstudy, we introduce MambaMIR, an Arbitrary-Masked Mamba-based model with\nwavelet decomposition for joint medical image reconstruction and uncertainty\nestimation. A novel Arbitrary Scan Masking (ASM) mechanism \"masks out\"\nredundant information to introduce randomness for further uncertainty\nestimation. Compared to the commonly used Monte Carlo (MC) dropout, our\nproposed MC-ASM provides an uncertainty map without the need for hyperparameter\ntuning and mitigates the performance drop typically observed when applying\ndropout to low-level tasks. For further texture preservation and better\nperceptual quality, we employ the wavelet transformation into MambaMIR and\nexplore its variant based on the Generative Adversarial Network, namely\nMambaMIR-GAN. Comprehensive experiments have been conducted for multiple\nrepresentative medical image reconstruction tasks, demonstrating that the\nproposed MambaMIR and MambaMIR-GAN outperform other baseline and\nstate-of-the-art methods in different reconstruction tasks, where MambaMIR\nachieves the best reconstruction fidelity and MambaMIR-GAN has the best\nperceptual quality. In addition, our MC-ASM provides uncertainty maps as an\nadditional tool for clinicians, while mitigating the typical performance drop\ncaused by the commonly used dropout.\n","authors":["Jiahao Huang","Liutao Yang","Fanwen Wang","Yang Nan","Weiwen Wu","Chengyan Wang","Kuangyu Shi","Angelica I. Aviles-Rivero","Carola-Bibiane Schönlieb","Daoqiang Zhang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2405.17659v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17880v1","updated":"2024-06-25T18:39:43Z","published":"2024-06-25T18:39:43Z","title":"MLLM as Video Narrator: Mitigating Modality Imbalance in Video Moment\n  Retrieval","summary":"  Video Moment Retrieval (VMR) aims to localize a specific temporal segment\nwithin an untrimmed long video given a natural language query. Existing methods\noften suffer from inadequate training annotations, i.e., the sentence typically\nmatches with a fraction of the prominent video content in the foreground with\nlimited wording diversity. This intrinsic modality imbalance leaves a\nconsiderable portion of visual information remaining unaligned with text. It\nconfines the cross-modal alignment knowledge within the scope of a limited text\ncorpus, thereby leading to sub-optimal visual-textual modeling and poor\ngeneralizability. By leveraging the visual-textual understanding capability of\nmulti-modal large language models (MLLM), in this work, we take an MLLM as a\nvideo narrator to generate plausible textual descriptions of the video, thereby\nmitigating the modality imbalance and boosting the temporal localization. To\neffectively maintain temporal sensibility for localization, we design to get\ntext narratives for each certain video timestamp and construct a structured\ntext paragraph with time information, which is temporally aligned with the\nvisual content. Then we perform cross-modal feature merging between the\ntemporal-aware narratives and corresponding video temporal features to produce\nsemantic-enhanced video representation sequences for query localization.\nSubsequently, we introduce a uni-modal narrative-query matching mechanism,\nwhich encourages the model to extract complementary information from contextual\ncohesive descriptions for improved retrieval. Extensive experiments on two\nbenchmarks show the effectiveness and generalizability of our proposed method.\n","authors":["Weitong Cai","Jiabo Huang","Shaogang Gong","Hailin Jin","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17880v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.17876v1","updated":"2024-06-25T18:35:13Z","published":"2024-06-25T18:35:13Z","title":"ET tu, CLIP? Addressing Common Object Errors for Unseen Environments","summary":"  We introduce a simple method that employs pre-trained CLIP encoders to\nenhance model generalization in the ALFRED task. In contrast to previous\nliterature where CLIP replaces the visual encoder, we suggest using CLIP as an\nadditional module through an auxiliary object detection objective. We validate\nour method on the recently proposed Episodic Transformer architecture and\ndemonstrate that incorporating CLIP improves task performance on the unseen\nvalidation set. Additionally, our analysis results support that CLIP especially\nhelps with leveraging object descriptions, detecting small objects, and\ninterpreting rare words.\n","authors":["Ye Won Byun","Cathy Jiao","Shahriar Noroozizadeh","Jimin Sun","Rosa Vitiello"],"pdf_url":"https://arxiv.org/pdf/2406.17876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15104v2","updated":"2024-06-25T18:21:17Z","published":"2024-06-21T12:45:07Z","title":"Deciphering the Definition of Adversarial Robustness for post-hoc OOD\n  Detectors","summary":"  Detecting out-of-distribution (OOD) inputs is critical for safely deploying\ndeep learning models in real-world scenarios. In recent years, many OOD\ndetectors have been developed, and even the benchmarking has been standardized,\ni.e. OpenOOD. The number of post-hoc detectors is growing fast and showing an\noption to protect a pre-trained classifier against natural distribution shifts,\nclaiming to be ready for real-world scenarios. However, its efficacy in\nhandling adversarial examples has been neglected in the majority of studies.\nThis paper investigates the adversarial robustness of the 16 post-hoc detectors\non several evasion attacks and discuss a roadmap towards adversarial defense in\nOOD detectors.\n","authors":["Peter Lorenz","Mario Fernandez","Jens Müller","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2406.15104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16549v3","updated":"2024-06-25T18:20:40Z","published":"2024-01-29T20:37:03Z","title":"Deep Learning for Multi-Label Learning: A Comprehensive Survey","summary":"  Multi-label learning is a rapidly growing research area that aims to predict\nmultiple labels from a single input data point. In the era of big data, tasks\ninvolving multi-label classification (MLC) or ranking present significant and\nintricate challenges, capturing considerable attention in diverse domains.\nInherent difficulties in MLC include dealing with high-dimensional data,\naddressing label correlations, and handling partial labels, for which\nconventional methods prove ineffective. Recent years have witnessed a notable\nincrease in adopting deep learning (DL) techniques to address these challenges\nmore effectively in MLC. Notably, there is a burgeoning effort to harness the\nrobust learning capabilities of DL for improved modelling of label dependencies\nand other challenges in MLC. However, it is noteworthy that comprehensive\nstudies specifically dedicated to DL for multi-label learning are limited.\nThus, this survey aims to thoroughly review recent progress in DL for\nmulti-label learning, along with a summary of open research problems in MLC.\nThe review consolidates existing research efforts in DL for MLC,including deep\nneural networks, transformers, autoencoders, and convolutional and recurrent\narchitectures. Finally, the study presents a comparative analysis of the\nexisting methods to provide insightful observations and stimulate future\nresearch directions in this domain.\n","authors":["Adane Nega Tarekegn","Mohib Ullah","Faouzi Alaya Cheikh"],"pdf_url":"https://arxiv.org/pdf/2401.16549v3.pdf","comment":"20 pages, 5 tables"},{"id":"http://arxiv.org/abs/2406.17869v1","updated":"2024-06-25T18:16:25Z","published":"2024-06-25T18:16:25Z","title":"Burst Image Super-Resolution with Base Frame Selection","summary":"  Burst image super-resolution has been a topic of active research in recent\nyears due to its ability to obtain a high-resolution image by using\ncomplementary information between multiple frames in the burst. In this work,\nwe explore using burst shots with non-uniform exposures to confront real-world\npractical scenarios by introducing a new benchmark dataset, dubbed\nNon-uniformly Exposed Burst Image (NEBI), that includes the burst frames at\nvarying exposure times to obtain a broader range of irradiance and motion\ncharacteristics within a scene. As burst shots with non-uniform exposures\nexhibit varying levels of degradation, fusing information of the burst shots\ninto the first frame as a base frame may not result in optimal image quality.\nTo address this limitation, we propose a Frame Selection Network (FSN) for\nnon-uniform scenarios. This network seamlessly integrates into existing\nsuper-resolution methods in a plug-and-play manner with low computational\ncosts. The comparative analysis reveals the effectiveness of the nonuniform\nsetting for the practical scenario and our FSN on synthetic-/real- NEBI\ndatasets.\n","authors":["Sanghyun Kim","Min Jung Lee","Woohyeok Kim","Deunsol Jung","Jaesung Rim","Sunghyun Cho","Minsu Cho"],"pdf_url":"https://arxiv.org/pdf/2406.17869v1.pdf","comment":"CVPR2024W NTIRE accepted"},{"id":"http://arxiv.org/abs/2406.01274v2","updated":"2024-06-25T18:10:15Z","published":"2024-06-03T12:40:30Z","title":"Expected Grad-CAM: Towards gradient faithfulness","summary":"  Although input-gradients techniques have evolved to mitigate and tackle the\nchallenges associated with gradients, modern gradient-weighted CAM approaches\nstill rely on vanilla gradients, which are inherently susceptible to the\nsaturation phenomena. Despite recent enhancements have incorporated\ncounterfactual gradient strategies as a mitigating measure, these local\nexplanation techniques still exhibit a lack of sensitivity to their baseline\nparameter. Our work proposes a gradient-weighted CAM augmentation that tackles\nboth the saturation and sensitivity problem by reshaping the gradient\ncomputation, incorporating two well-established and provably approaches:\nExpected Gradients and kernel smoothing. By revisiting the original formulation\nas the smoothed expectation of the perturbed integrated gradients, one can\nconcurrently construct more faithful, localized and robust explanations which\nminimize infidelity. Through fine modulation of the perturbation distribution\nit is possible to regulate the complexity characteristic of the explanation,\nselectively discriminating stable features. Our technique, Expected Grad-CAM,\ndifferently from recent works, exclusively optimizes the gradient computation,\npurposefully designed as an enhanced substitute of the foundational Grad-CAM\nalgorithm and any method built therefrom. Quantitative and qualitative\nevaluations have been conducted to assess the effectiveness of our method.\n","authors":["Vincenzo Buono","Peyman Sheikholharam Mashhadi","Mahmoud Rahat","Prayag Tiwari","Stefan Byttner"],"pdf_url":"https://arxiv.org/pdf/2406.01274v2.pdf","comment":"Updated appendix figures to vector format for improved clarity"},{"id":"http://arxiv.org/abs/2406.17858v1","updated":"2024-06-25T18:02:11Z","published":"2024-06-25T18:02:11Z","title":"Depth-Driven Geometric Prompt Learning for Laparoscopic Liver Landmark\n  Detection","summary":"  Laparoscopic liver surgery poses a complex intraoperative dynamic environment\nfor surgeons, where remains a significant challenge to distinguish critical or\neven hidden structures inside the liver. Liver anatomical landmarks, e.g.,\nridge and ligament, serve as important markers for 2D-3D alignment, which can\nsignificantly enhance the spatial perception of surgeons for precise surgery.\nTo facilitate the detection of laparoscopic liver landmarks, we collect a novel\ndataset called L3D, which comprises 1,152 frames with elaborated landmark\nannotations from surgical videos of 39 patients across two medical sites. For\nbenchmarking purposes, 12 mainstream detection methods are selected and\ncomprehensively evaluated on L3D. Further, we propose a depth-driven geometric\nprompt learning network, namely D2GPLand. Specifically, we design a Depth-aware\nPrompt Embedding (DPE) module that is guided by self-supervised prompts and\ngenerates semantically relevant geometric information with the benefit of\nglobal depth cues extracted from SAM-based features. Additionally, a\nSemantic-specific Geometric Augmentation (SGA) scheme is introduced to\nefficiently merge RGB-D spatial and geometric information through reverse\nanatomic perception. The experimental results indicate that D2GPLand obtains\nstate-of-the-art performance on L3D, with 63.52% DICE and 48.68% IoU scores.\nTogether with 2D-3D fusion technology, our method can directly provide the\nsurgeon with intuitive guidance information in laparoscopic scenarios.\n","authors":["Jialun Pei","Ruize Cui","Yaoqian Li","Weixin Si","Jing Qin","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.17858v1.pdf","comment":"This paper has been accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17840v1","updated":"2024-06-25T17:46:28Z","published":"2024-06-25T17:46:28Z","title":"Human-Object Interaction from Human-Level Instructions","summary":"  Intelligent agents need to autonomously navigate and interact within\ncontextual environments to perform a wide range of daily tasks based on\nhuman-level instructions. These agents require a foundational understanding of\nthe world, incorporating common sense and knowledge, to interpret such\ninstructions. Moreover, they must possess precise low-level skills for movement\nand interaction to execute the detailed task plans derived from these\ninstructions. In this work, we address the task of synthesizing continuous\nhuman-object interactions for manipulating large objects within contextual\nenvironments, guided by human-level instructions. Our goal is to generate\nsynchronized object motion, full-body human motion, and detailed finger motion,\nall essential for realistic interactions. Our framework consists of a large\nlanguage model (LLM) planning module and a low-level motion generator. We use\nLLMs to deduce spatial object relationships and devise a method for accurately\ndetermining their positions and orientations in target scene layouts.\nAdditionally, the LLM planner outlines a detailed task plan specifying a\nsequence of sub-tasks. This task plan, along with the target object poses,\nserves as input for our low-level motion generator, which seamlessly alternates\nbetween navigation and interaction modules. We present the first complete\nsystem that can synthesize object motion, full-body motion, and finger motion\nsimultaneously from human-level instructions. Our experiments demonstrate the\neffectiveness of our high-level planner in generating plausible target layouts\nand our low-level motion generator in synthesizing realistic interactions for\ndiverse objects. Please refer to our project page for more results:\nhttps://hoifhli.github.io/.\n","authors":["Zhen Wu","Jiaman Li","C. Karen Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17840v1.pdf","comment":"10 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2406.17768v1","updated":"2024-06-25T17:50:03Z","published":"2024-06-25T17:50:03Z","title":"EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot\n  Skills from Offline Data","summary":"  Most reinforcement learning (RL) methods focus on learning optimal policies\nover low-level action spaces. While these methods can perform well in their\ntraining environments, they lack the flexibility to transfer to new tasks.\nInstead, RL agents that can act over useful, temporally extended skills rather\nthan low-level actions can learn new tasks more easily. Prior work in\nskill-based RL either requires expert supervision to define useful skills,\nwhich is hard to scale, or learns a skill-space from offline data with\nheuristics that limit the adaptability of the skills, making them difficult to\ntransfer during downstream RL. Our approach, EXTRACT, instead utilizes\npre-trained vision language models to extract a discrete set of semantically\nmeaningful skills from offline data, each of which is parameterized by\ncontinuous arguments, without human supervision. This skill parameterization\nallows robots to learn new tasks by only needing to learn when to select a\nspecific skill and how to modify its arguments for the specific task. We\ndemonstrate through experiments in sparse-reward, image-based, robot\nmanipulation environments that EXTRACT can more quickly learn new tasks than\nprior works, with major gains in sample efficiency and performance over prior\nskill-based RL. Website at https://www.jessezhang.net/projects/extract/.\n","authors":["Jesse Zhang","Minho Heo","Zuxin Liu","Erdem Biyik","Joseph J Lim","Yao Liu","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2406.17768v1.pdf","comment":"22 pages, 13 figures"},{"id":"http://arxiv.org/abs/2206.08101v3","updated":"2024-06-25T17:49:35Z","published":"2022-06-16T11:44:11Z","title":"Towards Diverse Evaluation of Class Incremental Learning: A\n  Representation Learning Perspective","summary":"  Class incremental learning (CIL) algorithms aim to continually learn new\nobject classes from incrementally arriving data while not forgetting past\nlearned classes. The common evaluation protocol for CIL algorithms is to\nmeasure the average test accuracy across all classes learned so far -- however,\nwe argue that solely focusing on maximizing the test accuracy may not\nnecessarily lead to developing a CIL algorithm that also continually learns and\nupdates the representations, which may be transferred to the downstream tasks.\nTo that end, we experimentally analyze neural network models trained by CIL\nalgorithms using various evaluation protocols in representation learning and\npropose new analysis methods. Our experiments show that most state-of-the-art\nalgorithms prioritize high stability and do not significantly change the\nlearned representation, and sometimes even learn a representation of lower\nquality than a naive baseline. However, we observe that these algorithms can\nstill achieve high test accuracy because they enable a model to learn a\nclassifier that closely resembles an estimated linear classifier trained for\nlinear probing. Furthermore, the base model learned in the first task, which\ninvolves single-task learning, exhibits varying levels of representation\nquality across different algorithms, and this variance impacts the final\nperformance of CIL algorithms. Therefore, we suggest that the\nrepresentation-level evaluation should be considered as an additional recipe\nfor more diverse evaluation for CIL algorithms.\n","authors":["Sungmin Cha","Jihwan Kwak","Dongsub Shim","Hyunwoo Kim","Moontae Lee","Honglak Lee","Taesup Moon"],"pdf_url":"https://arxiv.org/pdf/2206.08101v3.pdf","comment":"CoLLAs 2024 camera-ready version"},{"id":"http://arxiv.org/abs/2406.17763v1","updated":"2024-06-25T17:48:24Z","published":"2024-06-25T17:48:24Z","title":"DiffusionPDE: Generative PDE-Solving Under Partial Observation","summary":"  We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.\n","authors":["Jiahe Huang","Guandao Yang","Zichen Wang","Jeong Joon Park"],"pdf_url":"https://arxiv.org/pdf/2406.17763v1.pdf","comment":"Project page: https://jhhuangchloe.github.io/Diffusion-PDE/"},{"id":"http://arxiv.org/abs/2406.17762v1","updated":"2024-06-25T17:47:13Z","published":"2024-06-25T17:47:13Z","title":"Solving Hard Mizar Problems with Instantiation and Strategy Invention","summary":"  In this work, we prove over 3000 previously ATP-unproved Mizar/MPTP problems\nby using several ATP and AI methods, raising the number of ATP-solved Mizar\nproblems from 75\\% to above 80\\%. First, we start to experiment with the cvc5\nSMT solver which uses several instantiation-based heuristics that differ from\nthe superposition-based systems, that were previously applied to Mizar,and add\nmany new solutions. Then we use automated strategy invention to develop cvc5\nstrategies that largely improve cvc5's performance on the hard problems. In\nparticular, the best invented strategy solves over 14\\% more problems than the\nbest previously available cvc5 strategy. We also show that different\nclausification methods have a high impact on such instantiation-based methods,\nagain producing many new solutions. In total, the methods solve 3021 (21.3\\%)\nof the 14163 previously unsolved hard Mizar problems. This is a new milestone\nover the Mizar large-theory benchmark and a large strengthening of the hammer\nmethods for Mizar.\n","authors":["Jan Jakubův","Mikoláš Janota","Josef Urban"],"pdf_url":"https://arxiv.org/pdf/2406.17762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17761v1","updated":"2024-06-25T17:45:26Z","published":"2024-06-25T17:45:26Z","title":"CaLMQA: Exploring culturally specific long-form question answering\n  across 23 languages","summary":"  Large language models (LLMs) are commonly used for long-form question\nanswering, which requires them to generate paragraph-length answers to complex\nquestions. While long-form QA has been well-studied in English via many\ndifferent datasets and evaluation metrics, this research has not been extended\nto cover most other languages. To bridge this gap, we introduce CaLMQA, a\ncollection of 2.6K complex questions spanning 23 languages, including\nunder-resourced, rarely-studied languages such as Fijian and Kirundi. Our\ndataset includes both naturally-occurring questions collected from community\nweb forums as well as questions written by native speakers, whom we hire for\nthis purpose. Our process yields diverse, complex questions that reflect\ncultural topics (e.g. traditions, laws, news) and the language usage of native\nspeakers. We conduct automatic evaluation across a suite of open- and\nclosed-source models using our novel metric CaLMScore, which detects incorrect\nlanguage and token repetitions in answers, and observe that the quality of\nLLM-generated answers degrades significantly for some low-resource languages.\nWe perform human evaluation on a subset of models and see that model\nperformance is significantly worse for culturally specific questions than for\nculturally agnostic questions. Our findings highlight the need for further\nresearch in LLM multilingual capabilities and non-English LFQA evaluation.\n","authors":["Shane Arora","Marzena Karpinska","Hung-Ting Chen","Ipsita Bhattacharjee","Mohit Iyyer","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2406.17761v1.pdf","comment":"39 pages, 16 figures. Code and data available at\n  https://github.com/2015aroras/CaLMQA"},{"id":"http://arxiv.org/abs/2406.16793v2","updated":"2024-06-25T17:45:06Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the number of learning rates in Adam: Instead of assigning an\nindividual learning rate for each parameter using $1/\\sqrt{v}$, Adam-mini uses\nthe average of $v$ within a pre-defined parameter block as the learning rate\nfor that block. Such a design is inspired by two empirical findings. First, the\nHessian of Transformers exhibits a near-block diagonal structure with different\nsizes of dense sub-blocks. Second, for each of these dense sub-blocks, there\nexists a single high-quality learning rate that can outperform Adam, provided\nthat sufficient resources are available to search it out. Adam-mini provides\none cost-effective way to find these good learning rates and manage to cut down\n$\\geq$ 90% $v$ in Adam. Empirically, we verify that Adam-mini performs on par\nor better than AdamW on various language models sized from 125M to 7B for\npre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of\nAdam-mini also alleviates communication overheads among GPUs and CPUs, thereby\nincreasing throughput. For instance, Adam-mini achieves 49.6% higher throughput\nthan AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06582v2","updated":"2024-06-25T17:44:00Z","published":"2024-06-04T20:08:25Z","title":"Discrete Multimodal Transformers with a Pretrained Large Language Model\n  for Mixed-Supervision Speech Processing","summary":"  Recent work on discrete speech tokenization has paved the way for models that\ncan seamlessly perform multiple tasks across modalities, e.g., speech\nrecognition, text to speech, speech to speech translation. Moreover, large\nlanguage models (LLMs) pretrained from vast text corpora contain rich\nlinguistic information that can improve accuracy in a variety of tasks. In this\npaper, we present a decoder-only Discrete Multimodal Language Model (DMLM),\nwhich can be flexibly applied to multiple tasks (ASR, T2S, S2TT, etc.) and\nmodalities (text, speech, vision). We explore several critical aspects of\ndiscrete multi-modal models, including the loss function, weight\ninitialization, mixed training supervision, and codebook. Our results show that\nDMLM benefits significantly, across multiple tasks and datasets, from a\ncombination of supervised and unsupervised training. Moreover, for ASR, it\nbenefits from initializing DMLM from a pretrained LLM, and from a codebook\nderived from Whisper activations.\n","authors":["Viet Anh Trinh","Rosy Southwell","Yiwen Guan","Xinlu He","Zhiyong Wang","Jacob Whitehill"],"pdf_url":"https://arxiv.org/pdf/2406.06582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17759v1","updated":"2024-06-25T17:43:13Z","published":"2024-06-25T17:43:13Z","title":"Interpreting Attention Layer Outputs with Sparse Autoencoders","summary":"  Decomposing model activations into interpretable components is a key open\nproblem in mechanistic interpretability. Sparse autoencoders (SAEs) are a\npopular method for decomposing the internal activations of trained transformers\ninto sparse, interpretable features, and have been applied to MLP layers and\nthe residual stream. In this work we train SAEs on attention layer outputs and\nshow that also here SAEs find a sparse, interpretable decomposition. We\ndemonstrate this on transformers from several model families and up to 2B\nparameters.\n  We perform a qualitative study of the features computed by attention layers,\nand find multiple families: long-range context, short-range context and\ninduction features. We qualitatively study the role of every head in GPT-2\nSmall, and estimate that at least 90% of the heads are polysemantic, i.e. have\nmultiple unrelated roles.\n  Further, we show that Sparse Autoencoders are a useful tool that enable\nresearchers to explain model behavior in greater detail than prior work. For\nexample, we explore the mystery of why models have so many seemingly redundant\ninduction heads, use SAEs to motivate the hypothesis that some are long-prefix\nwhereas others are short-prefix, and confirm this with more rigorous analysis.\nWe use our SAEs to analyze the computation performed by the Indirect Object\nIdentification circuit (Wang et al.), validating that the SAEs find causally\nmeaningful intermediate variables, and deepening our understanding of the\nsemantics of the circuit. We open-source the trained SAEs and a tool for\nexploring arbitrary prompts through the lens of Attention Output SAEs.\n","authors":["Connor Kissane","Robert Krzyzanowski","Joseph Isaac Bloom","Arthur Conmy","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.17759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13692v2","updated":"2024-06-25T17:42:18Z","published":"2023-09-24T16:49:55Z","title":"Regularization and Optimal Multiclass Learning","summary":"  The quintessential learning algorithm of empirical risk minimization (ERM) is\nknown to fail in various settings for which uniform convergence does not\ncharacterize learning. It is therefore unsurprising that the practice of\nmachine learning is rife with considerably richer algorithmic techniques for\nsuccessfully controlling model capacity. Nevertheless, no such technique or\nprinciple has broken away from the pack to characterize optimal learning in\nthese more general settings.\n  The purpose of this work is to characterize the role of regularization in\nperhaps the simplest setting for which ERM fails: multiclass learning with\narbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal\nlearning algorithms that dovetail with tried-and-true algorithmic principles:\nOccam's Razor as embodied by structural risk minimization (SRM), the principle\nof maximum entropy, and Bayesian reasoning. Most notably, we introduce an\noptimal learner which relaxes structural risk minimization on two dimensions:\nit allows the regularization function to be \"local\" to datapoints, and uses an\nunsupervised learning stage to learn this regularizer at the outset. We justify\nthese relaxations by showing that they are necessary: removing either dimension\nfails to yield a near-optimal learner. We also extract from OIGs a\ncombinatorial sequence we term the Hall complexity, which is the first to\ncharacterize a problem's transductive error rate exactly.\n  Lastly, we introduce a generalization of OIGs and the transductive learning\nsetting to the agnostic case, where we show that optimal orientations of\nHamming graphs -- judged using nodes' outdegrees minus a system of\nnode-dependent credits -- characterize optimal learners exactly. We demonstrate\nthat an agnostic version of the Hall complexity again characterizes error rates\nexactly, and exhibit an optimal learner using maximum entropy programs.\n","authors":["Julian Asilis","Siddartha Devic","Shaddin Dughmi","Vatsal Sharan","Shang-Hua Teng"],"pdf_url":"https://arxiv.org/pdf/2309.13692v2.pdf","comment":"COLT 2024; 43 pages"},{"id":"http://arxiv.org/abs/2405.13285v2","updated":"2024-06-25T17:40:35Z","published":"2024-05-22T01:54:51Z","title":"Enhancing Active Learning for Sentinel 2 Imagery through Contrastive\n  Learning and Uncertainty Estimation","summary":"  In this paper, we introduce a novel method designed to enhance label\nefficiency in satellite imagery analysis by integrating semi-supervised\nlearning (SSL) with active learning strategies. Our approach utilizes\ncontrastive learning together with uncertainty estimations via Monte Carlo\nDropout (MC Dropout), with a particular focus on Sentinel-2 imagery analyzed\nusing the Eurosat dataset. We explore the effectiveness of our method in\nscenarios featuring both balanced and unbalanced class distributions. Our\nresults show that the proposed method performs better than several other\npopular methods in this field, enabling significant savings in labeling effort\nwhile maintaining high classification accuracy. These findings highlight the\npotential of our approach to facilitate scalable and cost-effective satellite\nimage analysis, particularly advantageous for extensive environmental\nmonitoring and land use classification tasks.\n","authors":["David Pogorzelski","Peter Arlinghaus","Wenyan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.13285v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17749v1","updated":"2024-06-25T17:34:52Z","published":"2024-06-25T17:34:52Z","title":"Benchmarking Deep Learning Models on NVIDIA Jetson Nano for Real-Time\n  Systems: An Empirical Investigation","summary":"  The proliferation of complex deep learning (DL) models has revolutionized\nvarious applications, including computer vision-based solutions, prompting\ntheir integration into real-time systems. However, the resource-intensive\nnature of these models poses challenges for deployment on low-computational\npower and low-memory devices, like embedded and edge devices. This work\nempirically investigates the optimization of such complex DL models to analyze\ntheir functionality on an embedded device, particularly on the NVIDIA Jetson\nNano. It evaluates the effectiveness of the optimized models in terms of their\ninference speed for image classification and video action detection. The\nexperimental results reveal that, on average, optimized models exhibit a 16.11%\nspeed improvement over their non-optimized counterparts. This not only\nemphasizes the critical need to consider hardware constraints and environmental\nsustainability in model development and deployment but also underscores the\npivotal role of model optimization in enabling the widespread deployment of\nAI-assisted technologies on resource-constrained computational systems. It also\nserves as proof that prioritizing hardware-specific model optimization leads to\nefficient and scalable solutions that substantially decrease energy consumption\nand carbon footprint.\n","authors":["Tushar Prasanna Swaminathan","Christopher Silver","Thangarajah Akilan"],"pdf_url":"https://arxiv.org/pdf/2406.17749v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.17748v1","updated":"2024-06-25T17:34:51Z","published":"2024-06-25T17:34:51Z","title":"A New Perspective on Shampoo's Preconditioner","summary":"  Shampoo, a second-order optimization algorithm which uses a Kronecker product\npreconditioner, has recently garnered increasing attention from the machine\nlearning community. The preconditioner used by Shampoo can be viewed either as\nan approximation of the Gauss--Newton component of the Hessian or the\ncovariance matrix of the gradients maintained by Adagrad. We provide an\nexplicit and novel connection between the $\\textit{optimal}$ Kronecker product\napproximation of these matrices and the approximation made by Shampoo. Our\nconnection highlights a subtle but common misconception about Shampoo's\napproximation. In particular, the $\\textit{square}$ of the approximation used\nby the Shampoo optimizer is equivalent to a single step of the power iteration\nalgorithm for computing the aforementioned optimal Kronecker product\napproximation. Across a variety of datasets and architectures we empirically\ndemonstrate that this is close to the optimal Kronecker product approximation.\nAdditionally, for the Hessian approximation viewpoint, we empirically study the\nimpact of various practical tricks to make Shampoo more computationally\nefficient (such as using the batch gradient and the empirical Fisher) on the\nquality of Hessian approximation.\n","authors":["Depen Morwani","Itai Shapira","Nikhil Vyas","Eran Malach","Sham Kakade","Lucas Janson"],"pdf_url":"https://arxiv.org/pdf/2406.17748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17747v1","updated":"2024-06-25T17:34:09Z","published":"2024-06-25T17:34:09Z","title":"Probing the effects of broken symmetries in machine learning","summary":"  Symmetry is one of the most central concepts in physics, and it is no\nsurprise that it has also been widely adopted as an inductive bias for\nmachine-learning models applied to the physical sciences. This is especially\ntrue for models targeting the properties of matter at the atomic scale. Both\nestablished and state-of-the-art approaches, with almost no exceptions, are\nbuilt to be exactly equivariant to translations, permutations, and rotations of\nthe atoms. Incorporating symmetries -- rotations in particular -- constrains\nthe model design space and implies more complicated architectures that are\noften also computationally demanding. There are indications that non-symmetric\nmodels can easily learn symmetries from data, and that doing so can even be\nbeneficial for the accuracy of the model. We put a model that obeys rotational\ninvariance only approximately to the test, in realistic scenarios involving\nsimulations of gas-phase, liquid, and solid water. We focus specifically on\nphysical observables that are likely to be affected -- directly or indirectly\n-- by symmetry breaking, finding negligible consequences when the model is used\nin an interpolative, bulk, regime. Even for extrapolative gas-phase\npredictions, the model remains very stable, even though symmetry artifacts are\nnoticeable. We also discuss strategies that can be used to systematically\nreduce the magnitude of symmetry breaking when it occurs, and assess their\nimpact on the convergence of observables.\n","authors":["Marcel F. Langer","Sergey N. Pozdnyakov","Michele Ceriotti"],"pdf_url":"https://arxiv.org/pdf/2406.17747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09384v2","updated":"2024-06-25T17:33:31Z","published":"2024-01-17T17:55:06Z","title":"Diverse Part Synthesis for 3D Shape Creation","summary":"  Methods that use neural networks for synthesizing 3D shapes in the form of a\npart-based representation have been introduced over the last few years. These\nmethods represent shapes as a graph or hierarchy of parts and enable a variety\nof applications such as shape sampling and reconstruction. However, current\nmethods do not allow easily regenerating individual shape parts according to\nuser preferences. In this paper, we investigate techniques that allow the user\nto generate multiple, diverse suggestions for individual parts. Specifically,\nwe experiment with multimodal deep generative models that allow sampling\ndiverse suggestions for shape parts and focus on models which have not been\nconsidered in previous work on shape synthesis. To provide a comparative study\nof these techniques, we introduce a method for synthesizing 3D shapes in a\npart-based representation and evaluate all the part suggestion techniques\nwithin this synthesis method. In our method, which is inspired by previous\nwork, shapes are represented as a set of parts in the form of implicit\nfunctions which are then positioned in space to form the final shape. Synthesis\nin this representation is enabled by a neural network architecture based on an\nimplicit decoder and a spatial transformer. We compare the various multimodal\ngenerative models by evaluating their performance in generating part\nsuggestions. Our contribution is to show with qualitative and quantitative\nevaluations which of the new techniques for multimodal part generation perform\nthe best and that a synthesis method based on the top-performing techniques\nallows the user to more finely control the parts that are generated in the 3D\nshapes while maintaining high shape fidelity when reconstructing shapes.\n","authors":["Yanran Guan","Oliver van Kaick"],"pdf_url":"https://arxiv.org/pdf/2401.09384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17745v1","updated":"2024-06-25T17:31:04Z","published":"2024-06-25T17:31:04Z","title":"Light-weight End-to-End Graph Interest Network for CTR Prediction in\n  E-commerce Search","summary":"  Click-through-rate (CTR) prediction has an essential impact on improving user\nexperience and revenue in e-commerce search. With the development of deep\nlearning, graph-based methods are well exploited to utilize graph structure\nextracted from user behaviors and other information to help embedding learning.\nHowever, most of the previous graph-based methods mainly focus on\nrecommendation scenarios, and therefore their graph structures highly depend on\nitem's sequential information from user behaviors, ignoring query's sequential\nsignal and query-item correlation. In this paper, we propose a new approach\nnamed Light-weight End-to-End Graph Interest Network (EGIN) to effectively mine\nusers' search interests and tackle previous challenges. (i) EGIN utilizes query\nand item's correlation and sequential information from the search system to\nbuild a heterogeneous graph for better CTR prediction in e-commerce search.\n(ii) EGIN's graph embedding learning shares the same training input and is\njointly trained with CTR prediction, making the end-to-end framework effortless\nto deploy in large-scale search systems. The proposed EGIN is composed of three\nparts: query-item heterogeneous graph, light-weight graph sampling, and\nmulti-interest network. The query-item heterogeneous graph captures correlation\nand sequential information of query and item efficiently by the proposed\nlight-weight graph sampling. The multi-interest network is well designed to\nutilize graph embedding to capture various similarity relationships between\nquery and item to enhance the final CTR prediction. We conduct extensive\nexperiments on both public and industrial datasets to demonstrate the\neffectiveness of the proposed EGIN. At the same time, the training cost of\ngraph learning is relatively low compared with the main CTR prediction task,\nensuring efficiency in practical applications.\n","authors":["Pai Peng","Quanxiang Jia","Ziqiang Zhou","Shuang Hong","Zichong Xiao"],"pdf_url":"https://arxiv.org/pdf/2406.17745v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.17740v1","updated":"2024-06-25T17:26:05Z","published":"2024-06-25T17:26:05Z","title":"Structured Unrestricted-Rank Matrices for Parameter Efficient\n  Fine-tuning","summary":"  Recent efforts to scale Transformer models have demonstrated rapid progress\nacross a wide range of tasks (Wei et al., 2022). However, fine-tuning these\nmodels for downstream tasks is expensive due to their large parameter counts.\nParameter-efficient fine-tuning (PEFT) approaches have emerged as a viable\nalternative by allowing us to fine-tune models by updating only a small number\nof parameters. In this work, we propose a general framework for parameter\nefficient fine-tuning (PEFT), based on structured unrestricted-rank matrices\n(SURM) which can serve as a drop-in replacement for popular approaches such as\nAdapters and LoRA. Unlike other methods like LoRA, SURMs provides more\nflexibility in finding the right balance between compactness and\nexpressiveness. This is achieved by using low displacement rank matrices\n(LDRMs), which hasn't been used in this context before. SURMs remain\ncompetitive with baselines, often providing significant quality improvements\nwhile using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on\nvarious image classification tasks while replacing low-rank matrices in LoRA.\nIt also results in up to 12x reduction of the number of parameters in adapters\n(with virtually no loss in quality) on the GLUE benchmark.\n","authors":["Arijit Sehanobish","Avinava Dubey","Krzysztof Choromanski","Somnath Basu Roy Chowdhury","Deepali Jain","Vikas Sindhwani","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2406.17740v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.17737v1","updated":"2024-06-25T17:24:07Z","published":"2024-06-25T17:24:07Z","title":"LLM Targeted Underperformance Disproportionately Impacts Vulnerable\n  Users","summary":"  While state-of-the-art Large Language Models (LLMs) have shown impressive\nperformance on many tasks, there has been extensive research on undesirable\nmodel behavior such as hallucinations and bias. In this work, we investigate\nhow the quality of LLM responses changes in terms of information accuracy,\ntruthfulness, and refusals depending on three user traits: English proficiency,\neducation level, and country of origin. We present extensive experimentation on\nthree state-of-the-art LLMs and two different datasets targeting truthfulness\nand factuality. Our findings suggest that undesirable behaviors in\nstate-of-the-art LLMs occur disproportionately more for users with lower\nEnglish proficiency, of lower education status, and originating from outside\nthe US, rendering these models unreliable sources of information towards their\nmost vulnerable users.\n","authors":["Elinor Poole-Dayan","Deb Roy","Jad Kabbara"],"pdf_url":"https://arxiv.org/pdf/2406.17737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.03145v2","updated":"2024-06-25T17:20:06Z","published":"2023-09-06T16:41:41Z","title":"The Best Arm Evades: Near-optimal Multi-pass Streaming Lower Bounds for\n  Pure Exploration in Multi-armed Bandits","summary":"  We give a near-optimal sample-pass trade-off for pure exploration in\nmulti-armed bandits (MABs) via multi-pass streaming algorithms: any streaming\nalgorithm with sublinear memory that uses the optimal sample complexity of\n$O(\\frac{n}{\\Delta^2})$ requires\n$\\Omega(\\frac{\\log{(1/\\Delta)}}{\\log\\log{(1/\\Delta)}})$ passes. Here, $n$ is\nthe number of arms and $\\Delta$ is the reward gap between the best and the\nsecond-best arms. Our result matches the $O(\\log(\\frac{1}{\\Delta}))$-pass\nalgorithm of Jin et al. [ICML'21] (up to lower order terms) that only uses\n$O(1)$ memory and answers an open question posed by Assadi and Wang [STOC'20].\n","authors":["Sepehr Assadi","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2309.03145v2.pdf","comment":"COLT 2024"},{"id":"http://arxiv.org/abs/2401.10748v2","updated":"2024-06-25T17:08:56Z","published":"2023-12-28T18:30:13Z","title":"Fast gradient-free activation maximization for neurons in spiking neural\n  networks","summary":"  Elements of neural networks, both biological and artificial, can be described\nby their selectivity for specific cognitive features. Understanding these\nfeatures is important for understanding the inner workings of neural networks.\nFor a living system, such as a neuron, whose response to a stimulus is unknown\nand not differentiable, the only way to reveal these features is through a\nfeedback loop that exposes it to a large set of different stimuli. The\nproperties of these stimuli should be varied iteratively in order to maximize\nthe neuronal response. To utilize this feedback loop for a biological neural\nnetwork, it is important to run it quickly and efficiently in order to reach\nthe stimuli that maximizes certain neurons' activation with the least number of\niterations possible. Here we present a framework with an efficient design for\nsuch a loop. We successfully tested it on an artificial spiking neural network\n(SNN), which is a model that simulates the asynchronous spiking activity of\nneurons in living brains. Our optimization method for activation maximization\nis based on the low-rank Tensor Train decomposition of the discrete activation\nfunction. The optimization space is the latent parameter space of images\ngenerated by SN-GAN or VQ-VAE generative models. To our knowledge, this is the\nfirst time that effective AM has been applied to SNNs. We track changes in the\noptimal stimuli for artificial neurons during training and show that highly\nselective neurons can form already in the early epochs of training and in the\nearly layers of a convolutional spiking network. This formation of refined\noptimal stimuli is associated with an increase in classification accuracy. Some\nneurons, especially in the deeper layers, may gradually change the concepts\nthey are selective for during learning, potentially explaining their importance\nfor model performance.\n","authors":["Nikita Pospelov","Andrei Chertkov","Maxim Beketov","Ivan Oseledets","Konstantin Anokhin"],"pdf_url":"https://arxiv.org/pdf/2401.10748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17718v1","updated":"2024-06-25T17:06:57Z","published":"2024-06-25T17:06:57Z","title":"When does Self-Prediction help? Understanding Auxiliary Tasks in\n  Reinforcement Learning","summary":"  We investigate the impact of auxiliary learning tasks such as observation\nreconstruction and latent self-prediction on the representation learning\nproblem in reinforcement learning. We also study how they interact with\ndistractions and observation functions in the MDP. We provide a theoretical\nanalysis of the learning dynamics of observation reconstruction, latent\nself-prediction, and TD learning in the presence of distractions and\nobservation functions under linear model assumptions. With this formalization,\nwe are able to explain why latent-self prediction is a helpful \\emph{auxiliary\ntask}, while observation reconstruction can provide more useful features when\nused in isolation. Our empirical analysis shows that the insights obtained from\nour learning dynamics framework predicts the behavior of these loss functions\nbeyond the linear model assumption in non-linear neural networks. This\nreinforces the usefulness of the linear model framework not only for\ntheoretical analysis, but also practical benefit for applied problems.\n","authors":["Claas Voelcker","Tyler Kastner","Igor Gilitschenski","Amir-massoud Farahmand"],"pdf_url":"https://arxiv.org/pdf/2406.17718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14169v5","updated":"2024-06-25T17:03:22Z","published":"2024-02-21T23:18:03Z","title":"A Temporal Stochastic Bias Correction using a Machine Learning Attention\n  model","summary":"  Climate models are biased with respect to real-world observations. They\nusually need to be adjusted before being used in impact studies. The suite of\nstatistical methods that enable such adjustments is called bias correction\n(BC). However, BC methods currently struggle to adjust temporal biases. Because\nthey mostly disregard the dependence between consecutive time points. As a\nresult, climate statistics with long-range temporal properties, such as\nheatwave duration and frequency, cannot be corrected accurately. This makes it\nmore difficult to produce reliable impact studies on such climate statistics.\nThis paper offers a novel BC methodology to correct temporal biases. This is\nmade possible by rethinking the philosophy behind BC. We will introduce BC as a\ntime-indexed regression task with stochastic outputs. Rethinking BC enables us\nto adapt state-of-the-art machine learning (ML) attention models and thereby\nlearn different types of biases, including temporal asynchronicities. With a\ncase study of heatwave duration statistics in Abuja, Nigeria, and Tokyo, Japan,\nwe show more accurate results than current climate model outputs and\nalternative BC methods.\n","authors":["Omer Nivron","Damon J. Wischik","Mathieu Vrac","Emily Shuckburgh","Alex T. Archibald"],"pdf_url":"https://arxiv.org/pdf/2402.14169v5.pdf","comment":"38 pages, 31 figures"},{"id":"http://arxiv.org/abs/2402.15422v2","updated":"2024-06-25T17:02:10Z","published":"2024-02-23T16:32:28Z","title":"A Data-Centric Approach To Generate Faithful and High Quality Patient\n  Summaries with Large Language Models","summary":"  Patients often face difficulties in understanding their hospitalizations,\nwhile healthcare workers have limited resources to provide explanations. In\nthis work, we investigate the potential of large language models to generate\npatient summaries based on doctors' notes and study the effect of training data\non the faithfulness and quality of the generated summaries. To this end, we\nrelease (i) a rigorous labeling protocol for errors in medical texts and (ii) a\npublicly available dataset of annotated hallucinations in 100 doctor-written\nand 100 generated summaries. We show that fine-tuning on hallucination-free\ndata effectively reduces hallucinations from 2.60 to 1.55 per summary for Llama\n2, while preserving relevant information. We observe a similar effect on GPT-4\n(0.70 to 0.40), when the few-shot examples are hallucination-free. We also\nconduct a qualitative evaluation using hallucination-free and improved training\ndata. We find that common quantitative metrics do not correlate well with\nfaithfulness and quality. Finally, we test GPT-4 for automatic hallucination\ndetection, which clearly outperforms common baselines.\n","authors":["Stefan Hegselmann","Shannon Zejiang Shen","Florian Gierse","Monica Agrawal","David Sontag","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2402.15422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03806v2","updated":"2024-06-25T17:01:54Z","published":"2023-12-06T16:23:26Z","title":"XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies","summary":"  We present XCube (abbreviated as $\\mathcal{X}^3$), a novel generative model\nfor high-resolution sparse 3D voxel grids with arbitrary attributes. Our model\ncan generate millions of voxels with a finest effective resolution of up to\n$1024^3$ in a feed-forward fashion without time-consuming test-time\noptimization. To achieve this, we employ a hierarchical voxel latent diffusion\nmodel which generates progressively higher resolution grids in a coarse-to-fine\nmanner using a custom framework built on the highly efficient VDB data\nstructure. Apart from generating high-resolution objects, we demonstrate the\neffectiveness of XCube on large outdoor scenes at scales of 100m$\\times$100m\nwith a voxel size as small as 10cm. We observe clear qualitative and\nquantitative improvements over past approaches. In addition to unconditional\ngeneration, we show that our model can be used to solve a variety of tasks such\nas user-guided editing, scene completion from a single scan, and text-to-3D.\nThe source code and more results can be found at\nhttps://research.nvidia.com/labs/toronto-ai/xcube/.\n","authors":["Xuanchi Ren","Jiahui Huang","Xiaohui Zeng","Ken Museth","Sanja Fidler","Francis Williams"],"pdf_url":"https://arxiv.org/pdf/2312.03806v2.pdf","comment":"CVPR 2024 Highlight. Code: https://github.com/nv-tlabs/XCube/\n  Website: https://research.nvidia.com/labs/toronto-ai/xcube/"},{"id":"http://arxiv.org/abs/2406.17714v1","updated":"2024-06-25T16:56:17Z","published":"2024-06-25T16:56:17Z","title":"Compositional Models for Estimating Causal Effects","summary":"  Many real-world systems can be represented as sets of interacting components.\nExamples of such systems include computational systems such as query\nprocessors, natural systems such as cells, and social systems such as families.\nMany approaches have been proposed in traditional (associational) machine\nlearning to model such structured systems, including statistical relational\nmodels and graph neural networks. Despite this prior work, existing approaches\nto estimating causal effects typically treat such systems as single units,\nrepresent them with a fixed set of variables and assume a homogeneous\ndata-generating process. We study a compositional approach for estimating\nindividual treatment effects (ITE) in structured systems, where each unit is\nrepresented by the composition of multiple heterogeneous components. This\napproach uses a modular architecture to model potential outcomes at each\ncomponent and aggregates component-level potential outcomes to obtain the\nunit-level potential outcomes. We discover novel benefits of the compositional\napproach in causal inference - systematic generalization to estimate\ncounterfactual outcomes of unseen combinations of components and improved\noverlap guarantees between treatment and control groups compared to the\nclassical methods for causal effect estimation. We also introduce a set of\nnovel environments for empirically evaluating the compositional approach and\ndemonstrate the effectiveness of our approach using both simulated and\nreal-world data.\n","authors":["Purva Pruthi","David Jensen"],"pdf_url":"https://arxiv.org/pdf/2406.17714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17711v1","updated":"2024-06-25T16:52:37Z","published":"2024-06-25T16:52:37Z","title":"Data curation via joint example selection further accelerates multimodal\n  learning","summary":"  Data curation is an essential component of large-scale pretraining. In this\nwork, we demonstrate that jointly selecting batches of data is more effective\nfor learning than selecting examples independently. Multimodal contrastive\nobjectives expose the dependencies between data and thus naturally yield\ncriteria for measuring the joint learnability of a batch. We derive a simple\nand tractable algorithm for selecting such batches, which significantly\naccelerate training beyond individually-prioritized data points. As performance\nimproves by selecting from larger super-batches, we also leverage recent\nadvances in model approximation to reduce the associated computational\noverhead. As a result, our approach--multimodal contrastive learning with joint\nexample selection (JEST)--surpasses state-of-the-art models with up to\n13$\\times$ fewer iterations and 10$\\times$ less computation. Essential to the\nperformance of JEST is the ability to steer the data selection process towards\nthe distribution of smaller, well-curated datasets via pretrained reference\nmodels, exposing the level of data curation as a new dimension for neural\nscaling laws.\n","authors":["Talfan Evans","Nikhil Parthasarathy","Hamza Merzic","Olivier J. Henaff"],"pdf_url":"https://arxiv.org/pdf/2406.17711v1.pdf","comment":"Main text: 9 pages, 5 figures, 3 tables, 1 algorithm. Appendix: 7\n  pages, 5 figures, 1 table, 2. algorithm"},{"id":"http://arxiv.org/abs/2406.17706v1","updated":"2024-06-25T16:45:47Z","published":"2024-06-25T16:45:47Z","title":"FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model","summary":"  Large language models (LLMs) show amazing performance on many domain-specific\ntasks after fine-tuning with some appropriate data. However, many\ndomain-specific data are privately distributed across multiple owners. Thus,\nthis dilemma raises the interest in how to perform LLM fine-tuning in federated\nlearning (FL). However, confronted with limited computation and communication\ncapacities, FL clients struggle to fine-tune an LLM effectively. To this end,\nwe introduce FedBiOT, a resource-efficient LLM fine-tuning approach to FL.\nSpecifically, our method involves the server generating a compressed LLM and\naligning its performance with the full model. Subsequently, the clients\nfine-tune a lightweight yet important part of the compressed model, referred to\nas an adapter. Notice that as the server has no access to the private data\nowned by the clients, the data used for alignment by the server has a different\ndistribution from the one used for fine-tuning by clients. We formulate the\nproblem into a bi-level optimization problem to minimize the negative effect of\ndata discrepancy and derive the updating rules for the server and clients. We\nconduct extensive experiments on LLaMA-2, empirically showing that the adapter\nhas exceptional performance when reintegrated into the global LLM. The results\nalso indicate that the proposed FedBiOT significantly reduces resource\nconsumption compared to existing benchmarks, all while achieving comparable\nperformance levels.\n","authors":["Feijie Wu","Zitao Li","Yaliang Li","Bolin Ding","Jing Gao"],"pdf_url":"https://arxiv.org/pdf/2406.17706v1.pdf","comment":"KDD 2024"},{"id":"http://arxiv.org/abs/2406.17699v1","updated":"2024-06-25T16:38:53Z","published":"2024-06-25T16:38:53Z","title":"Can independent Metropolis beat crude Monte Carlo?","summary":"  Assume that we would like to estimate the expected value of a function $F$\nwith respect to a density $\\pi$. We prove that if $\\pi$ is close enough under\nKL divergence to another density $q$, an independent Metropolis sampler\nestimator that obtains samples from $\\pi$ with proposal density $q$, enriched\nwith a variance reduction computational strategy based on control variates,\nachieves smaller asymptotic variance than that of the crude Monte Carlo\nestimator. The control variates construction requires no extra computational\neffort but assumes that the expected value of $F$ under $q$ is analytically\navailable. We illustrate this result by calculating the marginal likelihood in\na linear regression model with prior-likelihood conflict and a non-conjugate\nprior. Furthermore, we propose an adaptive independent Metropolis algorithm\nthat adapts the proposal density such that its KL divergence with the target is\nbeing reduced. We demonstrate its applicability in a Bayesian logistic and\nGaussian process regression problems and we rigorously justify our asymptotic\narguments under easily verifiable and essentially minimal conditions.\n","authors":["Siran Liu","Petros Dellaportas","Michalis K. Titsias"],"pdf_url":"https://arxiv.org/pdf/2406.17699v1.pdf","comment":"37 pages, 3 figures"},{"id":"http://arxiv.org/abs/2406.17698v1","updated":"2024-06-25T16:38:27Z","published":"2024-06-25T16:38:27Z","title":"Identifying Nonstationary Causal Structures with High-Order Markov\n  Switching Models","summary":"  Causal discovery in time series is a rapidly evolving field with a wide\nvariety of applications in other areas such as climate science and\nneuroscience. Traditional approaches assume a stationary causal graph, which\ncan be adapted to nonstationary time series with time-dependent effects or\nheterogeneous noise. In this work we address nonstationarity via\nregime-dependent causal structures. We first establish identifiability for\nhigh-order Markov Switching Models, which provide the foundations for\nidentifiable regime-dependent causal discovery. Our empirical studies\ndemonstrate the scalability of our proposed approach for high-order\nregime-dependent structure estimation, and we illustrate its applicability on\nbrain activity data.\n","authors":["Carles Balsells-Rodas","Yixin Wang","Pedro A. M. Mediano","Yingzhen Li"],"pdf_url":"https://arxiv.org/pdf/2406.17698v1.pdf","comment":"CI4TS Workshop @UAI2024"},{"id":"http://arxiv.org/abs/2406.17697v1","updated":"2024-06-25T16:33:33Z","published":"2024-06-25T16:33:33Z","title":"HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target\n  Binding Affinity Prediction","summary":"  Drug target binding affinity (DTA) is a key criterion for drug screening.\nExisting experimental methods are time-consuming and rely on limited structural\nand domain information. While learning-based methods can model sequence and\nstructural information, they struggle to integrate contextual data and often\nlack comprehensive modeling of drug-target interactions. In this study, we\npropose a novel DTA prediction method, termed HGTDP-DTA, which utilizes dynamic\nprompts within a hybrid Graph-Transformer framework. Our method generates\ncontext-specific prompts for each drug-target pair, enhancing the model's\nability to capture unique interactions. The introduction of prompt tuning\nfurther optimizes the prediction process by filtering out irrelevant noise and\nemphasizing task-relevant information, dynamically adjusting the input features\nof the molecular graph. The proposed hybrid Graph-Transformer architecture\ncombines structural information from Graph Convolutional Networks (GCNs) with\nsequence information captured by Transformers, facilitating the interaction\nbetween global and local information. Additionally, we adopted the multi-view\nfeature fusion method to project molecular graph views and affinity subgraph\nviews into a common feature space, effectively combining structural and\ncontextual information. Experiments on two widely used public datasets, Davis\nand KIBA, show that HGTDP-DTA outperforms state-of-the-art DTA prediction\nmethods in both prediction performance and generalization ability.\n","authors":["Xi Xiao","Wentao Wang","Jiacheng Xie","Lijing Zhu","Gaofei Chen","Zhengji Li","Tianyang Wang","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2406.17697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17692v1","updated":"2024-06-25T16:32:33Z","published":"2024-06-25T16:32:33Z","title":"From Distributional to Overton Pluralism: Investigating Large Language\n  Model Alignment","summary":"  The alignment process changes several properties of a large language model's\n(LLM's) output distribution. We analyze two aspects of post-alignment\ndistributional shift of LLM responses. First, we re-examine previously reported\nreductions in response diversity post-alignment. Our analysis suggests that an\napparent drop in the diversity of responses is largely explained by quality\ncontrol and information aggregation. Alignment suppresses irrelevant and\nunhelpful content while shifting the output distribution toward longer\nresponses that cover information spanning several responses from the base LLM,\nessentially presenting diverse information in a single response. Finding little\nevidence that alignment suppresses useful information, it is natural to ask the\nopposite question: do aligned models surface information that cannot be\nrecovered from base models? Our second investigation shows this is not the case\nand the behavior of aligned models is recoverable from base models without\nfine-tuning. A combination of in-context examples and lower-resolution semantic\nhints about response content can elicit responses from base LLMs that are as\nsimilar to alignment-tuned LLM responses as alignment-tuned LLM responses are\nto each other. Taken together, these results indicate that current alignment\ntechniques capture but do not extend the useful subset of assistant-like base\nLLM behavior, providing further evidence for the Superficial Alignment\nHypothesis. They also show that in-context alignment can go surprisingly far as\na strategy for imitating aligned LLMs without fine-tuning. Our code and data is\navailable at https://github.com/thomlake/investigating-alignment.\n","authors":["Thom Lake","Eunsol Choi","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2406.17692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03575v2","updated":"2024-06-25T16:32:20Z","published":"2023-10-05T14:53:40Z","title":"Analysis of learning a flow-based generative model from limited sample\n  complexity","summary":"  We study the problem of training a flow-based generative model, parametrized\nby a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.\nWe provide a sharp end-to-end analysis of the problem. First, we provide a\ntight closed-form characterization of the learnt velocity field, when\nparametrized by a shallow denoising auto-encoder trained on a finite number $n$\nof samples from the target distribution. Building on this analysis, we provide\na sharp description of the corresponding generative flow, which pushes the base\nGaussian density forward to an approximation of the target density. In\nparticular, we provide closed-form formulae for the distance between the mean\nof the generated mixture and the mean of the target mixture, which we show\ndecays as $\\Theta_n(\\frac{1}{n})$. Finally, this rate is shown to be in fact\nBayes-optimal.\n","authors":["Hugo Cui","Florent Krzakala","Eric Vanden-Eijnden","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2310.03575v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12803v2","updated":"2024-06-25T16:17:27Z","published":"2022-12-01T20:51:47Z","title":"PiPar: Pipeline Parallelism for Collaborative Machine Learning","summary":"  Collaborative machine learning (CML) techniques, such as federated learning,\nhave been proposed to train deep learning models across multiple mobile devices\nand a server. CML techniques are privacy-preserving as a local model that is\ntrained on each device instead of the raw data from the device is shared with\nthe server. However, CML training is inefficient due to low resource\nutilization. We identify idling resources on the server and devices due to\nsequential computation and communication as the principal cause of low resource\nutilization. A novel framework PiPar that leverages pipeline parallelism for\nCML techniques is developed to substantially improve resource utilization. A\nnew training pipeline is designed to parallelize the computations on different\nhardware resources and communication on different bandwidth resources, thereby\naccelerating the training process in CML. A low overhead automated parameter\nselection method is proposed to optimize the pipeline, maximizing the\nutilization of available resources. The experimental results confirm the\nvalidity of the underlying approach of PiPar and highlight that when compared\nto federated learning: (i) the idle time of the server can be reduced by up to\n64.1x, and (ii) the overall training time can be accelerated by up to 34.6x\nunder varying network conditions for a collection of six small and large\npopular deep neural networks and four datasets without sacrificing accuracy. It\nis also experimentally demonstrated that PiPar achieves performance benefits\nwhen incorporating differential privacy methods and operating in environments\nwith heterogeneous devices and changing bandwidths.\n","authors":["Zihan Zhang","Philip Rodgers","Peter Kilpatrick","Ivor Spence","Blesson Varghese"],"pdf_url":"https://arxiv.org/pdf/2302.12803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05099v4","updated":"2024-06-25T16:16:49Z","published":"2023-04-11T09:51:13Z","title":"Feudal Graph Reinforcement Learning","summary":"  Graph-based representations and message-passing modular policies constitute\nprominent approaches to tackling composable control problems in Reinforcement\nLearning (RL). However, as shown by recent graph deep learning literature, such\nlocal message-passing operators can create information bottlenecks and hinder\nglobal coordination. The issue becomes more serious in tasks requiring\nhigh-level planning. In this work, we propose a novel methodology, named Feudal\nGraph Reinforcement Learning (FGRL), that addresses such challenges by relying\non hierarchical RL and a pyramidal message-passing architecture. In particular,\nFGRL defines a hierarchy of policies where high-level commands are propagated\nfrom the top of the hierarchy down through a layered graph structure. The\nbottom layers mimic the morphology of the physical system, while the upper\nlayers correspond to higher-order sub-modules. The resulting agents are then\ncharacterized by a committee of policies where actions at a certain level set\ngoals for the level below, thus implementing a hierarchical decision-making\nstructure that can naturally implement task decomposition. We evaluate the\nproposed framework on a graph clustering problem and MuJoCo locomotion tasks;\nsimulation results show that FGRL compares favorably against relevant\nbaselines. Furthermore, an in-depth analysis of the command propagation\nmechanism provides evidence that the introduced message-passing scheme favors\nlearning hierarchical decision-making policies.\n","authors":["Tommaso Marzi","Arshjot Khehra","Andrea Cini","Cesare Alippi"],"pdf_url":"https://arxiv.org/pdf/2304.05099v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07434v2","updated":"2024-06-25T16:10:41Z","published":"2023-12-12T17:00:13Z","title":"Multi-Modal Conformal Prediction Regions with Simple Structures by\n  Optimizing Convex Shape Templates","summary":"  Conformal prediction is a statistical tool for producing prediction regions\nfor machine learning models that are valid with high probability. A key\ncomponent of conformal prediction algorithms is a \\emph{non-conformity score\nfunction} that quantifies how different a model's prediction is from the\nunknown ground truth value. Essentially, these functions determine the shape\nand the size of the conformal prediction regions. While prior work has gone\ninto creating score functions that produce multi-model prediction regions, such\nregions are generally too complex for use in downstream planning and control\nproblems. We propose a method that optimizes parameterized \\emph{shape template\nfunctions} over calibration data, which results in non-conformity score\nfunctions that produce prediction regions with minimum volume. Our approach\nresults in prediction regions that are \\emph{multi-modal}, so they can properly\ncapture residuals of distributions that have multiple modes, and\n\\emph{practical}, so each region is convex and can be easily incorporated into\ndownstream tasks, such as a motion planner using conformal prediction regions.\nOur method applies to general supervised learning tasks, while we illustrate\nits use in time-series prediction. We provide a toolbox and present\nillustrative case studies of F16 fighter jets and autonomous vehicles, showing\nan up to $68\\%$ reduction in prediction region area compared to a circular\nbaseline region.\n","authors":["Renukanandan Tumu","Matthew Cleaveland","Rahul Mangharam","George J. Pappas","Lars Lindemann"],"pdf_url":"https://arxiv.org/pdf/2312.07434v2.pdf","comment":"Accepted to L4DC 2024. 14 pages, 3 figures. The source code and\n  toolbox are available at\n  https://github.com/nandantumu/conformal_region_designer"},{"id":"http://arxiv.org/abs/2306.14094v2","updated":"2024-06-25T16:07:24Z","published":"2023-06-25T02:05:34Z","title":"Locally Differentially Private Distributed Online Learning with\n  Guaranteed Optimality","summary":"  Distributed online learning is gaining increased traction due to its unique\nability to process large-scale datasets and streaming data. To address the\ngrowing public awareness and concern on privacy protection, plenty of\nalgorithms have been proposed to enable differential privacy in distributed\nonline optimization and learning. However, these algorithms often face the\ndilemma of trading learning accuracy for privacy. By exploiting the unique\ncharacteristics of online learning, this paper proposes an approach that\ntackles the dilemma and ensures both differential privacy and learning accuracy\nin distributed online learning. More specifically, while ensuring a diminishing\nexpected instantaneous regret, the approach can simultaneously ensure a finite\ncumulative privacy budget, even in the infinite time horizon. To cater for the\nfully distributed setting, we adopt the local differential-privacy framework,\nwhich avoids the reliance on a trusted data curator, and, hence, provides\nstronger protection than the classic \"centralized\" (global) differential\nprivacy. To the best of our knowledge, this is the first algorithm that\nsuccessfully ensures both rigorous local differential privacy and learning\naccuracy. The effectiveness of the proposed algorithm is evaluated using\nmachine learning tasks, including logistic regression on the the \"mushrooms\"\ndatasets and CNN-based image classification on the \"MNIST\" and \"CIFAR-10\"\ndatasets.\n","authors":["Ziqin Chen","Yongqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14094v2.pdf","comment":"23 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.17673v1","updated":"2024-06-25T16:03:50Z","published":"2024-06-25T16:03:50Z","title":"LaTable: Towards Large Tabular Models","summary":"  Tabular data is one of the most ubiquitous modalities, yet the literature on\ntabular generative foundation models is lagging far behind its text and vision\ncounterparts. Creating such a model is hard, due to the heterogeneous feature\nspaces of different tabular datasets, tabular metadata (e.g. dataset\ndescription and feature headers), and tables lacking prior knowledge (e.g.\nfeature order). In this work we propose LaTable: a novel tabular diffusion\nmodel that addresses these challenges and can be trained across different\ndatasets. Through extensive experiments we find that LaTable outperforms\nbaselines on in-distribution generation, and that finetuning LaTable can\ngenerate out-of-distribution datasets better with fewer samples. On the other\nhand, we explore the poor zero-shot performance of LaTable, and what it may\nteach us about building generative tabular foundation models with better zero-\nand few-shot generation capabilities.\n","authors":["Boris van Breugel","Jonathan Crabbé","Rob Davis","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2406.17673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16883v2","updated":"2024-06-25T16:01:57Z","published":"2024-03-25T15:53:32Z","title":"GLAD: Improving Latent Graph Generative Modeling with Simple\n  Quantization","summary":"  Exploring the graph latent structures has not garnered much attention in the\ngraph generative research field. Yet, exploiting the latent space is as crucial\nas working on the data space for discrete data such as graphs. However,\nprevious methods either failed to preserve the permutation symmetry of graphs\nor lacked an effective approaches to model appropriately within the latent\nspace. To mitigate those issues, we propose a simple, yet effective discrete\nlatent graph diffusion generative model. Our model, namely GLAD, not only\novercomes the drawbacks of existing latent approaches, but also alleviates\ninherent issues present in diffusion methods applied on the graph space. We\nvalidate our generative model on the molecular benchmark datasets, on which it\ndemonstrates competitive performance compared with the state-of-the-art\nbaselines.\n","authors":["Van Khoa Nguyen","Yoann Boget","Frantzeska Lavda","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2403.16883v2.pdf","comment":"Accepted in the 2nd Structured Probabilistic Inference & Generative\n  Modeling workshop of ICML 2024"},{"id":"http://arxiv.org/abs/2406.17660v1","updated":"2024-06-25T15:50:32Z","published":"2024-06-25T15:50:32Z","title":"Grass: Compute Efficient Low-Memory LLM Training with Structured Sparse\n  Gradients","summary":"  Large language model (LLM) training and finetuning are often bottlenecked by\nlimited GPU memory. While existing projection-based optimization methods\naddress this by projecting gradients into a lower-dimensional subspace to\nreduce optimizer state memory, they typically rely on dense projection\nmatrices, which can introduce computational and memory overheads. In this work,\nwe propose Grass (GRAdient Stuctured Sparsification), a novel approach that\nleverages sparse projections to transform gradients into structured sparse\nupdates. This design not only significantly reduces memory usage for optimizer\nstates but also minimizes gradient memory footprint, computation, and\ncommunication costs, leading to substantial throughput improvements. Extensive\nexperiments on pretraining and finetuning tasks demonstrate that Grass achieves\ncompetitive performance to full-rank training and existing projection-based\nmethods. Notably, Grass enables half-precision pretraining of a 13B parameter\nLLaMA model on a single 40GB A100 GPU--a feat infeasible for previous\nmethods--and yields up to a $2\\times$ throughput improvement on an 8-GPU\nsystem. Code can be found at https://github.com/aashiqmuhamed/GRASS .\n","authors":["Aashiq Muhamed","Oscar Li","David Woodruff","Mona Diab","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2406.17660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17649v1","updated":"2024-06-25T15:41:26Z","published":"2024-06-25T15:41:26Z","title":"Privacy Preserving Reinforcement Learning for Population Processes","summary":"  We consider the problem of privacy protection in Reinforcement Learning (RL)\nalgorithms that operate over population processes, a practical but understudied\nsetting that includes, for example, the control of epidemics in large\npopulations of dynamically interacting individuals. In this setting, the RL\nalgorithm interacts with the population over $T$ time steps by receiving\npopulation-level statistics as state and performing actions which can affect\nthe entire population at each time step. An individual's data can be collected\nacross multiple interactions and their privacy must be protected at all times.\nWe clarify the Bayesian semantics of Differential Privacy (DP) in the presence\nof correlated data in population processes through a Pufferfish Privacy\nanalysis. We then give a meta algorithm that can take any RL algorithm as input\nand make it differentially private. This is achieved by taking an approach that\nuses DP mechanisms to privatize the state and reward signal at each time step\nbefore the RL algorithm receives them as input. Our main theoretical result\nshows that the value-function approximation error when applying standard RL\nalgorithms directly to the privatized states shrinks quickly as the population\nsize and privacy budget increase. This highlights that reasonable\nprivacy-utility trade-offs are possible for differentially private RL\nalgorithms in population processes. Our theoretical findings are validated by\nexperiments performed on a simulated epidemic control problem over large\npopulation sizes.\n","authors":["Samuel Yang-Zhao","Kee Siong Ng"],"pdf_url":"https://arxiv.org/pdf/2406.17649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17640v1","updated":"2024-06-25T15:24:06Z","published":"2024-06-25T15:24:06Z","title":"BayTTA: Uncertainty-aware medical image classification with optimized\n  test-time augmentation using Bayesian model averaging","summary":"  Test-time augmentation (TTA) is a well-known technique employed during the\ntesting phase of computer vision tasks. It involves aggregating multiple\naugmented versions of input data. Combining predictions using a simple average\nformulation is a common and straightforward approach after performing TTA. This\npaper introduces a novel framework for optimizing TTA, called BayTTA\n(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,\nwe generate a model list associated with different variations of the input data\ncreated through TTA. Then, we use BMA to combine model predictions weighted by\ntheir respective posterior probabilities. Such an approach allows one to take\ninto account model uncertainty, and thus to enhance the predictive performance\nof the related machine learning or deep learning model. We evaluate the\nperformance of BayTTA on various public data, including three medical image\ndatasets comprising skin cancer, breast cancer, and chest X-ray images and two\nwell-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental\nresults indicate that BayTTA can be effectively integrated into\nstate-of-the-art deep learning models used in medical image analysis as well as\ninto some popular pre-trained CNN models such as VGG-16, MobileNetV2,\nDenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in\ntheir accuracy and robustness performance.\n","authors":["Zeinab Sherkatghanad","Moloud Abdar","Mohammadreza Bakhtyari","Vladimir Makarenkov"],"pdf_url":"https://arxiv.org/pdf/2406.17640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v1","updated":"2024-06-25T15:24:02Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17633v1","updated":"2024-06-25T15:20:25Z","published":"2024-06-25T15:20:25Z","title":"Knowledge Distillation in Automated Annotation: Supervised Text\n  Classification with LLM-Generated Training Labels","summary":"  Computational social science (CSS) practitioners often rely on human-labeled\ndata to fine-tune supervised text classifiers. We assess the potential for\nresearchers to augment or replace human-generated training data with surrogate\ntraining labels from generative large language models (LLMs). We introduce a\nrecommended workflow and test this LLM application by replicating 14\nclassification tasks and measuring performance. We employ a novel corpus of\nEnglish-language text classification data sets from recent CSS articles in\nhigh-impact journals. Because these data sets are stored in password-protected\narchives, our analyses are less prone to issues of contamination. For each\ntask, we compare supervised classifiers fine-tuned using GPT-4 labels against\nclassifiers fine-tuned with human annotations and against labels from GPT-4 and\nMistral-7B with few-shot in-context learning. Our findings indicate that\nsupervised classification models fine-tuned on LLM-generated labels perform\ncomparably to models fine-tuned with labels from human annotators. Fine-tuning\nmodels using LLM-generated labels can be a fast, efficient and cost-effective\nmethod of building supervised text classifiers.\n","authors":["Nicholas Pangakis","Samuel Wolken"],"pdf_url":"https://arxiv.org/pdf/2406.17633v1.pdf","comment":"In Proceedings of the Sixth Workshop on Natural Language Processing\n  and Computational Social Science"},{"id":"http://arxiv.org/abs/2406.17630v1","updated":"2024-06-25T15:17:01Z","published":"2024-06-25T15:17:01Z","title":"KANQAS: Kolmogorov Arnold Network for Quantum Architecture Search","summary":"  Quantum architecture search~(QAS) is a promising direction for optimization\nand automated design of quantum circuits towards quantum advantage. Recent\ntechniques in QAS focus on machine learning-based approaches from reinforcement\nlearning, like deep Q-network. While multi-layer perceptron-based deep\nQ-networks have been applied for QAS, their interpretability remains\nchallenging due to the high number of parameters. In this work, we evaluate the\npracticality of KANs in quantum architecture search problems, analyzing their\nefficiency in terms of the probability of success, frequency of optimal\nsolutions and their dependencies on various degrees of freedom of the network.\nIn a noiseless scenario, the probability of success and the number of optimal\nquantum circuit configurations to generate the multi-qubit maximally entangled\nstates are significantly higher than MLPs. Moreover in noisy scenarios, KAN can\nachieve a better fidelity in approximating maximally entangled state than MLPs,\nwhere the performance of the MLP significantly depends on the choice of\nactivation function. Further investigation reveals that KAN requires a very\nsmall number of learnable parameters compared to MLPs, however, the average\ntime of executing each episode for KAN is much higher.\n","authors":["Akash Kundu","Aritra Sarkar","Abhishek Sadhu"],"pdf_url":"https://arxiv.org/pdf/2406.17630v1.pdf","comment":"10 pages and 4 figures"},{"id":"http://arxiv.org/abs/2211.05408v4","updated":"2024-06-25T15:16:17Z","published":"2022-11-10T08:24:52Z","title":"Controlling Moments with Kernel Stein Discrepancies","summary":"  Kernel Stein discrepancies (KSDs) measure the quality of a distributional\napproximation and can be computed even when the target density has an\nintractable normalizing constant. Notable applications include the diagnosis of\napproximate MCMC samplers and goodness-of-fit tests for unnormalized\nstatistical models. The present work analyzes the convergence control\nproperties of KSDs. We first show that standard KSDs used for weak convergence\ncontrol fail to control moment convergence. To address this limitation, we next\nprovide sufficient conditions under which alternative diffusion KSDs control\nboth moment and weak convergence. As an immediate consequence we develop, for\neach $q > 0$, the first KSDs known to exactly characterize $q$-Wasserstein\nconvergence.\n","authors":["Heishiro Kanagawa","Alessandro Barp","Arthur Gretton","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2211.05408v4.pdf","comment":"103 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.17627v1","updated":"2024-06-25T15:15:27Z","published":"2024-06-25T15:15:27Z","title":"Querying Labeled Time Series Data with Scenario Programs","summary":"  In order to ensure autonomous vehicles are safe for on-road deployment,\nsimulation-based testing has become an integral complement to on-road testing.\nThe rise in simulation testing and validation reflects a growing need to verify\nthat AV behavior is consistent with desired outcomes even in edge case\nscenarios $-$ which may seldom or never appear in on-road testing data. This\nraises a critical question: to what extent are AV failures in simulation\nconsistent with data collected from real-world testing? As a result of the gap\nbetween simulated and real sensor data (sim-to-real gap), failures in\nsimulation can either be spurious (simulation- or simulator-specific issues) or\nrelevant (safety-critical AV system issues). One possible method for validating\nif simulated time series failures are consistent with real world time series\nsensor data could involve retrieving instances of the failure scenario from a\nreal-world time series dataset, in order to understand AV performance in these\nscenarios. Adopting this strategy, we propose a formal definition of what\nconstitutes a match between a real-world labeled time series data item and a\nsimulated scenario written from a fragment of the Scenic probabilistic\nprogramming language for simulation generation. With this definition of a\nmatch, we develop a querying algorithm that identifies the subset of a labeled\ntime series dataset matching a given scenario. To allow this approach to be\nused to verify the safety of other cyber-physical systems (CPS), we present a\ndefinition and algorithm for matching scalable beyond the autonomous vehicles\ndomain. Experiments demonstrate the precision and scalability of the algorithm\nfor a set of challenging and uncommon time series scenarios identified from the\nnuScenes autonomous driving dataset. We include a full system implementation of\nthe querying algorithm freely available for use across a wide range of CPS.\n","authors":["Devan Shanker"],"pdf_url":"https://arxiv.org/pdf/2406.17627v1.pdf","comment":"72 pages, 6 figures, 5 algorithms. Published on\n  https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-136.html"},{"id":"http://arxiv.org/abs/2403.15022v3","updated":"2024-06-25T15:14:12Z","published":"2024-03-22T08:11:14Z","title":"Insights into the Lottery Ticket Hypothesis and Iterative Magnitude\n  Pruning","summary":"  Lottery ticket hypothesis for deep neural networks emphasizes the importance\nof initialization used to re-train the sparser networks obtained using the\niterative magnitude pruning process. An explanation for why the specific\ninitialization proposed by the lottery ticket hypothesis tends to work better\nin terms of generalization (and training) performance has been lacking.\nMoreover, the underlying principles in iterative magnitude pruning, like the\npruning of smaller magnitude weights and the role of the iterative process,\nlack full understanding and explanation. In this work, we attempt to provide\ninsights into these phenomena by empirically studying the volume/geometry and\nloss landscape characteristics of the solutions obtained at various stages of\nthe iterative magnitude pruning process.\n","authors":["Tausifa Jan Saleem","Ramanjit Ahuja","Surendra Prasad","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2403.15022v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12355v2","updated":"2024-06-25T15:06:33Z","published":"2023-02-23T22:39:43Z","title":"Fundamental Bounds on Online Strategic Classification","summary":"  We study the problem of online binary classification where strategic agents\ncan manipulate their observable features in predefined ways, modeled by a\nmanipulation graph, in order to receive a positive classification. We show this\nsetting differs in fundamental ways from non-strategic online classification.\nFor instance, whereas in the non-strategic case, a mistake bound of $\\ln|H|$ is\nachievable via the halving algorithm when the target function belongs to a\nknown class $H$, we show that no deterministic algorithm can achieve a mistake\nbound $o(\\Delta)$ in the strategic setting, where $\\Delta$ is the maximum\ndegree of the manipulation graph (even when $|H|=O(\\Delta)$). We obtain an\nalgorithm achieving mistake bound $O(\\Delta\\ln|H|)$. We also extend this to the\nagnostic setting and obtain an algorithm with a $\\Delta$ multiplicative regret,\nand we show no deterministic algorithm can achieve $o(\\Delta)$ multiplicative\nregret.\n  Next, we study two randomized models based on whether the random choices are\nmade before or after agents respond, and show they exhibit fundamental\ndifferences. In the first model, at each round the learner deterministically\nchooses a probability distribution over classifiers inducing expected values on\neach vertex (probabilities of being classified as positive), which the\nstrategic agents respond to. We show that any learner in this model has to\nsuffer linear regret. On the other hand, in the second model, while the\nadversary who selects the next agent must respond to the learner's probability\ndistribution over classifiers, the agent then responds to the actual hypothesis\nclassifier drawn from this distribution. Surprisingly, we show this model is\nmore advantageous to the learner, and we design randomized algorithms that\nachieve sublinear regret bounds against both oblivious and adaptive\nadversaries.\n","authors":["Saba Ahmadi","Avrim Blum","Kunhe Yang"],"pdf_url":"https://arxiv.org/pdf/2302.12355v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17615v1","updated":"2024-06-25T15:01:39Z","published":"2024-06-25T15:01:39Z","title":"Aligning Programming Language and Natural Language: Exploring Design\n  Choices in Multi-Modal Transformer-Based Embedding for Bug Localization","summary":"  Bug localization refers to the identification of source code files which is\nin a programming language and also responsible for the unexpected behavior of\nsoftware using the bug report, which is a natural language. As bug localization\nis labor-intensive, bug localization models are employed to assist software\ndevelopers. Due to the domain difference between source code files and bug\nreports, modern bug-localization systems, based on deep learning models, rely\nheavily on embedding techniques that project bug reports and source code files\ninto a shared vector space. The creation of an embedding involves several\ndesign choices, but the impact of these choices on the quality of embedding and\nthe performance of bug localization models remains unexplained in current\nresearch.\n  To address this gap, our study evaluated 14 distinct embedding models to gain\ninsights into the effects of various design choices. Subsequently, we developed\nbug localization models utilizing these embedding models to assess the\ninfluence of these choices on the performance of the localization models. Our\nfindings indicate that the pre-training strategies significantly affect the\nquality of the embedding. Moreover, we discovered that the familiarity of the\nembedding models with the data has a notable impact on the bug localization\nmodel's performance. Notably, when the training and testing data are collected\nfrom different projects, the performance of the bug localization models\nexhibits substantial fluctuations.\n","authors":["Partha Chakraborty","Venkatraman Arumugam","Meiyappan Nagappan"],"pdf_url":"https://arxiv.org/pdf/2406.17615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17611v1","updated":"2024-06-25T14:57:38Z","published":"2024-06-25T14:57:38Z","title":"Distributed Training of Large Graph Neural Networks with Variable\n  Communication Rates","summary":"  Training Graph Neural Networks (GNNs) on large graphs presents unique\nchallenges due to the large memory and computing requirements. Distributed GNN\ntraining, where the graph is partitioned across multiple machines, is a common\napproach to training GNNs on large graphs. However, as the graph cannot\ngenerally be decomposed into small non-interacting components, data\ncommunication between the training machines quickly limits training speeds.\nCompressing the communicated node activations by a fixed amount improves the\ntraining speeds, but lowers the accuracy of the trained GNN. In this paper, we\nintroduce a variable compression scheme for reducing the communication volume\nin distributed GNN training without compromising the accuracy of the learned\nmodel. Based on our theoretical analysis, we derive a variable compression\nmethod that converges to a solution equivalent to the full communication case,\nfor all graph partitioning schemes. Our empirical results show that our method\nattains a comparable performance to the one obtained with full communication.\nWe outperform full communication at any fixed compression ratio for any\ncommunication budget.\n","authors":["Juan Cervino","Md Asadullah Turja","Hesham Mostafa","Nageen Himayat","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2406.17611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17606v1","updated":"2024-06-25T14:48:28Z","published":"2024-06-25T14:48:28Z","title":"Diffusion-based Adversarial Purification for Intrusion Detection","summary":"  The escalating sophistication of cyberattacks has encouraged the integration\nof machine learning techniques in intrusion detection systems, but the rise of\nadversarial examples presents a significant challenge. These crafted\nperturbations mislead ML models, enabling attackers to evade detection or\ntrigger false alerts. As a reaction, adversarial purification has emerged as a\ncompelling solution, particularly with diffusion models showing promising\nresults. However, their purification potential remains unexplored in the\ncontext of intrusion detection. This paper demonstrates the effectiveness of\ndiffusion models in purifying adversarial examples in network intrusion\ndetection. Through a comprehensive analysis of the diffusion parameters, we\nidentify optimal configurations maximizing adversarial robustness with minimal\nimpact on normal performance. Importantly, this study reveals insights into the\nrelationship between diffusion noise and diffusion steps, representing a novel\ncontribution to the field. Our experiments are carried out on two datasets and\nagainst 5 adversarial attacks. The implementation code is publicly available.\n","authors":["Mohamed Amine Merzouk","Erwan Beurier","Reda Yaich","Nora Boulahia-Cuppens","Frédéric Cuppens"],"pdf_url":"https://arxiv.org/pdf/2406.17606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17597v1","updated":"2024-06-25T14:40:34Z","published":"2024-06-25T14:40:34Z","title":"Constructing structured tensor priors for Bayesian inverse problems","summary":"  Specifying a prior distribution is an essential part of solving Bayesian\ninverse problems. The prior encodes a belief on the nature of the solution and\nthis regularizes the problem. In this article we completely characterize a\nGaussian prior that encodes the belief that the solution is a structured\ntensor. We first define the notion of (A,b)-constrained tensors and show that\nthey describe a large variety of different structures such as Hankel,\ncirculant, triangular, symmetric, and so on. Then we completely characterize\nthe Gaussian probability distribution of such tensors by specifying its mean\nvector and covariance matrix. Furthermore, explicit expressions are proved for\nthe covariance matrix of tensors whose entries are invariant under a\npermutation. These results unlock a whole new class of priors for Bayesian\ninverse problems. We illustrate how new kernel functions can be designed and\nefficiently computed and apply our results on two particular Bayesian inverse\nproblems: completing a Hankel matrix from a few noisy measurements and learning\nan image classifier of handwritten digits. The effectiveness of the proposed\npriors is demonstrated for both problems. All applications have been\nimplemented as reactive Pluto notebooks in Julia.\n","authors":["Kim Batselier"],"pdf_url":"https://arxiv.org/pdf/2406.17597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19809v2","updated":"2024-06-25T14:39:52Z","published":"2023-10-16T13:01:35Z","title":"MgNO: Efficient Parameterization of Linear Operators via Multigrid","summary":"  In this work, we propose a concise neural operator architecture for operator\nlearning. Drawing an analogy with a conventional fully connected neural\nnetwork, we define the neural operator as follows: the output of the $i$-th\nneuron in a nonlinear operator layer is defined by $\\mathcal O_i(u) =\n\\sigma\\left( \\sum_j \\mathcal W_{ij} u + \\mathcal B_{ij}\\right)$. Here,\n$\\mathcal W_{ij}$ denotes the bounded linear operator connecting $j$-th input\nneuron to $i$-th output neuron, and the bias $\\mathcal B_{ij}$ takes the form\nof a function rather than a scalar. Given its new universal approximation\nproperty, the efficient parameterization of the bounded linear operators\nbetween two neurons (Banach spaces) plays a critical role. As a result, we\nintroduce MgNO, utilizing multigrid structures to parameterize these linear\noperators between neurons. This approach offers both mathematical rigor and\npractical expressivity. Additionally, MgNO obviates the need for conventional\nlifting and projecting operators typically required in previous neural\noperators. Moreover, it seamlessly accommodates diverse boundary conditions.\nOur empirical observations reveal that MgNO exhibits superior ease of training\ncompared to other CNN-based models, while also displaying a reduced\nsusceptibility to overfitting when contrasted with spectral-type neural\noperators. We demonstrate the efficiency and accuracy of our method with\nconsistently state-of-the-art performance on different types of partial\ndifferential equations (PDEs).\n","authors":["Juncai He","Xinliang Liu","Jinchao Xu"],"pdf_url":"https://arxiv.org/pdf/2310.19809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.09470v2","updated":"2024-06-25T14:36:33Z","published":"2023-03-16T16:43:24Z","title":"Learning with Noisy Labels through Learnable Weighting and Centroid\n  Similarity","summary":"  We introduce a novel method for training machine learning models in the\npresence of noisy labels, which are prevalent in domains such as medical\ndiagnosis and autonomous driving and have the potential to degrade a model's\ngeneralization performance. Inspired by established literature that highlights\nhow deep learning models are prone to overfitting to noisy samples in the later\nepochs of training, we propose a strategic approach. This strategy leverages\nthe distance to class centroids in the latent space and incorporates a\ndiscounting mechanism, aiming to diminish the influence of samples that lie\ndistant from all class centroids. By doing so, we effectively counteract the\nadverse effects of noisy labels. The foundational premise of our approach is\nthe assumption that samples situated further from their respective class\ncentroid in the initial stages of training are more likely to be associated\nwith noise. Our methodology is grounded in robust theoretical principles and\nhas been validated empirically through extensive experiments on several\nbenchmark datasets. Our results show that our method consistently outperforms\nthe existing state-of-the-art techniques, achieving significant improvements in\nclassification accuracy in the presence of noisy labels. The code for our\nproposed loss function and supplementary materials is available at\nhttps://github.com/wanifarooq/NCOD\n","authors":["Farooq Ahmad Wani","Maria Sofia Bucarelli","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2303.09470v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17585v1","updated":"2024-06-25T14:28:17Z","published":"2024-06-25T14:28:17Z","title":"Learning Dynamic Bayesian Networks from Data: Foundations, First\n  Principles and Numerical Comparisons","summary":"  In this paper, we present a guide to the foundations of learning Dynamic\nBayesian Networks (DBNs) from data in the form of multiple samples of\ntrajectories for some length of time. We present the formalism for a generic as\nwell as a set of common types of DBNs for particular variable distributions. We\npresent the analytical form of the models, with a comprehensive discussion on\nthe interdependence between structure and weights in a DBN model and their\nimplications for learning. Next, we give a broad overview of learning methods\nand describe and categorize them based on the most important statistical\nfeatures, and how they treat the interplay between learning structure and\nweights. We give the analytical form of the likelihood and Bayesian score\nfunctions, emphasizing the distinction from the static case. We discuss\nfunctions used in optimization to enforce structural requirements. We briefly\ndiscuss more complex extensions and representations. Finally we present a set\nof comparisons in different settings for various distinct but representative\nalgorithms across the variants.\n","authors":["Vyacheslav Kungurtsev","Petr Rysavy","Fadwa Idlahcen","Pavel Rytir","Ales Wodecki"],"pdf_url":"https://arxiv.org/pdf/2406.17585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17583v1","updated":"2024-06-25T14:27:03Z","published":"2024-06-25T14:27:03Z","title":"Towards Compositional Interpretability for XAI","summary":"  Artificial intelligence (AI) is currently based largely on black-box machine\nlearning models which lack interpretability. The field of eXplainable AI (XAI)\nstrives to address this major concern, being critical in high-stakes areas such\nas the finance, legal and health sectors.\n  We present an approach to defining AI models and their interpretability based\non category theory. For this we employ the notion of a compositional model,\nwhich sees a model in terms of formal string diagrams which capture its\nabstract structure together with its concrete implementation. This\ncomprehensive view incorporates deterministic, probabilistic and quantum\nmodels. We compare a wide range of AI models as compositional models, including\nlinear and rule-based models, (recurrent) neural networks, transformers, VAEs,\nand causal and DisCoCirc models.\n  Next we give a definition of interpretation of a model in terms of its\ncompositional structure, demonstrating how to analyse the interpretability of a\nmodel, and using this to clarify common themes in XAI. We find that what makes\nthe standard 'intrinsically interpretable' models so transparent is brought out\nmost clearly diagrammatically. This leads us to the more general notion of\ncompositionally-interpretable (CI) models, which additionally include, for\ninstance, causal, conceptual space, and DisCoCirc models.\n  We next demonstrate the explainability benefits of CI models. Firstly, their\ncompositional structure may allow the computation of other quantities of\ninterest, and may facilitate inference from the model to the modelled\nphenomenon by matching its structure. Secondly, they allow for diagrammatic\nexplanations for their behaviour, based on influence constraints, diagram\nsurgery and rewrite explanations. Finally, we discuss many future directions\nfor the approach, raising the question of how to learn such meaningfully\nstructured models in practice.\n","authors":["Sean Tull","Robin Lorenz","Stephen Clark","Ilyas Khan","Bob Coecke"],"pdf_url":"https://arxiv.org/pdf/2406.17583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17576v1","updated":"2024-06-25T14:16:40Z","published":"2024-06-25T14:16:40Z","title":"Leveraging Reinforcement Learning in Red Teaming for Advanced Ransomware\n  Attack Simulations","summary":"  Ransomware presents a significant and increasing threat to individuals and\norganizations by encrypting their systems and not releasing them until a large\nfee has been extracted. To bolster preparedness against potential attacks,\norganizations commonly conduct red teaming exercises, which involve simulated\nattacks to assess existing security measures. This paper proposes a novel\napproach utilizing reinforcement learning (RL) to simulate ransomware attacks.\nBy training an RL agent in a simulated environment mirroring real-world\nnetworks, effective attack strategies can be learned quickly, significantly\nstreamlining traditional, manual penetration testing processes. The attack\npathways revealed by the RL agent can provide valuable insights to the defense\nteam, helping them identify network weak points and develop more resilient\ndefensive measures. Experimental results on a 152-host example network confirm\nthe effectiveness of the proposed approach, demonstrating the RL agent's\ncapability to discover and orchestrate attacks on high-value targets while\nevading honeyfiles (decoy files strategically placed to detect unauthorized\naccess).\n","authors":["Cheng Wang","Christopher Redino","Ryan Clark","Abdul Rahman","Sal Aguinaga","Sathvik Murli","Dhruv Nandakumar","Roland Rao","Lanxiao Huang","Daniel Radke","Edward Bowen"],"pdf_url":"https://arxiv.org/pdf/2406.17576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17563v1","updated":"2024-06-25T14:00:42Z","published":"2024-06-25T14:00:42Z","title":"Multi-property Steering of Large Language Models with Dynamic Activation\n  Composition","summary":"  Activation steering methods were shown to be effective in conditioning\nlanguage model generation by additively intervening over models' intermediate\nrepresentations. However, the evaluation of these techniques has so far been\nlimited to single conditioning properties and synthetic settings. In this work,\nwe conduct a comprehensive evaluation of various activation steering\nstrategies, highlighting the property-dependent nature of optimal parameters to\nensure a robust effect throughout generation. To address this issue, we propose\nDynamic Activation Composition, an information-theoretic approach to modulate\nthe steering intensity of one or more properties throughout generation. Our\nexperiments on multi-property steering show that our method successfully\nmaintains high conditioning while minimizing the impact of conditioning on\ngeneration fluency.\n","authors":["Daniel Scalena","Gabriele Sarti","Malvina Nissim"],"pdf_url":"https://arxiv.org/pdf/2406.17563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15317v3","updated":"2024-06-25T13:53:57Z","published":"2023-11-26T14:35:28Z","title":"Generalized Graph Prompt: Toward a Unification of Pre-Training and\n  Downstream Tasks on Graphs","summary":"  Graph neural networks have emerged as a powerful tool for graph\nrepresentation learning, but their performance heavily relies on abundant\ntask-specific supervision. To reduce labeling requirement, the \"pre-train,\nprompt\" paradigms have become increasingly common. However, existing study of\nprompting on graphs is limited, lacking a universal treatment to appeal to\ndifferent downstream tasks. In this paper, we propose GraphPrompt, a novel\npre-training and prompting framework on graphs. GraphPrompt not only unifies\npre-training and downstream tasks into a common task template but also employs\na learnable prompt to assist a downstream task in locating the most relevant\nknowledge from the pre-trained model in a task-specific manner. To further\nenhance GraphPrompt in these two stages, we extend it into GraphPrompt+ with\ntwo major enhancements. First, we generalize several popular graph pre-training\ntasks beyond simple link prediction to broaden the compatibility with our task\ntemplate. Second, we propose a more generalized prompt design that incorporates\na series of prompt vectors within every layer of the pre-trained graph encoder,\nin order to capitalize on the hierarchical information across different layers\nbeyond just the readout layer. Finally, we conduct extensive experiments on\nfive public datasets to evaluate and analyze GraphPrompt and GraphPrompt+.\n","authors":["Xingtong Yu","Zhenghao Liu","Yuan Fang","Zemin Liu","Sihong Chen","Xinming Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15317v3.pdf","comment":"Extension of \"GraphPrompt: Unifying Pre-Training and Downstream Tasks\n  for Graph Neural Networks\". arXiv admin note: substantial text overlap with\n  arXiv:2302.08043"},{"id":"http://arxiv.org/abs/2406.17556v1","updated":"2024-06-25T13:49:56Z","published":"2024-06-25T13:49:56Z","title":"Modularity Based Community Detection in Hypergraphs","summary":"  In this paper, we propose a scalable community detection algorithm using\nhypergraph modularity function, h-Louvain. It is an adaptation of the classical\nLouvain algorithm in the context of hypergraphs. We observe that a direct\napplication of the Louvain algorithm to optimize the hypergraph modularity\nfunction often fails to find meaningful communities. We propose a solution to\nthis issue by adjusting the initial stage of the algorithm via carefully and\ndynamically tuned linear combination of the graph modularity function of the\ncorresponding two-section graph and the desired hypergraph modularity function.\nThe process is guided by Bayesian optimization of the hyper-parameters of the\nproposed procedure. Various experiments on synthetic as well as real-world\nnetworks are performed showing that this process yields improved results in\nvarious regimes.\n","authors":["Bogumił Kamiński","Paweł Misiorek","Paweł Prałat","François Théberge"],"pdf_url":"https://arxiv.org/pdf/2406.17556v1.pdf","comment":"21 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2401.02721v2","updated":"2024-06-25T13:49:31Z","published":"2024-01-05T09:32:39Z","title":"A Cost-Efficient FPGA Implementation of Tiny Transformer Model using\n  Neural ODE","summary":"  Transformer has been adopted to a wide range of tasks and shown to outperform\nCNNs and RNNs while it suffers from high training cost and computational\ncomplexity. To address these issues, a hybrid approach has become a recent\nresearch trend, which replaces a part of ResNet with an MHSA (Multi-Head\nSelf-Attention). In this paper, we propose a lightweight hybrid model which\nuses Neural ODE (Ordinary Differential Equation) as a backbone instead of\nResNet for 12.1$\\times$ parameter reduction. For the STL10 dataset, the\nproposed model achieves 80.15% top-1 accuracy which is comparable to ResNet50.\nThen, the proposed model is deployed on a modest-sized FPGA device for edge\ncomputing. To further reduce FPGA resource utilization, the model is quantized\nfollowing QAT (Quantization Aware Training) scheme instead of PTQ (Post\nTraining Quantization) to suppress the accuracy loss. As a result, an extremely\nlightweight Transformer-based model can be implemented on resource-limited\nFPGAs. The weights of the feature extraction network are stored on-chip to\nminimize the memory transfer overhead, allowing faster inference. By\neliminating the overhead of memory transfers, inference can be executed\nseamlessly, leading to accelerated inference. The proposed FPGA implementation\nachieves a 34.01$\\times$ speedup for the backbone and MHSA parts, and it\nachieves an overall 9.85$\\times$ speedup when taking into account software pre-\nand post-processing. It also achieves an overall 7.10$\\times$ higher energy\nefficiency compared to the ARM Cortex-A53 CPU.\n","authors":["Ikumi Okubo","Keisuke Sugiura","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2401.02721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14425v2","updated":"2024-06-25T13:48:41Z","published":"2024-06-20T15:49:28Z","title":"SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource\n  Languages","summary":"  Question Answering (QA) datasets have been instrumental in developing and\nevaluating Large Language Model (LLM) capabilities. However, such datasets are\nscarce for languages other than English due to the cost and difficulties of\ncollection and manual annotation. This means that producing novel models and\nmeasuring the performance of multilingual LLMs in low-resource languages is\nchallenging. To mitigate this, we propose $\\textbf{S}$yn$\\textbf{DAR}$in, a\nmethod for generating and validating QA datasets for low-resource languages. We\nutilize parallel content mining to obtain $\\textit{human-curated}$ paragraphs\nbetween English and the target language. We use the English data as context to\n$\\textit{generate}$ synthetic multiple-choice (MC) question-answer pairs, which\nare automatically translated and further validated for quality. Combining these\nwith their designated non-English $\\textit{human-curated}$ paragraphs form the\nfinal QA dataset. The method allows to maintain the content quality, reduces\nthe likelihood of factual errors, and circumvents the need for costly\nannotation. To test the method, we created a QA dataset with $1.2$K samples for\nthe Armenian language. The human evaluation shows that $98\\%$ of the generated\nEnglish data maintains quality and diversity in the question types and topics,\nwhile the translation validation pipeline can filter out $\\sim70\\%$ of data\nwith poor quality. We use the dataset to benchmark state-of-the-art LLMs,\nshowing their inability to achieve human accuracy with some model performances\ncloser to random chance. This shows that the generated dataset is non-trivial\nand can be used to evaluate reasoning capabilities in low-resource language.\n","authors":["Gayane Ghazaryan","Erik Arakelyan","Pasquale Minervini","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2406.14425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09335v2","updated":"2024-06-25T13:47:06Z","published":"2024-06-13T17:17:31Z","title":"Instance-level quantitative saliency in multiple sclerosis lesion\n  segmentation","summary":"  In recent years, explainable methods for artificial intelligence (XAI) have\ntried to reveal and describe models' decision mechanisms in the case of\nclassification tasks. However, XAI for semantic segmentation and in particular\nfor single instances has been little studied to date. Understanding the process\nunderlying automatic segmentation of single instances is crucial to reveal what\ninformation was used to detect and segment a given object of interest. In this\nstudy, we proposed two instance-level explanation maps for semantic\nsegmentation based on SmoothGrad and Grad-CAM++ methods. Then, we investigated\ntheir relevance for the detection and segmentation of white matter lesions\n(WML), a magnetic resonance imaging (MRI) biomarker in multiple sclerosis (MS).\n687 patients diagnosed with MS for a total of 4043 FLAIR and MPRAGE MRI scans\nwere collected at the University Hospital of Basel, Switzerland. Data were\nrandomly split into training, validation and test sets to train a 3D U-Net for\nMS lesion segmentation. We observed 3050 true positive (TP), 1818 false\npositive (FP), and 789 false negative (FN) cases. We generated instance-level\nexplanation maps for semantic segmentation, by developing two XAI methods based\non SmoothGrad and Grad-CAM++. We investigated: 1) the distribution of gradients\nin saliency maps with respect to both input MRI sequences; 2) the model's\nresponse in the case of synthetic lesions; 3) the amount of perilesional tissue\nneeded by the model to segment a lesion. Saliency maps (based on SmoothGrad) in\nFLAIR showed positive values inside a lesion and negative in its neighborhood.\nPeak values of saliency maps generated for these four groups of volumes\npresented distributions that differ significantly from one another, suggesting\na quantitative nature of the proposed saliency. Contextual information of 7mm\naround the lesion border was required for their segmentation.\n","authors":["Federico Spagnolo","Nataliia Molchanova","Roger Schaer","Meritxell Bach Cuadra","Mario Ocampo Pineda","Lester Melie-Garcia","Cristina Granziera","Vincent Andrearczyk","Adrien Depeursinge"],"pdf_url":"https://arxiv.org/pdf/2406.09335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07095v2","updated":"2024-06-25T13:46:24Z","published":"2024-03-11T18:44:36Z","title":"Overcoming the Paradox of Certified Training with Gaussian Smoothing","summary":"  Training neural networks with high certified accuracy against adversarial\nexamples remains an open problem despite significant efforts. While\ncertification methods can effectively leverage tight convex relaxations for\nbound computation, in training, these methods perform worse than looser\nrelaxations. Prior work hypothesized that this is caused by the discontinuity\nand perturbation sensitivity of the loss surface induced by these tighter\nrelaxations. In this work, we show theoretically that Gaussian Loss Smoothing\ncan alleviate both issues. We confirm this empirically by proposing a certified\ntraining method combining PGPE, an algorithm computing gradients of a smoothed\nloss, with different convex relaxations. When using this training method, we\nobserve that tighter bounds indeed lead to strictly better networks. While\nscaling PGPE training remains challenging due to high computational cost, we\nshow that by using a not theoretically sound, yet much cheaper smoothing\napproximation, we obtain better certified accuracies than state-of-the-art\nmethods when training on the same network architecture. Our results clearly\ndemonstrate the promise of Gaussian Loss Smoothing for training certifiably\nrobust neural networks.\n","authors":["Stefan Balauca","Mark Niklas Müller","Yuhao Mao","Maximilian Baader","Marc Fischer","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2403.07095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11253v3","updated":"2024-06-25T13:39:52Z","published":"2024-02-17T11:25:26Z","title":"Aligning Large Language Models by On-Policy Self-Judgment","summary":"  Existing approaches for aligning large language models with human preferences\nface a trade-off that requires a separate reward model (RM) for on-policy\nlearning. In this paper, we present a novel alignment framework, SELF-JUDGE\nthat (1) does on-policy learning and 2) is parameter efficient, as it does not\nrequire an additional RM for evaluating the samples for on-policy learning. To\nthis end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a\nsingle model to act as both a policy and a judge. Specifically, we view the\npairwise judgment task, choosing the better response from a response pair, as a\nspecial case of the instruction-following task. The resulting model can judge\npreferences of on-the-fly responses from current policy initialized from\nitself. Experimental results show the efficacy of SELF-JUDGE, outperforming\nbaselines in preference benchmarks. We also show that the rejecting sampling by\nitself can improve performance further without an additional evaluator.\n","authors":["Sangkyu Lee","Sungdong Kim","Ashkan Yousefpour","Minjoon Seo","Kang Min Yoo","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2402.11253v3.pdf","comment":"Published as a main conference paper at ACL 2024"},{"id":"http://arxiv.org/abs/2401.02283v3","updated":"2024-06-25T13:35:13Z","published":"2024-01-04T14:01:24Z","title":"DEM: A Method for Certifying Deep Neural Network Classifier Outputs in\n  Aerospace","summary":"  Software development in the aerospace domain requires adhering to strict,\nhigh-quality standards. While there exist regulatory guidelines for commercial\nsoftware in this domain (e.g., ARP-4754 and DO-178), these do not apply to\nsoftware with deep neural network (DNN) components. Consequently, it is unclear\nhow to allow aerospace systems to benefit from the deep learning revolution.\nOur work here seeks to address this challenge with a novel, output-centric\napproach for DNN certification. Our method employs statistical verification\ntechniques, and has the key advantage of being able to flag specific inputs for\nwhich the DNN's output may be unreliable - so that they may be later inspected\nby a human expert. To achieve this, our method conducts a statistical analysis\nof the DNN's predictions for other, nearby inputs, in order to detect\ninconsistencies. This is in contrast to existing techniques, which typically\nattempt to certify the entire DNN, as opposed to individual outputs. Our method\nuses the DNN as a black-box, and makes no assumptions about its topology. We\nhope that this work constitutes another step towards integrating DNNs in\nsafety-critical applications - especially in the aerospace domain, where high\nstandards of quality and reliability are crucial.\n","authors":["Guy Katz","Natan Levy","Idan Refaeli","Raz Yerushalmi"],"pdf_url":"https://arxiv.org/pdf/2401.02283v3.pdf","comment":"This is a preprint version of a paper that will appear at 43rd\n  Digital Avionics Systems Conference (DASC 2024)"},{"id":"http://arxiv.org/abs/2406.17542v1","updated":"2024-06-25T13:29:14Z","published":"2024-06-25T13:29:14Z","title":"CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained\n  Models using Greedy Coordinate Descent","summary":"  Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses coordinate descent to minimize the\nlayer-wise reconstruction loss to achieve high-quality quantized weights. Our\nalgorithm is easy to implement and scales efficiently to models with hundreds\nof billions of parameters. Through extensive evaluation on the PaLM2 model\nfamily, we demonstrate that CDQuant consistently outperforms GPTQ across\ndiverse model sizes and quantization levels. In particular, for INT2\nquantization of PaLM2-Otter, CDQuant achieves a 10% reduction in perplexity\ncompared to GPTQ.\n","authors":["Pranav Ajit Nair","Arun Sai Suggala"],"pdf_url":"https://arxiv.org/pdf/2406.17542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09346v2","updated":"2024-06-25T13:25:08Z","published":"2024-06-13T17:31:02Z","title":"Scoreformer: A Surrogate Model For Large-Scale Prediction of Docking\n  Scores","summary":"  In this study, we present ScoreFormer, a novel graph transformer model\ndesigned to accurately predict molecular docking scores, thereby optimizing\nhigh-throughput virtual screening (HTVS) in drug discovery. The architecture\nintegrates Principal Neighborhood Aggregation (PNA) and Learnable Random Walk\nPositional Encodings (LRWPE), enhancing the model's ability to understand\ncomplex molecular structures and their relationship with their respective\ndocking scores. This approach significantly surpasses traditional HTVS methods\nand recent Graph Neural Network (GNN) models in both recovery and efficiency\ndue to a wider coverage of the chemical space and enhanced performance. Our\nresults demonstrate that ScoreFormer achieves competitive performance in\ndocking score prediction and offers a substantial 1.65-fold reduction in\ninference time compared to existing models. We evaluated ScoreFormer across\nmultiple datasets under various conditions, confirming its robustness and\nreliability in identifying potential drug candidates rapidly.\n","authors":["Álvaro Ciudad","Adrián Morales-Pastor","Laura Malo","Isaac Filella-Mercè","Victor Guallar","Alexis Molina"],"pdf_url":"https://arxiv.org/pdf/2406.09346v2.pdf","comment":"Accepted at the 1st Machine Learning for Life and Material Sciences\n  Workshop at ICML 2024"},{"id":"http://arxiv.org/abs/2406.17537v1","updated":"2024-06-25T13:21:01Z","published":"2024-06-25T13:21:01Z","title":"SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using\n  SincNet and Variational Autoencoder","summary":"  Over the past few decades, electroencephalography (EEG) monitoring has become\na pivotal tool for diagnosing neurological disorders, particularly for\ndetecting seizures. Epilepsy, one of the most prevalent neurological diseases\nworldwide, affects approximately the 1 \\% of the population. These patients\nface significant risks, underscoring the need for reliable, continuous seizure\nmonitoring in daily life. Most of the techniques discussed in the literature\nrely on supervised Machine Learning (ML) methods. However, the challenge of\naccurately labeling variations in epileptic EEG waveforms complicates the use\nof these approaches. Additionally, the rarity of ictal events introduces an\nhigh imbalancing within the data, which could lead to poor prediction\nperformance in supervised learning approaches. Instead, a semi-supervised\napproach allows to train the model only on data not containing seizures, thus\navoiding the issues related to the data imbalancing. This work proposes a\nsemi-supervised approach for detecting epileptic seizures from EEG data,\nutilizing a novel Deep Learning-based method called SincVAE. This proposal\nincorporates the learning of an ad-hoc array of bandpass filter as a first\nlayer of a Variational Autoencoder (VAE), potentially eliminating the\npreprocessing stage where informative band frequencies are identified and\nisolated. Results indicate that SincVAE improves seizure detection in EEG data\nand is capable of identifying early seizures during the preictal stage as well\nas monitoring patients throughout the postictal stage.\n","authors":["Andrea Pollastro","Francesco Isgrò","Roberto Prevete"],"pdf_url":"https://arxiv.org/pdf/2406.17537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17536v1","updated":"2024-06-25T13:20:39Z","published":"2024-06-25T13:20:39Z","title":"MedMNIST-C: Comprehensive benchmark and improved classifier robustness\n  by simulating realistic image corruptions","summary":"  The integration of neural-network-based systems into clinical practice is\nlimited by challenges related to domain generalization and robustness. The\ncomputer vision community established benchmarks such as ImageNet-C as a\nfundamental prerequisite to measure progress towards those challenges. Similar\ndatasets are largely absent in the medical imaging community which lacks a\ncomprehensive benchmark that spans across imaging modalities and applications.\nTo address this gap, we create and open-source MedMNIST-C, a benchmark dataset\nbased on the MedMNIST+ collection covering 12 datasets and 9 imaging\nmodalities. We simulate task and modality-specific image corruptions of varying\nseverity to comprehensively evaluate the robustness of established algorithms\nagainst real-world artifacts and distribution shifts. We further provide\nquantitative evidence that our simple-to-use artificial corruptions allow for\nhighly performant, lightweight data augmentation to enhance model robustness.\nUnlike traditional, generic augmentation strategies, our approach leverages\ndomain knowledge, exhibiting significantly higher robustness when compared to\nwidely adopted methods. By introducing MedMNIST-C and open-sourcing the\ncorresponding library allowing for targeted data augmentations, we contribute\nto the development of increasingly robust methods tailored to the challenges of\nmedical imaging. The code is available at\nhttps://github.com/francescodisalvo05/medmnistc-api}{github.com/francescodisalvo05/medmnistc-api.\n","authors":["Francesco Di Salvo","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2406.17536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02111v2","updated":"2024-06-25T13:11:33Z","published":"2024-02-03T10:24:30Z","title":"Accelerating Look-ahead in Bayesian Optimization: Multilevel Monte Carlo\n  is All you Need","summary":"  We leverage multilevel Monte Carlo (MLMC) to improve the performance of\nmulti-step look-ahead Bayesian optimization (BO) methods that involve nested\nexpectations and maximizations. Often these expectations must be computed by\nMonte Carlo (MC). The complexity rate of naive MC degrades for nested\noperations, whereas MLMC is capable of achieving the canonical MC convergence\nrate for this type of problem, independently of dimension and without any\nsmoothness assumptions. Our theoretical study focuses on the approximation\nimprovements for twoand three-step look-ahead acquisition functions, but, as we\ndiscuss, the approach is generalizable in various ways, including beyond the\ncontext of BO. Our findings are verified numerically and the benefits of MLMC\nfor BO are illustrated on several benchmark examples. Code is available at\nhttps://github.com/Shangda-Yang/MLMCBO .\n","authors":["Shangda Yang","Vitaly Zankin","Maximilian Balandat","Stefan Scherer","Kevin Carlberg","Neil Walton","Kody J. H. Law"],"pdf_url":"https://arxiv.org/pdf/2402.02111v2.pdf","comment":"Preprint ICML 2024"},{"id":"http://arxiv.org/abs/2402.12479v3","updated":"2024-06-25T13:10:06Z","published":"2024-02-19T19:34:07Z","title":"In value-based deep reinforcement learning, a pruned network is a good\n  network","summary":"  Recent work has shown that deep reinforcement learning agents have difficulty\nin effectively using their network parameters. We leverage prior insights into\nthe advantages of sparse training techniques and demonstrate that gradual\nmagnitude pruning enables value-based agents to maximize parameter\neffectiveness. This results in networks that yield dramatic performance\nimprovements over traditional networks, using only a small fraction of the full\nnetwork parameters.\n","authors":["Johan Obando-Ceron","Aaron Courville","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2402.12479v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.00787v2","updated":"2024-06-25T13:09:23Z","published":"2023-11-01T19:11:46Z","title":"Accelerating Electronic Stopping Power Predictions by 10 Million Times\n  with a Combination of Time-Dependent Density Functional Theory and Machine\n  Learning","summary":"  Knowing the rate at which particle radiation releases energy in a material,\nthe stopping power, is key to designing nuclear reactors, medical treatments,\nsemiconductor and quantum materials, and many other technologies. While the\nnuclear contribution to stopping power, i.e., elastic scattering between atoms,\nis well understood in the literature, the route for gathering data on the\nelectronic contribution has for decades remained costly and reliant on many\nsimplifying assumptions, including that materials are isotropic. We establish a\nmethod that combines time-dependent density functional theory (TDDFT) and\nmachine learning to reduce the time to assess new materials to mere hours on a\nsupercomputer and provides valuable data on how atomic details influence\nelectronic stopping. Our approach uses TDDFT to compute the electronic stopping\ncontributions to stopping power from first principles in several directions and\nthen machine learning to interpolate to other directions at a cost of 10\nmillion times fewer core-hours. We demonstrate the combined approach in a study\nof proton irradiation in aluminum and employ it to predict how the depth of\nmaximum energy deposition, the \"Bragg Peak,\" varies depending on incident angle\n-- a quantity otherwise inaccessible to modelers. The lack of any experimental\ninformation requirement makes our method applicable to most materials, and its\nspeed makes it a prime candidate for enabling quantum-to-continuum models of\nradiation damage. The prospect of reusing valuable TDDFT data for training the\nmodel make our approach appealing for applications in the age of materials data\nscience.\n","authors":["Logan Ward","Ben Blaiszik","Cheng-Wei Lee","Troy Martin","Ian Foster","André Schleife"],"pdf_url":"https://arxiv.org/pdf/2311.00787v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.13049v4","updated":"2024-06-25T13:06:13Z","published":"2023-08-24T19:35:58Z","title":"Bayesian Exploration Networks","summary":"  Bayesian reinforcement learning (RL) offers a principled and elegant approach\nfor sequential decision making under uncertainty. Most notably, Bayesian agents\ndo not face an exploration/exploitation dilemma, a major pathology of\nfrequentist methods. However theoretical understanding of model-free approaches\nis lacking. In this paper, we introduce a novel Bayesian model-free formulation\nand the first analysis showing that model-free approaches can yield\nBayes-optimal policies. We show all existing model-free approaches make\napproximations that yield policies that can be arbitrarily Bayes-suboptimal. As\na first step towards model-free Bayes optimality, we introduce the Bayesian\nexploration network (BEN) which uses normalising flows to model both the\naleatoric uncertainty (via density estimation) and epistemic uncertainty (via\nvariational inference) in the Bellman operator. In the limit of complete\noptimisation, BEN learns true Bayes-optimal policies, but like in variational\nexpectation-maximisation, partial optimisation renders our approach tractable.\nEmpirical results demonstrate that BEN can learn true Bayes-optimal policies in\ntasks where existing model-free approaches fail.\n","authors":["Mattie Fellows","Brandon Kaplowitz","Christian Schroeder de Witt","Shimon Whiteson"],"pdf_url":"https://arxiv.org/pdf/2308.13049v4.pdf","comment":"Typos fixed and provided clearer proof of Theorem 3.2"},{"id":"http://arxiv.org/abs/2406.17523v1","updated":"2024-06-25T13:06:09Z","published":"2024-06-25T13:06:09Z","title":"On the consistency of hyper-parameter selection in value-based deep\n  reinforcement learning","summary":"  Deep reinforcement learning (deep RL) has achieved tremendous success on\nvarious domains through a combination of algorithmic design and careful\nselection of hyper-parameters. Algorithmic improvements are often the result of\niterative enhancements built upon prior approaches, while hyper-parameter\nchoices are typically inherited from previous methods or fine-tuned\nspecifically for the proposed technique. Despite their crucial impact on\nperformance, hyper-parameter choices are frequently overshadowed by algorithmic\nadvancements. This paper conducts an extensive empirical study focusing on the\nreliability of hyper-parameter selection for value-based deep reinforcement\nlearning agents, including the introduction of a new score to quantify the\nconsistency and reliability of various hyper-parameters. Our findings not only\nhelp establish which hyper-parameters are most critical to tune, but also help\nclarify which tunings remain consistent across different training regimes.\n","authors":["Johan Obando-Ceron","João G. M. Araújo","Aaron Courville","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2406.17523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09631v5","updated":"2024-06-25T13:00:08Z","published":"2024-02-15T00:20:30Z","title":"Representation Surgery: Theory and Practice of Affine Steering","summary":"  Language models often exhibit undesirable behavior, e.g., generating toxic or\ngender-biased text. In the case of neural language models, an encoding of the\nundesirable behavior is often present in the model's representations. Thus, one\nnatural (and common) approach to prevent the model from exhibiting undesirable\nbehavior is to steer the model's representations in a manner that reduces the\nprobability of it generating undesirable text. This paper investigates the\nformal and empirical properties of steering functions, i.e., transformation of\nthe neural language model's representations that alter its behavior. First, we\nderive two optimal, in the least-squares sense, affine steering functions under\ndifferent constraints. Our theory provides justification for existing\napproaches and offers a novel, improved steering approach. Second, we offer a\nseries of experiments that demonstrate the empirical effectiveness of the\nmethods in mitigating bias and reducing toxic generation.\n","authors":["Shashwat Singh","Shauli Ravfogel","Jonathan Herzig","Roee Aharoni","Ryan Cotterell","Ponnurangam Kumaraguru"],"pdf_url":"https://arxiv.org/pdf/2402.09631v5.pdf","comment":"Accepted in ICML 2024"},{"id":"http://arxiv.org/abs/2406.17517v1","updated":"2024-06-25T12:54:35Z","published":"2024-06-25T12:54:35Z","title":"Preserving Node Distinctness in Graph Autoencoders via Similarity\n  Distillation","summary":"  Graph autoencoders (GAEs), as a kind of generative self-supervised learning\napproach, have shown great potential in recent years. GAEs typically rely on\ndistance-based criteria, such as mean-square-error (MSE), to reconstruct the\ninput graph. However, relying solely on a single reconstruction criterion may\nlead to a loss of distinctiveness in the reconstructed graph, causing nodes to\ncollapse into similar representations and resulting in sub-optimal performance.\nTo address this issue, we have developed a simple yet effective strategy to\npreserve the necessary distinctness in the reconstructed graph. Inspired by the\nknowledge distillation technique, we found that the dual encoder-decoder\narchitecture of GAEs can be viewed as a teacher-student relationship.\nTherefore, we propose transferring the knowledge of distinctness from the raw\ngraph to the reconstructed graph, achieved through a simple KL constraint.\nSpecifically, we compute pairwise node similarity scores in the raw graph and\nreconstructed graph. During the training process, the KL constraint is\noptimized alongside the reconstruction criterion. We conducted extensive\nexperiments across three types of graph tasks, demonstrating the effectiveness\nand generality of our strategy. This indicates that the proposed approach can\nbe employed as a plug-and-play method to avoid vague reconstructions and\nenhance overall performance.\n","authors":["Ge Chen","Yulan Hu","Sheng Ouyang","Yong Liu","Cuicui Luo"],"pdf_url":"https://arxiv.org/pdf/2406.17517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08574v2","updated":"2024-06-25T12:50:34Z","published":"2023-10-12T17:57:57Z","title":"Jigsaw: Supporting Designers to Prototype Multimodal Applications by\n  Chaining AI Foundation Models","summary":"  Recent advancements in AI foundation models have made it possible for them to\nbe utilized off-the-shelf for creative tasks, including ideating design\nconcepts or generating visual prototypes. However, integrating these models\ninto the creative process can be challenging as they often exist as standalone\napplications tailored to specific tasks. To address this challenge, we\nintroduce Jigsaw, a prototype system that employs puzzle pieces as metaphors to\nrepresent foundation models. Jigsaw allows designers to combine different\nfoundation model capabilities across various modalities by assembling\ncompatible puzzle pieces. To inform the design of Jigsaw, we interviewed ten\ndesigners and distilled design goals. In a user study, we showed that Jigsaw\nenhanced designers' understanding of available foundation model capabilities,\nprovided guidance on combining capabilities across different modalities and\ntasks, and served as a canvas to support design exploration, prototyping, and\ndocumentation.\n","authors":["David Chuan-En Lin","Nikolas Martelaro"],"pdf_url":"https://arxiv.org/pdf/2310.08574v2.pdf","comment":"https://jigsaw.to"},{"id":"http://arxiv.org/abs/2406.17503v1","updated":"2024-06-25T12:43:33Z","published":"2024-06-25T12:43:33Z","title":"WAVE: Weight Template for Adaptive Initialization of Variable-sized\n  Models","summary":"  The expansion of model parameters underscores the significance of pre-trained\nmodels; however, the constraints encountered during model deployment\nnecessitate models of variable sizes. Consequently, the traditional\npre-training and fine-tuning paradigm fails to address the initialization\nproblem when target models are incompatible with pre-trained models. We tackle\nthis issue from a multitasking perspective and introduce \\textbf{WAVE}, which\nincorporates a set of shared \\textbf{W}eight templates for \\textbf{A}daptive\ninitialization of \\textbf{V}ariable-siz\\textbf{E}d Models. During\ninitialization, target models will initialize the corresponding weight scalers\ntailored to their model size, which are sufficient to learn the connection\nrules of weight templates based on the Kronecker product from a limited amount\nof data. For the construction of the weight templates, WAVE utilizes the\n\\textit{Learngene} framework, which structurally condenses common knowledge\nfrom ancestry models into weight templates as the learngenes through knowledge\ndistillation. This process allows the integration of pre-trained models'\nknowledge into structured knowledge according to the rules of weight templates.\nWe provide a comprehensive benchmark for the learngenes, and extensive\nexperiments demonstrate the efficacy of WAVE. The results show that WAVE\nachieves state-of-the-art performance when initializing models with various\ndepth and width, and even outperforms the direct pre-training of $n$ entire\nmodels, particularly for smaller models, saving approximately $n\\times$ and\n$5\\times$ in computational and storage resources, respectively. WAVE\nsimultaneously achieves the most efficient knowledge transfer across a series\nof datasets, specifically achieving an average improvement of 1.8\\% and 1.2\\%\non 7 downstream datasets.\n","authors":["Fu Feng","Yucheng Xie","Jing Wang","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2406.17503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06062v3","updated":"2024-06-25T12:36:02Z","published":"2023-11-10T13:55:05Z","title":"Practical Membership Inference Attacks against Fine-tuned Large Language\n  Models via Self-prompt Calibration","summary":"  Membership Inference Attacks (MIA) aim to infer whether a target data record\nhas been utilized for model training or not. Prior attempts have quantified the\nprivacy risks of language models (LMs) via MIAs, but there is still no\nconsensus on whether existing MIA algorithms can cause remarkable privacy\nleakage on practical Large Language Models (LLMs). Existing MIAs designed for\nLMs can be classified into two categories: reference-free and reference-based\nattacks. They are both based on the hypothesis that training records\nconsistently strike a higher probability of being sampled. Nevertheless, this\nhypothesis heavily relies on the overfitting of target models, which will be\nmitigated by multiple regularization methods and the generalization of LLMs.\nThe reference-based attack seems to achieve promising effectiveness in LLMs,\nwhich measures a more reliable membership signal by comparing the probability\ndiscrepancy between the target model and the reference model. However, the\nperformance of reference-based attack is highly dependent on a reference\ndataset that closely resembles the training dataset, which is usually\ninaccessible in the practical scenario. Overall, existing MIAs are unable to\neffectively unveil privacy leakage over practical fine-tuned LLMs that are\noverfitting-free and private. We propose a Membership Inference Attack based on\nSelf-calibrated Probabilistic Variation (SPV-MIA). Specifically, since\nmemorization in LLMs is inevitable during the training process and occurs\nbefore overfitting, we introduce a more reliable membership signal,\nprobabilistic variation, which is based on memorization rather than\noverfitting. Furthermore, we introduce a self-prompt approach, which constructs\nthe dataset to fine-tune the reference model by prompting the target LLM\nitself. In this manner, the adversary can collect a dataset with a similar\ndistribution from public APIs.\n","authors":["Wenjie Fu","Huandong Wang","Chen Gao","Guanghua Liu","Yong Li","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.06062v3.pdf","comment":"Repo: https://github.com/wjfu99/MIA-LLMs"},{"id":"http://arxiv.org/abs/2308.12143v4","updated":"2024-06-25T12:34:46Z","published":"2023-08-23T14:00:58Z","title":"A Probabilistic Fluctuation based Membership Inference Attack for\n  Diffusion Models","summary":"  Membership Inference Attack (MIA) identifies whether a record exists in a\nmachine learning model's training set by querying the model. MIAs on the\nclassic classification models have been well-studied, and recent works have\nstarted to explore how to transplant MIA onto generative models. Our\ninvestigation indicates that existing MIAs designed for generative models\nmainly depend on the overfitting in target models. However, overfitting can be\navoided by employing various regularization techniques, whereas existing MIAs\ndemonstrate poor performance in practice. Unlike overfitting, memorization is\nessential for deep learning models to attain optimal performance, making it a\nmore prevalent phenomenon. Memorization in generative models leads to an\nincreasing trend in the probability distribution of generating records around\nthe member record. Therefore, we propose a Probabilistic Fluctuation Assessing\nMembership Inference Attack (PFAMI), a black-box MIA that infers memberships by\ndetecting these trends via analyzing the overall probabilistic fluctuations\naround given records. We conduct extensive experiments across multiple\ngenerative models and datasets, which demonstrate PFAMI can improve the attack\nsuccess rate (ASR) by about 27.9% when compared with the best baseline.\n","authors":["Wenjie Fu","Huandong Wang","Chen Gao","Guanghua Liu","Yong Li","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2308.12143v4.pdf","comment":"Repo: https://github.com/wjfu99/MIA-Gen"},{"id":"http://arxiv.org/abs/2406.17490v1","updated":"2024-06-25T12:17:44Z","published":"2024-06-25T12:17:44Z","title":"BricksRL: A Platform for Democratizing Robotics and Reinforcement\n  Learning Research and Education with LEGO","summary":"  We present BricksRL, a platform designed to democratize access to robotics\nfor reinforcement learning research and education. BricksRL facilitates the\ncreation, design, and training of custom LEGO robots in the real world by\ninterfacing them with the TorchRL library for reinforcement learning agents.\nThe integration of TorchRL with the LEGO hubs, via Bluetooth bidirectional\ncommunication, enables state-of-the-art reinforcement learning training on GPUs\nfor a wide variety of LEGO builds. This offers a flexible and cost-efficient\napproach for scaling and also provides a robust infrastructure for\nrobot-environment-algorithm communication. We present various experiments\nacross tasks and robot configurations, providing built plans and training\nresults. Furthermore, we demonstrate that inexpensive LEGO robots can be\ntrained end-to-end in the real world to achieve simple tasks, with training\ntimes typically under 120 minutes on a normal laptop. Moreover, we show how\nusers can extend the capabilities, exemplified by the successful integration of\nnon-LEGO sensors. By enhancing accessibility to both robotics and reinforcement\nlearning, BricksRL establishes a strong foundation for democratized robotic\nlearning in research and educational settings.\n","authors":["Sebastian Dittert","Vincent Moens","Gianni De Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2406.17490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17477v1","updated":"2024-06-25T11:49:33Z","published":"2024-06-25T11:49:33Z","title":"Towards Federated Low-Rank Adaptation with Rank-Heterogeneous\n  Communication","summary":"  Low-rank adaptation (LoRA) is an attractive alternative of adapting full\nweights for the federated fine-tuning of large pretrained models, which can\nsignificantly reduce the memory and communication burden. In principle,\nfederated LoRA can provide an effective mean to allocate different resources to\neach client by tuning ranks for each client, which can be useful in achieving a\nbetter communication-performance tradeoff. We find, however, that the empirical\nperformance of LoRA is highly unstable with respect to such rank-heterogeneity,\nseverely limiting the applicability to the scenarios where it is desirable or\neven required to allocate nonuniform communication bandwidth to each client due\nto constrained total bandwidth. Our investigation reveals that the root cause\nof this instability is the zero-padding-based aggregation strategy adopted in\nconventional federated LoRA frameworks, which causes the information from high\nrank clients to get diluted during the aggregation process. To address this\nissue, we propose a new replication-based padding strategy, which allows us to\nbetter leverage the information from clients with high-quality datasets. This\nmethod ensures that valuable information from high rank clients is retained\nduring the aggregation process, accelerating the convergence speed and\nenhancing the overall prediction quality of the global model.\n","authors":["Yuji Byun","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2406.17477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07266v2","updated":"2024-06-25T11:42:09Z","published":"2024-06-11T13:51:51Z","title":"Efficient 3D Molecular Generation with Flow Matching and Scale Optimal\n  Transport","summary":"  Generative models for 3D drug design have gained prominence recently for\ntheir potential to design ligands directly within protein pockets. Current\napproaches, however, often suffer from very slow sampling times or generate\nmolecules with poor chemical validity. Addressing these limitations, we propose\nSemla, a scalable E(3)-equivariant message passing architecture. We further\nintroduce a molecular generation model, SemlaFlow, which is trained using flow\nmatching along with scale optimal transport, a novel extension of equivariant\noptimal transport. Our model produces state-of-the-art results on benchmark\ndatasets with just 100 sampling steps. Crucially, SemlaFlow samples high\nquality molecules with as few as 20 steps, corresponding to a two\norder-of-magnitude speed-up compared to state-of-the-art, without sacrificing\nperformance. Furthermore, we highlight limitations of current evaluation\nmethods for 3D generation and propose new benchmark metrics for unconditional\nmolecular generators. Finally, using these new metrics, we compare our model's\nability to generate high quality samples against current approaches and further\ndemonstrate SemlaFlow's strong performance.\n","authors":["Ross Irwin","Alessandro Tibo","Jon Paul Janet","Simon Olsson"],"pdf_url":"https://arxiv.org/pdf/2406.07266v2.pdf","comment":"Preprint. Code to be released upon full publication"},{"id":"http://arxiv.org/abs/2406.17475v1","updated":"2024-06-25T11:41:50Z","published":"2024-06-25T11:41:50Z","title":"Performative Debias with Fair-exposure Optimization Driven by Strategic\n  Agents in Recommender Systems","summary":"  Data bias, e.g., popularity impairs the dynamics of two-sided markets within\nrecommender systems. This overshadows the less visible but potentially\nintriguing long-tail items that could capture user interest. Despite the\nabundance of research surrounding this issue, it still poses challenges and\nremains a hot topic in academic circles. Along this line, in this paper, we\ndeveloped a re-ranking approach in dynamic settings with fair-exposure\noptimization driven by strategic agents. Designed for the producer side, the\nexecution of agents assumes content creators can modify item features based on\nstrategic incentives to maximize their exposure. This iterative process entails\nan end-to-end optimization, employing differentiable ranking operators that\nsimultaneously target accuracy and fairness. Joint objectives ensure the\nperformance of recommendations while enhancing the visibility of tail items. We\nalso leveraged the performativity nature of predictions to illustrate how\nstrategic learning influences content creators to shift towards fairness\nefficiently, thereby incentivizing features of tail items. Through\ncomprehensive experiments on both public and industrial datasets, we have\nsubstantiated the effectiveness and dominance of the proposed method especially\non unveiling the potential of tail items.\n","authors":["Zhichen Xiang","Hongke Zhao","Chuang Zhao","Ming He","Jianping Fan"],"pdf_url":"https://arxiv.org/pdf/2406.17475v1.pdf","comment":"SIGKDD 2024 accepted paper"},{"id":"http://arxiv.org/abs/2406.17470v1","updated":"2024-06-25T11:15:53Z","published":"2024-06-25T11:15:53Z","title":"Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced\n  Federated Learning","summary":"  Leveraging the computing and sensing capabilities of vehicles, vehicular\nfederated learning (VFL) has been applied to edge training for connected\nvehicles. The dynamic and interconnected nature of vehicular networks presents\nunique opportunities to harness direct vehicle-to-vehicle (V2V) communications,\nenhancing VFL training efficiency. In this paper, we formulate a stochastic\noptimization problem to optimize the VFL training performance, considering the\nenergy constraints and mobility of vehicles, and propose a V2V-enhanced dynamic\nscheduling (VEDS) algorithm to solve it. The model aggregation requirements of\nVFL and the limited transmission time due to mobility result in a stepwise\nobjective function, which presents challenges in solving the problem. We thus\npropose a derivative-based drift-plus-penalty method to convert the long-term\nstochastic optimization problem to an online mixed integer nonlinear\nprogramming (MINLP) problem, and provide a theoretical analysis to bound the\nperformance gap between the online solution and the offline optimal solution.\nFurther analysis of the scheduling priority reduces the original problem into a\nset of convex optimization problems, which are efficiently solved using the\ninterior-point method. Experimental results demonstrate that compared with the\nstate-of-the-art benchmarks, the proposed algorithm enhances the image\nclassification accuracy on the CIFAR-10 dataset by 3.18% and reduces the\naverage displacement errors on the Argoverse trajectory prediction dataset by\n10.21%.\n","authors":["Jintao Yan","Tan Chen","Yuxuan Sun","Zhaojun Nan","Sheng Zhou","Zhisheng Niu"],"pdf_url":"https://arxiv.org/pdf/2406.17470v1.pdf","comment":"Submitted to IEEE for possible publication"},{"id":"http://arxiv.org/abs/2406.17467v1","updated":"2024-06-25T11:12:52Z","published":"2024-06-25T11:12:52Z","title":"Early learning of the optimal constant solution in neural networks and\n  humans","summary":"  Deep neural networks learn increasingly complex functions over the course of\ntraining. Here, we show both empirically and theoretically that learning of the\ntarget function is preceded by an early phase in which networks learn the\noptimal constant solution (OCS) - that is, initial model responses mirror the\ndistribution of target labels, while entirely ignoring information provided in\nthe input. Using a hierarchical category learning task, we derive exact\nsolutions for learning dynamics in deep linear networks trained with bias\nterms. Even when initialized to zero, this simple architectural feature induces\nsubstantial changes in early dynamics. We identify hallmarks of this early OCS\nphase and illustrate how these signatures are observed in deep linear networks\nand larger, more complex (and nonlinear) convolutional neural networks solving\na hierarchical learning task based on MNIST and CIFAR10. We explain these\nobservations by proving that deep linear networks necessarily learn the OCS\nduring early learning. To further probe the generality of our results, we train\nhuman learners over the course of three days on the category learning task. We\nthen identify qualitative signatures of this early OCS phase in terms of the\ndynamics of true negative (correct-rejection) rates. Surprisingly, we find the\nsame early reliance on the OCS in the behaviour of human learners. Finally, we\nshow that learning of the OCS can emerge even in the absence of bias terms and\nis equivalently driven by generic correlations in the input data. Overall, our\nwork suggests the OCS as a universal learning principle in supervised,\nerror-corrective learning, and the mechanistic reasons for its prevalence.\n","authors":["Jirko Rubruck","Jan P. Bauer","Andrew Saxe","Christopher Summerfield"],"pdf_url":"https://arxiv.org/pdf/2406.17467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.15057v3","updated":"2024-06-25T11:00:05Z","published":"2023-03-27T10:00:50Z","title":"Towards Unbiased Calibration using Meta-Regularization","summary":"  Model miscalibration has been frequently identified in modern deep neural\nnetworks. Recent work aims to improve model calibration directly through a\ndifferentiable calibration proxy. However, the calibration produced is often\nbiased due to the binning mechanism. In this work, we propose to learn\nbetter-calibrated models via meta-regularization, which has two components: (1)\ngamma network (gamma-net), a meta learner that outputs sample-wise gamma values\n(continuous variable) for Focal loss for regularizing the backbone network; (2)\nsmooth expected calibration error (SECE), a Gaussian-kernel based, unbiased,\nand differentiable surrogate to ECE that enables the smooth optimization of\ngamma-Net. We evaluate the effectiveness of the proposed approach in\nregularizing neural networks towards improved and unbiased calibration on three\ncomputer vision datasets. We empirically demonstrate that: (a) learning\nsample-wise gamma as continuous variables can effectively improve calibration;\n(b) SECE smoothly optimizes gamma-net towards unbiased and robust calibration\nwith respect to the binning schemes; and (c) the combination of gamma-net and\nSECE achieves the best calibration performance across various calibration\nmetrics while retaining very competitive predictive performance as compared to\nmultiple recently proposed methods.\n","authors":["Cheng Wang","Jacek Golebiowski"],"pdf_url":"https://arxiv.org/pdf/2303.15057v3.pdf","comment":"20 pages. Accepted at TMLR:\n  https://openreview.net/forum?id=Yf8iHCfG4W"},{"id":"http://arxiv.org/abs/2406.10918v3","updated":"2024-06-25T10:50:09Z","published":"2024-06-16T12:46:40Z","title":"Embodied Question Answering via Multi-LLM Systems","summary":"  Embodied Question Answering (EQA) is an important problem, which involves an\nagent exploring the environment to answer user queries. In the existing\nliterature, EQA has exclusively been studied in single-agent scenarios, where\nexploration can be time-consuming and costly. In this work, we consider EQA in\na multi-agent framework involving multiple large language models (LLM) based\nagents independently answering queries about a household environment. To\ngenerate one answer for each query, we use the individual responses to train a\nCentral Answer Model (CAM) that aggregates responses for a robust answer. Using\nCAM, we observe a $50\\%$ higher EQA accuracy when compared against aggregation\nmethods for ensemble LLM, such as voting schemes and debates. CAM does not\nrequire any form of agent communication, alleviating it from the associated\ncosts. We ablate CAM with various nonlinear (neural network, random forest,\ndecision tree, XGBoost) and linear (logistic regression classifier, SVM)\nalgorithms. Finally, we present a feature importance analysis for CAM via\npermutation feature importance (PFI), quantifying CAMs reliance on each\nindependent agent and query context.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Dinesh Manocha","Amrit Singh Bedi"],"pdf_url":"https://arxiv.org/pdf/2406.10918v3.pdf","comment":"17 pages, 13 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2311.04517v5","updated":"2024-06-25T10:49:06Z","published":"2023-11-08T08:02:52Z","title":"High-Performance Hybrid Algorithm for Minimum Sum-of-Squares Clustering\n  of Infinitely Tall Data","summary":"  This paper introduces a novel formulation of the clustering problem, namely\nthe Minimum Sum-of-Squares Clustering of Infinitely Tall Data (MSSC-ITD), and\npresents HPClust, an innovative set of hybrid parallel approaches for its\neffective solution. By utilizing modern high-performance computing techniques,\nHPClust enhances key clustering metrics: effectiveness, computational\nefficiency, and scalability. In contrast to vanilla data parallelism, which\nonly accelerates processing time through the MapReduce framework, our approach\nunlocks superior performance by leveraging the multi-strategy\ncompetitive-cooperative parallelism and intricate properties of the objective\nfunction landscape. Unlike other available algorithms that struggle to scale,\nour algorithm is inherently parallel in nature, improving solution quality\nthrough increased scalability and parallelism, and outperforming even advanced\nalgorithms designed for small and medium-sized datasets. Our evaluation of\nHPClust, featuring four parallel strategies, demonstrates its superiority over\ntraditional and cutting-edge methods by offering better performance in the key\nmetrics. These results also show that parallel processing not only enhances the\nclustering efficiency, but the accuracy as well. Additionally, we explore the\nbalance between computational efficiency and clustering quality, providing\ninsights into optimal parallel strategies based on dataset specifics and\nresource availability. This research advances our understanding of parallelism\nin clustering algorithms, demonstrating that a judicious hybridization of\nadvanced parallel approaches yields optimal results for MSSC-ITD. Experiments\non synthetic data further confirm HPClust's exceptional scalability and\nrobustness to noise.\n","authors":["Ravil Mussabayev","Rustam Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2311.04517v5.pdf","comment":"Published in the MDPI \"Mathematics\" journal"},{"id":"http://arxiv.org/abs/2402.09910v2","updated":"2024-06-25T10:33:41Z","published":"2024-02-15T12:17:15Z","title":"DE-COP: Detecting Copyrighted Content in Language Models Training Data","summary":"  How can we detect if copyrighted content was used in the training process of\na language model, considering that the training data is typically undisclosed?\nWe are motivated by the premise that a language model is likely to identify\nverbatim excerpts from its training text. We propose DE-COP, a method to\ndetermine whether a piece of copyrighted content was included in training.\nDE-COP's core approach is to probe an LLM with multiple-choice questions, whose\noptions include both verbatim text and their paraphrases. We construct\nBookTection, a benchmark with excerpts from 165 books published prior and\nsubsequent to a model's training cutoff, along with their paraphrases. Our\nexperiments show that DE-COP surpasses the prior best method by 9.6% in\ndetection performance (AUC) on models with logits available. Moreover, DE-COP\nalso achieves an average accuracy of 72% for detecting suspect books on fully\nblack-box models where prior methods give approximately 4% accuracy. The code\nand datasets are available at https://github.com/LeiLiLab/DE-COP.\n","authors":["André V. Duarte","Xuandong Zhao","Arlindo L. Oliveira","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2402.09910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16843v2","updated":"2024-06-25T10:27:26Z","published":"2024-01-30T09:34:15Z","title":"Evaluating ML-Based Anomaly Detection Across Datasets of Varied\n  Integrity: A Case Study","summary":"  Cybersecurity remains a critical challenge in the digital age, with network\ntraffic flow anomaly detection being a key pivotal instrument in the fight\nagainst cyber threats. In this study, we address the prevalent issue of data\nintegrity in network traffic datasets, which are instrumental in developing\nmachine learning (ML) models for anomaly detection. We introduce two refined\nversions of the CICIDS-2017 dataset, NFS-2023-nTE and NFS-2023-TE, processed\nusing NFStream to ensure methodologically sound flow expiration and labeling.\nOur research contrasts the performance of the Random Forest (RF) algorithm\nacross the original CICIDS-2017, its refined counterparts WTMC-2021 and\nCRiSIS-2022, and our NFStream-generated datasets, in both binary and\nmulti-class classification contexts. We observe that the RF model exhibits\nexceptional robustness, achieving consistent high-performance metrics\nirrespective of the underlying dataset quality, which prompts a critical\ndiscussion on the actual impact of data integrity on ML efficacy. Our study\nunderscores the importance of continual refinement and methodological rigor in\ndataset generation for network security research. As the landscape of network\nthreats evolves, so must the tools and techniques used to detect and analyze\nthem.\n","authors":["Adrian Pekar","Richard Jozsa"],"pdf_url":"https://arxiv.org/pdf/2401.16843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04163v2","updated":"2024-06-25T10:26:49Z","published":"2024-06-06T15:20:37Z","title":"Essentially Sharp Estimates on the Entropy Regularization Error in\n  Discrete Discounted Markov Decision Processes","summary":"  We study the error introduced by entropy regularization of infinite-horizon\ndiscrete discounted Markov decision processes. We show that this error\ndecreases exponentially in the inverse regularization strength both in a\nweighted KL-divergence and in value with a problem-specific exponent. We\nprovide a lower bound matching our upper bound up to a polynomial factor. Our\nproof relies on the correspondence of the solutions of entropy-regularized\nMarkov decision processes with gradient flows of the unregularized reward with\nrespect to a Riemannian metric common in natural policy gradient methods.\nFurther, this correspondence allows us to identify the limit of the gradient\nflow as the generalized maximum entropy optimal policy, thereby characterizing\nthe implicit bias of the Kakade gradient flow which corresponds to a\ntime-continuous version of the natural policy gradient method. We use this to\nshow that for entropy-regularized natural policy gradient methods the overall\nerror decays exponentially in the square root of the number of iterations\nimproving existing sublinear guarantees.\n","authors":["Johannes Müller","Semih Cayci"],"pdf_url":"https://arxiv.org/pdf/2406.04163v2.pdf","comment":"26 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.11795v2","updated":"2024-06-25T10:20:49Z","published":"2024-03-18T13:53:17Z","title":"Low-Cost Privacy-Aware Decentralized Learning","summary":"  This paper introduces ZIP-DL, a novel privacy-aware decentralized learning\n(DL) algorithm that exploits correlated noise to provide strong privacy\nprotection against a local adversary while yielding efficient convergence\nguarantees for a low communication cost. The progressive neutralization of the\nadded noise during the distributed aggregation process results in ZIP-DL\nfostering a high model accuracy under privacy guarantees. ZIP-DL further uses a\nsingle communication round between each gradient descent, thus minimizing\ncommunication overhead. We provide theoretical guarantees for both convergence\nspeed and privacy guarantees, thereby making ZIP-DL applicable to practical\nscenarios. Our extensive experimental study shows that ZIP-DL significantly\noutperforms the state-of-the-art in terms of vulnerability/accuracy trade-off.\nIn particular, ZIP-DL (i) reduces the efficacy of linkability attacks by up to\n52 percentage points compared to baseline DL, (ii) improves accuracy by up to\n37 percent w.r.t. the state-of-the-art privacy-preserving mechanism operating\nunder the same threat model as ours, when configured to provide the same\nprotection against membership inference attacks, and (iii) reduces\ncommunication by up to 10.5x against the same competitor for the same level of\nprotection.\n","authors":["Sayan Biswas","Davide Frey","Romaric Gaudel","Anne-Marie Kermarrec","Dimitri Lerévérend","Rafael Pires","Rishi Sharma","François Taïani"],"pdf_url":"https://arxiv.org/pdf/2403.11795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17433v1","updated":"2024-06-25T10:16:19Z","published":"2024-06-25T10:16:19Z","title":"Mind the Graph When Balancing Data for Fairness or Robustness","summary":"  Failures of fairness or robustness in machine learning predictive settings\ncan be due to undesired dependencies between covariates, outcomes and auxiliary\nfactors of variation. A common strategy to mitigate these failures is data\nbalancing, which attempts to remove those undesired dependencies. In this work,\nwe define conditions on the training distribution for data balancing to lead to\nfair or robust models. Our results display that, in many cases, the balanced\ndistribution does not correspond to selectively removing the undesired\ndependencies in a causal graph of the task, leading to multiple failure modes\nand even interference with other mitigation techniques such as regularization.\nOverall, our results highlight the importance of taking the causal graph into\naccount before performing data balancing.\n","authors":["Jessica Schrouff","Alexis Bellot","Amal Rannen-Triki","Alan Malek","Isabela Albuquerque","Arthur Gretton","Alexander D'Amour","Silvia Chiappa"],"pdf_url":"https://arxiv.org/pdf/2406.17433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17427v1","updated":"2024-06-25T10:06:07Z","published":"2024-06-25T10:06:07Z","title":"A Critical Analysis of the Theoretical Framework of the Extreme Learning\n  Machine","summary":"  Despite the number of successful applications of the Extreme Learning Machine\n(ELM), we show that its underlying foundational principles do not have a\nrigorous mathematical justification. Specifically, we refute the proofs of two\nmain statements, and we also create a dataset that provides a counterexample to\nthe ELM learning algorithm and explain its design, which leads to many such\ncounterexamples. Finally, we provide alternative statements of the foundations,\nwhich justify the efficiency of ELM in some theoretical cases.\n","authors":["Irina Perfilievaa","Nicolas Madrid","Manuel Ojeda-Aciego","Piotr Artiemjew","Agnieszka Niemczynowicz"],"pdf_url":"https://arxiv.org/pdf/2406.17427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17425v1","updated":"2024-06-25T09:59:31Z","published":"2024-06-25T09:59:31Z","title":"CuDA2: An approach for Incorporating Traitor Agents into Cooperative\n  Multi-Agent Systems","summary":"  Cooperative Multi-Agent Reinforcement Learning (CMARL) strategies are well\nknown to be vulnerable to adversarial perturbations. Previous works on\nadversarial attacks have primarily focused on white-box attacks that directly\nperturb the states or actions of victim agents, often in scenarios with a\nlimited number of attacks. However, gaining complete access to victim agents in\nreal-world environments is exceedingly difficult. To create more realistic\nadversarial attacks, we introduce a novel method that involves injecting\ntraitor agents into the CMARL system. We model this problem as a Traitor Markov\nDecision Process (TMDP), where traitors cannot directly attack the victim\nagents but can influence their formation or positioning through collisions. In\nTMDP, traitors are trained using the same MARL algorithm as the victim agents,\nwith their reward function set as the negative of the victim agents' reward.\nDespite this, the training efficiency for traitors remains low because it is\nchallenging for them to directly associate their actions with the victim\nagents' rewards. To address this issue, we propose the Curiosity-Driven\nAdversarial Attack (CuDA2) framework. CuDA2 enhances the efficiency and\naggressiveness of attacks on the specified victim agents' policies while\nmaintaining the optimal policy invariance of the traitors. Specifically, we\nemploy a pre-trained Random Network Distillation (RND) module, where the extra\nreward generated by the RND module encourages traitors to explore states\nunencountered by the victim agents. Extensive experiments on various scenarios\nfrom SMAC demonstrate that our CuDA2 framework offers comparable or superior\nadversarial attack capabilities compared to other baselines.\n","authors":["Zhen Chen","Yong Liao","Youpeng Zhao","Zipeng Dai","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.17425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17418v1","updated":"2024-06-25T09:40:47Z","published":"2024-06-25T09:40:47Z","title":"SE-VGAE: Unsupervised Disentangled Representation Learning for\n  Interpretable Architectural Layout Design Graph Generation","summary":"  Despite the suitability of graphs for capturing the relational structures\ninherent in architectural layout designs, there is a notable dearth of research\non interpreting architectural design space using graph-based representation\nlearning and exploring architectural design graph generation. Concurrently,\ndisentangled representation learning in graph generation faces challenges such\nas node permutation invariance and representation expressiveness. To address\nthese challenges, we introduce an unsupervised disentangled representation\nlearning framework, Style-based Edge-augmented Variational Graph Auto-Encoder\n(SE-VGAE), aiming to generate architectural layout in the form of attributed\nadjacency multi-graphs while prioritizing representation disentanglement. The\nframework is designed with three alternative pipelines, each integrating a\ntransformer-based edge-augmented encoder, a latent space disentanglement\nmodule, and a style-based decoder. These components collectively facilitate the\ndecomposition of latent factors influencing architectural layout graph\ngeneration, enhancing generation fidelity and diversity. We also provide\ninsights into optimizing the framework by systematically exploring graph\nfeature augmentation schemes and evaluating their effectiveness for\ndisentangling architectural layout representation through extensive\nexperiments. Additionally, we contribute a new benchmark large-scale\narchitectural layout graph dataset extracted from real-world floor plan images\nto facilitate the exploration of graph data-based architectural design\nrepresentation space interpretation. This study pioneered disentangled\nrepresentation learning for the architectural layout graph generation. The code\nand dataset of this study will be open-sourced.\n","authors":["Jielin Chen","Rudi Stouffs"],"pdf_url":"https://arxiv.org/pdf/2406.17418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.09289v2","updated":"2024-06-25T09:40:14Z","published":"2022-02-18T16:31:57Z","title":"A Numerical Proof of Shell Model Turbulence Closure","summary":"  The development of turbulence closure models, parametrizing the influence of\nsmall non-resolved scales on the dynamics of large resolved ones, is an\noutstanding theoretical challenge with vast applicative relevance. We present a\nclosure, based on deep recurrent neural networks, that quantitatively\nreproduces, within statistical errors, Eulerian and Lagrangian structure\nfunctions and the intermittent statistics of the energy cascade, including\nthose of subgrid fluxes. To achieve high-order statistical accuracy, and thus a\nstringent statistical test, we employ shell models of turbulence. Our results\nencourage the development of similar approaches for 3D Navier-Stokes\nturbulence.\n","authors":["Giulio Ortali","Alessandro Corbetta","Gianluigi Rozza","Federico Toschi"],"pdf_url":"https://arxiv.org/pdf/2202.09289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10710v2","updated":"2024-06-25T09:37:40Z","published":"2024-01-19T14:18:32Z","title":"Classification with neural networks with quadratic decision functions","summary":"  Neural networks with quadratic decision functions have been introduced as\nalternatives to standard neural networks with affine linear ones. They are\nadvantageous when the objects or classes to be identified are compact and of\nbasic geometries like circles, ellipses etc. In this paper we investigate the\nuse of such ansatz functions for classification. In particular we test and\ncompare the algorithm on the MNIST dataset for classification of handwritten\ndigits and for classification of subspecies. We also show, that the\nimplementation can be based on the neural network structure in the software\nTensorflow and Keras, respectively.\n","authors":["Leon Frischauf","Otmar Scherzer","Cong Shi"],"pdf_url":"https://arxiv.org/pdf/2401.10710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17415v1","updated":"2024-06-25T09:37:15Z","published":"2024-06-25T09:37:15Z","title":"Variable Layer-Wise Quantization: A Simple and Effective Approach to\n  Quantize LLMs","summary":"  We present a simple variable quantization approach that quantizes different\nlayers of a large language model (LLM) at different bit levels. Specifically,\nwe quantize the most important layers to higher bit precision and less\nimportant layers to lower bits to achieve floating point quantization levels.\nWe propose two effective strategies to measure the importance of layers within\nLLMs: the first measures the importance of a layer based on how different its\noutput embeddings are from the input embeddings (the higher the better); the\nsecond estimates the importance of a layer using the number of layer weights\nthat are much larger than average (the smaller the better). We show that\nquantizing different layers at varying bits according to our importance scores\nresults in minimal performance drop with a far more compressed model size.\nFinally, we present several practical key takeaways from our variable\nlayer-wise quantization experiments: (a) LLM performance under variable\nquantization remains close to the original model until 25-50% of layers are\nmoved in lower quantization using our proposed ordering but only until 5-10% if\nmoved using no specific ordering; (b) Quantizing LLMs to lower bits performs\nsubstantially better than pruning unless extreme quantization (2-bit) is used;\nand (c) Layer-wise quantization to lower bits works better in the case of\nlarger LLMs with more layers compared to smaller LLMs with fewer layers. The\ncode used to run the experiments is available at:\nhttps://github.com/RazvanDu/LayerwiseQuant.\n","authors":["Razvan-Gabriel Dumitru","Vikas Yadav","Rishabh Maheshwary","Paul-Ioan Clotan","Sathwik Tejaswi Madhusudhan","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2406.17415v1.pdf","comment":"submitted to EMNLP, 15 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.04666v2","updated":"2024-06-25T09:28:43Z","published":"2024-03-07T17:13:12Z","title":"Telecom Language Models: Must They Be Large?","summary":"  The increasing interest in Large Language Models (LLMs) within the\ntelecommunications sector underscores their potential to revolutionize\noperational efficiency. However, the deployment of these sophisticated models\nis often hampered by their substantial size and computational demands, raising\nconcerns about their viability in resource-constrained environments. Addressing\nthis challenge, recent advancements have seen the emergence of small language\nmodels that surprisingly exhibit performance comparable to their larger\ncounterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a\ncompact yet powerful model, exemplifies this new wave of efficient small\nlanguage models. This paper conducts a comprehensive evaluation of Phi-2's\nintrinsic understanding of the telecommunications domain. Recognizing the\nscale-related limitations, we enhance Phi-2's capabilities through a\nRetrieval-Augmented Generation approach, meticulously integrating an extensive\nknowledge base specifically curated with telecom standard specifications. The\nenhanced Phi-2 model demonstrates a profound improvement in accuracy, answering\nquestions about telecom standards with a precision that closely rivals the more\nresource-intensive GPT-3.5. The paper further explores the refined capabilities\nof Phi-2 in addressing problem-solving scenarios within the telecom sector,\nhighlighting its potential and limitations.\n","authors":["Nicola Piovesan","Antonio De Domenico","Fadhel Ayed"],"pdf_url":"https://arxiv.org/pdf/2403.04666v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17404v1","updated":"2024-06-25T09:25:39Z","published":"2024-06-25T09:25:39Z","title":"Make Some Noise: Unlocking Language Model Parallel Inference Capability\n  through Noisy Training","summary":"  Existing speculative decoding methods typically require additional model\nstructure and training processes to assist the model for draft token\ngeneration. This makes the migration of acceleration methods to the new model\nmore costly and more demanding on device memory. To address this problem, we\npropose the Make Some Noise (MSN) training framework as a replacement for the\nsupervised fine-tuning stage of the large language model. The training method\nsimply introduces some noise at the input for the model to learn the denoising\ntask. It significantly enhances the parallel decoding capability of the model\nwithout affecting the original task capability. In addition, we propose a\ntree-based retrieval-augmented Jacobi (TR-Jacobi) decoding strategy to further\nimprove the inference speed of MSN models. Experiments in both the general and\ncode domains have shown that MSN can improve inference speed by 2.3-2.7x times\nwithout compromising model performance. The MSN model also achieves comparable\nacceleration ratios to the SOTA model with additional model structure on\nSpec-Bench.\n","authors":["Yixuan Wang","Xianzhen Luo","Fuxuan Wei","Yijun Liu","Qingfu Zhu","Xuanyu Zhang","Qing Yang","Dongliang Xu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2406.17404v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.17399v1","updated":"2024-06-25T09:23:25Z","published":"2024-06-25T09:23:25Z","title":"GradCheck: Analyzing classifier guidance gradients for conditional\n  diffusion sampling","summary":"  To sample from an unconditionally trained Denoising Diffusion Probabilistic\nModel (DDPM), classifier guidance adds conditional information during sampling,\nbut the gradients from classifiers, especially those not trained on noisy\nimages, are often unstable. This study conducts a gradient analysis comparing\nrobust and non-robust classifiers, as well as multiple gradient stabilization\ntechniques. Experimental results demonstrate that these techniques\nsignificantly improve the quality of class-conditional samples for non-robust\nclassifiers by providing more stable and informative classifier guidance\ngradients. The findings highlight the importance of gradient stability in\nenhancing the performance of classifier guidance, especially on non-robust\nclassifiers.\n","authors":["Philipp Vaeth","Alexander M. Fruehwald","Benjamin Paassen","Magda Gregorova"],"pdf_url":"https://arxiv.org/pdf/2406.17399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.09871v3","updated":"2024-06-25T09:10:46Z","published":"2024-04-15T15:42:12Z","title":"Explainable Online Unsupervised Anomaly Detection for Cyber-Physical\n  Systems via Causal Discovery from Time Series","summary":"  Online unsupervised detection of anomalies is crucial to guarantee the\ncorrect operation of cyber-physical systems and the safety of humans\ninteracting with them. State-of-the-art approaches based on deep learning via\nneural networks achieve outstanding performance at anomaly recognition,\nevaluating the discrepancy between a normal model of the system (with no\nanomalies) and the real-time stream of sensor time series. However, large\ntraining data and time are typically required, and explainability is still a\nchallenge to identify the root of the anomaly and implement predictive\nmaintainance. In this paper, we use causal discovery to learn a normal causal\ngraph of the system, and we evaluate the persistency of causal links during\nreal-time acquisition of sensor data to promptly detect anomalies. On two\nbenchmark anomaly detection datasets, we show that our method has higher\ntraining efficiency, outperforms the accuracy of state-of-the-art neural\narchitectures and correctly identifies the sources of >10 different anomalies.\nThe code is at https://github.com/Isla-lab/causal_anomaly_detection.\n","authors":["Daniele Meli"],"pdf_url":"https://arxiv.org/pdf/2404.09871v3.pdf","comment":"In publication for IEEE Conference on Automation and Smart\n  Engineering (CASE) 2024"},{"id":"http://arxiv.org/abs/2406.17386v1","updated":"2024-06-25T09:05:22Z","published":"2024-06-25T09:05:22Z","title":"Double Momentum Method for Lower-Level Constrained Bilevel Optimization","summary":"  Bilevel optimization (BO) has recently gained prominence in many machine\nlearning applications due to its ability to capture the nested structure\ninherent in these problems. Recently, many hypergradient methods have been\nproposed as effective solutions for solving large-scale problems. However,\ncurrent hypergradient methods for the lower-level constrained bilevel\noptimization (LCBO) problems need very restrictive assumptions, namely, where\noptimality conditions satisfy the differentiability and invertibility\nconditions and lack a solid analysis of the convergence rate. What's worse,\nexisting methods require either double-loop updates, which are sometimes less\nefficient. To solve this problem, in this paper, we propose a new hypergradient\nof LCBO leveraging the theory of nonsmooth implicit function theorem instead of\nusing the restrive assumptions. In addition, we propose a \\textit{single-loop\nsingle-timescale} algorithm based on the double-momentum method and adaptive\nstep size method and prove it can return a $(\\delta, \\epsilon)$-stationary\npoint with $\\tilde{\\mathcal{O}}(d_2^2\\epsilon^{-4})$ iterations. Experiments on\ntwo applications demonstrate the effectiveness of our proposed method.\n","authors":["Wanli Shi","Yi Chang","Bin Gu"],"pdf_url":"https://arxiv.org/pdf/2406.17386v1.pdf","comment":"27pages, 9 figures"},{"id":"http://arxiv.org/abs/2308.08634v2","updated":"2024-06-25T09:04:08Z","published":"2023-08-16T19:14:52Z","title":"FedPop: Federated Population-based Hyperparameter Tuning","summary":"  Federated Learning (FL) is a distributed machine learning (ML) paradigm, in\nwhich multiple clients collaboratively train ML models without centralizing\ntheir local data. Similar to conventional ML pipelines, the client local\noptimization and server aggregation procedure in FL are sensitive to the\nhyperparameter (HP) selection. Despite extensive research on tuning HPs for\ncentralized ML, these methods yield suboptimal results when employed in FL.\nThis is mainly because their \"training-after-tuning\" framework is unsuitable\nfor FL with limited client computation power. While some approaches have been\nproposed for HP-Tuning in FL, they are limited to the HPs for client local\nupdates. In this work, we propose a novel HP-tuning algorithm, called Federated\nPopulation-based Hyperparameter Tuning (FedPop), to address this vital yet\nchallenging problem. FedPop employs population-based evolutionary algorithms to\noptimize the HPs, which accommodates various HP types at both client and server\nsides. Compared with prior tuning methods, FedPop employs an online\n\"tuning-while-training\" framework, offering computational efficiency and\nenabling the exploration of a broader HP search space. Our empirical validation\non the common FL benchmarks and complex real-world FL datasets demonstrates the\neffectiveness of the proposed method, which substantially outperforms the\nconcurrent state-of-the-art HP tuning methods for FL.\n","authors":["Haokun Chen","Denis Krompass","Jindong Gu","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2308.08634v2.pdf","comment":"Code: https://github.com/HaokunChen245/FedPop"},{"id":"http://arxiv.org/abs/2401.04364v2","updated":"2024-06-25T09:02:42Z","published":"2024-01-09T05:32:22Z","title":"SoK: Facial Deepfake Detectors","summary":"  Deepfakes have rapidly emerged as a profound and serious threat to society,\nprimarily due to their ease of creation and dissemination. This situation has\ntriggered an accelerated development of deepfake detection technologies.\nHowever, many existing detectors rely heavily on lab-generated datasets for\nvalidation, which may not effectively prepare them for novel, emerging, and\nreal-world deepfake techniques. In this paper, we conduct an extensive and\ncomprehensive review and analysis of the latest state-of-the-art deepfake\ndetectors, evaluating them against several critical criteria. These criteria\nfacilitate the categorization of these detectors into 4 high-level groups and\n13 fine-grained sub-groups, all aligned with a unified standard conceptual\nframework. This classification and framework offer deep and practical insights\ninto the factors that affect detector efficacy. We assess the generalizability\nof 16 leading detectors across various standard attack scenarios, including\nblack-box, white-box, and gray-box settings. Our systematized analysis and\nexperimentation lay the groundwork for a deeper understanding of deepfake\ndetectors and their generalizability, paving the way for future research\nfocused on creating detectors adept at countering various attack scenarios.\nAdditionally, this work offers insights for developing more proactive defenses\nagainst deepfakes.\n","authors":["Binh M. Le","Jiwon Kim","Shahroz Tariq","Kristen Moore","Alsharif Abuadbba","Simon S. Woo"],"pdf_url":"https://arxiv.org/pdf/2401.04364v2.pdf","comment":"18 pages, 6 figures, 5 table, under peer-review"},{"id":"http://arxiv.org/abs/2406.17381v1","updated":"2024-06-25T08:57:47Z","published":"2024-06-25T08:57:47Z","title":"Forget but Recall: Incremental Latent Rectification in Continual\n  Learning","summary":"  Intrinsic capability to continuously learn a changing data stream is a\ndesideratum of deep neural networks (DNNs). However, current DNNs suffer from\ncatastrophic forgetting, which hinders remembering past knowledge. To mitigate\nthis issue, existing Continual Learning (CL) approaches either retain exemplars\nfor replay, regularize learning, or allocate dedicated capacity for new tasks.\nThis paper investigates an unexplored CL direction for incremental learning\ncalled Incremental Latent Rectification or ILR. In a nutshell, ILR learns to\npropagate with correction (or rectify) the representation from the current\ntrained DNN backward to the representation space of the old task, where\nperforming predictive decisions is easier. This rectification process only\nemploys a chain of small representation mapping networks, called rectifier\nunits. Empirical experiments on several continual learning benchmarks,\nincluding CIFAR10, CIFAR100, and Tiny ImageNet, demonstrate the effectiveness\nand potential of this novel CL direction compared to existing representative CL\nmethods.\n","authors":["Nghia D. Nguyen","Hieu Trung Nguyen","Ang Li","Hoang Pham","Viet Anh Nguyen","Khoa D. Doan"],"pdf_url":"https://arxiv.org/pdf/2406.17381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02736v2","updated":"2024-06-25T08:55:16Z","published":"2024-01-05T10:14:39Z","title":"On the numerical reliability of nonsmooth autodiff: a MaxPool case study","summary":"  This paper considers the reliability of automatic differentiation (AD) for\nneural networks involving the nonsmooth MaxPool operation. We investigate the\nbehavior of AD across different precision levels (16, 32, 64 bits) and\nconvolutional architectures (LeNet, VGG, and ResNet) on various datasets\n(MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recent\nresearch has shown that it coincides with the derivative almost everywhere,\neven in the presence of nonsmooth operations (such as MaxPool and ReLU). On the\nother hand, in practice, AD operates with floating-point numbers (not real\nnumbers), and there is, therefore, a need to explore subsets on which AD can be\nnumerically incorrect. These subsets include a bifurcation zone (where AD is\nincorrect over reals) and a compensation zone (where AD is incorrect over\nfloating-point numbers but correct over reals). Using SGD for the training\nprocess, we study the impact of different choices of the nonsmooth Jacobian for\nthe MaxPool function on the precision of 16 and 32 bits. These findings suggest\nthat nonsmooth MaxPool Jacobians with lower norms help maintain stable and\nefficient test accuracy, whereas those with higher norms can result in\ninstability and decreased performance. We also observe that the influence of\nMaxPool's nonsmooth Jacobians on learning can be reduced by using batch\nnormalization, Adam-like optimizers, or increasing the precision level.\n","authors":["Ryan Boustany"],"pdf_url":"https://arxiv.org/pdf/2401.02736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14103v2","updated":"2024-06-25T08:50:33Z","published":"2024-02-21T19:55:01Z","title":"Computational-Statistical Gaps for Improper Learning in Sparse Linear\n  Regression","summary":"  We study computational-statistical gaps for improper learning in sparse\nlinear regression. More specifically, given $n$ samples from a $k$-sparse\nlinear model in dimension $d$, we ask what is the minimum sample complexity to\nefficiently (in time polynomial in $d$, $k$, and $n$) find a potentially dense\nestimate for the regression vector that achieves non-trivial prediction error\non the $n$ samples. Information-theoretically this can be achieved using\n$\\Theta(k \\log (d/k))$ samples. Yet, despite its prominence in the literature,\nthere is no polynomial-time algorithm known to achieve the same guarantees\nusing less than $\\Theta(d)$ samples without additional restrictions on the\nmodel. Similarly, existing hardness results are either restricted to the proper\nsetting, in which the estimate must be sparse as well, or only apply to\nspecific algorithms.\n  We give evidence that efficient algorithms for this task require at least\n(roughly) $\\Omega(k^2)$ samples. In particular, we show that an improper\nlearning algorithm for sparse linear regression can be used to solve sparse PCA\nproblems (with a negative spike) in their Wishart form, in regimes in which\nefficient algorithms are widely believed to require at least $\\Omega(k^2)$\nsamples. We complement our reduction with low-degree and statistical query\nlower bounds for the sparse PCA problems from which we reduce.\n  Our hardness results apply to the (correlated) random design setting in which\nthe covariates are drawn i.i.d. from a mean-zero Gaussian distribution with\nunknown covariance.\n","authors":["Rares-Darius Buhai","Jingqiu Ding","Stefan Tiegel"],"pdf_url":"https://arxiv.org/pdf/2402.14103v2.pdf","comment":"24 pages; updated typos, some explanations, and references"},{"id":"http://arxiv.org/abs/2406.17374v1","updated":"2024-06-25T08:49:07Z","published":"2024-06-25T08:49:07Z","title":"Generalizability of experimental studies","summary":"  Experimental studies are a cornerstone of machine learning (ML) research. A\ncommon, but often implicit, assumption is that the results of a study will\ngeneralize beyond the study itself, e.g. to new data. That is, there is a high\nprobability that repeating the study under different conditions will yield\nsimilar results. Despite the importance of the concept, the problem of\nmeasuring generalizability remains open. This is probably due to the lack of a\nmathematical formalization of experimental studies. In this paper, we propose\nsuch a formalization and develop a quantifiable notion of generalizability.\nThis notion allows to explore the generalizability of existing studies and to\nestimate the number of experiments needed to achieve the generalizability of\nnew studies. To demonstrate its usefulness, we apply it to two recently\npublished benchmarks to discern generalizable and non-generalizable results. We\nalso publish a Python module that allows our analysis to be repeated for other\nexperimental studies.\n","authors":["Federico Matteucci","Vadim Arzamasov","Jose Cribeiro-Ramallo","Marco Heyden","Konstantin Ntounas","Klemens Böhm"],"pdf_url":"https://arxiv.org/pdf/2406.17374v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2406.14868v2","updated":"2024-06-25T08:44:24Z","published":"2024-06-21T05:13:20Z","title":"Direct Multi-Turn Preference Optimization for Language Agents","summary":"  Adapting Large Language Models (LLMs) for agent tasks is critical in\ndeveloping language agents. Direct Preference Optimization (DPO) is a promising\ntechnique for this adaptation with the alleviation of compounding errors,\noffering a means to directly optimize Reinforcement Learning (RL) objectives.\nHowever, applying DPO to multi-turn tasks presents challenges due to the\ninability to cancel the partition function. Overcoming this obstacle involves\nmaking the partition function independent of the current state and addressing\nlength disparities between preferred and dis-preferred trajectories. In this\nlight, we replace the policy constraint with the state-action occupancy measure\nconstraint in the RL objective and add length normalization to the\nBradley-Terry model, yielding a novel loss function named DMPO for multi-turn\nagent tasks with theoretical explanations. Extensive experiments on three\nmulti-turn agent task datasets confirm the effectiveness and superiority of the\nDMPO loss.\n","authors":["Wentao Shi","Mengqi Yuan","Junkang Wu","Qifan Wang","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2406.14868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13418v2","updated":"2024-06-25T08:26:33Z","published":"2024-02-20T23:06:21Z","title":"Efficiently Predicting Mutational Effect on Homologous Proteins by\n  Evolution Encoding","summary":"  Predicting protein properties is paramount for biological and medical\nadvancements. Current protein engineering mutates on a typical protein, called\nthe wild-type, to construct a family of homologous proteins and study their\nproperties. Yet, existing methods easily neglect subtle mutations, failing to\ncapture the effect on the protein properties. To this end, we propose EvolMPNN,\nEvolution-aware Message Passing Neural Network, an efficient model to learn\nevolution-aware protein embeddings. EvolMPNN samples sets of anchor proteins,\ncomputes evolutionary information by means of residues and employs a\ndifferentiable evolution-aware aggregation scheme over these sampled anchors.\nThis way, EvolMPNN can efficiently utilise a novel message-passing method to\ncapture the mutation effect on proteins with respect to the anchor proteins.\nAfterwards, the aggregated evolution-aware embeddings are integrated with\nsequence embeddings to generate final comprehensive protein embeddings. Our\nmodel shows up to 6.4% better than state-of-the-art methods and attains 36X\ninference speedup in comparison with large pre-trained models. Code and models\nare available at https://github.com/zhiqiangzhongddu/EvolMPNN.\n","authors":["Zhiqiang Zhong","Davide Mottin"],"pdf_url":"https://arxiv.org/pdf/2402.13418v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13414v2","updated":"2024-06-25T08:26:19Z","published":"2024-02-20T22:50:41Z","title":"Harnessing Large Language Models as Post-hoc Correctors","summary":"  As Machine Learning (ML) models grow in size and demand higher-quality\ntraining data, the expenses associated with re-training and fine-tuning these\nmodels are escalating rapidly. Inspired by recent impressive achievements of\nLarge Language Models (LLMs) in different fields, this paper delves into the\nquestion: can LLMs efficiently improve an ML's performance at a minimal cost?\nWe show that, through our proposed training-free framework LlmCorr, an LLM can\nwork as a post-hoc corrector to propose corrections for the predictions of an\narbitrary ML model. In particular, we form a contextual knowledge database by\nincorporating the dataset's label information and the ML model's predictions on\nthe validation dataset. Leveraging the in-context learning capability of LLMs,\nwe ask the LLM to summarise the instances in which the ML model makes mistakes\nand the correlation between primary predictions and true labels. Following\nthis, the LLM can transfer its acquired knowledge to suggest corrections for\nthe ML model's predictions. Our experimental results on text analysis and the\nchallenging molecular predictions show that \\model improves the performance of\na number of models by up to 39%.\n","authors":["Zhiqiang Zhong","Kuangyu Zhou","Davide Mottin"],"pdf_url":"https://arxiv.org/pdf/2402.13414v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17352v1","updated":"2024-06-25T08:11:22Z","published":"2024-06-25T08:11:22Z","title":"Development of a digital tool for monitoring the behaviour of pre-weaned\n  calves using accelerometer neck-collars","summary":"  Automatic monitoring of calf behaviour is a promising way of assessing animal\nwelfare from their first week on farms. This study aims to (i) develop machine\nlearning models from accelerometer data to classify the main behaviours of\npre-weaned calves and (ii) set up a digital tool for monitoring the behaviour\nof pre-weaned calves from the models' prediction. Thirty pre-weaned calves were\nequipped with a 3-D accelerometer attached to a neck-collar for two months and\nfilmed simultaneously. The behaviours were annotated, resulting in 27.4 hours\nof observation aligned with the accelerometer data. The time-series were then\nsplit into 3 seconds windows. Two machine learning models were tuned using data\nfrom 80% of the calves: (i) a Random Forest model to classify between active\nand inactive behaviours using a set of 11 hand-craft features [model 1] and\n(ii) a RidgeClassifierCV model to classify between lying, running, drinking\nmilk and other behaviours using ROCKET features [model 2]. The performance of\nthe models was tested using data from the remaining 20% of the calves. Model 1\nachieved a balanced accuracy of 0.92. Model 2 achieved a balanced accuracy of\n0.84. Behavioural metrics such as daily activity ratio and episodes of running,\nlying, drinking milk, and other behaviours expressed over time were deduced\nfrom the predictions. All the development was finally embedded into a Python\ndashboard so that the individual calf metrics could be displayed directly from\nthe raw accelerometer files.\n","authors":["Oshana Dissanayake","Sarah E. Mcpherson","Joseph Allyndrée","Emer Kennedy","Pádraig Cunningham","Lucile Riaboff"],"pdf_url":"https://arxiv.org/pdf/2406.17352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17346v1","updated":"2024-06-25T07:59:29Z","published":"2024-06-25T07:59:29Z","title":"Stacked Confusion Reject Plots (SCORE)","summary":"  Machine learning is more and more applied in critical application areas like\nhealth and driver assistance. To minimize the risk of wrong decisions, in such\napplications it is necessary to consider the certainty of a classification to\nreject uncertain samples. An established tool for this are reject curves that\nvisualize the trade-off between the number of rejected samples and\nclassification performance metrics. We argue that common reject curves are too\nabstract and hard to interpret by non-experts. We propose Stacked Confusion\nReject Plots (SCORE) that offer a more intuitive understanding of the used data\nand the classifier's behavior. We present example plots on artificial Gaussian\ndata to document the different options of SCORE and provide the code as a\nPython package.\n","authors":["Stephan Hasler","Lydia Fischer"],"pdf_url":"https://arxiv.org/pdf/2406.17346v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.17341v1","updated":"2024-06-25T07:54:32Z","published":"2024-06-25T07:54:32Z","title":"Generative Modelling of Structurally Constrained Graphs","summary":"  Graph diffusion models have emerged as state-of-the-art techniques in graph\ngeneration, yet integrating domain knowledge into these models remains\nchallenging. Domain knowledge is particularly important in real-world\nscenarios, where invalid generated graphs hinder deployment in practical\napplications. Unconstrained and conditioned graph generative models fail to\nguarantee such domain-specific structural properties. We present ConStruct, a\nnovel framework that allows for hard-constraining graph diffusion models to\nincorporate specific properties, such as planarity or acyclicity. Our approach\nensures that the sampled graphs remain within the domain of graphs that verify\nthe specified property throughout the entire trajectory in both the forward and\nreverse processes. This is achieved by introducing a specific edge-absorbing\nnoise model and a new projector operator. ConStruct demonstrates versatility\nacross several structural and edge-deletion invariant constraints and achieves\nstate-of-the-art performance for both synthetic benchmarks and attributed\nreal-world datasets. For example, by leveraging planarity in digital pathology\ngraph datasets, the proposed method outperforms existing baselines and enhances\ngenerated data validity by up to 71.1 percentage points.\n","authors":["Manuel Madeira","Clement Vignac","Dorina Thanou","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2406.17341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17338v1","updated":"2024-06-25T07:50:09Z","published":"2024-06-25T07:50:09Z","title":"Robustly Optimized Deep Feature Decoupling Network for Fatty Liver\n  Diseases Detection","summary":"  Current medical image classification efforts mainly aim for higher average\nperformance, often neglecting the balance between different classes. This can\nlead to significant differences in recognition accuracy between classes and\nobvious recognition weaknesses. Without the support of massive data, deep\nlearning faces challenges in fine-grained classification of fatty liver. In\nthis paper, we propose an innovative deep learning framework that combines\nfeature decoupling and adaptive adversarial training. Firstly, we employ two\niteratively compressed decouplers to supervised decouple common features and\nspecific features related to fatty liver in abdominal ultrasound images.\nSubsequently, the decoupled features are concatenated with the original image\nafter transforming the color space and are fed into the classifier. During\nadversarial training, we adaptively adjust the perturbation and balance the\nadversarial strength by the accuracy of each class. The model will eliminate\nrecognition weaknesses by correctly classifying adversarial samples, thus\nimproving recognition robustness. Finally, the accuracy of our method improved\nby 4.16%, achieving 82.95%. As demonstrated by extensive experiments, our\nmethod is a generalized learning framework that can be directly used to\neliminate the recognition weaknesses of any classifier while improving its\naverage performance. Code is available at https://github.com/HP-ML/MICCAI2024.\n","authors":["Peng Huang","Shu Hu","Bo Peng","Jiashu Zhang","Xi Wu","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17338v1.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2404.17990v2","updated":"2024-06-25T07:46:30Z","published":"2024-04-27T19:40:35Z","title":"TabVFL: Improving Latent Representation in Vertical Federated Learning","summary":"  Autoencoders are popular neural networks that are able to compress high\ndimensional data to extract relevant latent information. TabNet is a\nstate-of-the-art neural network model designed for tabular data that utilizes\nan autoencoder architecture for training. Vertical Federated Learning (VFL) is\nan emerging distributed machine learning paradigm that allows multiple parties\nto train a model collaboratively on vertically partitioned data while\nmaintaining data privacy. The existing design of training autoencoders in VFL\nis to train a separate autoencoder in each participant and aggregate the latent\nrepresentation later. This design could potentially break important\ncorrelations between feature data of participating parties, as each autoencoder\nis trained on locally available features while disregarding the features of\nothers. In addition, traditional autoencoders are not specifically designed for\ntabular data, which is ubiquitous in VFL settings. Moreover, the impact of\nclient failures during training on the model robustness is under-researched in\nthe VFL scene. In this paper, we propose TabVFL, a distributed framework\ndesigned to improve latent representation learning using the joint features of\nparticipants. The framework (i) preserves privacy by mitigating potential data\nleakage with the addition of a fully-connected layer, (ii) conserves feature\ncorrelations by learning one latent representation vector, and (iii) provides\nenhanced robustness against client failures during training phase. Extensive\nexperiments on five classification datasets show that TabVFL can outperform the\nprior work design, with 26.12% of improvement on f1-score.\n","authors":["Mohamed Rashad","Zilong Zhao","Jeremie Decouchant","Lydia Y. Chen"],"pdf_url":"https://arxiv.org/pdf/2404.17990v2.pdf","comment":"This document is a preprint of a paper accepted at IEEE SRDS 2024"},{"id":"http://arxiv.org/abs/2406.17335v1","updated":"2024-06-25T07:45:00Z","published":"2024-06-25T07:45:00Z","title":"A Thorough Performance Benchmarking on Lightweight Embedding-based\n  Recommender Systems","summary":"  Since the creation of the Web, recommender systems (RSs) have been an\nindispensable mechanism in information filtering. State-of-the-art RSs\nprimarily depend on categorical features, which ecoded by embedding vectors,\nresulting in excessively large embedding tables. To prevent over-parameterized\nembedding tables from harming scalability, both academia and industry have seen\nincreasing efforts in compressing RS embeddings. However, despite the\nprosperity of lightweight embedding-based RSs (LERSs), a wide diversity is seen\nin evaluation protocols, resulting in obstacles when relating LERS performance\nto real-world usability. Moreover, despite the common goal of lightweight\nembeddings, LERSs are evaluated with a single choice between the two main\nrecommendation tasks -- collaborative filtering and content-based\nrecommendation. This lack of discussions on cross-task transferability hinders\nthe development of unified, more scalable solutions. Motivated by these issues,\nthis study investigates various LERSs' performance, efficiency, and cross-task\ntransferability via a thorough benchmarking process. Additionally, we propose\nan efficient embedding compression method using magnitude pruning, which is an\neasy-to-deploy yet highly competitive baseline that outperforms various complex\nLERSs. Our study reveals the distinct performance of LERSs across the two\ntasks, shedding light on their effectiveness and generalizability. To support\nedge-based recommendations, we tested all LERSs on a Raspberry Pi 4, where the\nefficiency bottleneck is exposed. Finally, we conclude this paper with critical\nsummaries of LERS performance, model selection suggestions, and underexplored\nchallenges around LERSs for future research. To encourage future research, we\npublish source codes and artifacts at \\href{this\nlink}{https://github.com/chenxing1999/recsys-benchmark}.\n","authors":["Hung Vinh Tran","Tong Chen","Quoc Viet Hung Nguyen","Zi Huang","Lizhen Cui","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2406.17335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17879v4","updated":"2024-06-25T07:44:31Z","published":"2023-03-31T08:26:18Z","title":"CoSMo: a Framework to Instantiate Conditioned Process Simulation Models","summary":"  Process simulation is gaining attention for its ability to assess potential\nperformance improvements and risks associated with business process changes.\nThe existing literature presents various techniques, generally grounded in\nprocess models discovered from event log data or built upon deep learning\nalgorithms. These techniques have specific strengths and limitations.\nTraditional data-driven approaches offer increased interpretability, while deep\nlearning-based excel at generalizing changes across large event logs. However,\nthe practical application of deep learning faces challenges related to managing\nstochasticity and integrating information for what-if analysis. This paper\nintroduces a novel recurrent neural architecture tailored to discover\nCOnditioned process Simulation MOdels (CoSMo) based on user-based constraints\nor any other nature of a-priori knowledge. This architecture facilitates the\nsimulation of event logs that adhere to specific constraints by incorporating\ndeclarative-based rules into the learning phase as an attempt to fill the gap\nof incorporating information into deep learning models to perform what-if\nanalysis. Experimental validation illustrates CoSMo's efficacy in simulating\nevent logs while adhering to predefined declarative conditions, emphasizing\nboth control-flow and data-flow perspectives.\n","authors":["Rafael S. Oyamada","Gabriel M. Tavares","Sylvio Barbon Junior","Paolo Ceravolo"],"pdf_url":"https://arxiv.org/pdf/2303.17879v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13584v3","updated":"2024-06-25T07:42:54Z","published":"2023-01-31T12:31:13Z","title":"Straight-Through meets Sparse Recovery: the Support Exploration\n  Algorithm","summary":"  The {\\it straight-through estimator} (STE) is commonly used to optimize\nquantized neural networks, yet its contexts of effective performance are still\nunclear despite empirical successes.To make a step forward in this\ncomprehension, we apply STE to a well-understood problem: {\\it sparse support\nrecovery}. We introduce the {\\it Support Exploration Algorithm} (SEA), a novel\nalgorithm promoting sparsity, and we analyze its performance in support\nrecovery (a.k.a. model selection) problems. SEA explores more supports than the\nstate-of-the-art, leading to superior performance in experiments, especially\nwhen the columns of $A$ are strongly coherent.The theoretical analysis\nconsiders recovery guarantees when the linear measurements matrix $A$ satisfies\nthe {\\it Restricted Isometry Property} (RIP).The sufficient conditions of\nrecovery are comparable but more stringent than those of the state-of-the-art\nin sparse support recovery. Their significance lies mainly in their\napplicability to an instance of the STE.\n","authors":["Mimoun Mohamed","François Malgouyres","Valentin Emiya","Caroline Chaux"],"pdf_url":"https://arxiv.org/pdf/2301.13584v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12193v2","updated":"2024-06-25T07:25:23Z","published":"2024-06-18T01:47:38Z","title":"Adaptive Collaborative Correlation Learning-based Semi-Supervised\n  Multi-Label Feature Selection","summary":"  Semi-supervised multi-label feature selection has recently been developed to\nsolve the curse of dimensionality problem in high-dimensional multi-label data\nwith certain samples missing labels. Although many efforts have been made, most\nexisting methods use a predefined graph approach to capture the sample\nsimilarity or the label correlation. In this manner, the presence of noise and\noutliers within the original feature space can undermine the reliability of the\nresulting sample similarity graph. It also fails to precisely depict the label\ncorrelation due to the existence of unknown labels. Besides, these methods only\nconsider the discriminative power of selected features, while neglecting their\nredundancy. In this paper, we propose an Adaptive Collaborative Correlation\nlEarning-based Semi-Supervised Multi-label Feature Selection (Access-MFS)\nmethod to address these issues. Specifically, a generalized regression model\nequipped with an extended uncorrelated constraint is introduced to select\ndiscriminative yet irrelevant features and maintain consistency between\npredicted and ground-truth labels in labeled data, simultaneously. Then, the\ninstance correlation and label correlation are integrated into the proposed\nregression model to adaptively learn both the sample similarity graph and the\nlabel similarity graph, which mutually enhance feature selection performance.\nExtensive experimental results demonstrate the superiority of the proposed\nAccess-MFS over other state-of-the-art methods.\n","authors":["Yanyong Huang","Li Yang","Dongjie Wang","Ke Li","Xiuwen Yi","Fengmao Lv","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2406.12193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17323v1","updated":"2024-06-25T07:14:15Z","published":"2024-06-25T07:14:15Z","title":"XAMI -- A Benchmark Dataset for Artefact Detection in XMM-Newton Optical\n  Images","summary":"  Reflected or scattered light produce artefacts in astronomical observations\nthat can negatively impact the scientific study. Hence, automated detection of\nthese artefacts is highly beneficial, especially with the increasing amounts of\ndata gathered. Machine learning methods are well-suited to this problem, but\ncurrently there is a lack of annotated data to train such approaches to detect\nartefacts in astronomical observations. In this work, we present a dataset of\nimages from the XMM-Newton space telescope Optical Monitoring camera showing\ndifferent types of artefacts. We hand-annotated a sample of 1000 images with\nartefacts which we use to train automated ML methods. We further demonstrate\ntechniques tailored for accurate detection and masking of artefacts using\ninstance segmentation. We adopt a hybrid approach, combining knowledge from\nboth convolutional neural networks (CNNs) and transformer-based models and use\ntheir advantages in segmentation. The presented method and dataset will advance\nartefact detection in astronomical observations by providing a reproducible\nbaseline. All code and data are made available\n(https://github.com/ESA-Datalabs/XAMI-model and\nhttps://github.com/ESA-Datalabs/XAMI-dataset).\n","authors":["Elisabeta-Iulia Dima","Pablo Gómez","Sandor Kruk","Peter Kretschmar","Simon Rosen","Călin-Adrian Popa"],"pdf_url":"https://arxiv.org/pdf/2406.17323v1.pdf","comment":"submitted to SPAICE 2024"},{"id":"http://arxiv.org/abs/2406.17322v1","updated":"2024-06-25T07:14:14Z","published":"2024-06-25T07:14:14Z","title":"ALPBench: A Benchmark for Active Learning Pipelines on Tabular Data","summary":"  In settings where only a budgeted amount of labeled data can be afforded,\nactive learning seeks to devise query strategies for selecting the most\ninformative data points to be labeled, aiming to enhance learning algorithms'\nefficiency and performance. Numerous such query strategies have been proposed\nand compared in the active learning literature. However, the community still\nlacks standardized benchmarks for comparing the performance of different query\nstrategies. This particularly holds for the combination of query strategies\nwith different learning algorithms into active learning pipelines and examining\nthe impact of the learning algorithm choice. To close this gap, we propose\nALPBench, which facilitates the specification, execution, and performance\nmonitoring of active learning pipelines. It has built-in measures to ensure\nevaluations are done reproducibly, saving exact dataset splits and\nhyperparameter settings of used algorithms. In total, ALPBench consists of 86\nreal-world tabular classification datasets and 5 active learning settings,\nyielding 430 active learning problems. To demonstrate its usefulness and broad\ncompatibility with various learning algorithms and query strategies, we conduct\nan exemplary study evaluating 9 query strategies paired with 8 learning\nalgorithms in 2 different settings. We provide ALPBench here:\nhttps://github.com/ValentinMargraf/ActiveLearningPipelines.\n","authors":["Valentin Margraf","Marcel Wever","Sandra Gilhuber","Gabriel Marques Tavares","Thomas Seidl","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2406.17322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.14642v5","updated":"2024-06-25T07:08:34Z","published":"2021-06-28T12:41:45Z","title":"Expert Q-learning: Deep Reinforcement Learning with Coarse State Values\n  from Offline Expert Examples","summary":"  In this article, we propose a novel algorithm for deep reinforcement learning\nnamed Expert Q-learning. Expert Q-learning is inspired by Dueling Q-learning\nand aims at incorporating semi-supervised learning into reinforcement learning\nthrough splitting Q-values into state values and action advantages. We require\nthat an offline expert assesses the value of a state in a coarse manner using\nthree discrete values. An expert network is designed in addition to the\nQ-network, which updates each time following the regular offline minibatch\nupdate whenever the expert example buffer is not empty. Using the board game\nOthello, we compare our algorithm with the baseline Q-learning algorithm, which\nis a combination of Double Q-learning and Dueling Q-learning. Our results show\nthat Expert Q-learning is indeed useful and more resistant to the\noverestimation bias. The baseline Q-learning algorithm exhibits unstable and\nsuboptimal behavior in non-deterministic settings, whereas Expert Q-learning\ndemonstrates more robust performance with higher scores, illustrating that our\nalgorithm is indeed suitable to integrate state values from expert examples\ninto Q-learning.\n","authors":["Li Meng","Anis Yazidi","Morten Goodwin","Paal Engelstad"],"pdf_url":"https://arxiv.org/pdf/2106.14642v5.pdf","comment":"Camera-ready version"},{"id":"http://arxiv.org/abs/2310.07710v2","updated":"2024-06-25T07:08:17Z","published":"2023-10-11T17:57:35Z","title":"A Resilient and Accessible Distribution-Preserving Watermark for Large\n  Language Models","summary":"  Watermarking techniques offer a promising way to identify machine-generated\ncontent via embedding covert information into the contents generated from\nlanguage models. A challenge in the domain lies in preserving the distribution\nof original generated content after watermarking. Our research extends and\nimproves upon existing watermarking framework, placing emphasis on the\nimportance of a \\textbf{Di}stribution-\\textbf{P}reserving (DiP) watermark.\nContrary to the current strategies, our proposed DiPmark simultaneously\npreserves the original token distribution during watermarking\n(distribution-preserving), is detectable without access to the language model\nAPI and prompts (accessible), and is provably robust to moderate changes of\ntokens (resilient). DiPmark operates by selecting a random set of tokens prior\nto the generation of a word, then modifying the token distribution through a\ndistribution-preserving reweight function to enhance the probability of these\nselected tokens during the sampling process. Extensive empirical evaluation on\nvarious language models and tasks demonstrates our approach's\ndistribution-preserving property, accessibility, and resilience, making it a\neffective solution for watermarking tasks that demand impeccable quality\npreservation.\n","authors":["Yihan Wu","Zhengmian Hu","Junfeng Guo","Hongyang Zhang","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2310.07710v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.17316v1","updated":"2024-06-25T06:57:47Z","published":"2024-06-25T06:57:47Z","title":"A review of unsupervised learning in astronomy","summary":"  This review summarizes popular unsupervised learning methods, and gives an\noverview of their past, current, and future uses in astronomy. Unsupervised\nlearning aims to organise the information content of a dataset, in such a way\nthat knowledge can be extracted. Traditionally this has been achieved through\ndimensionality reduction techniques that aid the ranking of a dataset, for\nexample through principal component analysis or by using auto-encoders, or\nsimpler visualisation of a high dimensional space, for example through the use\nof a self organising map. Other desirable properties of unsupervised learning\ninclude the identification of clusters, i.e. groups of similar objects, which\nhas traditionally been achieved by the k-means algorithm and more recently\nthrough density-based clustering such as HDBSCAN. More recently, complex\nframeworks have emerged, that chain together dimensionality reduction and\nclustering methods. However, no dataset is fully unknown. Thus, nowadays a lot\nof research has been directed towards self-supervised and semi-supervised\nmethods that stand to gain from both supervised and unsupervised learning.\n","authors":["Sotiria Fotopoulou"],"pdf_url":"https://arxiv.org/pdf/2406.17316v1.pdf","comment":"30 pages, 6 figures. Invited contribution to special issue in\n  Astronomy & Computing"},{"id":"http://arxiv.org/abs/2406.17308v1","updated":"2024-06-25T06:41:09Z","published":"2024-06-25T06:41:09Z","title":"Improving Realized LGD Approximation: A Novel Framework with XGBoost for\n  Handling Missing Cash-Flow Data","summary":"  The scope for the accurate calculation of the Loss Given Default (LGD)\nparameter is comprehensive in terms of financial data. In this research, we aim\nto explore methods for improving the approximation of realized LGD in\nconditions of limited access to the cash-flow data. We enhance the performance\nof the method which relies on the differences between exposure values (delta\noutstanding approach) by employing machine learning (ML) techniques. The\nresearch utilizes the data from the mortgage portfolio of one of the European\ncountries and assumes a close resemblance to similar economic contexts. It\nincorporates non-financial variables and macroeconomic data related to the\nhousing market, improving the accuracy of loss severity approximation. The\nproposed methodology attempts to mitigate the country-specific (related to the\nlocal legal) or portfolio-specific factors in aim to show the general advantage\nof applying ML techniques, rather than case-specific relation. We developed an\nXGBoost model that does not rely on cash-flow data yet enhances the accuracy of\nrealized LGD estimation compared to results obtained with the delta outstanding\napproach. A novel aspect of our work is the detailed exploration of the delta\noutstanding approach and the methodology for addressing conditions of limited\naccess to cash-flow data through machine learning models.\n","authors":["Zuzanna Kostecka","Robert Ślepaczuk"],"pdf_url":"https://arxiv.org/pdf/2406.17308v1.pdf","comment":"36 pages, 5 figures, 9 tables"},{"id":"http://arxiv.org/abs/2101.11932v5","updated":"2024-06-25T06:24:52Z","published":"2021-01-28T11:09:40Z","title":"Approximation Theory of Tree Tensor Networks: Tensorized Multivariate\n  Functions","summary":"  We study the approximation of multivariate functions with tensor networks\n(TNs). The main conclusion of this work is an answer to the following two\nquestions: ``What are the approximation capabilities of TNs?\" and \"What is an\nappropriate model class of functions that can be approximated with TNs?\"\n  To answer the former, we show that TNs can (near to) optimally replicate\n$h$-uniform and $h$-adaptive approximation, for any smoothness order of the\ntarget function. Tensor networks thus exhibit universal expressivity w.r.t.\nisotropic, anisotropic and mixed smoothness spaces that is comparable with more\ngeneral neural networks families such as deep rectified linear unit (ReLU)\nnetworks. Put differently, TNs have the capacity to (near to) optimally\napproximate many function classes -- without being adapted to the particular\nclass in question.\n  To answer the latter, as a candidate model class we consider approximation\nclasses of TNs and show that these are (quasi-)Banach spaces, that many types\nof classical smoothness spaces are continuously embedded into said\napproximation classes and that TN approximation classes are themselves not\nembedded in any classical smoothness space.\n","authors":["Mazen Ali","Anthony Nouy"],"pdf_url":"https://arxiv.org/pdf/2101.11932v5.pdf","comment":"This work is a continuation of M. Ali and A. Nouy. Approximation\n  theory of tree tensor networks: Tensorized univariate functions. Constructive\n  Approximation, 58(2):463-544, 2023. It is also available in two parts on\n  arXiv: for part I see arXiv:2007.00118, for part II see arXiv:2007.00128"},{"id":"http://arxiv.org/abs/2306.02568v3","updated":"2024-06-25T06:13:38Z","published":"2023-06-05T03:47:59Z","title":"Latent Optimal Paths by Gumbel Propagation for Variational Bayesian\n  Dynamic Programming","summary":"  We propose the stochastic optimal path which solves the classical optimal\npath problem by a probability-softening solution. This unified approach\ntransforms a wide range of DP problems into directed acyclic graphs in which\nall paths follow a Gibbs distribution. We show the equivalence of the Gibbs\ndistribution to a message-passing algorithm by the properties of the Gumbel\ndistribution and give all the ingredients required for variational Bayesian\ninference of a latent path, namely Bayesian dynamic programming (BDP). We\ndemonstrate the usage of BDP in the latent space of variational autoencoders\n(VAEs) and propose the BDP-VAE which captures structured sparse optimal paths\nas latent variables. This enables end-to-end training for generative tasks in\nwhich models rely on unobserved structural information. At last, we validate\nthe behavior of our approach and showcase its applicability in two real-world\napplications: text-to-speech and singing voice synthesis. Our implementation\ncode is available at\n\\url{https://github.com/XinleiNIU/LatentOptimalPathsBayesianDP}.\n","authors":["Xinlei Niu","Christian Walder","Jing Zhang","Charles Patrick Martin"],"pdf_url":"https://arxiv.org/pdf/2306.02568v3.pdf","comment":"Accepted by ICML 2024"},{"id":"http://arxiv.org/abs/2406.17298v1","updated":"2024-06-25T06:04:58Z","published":"2024-06-25T06:04:58Z","title":"Towards Efficient and Scalable Training of Differentially Private Deep\n  Learning","summary":"  Differentially private stochastic gradient descent (DP-SGD) is the standard\nalgorithm for training machine learning models under differential privacy (DP).\nThe major drawback of DP-SGD is the drop in utility which prior work has\ncomprehensively studied. However, in practice another major drawback that\nhinders the large-scale deployment is the significantly higher computational\ncost. We conduct a comprehensive empirical study to quantify the computational\ncost of training deep learning models under DP and benchmark methods that aim\nat reducing the cost. Among these are more efficient implementations of DP-SGD\nand training with lower precision. Finally, we study the scaling behaviour\nusing up to 80 GPUs.\n","authors":["Sebastian Rodriguez Beltran","Marlon Tobaben","Niki Loppi","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2406.17298v1.pdf","comment":"15 pages, 12 figures, Accepted to the Workshop on Advancing Neural\n  Network Training at International Conference on Machine Learning (WANT@ICML\n  2024)"},{"id":"http://arxiv.org/abs/2406.17296v1","updated":"2024-06-25T05:45:12Z","published":"2024-06-25T05:45:12Z","title":"BlockLLM: Memory-Efficient Adaptation of LLMs by Selecting and\n  Optimizing the Right Coordinate Blocks","summary":"  Training large language models (LLMs) for pretraining or adapting to new\ntasks and domains has become increasingly critical as their applications\nexpand. However, as the model and the data sizes grow, the training process\npresents significant memory challenges, often requiring a prohibitive amount of\nGPU memory that may not be readily available. Existing methods such as low-rank\nadaptation (LoRA) add trainable low-rank matrix factorizations, altering the\ntraining dynamics and limiting the model's parameter search to a low-rank\nsubspace. GaLore, a more recent method, employs Gradient Low-Rank Projection to\nreduce the memory footprint, in the full parameter training setting. However\nGaLore can only be applied to a subset of the LLM layers that satisfy the\n\"reversibility\" property, thus limiting their applicability. In response to\nthese challenges, we introduce BlockLLM, an approach inspired by block\ncoordinate descent. Our method carefully selects and updates a very small\nsubset of the trainable parameters without altering any part of its\narchitecture and training procedure. BlockLLM achieves state-of-the-art\nperformance in both finetuning and pretraining tasks, while reducing the memory\nfootprint of the underlying optimization process. Our experiments demonstrate\nthat fine-tuning with only less than 5% of the parameters, BlockLLM achieves\nstate-of-the-art perplexity scores on the GLUE benchmarks. On Llama model\npretrained on C4 dataset, BlockLLM is able to train with significantly less\nmemory than the state-of-the-art, while still maintaining competitive\nperformance.\n","authors":["Amrutha Varshini Ramesh","Vignesh Ganapathiraman","Issam H. Laradji","Mark Schmidt"],"pdf_url":"https://arxiv.org/pdf/2406.17296v1.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.17295v1","updated":"2024-06-25T05:45:07Z","published":"2024-06-25T05:45:07Z","title":"MatText: Do Language Models Need More than Text & Scale for Materials\n  Modeling?","summary":"  Effectively representing materials as text has the potential to leverage the\nvast advancements of large language models (LLMs) for discovering new\nmaterials. While LLMs have shown remarkable success in various domains, their\napplication to materials science remains underexplored. A fundamental challenge\nis the lack of understanding of how to best utilize text-based representations\nfor materials modeling. This challenge is further compounded by the absence of\na comprehensive benchmark to rigorously evaluate the capabilities and\nlimitations of these text representations in capturing the complexity of\nmaterial systems. To address this gap, we propose MatText, a suite of\nbenchmarking tools and datasets designed to systematically evaluate the\nperformance of language models in modeling materials. MatText encompasses nine\ndistinct text-based representations for material systems, including several\nnovel representations. Each representation incorporates unique inductive biases\nthat capture relevant information and integrate prior physical knowledge about\nmaterials. Additionally, MatText provides essential tools for training and\nbenchmarking the performance of language models in the context of materials\nscience. These tools include standardized dataset splits for each\nrepresentation, probes for evaluating sensitivity to geometric factors, and\ntools for seamlessly converting crystal structures into text. Using MatText, we\nconduct an extensive analysis of the capabilities of language models in\nmodeling materials. Our findings reveal that current language models\nconsistently struggle to capture the geometric information crucial for\nmaterials modeling across all representations. Instead, these models tend to\nleverage local information, which is emphasized in some of our novel\nrepresentations. Our analysis underscores MatText's ability to reveal\nshortcomings of text-based methods for materials design.\n","authors":["Nawaf Alampara","Santiago Miret","Kevin Maik Jablonka"],"pdf_url":"https://arxiv.org/pdf/2406.17295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17285v1","updated":"2024-06-25T05:23:41Z","published":"2024-06-25T05:23:41Z","title":"EON-1: A Brain-Inspired Processor for Near-Sensor Extreme Edge Online\n  Feature Extraction","summary":"  For Edge AI applications, deploying online learning and adaptation on\nresource-constrained embedded devices can deal with fast sensor-generated\nstreams of data in changing environments. However, since maintaining\nlow-latency and power-efficient inference is paramount at the Edge, online\nlearning and adaptation on the device should impose minimal additional overhead\nfor inference. With this goal in mind, we explore energy-efficient learning and\nadaptation on-device for streaming-data Edge AI applications using Spiking\nNeural Networks (SNNs), which follow the principles of brain-inspired\ncomputing, such as high-parallelism, neuron co-located memory and compute, and\nevent-driven processing. We propose EON-1, a brain-inspired processor for\nnear-sensor extreme edge online feature extraction, that integrates a fast\nonline learning and adaptation algorithm. We report results of only 1% energy\noverhead for learning, by far the lowest overhead when compared to other SoTA\nsolutions, while attaining comparable inference accuracy. Furthermore, we\ndemonstrate that EON-1 is up for the challenge of low-latency processing of HD\nand UHD streaming video in real-time, with learning enabled.\n","authors":["Alexandra Dobrita","Amirreza Yousefzadeh","Simon Thorpe","Kanishkan Vadivel","Paul Detterer","Guangzhi Tang","Gert-Jan van Schaik","Mario Konijnenburg","Anteneh Gebregiorgis","Said Hamdioui","Manolis Sifalakis"],"pdf_url":"https://arxiv.org/pdf/2406.17285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17281v1","updated":"2024-06-25T05:12:51Z","published":"2024-06-25T05:12:51Z","title":"Distance Recomputator and Topology Reconstructor for Graph Neural\n  Networks","summary":"  This paper introduces novel methodologies, the Distance Recomputator and\nTopology Reconstructor, aimed at enhancing Graph Neural Networks (GNNs). The\nDistance Recomputator dynamically recalibrates node distances within k-hop\nneighborhoods using a dynamic encoding scheme, thereby improving the accuracy\nand adaptability of node representations. Concurrently, the Topology\nReconstructor adjusts local graph structures based on computed \"similarity\ndistances,\" optimizing network configurations for improved learning outcomes.\nThese methods address the limitations of static node representations and fixed\naggregation schemes in traditional GNNs, offering a more nuanced approach to\nmodeling complex and dynamic graph topologies.\n  Furthermore, our experimental evaluations demonstrate significant performance\nadvantages over existing methods across various benchmark datasets. The\nproposed Distance Recomputator and Topology Reconstructor not only enhance node\nrelationship modeling accuracy but also optimize information aggregation\nefficiency through an asynchronous aggregation mechanism. This approach proves\nparticularly effective in scenarios involving dynamic or large-scale graphs,\nshowcasing the methods' robustness and applicability in real-world graph\nlearning tasks.\n","authors":["Dong Liu","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.17281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.05519v3","updated":"2024-06-25T05:01:09Z","published":"2023-09-11T15:02:25Z","title":"NExT-GPT: Any-to-Any Multimodal LLM","summary":"  While recently Multimodal Large Language Models (MM-LLMs) have made exciting\nstrides, they mostly fall prey to the limitation of only input-side multimodal\nunderstanding, without the ability to produce content in multiple modalities.\nAs we humans always perceive the world and communicate with people through\nvarious modalities, developing any-to-any MM-LLMs capable of accepting and\ndelivering content in any modality becomes essential to human-level AI. To fill\nthe gap, we present an end-to-end general-purpose any-to-any MM-LLM system,\nNExT-GPT. We connect an LLM with multimodal adaptors and different diffusion\ndecoders, enabling NExT-GPT to perceive inputs and generate outputs in\narbitrary combinations of text, images, videos, and audio. By leveraging the\nexisting well-trained highly-performing encoders and decoders, NExT-GPT is\ntuned with only a small amount of parameter (1%) of certain projection layers,\nwhich not only benefits low-cost training and also facilitates convenient\nexpansion to more potential modalities. Moreover, we introduce a\nmodality-switching instruction tuning (MosIT) and manually curate a\nhigh-quality dataset for MosIT, based on which NExT-GPT is empowered with\ncomplex cross-modal semantic understanding and content generation. Overall, our\nresearch showcases the promising possibility of building an AI agent capable of\nmodeling universal modalities, paving the way for more human-like AI research\nin the community. Project page: https://next-gpt.github.io/\n","authors":["Shengqiong Wu","Hao Fei","Leigang Qu","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2309.05519v3.pdf","comment":"ICML 2024 (Oral)"},{"id":"http://arxiv.org/abs/2308.00177v4","updated":"2024-06-25T04:41:56Z","published":"2023-07-31T22:19:45Z","title":"Pretrained deep models outperform GBDTs in Learning-To-Rank under label\n  scarcity","summary":"  On tabular data, a significant body of literature has shown that current deep\nlearning (DL) models perform at best similarly to Gradient Boosted Decision\nTrees (GBDTs), while significantly underperforming them on outlier data.\nHowever, these works often study idealized problem settings which may fail to\ncapture complexities of real-world scenarios. We identify a natural tabular\ndata setting where DL models can outperform GBDTs: tabular Learning-to-Rank\n(LTR) under label scarcity. Tabular LTR applications, including search and\nrecommendation, often have an abundance of unlabeled data, and scarce labeled\ndata. We show that DL rankers can utilize unsupervised pretraining to exploit\nthis unlabeled data. In extensive experiments over both public and proprietary\ndatasets, we show that pretrained DL rankers consistently outperform GBDT\nrankers on ranking metrics -- sometimes by as much as 38% -- both overall and\non outliers.\n","authors":["Charlie Hou","Kiran Koshy Thekumparampil","Michael Shavlovsky","Giulia Fanti","Yesh Dattatreya","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2308.00177v4.pdf","comment":"ICML-MFPL 2023 Workshop Oral, SPIGM@ICML2024"},{"id":"http://arxiv.org/abs/2406.17274v1","updated":"2024-06-25T04:41:17Z","published":"2024-06-25T04:41:17Z","title":"Can We Trust the Performance Evaluation of Uncertainty Estimation\n  Methods in Text Summarization?","summary":"  Text summarization, a key natural language generation (NLG) task, is vital in\nvarious domains. However, the high cost of inaccurate summaries in\nrisk-critical applications, particularly those involving human-in-the-loop\ndecision-making, raises concerns about the reliability of uncertainty\nestimation on text summarization (UE-TS) evaluation methods. This concern stems\nfrom the dependency of uncertainty model metrics on diverse and potentially\nconflicting NLG metrics. To address this issue, we introduce a comprehensive\nUE-TS benchmark incorporating 31 NLG metrics across four dimensions. The\nbenchmark evaluates the uncertainty estimation capabilities of two large\nlanguage models and one pre-trained language model on three datasets, with\nhuman-annotation analysis incorporated where applicable. We also assess the\nperformance of 14 common uncertainty estimation methods within this benchmark.\nOur findings emphasize the importance of considering multiple uncorrelated NLG\nmetrics and diverse uncertainty estimation methods to ensure reliable and\nefficient evaluation of UE-TS techniques.\n","authors":["Jianfeng He","Runing Yang","Linlin Yu","Changbin Li","Ruoxi Jia","Feng Chen","Ming Jin","Chang-Tien Lu"],"pdf_url":"https://arxiv.org/pdf/2406.17274v1.pdf","comment":"63 pages, 41 figures, 11 tables"},{"id":"http://arxiv.org/abs/2307.01753v3","updated":"2024-06-25T04:39:44Z","published":"2023-07-04T14:49:23Z","title":"Local primordial non-Gaussianity from the large-scale clustering of\n  photometric DESI luminous red galaxies","summary":"  We use angular clustering of luminous red galaxies from the Dark Energy\nSpectroscopic Instrument (DESI) imaging surveys to constrain the local\nprimordial non-Gaussianity parameter $\\fnl$. Our sample comprises over 12\nmillion targets, covering 14,000 square degrees of the sky, with redshifts in\nthe range $0.2< z < 1.35$. We identify Galactic extinction, survey depth, and\nastronomical seeing as the primary sources of systematic error, and employ\nlinear regression and artificial neural networks to alleviate non-cosmological\nexcess clustering on large scales. Our methods are tested against simulations\nwith and without $\\fnl$ and systematics, showing superior performance of the\nneural network treatment. The neural network with a set of nine imaging\nproperty maps passes our systematic null test criteria, and is chosen as the\nfiducial treatment. Assuming the universality relation, we find $\\fnl =\n34^{+24(+50)}_{-44(-73)}$ at 68\\%(95\\%) confidence. We apply a series of\nrobustness tests (e.g., cuts on imaging, declination, or scales used) that show\nconsistency in the obtained constraints. We study how the regression method\nbiases the measured angular power-spectrum and degrades the $\\fnl$ constraining\npower. The use of the nine maps more than doubles the uncertainty compared to\nusing only the three primary maps in the regression. Our results thus motivate\nthe development of more efficient methods that avoid over-correction, protect\nlarge-scale clustering information, and preserve constraining power.\nAdditionally, our results encourage further studies of $\\fnl$ with DESI\nspectroscopic samples, where the inclusion of 3D clustering modes should help\nseparate imaging systematics and lessen the degradation in the $\\fnl$\nuncertainty.\n","authors":["Mehdi Rezaie","Ashley J. Ross","Hee-Jong Seo","Hui Kong","Anna Porredon","Lado Samushia","Edmond Chaussidon","Alex Krolewski","Arnaud de Mattia","Florian Beutler","Jessica Nicole Aguilar","Steven Ahlen","Shadab Alam","Santiago Avila","Benedict Bahr-Kalus","Jose Bermejo-Climent","David Brooks","Todd Claybaugh","Shaun Cole","Kyle Dawson","Axel de la Macorra","Peter Doel","Andreu Font-Ribera","Jaime E. Forero-Romero","Satya Gontcho A Gontcho","Julien Guy","Klaus Honscheid","Dragan Huterer","Theodore Kisner","Martin Landriau","Michael Levi","Marc Manera","Aaron Meisner","Ramon Miquel","Eva-Maria Mueller","Adam Myers","Jeffrey A. Newman","Jundan Nie","Nathalie Palanque-Delabrouille","Will Percival","Claire Poppett","Graziano Rossi","Eusebio Sanchez","Michael Schubnell","Gregory Tarlé","Benjamin Alan Weaver","Christophe Yèche","Zhimin Zhou","Hu Zou"],"pdf_url":"https://arxiv.org/pdf/2307.01753v3.pdf","comment":"21 pages, 17 figures, 7 tables (Appendix excluded). Published in\n  MNRAS"},{"id":"http://arxiv.org/abs/2406.17272v1","updated":"2024-06-25T04:35:50Z","published":"2024-06-25T04:35:50Z","title":"A Comprehensive Solution to Connect Speech Encoder and Large Language\n  Model for ASR","summary":"  Recent works have shown promising results in connecting speech encoders to\nlarge language models (LLMs) for speech recognition. However, several\nlimitations persist, including limited fine-tuning options, a lack of\nmechanisms to enforce speech-text alignment, and high insertion errors\nespecially in domain mismatch conditions. This paper presents a comprehensive\nsolution to address these issues. We begin by investigating more thoughtful\nfine-tuning schemes. Next, we propose a matching loss to enhance alignment\nbetween modalities. Finally, we explore training and inference methods to\nmitigate high insertion errors. Experimental results on the Librispeech corpus\ndemonstrate that partially fine-tuning the encoder and LLM using\nparameter-efficient methods, such as LoRA, is the most cost-effective approach.\nAdditionally, the matching loss improves modality alignment, enhancing\nperformance. The proposed training and inference methods significantly reduce\ninsertion errors.\n","authors":["Van Tung Pham","Yist Lin","Tao Han","Wei Li","Jun Zhang","Lu Lu","Yuxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17802v2","updated":"2024-06-25T04:34:38Z","published":"2024-01-31T12:52:10Z","title":"Distillation Enhanced Time Series Forecasting Network with Momentum\n  Contrastive Learning","summary":"  Contrastive representation learning is crucial in time series analysis as it\nalleviates the issue of data noise and incompleteness as well as sparsity of\nsupervision signal. However, existing constrastive learning frameworks usually\nfocus on intral-temporal features, which fails to fully exploit the intricate\nnature of time series data. To address this issue, we propose DE-TSMCL, an\ninnovative distillation enhanced framework for long sequence time series\nforecasting. Specifically, we design a learnable data augmentation mechanism\nwhich adaptively learns whether to mask a timestamp to obtain optimized\nsub-sequences. Then, we propose a contrastive learning task with momentum\nupdate to explore inter-sample and intra-temporal correlations of time series\nto learn the underlying structure feature on the unlabeled time series.\nMeanwhile, we design a supervised task to learn more robust representations and\nfacilitate the contrastive learning process. Finally, we jointly optimize the\nabove two tasks. By developing model loss from multiple tasks, we can learn\neffective representations for downstream forecasting task. Extensive\nexperiments, in comparison with state-of-the-arts, well demonstrate the\neffectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.\n","authors":["Haozhi Gao","Qianqian Ren","Jinbao Li"],"pdf_url":"https://arxiv.org/pdf/2401.17802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16026v2","updated":"2024-06-25T04:28:09Z","published":"2024-06-23T06:23:12Z","title":"CEST-KAN: Kolmogorov-Arnold Networks for CEST MRI Data Analysis","summary":"  Purpose: This study aims to propose and investigate the feasibility of using\nKolmogorov-Arnold Network (KAN) for CEST MRI data analysis (CEST-KAN). Methods:\nCEST MRI data were acquired from twelve healthy volunteers at 3T. Data from ten\nsubjects were used for training, while the remaining two were reserved for\ntesting. The performance of multi-layer perceptron (MLP) and KAN models with\nthe same network settings were evaluated and compared to the conventional\nmulti-pool Lorentzian fitting (MPLF) method in generating water and multiple\nCEST contrasts, including amide, relayed nuclear Overhauser effect (rNOE), and\nmagnetization transfer (MT). Results: The water and CEST maps generated by both\nMLP and KAN were visually comparable to the MPLF results. However, the KAN\nmodel demonstrated higher accuracy in extrapolating the CEST fitting metrics,\nas evidenced by the smaller validation loss during training and smaller\nabsolute error during testing. Voxel-wise correlation analysis showed that all\nfour CEST fitting metrics generated by KAN consistently exhibited higher\nPearson coefficients than the MLP results, indicating superior performance.\nMoreover, the KAN models consistently outperformed the MLP models in varying\nhidden layer numbers despite longer training time. Conclusion: In this study,\nwe demonstrated for the first time the feasibility of utilizing KAN for CEST\nMRI data analysis, highlighting its superiority over MLP in this task. The\nfindings suggest that CEST-KAN has the potential to be a robust and reliable\npost-analysis tool for CEST MRI in clinical settings.\n","authors":["Jiawen Wang","Pei Cai","Ziyan Wang","Huabin Zhang","Jianpan Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16026v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17266v1","updated":"2024-06-25T04:20:49Z","published":"2024-06-25T04:20:49Z","title":"AG-LSEC: Audio Grounded Lexical Speaker Error Correction","summary":"  Speaker Diarization (SD) systems are typically audio-based and operate\nindependently of the ASR system in traditional speech transcription pipelines\nand can have speaker errors due to SD and/or ASR reconciliation, especially\naround speaker turns and regions of speech overlap. To reduce these errors, a\nLexical Speaker Error Correction (LSEC), in which an external language model\nprovides lexical information to correct the speaker errors, was recently\nproposed. Though the approach achieves good Word Diarization error rate (WDER)\nimprovements, it does not use any additional acoustic information and is prone\nto miscorrections. In this paper, we propose to enhance and acoustically ground\nthe LSEC system with speaker scores directly derived from the existing SD\npipeline. This approach achieves significant relative WDER reductions in the\nrange of 25-40% over the audio-based SD, ASR system and beats the LSEC system\nby 15-25% relative on RT03-CTS, Callhome American English and Fisher datasets.\n","authors":["Rohit Paturi","Xiang Li","Sundararajan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.17266v1.pdf","comment":"Accepted at INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.17263v1","updated":"2024-06-25T04:07:22Z","published":"2024-06-25T04:07:22Z","title":"Efficient, Multimodal, and Derivative-Free Bayesian Inference With\n  Fisher-Rao Gradient Flows","summary":"  In this paper, we study efficient approximate sampling for probability\ndistributions known up to normalization constants. We specifically focus on a\nproblem class arising in Bayesian inference for large-scale inverse problems in\nscience and engineering applications. The computational challenges we address\nwith the proposed methodology are: (i) the need for repeated evaluations of\nexpensive forward models; (ii) the potential existence of multiple modes; and\n(iii) the fact that gradient of, or adjoint solver for, the forward model might\nnot be feasible.\n  While existing Bayesian inference methods meet some of these challenges\nindividually, we propose a framework that tackles all three systematically. Our\napproach builds upon the Fisher-Rao gradient flow in probability space,\nyielding a dynamical system for probability densities that converges towards\nthe target distribution at a uniform exponential rate. This rapid convergence\nis advantageous for the computational burden outlined in (i). We apply Gaussian\nmixture approximations with operator splitting techniques to simulate the flow\nnumerically; the resulting approximation can capture multiple modes thus\naddressing (ii). Furthermore, we employ the Kalman methodology to facilitate a\nderivative-free update of these Gaussian components and their respective\nweights, addressing the issue in (iii).\n  The proposed methodology results in an efficient derivative-free sampler\nflexible enough to handle multi-modal distributions: Gaussian Mixture Kalman\nInversion (GMKI). The effectiveness of GMKI is demonstrated both theoretically\nand numerically in several experiments with multimodal target distributions,\nincluding proof-of-concept and two-dimensional examples, as well as a\nlarge-scale application: recovering the Navier-Stokes initial condition from\nsolution data at positive times.\n","authors":["Yifan Chen","Daniel Zhengyu Huang","Jiaoyang Huang","Sebastian Reich","Andrew M. Stuart"],"pdf_url":"https://arxiv.org/pdf/2406.17263v1.pdf","comment":"42 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.17251v1","updated":"2024-06-25T03:35:20Z","published":"2024-06-25T03:35:20Z","title":"TopoGCL: Topological Graph Contrastive Learning","summary":"  Graph contrastive learning (GCL) has recently emerged as a new concept which\nallows for capitalizing on the strengths of graph neural networks (GNNs) to\nlearn rich representations in a wide variety of applications which involve\nabundant unlabeled information. However, existing GCL approaches largely tend\nto overlook the important latent information on higher-order graph\nsubstructures. We address this limitation by introducing the concepts of\ntopological invariance and extended persistence on graphs to GCL. In\nparticular, we propose a new contrastive mode which targets topological\nrepresentations of the two augmented views from the same graph, yielded by\nextracting latent shape properties of the graph at multiple resolutions. Along\nwith the extended topological layer, we introduce a new extended persistence\nsummary, namely, extended persistence landscapes (EPL) and derive its\ntheoretical stability guarantees. Our extensive numerical results on\nbiological, chemical, and social interaction graphs show that the new\nTopological Graph Contrastive Learning (TopoGCL) model delivers significant\nperformance gains in unsupervised graph classification for 11 out of 12\nconsidered datasets and also exhibits robustness under noisy scenarios.\n","authors":["Yuzhou Chen","Jose Frias","Yulia R. Gel"],"pdf_url":"https://arxiv.org/pdf/2406.17251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17245v1","updated":"2024-06-25T03:24:06Z","published":"2024-06-25T03:24:06Z","title":"Unlocking Continual Learning Abilities in Language Models","summary":"  Language models (LMs) exhibit impressive performance and generalization\ncapabilities. However, LMs struggle with the persistent challenge of\ncatastrophic forgetting, which undermines their long-term sustainability in\ncontinual learning (CL). Existing approaches usually address the issue by\nincorporating old task data or task-wise inductive bias into LMs. However, old\ndata and accurate task information are often unavailable or costly to collect,\nhindering the availability of current CL approaches for LMs. To address this\nlimitation, we introduce $\\textbf{MIGU}$ ($\\textbf{M}$agn$\\textbf{I}$tude-based\n$\\textbf{G}$radient $\\textbf{U}$pdating for continual learning), a\nrehearsal-free and task-label-free method that only updates the model\nparameters with large magnitudes of output in LMs' linear layers. MIGU is based\non our observation that the L1-normalized magnitude distribution of the output\nin LMs' linear layers is different when the LM models deal with different task\ndata. By imposing this simple constraint on the gradient update process, we can\nleverage the inherent behaviors of LMs, thereby unlocking their innate CL\nabilities. Our experiments demonstrate that MIGU is universally applicable to\nall three LM architectures (T5, RoBERTa, and Llama2), delivering\nstate-of-the-art or on-par performance across continual finetuning and\ncontinual pre-training settings on four CL benchmarks. For example, MIGU brings\na 15.2% average accuracy improvement over conventional parameter-efficient\nfinetuning baselines in a 15-task CL benchmark. MIGU can also seamlessly\nintegrate with all three existing CL types to further enhance performance. Code\nis available at \\href{https://github.com/wenyudu/MIGU}{this https URL}.\n","authors":["Wenyu Du","Shuang Cheng","Tongxu Luo","Zihan Qiu","Zeyu Huang","Ka Chun Cheung","Reynold Cheng","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2406.17245v1.pdf","comment":"preprint, 19 pages"},{"id":"http://arxiv.org/abs/2406.16252v2","updated":"2024-06-25T03:17:40Z","published":"2024-06-24T01:22:54Z","title":"Graph-Augmented LLMs for Personalized Health Insights: A Case Study in\n  Sleep Analysis","summary":"  Health monitoring systems have revolutionized modern healthcare by enabling\nthe continuous capture of physiological and behavioral data, essential for\npreventive measures and early health intervention. While integrating this data\nwith Large Language Models (LLMs) has shown promise in delivering interactive\nhealth advice, traditional methods like Retrieval-Augmented Generation (RAG)\nand fine-tuning often fail to fully utilize the complex, multi-dimensional, and\ntemporally relevant data from wearable devices. These conventional approaches\ntypically provide limited actionable and personalized health insights due to\ntheir inadequate capacity to dynamically integrate and interpret diverse health\ndata streams. In response, this paper introduces a graph-augmented LLM\nframework designed to significantly enhance the personalization and clarity of\nhealth insights. Utilizing a hierarchical graph structure, the framework\ncaptures inter and intra-patient relationships, enriching LLM prompts with\ndynamic feature importance scores derived from a Random Forest Model. The\neffectiveness of this approach is demonstrated through a sleep analysis case\nstudy involving 20 college students during the COVID-19 lockdown, highlighting\nthe potential of our model to generate actionable and personalized health\ninsights efficiently. We leverage another LLM to evaluate the insights for\nrelevance, comprehensiveness, actionability, and personalization, addressing\nthe critical need for models that process and interpret complex health data\neffectively. Our findings show that augmenting prompts with our framework\nyields significant improvements in all 4 criteria. Through our framework, we\ncan elicit well-crafted, more thoughtful responses tailored to a specific\npatient.\n","authors":["Ajan Subramanian","Zhongqi Yang","Iman Azimi","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2406.16252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10963v2","updated":"2024-06-25T03:14:10Z","published":"2024-02-13T20:16:29Z","title":"GLoRe: When, Where, and How to Improve LLM Reasoning via Global and\n  Local Refinements","summary":"  State-of-the-art language models can exhibit impressive reasoning refinement\ncapabilities on math, science or coding tasks. However, recent work\ndemonstrates that even the best models struggle to identify \\textit{when and\nwhere to refine} without access to external feedback. Outcome-based Reward\nModels (\\textbf{ORMs}), trained to predict correctness of the final answer\nindicating when to refine, offer one convenient solution for deciding when to\nrefine. Process Based Reward Models (\\textbf{PRMs}), trained to predict\ncorrectness of intermediate steps, can then be used to indicate where to\nrefine. But they are expensive to train, requiring extensive human annotations.\nIn this paper, we propose Stepwise ORMs (\\textbf{SORMs}) which are trained,\nonly on synthetic data, to approximate the expected future reward of the\noptimal policy or $V^{\\star}$. More specifically, SORMs are trained to predict\nthe correctness of the final answer when sampling the current policy many times\n(rather than only once as in the case of ORMs). Our experiments show that SORMs\ncan more accurately detect incorrect reasoning steps compared to ORMs, thus\nimproving downstream accuracy when doing refinements. We then train\n\\textit{global} refinement models, which take only the question and a draft\nsolution as input and predict a corrected solution, and \\textit{local}\nrefinement models which also take as input a critique indicating the location\nof the first reasoning error. We generate training data for both models\nsynthetically by reusing data used to train the SORM. We find combining global\nand local refinements, using the ORM as a reranker, significantly outperforms\neither one individually, as well as a best of three sample baseline. With this\nstrategy we can improve the accuracy of a LLaMA-2 13B model (already fine-tuned\nwith RL) on GSM8K from 53\\% to 65\\% when greedily sampled.\n","authors":["Alex Havrilla","Sharath Raparthy","Christoforus Nalmpantis","Jane Dwivedi-Yu","Maksym Zhuravinskyi","Eric Hambro","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2402.10963v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17238v1","updated":"2024-06-25T02:59:02Z","published":"2024-06-25T02:59:02Z","title":"Expansive Synthesis: Generating Large-Scale Datasets from Minimal\n  Samples","summary":"  The challenge of limited availability of data for training in machine\nlearning arises in many applications and the impact on performance and\ngeneralization is serious. Traditional data augmentation methods aim to enhance\ntraining with a moderately sufficient data set. Generative models like\nGenerative Adversarial Networks (GANs) often face problematic convergence when\ngenerating significant and diverse data samples. Diffusion models, though\neffective, still struggle with high computational cost and long training times.\nThis paper introduces an innovative Expansive Synthesis model that generates\nlarge-scale, high-fidelity datasets from minimal samples. The proposed approach\nexploits expander graph mappings and feature interpolation to synthesize\nexpanded datasets while preserving the intrinsic data distribution and feature\nstructural relationships. The rationale of the model is rooted in the\nnon-linear property of neural networks' latent space and in its capture by a\nKoopman operator to yield a linear space of features to facilitate the\nconstruction of larger and enriched consistent datasets starting with a much\nsmaller dataset. This process is optimized by an autoencoder architecture\nenhanced with self-attention layers and further refined for distributional\nconsistency by optimal transport. We validate our Expansive Synthesis by\ntraining classifiers on the generated datasets and comparing their performance\nto classifiers trained on larger, original datasets. Experimental results\ndemonstrate that classifiers trained on synthesized data achieve performance\nmetrics on par with those trained on full-scale datasets, showcasing the\nmodel's potential to effectively augment training data. This work represents a\nsignificant advancement in data generation, offering a robust solution to data\nscarcity and paving the way for enhanced data availability in machine learning\napplications.\n","authors":["Vahid Jebraeeli","Bo Jiang","Hamid Krim","Derya Cansever"],"pdf_url":"https://arxiv.org/pdf/2406.17238v1.pdf","comment":"14 pages. arXiv admin note: text overlap with arXiv:2405.13866"}],"Robotics":[{"id":"http://arxiv.org/abs/2406.17768v1","updated":"2024-06-25T17:50:03Z","published":"2024-06-25T17:50:03Z","title":"EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot\n  Skills from Offline Data","summary":"  Most reinforcement learning (RL) methods focus on learning optimal policies\nover low-level action spaces. While these methods can perform well in their\ntraining environments, they lack the flexibility to transfer to new tasks.\nInstead, RL agents that can act over useful, temporally extended skills rather\nthan low-level actions can learn new tasks more easily. Prior work in\nskill-based RL either requires expert supervision to define useful skills,\nwhich is hard to scale, or learns a skill-space from offline data with\nheuristics that limit the adaptability of the skills, making them difficult to\ntransfer during downstream RL. Our approach, EXTRACT, instead utilizes\npre-trained vision language models to extract a discrete set of semantically\nmeaningful skills from offline data, each of which is parameterized by\ncontinuous arguments, without human supervision. This skill parameterization\nallows robots to learn new tasks by only needing to learn when to select a\nspecific skill and how to modify its arguments for the specific task. We\ndemonstrate through experiments in sparse-reward, image-based, robot\nmanipulation environments that EXTRACT can more quickly learn new tasks than\nprior works, with major gains in sample efficiency and performance over prior\nskill-based RL. Website at https://www.jessezhang.net/projects/extract/.\n","authors":["Jesse Zhang","Minho Heo","Zuxin Liu","Erdem Biyik","Joseph J Lim","Yao Liu","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2406.17768v1.pdf","comment":"22 pages, 13 figures"},{"id":"http://arxiv.org/abs/2406.17757v1","updated":"2024-06-25T17:42:22Z","published":"2024-06-25T17:42:22Z","title":"Automatic Parameter Tuning of Self-Driving Vehicles","summary":"  Modern automated driving solutions utilize trajectory planning and control\ncomponents with numerous parameters that need to be tuned for different driving\nsituations and vehicle types to achieve optimal performance. This paper\nproposes a method to automatically tune such parameters to resemble expert\ndemonstrations. We utilize a cost function which captures deviations of the\nclosed-loop operation of the controller from the recorded desired driving\nbehavior. Parameter tuning is then accomplished by using local optimization\ntechniques. Three optimization alternatives are compared in a case study, where\na trajectory planner is tuned for lane following in a real-world driving\nscenario. The results suggest that the proposed approach improves manually\ntuned initial parameters significantly even with respect to noisy demonstration\ndata.\n","authors":["Hung-Ju Wu","Vladislav Nenchev","Christian Rathgeber"],"pdf_url":"https://arxiv.org/pdf/2406.17757v1.pdf","comment":"Preprint to appear at the 2024 IEEE Conference on Control Technology\n  and Applications (CCTA)"},{"id":"http://arxiv.org/abs/2406.17707v1","updated":"2024-06-25T16:46:21Z","published":"2024-06-25T16:46:21Z","title":"SurgeMOD: Translating image-space tissue motions into vision-based\n  surgical forces","summary":"  We present a new approach for vision-based force estimation in Minimally\nInvasive Robotic Surgery based on frequency domain basis of motion of organs\nderived directly from video. Using internal movements generated by natural\nprocesses like breathing or the cardiac cycle, we infer the image-space basis\nof the motion on the frequency domain. As we are working with this\nrepresentation, we discretize the problem to a limited amount of\nlow-frequencies to build an image-space mechanical model of the environment. We\nuse this pre-built model to define our force estimation problem as a dynamic\nconstraint problem. We demonstrate that this method can estimate point contact\nforces reliably for silicone phantom and ex-vivo experiments, matching real\nreadings from a force sensor. In addition, we perform qualitative experiments\nin which we synthesize coherent force textures from surgical videos over a\ncertain region of interest selected by the user. Our method demonstrates good\nresults for both quantitative and qualitative analysis, providing a good\nstarting point for a purely vision-based method for surgical force estimation.\n","authors":["Mikel De Iturrate Reyzabal","Dionysios Malas","Shuai Wang","Sebastien Ourselin","Hongbin Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17659v1","updated":"2024-06-25T15:49:47Z","published":"2024-06-25T15:49:47Z","title":"DKPROMPT: Domain Knowledge Prompting Vision-Language Models for\n  Open-World Planning","summary":"  Vision-language models (VLMs) have been applied to robot task planning\nproblems, where the robot receives a task in natural language and generates\nplans based on visual inputs. While current VLMs have demonstrated strong\nvision-language understanding capabilities, their performance is still far from\nbeing satisfactory in planning tasks. At the same time, although classical task\nplanners, such as PDDL-based, are strong in planning for long-horizon tasks,\nthey do not work well in open worlds where unforeseen situations are common. In\nthis paper, we propose a novel task planning and execution framework, called\nDKPROMPT, which automates VLM prompting using domain knowledge in PDDL for\nclassical planning in open worlds. Results from quantitative experiments show\nthat DKPROMPT outperforms classical planning, pure VLM-based and a few other\ncompetitive baselines in task completion rate.\n","authors":["Xiaohan Zhang","Zainab Altaweel","Yohei Hayamizu","Yan Ding","Saeid Amiri","Hao Yang","Andy Kaminski","Chad Esselink","Shiqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.17659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17654v1","updated":"2024-06-25T15:46:39Z","published":"2024-06-25T15:46:39Z","title":"MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for\n  Multi-View 3D Object Detection","summary":"  Multi-view 3D object detection is a crucial component of autonomous driving\nsystems. Contemporary query-based methods primarily depend either on\ndataset-specific initialization of 3D anchors, introducing bias, or utilize\ndense attention mechanisms, which are computationally inefficient and\nunscalable. To overcome these issues, we present MDHA, a novel sparse\nquery-based framework, which constructs adaptive 3D output proposals using\nhybrid anchors from multi-view, multi-scale input. Fixed 2D anchors are\ncombined with depth predictions to form 2.5D anchors, which are projected to\nobtain 3D proposals. To ensure high efficiency, our proposed Anchor Encoder\nperforms sparse refinement and selects the top-k anchors and features.\nMoreover, while existing multi-view attention mechanisms rely on projecting\nreference points to multiple images, our novel Circular Deformable Attention\nmechanism only projects to a single image but allows reference points to\nseamlessly attend to adjacent images, improving efficiency without compromising\non performance. On the nuScenes val set, it achieves 46.4% mAP and 55.0% NDS\nwith a ResNet101 backbone. MDHA significantly outperforms the baseline, where\nanchor proposals are modelled as learnable embeddings.\n","authors":["Michelle Adeline","Junn Yong Loo","Vishnu Monn Baskaran"],"pdf_url":"https://arxiv.org/pdf/2406.17654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15639v2","updated":"2024-06-25T15:43:31Z","published":"2024-06-21T20:34:37Z","title":"Low Fidelity Visuo-Tactile Pretraining Improves Vision-Only Manipulation\n  Performance","summary":"  Tactile perception is a critical component of solving real-world manipulation\ntasks, but tactile sensors for manipulation have barriers to use such as\nfragility and cost. In this work, we engage a robust, low-cost tactile sensor,\nBeadSight, as an alternative to precise pre-calibrated sensors for a\npretraining approach to manipulation. We show that tactile pretraining, even\nwith a low-fidelity sensor as BeadSight, can improve an imitation learning\nagent's performance on complex manipulation tasks. We demonstrate this method\nagainst a baseline USB cable plugging task, previously achieved with a much\nhigher precision GelSight sensor as the tactile input to pretraining. Our best\nBeadSight pretrained visuo-tactile agent completed the task with 70\\% accuracy\ncompared to 85\\% for the best GelSight pretrained visuo-tactile agent, with\nvision-only inference for both.\n","authors":["Selam Gano","Abraham George","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2406.15639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17641v1","updated":"2024-06-25T15:24:08Z","published":"2024-06-25T15:24:08Z","title":"The experience of humans' and robots' mutual (im)politeness in enacted\n  service scenarios: An empirical study","summary":"  The paper reports an empirical study of the effect of human treatment of a\nrobot on the social perception of the robot's behavior. The study employed an\nenacted interaction between an anthropomorphic \"waiter\" robot and two\ncustomers. The robot and one of the customers (acted out by a researcher) were\nfollowing four different interaction scripts, representing all combinations of\nmutual politeness and impoliteness of the robot and the customer. The\nparticipants (N=24, within-subject design) were assigned the role of an\n\"included observer\", that is, a fellow customer who was present in the\nsituation without being actively involved in the interactions. The participants\nassessed how they experienced the interaction scenarios by providing Likert\nscale scores and free-text responses. The results indicate that while impolite\nrobots' behavior was generally assessed negatively, it was commonly perceived\nas more justifiable and fairer if the robot was treated impolitely by the\nhuman. Politeness reciprocity expectations in the context of the social\nperception of robots are discussed.\n","authors":["Victor Kaptelinin","Suna Bensch","Thomas Hellström","Patrik Björnfot","Shikhar Kumar"],"pdf_url":"https://arxiv.org/pdf/2406.17641v1.pdf","comment":"19 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2406.17627v1","updated":"2024-06-25T15:15:27Z","published":"2024-06-25T15:15:27Z","title":"Querying Labeled Time Series Data with Scenario Programs","summary":"  In order to ensure autonomous vehicles are safe for on-road deployment,\nsimulation-based testing has become an integral complement to on-road testing.\nThe rise in simulation testing and validation reflects a growing need to verify\nthat AV behavior is consistent with desired outcomes even in edge case\nscenarios $-$ which may seldom or never appear in on-road testing data. This\nraises a critical question: to what extent are AV failures in simulation\nconsistent with data collected from real-world testing? As a result of the gap\nbetween simulated and real sensor data (sim-to-real gap), failures in\nsimulation can either be spurious (simulation- or simulator-specific issues) or\nrelevant (safety-critical AV system issues). One possible method for validating\nif simulated time series failures are consistent with real world time series\nsensor data could involve retrieving instances of the failure scenario from a\nreal-world time series dataset, in order to understand AV performance in these\nscenarios. Adopting this strategy, we propose a formal definition of what\nconstitutes a match between a real-world labeled time series data item and a\nsimulated scenario written from a fragment of the Scenic probabilistic\nprogramming language for simulation generation. With this definition of a\nmatch, we develop a querying algorithm that identifies the subset of a labeled\ntime series dataset matching a given scenario. To allow this approach to be\nused to verify the safety of other cyber-physical systems (CPS), we present a\ndefinition and algorithm for matching scalable beyond the autonomous vehicles\ndomain. Experiments demonstrate the precision and scalability of the algorithm\nfor a set of challenging and uncommon time series scenarios identified from the\nnuScenes autonomous driving dataset. We include a full system implementation of\nthe querying algorithm freely available for use across a wide range of CPS.\n","authors":["Devan Shanker"],"pdf_url":"https://arxiv.org/pdf/2406.17627v1.pdf","comment":"72 pages, 6 figures, 5 algorithms. Published on\n  https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-136.html"},{"id":"http://arxiv.org/abs/2406.17620v1","updated":"2024-06-25T15:05:00Z","published":"2024-06-25T15:05:00Z","title":"OCCAM: Online Continuous Controller Adaptation with Meta-Learned Models","summary":"  Control tuning and adaptation present a significant challenge to the usage of\nrobots in diverse environments. It is often nontrivial to find a single set of\ncontrol parameters by hand that work well across the broad array of\nenvironments and conditions that a robot might encounter. Automated adaptation\napproaches must utilize prior knowledge about the system while adapting to\nsignificant domain shifts to find new control parameters quickly. In this work,\nwe present a general framework for online controller adaptation that deals with\nthese challenges. We combine meta-learning with Bayesian recursive estimation\nto learn prior predictive models of system performance that quickly adapt to\nonline data, even when there is significant domain shift. These predictive\nmodels can be used as cost functions within efficient sampling-based\noptimization routines to find new control parameters online that maximize\nsystem performance. Our framework is powerful and flexible enough to adapt\ncontrollers for four diverse systems: a simulated race car, a simulated\nquadrupedal robot, and a simulated and physical quadrotor.\n","authors":["Hersh Sanghvi","Spencer Folk","Camillo Jose Taylor"],"pdf_url":"https://arxiv.org/pdf/2406.17620v1.pdf","comment":"8 pages, 4 figures. Currently under peer review"},{"id":"http://arxiv.org/abs/2406.17604v1","updated":"2024-06-25T14:45:49Z","published":"2024-06-25T14:45:49Z","title":"Optimizing Energy-Efficient Braking Trajectories with Anticipatory Road\n  Data for Automated Vehicles","summary":"  Trajectory planning in automated driving typically focuses on satisfying\nsafety and comfort requirements within the vehicle's onboard sensor range. This\npaper introduces a method that leverages anticipatory road data, such as speed\nlimits, road slopes, and traffic lights, beyond the local perception range to\noptimize energy-efficient braking trajectories. For that, coasting, which\nreduces energy consumption, and active braking are combined to transition from\nthe current vehicle velocity to a lower target velocity at a given distance\nahead. Finding the switching instants between the coasting phases and the\ncontinuous control for the braking phase is addressed as an optimal trade-off\nbetween maximizing coasting periods and minimizing braking effort. The\nresulting switched optimal control problem is solved by deriving necessary\noptimality conditions. To facilitate the incorporation of additional\nfeasibility constraints for multi-phase trajectories, a sub-optimal alternative\nsolution based on parametric optimization is proposed. Both methods are\ncompared in simulation.\n","authors":["Andres Alvarez Prado","Vladislav Nenchev","Christian Rathgeber"],"pdf_url":"https://arxiv.org/pdf/2406.17604v1.pdf","comment":"Preprint to appear at the European Control Conference 2024 (ECC'24)"},{"id":"http://arxiv.org/abs/2406.17586v1","updated":"2024-06-25T14:28:21Z","published":"2024-06-25T14:28:21Z","title":"Benchmarking SLAM Algorithms in the Cloud: The SLAM Hive System","summary":"  Evaluating the performance of Simultaneous Localization and Mapping (SLAM)\nalgorithms is essential for scientists and users of robotic systems alike. But\nthere are a multitude different permutations of possible options of hardware\nsetups and algorithm configurations, as well as different datasets and\nalgorithms, such that it is infeasible to thoroughly compare SLAM systems\nagainst the full state of the art. To solve that we present the SLAM Hive\nBenchmarking Suite, which is able to analyze SLAM algorithms in thousands of\nmapping runs, through its utilization of container technology and deployment in\nthe cloud. This paper presents the architecture and open source implementation\nof SLAM Hive and compares it to existing efforts on SLAM evaluation. We perform\nmapping runs of many of the most popular visual and LiDAR based SLAM algorithms\nagainst commonly used datasets and show how SLAM Hive and then be used to\nconveniently analyze the results against various aspects. Through this we\nenvision that SLAM Hive can become an essential tool for proper comparisons and\nevaluations of SLAM algorithms and thus drive the scientific development in the\nresearch on SLAM. The open source software as well as a demo to show the live\nanalysis of 100s of mapping runs can be found on our SLAM Hive website.\n","authors":["Xinzhe Liu","Yuanyuan Yang","Bowen Xu","Sören Schwertfeger"],"pdf_url":"https://arxiv.org/pdf/2406.17586v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2303.11854"},{"id":"http://arxiv.org/abs/2406.17531v1","updated":"2024-06-25T13:15:36Z","published":"2024-06-25T13:15:36Z","title":"Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity\n  Awareness","summary":"  This paper presents a system for diversity-aware autonomous conversation\nleveraging the capabilities of large language models (LLMs). The system adapts\nto diverse populations and individuals, considering factors like background,\npersonality, age, gender, and culture. The conversation flow is guided by the\nstructure of the system's pre-established knowledge base, while LLMs are tasked\nwith various functions, including generating diversity-aware sentences.\nAchieving diversity-awareness involves providing carefully crafted prompts to\nthe models, incorporating comprehensive information about users, conversation\nhistory, contextual details, and specific guidelines. To assess the system's\nperformance, we conducted both controlled and real-world experiments, measuring\na wide range of performance indicators.\n","authors":["Lucrezia Grassi","Carmine Tommaso Recchiuto","Antonio Sgorbissa"],"pdf_url":"https://arxiv.org/pdf/2406.17531v1.pdf","comment":"8 pages, 6 figures, 7 tables. This paper has been accepted for\n  publication at IEEE ROMAN 2024"},{"id":"http://arxiv.org/abs/2406.17530v1","updated":"2024-06-25T13:14:26Z","published":"2024-06-25T13:14:26Z","title":"Point Tree Transformer for Point Cloud Registration","summary":"  Point cloud registration is a fundamental task in the fields of computer\nvision and robotics. Recent developments in transformer-based methods have\ndemonstrated enhanced performance in this domain. However, the standard\nattention mechanism utilized in these methods often integrates many\nlow-relevance points, thereby struggling to prioritize its attention weights on\nsparse yet meaningful points. This inefficiency leads to limited local\nstructure modeling capabilities and quadratic computational complexity. To\novercome these limitations, we propose the Point Tree Transformer (PTT), a\nnovel transformer-based approach for point cloud registration that efficiently\nextracts comprehensive local and global features while maintaining linear\ncomputational complexity. The PTT constructs hierarchical feature trees from\npoint clouds in a coarse-to-dense manner, and introduces a novel Point Tree\nAttention (PTA) mechanism, which follows the tree structure to facilitate the\nprogressive convergence of attended regions towards salient points.\nSpecifically, each tree layer selectively identifies a subset of key points\nwith the highest attention scores. Subsequent layers focus attention on areas\nof significant relevance, derived from the child points of the selected point\nset. The feature extraction process additionally incorporates coarse point\nfeatures that capture high-level semantic information, thus facilitating local\nstructure modeling and the progressive integration of multiscale information.\nConsequently, PTA empowers the model to concentrate on crucial local structures\nand derive detailed local information while maintaining linear computational\ncomplexity. Extensive experiments conducted on the 3DMatch, ModelNet40, and\nKITTI datasets demonstrate that our method achieves superior performance over\nthe state-of-the-art methods.\n","authors":["Meiling Wang","Guangyan Chen","Yi Yang","Li Yuan","Yufeng Yue"],"pdf_url":"https://arxiv.org/pdf/2406.17530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17520v1","updated":"2024-06-25T12:59:46Z","published":"2024-06-25T12:59:46Z","title":"Tell Me Where You Are: Multimodal LLMs Meet Place Recognition","summary":"  Large language models (LLMs) exhibit a variety of promising capabilities in\nrobotics, including long-horizon planning and commonsense reasoning. However,\ntheir performance in place recognition is still underexplored. In this work, we\nintroduce multimodal LLMs (MLLMs) to visual place recognition (VPR), where a\nrobot must localize itself using visual observations. Our key design is to use\nvision-based retrieval to propose several candidates and then leverage\nlanguage-based reasoning to carefully inspect each candidate for a final\ndecision. Specifically, we leverage the robust visual features produced by\noff-the-shelf vision foundation models (VFMs) to obtain several candidate\nlocations. We then prompt an MLLM to describe the differences between the\ncurrent observation and each candidate in a pairwise manner, and reason about\nthe best candidate based on these descriptions. Our results on three datasets\ndemonstrate that integrating the general-purpose visual features from VFMs with\nthe reasoning capabilities of MLLMs already provides an effective place\nrecognition solution, without any VPR-specific supervised training. We believe\nour work can inspire new possibilities for applying and designing foundation\nmodels, i.e., VFMs, LLMs, and MLLMs, to enhance the localization and navigation\nof mobile robots.\n","authors":["Zonglin Lyu","Juexiao Zhang","Mingxuan Lu","Yiming Li","Chen Feng"],"pdf_url":"https://arxiv.org/pdf/2406.17520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07017v2","updated":"2024-06-25T12:42:39Z","published":"2024-05-11T13:51:33Z","title":"Robot Agnostic Visual Servoing considering kinematic constraints enabled\n  by a decoupled network trajectory planner structure","summary":"  We propose a visual servoing method consisting of a detection network and a\nvelocity trajectory planner. First, the detection network estimates the objects\nposition and orientation in the image space. Furthermore, these are normalized\nand filtered. The direction and orientation is then the input to the trajectory\nplanner, which considers the kinematic constrains of the used robotic system.\nThis allows safe and stable control, since the kinematic boundary values are\ntaken into account in planning. Also, by having direction estimation and\nvelocity planner separated, the learning part of the method does not directly\ninfluence the control value. This also enables the transfer of the method to\ndifferent robotic systems without retraining, therefore being robot agnostic.\nWe evaluate our method on different visual servoing tasks with and without\nclutter on two different robotic systems. Our method achieved mean absolute\nposition errors of <0.5 mm and orientation errors of <1{\\deg}. Additionally, we\ntransferred the method to a new system which differs in robot and camera,\nemphasizing robot agnostic capability of our method.\n","authors":["Constantin Schempp","Christian Friedrich"],"pdf_url":"https://arxiv.org/pdf/2405.07017v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2405.06991v2","updated":"2024-06-25T12:28:34Z","published":"2024-05-11T11:45:19Z","title":"PIPE: Process Informed Parameter Estimation, a learning based approach\n  to task generalized system identification","summary":"  We address the problem of robot guided assembly tasks, by using a\nlearning-based approach to identify contact model parameters for known and\nnovel parts. First, a Variational Autoencoder (VAE) is used to extract\ngeometric features of assembly parts. Then, we combine the extracted features\nwith physical knowledge to derive the parameters of a contact model using our\nnewly proposed neural network structure. The measured force from real\nexperiments is used to supervise the predicted forces, thus avoiding the need\nfor ground truth model parameters. Although trained only on a small set of\nassembly parts, good contact model estimation for unknown objects were\nachieved. Our main contribution is the network structure that allows us to\nestimate contact models of assembly tasks depending on the geometry of the part\nto be joined. Where current system identification processes have to record new\ndata for a new assembly process, our method only requires the 3D model of the\nassembly part. We evaluate our method by estimating contact models for\nrobot-guided assembly tasks of pin connectors as well as electronic plugs and\ncompare the results with real experiments.\n","authors":["Constantin Schempp","Christian Friedrich"],"pdf_url":"https://arxiv.org/pdf/2405.06991v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2406.17490v1","updated":"2024-06-25T12:17:44Z","published":"2024-06-25T12:17:44Z","title":"BricksRL: A Platform for Democratizing Robotics and Reinforcement\n  Learning Research and Education with LEGO","summary":"  We present BricksRL, a platform designed to democratize access to robotics\nfor reinforcement learning research and education. BricksRL facilitates the\ncreation, design, and training of custom LEGO robots in the real world by\ninterfacing them with the TorchRL library for reinforcement learning agents.\nThe integration of TorchRL with the LEGO hubs, via Bluetooth bidirectional\ncommunication, enables state-of-the-art reinforcement learning training on GPUs\nfor a wide variety of LEGO builds. This offers a flexible and cost-efficient\napproach for scaling and also provides a robust infrastructure for\nrobot-environment-algorithm communication. We present various experiments\nacross tasks and robot configurations, providing built plans and training\nresults. Furthermore, we demonstrate that inexpensive LEGO robots can be\ntrained end-to-end in the real world to achieve simple tasks, with training\ntimes typically under 120 minutes on a normal laptop. Moreover, we show how\nusers can extend the capabilities, exemplified by the successful integration of\nnon-LEGO sensors. By enhancing accessibility to both robotics and reinforcement\nlearning, BricksRL establishes a strong foundation for democratized robotic\nlearning in research and educational settings.\n","authors":["Sebastian Dittert","Vincent Moens","Gianni De Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2406.17490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06208v2","updated":"2024-06-25T11:11:00Z","published":"2023-10-09T23:34:09Z","title":"Human-Robot Gym: Benchmarking Reinforcement Learning in Human-Robot\n  Collaboration","summary":"  Deep reinforcement learning (RL) has shown promising results in robot motion\nplanning with first attempts in human-robot collaboration (HRC). However, a\nfair comparison of RL approaches in HRC under the constraint of guaranteed\nsafety is yet to be made. We, therefore, present human-robot gym, a benchmark\nsuite for safe RL in HRC. Our benchmark suite provides eight challenging,\nrealistic HRC tasks in a modular simulation framework. Most importantly,\nhuman-robot gym includes a safety shield that provably guarantees human safety.\nWe are, thereby, the first to provide a benchmark suite to train RL agents that\nadhere to the safety specifications of real-world HRC. This bridges a critical\ngap between theoretic RL research and its real-world deployment. Our evaluation\nof six tasks led to three key results: (a) the diverse nature of the tasks\noffered by human-robot gym creates a challenging benchmark for state-of-the-art\nRL methods, (b) incorporating expert knowledge in RL training in the form of an\naction-based reward can outperform the expert, and (c) our agents negligibly\noverfit to training data.\n","authors":["Jakob Thumm","Felix Trost","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2310.06208v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17420v1","updated":"2024-06-25T09:45:50Z","published":"2024-06-25T09:45:50Z","title":"Real-Time Remote Control via VR over Limited Wireless Connectivity","summary":"  This work introduces a solution to enhance human-robot interaction over\nlimited wireless connectivity. The goal is toenable remote control of a robot\nthrough a virtual reality (VR)interface, ensuring a smooth transition to\nautonomous mode in the event of connectivity loss. The VR interface provides\naccessto a dynamic 3D virtual map that undergoes continuous updatesusing\nreal-time sensor data collected and transmitted by therobot. Furthermore, the\nrobot monitors wireless connectivity and automatically switches to a autonomous\nmode in scenarios with limited connectivity. By integrating four key\nfunctionalities: real-time mapping, remote control through glasses VR,\ncontinuous monitoring of wireless connectivity, and autonomous navigation\nduring limited connectivity, we achieve seamless end-to-end operation.\n","authors":["H. P. Madushanka","Rafaela Scaciota","Sumudu Samarakoon","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2406.17420v1.pdf","comment":"Accepted in ISCC 2024 conference"},{"id":"http://arxiv.org/abs/2309.06955v2","updated":"2024-06-25T09:20:13Z","published":"2023-09-13T13:41:34Z","title":"Enhancing Dexterity in Confined Spaces: Real-Time Motion Planning for\n  Multi-Fingered In-Hand Manipulation","summary":"  Dexterous in-hand manipulation in robotics, particularly with multi-fingered\nrobotic hands, poses significant challenges due to the intricate avoidance of\ncollisions among fingers and the object being manipulated. Collision-free paths\nfor all fingers must be generated in real-time, as the rapid changes in hand\nand finger positions necessitate instantaneous recalculations to prevent\ncollisions and ensure undisturbed movement. This study introduces a real-time\napproach to motion planning in high-dimensional spaces. We first explicitly\nmodel the collision-free space using neural networks that are retrievable in\nreal time. Then, we combined the C-space representation with closed-loop\ncontrol via dynamical system and sampling-based planning approaches. This\nintegration enhances the efficiency and feasibility of path-finding, enabling\ndynamic obstacle avoidance, thereby advancing the capabilities of\nmulti-fingered robotic hands for in-hand manipulation tasks.\n","authors":["Xiao Gao","Kunpeng Yao","Farshad Khadivar","Aude Billard"],"pdf_url":"https://arxiv.org/pdf/2309.06955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17379v1","updated":"2024-06-25T08:55:15Z","published":"2024-06-25T08:55:15Z","title":"Constructing Behavior Trees from Temporal Plans for Robotic Applications","summary":"  Executing temporal plans in the real and open world requires adapting to\nuncertainty both in the environment and in the plan actions. A plan executor\nmust therefore be flexible to dispatch actions based on the actual execution\nconditions. In general, this involves considering both event and time-based\nconstraints between the actions in the plan. A simple temporal network (STN) is\na convenient framework for specifying the constraints between actions in the\nplan. Likewise, a behavior tree (BT) is a convenient framework for controlling\nthe execution flow of the actions in the plan. The principle contributions of\nthis paper are i) an algorithm for transforming a plan into an STN, and ii) an\nalgorithm for transforming an STN into a BT. When combined, these algorithms\ndefine a systematic approach for executing total-order (time-triggered) plans\nin robots operating in the real world. Our approach is based on creating a\ngraph describing a deordered (state-triggered) plan and then creating a BT\nrepresenting a partial-order (determined at runtime) plan. This approach\nensures the correct execution of plans, including those with required\nconcurrency. We demonstrate the validity of our approach within the PlanSys2\nframework on real robots.\n","authors":["Josh Zapf","Marco Roveri","Francisco Martin","Juan Carlos Manzanares"],"pdf_url":"https://arxiv.org/pdf/2406.17379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06807v2","updated":"2024-06-25T08:25:30Z","published":"2024-04-10T07:55:01Z","title":"Sound Matters: Auditory Detectability of Mobile Robots","summary":"  Mobile robots are increasingly being used in noisy environments for social\npurposes, e.g. to provide support in healthcare or public spaces. Since these\nrobots also operate beyond human sight, the question arises as to how different\nrobot types, ambient noise or cognitive engagement impacts the detection of the\nrobots by their sound. To address this research gap, we conducted a user study\nmeasuring auditory detection distances for a wheeled (Turtlebot 2i) and\nquadruped robot (Unitree Go 1), which emit different consequential sounds when\nmoving. Additionally, we also manipulated background noise levels and\nparticipants' engagement in a secondary task during the study. Our results\nshowed that the quadruped robot sound was detected significantly better (i.e.,\nat a larger distance) than the wheeled one, which demonstrates that the\nmovement mechanism has a meaningful impact on the auditory detectability. The\ndetectability for both robots diminished significantly as background noise\nincreased. But even in high background noise, participants detected the\nquadruped robot at a significantly larger distance. The engagement in a\nsecondary task had hardly any impact. In essence, these findings highlight the\ncritical role of distinguishing auditory characteristics of different robots to\nimprove the smooth human-centered navigation of mobile robots in noisy\nenvironments.\n","authors":["Subham Agrawal","Marlene Wessels","Jorge de Heuvel","Johannes Kraus","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2404.06807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08983v2","updated":"2024-06-25T08:23:05Z","published":"2023-11-15T14:16:42Z","title":"Edge Accelerated Robot Navigation With Collaborative Motion Planning","summary":"  Low-cost distributed robots suffer from limited onboard computing power,\nresulting in excessive computation time when navigating in cluttered\nenvironments. This paper presents Edge Accelerated Robot Navigation (EARN), to\nachieve real-time collision avoidance by adopting collaborative motion planning\n(CMP). As such, each robot can dynamically switch between a conservative motion\nplanner executed locally to guarantee safety (e.g., path-following) and an\naggressive motion planner executed non-locally to guarantee efficiency (e.g.,\novertaking). In contrast to existing motion planning approaches that ignore the\ninterdependency between low-level motion planning and high-level resource\nallocation, EARN adopts model predictive switching (MPS) that maximizes the\nexpected switching gain with respect to robot states and actions under\ncomputation and communication resource constraints. The MPS problem is solved\nby a tightly-coupled decision making and motion planning framework based on\nbilevel mixed-integer nonlinear programming and penalty dual decomposition. We\nvalidate the performance of EARN in indoor simulation, outdoor simulation, and\nreal-world environments. Experiments show that EARN achieves significantly\nsmaller navigation time and higher success rates than state-of-the-art\nnavigation approaches.\n","authors":["Guoliang Li","Ruihua Han","Shuai Wang","Fei Gao","Yonina C. Eldar","Chengzhong Xu"],"pdf_url":"https://arxiv.org/pdf/2311.08983v2.pdf","comment":"12 pages, 13 figures, 3 tables, to appear in IEEE/ASME Transactions\n  on Mechatronics"},{"id":"http://arxiv.org/abs/2406.17333v1","updated":"2024-06-25T07:34:48Z","published":"2024-06-25T07:34:48Z","title":"Task Adaptation in Industrial Human-Robot Interaction: Leveraging\n  Riemannian Motion Policies","summary":"  In real-world industrial environments, modern robots often rely on human\noperators for crucial decision-making and mission synthesis from individual\ntasks. Effective and safe collaboration between humans and robots requires\nsystems that can adjust their motion based on human intentions, enabling\ndynamic task planning and adaptation. Addressing the needs of industrial\napplications, we propose a motion control framework that (i) removes the need\nfor manual control of the robot's movement; (ii) facilitates the formulation\nand combination of complex tasks; and (iii) allows the seamless integration of\nhuman intent recognition and robot motion planning. For this purpose, we\nleverage a modular and purely reactive approach for task parametrization and\nmotion generation, embodied by Riemannian Motion Policies. The effectiveness of\nour method is demonstrated, evaluated, and compared to \\remove{state-of-the-art\napproaches}\\add{a representative state-of-the-art approach} in experimental\nscenarios inspired by realistic industrial Human-Robot Interaction settings.\n","authors":["Mike Allenspach","Michael Pantic","Rik Girod","Lionel Ott","Roland Siegwart"],"pdf_url":"https://arxiv.org/pdf/2406.17333v1.pdf","comment":"9 pages; Robotics, Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2406.17313v1","updated":"2024-06-25T06:52:02Z","published":"2024-06-25T06:52:02Z","title":"Modelling and Hovering Stabilisation of a Free-Rotating Wing UAV","summary":"  We propose a multibody model of a freewing UAV. This model allows obtaining\nsimulations of the UAV's behaviour and, in the future, to design a control law\nstabilising the entire flight envelope (hovering and forward flight). We also\ndescribe the realisation of a prototype and a comparison of possible methods\nfor estimating the UAV's states. With this prototype, we report on experimental\nhovering flights with a non-linear incremental dynamic inversion controller to\nstabilise the wing and a proportional derivative controller for the fuselage\nstabilization.\n","authors":["Florian Sansou","Gautier Hattenberger","Luca Zaccarian","Fabrice Demourant","Thomas Loquen"],"pdf_url":"https://arxiv.org/pdf/2406.17313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16164v2","updated":"2024-06-25T06:35:22Z","published":"2024-06-23T16:54:07Z","title":"TornadoDrone: Bio-inspired DRL-based Drone Landing on 6D Platform with\n  Wind Force Disturbances","summary":"  Autonomous drone navigation faces a critical challenge in achieving accurate\nlandings on dynamic platforms, especially under unpredictable conditions such\nas wind turbulence. Our research introduces TornadoDrone, a novel Deep\nReinforcement Learning (DRL) model that adopts bio-inspired mechanisms to adapt\nto wind forces, mirroring the natural adaptability seen in birds. This model,\nunlike traditional approaches, derives its adaptability from indirect cues such\nas changes in position and velocity, rather than direct wind force\nmeasurements. TornadoDrone was rigorously trained in the gym-pybullet-drone\nsimulator, which closely replicates the complexities of wind dynamics in the\nreal world. Through extensive testing with Crazyflie 2.1 drones in both\nsimulated and real windy conditions, TornadoDrone demonstrated a high\nperformance in maintaining high-precision landing accuracy on moving platforms,\nsurpassing conventional control methods such as PID controllers with Extended\nKalman Filters. The study not only highlights the potential of DRL to tackle\ncomplex aerodynamic challenges but also paves the way for advanced autonomous\nsystems that can adapt to environmental changes in real-time. The success of\nTornadoDrone signifies a leap forward in drone technology, particularly for\ncritical applications such as surveillance and emergency response, where\nreliability and precision are paramount.\n","authors":["Robinroy Peter","Lavanya Ratnabala","Demetros Aschu","Aleksey Fedoseev","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2406.16164v2.pdf","comment":"Submitted to IEEE. arXiv admin note: substantial text overlap with\n  arXiv:2403.06572"},{"id":"http://arxiv.org/abs/2406.17286v1","updated":"2024-06-25T05:29:10Z","published":"2024-06-25T05:29:10Z","title":"Prioritized experience replay-based DDQN for Unmanned Vehicle Path\n  Planning","summary":"  Path planning module is a key module for autonomous vehicle navigation, which\ndirectly affects its operating efficiency and safety. In complex environments\nwith many obstacles, traditional planning algorithms often cannot meet the\nneeds of intelligence, which may lead to problems such as dead zones in\nunmanned vehicles. This paper proposes a path planning algorithm based on DDQN\nand combines it with the prioritized experience replay method to solve the\nproblem that traditional path planning algorithms often fall into dead zones. A\nseries of simulation experiment results prove that the path planning algorithm\nbased on DDQN is significantly better than other methods in terms of speed and\naccuracy, especially the ability to break through dead zones in extreme\nenvironments. Research shows that the path planning algorithm based on DDQN\nperforms well in terms of path quality and safety. These research results\nprovide an important reference for the research on automatic navigation of\nautonomous vehicles.\n","authors":["Liu Lipeng","Letian Xu","Jiabei Liu","Haopeng Zhao","Tongzhou Jiang","Tianyao Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.17286v1.pdf","comment":"4 pages, 6 figures, 2024 5th International Conference on Information\n  Science, Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2406.17279v1","updated":"2024-06-25T05:08:44Z","published":"2024-06-25T05:08:44Z","title":"Learning Decentralized Multi-Biped Control for Payload Transport","summary":"  Payload transport over flat terrain via multi-wheel robot carriers is\nwell-understood, highly effective, and configurable. In this paper, our goal is\nto provide similar effectiveness and configurability for transport over rough\nterrain that is more suitable for legs rather than wheels. For this purpose, we\nconsider multi-biped robot carriers, where wheels are replaced by multiple\nbipedal robots attached to the carrier. Our main contribution is to design a\ndecentralized controller for such systems that can be effectively applied to\nvarying numbers and configurations of rigidly attached bipedal robots without\nretraining. We present a reinforcement learning approach for training the\ncontroller in simulation that supports transfer to the real world. Our\nexperiments in simulation provide quantitative metrics showing the\neffectiveness of the approach over a wide variety of simulated transport\nscenarios. In addition, we demonstrate the controller in the real-world for\nsystems composed of two and three Cassie robots. To our knowledge, this is the\nfirst example of a scalable multi-biped payload transport system.\n","authors":["Bikram Pandit","Ashutosh Gupta","Mohitvishnu S. Gadde","Addison Johnson","Aayam Kumar Shrestha","Helei Duan","Jeremy Dao","Alan Fern"],"pdf_url":"https://arxiv.org/pdf/2406.17279v1.pdf","comment":"Submitted to CoRL 2024, Project website: decmbc.github.io"},{"id":"http://arxiv.org/abs/2401.09160v2","updated":"2024-06-25T04:15:03Z","published":"2024-01-17T12:08:30Z","title":"DK-SLAM: Monocular Visual SLAM with Deep Keypoint Learning, Tracking and\n  Loop-Closing","summary":"  The performance of visual SLAM in complex, real-world scenarios is often\ncompromised by unreliable feature extraction and matching when using\nhandcrafted features. Although deep learning-based local features excel at\ncapturing high-level information and perform well on matching benchmarks, they\nstruggle with generalization in continuous motion scenes, adversely affecting\nloop detection accuracy. Our system employs a Model-Agnostic Meta-Learning\n(MAML) strategy to optimize the training of keypoint extraction networks,\nenhancing their adaptability to diverse environments. Additionally, we\nintroduce a coarse-to-fine feature tracking mechanism for learned keypoints. It\nbegins with a direct method to approximate the relative pose between\nconsecutive frames, followed by a feature matching method for refined pose\nestimation. To mitigate cumulative positioning errors, DK-SLAM incorporates a\nnovel online learning module that utilizes binary features for loop closure\ndetection. This module dynamically identifies loop nodes within a sequence,\nensuring accurate and efficient localization. Experimental evaluations on\npublicly available datasets demonstrate that DK-SLAM outperforms leading\ntraditional and learning based SLAM systems, such as ORB-SLAM3 and LIFT-SLAM.\nThese results underscore the efficacy and robustness of our DK-SLAM in varied\nand challenging real-world environments.\n","authors":["Hao Qu","Lilian Zhang","Jun Mao","Junbo Tie","Xiaofeng He","Xiaoping Hu","Yifei Shi","Changhao Chen"],"pdf_url":"https://arxiv.org/pdf/2401.09160v2.pdf","comment":"In submission"},{"id":"http://arxiv.org/abs/2406.17249v1","updated":"2024-06-25T03:34:02Z","published":"2024-06-25T03:34:02Z","title":"SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for\n  Multi-Robot Navigation","summary":"  This paper develops a real-time decentralized metric-semantic Simultaneous\nLocalization and Mapping (SLAM) approach that leverages a sparse and\nlightweight object-based representation to enable a heterogeneous robot team to\nautonomously explore 3D environments featuring indoor, urban, and forested\nareas without relying on GPS. We use a hierarchical metric-semantic\nrepresentation of the environment, including high-level sparse semantic maps of\nobject models and low-level voxel maps. We leverage the informativeness and\nviewpoint invariance of the high-level semantic map to obtain an effective\nsemantics-driven place-recognition algorithm for inter-robot loop closure\ndetection across aerial and ground robots with different sensing modalities. A\ncommunication module is designed to track each robot's observations and those\nof other robots within the communication range. Such observations are then used\nto construct a merged map. Our framework enables real-time decentralized\noperations onboard robots, allowing them to opportunistically leverage\ncommunication. We integrate and deploy our proposed framework on three types of\naerial and ground robots. Extensive experimental results show an average\nlocalization error of 0.22 meters in position and -0.16 degrees in orientation,\nan object mapping F1 score of 0.92, and a communication packet size of merely\n2-3 megabytes per kilometer trajectory with 1,000 landmarks. The project\nwebsite can be found at https://xurobotics.github.io/slideslam/.\n","authors":["Xu Liu","Jiuzhou Lei","Ankit Prabhu","Yuezhan Tao","Igor Spasojevic","Pratik Chaudhari","Nikolay Atanasov","Vijay Kumar"],"pdf_url":"https://arxiv.org/pdf/2406.17249v1.pdf","comment":"Preliminary release"},{"id":"http://arxiv.org/abs/2402.09246v4","updated":"2024-06-25T02:55:44Z","published":"2024-02-14T15:34:38Z","title":"Who Plays First? Optimizing the Order of Play in Stackelberg Games with\n  Many Robots","summary":"  We consider the multi-agent spatial navigation problem of computing the\nsocially optimal order of play, i.e., the sequence in which the agents commit\nto their decisions, and its associated equilibrium in an N-player Stackelberg\ntrajectory game. We model this problem as a mixed-integer optimization problem\nover the space of all possible Stackelberg games associated with the order of\nplay's permutations. To solve the problem, we introduce Branch and Play (B&P),\nan efficient and exact algorithm that provably converges to a socially optimal\norder of play and its Stackelberg equilibrium. As a subroutine for B&P, we\nemploy and extend sequential trajectory planning, i.e., a popular multi-agent\ncontrol approach, to scalably compute valid local Stackelberg equilibria for\nany given order of play. We demonstrate the practical utility of B&P to\ncoordinate air traffic control, swarm formation, and delivery vehicle fleets.\nWe find that B&P consistently outperforms various baselines, and computes the\nsocially optimal equilibrium.\n","authors":["Haimin Hu","Gabriele Dragotto","Zixu Zhang","Kaiqu Liang","Bartolomeo Stellato","Jaime F. Fisac"],"pdf_url":"https://arxiv.org/pdf/2402.09246v4.pdf","comment":"Robotics: Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2405.07536v6","updated":"2024-06-25T01:43:43Z","published":"2024-05-13T08:09:24Z","title":"Multi-AUV Kinematic Task Assignment based on Self-organizing Map Neural\n  Network and Dubins Path Generator","summary":"  To deal with the task assignment problem of multi-AUV systems under kinematic\nconstraints, which means steering capability constraints for underactuated AUVs\nor other vehicles likely, an improved task assignment algorithm is proposed\ncombining the Dubins Path algorithm with improved SOM neural network algorithm.\nAt first, the aimed tasks are assigned to the AUVs by improved SOM neural\nnetwork method based on workload balance and neighborhood function. When there\nexists kinematic constraints or obstacles which may cause failure of trajectory\nplanning, task re-assignment will be implemented by change the weights of SOM\nneurals, until the AUVs can have paths to reach all the targets. Then, the\nDubins paths are generated in several limited cases. AUV's yaw angle is\nlimited, which result in new assignments to the targets. Computation flow is\ndesigned so that the algorithm in MATLAB and Python can realizes the path\nplanning to multiple targets. Finally, simulation results prove that the\nproposed algorithm can effectively accomplish the task assignment task for\nmulti-AUV system.\n","authors":["Xin Li","Wenyang Gan","Pang Wen","Daqi Zhu"],"pdf_url":"https://arxiv.org/pdf/2405.07536v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09933v2","updated":"2024-06-25T23:26:47Z","published":"2024-03-15T00:17:38Z","title":"Design and Control Co-Optimization for Automated Design Iteration of\n  Dexterous Anthropomorphic Soft Robotic Hands","summary":"  We automate soft robotic hand design iteration by co-optimizing design and\ncontrol policy for dexterous manipulation skills in simulation. Our design\niteration pipeline combines genetic algorithms and policy transfer to learn\ncontrol policies for nearly 400 hand designs, testing grasp quality under\nexternal force disturbances. We validate the optimized designs in the real\nworld through teleoperation of pickup and reorient manipulation tasks. Our real\nworld evaluation, from over 900 teleoperated tasks, shows that the trend in\ndesign performance in simulation resembles that of the real world. Furthermore,\nwe show that optimized hand designs from our approach outperform existing soft\nrobot hands from prior work in the real world. The results highlight the\nusefulness of simulation in guiding parameter choices for anthropomorphic soft\nrobotic hand systems, and the effectiveness of our automated design iteration\napproach, despite the sim-to-real gap.\n","authors":["Pragna Mannam","Xingyu Liu","Ding Zhao","Jean Oh","Nancy Pollard"],"pdf_url":"https://arxiv.org/pdf/2403.09933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02416v3","updated":"2024-06-25T22:21:17Z","published":"2024-01-04T18:59:25Z","title":"ODIN: A Single Model for 2D and 3D Segmentation","summary":"  State-of-the-art models on contemporary 3D segmentation benchmarks like\nScanNet consume and label dataset-provided 3D point clouds, obtained through\npost processing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website (https://odin-seg.github.io).\n","authors":["Ayush Jain","Pushkal Katara","Nikolaos Gkanatsios","Adam W. Harley","Gabriel Sarch","Kriti Aggarwal","Vishrav Chaudhary","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2401.02416v3.pdf","comment":"Camera Ready (CVPR 2024, Highlight)"},{"id":"http://arxiv.org/abs/2406.17932v1","updated":"2024-06-25T20:47:10Z","published":"2024-06-25T20:47:10Z","title":"SonicSense: Object Perception from In-Hand Acoustic Vibration","summary":"  We introduce SonicSense, a holistic design of hardware and software to enable\nrich robot object perception through in-hand acoustic vibration sensing. While\nprevious studies have shown promising results with acoustic sensing for object\nperception, current solutions are constrained to a handful of objects with\nsimple geometries and homogeneous materials, single-finger sensing, and mixing\ntraining and testing on the same objects. SonicSense enables container\ninventory status differentiation, heterogeneous material prediction, 3D shape\nreconstruction, and object re-identification from a diverse set of 83\nreal-world objects. Our system employs a simple but effective heuristic\nexploration policy to interact with the objects as well as end-to-end\nlearning-based algorithms to fuse vibration signals to infer object properties.\nOur framework underscores the significance of in-hand acoustic vibration\nsensing in advancing robot tactile perception.\n","authors":["Jiaxun Liu","Boyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2406.17932v1.pdf","comment":"Our project website is at: http://generalroboticslab.com/SonicSense"},{"id":"http://arxiv.org/abs/2210.09531v2","updated":"2024-06-25T19:35:40Z","published":"2022-10-18T01:48:32Z","title":"The Brain-Inspired Cooperative Shared Control for Brain-Machine\n  Interface","summary":"  In the practical application of brain-machine interface technology, the\nproblem often faced is the low information content and high noise of the neural\nsignals collected by the electrode and the difficulty of decoding by the\ndecoder, which makes it difficult for the robotic to obtain stable instructions\nto complete the task. The idea based on the principle of cooperative shared\ncontrol can be achieved by extracting general motor commands from brain\nactivity, while the fine details of the movement can be hosted to the robot for\ncompletion, or the brain can have complete control. This study proposes a\nbrain-machine interface shared control system based on spiking neural networks\nfor robotic arm movement control and wheeled robots wheel speed control and\nsteering, respectively. The former can reliably control the robotic arm to move\nto the destination position, while the latter controls the wheeled robots for\nobject tracking and map generation. The results show that the shared control\nbased on brain-inspired intelligence can perform some typical tasks in complex\nenvironments and positively improve the fluency and ease of use of\nbrain-machine interaction, and also demonstrate the potential of this control\nmethod in clinical applications of brain-machine interfaces.\n","authors":["Shengjie Zheng","Ling Liu","Junjie Yang","Lang Qian","Gang Gao","Xin Chen","Wenqi Jin","Chunshan Deng","Xiaojian Li"],"pdf_url":"https://arxiv.org/pdf/2210.09531v2.pdf","comment":"This article need to update the corrected figure and data"},{"id":"http://arxiv.org/abs/2406.17898v1","updated":"2024-06-25T19:19:10Z","published":"2024-06-25T19:19:10Z","title":"Human-centered In-building Embodied Delivery Benchmark","summary":"  Recently, the concept of embodied intelligence has been widely accepted and\npopularized, leading people to naturally consider the potential for\ncommercialization in this field. In this work, we propose a specific commercial\nscenario simulation, human-centered in-building embodied delivery. Furthermore,\nfor this scenario, we have developed a brand-new virtual environment system\nfrom scratch, constructing a multi-level connected building space modeled after\na polar research station. This environment also includes autonomous human\ncharacters and robots with grasping and mobility capabilities, as well as a\nlarge number of interactive items. Based on this environment, we have built a\ndelivery dataset containing 13k language instructions to guide robots in\nproviding services. We simulate human behavior through human characters and\nsample their various needs in daily life. Finally, we proposed a method\ncentered around a large multimodal model to serve as the baseline system for\nthis dataset. Compared to past embodied data work, our work focuses on a\nvirtual environment centered around human-robot interaction for commercial\nscenarios. We believe this will bring new perspectives and exploration angles\nto the embodied community.\n","authors":["Zhuoqun Xu","Yang Liu","Xiaoqi Li","Jiyao Zhang","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2406.17898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17876v1","updated":"2024-06-25T18:35:13Z","published":"2024-06-25T18:35:13Z","title":"ET tu, CLIP? Addressing Common Object Errors for Unseen Environments","summary":"  We introduce a simple method that employs pre-trained CLIP encoders to\nenhance model generalization in the ALFRED task. In contrast to previous\nliterature where CLIP replaces the visual encoder, we suggest using CLIP as an\nadditional module through an auxiliary object detection objective. We validate\nour method on the recently proposed Episodic Transformer architecture and\ndemonstrate that incorporating CLIP improves task performance on the unseen\nvalidation set. Additionally, our analysis results support that CLIP especially\nhelps with leveraging object descriptions, detecting small objects, and\ninterpreting rare words.\n","authors":["Ye Won Byun","Cathy Jiao","Shahriar Noroozizadeh","Jimin Sun","Rosa Vitiello"],"pdf_url":"https://arxiv.org/pdf/2406.17876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06415v3","updated":"2024-06-25T18:22:21Z","published":"2022-09-14T04:58:03Z","title":"DMCA: Dense Multi-agent Navigation using Attention and Communication","summary":"  In decentralized multi-robot navigation, ensuring safe and efficient movement\nwith limited environmental awareness remains a challenge. While robots\ntraditionally navigate based on local observations, this approach falters in\ncomplex environments. A possible solution is to enhance understanding of the\nworld through inter-agent communication, but mere information broadcasting\nfalls short in efficiency. In this work, we address this problem by\nsimultaneously learning decentralized multi-robot collision avoidance and\nselective inter-agent communication. We use a multi-head self-attention\nmechanism that encodes observable information from neighboring robots into a\nconcise and fixed-length observation vector, thereby handling varying numbers\nof neighbors. Our method focuses on improving navigation performance through\nselective communication. We cast the communication selection as a link\nprediction problem, where the network determines the necessity of establishing\na communication link with a specific neighbor based on the observable state\ninformation. The communicated information enhances the neighbor's observation\nand aids in selecting an appropriate navigation plan. By training the network\nend-to-end, we concurrently learn the optimal weights for the observation\nencoder, communication selection, and navigation components. We showcase the\nbenefits of our approach by achieving safe and efficient navigation among\nmultiple robots, even in dense and challenging environments. Comparative\nevaluations against various learning-based and model-based baselines\ndemonstrate our superior navigation performance, resulting in an impressive\nimprovement of up to 24% in success rate within complex evaluation scenarios.\n","authors":["Senthil Hariharan Arul","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2209.06415v3.pdf","comment":null}]},"2024-06-26T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2406.07544v2","updated":"2024-06-26T17:59:50Z","published":"2024-06-11T17:59:45Z","title":"Situational Awareness Matters in 3D Vision Language Reasoning","summary":"  Being able to carry out complicated vision language reasoning tasks in 3D\nspace represents a significant milestone in developing household robots and\nhuman-centered embodied AI. In this work, we demonstrate that a critical and\ndistinct challenge in 3D vision language reasoning is situational awareness,\nwhich incorporates two key components: (1) The autonomous agent grounds its\nself-location based on a language prompt. (2) The agent answers open-ended\nquestions from the perspective of its calculated position. To address this\nchallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D\nvision language reasoning. We tokenize the 3D scene into sparse voxel\nrepresentation and propose a language-grounded situation estimator, followed by\na situated question answering module. Experiments on the SQA3D and ScanQA\ndatasets show that SIG3D outperforms state-of-the-art models in situation\nestimation and question answering by a large margin (e.g., an enhancement of\nover 30% on situation estimation accuracy). Subsequent analysis corroborates\nour architectural design choices, explores the distinct functions of visual and\ntextual tokens, and highlights the importance of situational awareness in the\ndomain of 3D question answering.\n","authors":["Yunze Man","Liang-Yan Gui","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2406.07544v2.pdf","comment":"CVPR 2024. Project Page: https://yunzeman.github.io/situation3d"},{"id":"http://arxiv.org/abs/2406.18532v1","updated":"2024-06-26T17:59:18Z","published":"2024-06-26T17:59:18Z","title":"Symbolic Learning Enables Self-Evolving Agents","summary":"  The AI community has been exploring a pathway to artificial general\nintelligence (AGI) by developing \"language agents\", which are complex large\nlanguage models (LLMs) pipelines involving both prompting techniques and tool\nusage methods. While language agents have demonstrated impressive capabilities\nfor many real-world tasks, a fundamental limitation of current language agents\nresearch is that they are model-centric, or engineering-centric. That's to say,\nthe progress on prompts, tools, and pipelines of language agents requires\nsubstantial manual engineering efforts from human experts rather than\nautomatically learning from data. We believe the transition from model-centric,\nor engineering-centric, to data-centric, i.e., the ability of language agents\nto autonomously learn and evolve in environments, is the key for them to\npossibly achieve AGI.\n  In this work, we introduce agent symbolic learning, a systematic framework\nthat enables language agents to optimize themselves on their own in a\ndata-centric way using symbolic optimizers. Specifically, we consider agents as\nsymbolic networks where learnable weights are defined by prompts, tools, and\nthe way they are stacked together. Agent symbolic learning is designed to\noptimize the symbolic network within language agents by mimicking two\nfundamental algorithms in connectionist learning: back-propagation and gradient\ndescent. Instead of dealing with numeric weights, agent symbolic learning works\nwith natural language simulacrums of weights, loss, and gradients. We conduct\nproof-of-concept experiments on both standard benchmarks and complex real-world\ntasks and show that agent symbolic learning enables language agents to update\nthemselves after being created and deployed in the wild, resulting in\n\"self-evolving agents\".\n","authors":["Wangchunshu Zhou","Yixin Ou","Shengwei Ding","Long Li","Jialong Wu","Tiannan Wang","Jiamin Chen","Shuai Wang","Xiaohua Xu","Ningyu Zhang","Huajun Chen","Yuchen Eleanor Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.18532v1.pdf","comment":"Code available at https://github.com/aiwaves-cn/agents"},{"id":"http://arxiv.org/abs/2406.18518v1","updated":"2024-06-26T17:49:11Z","published":"2024-06-26T17:49:11Z","title":"APIGen: Automated Pipeline for Generating Verifiable and Diverse\n  Function-Calling Datasets","summary":"  The advancement of function-calling agent models requires diverse, reliable,\nand high-quality datasets. This paper presents APIGen, an automated data\ngeneration pipeline designed to synthesize verifiable high-quality datasets for\nfunction-calling applications. We leverage APIGen and collect 3,673 executable\nAPIs across 21 different categories to generate diverse function-calling\ndatasets in a scalable and structured manner. Each data in our dataset is\nverified through three hierarchical stages: format checking, actual function\nexecutions, and semantic verification, ensuring its reliability and\ncorrectness. We demonstrate that models trained with our curated datasets, even\nwith only 7B parameters, can achieve state-of-the-art performance on the\nBerkeley Function-Calling Benchmark, outperforming multiple GPT-4 models.\nMoreover, our 1B model achieves exceptional performance, surpassing\nGPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000\nhigh-quality entries, aiming to advance the field of function-calling agent\ndomains. The dataset is available on Huggingface:\nhttps://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and the\nproject homepage: https://apigen-pipeline.github.io/\n","authors":["Zuxin Liu","Thai Hoang","Jianguo Zhang","Ming Zhu","Tian Lan","Shirley Kokane","Juntao Tan","Weiran Yao","Zhiwei Liu","Yihao Feng","Rithesh Murthy","Liangwei Yang","Silvio Savarese","Juan Carlos Niebles","Huan Wang","Shelby Heinecke","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.18518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00716v3","updated":"2024-06-26T17:48:18Z","published":"2024-04-25T15:51:06Z","title":"Large Language Models in the Clinic: A Comprehensive Benchmark","summary":"  The adoption of large language models (LLMs) to assist clinicians has\nattracted remarkable attention. Existing works mainly adopt the close-ended\nquestion-answering (QA) task with answer options for evaluation. However, many\nclinical decisions involve answering open-ended questions without pre-set\noptions. To better understand LLMs in the clinic, we construct a benchmark\nClinicBench. We first collect eleven existing datasets covering diverse\nclinical language generation, understanding, and reasoning tasks. Furthermore,\nwe construct six novel datasets and complex clinical tasks that are close to\nreal-world practice, i.e., referral QA, treatment recommendation,\nhospitalization (long document) summarization, patient education, pharmacology\nQA and drug interaction for emerging drugs. We conduct an extensive evaluation\nof twenty-two LLMs under both zero-shot and few-shot settings. Finally, we\ninvite medical experts to evaluate the clinical usefulness of LLMs.\n","authors":["Andrew Liu","Hongjian Zhou","Yining Hua","Omid Rohanian","Anshul Thakur","Lei Clifton","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2405.00716v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10552v2","updated":"2024-06-26T17:42:59Z","published":"2024-06-15T08:13:47Z","title":"Large Language Model Enhanced Clustering for News Event Detection","summary":"  The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labeling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes latent feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that combining LLM embeddings with clustering algorithms yields the\nbest results, demonstrating greater robustness in terms of CSAI scores.\nMoreover, post-event detection tasks generate meaningful insights, facilitating\neffective interpretation of event clustering results. Overall, our experimental\nresults indicate that the proposed framework offers valuable insights and could\nenhance the accuracy and depth of news reporting.\n","authors":["Adane Nega Tarekegn"],"pdf_url":"https://arxiv.org/pdf/2406.10552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01248v3","updated":"2024-06-26T17:40:14Z","published":"2023-11-02T14:02:42Z","title":"Multimodal and Force-Matched Imitation Learning with a See-Through\n  Visuotactile Sensor","summary":"  Contact-rich tasks continue to present a variety of challenges for robotic\nmanipulation. In this work, we leverage a multimodal visuotactile sensor within\nthe framework of imitation learning (IL) to perform contact rich tasks that\ninvolve relative motion (slipping/sliding) between the end-effector and object.\nWe introduce two algorithmic contributions, tactile force matching and learned\nmode switching, as complimentary methods for improving IL. Tactile force\nmatching enhances kinesthetic teaching by reading approximate forces during the\ndemonstration and generating an adapted robot trajectory that recreates the\nrecorded forces. Learned mode switching uses IL to couple visual and tactile\nsensor modes with the learned motion policy, simplifying the transition from\nreaching to contacting. We perform robotic manipulation experiments on four\ndoor opening tasks with a variety of observation and method configurations to\nstudy the utility of our proposed improvements and multimodal visuotactile\nsensing. Our results show that the inclusion of force matching raises average\npolicy success rates by 62.5%, visuotactile mode switching by 30.3%, and\nvisuotactile data as a policy input by 42.5%, emphasizing the value of\nsee-through tactile sensing for IL, both for data collection to allow force\nmatching, and for policy execution to allow accurate task feedback.\n","authors":["Trevor Ablett","Oliver Limoyo","Adam Sigal","Affan Jilani","Jonathan Kelly","Kaleem Siddiqi","Francois Hogan","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2311.01248v3.pdf","comment":"Submitted to IEEE Transactions on Robotics (T-RO): Special Section on\n  Tactile Robotics"},{"id":"http://arxiv.org/abs/2406.16990v2","updated":"2024-06-26T17:36:53Z","published":"2024-06-24T06:02:07Z","title":"AND: Audio Network Dissection for Interpreting Deep Acoustic Models","summary":"  Neuron-level interpretations aim to explain network behaviors and properties\nby investigating neurons responsive to specific perceptual or structural input\npatterns. Although there is emerging work in the vision and language domains,\nnone is explored for acoustic models. To bridge the gap, we introduce\n$\\textit{AND}$, the first $\\textbf{A}$udio $\\textbf{N}$etwork\n$\\textbf{D}$issection framework that automatically establishes natural language\nexplanations of acoustic neurons based on highly-responsive audio.\n$\\textit{AND}$ features the use of LLMs to summarize mutual acoustic features\nand identities among audio. Extensive experiments are conducted to verify\n$\\textit{AND}$'s precise and informative descriptions. In addition, we\ndemonstrate a potential use of $\\textit{AND}$ for audio machine unlearning by\nconducting concept-specific pruning based on the generated descriptions.\nFinally, we highlight two acoustic model behaviors with analysis by\n$\\textit{AND}$: (i) models discriminate audio with a combination of basic\nacoustic features rather than high-level abstract concepts; (ii) training\nstrategies affect model behaviors and neuron interpretability -- supervised\ntraining guides neurons to gradually narrow their attention, while\nself-supervised learning encourages neurons to be polysemantic for exploring\nhigh-level features.\n","authors":["Tung-Yu Wu","Yu-Xiang Lin","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2406.16990v2.pdf","comment":"Accepted by ICML'24"},{"id":"http://arxiv.org/abs/2406.18505v1","updated":"2024-06-26T17:14:45Z","published":"2024-06-26T17:14:45Z","title":"Mental Modeling of Reinforcement Learning Agents by Language Models","summary":"  Can emergent language models faithfully model the intelligence of\ndecision-making agents? Though modern language models exhibit already some\nreasoning ability, and theoretically can potentially express any probable\ndistribution over tokens, it remains underexplored how the world knowledge\nthese pretrained models have memorized can be utilized to comprehend an agent's\nbehaviour in the physical world. This study empirically examines, for the first\ntime, how well large language models (LLMs) can build a mental model of agents,\ntermed agent mental modelling, by reasoning about an agent's behaviour and its\neffect on states from agent interaction history. This research may unveil the\npotential of leveraging LLMs for elucidating RL agent behaviour, addressing a\nkey challenge in eXplainable reinforcement learning (XRL). To this end, we\npropose specific evaluation metrics and test them on selected RL task datasets\nof varying complexity, reporting findings on agent mental model establishment.\nOur results disclose that LLMs are not yet capable of fully mental modelling\nagents through inference alone without further innovations. This work thus\nprovides new insights into the capabilities and limitations of modern LLMs.\n","authors":["Wenhao Lu","Xufeng Zhao","Josua Spisak","Jae Hee Lee","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2406.18505v1.pdf","comment":"https://lukaswill.github.io/"},{"id":"http://arxiv.org/abs/2406.15877v2","updated":"2024-06-26T17:05:14Z","published":"2024-06-22T15:52:04Z","title":"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls\n  and Complex Instructions","summary":"  Automated software engineering has been greatly empowered by the recent\nadvances in Large Language Models (LLMs) for programming. While current\nbenchmarks have shown that LLMs can perform various software engineering tasks\nlike human developers, the majority of their evaluations are limited to short\nand self-contained algorithmic tasks. Solving challenging and practical\nprogramming tasks requires the capability of utilizing diverse function calls\nas tools to efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.\nTo assess how well LLMs can solve challenging and practical programming tasks,\nwe introduce Bench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\nprogramming tasks. To evaluate LLMs rigorously, each programming task\nencompasses 5.6 test cases with an average branch coverage of 99%. In addition,\nwe propose a natural-language-oriented variant of Bench, Benchi, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.\n","authors":["Terry Yue Zhuo","Minh Chien Vu","Jenny Chim","Han Hu","Wenhao Yu","Ratnadira Widyasari","Imam Nur Bani Yusuf","Haolan Zhan","Junda He","Indraneil Paul","Simon Brunner","Chen Gong","Thong Hoang","Armel Randy Zebaze","Xiaoheng Hong","Wen-Ding Li","Jean Kaddour","Ming Xu","Zhihan Zhang","Prateek Yadav","Naman Jain","Alex Gu","Zhoujun Cheng","Jiawei Liu","Qian Liu","Zijian Wang","David Lo","Binyuan Hui","Niklas Muennighoff","Daniel Fried","Xiaoning Du","Harm de Vries","Leandro Von Werra"],"pdf_url":"https://arxiv.org/pdf/2406.15877v2.pdf","comment":"44 pages, 14 figures, 7 tables, built with love by the BigCode\n  community :)"},{"id":"http://arxiv.org/abs/2402.08609v3","updated":"2024-06-26T16:50:01Z","published":"2024-02-13T17:18:56Z","title":"Mixtures of Experts Unlock Parameter Scaling for Deep RL","summary":"  The recent rapid progress in (self) supervised learning models is in large\npart predicted by empirical scaling laws: a model's performance scales\nproportionally to its size. Analogous scaling laws remain elusive for\nreinforcement learning domains, however, where increasing the parameter count\nof a model often hurts its final performance. In this paper, we demonstrate\nthat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs\n(Puigcerver et al., 2023), into value-based networks results in more\nparameter-scalable models, evidenced by substantial performance increases\nacross a variety of training regimes and model sizes. This work thus provides\nstrong empirical evidence towards developing scaling laws for reinforcement\nlearning.\n","authors":["Johan Obando-Ceron","Ghada Sokar","Timon Willi","Clare Lyle","Jesse Farebrother","Jakob Foerster","Gintare Karolina Dziugaite","Doina Precup","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2402.08609v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15009v2","updated":"2024-06-26T16:26:50Z","published":"2024-06-21T09:38:03Z","title":"Fair, Manipulation-Robust, and Transparent Sortition","summary":"  Sortition, the random selection of political representatives, is increasingly\nbeing used around the world to choose participants of deliberative processes\nlike Citizens' Assemblies. Motivated by sortition's practical importance, there\nhas been a recent flurry of research on sortition algorithms, whose task it is\nto select a panel from among a pool of volunteers. This panel must satisfy\nquotas enforcing representation of key population subgroups. Past work has\ncontributed an algorithmic approach for fulfilling this task while ensuring\nthat volunteers' chances of selection are maximally equal, as measured by any\nconvex equality objective. The question, then, is: which equality objective is\nthe right one? Past work has mainly studied the objectives Minimax and Leximin,\nwhich respectively minimize the maximum and maximize the minimum chance of\nselection given to any volunteer. Recent work showed that both of these\nobjectives have key weaknesses: Minimax is highly robust to manipulation but is\narbitrarily unfair; oppositely, Leximin is highly fair but arbitrarily\nmanipulable.\n  In light of this gap, we propose a new equality objective, Goldilocks, that\naims to achieve these ideals simultaneously by ensuring that no volunteer\nreceives too little or too much chance of selection. We theoretically bound the\nextent to which Goldilocks achieves these ideals, finding that in an important\nsense, Goldilocks recovers among the best available solutions in a given\ninstance. We then extend our bounds to the case where the output of Goldilocks\nis transformed to achieve a third goal, Transparency. Our empirical analysis of\nGoldilocks in real data is even more promising: we find that this objective\nachieves nearly instance-optimal minimum and maximum selection probabilities\nsimultaneously in most real instances -- an outcome not even guaranteed to be\npossible for any algorithm.\n","authors":["Carmel Baharav","Bailey Flanigan"],"pdf_url":"https://arxiv.org/pdf/2406.15009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02706v2","updated":"2024-06-26T16:11:55Z","published":"2023-12-05T12:07:30Z","title":"Large Knowledge Model: Perspectives and Challenges","summary":"  Humankind's understanding of the world is fundamentally linked to our\nperception and cognition, with \\emph{human languages} serving as one of the\nmajor carriers of \\emph{world knowledge}. In this vein, \\emph{Large Language\nModels} (LLMs) like ChatGPT epitomize the pre-training of extensive,\nsequence-based world knowledge into neural networks, facilitating the\nprocessing and manipulation of this knowledge in a parametric space. This\narticle explores large models through the lens of \"knowledge\". We initially\ninvestigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in\nenhancing LLMs, covering aspects like knowledge-augmented language model,\nstructure-inducing pre-training, knowledgeable prompts, structured CoT,\nknowledge editing, semantic tools for LLM and knowledgeable AI agents.\nSubsequently, we examine how LLMs can boost traditional symbolic knowledge\nbases, encompassing aspects like using LLM as KG builder and controller,\nstructured knowledge pretraining, and LLM-enhanced symbolic reasoning.\nConsidering the intricate nature of human knowledge, we advocate for the\ncreation of \\emph{Large Knowledge Models} (LKM), specifically engineered to\nmanage diversified spectrum of knowledge structures. This promising undertaking\nwould entail several key challenges, such as disentangling knowledge base from\nlanguage models, cognitive alignment with human knowledge, integration of\nperception and cognition, and building large commonsense models for interacting\nwith physical world, among others. We finally propose a five-\"A\" principle to\ndistinguish the concept of LKM.\n","authors":["Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2312.02706v2.pdf","comment":"Data Intelligence, Published: Jun 18, 2024"},{"id":"http://arxiv.org/abs/2406.18460v1","updated":"2024-06-26T16:10:53Z","published":"2024-06-26T16:10:53Z","title":"Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain\n  Human-Machine Conversation","summary":"  Recently, various methods have been proposed to create open-domain\nconversational agents with Large Language Models (LLMs). These models are able\nto answer user queries, but in a one-way Q&A format rather than a true\nconversation. Fine-tuning on particular datasets is the usual way to modify\ntheir style to increase conversational ability, but this is expensive and\nusually only available in a few languages. In this study, we explore role-play\nzero-shot prompting as an efficient and cost-effective solution for open-domain\nconversation, using capable multilingual LLMs (Beeching et al., 2023) trained\nto obey instructions. We design a prompting system that, when combined with an\ninstruction-following model - here Vicuna (Chiang et al., 2023) - produces\nconversational agents that match and even surpass fine-tuned models in human\nevaluation in French in two different tasks.\n","authors":["Ahmed Njifenjou","Virgile Sucal","Bassam Jabaian","Fabrice Lefèvre"],"pdf_url":"https://arxiv.org/pdf/2406.18460v1.pdf","comment":"Updated version of a paper originally submitted at SIGDIAL 2023"},{"id":"http://arxiv.org/abs/2406.14711v2","updated":"2024-06-26T16:05:20Z","published":"2024-06-20T20:09:37Z","title":"MultiAgent Collaboration Attack: Investigating Adversarial Attacks in\n  Large Language Model Collaborations via Debate","summary":"  Large Language Models (LLMs) have shown exceptional results on current\nbenchmarks when working individually. The advancement in their capabilities,\nalong with a reduction in parameter size and inference times, has facilitated\nthe use of these models as agents, enabling interactions among multiple models\nto execute complex tasks. Such collaborations offer several advantages,\nincluding the use of specialized models (e.g. coding), improved confidence\nthrough multiple computations, and enhanced divergent thinking, leading to more\ndiverse outputs. Thus, the collaborative use of language models is expected to\ngrow significantly in the coming years. In this work, we evaluate the behavior\nof a network of models collaborating through debate under the influence of an\nadversary. We introduce pertinent metrics to assess the adversary's\neffectiveness, focusing on system accuracy and model agreement. Our findings\nhighlight the importance of a model's persuasive ability in influencing others.\nAdditionally, we explore inference-time methods to generate more compelling\narguments and evaluate the potential of prompt-based mitigation as a defensive\nstrategy.\n","authors":["Alfonso Amayuelas","Xianjun Yang","Antonis Antoniades","Wenyue Hua","Liangming Pan","William Wang"],"pdf_url":"https://arxiv.org/pdf/2406.14711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18451v1","updated":"2024-06-26T16:00:35Z","published":"2024-06-26T16:00:35Z","title":"Detecting Brittle Decisions for Free: Leveraging Margin Consistency in\n  Deep Robust Classifiers","summary":"  Despite extensive research on adversarial training strategies to improve\nrobustness, the decisions of even the most robust deep learning models can\nstill be quite sensitive to imperceptible perturbations, creating serious risks\nwhen deploying them for high-stakes real-world applications. While detecting\nsuch cases may be critical, evaluating a model's vulnerability at a\nper-instance level using adversarial attacks is computationally too intensive\nand unsuitable for real-time deployment scenarios. The input space margin is\nthe exact score to detect non-robust samples and is intractable for deep neural\nnetworks. This paper introduces the concept of margin consistency -- a property\nthat links the input space margins and the logit margins in robust models --\nfor efficient detection of vulnerable samples. First, we establish that margin\nconsistency is a necessary and sufficient condition to use a model's logit\nmargin as a score for identifying non-robust samples. Next, through\ncomprehensive empirical analysis of various robustly trained models on CIFAR10\nand CIFAR100 datasets, we show that they indicate strong margin consistency\nwith a strong correlation between their input space margins and the logit\nmargins. Then, we show that we can effectively use the logit margin to\nconfidently detect brittle decisions with such models and accurately estimate\nrobust accuracy on an arbitrarily large test set by estimating the input\nmargins only on a small subset. Finally, we address cases where the model is\nnot sufficiently margin-consistent by learning a pseudo-margin from the feature\nrepresentation. Our findings highlight the potential of leveraging deep\nrepresentations to efficiently assess adversarial vulnerability in deployment\nscenarios.\n","authors":["Jonas Ngnawé","Sabyasachi Sahoo","Yann Pequignot","Frédéric Precioso","Christian Gagné"],"pdf_url":"https://arxiv.org/pdf/2406.18451v1.pdf","comment":"11 pages, 7 figures, 2 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2406.18450v1","updated":"2024-06-26T15:59:13Z","published":"2024-06-26T15:59:13Z","title":"Preference Elicitation for Offline Reinforcement Learning","summary":"  Applying reinforcement learning (RL) to real-world problems is often made\nchallenging by the inability to interact with the environment and the\ndifficulty of designing reward functions. Offline RL addresses the first\nchallenge by considering access to an offline dataset of environment\ninteractions labeled by the reward function. In contrast, Preference-based RL\ndoes not assume access to the reward function and learns it from preferences,\nbut typically requires an online interaction with the environment. We bridge\nthe gap between these frameworks by exploring efficient methods for acquiring\npreference feedback in a fully offline setup. We propose Sim-OPRL, an offline\npreference-based reinforcement learning algorithm, which leverages a learned\nenvironment model to elicit preference feedback on simulated rollouts. Drawing\non insights from both the offline RL and the preference-based RL literature,\nour algorithm employs a pessimistic approach for out-of-distribution data, and\nan optimistic approach for acquiring informative preferences about the optimal\npolicy. We provide theoretical guarantees regarding the sample complexity of\nour approach, dependent on how well the offline data covers the optimal policy.\nFinally, we demonstrate the empirical performance of Sim-OPRL in different\nenvironments.\n","authors":["Alizée Pace","Bernhard Schölkopf","Gunnar Rätsch","Giorgia Ramponi"],"pdf_url":"https://arxiv.org/pdf/2406.18450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15515v3","updated":"2024-06-26T15:57:22Z","published":"2024-04-23T20:59:03Z","title":"ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic\n  Executors in Large Language Models","summary":"  Theory of Mind (ToM) refers to the ability of individuals to attribute mental\nstates to others. While Large Language Models (LLMs) have shown some promise\nwith ToM ability, they still struggle with complex ToM reasoning. Our approach\nleverages an external symbolic executor, specifically the SMCDEL model checker,\nand fine-tuning to improve the ToM reasoning ability of LLMs. In our approach,\nan LLM is first fine-tuned through pairs of natural language and symbolic\nformulation representation of ToM problems and is then instructed to generate\nthe symbolic formulation with a one-shot in-context example. The generated\nsymbolic formulation is then executed by the SMCDEL model checker to perform\ntransparent and verifiable ToM reasoning and give the final result. We\ndemonstrate that our approach, ToM-LM, shows a significant improvement over all\nthe constructed baselines. Our study proposes a novel view about externalizing\na particular component of ToM reasoning, mainly reasoning about beliefs, and\nsuggests generalizing it to other aspects of ToM reasoning.\n","authors":["Weizhi Tang","Vaishak Belle"],"pdf_url":"https://arxiv.org/pdf/2404.15515v3.pdf","comment":"Accepted at NeSy 2024"},{"id":"http://arxiv.org/abs/2406.18449v1","updated":"2024-06-26T15:53:54Z","published":"2024-06-26T15:53:54Z","title":"Cascading Large Language Models for Salient Event Graph Generation","summary":"  Generating event graphs from long documents is challenging due to the\ninherent complexity of multiple tasks involved such as detecting events,\nidentifying their relationships, and reconciling unstructured input with\nstructured graphs. Recent studies typically consider all events with equal\nimportance, failing to distinguish salient events crucial for understanding\nnarratives. This paper presents CALLMSAE, a CAscading Large Language Model\nframework for SAlient Event graph generation, which leverages the capabilities\nof LLMs and eliminates the need for costly human annotations. We first identify\nsalient events by prompting LLMs to generate summaries, from which salient\nevents are identified. Next, we develop an iterative code refinement prompting\nstrategy to generate event relation graphs, removing hallucinated relations and\nrecovering missing edges. Fine-tuning contextualised graph generation models on\nthe LLM-generated graphs outperforms the models trained on CAEVO-generated\ndata. Experimental results on a human-annotated test set show that the proposed\nmethod generates salient and more accurate graphs, outperforming competitive\nbaselines.\n","authors":["Xingwei Tan","Yuxiang Zhou","Gabriele Pergola","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2406.18449v1.pdf","comment":"9 + 12 pages"},{"id":"http://arxiv.org/abs/2406.01389v2","updated":"2024-06-26T15:42:57Z","published":"2024-06-03T14:51:27Z","title":"RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy\n  Evaluation","summary":"  In many real-world decision problems there is partially observed, hidden or\nlatent information that remains fixed throughout an interaction. Such decision\nproblems can be modeled as Latent Markov Decision Processes (LMDPs), where a\nlatent variable is selected at the beginning of an interaction and is not\ndisclosed to the agent. In the last decade, there has been significant progress\nin solving LMDPs under different structural assumptions. However, for general\nLMDPs, there is no known learning algorithm that provably matches the existing\nlower bound (Kwon et al., 2021). We introduce the first sample-efficient\nalgorithm for LMDPs without any additional structural assumptions. Our result\nbuilds off a new perspective on the role of off-policy evaluation guarantees\nand coverage coefficients in LMDPs, a perspective, that has been overlooked in\nthe context of exploration in partially observed environments. Specifically, we\nestablish a novel off-policy evaluation lemma and introduce a new coverage\ncoefficient for LMDPs. Then, we show how these can be used to derive\nnear-optimal guarantees of an optimistic exploration algorithm. These results,\nwe believe, can be valuable for a wide range of interactive learning problems\nbeyond LMDPs, and especially, for partially observed environments.\n","authors":["Jeongyeol Kwon","Shie Mannor","Constantine Caramanis","Yonathan Efroni"],"pdf_url":"https://arxiv.org/pdf/2406.01389v2.pdf","comment":"Fixed typos + alpha"},{"id":"http://arxiv.org/abs/2311.14096v2","updated":"2024-06-26T15:26:44Z","published":"2023-11-23T16:45:56Z","title":"Cultural Bias and Cultural Alignment of Large Language Models","summary":"  Culture fundamentally shapes people's reasoning, behavior, and communication.\nAs people increasingly use generative artificial intelligence (AI) to expedite\nand automate personal and professional tasks, cultural values embedded in AI\nmodels may bias people's authentic expression and contribute to the dominance\nof certain cultures. We conduct a disaggregated evaluation of cultural bias for\nfive widely used large language models (OpenAI's GPT-4o/4-turbo/4/3.5-turbo/3)\nby comparing the models' responses to nationally representative survey data.\nAll models exhibit cultural values resembling English-speaking and Protestant\nEuropean countries. We test cultural prompting as a control strategy to\nincrease cultural alignment for each country/territory. For recent models\n(GPT-4, 4-turbo, 4o), this improves the cultural alignment of the models'\noutput for 71-81% of countries and territories. We suggest using cultural\nprompting and ongoing evaluation to reduce cultural bias in the output of\ngenerative AI.\n","authors":["Yan Tao","Olga Viberg","Ryan S. Baker","Rene F. Kizilcec"],"pdf_url":"https://arxiv.org/pdf/2311.14096v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18423v1","updated":"2024-06-26T15:18:49Z","published":"2024-06-26T15:18:49Z","title":"Graph Neural Networks for Emulation of Finite-Element Ice Dynamics in\n  Greenland and Antarctic Ice Sheets","summary":"  Although numerical models provide accurate solutions for ice sheet dynamics\nbased on physics laws, they accompany intensified computational demands to\nsolve partial differential equations. In recent years, convolutional neural\nnetworks (CNNs) have been widely used as statistical emulators for those\nnumerical models. However, since CNNs operate on regular grids, they cannot\nrepresent the refined meshes and computational efficiency of finite-element\nnumerical models. Therefore, instead of CNNs, this study adopts an equivariant\ngraph convolutional network (EGCN) as an emulator for the ice sheet dynamics\nmodeling. EGCN reproduces ice thickness and velocity changes in the Helheim\nGlacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44\ntimes faster computation time, respectively. Compared to the traditional CNN\nand graph convolutional network, EGCN shows outstanding accuracy in thickness\nprediction near fast ice streams by preserving the equivariance to the\ntranslation and rotation of graphs.\n","authors":["Younghyun Koo","Maryam Rahnemoonfar"],"pdf_url":"https://arxiv.org/pdf/2406.18423v1.pdf","comment":"6 pages, 2 figures, submitted to the ICML 2024 Workshop on Machine\n  Learning for Earth System Modeling"},{"id":"http://arxiv.org/abs/2406.18420v1","updated":"2024-06-26T15:15:15Z","published":"2024-06-26T15:15:15Z","title":"Mixture of Experts in a Mixture of RL settings","summary":"  Mixtures of Experts (MoEs) have gained prominence in (self-)supervised\nlearning due to their enhanced inference efficiency, adaptability to\ndistributed training, and modularity. Previous research has illustrated that\nMoEs can significantly boost Deep Reinforcement Learning (DRL) performance by\nexpanding the network's parameter count while reducing dormant neurons, thereby\nenhancing the model's learning capacity and ability to deal with\nnon-stationarity. In this work, we shed more light on MoEs' ability to deal\nwith non-stationarity and investigate MoEs in DRL settings with \"amplified\"\nnon-stationarity via multi-task training, providing further evidence that MoEs\nimprove learning capacity. In contrast to previous work, our multi-task results\nallow us to better understand the underlying causes for the beneficial effect\nof MoE in DRL training, the impact of the various MoE components, and insights\ninto how best to incorporate them in actor-critic-based DRL networks. Finally,\nwe also confirm results from previous work.\n","authors":["Timon Willi","Johan Obando-Ceron","Jakob Foerster","Karolina Dziugaite","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2406.18420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18414v1","updated":"2024-06-26T15:09:54Z","published":"2024-06-26T15:09:54Z","title":"BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using\n  Camera-LiDAR Data","summary":"  Compared with real-time multi-object tracking (MOT), offline multi-object\ntracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneous\nlink correction, and full track optimization but has to deal with the\nchallenges from bounding box misalignment and track evaluation, editing, and\nrefinement. This paper proposes \"BiTrack\", a 3D OMOT framework that includes\nmodules of 2D-3D detection fusion, initial trajectory generation, and\nbidirectional trajectory re-optimization to achieve optimal tracking results\nfrom camera-LiDAR data. The novelty of this paper includes threefold: (1)\ndevelopment of a point-level object registration technique that employs a\ndensity-based similarity metric to achieve accurate fusion of 2D-3D detection\nresults; (2) development of a set of data association and track management\nskills that utilizes a vertex-based similarity metric as well as false alarm\nrejection and track recovery mechanisms to generate reliable bidirectional\nobject trajectories; (3) development of a trajectory re-optimization scheme\nthat re-organizes track fragments of different fidelities in a greedy fashion,\nas well as refines each trajectory with completion and smoothing techniques.\nThe experiment results on the KITTI dataset demonstrate that BiTrack achieves\nthe state-of-the-art performance for 3D OMOT tasks in terms of accuracy and\nefficiency.\n","authors":["Kemiao Huang","Meiying Zhang","Qi Hao"],"pdf_url":"https://arxiv.org/pdf/2406.18414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12009v2","updated":"2024-06-26T15:00:52Z","published":"2023-12-19T09:58:54Z","title":"Active Preference Inference using Language Models and Probabilistic\n  Reasoning","summary":"  Actively inferring user preferences, for example by asking good questions, is\nimportant for any human-facing decision-making system. Active inference allows\nsuch systems to adapt and personalize themselves to nuanced individual\npreferences. To enable this ability for instruction-tuned large language models\n(LLMs), one may prompt them to ask users questions to infer their preferences,\ntransforming the language models into more robust, interactive systems.\nHowever, out of the box, these models are not efficient at extracting\npreferences: the questions they generate are not informative, requiring a high\nnumber of user interactions and impeding the usability of the downstream\nsystem. In this work, we introduce an inference-time algorithm that helps LLMs\nquickly infer preferences by using more informative questions. Our algorithm\nuses a probabilistic model whose conditional distributions are defined by\nprompting an LLM, and returns questions that optimize expected entropy and\nexpected model change. Results in a simplified interactive web shopping setting\nwith real product items show that an LLM equipped with our entropy reduction\nalgorithm outperforms baselines with the same underlying LLM on task\nperformance while using fewer user interactions.\n","authors":["Wasu Top Piriyakulkij","Volodymyr Kuleshov","Kevin Ellis"],"pdf_url":"https://arxiv.org/pdf/2312.12009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16772v2","updated":"2024-06-26T15:00:04Z","published":"2024-06-24T16:31:12Z","title":"OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?","summary":"  In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).\n","authors":["Zhen Huang","Zengzhi Wang","Shijie Xia","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.16772v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2406.18406v1","updated":"2024-06-26T14:57:38Z","published":"2024-06-26T14:57:38Z","title":"IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying\n  and Reweighting Context-Aware Neurons","summary":"  It is widely acknowledged that large language models (LLMs) encode a vast\nreservoir of knowledge after being trained on mass data. Recent studies\ndisclose knowledge conflicts in LLM generation, wherein outdated or incorrect\nparametric knowledge (i.e., encoded knowledge) contradicts new knowledge\nprovided in the context. To mitigate such knowledge conflicts, we propose a\nnovel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to\ncapitalize on neurons that are crucial in processing contextual cues.\nSpecifically, IRCAN first identifies neurons that significantly contribute to\ncontext processing, utilizing a context-aware attribution score derived from\nintegrated gradients. Subsequently, the identified context-aware neurons are\nstrengthened via reweighting. In doing so, we steer LLMs to generate\ncontext-sensitive outputs with respect to the new knowledge provided in the\ncontext. Extensive experiments conducted across a variety of models and tasks\ndemonstrate that IRCAN not only achieves remarkable improvements in handling\nknowledge conflicts but also offers a scalable, plug-andplay solution that can\nbe integrated seamlessly with existing models.\n","authors":["Dan Shi","Renren Jin","Tianhao Shen","Weilong Dong","Xinwei Wu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.18406v1.pdf","comment":"19 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2406.18394v1","updated":"2024-06-26T14:34:37Z","published":"2024-06-26T14:34:37Z","title":"AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha\n  Factors","summary":"  The variability and low signal-to-noise ratio in financial data, combined\nwith the necessity for interpretability, make the alpha factor mining workflow\na crucial component of quantitative investment. Transitioning from early manual\nextraction to genetic programming, the most advanced approach in this domain\ncurrently employs reinforcement learning to mine a set of combination factors\nwith fixed weights. However, the performance of resultant alpha factors\nexhibits inconsistency, and the inflexibility of fixed factor weights proves\ninsufficient in adapting to the dynamic nature of financial markets. To address\nthis issue, this paper proposes a two-stage formulaic alpha generating\nframework AlphaForge, for alpha factor mining and factor combination. This\nframework employs a generative-predictive neural network to generate factors,\nleveraging the robust spatial exploration capabilities inherent in deep\nlearning while concurrently preserving diversity. The combination model within\nthe framework incorporates the temporal performance of factors for selection\nand dynamically adjusts the weights assigned to each component alpha factor.\nExperiments conducted on real-world datasets demonstrate that our proposed\nmodel outperforms contemporary benchmarks in formulaic alpha factor mining.\nFurthermore, our model exhibits a notable enhancement in portfolio returns\nwithin the realm of quantitative investment.\n","authors":["Hao Shi","Cuicui Luo","Weili Song","Xinting Zhang","Xiang Ao"],"pdf_url":"https://arxiv.org/pdf/2406.18394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17775v2","updated":"2024-06-26T14:34:13Z","published":"2024-02-20T11:36:23Z","title":"WhaleNet: a Novel Deep Learning Architecture for Marine Mammals\n  Vocalizations on Watkins Marine Mammal Sound Database","summary":"  Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machine\nlearning applications. Nevertheless, the methodologies for data preparation,\npreprocessing, and classification documented in the literature exhibit\nconsiderable variability and are typically not applied to the dataset in its\nentirety. This study initially undertakes a concise review of the\nstate-of-the-art benchmarks pertaining to the dataset, with a particular focus\non clarifying data preparation and preprocessing techniques. Subsequently, we\nexplore the utilization of the Wavelet Scattering Transform (WST) and Mel\nspectrogram as preprocessing mechanisms for feature extraction. In this paper,\nwe introduce \\textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble\nNetwork), a sophisticated deep ensemble architecture for the classification of\nmarine mammal vocalizations, leveraging both WST and Mel spectrogram for\nenhanced feature discrimination. By integrating the insights derived from WST\nand Mel representations, we achieved an improvement in classification accuracy\nby $8-10\\%$ over existing architectures, corresponding to a classification\naccuracy of $97.61\\%$.\n","authors":["Alessandro Licciardi","Davide Carbone"],"pdf_url":"https://arxiv.org/pdf/2402.17775v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18388v1","updated":"2024-06-26T14:30:51Z","published":"2024-06-26T14:30:51Z","title":"SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and\n  Real-time Hysteresis Compensation Control Algorithm","summary":"  Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via\nnatural orifices and improve target lesion accessibility through curved paths.\nHowever, CDCMs face limitations in workspace and control accuracy due to\nnon-linear cable effects causing hysteresis. This paper introduces an\nextensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via\ntranslational motion without additional mechanical elements or actuation. We\ncollect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Based\non this dataset, we develop a real-time hysteresis compensation control\nalgorithm using the trained Temporal Convolutional Network (TCN) with a 1ms\ntime latency, effectively estimating the manipulator's hysteresis behavior.\nPerformance validation through random trajectory tracking tests and box\npointing tasks shows the proposed controller significantly reduces hysteresis\nby up to 69.5% in joint space and approximately 26% in the box pointing task.\n","authors":["Junhyun Park","Seonghyeok Jang","Myeongbo Park","Hyojae Park","Jeonghyeon Yoon","Minho Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.18388v1.pdf","comment":"12 pages, 14 figures, 6 tables"},{"id":"http://arxiv.org/abs/2210.13382v5","updated":"2024-06-26T14:27:49Z","published":"2022-10-24T16:29:55Z","title":"Emergent World Representations: Exploring a Sequence Model Trained on a\n  Synthetic Task","summary":"  Language models show a surprising range of capabilities, but the source of\ntheir apparent competence is unclear. Do these networks just memorize a\ncollection of surface statistics, or do they rely on internal representations\nof the process that generates the sequences they see? We investigate this\nquestion by applying a variant of the GPT model to the task of predicting legal\nmoves in a simple board game, Othello. Although the network has no a priori\nknowledge of the game or its rules, we uncover evidence of an emergent\nnonlinear internal representation of the board state. Interventional\nexperiments indicate this representation can be used to control the output of\nthe network and create \"latent saliency maps\" that can help explain predictions\nin human terms.\n","authors":["Kenneth Li","Aspen K. Hopkins","David Bau","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2210.13382v5.pdf","comment":"ICLR 2023 oral (notable-top-5%):\n  https://openreview.net/forum?id=DeG07_TcZvT ; code:\n  https://github.com/likenneth/othello_world"},{"id":"http://arxiv.org/abs/2406.18379v1","updated":"2024-06-26T14:21:09Z","published":"2024-06-26T14:21:09Z","title":"MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for\n  Iterative Binary Malware Summarization","summary":"  Binary malware summarization aims to automatically generate human-readable\ndescriptions of malware behaviors from executable files, facilitating tasks\nlike malware cracking and detection. Previous methods based on Large Language\nModels (LLMs) have shown great promise. However, they still face significant\nissues, including poor usability, inaccurate explanations, and incomplete\nsummaries, primarily due to the obscure pseudocode structure and the lack of\nmalware training summaries. Further, calling relationships between functions,\nwhich involve the rich interactions within a binary malware, remain largely\nunderexplored. To this end, we propose MALSIGHT, a novel code summarization\nframework that can iteratively generate descriptions of binary malware by\nexploring malicious source code and benign pseudocode. Specifically, we\nconstruct the first malware summaries, MalS and MalP, using an LLM and manually\nrefine this dataset with human effort. At the training stage, we tune our\nproposed MalT5, a novel LLM-based code model, on the MalS dataset and a benign\npseudocode dataset. Then, at the test stage, we iteratively feed the pseudocode\nfunctions into MalT5 to obtain the summary. Such a procedure facilitates the\nunderstanding of pseudocode structure and captures the intricate interactions\nbetween functions, thereby benefiting the usability, accuracy, and completeness\nof summaries. Additionally, we propose a novel evaluation benchmark,\nBLEURT-sum, to measure the quality of summaries. Experiments on three datasets\nshow the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5,\nwith only 0.77B parameters, delivers comparable performance to much larger\nChatGPT3.5.\n","authors":["Haolang Lu","Hongrui Peng","Guoshun Nan","Jiaoyang Cui","Cheng Wang","Weifei Jin"],"pdf_url":"https://arxiv.org/pdf/2406.18379v1.pdf","comment":"17 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.18370v1","updated":"2024-06-26T14:13:50Z","published":"2024-06-26T14:13:50Z","title":"Learning pure quantum states (almost) without regret","summary":"  We initiate the study of quantum state tomography with minimal regret. A\nlearner has sequential oracle access to an unknown pure quantum state, and in\neach round selects a pure probe state. Regret is incurred if the unknown state\nis measured orthogonal to this probe, and the learner's goal is to minimise the\nexpected cumulative regret over $T$ rounds. The challenge is to find a balance\nbetween the most informative measurements and measurements incurring minimal\nregret. We show that the cumulative regret scales as\n$\\Theta(\\operatorname{polylog} T)$ using a new tomography algorithm based on a\nmedian of means least squares estimator. This algorithm employs measurements\nbiased towards the unknown state and produces online estimates that are optimal\n(up to logarithmic terms) in the number of observed samples.\n","authors":["Josep Lumbreras","Mikhail Terekhov","Marco Tomamichel"],"pdf_url":"https://arxiv.org/pdf/2406.18370v1.pdf","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.03341v6","updated":"2024-06-26T14:11:53Z","published":"2023-06-06T01:26:53Z","title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language\n  Model","summary":"  We introduce Inference-Time Intervention (ITI), a technique designed to\nenhance the \"truthfulness\" of large language models (LLMs). ITI operates by\nshifting model activations during inference, following a set of directions\nacross a limited number of attention heads. This intervention significantly\nimproves the performance of LLaMA models on the TruthfulQA benchmark. On an\ninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from\n32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and\ndemonstrate how to balance it by tuning the intervention strength. ITI is\nminimally invasive and computationally inexpensive. Moreover, the technique is\ndata efficient: while approaches like RLHF require extensive annotations, ITI\nlocates truthful directions using only few hundred examples. Our findings\nsuggest that LLMs may have an internal representation of the likelihood of\nsomething being true, even as they produce falsehoods on the surface.\n","authors":["Kenneth Li","Oam Patel","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2306.03341v6.pdf","comment":"NeurIPS 2023 spotlight; code:\n  https://github.com/likenneth/honest_llama"},{"id":"http://arxiv.org/abs/2406.18364v1","updated":"2024-06-26T14:04:15Z","published":"2024-06-26T14:04:15Z","title":"Research on Information Extraction of LCSTS Dataset Based on an Improved\n  BERTSum-LSTM Model","summary":"  With the continuous advancement of artificial intelligence, natural language\nprocessing technology has become widely utilized in various fields. At the same\ntime, there are many challenges in creating Chinese news summaries. First of\nall, the semantics of Chinese news is complex, and the amount of information is\nenormous. Extracting critical information from Chinese news presents a\nsignificant challenge. Second, the news summary should be concise and clear,\nfocusing on the main content and avoiding redundancy. In addition, the\nparticularity of the Chinese language, such as polysemy, word segmentation,\netc., makes it challenging to generate Chinese news summaries. Based on the\nabove, this paper studies the information extraction method of the LCSTS\ndataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTM\nmodel to make it perform better in generating Chinese news summaries. The\nexperimental results show that the proposed method has a good effect on\ncreating news summaries, which is of great importance to the construction of\nnews summaries.\n","authors":["Yiming Chen","Haobin Chen","Simin Liu","Yunyun Liu","Fanhao Zhou","Bing Wei"],"pdf_url":"https://arxiv.org/pdf/2406.18364v1.pdf","comment":"submitted to ICMIII 2024"},{"id":"http://arxiv.org/abs/2406.18361v1","updated":"2024-06-26T14:01:07Z","published":"2024-06-26T14:01:07Z","title":"Stable Diffusion Segmentation for Biomedical Images with Single-step\n  Reverse Process","summary":"  Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg\n","authors":["Tianyu Lin","Zhiguang Chen","Zhonghao Yan","Fudan Zheng","Weijiang Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18361v1.pdf","comment":"Accepted at MICCAI 2024. Code and citation info see\n  https://github.com/lin-tianyu/Stable-Diffusion-Seg"},{"id":"http://arxiv.org/abs/2406.18354v1","updated":"2024-06-26T13:54:59Z","published":"2024-06-26T13:54:59Z","title":"Kolmogorov-Arnold Graph Neural Networks","summary":"  Graph neural networks (GNNs) excel in learning from network-like data but\noften lack interpretability, making their application challenging in domains\nrequiring transparent decision-making. We propose the Graph Kolmogorov-Arnold\nNetwork (GKAN), a novel GNN model leveraging spline-based activation functions\non edges to enhance both accuracy and interpretability. Our experiments on five\nbenchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN\nmodels in node classification, link prediction, and graph classification tasks.\nIn addition to the improved accuracy, GKAN's design inherently provides clear\ninsights into the model's decision-making process, eliminating the need for\npost-hoc explainability techniques. This paper discusses the methodology,\nperformance, and interpretability of GKAN, highlighting its potential for\napplications in domains where interpretability is crucial.\n","authors":["Gianluca De Carlo","Andrea Mastropietro","Aris Anagnostopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.18354v1.pdf","comment":"7 pages, 4 figures, under review"},{"id":"http://arxiv.org/abs/2406.18351v1","updated":"2024-06-26T13:52:47Z","published":"2024-06-26T13:52:47Z","title":"Reinforcement Learning with Intrinsically Motivated Feedback Graph for\n  Lost-sales Inventory Control","summary":"  Reinforcement learning (RL) has proven to be well-performed and\ngeneral-purpose in the inventory control (IC). However, further improvement of\nRL algorithms in the IC domain is impeded due to two limitations of online\nexperience. First, online experience is expensive to acquire in real-world\napplications. With the low sample efficiency nature of RL algorithms, it would\ntake extensive time to train the RL policy to convergence. Second, online\nexperience may not reflect the true demand due to the lost sales phenomenon\ntypical in IC, which makes the learning process more challenging. To address\nthe above challenges, we propose a decision framework that combines\nreinforcement learning with feedback graph (RLFG) and intrinsically motivated\nexploration (IME) to boost sample efficiency. In particular, we first take\nadvantage of the inherent properties of lost-sales IC problems and design the\nfeedback graph (FG) specially for lost-sales IC problems to generate abundant\nside experiences aid RL updates. Then we conduct a rigorous theoretical\nanalysis of how the designed FG reduces the sample complexity of RL methods.\nBased on the theoretical insights, we design an intrinsic reward to direct the\nRL agent to explore to the state-action space with more side experiences,\nfurther exploiting FG's power. Experimental results demonstrate that our method\ngreatly improves the sample efficiency of applying RL in IC. Our code is\navailable at https://anonymous.4open.science/r/RLIMFG4IC-811D/\n","authors":["Zifan Liu","Xinran Li","Shibo Chen","Gen Li","Jiashuo Jiang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18346v1","updated":"2024-06-26T13:42:13Z","published":"2024-06-26T13:42:13Z","title":"AI Alignment through Reinforcement Learning from Human Feedback?\n  Contradictions and Limitations","summary":"  This paper critically evaluates the attempts to align Artificial Intelligence\n(AI) systems, especially Large Language Models (LLMs), with human values and\nintentions through Reinforcement Learning from Feedback (RLxF) methods,\ninvolving either human feedback (RLHF) or AI feedback (RLAIF). Specifically, we\nshow the shortcomings of the broadly pursued alignment goals of honesty,\nharmlessness, and helpfulness. Through a multidisciplinary sociotechnical\ncritique, we examine both the theoretical underpinnings and practical\nimplementations of RLxF techniques, revealing significant limitations in their\napproach to capturing the complexities of human ethics and contributing to AI\nsafety. We highlight tensions and contradictions inherent in the goals of RLxF.\nIn addition, we discuss ethically-relevant issues that tend to be neglected in\ndiscussions about alignment and RLxF, among which the trade-offs between\nuser-friendliness and deception, flexibility and interpretability, and system\nsafety. We conclude by urging researchers and practitioners alike to critically\nassess the sociotechnical ramifications of RLxF, advocating for a more nuanced\nand reflective approach to its application in AI development.\n","authors":["Adam Dahlgren Lindström","Leila Methnani","Lea Krause","Petter Ericson","Íñigo Martínez de Rituerto de Troya","Dimitri Coelho Mollo","Roel Dobbe"],"pdf_url":"https://arxiv.org/pdf/2406.18346v1.pdf","comment":"12 pages, 1 table, to be submitted"},{"id":"http://arxiv.org/abs/2306.02411v2","updated":"2024-06-26T13:37:58Z","published":"2023-06-04T17:08:41Z","title":"Topological data quality via 0-dimensional persistence matching","summary":"  Data quality is crucial for the successful training, generalization and\nperformance of artificial intelligence models. We propose to measure data\nquality for supervised learning using topological data analysis techniques.\nSpecifically, we provide a novel topological invariant based on persistence\nmatchings induced by inclusions and using $0$-dimensional persistent homology.\nWe show that such an invariant is stable. We provide an algorithm and relate it\nto images, kernels, and cokernels of the induced morphisms. Also, we show that\nthe invariant allows us to understand whether the subset \"represents well\" the\nclusters from the larger dataset or not, and we also use it to estimate bounds\nfor the Hausdorff distance between the subset and the complete dataset. This\napproach enables us to explain why the chosen dataset will lead to poor\nperformance.\n","authors":["Álvaro Torras-Casas","Eduardo Paluzo-Hidalgo","Rocio Gonzalez-Diaz"],"pdf_url":"https://arxiv.org/pdf/2306.02411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18333v1","updated":"2024-06-26T13:21:08Z","published":"2024-06-26T13:21:08Z","title":"Continuous Sign Language Recognition Using Intra-inter Gloss Attention","summary":"  Many continuous sign language recognition (CSLR) studies adopt\ntransformer-based architectures for sequence modeling due to their powerful\ncapacity for capturing global contexts. Nevertheless, vanilla self-attention,\nwhich serves as the core module of the transformer, calculates a weighted\naverage over all time steps; therefore, the local temporal semantics of sign\nvideos may not be fully exploited. In this study, we introduce a novel module\nin sign language recognition studies, called intra-inter gloss attention\nmodule, to leverage the relationships among frames within glosses and the\nsemantic and grammatical dependencies between glosses in the video. In the\nintra-gloss attention module, the video is divided into equally sized chunks\nand a self-attention mechanism is applied within each chunk. This localized\nself-attention significantly reduces complexity and eliminates noise introduced\nby considering non-relative frames. In the inter-gloss attention module, we\nfirst aggregate the chunk-level features within each gloss chunk by average\npooling along the temporal dimension. Subsequently, multi-head self-attention\nis applied to all chunk-level features. Given the non-significance of the\nsigner-environment interaction, we utilize segmentation to remove the\nbackground of the videos. This enables the proposed model to direct its focus\ntoward the signer. Experimental results on the PHOENIX-2014 benchmark dataset\ndemonstrate that our method can effectively extract sign language features in\nan end-to-end manner without any prior knowledge, improve the accuracy of CSLR,\nand achieve the word error rate (WER) of 20.4 on the test set which is a\ncompetitive result compare to the state-of-the-art which uses additional\nsupervisions.\n","authors":["Hossein Ranjbar","Alireza Taheri"],"pdf_url":"https://arxiv.org/pdf/2406.18333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18326v1","updated":"2024-06-26T13:12:40Z","published":"2024-06-26T13:12:40Z","title":"PaCoST: Paired Confidence Significance Testing for Benchmark\n  Contamination Detection in Large Language Models","summary":"  Large language models (LLMs) are known to be trained on vast amounts of data,\nwhich may unintentionally or intentionally include data from commonly used\nbenchmarks. This inclusion can lead to cheatingly high scores on model\nleaderboards, yet result in disappointing performance in real-world\napplications. To address this benchmark contamination problem, we first propose\na set of requirements that practical contamination detection methods should\nfollow. Following these proposed requirements, we introduce PaCoST, a Paired\nConfidence Significance Testing to effectively detect benchmark contamination\nin LLMs. Our method constructs a counterpart for each piece of data with the\nsame distribution, and performs statistical analysis of the corresponding\nconfidence to test whether the model is significantly more confident under the\noriginal benchmark. We validate the effectiveness of PaCoST and apply it on\npopular open-source models and benchmarks. We find that almost all models and\nbenchmarks we tested are suspected contaminated more or less. We finally call\nfor new LLM evaluation methods.\n","authors":["Huixuan Zhang","Yun Lin","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2406.18326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16793v3","updated":"2024-06-26T13:03:16Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). We find\nthat $\\geq$ 90% of these learning rates in $v$ could be harmlessly removed if\nwe (1) carefully partition the parameters into blocks following our proposed\nprinciple on Hessian structure; (2) assign a single but good learning rate to\neach parameter block. We further find that, for each of these parameter blocks,\nthere exists a single high-quality learning rate that can outperform Adam,\nprovided that sufficient resources are available to search it out. We then\nprovide one cost-effective way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 125M to 7B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs and CPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18321v1","updated":"2024-06-26T13:02:35Z","published":"2024-06-26T13:02:35Z","title":"MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large\n  Language Models Using Odyssey Math Data","summary":"  Large language models (LLMs) have significantly advanced natural language\nunderstanding and demonstrated strong problem-solving abilities. Despite these\nsuccesses, most LLMs still struggle with solving mathematical problems due to\nthe intricate reasoning required. This paper investigates the mathematical\nproblem-solving capabilities of LLMs using the newly developed \"MathOdyssey\"\ndataset. The dataset includes diverse mathematical problems at high school and\nuniversity levels, created by experts from notable institutions to rigorously\ntest LLMs in advanced problem-solving scenarios and cover a wider range of\nsubject areas. By providing the MathOdyssey dataset as a resource to the AI\ncommunity, we aim to contribute to the understanding and improvement of AI\ncapabilities in complex mathematical problem-solving. We conduct benchmarking\non open-source models, such as Llama-3 and DBRX-Instruct, and closed-source\nmodels from the GPT series and Gemini models. Our results indicate that while\nLLMs perform well on routine and moderately difficult tasks, they face\nsignificant challenges with Olympiad-level problems and complex\nuniversity-level questions. Our analysis shows a narrowing performance gap\nbetween open-source and closed-source models, yet substantial challenges\nremain, particularly with the most demanding problems. This study highlights\nthe ongoing need for research to enhance the mathematical reasoning of LLMs.\nThe dataset, results, and code are publicly available.\n","authors":["Meng Fang","Xiangpeng Wan","Fei Lu","Fei Xing","Kai Zou"],"pdf_url":"https://arxiv.org/pdf/2406.18321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18312v1","updated":"2024-06-26T12:51:37Z","published":"2024-06-26T12:51:37Z","title":"AI-native Memory: A Pathway from LLMs Towards AGI","summary":"  Large language models (LLMs) have demonstrated the world with the sparks of\nartificial general intelligence (AGI). One opinion, especially from some\nstartups working on LLMs, argues that an LLM with nearly unlimited context\nlength can realize AGI. However, they might be too optimistic about the\nlong-context capability of (existing) LLMs -- (1) Recent literature has shown\nthat their effective context length is significantly smaller than their claimed\ncontext length; and (2) Our reasoning-in-a-haystack experiments further\ndemonstrate that simultaneously finding the relevant information from a long\ncontext and conducting (simple) reasoning is nearly impossible. In this paper,\nwe envision a pathway from LLMs to AGI through the integration of\n\\emph{memory}. We believe that AGI should be a system where LLMs serve as core\nprocessors. In addition to raw data, the memory in this system would store a\nlarge number of important conclusions derived from reasoning processes.\nCompared with retrieval-augmented generation (RAG) that merely processing raw\ndata, this approach not only connects semantically related information closer,\nbut also simplifies complex inferences at the time of querying. As an\nintermediate stage, the memory will likely be in the form of natural language\ndescriptions, which can be directly consumed by users too. Ultimately, every\nagent/person should have its own large personal model, a deep neural network\nmodel (thus \\emph{AI-native}) that parameterizes and compresses all types of\nmemory, even the ones cannot be described by natural languages. Finally, we\ndiscuss the significant potential of AI-native memory as the transformative\ninfrastructure for (proactive) engagement, personalization, distribution, and\nsocial in the AGI era, as well as the incurred privacy and security challenges\nwith preliminary solutions.\n","authors":["Jingbo Shang","Zai Zheng","Xiang Ying","Felix Tao","Mindverse Team"],"pdf_url":"https://arxiv.org/pdf/2406.18312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18305v1","updated":"2024-06-26T12:45:43Z","published":"2024-06-26T12:45:43Z","title":"S3: A Simple Strong Sample-effective Multimodal Dialog System","summary":"  In this work, we present a conceptually simple yet powerful baseline for the\nmultimodal dialog task, an S3 model, that achieves near state-of-the-art\nresults on two compelling leaderboards: MMMU and AI Journey Contest 2023. The\nsystem is based on a pre-trained large language model, pre-trained modality\nencoders for image and audio, and a trainable modality projector. The proposed\neffective data mixture for training such an architecture demonstrates that a\nmultimodal model based on a strong language model and trained on a small amount\nof multimodal data can perform efficiently in the task of multimodal dialog.\n","authors":["Elisei Rykov","Egor Malkershin","Alexander Panchenko"],"pdf_url":"https://arxiv.org/pdf/2406.18305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01179v2","updated":"2024-06-26T12:43:56Z","published":"2024-06-03T10:21:48Z","title":"Are AI-Generated Text Detectors Robust to Adversarial Perturbations?","summary":"  The widespread use of large language models (LLMs) has sparked concerns about\nthe potential misuse of AI-generated text, as these models can produce content\nthat closely resembles human-generated text. Current detectors for AI-generated\ntext (AIGT) lack robustness against adversarial perturbations, with even minor\nchanges in characters or words causing a reversal in distinguishing between\nhuman-created and AI-generated text. This paper investigates the robustness of\nexisting AIGT detection methods and introduces a novel detector, the Siamese\nCalibrated Reconstruction Network (SCRN). The SCRN employs a reconstruction\nnetwork to add and remove noise from text, extracting a semantic representation\nthat is robust to local perturbations. We also propose a siamese calibration\ntechnique to train the model to make equally confidence predictions under\ndifferent noise, which improves the model's robustness against adversarial\nperturbations. Experiments on four publicly available datasets show that the\nSCRN outperforms all baseline methods, achieving 6.5\\%-18.25\\% absolute\naccuracy improvement over the best baseline method under adversarial attacks.\nMoreover, it exhibits superior generalizability in cross-domain, cross-genre,\nand mixed-source scenarios. The code is available at\n\\url{https://github.com/CarlanLark/Robust-AIGC-Detector}.\n","authors":["Guanhua Huang","Yuchen Zhang","Zhe Li","Yongjian You","Mingze Wang","Zhouwang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.01179v2.pdf","comment":"Accepted to ACL 2024 main conference"},{"id":"http://arxiv.org/abs/2402.03741v3","updated":"2024-06-26T12:41:59Z","published":"2024-02-06T06:18:16Z","title":"SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent\n  Reinforcement Learning Systems","summary":"  Recent advancements in multi-agent reinforcement learning (MARL) have opened\nup vast application prospects, such as swarm control of drones, collaborative\nmanipulation by robotic arms, and multi-target encirclement. However, potential\nsecurity threats during the MARL deployment need more attention and thorough\ninvestigation. Recent research reveals that attackers can rapidly exploit the\nvictim's vulnerabilities, generating adversarial policies that result in the\nfailure of specific tasks. For instance, reducing the winning rate of a\nsuperhuman-level Go AI to around 20%. Existing studies predominantly focus on\ntwo-player competitive environments, assuming attackers possess complete global\nstate observation.\n  In this study, we unveil, for the first time, the capability of attackers to\ngenerate adversarial policies even when restricted to partial observations of\nthe victims in multi-agent competitive environments. Specifically, we propose a\nnovel black-box attack (SUB-PLAY) that incorporates the concept of constructing\nmultiple subgames to mitigate the impact of partial observability and suggests\nsharing transitions among subpolicies to improve attackers' exploitative\nability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under\nthree typical partial observability limitations. Visualization results indicate\nthat adversarial policies induce significantly different activations of the\nvictims' policy networks. Furthermore, we evaluate three potential defenses\naimed at exploring ways to mitigate security threats posed by adversarial\npolicies, providing constructive recommendations for deploying MARL in\ncompetitive environments.\n","authors":["Oubo Ma","Yuwen Pu","Linkang Du","Yang Dai","Ruo Wang","Xiaolei Liu","Yingcai Wu","Shouling Ji"],"pdf_url":"https://arxiv.org/pdf/2402.03741v3.pdf","comment":"To appear in the ACM Conference on Computer and Communications\n  Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA"},{"id":"http://arxiv.org/abs/2306.10376v6","updated":"2024-06-26T12:39:36Z","published":"2023-06-17T15:24:54Z","title":"CLARA: Classifying and Disambiguating User Commands for Reliable\n  Interactive Robotic Agents","summary":"  In this paper, we focus on inferring whether the given user command is clear,\nambiguous, or infeasible in the context of interactive robotic agents utilizing\nlarge language models (LLMs). To tackle this problem, we first present an\nuncertainty estimation method for LLMs to classify whether the command is\ncertain (i.e., clear) or not (i.e., ambiguous or infeasible). Once the command\nis classified as uncertain, we further distinguish it between ambiguous or\ninfeasible commands leveraging LLMs with situational aware context in a\nzero-shot manner. For ambiguous commands, we disambiguate the command by\ninteracting with users via question generation with LLMs. We believe that\nproper recognition of the given commands could lead to a decrease in\nmalfunction and undesired actions of the robot, enhancing the reliability of\ninteractive robot agents. We present a dataset for robotic situational\nawareness, consisting pair of high-level commands, scene descriptions, and\nlabels of command type (i.e., clear, ambiguous, or infeasible). We validate the\nproposed method on the collected dataset, pick-and-place tabletop simulation.\nFinally, we demonstrate the proposed approach in real-world human-robot\ninteraction experiments, i.e., handover scenarios.\n","authors":["Jeongeun Park","Seungwon Lim","Joonhyung Lee","Sangbeom Park","Minsuk Chang","Youngjae Yu","Sungjoon Choi"],"pdf_url":"https://arxiv.org/pdf/2306.10376v6.pdf","comment":"Project Page: https://clararobot.github.io/"},{"id":"http://arxiv.org/abs/2405.20204v2","updated":"2024-06-26T12:31:48Z","published":"2024-05-30T16:07:54Z","title":"Jina CLIP: Your CLIP Model Is Also Your Text Retriever","summary":"  Contrastive Language-Image Pretraining (CLIP) is widely used to train models\nto align images and texts in a common embedding space by mapping them to\nfixed-sized vectors. These models are key to multimodal information retrieval\nand related tasks. However, CLIP models generally underperform in text-only\ntasks compared to specialized text models. This creates inefficiencies for\ninformation retrieval systems that keep separate embeddings and models for\ntext-only and multimodal tasks. We propose a novel, multi-task contrastive\ntraining method to address this issue, which we use to train the jina-clip-v1\nmodel to achieve the state-of-the-art performance on both text-image and\ntext-text retrieval tasks.\n","authors":["Andreas Koukounas","Georgios Mastrapas","Michael Günther","Bo Wang","Scott Martens","Isabelle Mohr","Saba Sturua","Mohammad Kalim Akram","Joan Fontanals Martínez","Saahil Ognawala","Susana Guzman","Maximilian Werk","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2405.20204v2.pdf","comment":"4 pages, MFM-EAI@ICML2024"},{"id":"http://arxiv.org/abs/2406.18293v1","updated":"2024-06-26T12:23:54Z","published":"2024-06-26T12:23:54Z","title":"Combining Automated Optimisation of Hyperparameters and Reward Shape","summary":"  There has been significant progress in deep reinforcement learning (RL) in\nrecent years. Nevertheless, finding suitable hyperparameter configurations and\nreward functions remains challenging even for experts, and performance heavily\nrelies on these design choices. Also, most RL research is conducted on known\nbenchmarks where knowledge about these choices already exists. However, novel\npractical applications often pose complex tasks for which no prior knowledge\nabout good hyperparameters and reward functions is available, thus\nnecessitating their derivation from scratch. Prior work has examined\nautomatically tuning either hyperparameters or reward functions individually.\nWe demonstrate empirically that an RL algorithm's hyperparameter configurations\nand reward function are often mutually dependent, meaning neither can be fully\noptimised without appropriate values for the other. We then propose a\nmethodology for the combined optimisation of hyperparameters and the reward\nfunction. Furthermore, we include a variance penalty as an optimisation\nobjective to improve the stability of learned policies. We conducted extensive\nexperiments using Proximal Policy Optimisation and Soft Actor-Critic on four\nenvironments. Our results show that combined optimisation significantly\nimproves over baseline performance in half of the environments and achieves\ncompetitive performance in the others, with only a minor increase in\ncomputational costs. This suggests that combined optimisation should be best\npractice.\n","authors":["Julian Dierkes","Emma Cramer","Holger H. Hoos","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2406.18293v1.pdf","comment":"Published in the Reinforcement Learning Journal 2024"},{"id":"http://arxiv.org/abs/2404.05569v2","updated":"2024-06-26T11:42:10Z","published":"2024-04-08T14:43:13Z","title":"360$^\\circ$REA: Towards A Reusable Experience Accumulation with\n  360° Assessment for Multi-Agent System","summary":"  Large language model agents have demonstrated remarkable advancements across\nvarious complex tasks. Recent works focus on optimizing the agent team or\nemploying self-reflection to iteratively solve complex tasks. Since these\nagents are all based on the same LLM, only conducting self-evaluation or\nremoving underperforming agents does not substantively enhance the capability\nof the agents. We argue that a comprehensive evaluation and accumulating\nexperience from evaluation feedback is an effective approach to improving\nsystem performance. In this paper, we propose Reusable Experience Accumulation\nwith 360$^\\circ$ Assessment (360$^\\circ$REA), a hierarchical multi-agent\nframework inspired by corporate organizational practices. The framework employs\na novel 360$^\\circ$ performance assessment method for multi-perspective\nperformance evaluation with fine-grained assessment. To enhance the capability\nof agents in addressing complex tasks, we introduce dual-level experience pool\nfor agents to accumulate experience through fine-grained assessment. Extensive\nexperiments on complex task datasets demonstrate the effectiveness of\n360$^\\circ$REA.\n","authors":["Shen Gao","Hao Li","Chengrui Huang","Quan Tu","Zhiliang Tian","Minlie Huang","Shuo Shang"],"pdf_url":"https://arxiv.org/pdf/2404.05569v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04868v2","updated":"2024-06-26T11:17:13Z","published":"2024-05-08T07:50:21Z","title":"Enhancing Geometric Ontology Embeddings for $\\mathcal{EL}^{++}$ with\n  Negative Sampling and Deductive Closure Filtering","summary":"  Ontology embeddings map classes, relations, and individuals in ontologies\ninto $\\mathbb{R}^n$, and within $\\mathbb{R}^n$ similarity between entities can\nbe computed or new axioms inferred. For ontologies in the Description Logic\n$\\mathcal{EL}^{++}$, several embedding methods have been developed that\nexplicitly generate models of an ontology. However, these methods suffer from\nsome limitations; they do not distinguish between statements that are\nunprovable and provably false, and therefore they may use entailed statements\nas negatives. Furthermore, they do not utilize the deductive closure of an\nontology to identify statements that are inferred but not asserted. We\nevaluated a set of embedding methods for $\\mathcal{EL}^{++}$ ontologies based\non high-dimensional ball representation of concept descriptions, incorporating\nseveral modifications that aim to make use of the ontology deductive closure.\nIn particular, we designed novel negative losses that account both for the\ndeductive closure and different types of negatives. We demonstrate that our\nembedding methods improve over the baseline ontology embedding in the task of\nknowledge base or ontology completion.\n","authors":["Olga Mashkova","Fernando Zhapa-Camacho","Robert Hoehndorf"],"pdf_url":"https://arxiv.org/pdf/2405.04868v2.pdf","comment":"Revised version"},{"id":"http://arxiv.org/abs/2406.18259v1","updated":"2024-06-26T11:11:47Z","published":"2024-06-26T11:11:47Z","title":"Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and\n  Explainability is Complicated","summary":"  As LLMs rapidly advance, increasing concerns arise regarding risks about\nactual authorship of texts we see online and in real world. The task of\ndistinguishing LLM-authored texts is complicated by the nuanced and overlapping\nbehaviors of both machines and humans. In this paper, we challenge the current\npractice of considering LLM-generated text detection a binary classification\ntask of differentiating human from AI. Instead, we introduce a novel ternary\ntext classification scheme, adding an \"undecided\" category for texts that could\nbe attributed to either source, and we show that this new category is crucial\nto understand how to make the detection result more explainable to lay users.\nThis research shifts the paradigm from merely classifying to explaining\nmachine-generated texts, emphasizing need for detectors to provide clear and\nunderstandable explanations to users. Our study involves creating four new\ndatasets comprised of texts from various LLMs and human authors. Based on new\ndatasets, we performed binary classification tests to ascertain the most\neffective SOTA detection methods and identified SOTA LLMs capable of producing\nharder-to-detect texts. We constructed a new dataset of texts generated by two\ntop-performing LLMs and human authors, and asked three human annotators to\nproduce ternary labels with explanation notes. This dataset was used to\ninvestigate how three top-performing SOTA detectors behave in new ternary\nclassification context. Our results highlight why \"undecided\" category is much\nneeded from the viewpoint of explainability. Additionally, we conducted an\nanalysis of explainability of the three best-performing detectors and the\nexplanation notes of the human annotators, revealing insights about the\ncomplexity of explainable detection of machine-generated texts. Finally, we\npropose guidelines for developing future detection systems with improved\nexplanatory power.\n","authors":["Jiazhou Ji","Ruizhe Li","Shujun Li","Jie Guo","Weidong Qiu","Zheng Huang","Chiyu Chen","Xiaoyu Jiang","Xinru Lu"],"pdf_url":"https://arxiv.org/pdf/2406.18259v1.pdf","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.18254v1","updated":"2024-06-26T11:04:25Z","published":"2024-06-26T11:04:25Z","title":"Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with\n  1-to-K Contrastive Learning","summary":"  Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search,\nwhich aims to break the barriers between modality and language simultaneously\nand achieves image-text retrieval in the multi-lingual scenario with a single\nmodel. In recent years, excellent progress has been made based on cross-lingual\ncross-modal pre-training; particularly, the methods based on contrastive\nlearning on large-scale data have significantly improved retrieval tasks.\nHowever, these methods directly follow the existing pre-training methods in the\ncross-lingual or cross-modal domain, leading to two problems of inconsistency\nin CCR: The methods with cross-lingual style suffer from the intra-modal error\npropagation, resulting in inconsistent recall performance across languages in\nthe whole dataset. The methods with cross-modal style suffer from the\ninter-modal optimization direction bias, resulting in inconsistent rank across\nlanguages within each instance, which cannot be reflected by Recall@K. To solve\nthese problems, we propose a simple but effective 1-to-K contrastive learning\nmethod, which treats each language equally and eliminates error propagation and\noptimization bias. In addition, we propose a new evaluation metric, Mean Rank\nVariance (MRV), to reflect the rank inconsistency across languages within each\ninstance. Extensive experiments on four CCR datasets show that our method\nimproves both recall rates and MRV with smaller-scale pre-trained data,\nachieving the new state-of-art.\n","authors":["Zhijie Nie","Richong Zhang","Zhangchi Feng","Hailang Huang","Xudong Liu"],"pdf_url":"https://arxiv.org/pdf/2406.18254v1.pdf","comment":"Accepted by KDD 2024 Research Track"},{"id":"http://arxiv.org/abs/2402.08703v2","updated":"2024-06-26T11:03:21Z","published":"2024-02-13T16:56:31Z","title":"A Survey of Generative AI for de novo Drug Design: New Frontiers in\n  Molecule and Protein Generation","summary":"  Artificial intelligence (AI)-driven methods can vastly improve the\nhistorically costly drug design process, with various generative models already\nin widespread use. Generative models for de novo drug design, in particular,\nfocus on the creation of novel biological compounds entirely from scratch,\nrepresenting a promising future direction. Rapid development in the field,\ncombined with the inherent complexity of the drug design process, creates a\ndifficult landscape for new researchers to enter. In this survey, we organize\nde novo drug design into two overarching themes: small molecule and protein\ngeneration. Within each theme, we identify a variety of subtasks and\napplications, highlighting important datasets, benchmarks, and model\narchitectures and comparing the performance of top models. We take a broad\napproach to AI-driven drug design, allowing for both micro-level comparisons of\nvarious methods within each subtask and macro-level observations across\ndifferent fields. We discuss parallel challenges and approaches between the two\napplications and highlight future directions for AI-driven de novo drug design\nas a whole. An organized repository of all covered sources is available at\nhttps://github.com/gersteinlab/GenAI4Drug.\n","authors":["Xiangru Tang","Howard Dai","Elizabeth Knight","Fang Wu","Yunyang Li","Tianxiao Li","Mark Gerstein"],"pdf_url":"https://arxiv.org/pdf/2402.08703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v2","updated":"2024-06-26T10:58:48Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18239v1","updated":"2024-06-26T10:44:02Z","published":"2024-06-26T10:44:02Z","title":"Zero-shot prompt-based classification: topic labeling in times of\n  foundation models in German Tweets","summary":"  Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.\n","authors":["Simon Münker","Kai Kugler","Achim Rettinger"],"pdf_url":"https://arxiv.org/pdf/2406.18239v1.pdf","comment":"10 pages, 2 tables, 1 figure"},{"id":"http://arxiv.org/abs/2406.18237v1","updated":"2024-06-26T10:41:07Z","published":"2024-06-26T10:41:07Z","title":"PlaMo: Plan and Move in Rich 3D Physical Environments","summary":"  Controlling humanoids in complex physically simulated worlds is a\nlong-standing challenge with numerous applications in gaming, simulation, and\nvisual content creation. In our setup, given a rich and complex 3D scene, the\nuser provides a list of instructions composed of target locations and\nlocomotion types. To solve this task we present PlaMo, a scene-aware path\nplanner and a robust physics-based controller. The path planner produces a\nsequence of motion paths, considering the various limitations the scene imposes\non the motion, such as location, height, and speed. Complementing the planner,\nour control policy generates rich and realistic physical motion adhering to the\nplan. We demonstrate how the combination of both modules enables traversing\ncomplex landscapes in diverse forms while responding to real-time changes in\nthe environment. Video: https://youtu.be/wWlqSQlRZ9M .\n","authors":["Assaf Hallak","Gal Dalal","Chen Tessler","Kelly Guo","Shie Mannor","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2406.18237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03425v5","updated":"2024-06-26T10:38:29Z","published":"2024-04-04T13:06:25Z","title":"ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State\n  Space Model","summary":"  Convolutional neural networks (CNN) and Transformers have made impressive\nprogress in the field of remote sensing change detection (CD). However, both\narchitectures have inherent shortcomings: CNN are constrained by a limited\nreceptive field that may hinder their ability to capture broader spatial\ncontexts, while Transformers are computationally intensive, making them costly\nto train and deploy on large datasets. Recently, the Mamba architecture, based\non state space models, has shown remarkable performance in a series of natural\nlanguage processing tasks, which can effectively compensate for the\nshortcomings of the above two architectures. In this paper, we explore for the\nfirst time the potential of the Mamba architecture for remote sensing CD tasks.\nWe tailor the corresponding frameworks, called MambaBCD, MambaSCD, and\nMambaBDA, for binary change detection (BCD), semantic change detection (SCD),\nand building damage assessment (BDA), respectively. All three frameworks adopt\nthe cutting-edge Visual Mamba architecture as the encoder, which allows full\nlearning of global spatial contextual information from the input images. For\nthe change decoder, which is available in all three architectures, we propose\nthree spatio-temporal relationship modeling mechanisms, which can be naturally\ncombined with the Mamba architecture and fully utilize its attribute to achieve\nspatio-temporal interaction of multi-temporal features, thereby obtaining\naccurate change information. On five benchmark datasets, our proposed\nframeworks outperform current CNN- and Transformer-based approaches without\nusing any complex training strategies or tricks, fully demonstrating the\npotential of the Mamba architecture in CD tasks. Further experiments show that\nour architecture is quite robust to degraded data. The source code will be\navailable in https://github.com/ChenHongruixuan/MambaCD\n","authors":["Hongruixuan Chen","Jian Song","Chengxi Han","Junshi Xia","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2404.03425v5.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2310.02674v3","updated":"2024-06-26T10:31:54Z","published":"2023-10-04T09:26:44Z","title":"ObjFormer: Learning Land-Cover Changes From Paired OSM Data and Optical\n  High-Resolution Imagery via Object-Guided Transformer","summary":"  Optical high-resolution imagery and OSM data are two important data sources\nof change detection (CD). Previous related studies focus on utilizing the\ninformation in OSM data to aid the CD on optical high-resolution images. This\npaper pioneers the direct detection of land-cover changes utilizing paired OSM\ndata and optical imagery, thereby expanding the scope of CD tasks. To this end,\nwe propose an object-guided Transformer (ObjFormer) by naturally combining the\nobject-based image analysis (OBIA) technique with the advanced vision\nTransformer architecture. This combination can significantly reduce the\ncomputational overhead in the self-attention module without adding extra\nparameters or layers. ObjFormer has a hierarchical pseudo-siamese encoder\nconsisting of object-guided self-attention modules that extracts multi-level\nheterogeneous features from OSM data and optical images; a decoder consisting\nof object-guided cross-attention modules can recover land-cover changes from\nthe extracted heterogeneous features. Beyond basic binary change detection,\nthis paper raises a new semi-supervised semantic change detection task that\ndoes not require any manually annotated land-cover labels to train semantic\nchange detectors. Two lightweight semantic decoders are added to ObjFormer to\naccomplish this task efficiently. A converse cross-entropy loss is designed to\nfully utilize negative samples, contributing to the great performance\nimprovement in this task. A large-scale benchmark dataset called OpenMapCD\ncontaining 1,287 samples covering 40 regions on six continents is constructed\nto conduct detailed experiments. The results show the effectiveness of our\nmethods in this new kind of CD task. Additionally, case studies in Japanese\ncities demonstrate the framework's generalizability and practical potential.\nThe OpenMapCD and source code are available in\nhttps://github.com/ChenHongruixuan/ObjFormer\n","authors":["Hongruixuan Chen","Cuiling Lan","Jian Song","Clifford Broni-Bediako","Junshi Xia","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2310.02674v3.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2209.02000v3","updated":"2024-06-26T10:17:08Z","published":"2022-09-05T14:57:03Z","title":"Visual Odometry with Neuromorphic Resonator Networks","summary":"  Visual Odometry (VO) is a method to estimate self-motion of a mobile robot\nusing visual sensors. Unlike odometry based on integrating differential\nmeasurements that can accumulate errors, such as inertial sensors or wheel\nencoders, visual odometry is not compromised by drift. However, image-based VO\nis computationally demanding, limiting its application in use cases with\nlow-latency, -memory, and -energy requirements. Neuromorphic hardware offers\nlow-power solutions to many vision and AI problems, but designing such\nsolutions is complicated and often has to be assembled from scratch. Here we\npropose to use Vector Symbolic Architecture (VSA) as an abstraction layer to\ndesign algorithms compatible with neuromorphic hardware. Building from a VSA\nmodel for scene analysis, described in our companion paper, we present a\nmodular neuromorphic algorithm that achieves state-of-the-art performance on\ntwo-dimensional VO tasks. Specifically, the proposed algorithm stores and\nupdates a working memory of the presented visual environment. Based on this\nworking memory, a resonator network estimates the changing location and\norientation of the camera. We experimentally validate the neuromorphic\nVSA-based approach to VO with two benchmarks: one based on an event camera\ndataset and the other in a dynamic scene with a robotic task.\n","authors":["Alpha Renner","Lazar Supic","Andreea Danielescu","Giacomo Indiveri","E. Paxon Frady","Friedrich T. Sommer","Yulia Sandamirskaya"],"pdf_url":"https://arxiv.org/pdf/2209.02000v3.pdf","comment":"19 pages, 5 figures, minor revisions, added results for\n  shapes_translation dataset"},{"id":"http://arxiv.org/abs/2401.09986v2","updated":"2024-06-26T10:16:46Z","published":"2024-01-18T14:02:23Z","title":"Improving Local Training in Federated Learning via Temperature Scaling","summary":"  Federated learning is inherently hampered by data heterogeneity: non-i.i.d.\ntraining data over local clients. We propose a novel model training approach\nfor federated learning, FLex&Chill, which exploits the Logit Chilling method.\nThrough extensive evaluations, we demonstrate that, in the presence of\nnon-i.i.d. data characteristics inherent in federated learning systems, this\napproach can expedite model convergence and improve inference accuracy.\nQuantitatively, from our experiments, we observe up to 6X improvement in the\nglobal federated learning model convergence time, and up to 3.37% improvement\nin inference accuracy.\n","authors":["Kichang Lee","Songkuk Kim","JeongGil Ko"],"pdf_url":"https://arxiv.org/pdf/2401.09986v2.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2208.12880v4","updated":"2024-06-26T10:16:08Z","published":"2022-08-26T22:17:52Z","title":"Neuromorphic Visual Scene Understanding with Resonator Networks","summary":"  Analyzing a visual scene by inferring the configuration of a generative model\nis widely considered the most flexible and generalizable approach to scene\nunderstanding. Yet, one major problem is the computational challenge of the\ninference procedure, involving a combinatorial search across object identities\nand poses. Here we propose a neuromorphic solution exploiting three key\nconcepts: (1) a computational framework based on Vector Symbolic Architectures\n(VSA) with complex-valued vectors; (2) the design of Hierarchical Resonator\nNetworks (HRN) to factorize the non-commutative transforms translation and\nrotation in visual scenes; (3) the design of a multi-compartment spiking phasor\nneuron model for implementing complex-valued resonator networks on neuromorphic\nhardware. The VSA framework uses vector binding operations to form a generative\nimage model in which binding acts as the equivariant operation for geometric\ntransformations. A scene can, therefore, be described as a sum of vector\nproducts, which can then be efficiently factorized by a resonator network to\ninfer objects and their poses. The HRN features a partitioned architecture in\nwhich vector binding is equivariant for horizontal and vertical translation\nwithin one partition and for rotation and scaling within the other partition.\nThe spiking neuron model allows mapping the resonator network onto efficient\nand low-power neuromorphic hardware. Our approach is demonstrated on synthetic\nscenes composed of simple 2D shapes undergoing rigid geometric transformations\nand color changes. A companion paper demonstrates the same approach in\nreal-world application scenarios for machine vision and robotics.\n","authors":["Alpha Renner","Lazar Supic","Andreea Danielescu","Giacomo Indiveri","Bruno A. Olshausen","Yulia Sandamirskaya","Friedrich T. Sommer","E. Paxon Frady"],"pdf_url":"https://arxiv.org/pdf/2208.12880v4.pdf","comment":"23 pages, 8 figures, minor revisions and extended supplementary\n  material"},{"id":"http://arxiv.org/abs/2406.18221v1","updated":"2024-06-26T10:08:47Z","published":"2024-06-26T10:08:47Z","title":"Enhancing Data Privacy in Large Language Models through Private\n  Association Editing","summary":"  Large Language Models (LLMs) are powerful tools with extensive applications,\nbut their tendency to memorize private information raises significant concerns\nas private data leakage can easily happen. In this paper, we introduce Private\nAssociation Editing (PAE), a novel defense approach for private data leakage.\nPAE is designed to effectively remove Personally Identifiable Information (PII)\nwithout retraining the model. Our approach consists of a four-step procedure:\ndetecting memorized PII, applying PAE cards to mitigate memorization of private\ndata, verifying resilience to targeted data extraction (TDE) attacks, and\nensuring consistency in the post-edit LLMs. The versatility and efficiency of\nPAE, which allows for batch modifications, significantly enhance data privacy\nin LLMs. Experimental results demonstrate the effectiveness of PAE in\nmitigating private data leakage. We believe PAE will serve as a critical tool\nin the ongoing effort to protect data privacy in LLMs, encouraging the\ndevelopment of safer models for real-world applications.\n","authors":["Davide Venditti","Elena Sofia Ruzzetti","Giancarlo A. Xompero","Cristina Giannone","Andrea Favalli","Raniero Romagnoli","Fabio Massimo Zanzotto"],"pdf_url":"https://arxiv.org/pdf/2406.18221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18220v1","updated":"2024-06-26T10:08:24Z","published":"2024-06-26T10:08:24Z","title":"Guiding Video Prediction with Explicit Procedural Knowledge","summary":"  We propose a general way to integrate procedural knowledge of a domain into\ndeep learning models. We apply it to the case of video prediction, building on\ntop of object-centric deep models and show that this leads to a better\nperformance than using data-driven models alone. We develop an architecture\nthat facilitates latent space disentanglement in order to use the integrated\nprocedural knowledge, and establish a setup that allows the model to learn the\nprocedural interface in the latent space using the downstream task of video\nprediction. We contrast the performance to a state-of-the-art data-driven\napproach and show that problems where purely data-driven approaches struggle\ncan be handled by using knowledge about the domain, providing an alternative to\nsimply collecting more data.\n","authors":["Patrick Takenaka","Johannes Maucher","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2406.18220v1.pdf","comment":"Published in 2023 IEEE/CVF International Conference on Computer\n  Vision Workshops (ICCVW)"},{"id":"http://arxiv.org/abs/2406.18211v1","updated":"2024-06-26T09:51:49Z","published":"2024-06-26T09:51:49Z","title":"AI Cards: Towards an Applied Framework for Machine-Readable AI and Risk\n  Documentation Inspired by the EU AI Act","summary":"  With the upcoming enforcement of the EU AI Act, documentation of high-risk AI\nsystems and their risk management information will become a legal requirement\nplaying a pivotal role in demonstration of compliance. Despite its importance,\nthere is a lack of standards and guidelines to assist with drawing up AI and\nrisk documentation aligned with the AI Act. This paper aims to address this gap\nby providing an in-depth analysis of the AI Act's provisions regarding\ntechnical documentation, wherein we particularly focus on AI risk management.\nOn the basis of this analysis, we propose AI Cards as a novel holistic\nframework for representing a given intended use of an AI system by encompassing\ninformation regarding technical specifications, context of use, and risk\nmanagement, both in human- and machine-readable formats. While the\nhuman-readable representation of AI Cards provides AI stakeholders with a\ntransparent and comprehensible overview of the AI use case, its\nmachine-readable specification leverages on state of the art Semantic Web\ntechnologies to embody the interoperability needed for exchanging documentation\nwithin the AI value chain. This brings the flexibility required for reflecting\nchanges applied to the AI system and its context, provides the scalability\nneeded to accommodate potential amendments to legal requirements, and enables\ndevelopment of automated tools to assist with legal compliance and conformity\nassessment tasks. To solidify the benefits, we provide an exemplar AI Card for\nan AI-based student proctoring system and further discuss its potential\napplications within and beyond the context of the AI Act.\n","authors":["Delaram Golpayegani","Isabelle Hupont","Cecilia Panigutti","Harshvardhan J. Pandit","Sven Schade","Declan O'Sullivan","Dave Lewis"],"pdf_url":"https://arxiv.org/pdf/2406.18211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17709v2","updated":"2024-06-26T09:25:07Z","published":"2024-02-27T17:41:58Z","title":"Case-Based or Rule-Based: How Do Transformers Do the Math?","summary":"  Despite the impressive performance in a variety of complex tasks, modern\nlarge language models (LLMs) still have trouble dealing with some math problems\nthat are simple and intuitive for humans, such as addition. While we can easily\nlearn basic rules of addition and apply them to new problems of any length,\nLLMs struggle to do the same. Instead, they may rely on similar cases seen in\nthe training corpus for help. We define these two different reasoning\nmechanisms as \"rule-based reasoning\" and \"case-based reasoning\". Since\nrule-based reasoning is essential for acquiring systematic generalization\nability, we aim to explore exactly whether transformers use rule-based or\ncase-based reasoning for math problems. Through carefully designed intervention\nexperiments on five math tasks, we confirm that transformers are performing\ncase-based reasoning, no matter whether scratchpad is used, which aligns with\nthe previous observations that transformers use subgraph matching/shortcut\nlearning to reason. To mitigate such problems, we propose a Rule-Following\nFine-Tuning (RFFT) technique to teach transformers to perform rule-based\nreasoning. Specifically, we provide explicit rules in the input and then\ninstruct transformers to recite and follow the rules step by step. Through\nRFFT, we successfully enable LLMs fine-tuned on 1-5 digit addition to\ngeneralize to up to 12-digit addition with over 95% accuracy, which is over 40%\nhigher than scratchpad. The significant improvement demonstrates that teaching\nLLMs to use rules explicitly helps them learn rule-based reasoning and\ngeneralize better in length.\n","authors":["Yi Hu","Xiaojuan Tang","Haotong Yang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.17709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18193v1","updated":"2024-06-26T09:17:27Z","published":"2024-06-26T09:17:27Z","title":"MammothModa: Multi-Modal Large Language Model","summary":"  In this report, we introduce MammothModa, yet another multi-modal large\nlanguage model (MLLM) designed to achieve state-of-the-art performance starting\nfrom an elementary baseline. We focus on three key design insights: (i)\nIntegrating Visual Capabilities while Maintaining Complex Language\nUnderstanding: In addition to the vision encoder, we incorporated the Visual\nAttention Experts into the LLM to enhance its visual capabilities. (ii)\nExtending Context Window for High-Resolution and Long-Duration Visual Feature:\nWe explore the Visual Merger Module to effectively reduce the token number of\nhigh-resolution images and incorporated frame position ids to avoid position\ninterpolation. (iii) High-Quality Bilingual Datasets: We meticulously curated\nand filtered a high-quality bilingual multimodal dataset to reduce visual\nhallucinations. With above recipe we build MammothModa that consistently\noutperforms the state-of-the-art models, e.g., LLaVA-series, across main\nreal-world visual language benchmarks without bells and whistles.\n","authors":["Qi She","Junwen Pan","Xin Wan","Rui Zhang","Dawei Lu","Kai Huang"],"pdf_url":"https://arxiv.org/pdf/2406.18193v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.18192v1","updated":"2024-06-26T09:16:08Z","published":"2024-06-26T09:16:08Z","title":"Methodology of Adapting Large English Language Models for Specific\n  Cultural Contexts","summary":"  The rapid growth of large language models(LLMs) has emerged as a prominent\ntrend in the field of artificial intelligence. However, current\nstate-of-the-art LLMs are predominantly based on English. They encounter\nlimitations when directly applied to tasks in specific cultural domains, due to\ndeficiencies in domain-specific knowledge and misunderstandings caused by\ndifferences in cultural values. To address this challenge, our paper proposes a\nrapid adaptation method for large models in specific cultural contexts, which\nleverages instruction-tuning based on specific cultural knowledge and safety\nvalues data. Taking Chinese as the specific cultural context and utilizing the\nLLaMA3-8B as the experimental English LLM, the evaluation results demonstrate\nthat the adapted LLM significantly enhances its capabilities in domain-specific\nknowledge and adaptability to safety values, while maintaining its original\nexpertise advantages.\n","authors":["Wenjing Zhang","Siqi Xiao","Xuejiao Lei","Ning Wang","Huazheng Zhang","Meijuan An","Bikun Yang","Zhaoxiang Liu","Kai Wang","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2406.18192v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.18187v1","updated":"2024-06-26T09:03:52Z","published":"2024-06-26T09:03:52Z","title":"Selective Prompting Tuning for Personalized Conversations with LLMs","summary":"  In conversational AI, personalizing dialogues with persona profiles and\ncontextual understanding is essential. Despite large language models' (LLMs)\nimproved response coherence, effective persona integration remains a challenge.\nIn this work, we first study two common approaches for personalizing LLMs:\ntextual prompting and direct fine-tuning. We observed that textual prompting\noften struggles to yield responses that are similar to the ground truths in\ndatasets, while direct fine-tuning tends to produce repetitive or overly\ngeneric replies. To alleviate those issues, we propose \\textbf{S}elective\n\\textbf{P}rompt \\textbf{T}uning (SPT), which softly prompts LLMs for\npersonalized conversations in a selective way. Concretely, SPT initializes a\nset of soft prompts and uses a trainable dense retriever to adaptively select\nsuitable soft prompts for LLMs according to different input contexts, where the\nprompt retriever is dynamically updated through feedback from the LLMs.\nAdditionally, we propose context-prompt contrastive learning and prompt fusion\nlearning to encourage the SPT to enhance the diversity of personalized\nconversations. Experiments on the CONVAI2 dataset demonstrate that SPT\nsignificantly enhances response diversity by up to 90\\%, along with\nimprovements in other critical performance indicators. Those results highlight\nthe efficacy of SPT in fostering engaging and personalized dialogue generation.\nThe SPT model code (https://github.com/hqsiswiliam/SPT) is publicly available\nfor further exploration.\n","authors":["Qiushi Huang","Xubo Liu","Tom Ko","Bo Wu","Wenwu Wang","Yu Zhang","Lilian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18187v1.pdf","comment":"Accepted to ACL 2024 findings"},{"id":"http://arxiv.org/abs/2310.09234v5","updated":"2024-06-26T08:59:47Z","published":"2023-10-13T16:37:53Z","title":"ClickPrompt: CTR Models are Strong Prompt Generators for Adapting\n  Language Models to CTR Prediction","summary":"  Click-through rate (CTR) prediction has become increasingly indispensable for\nvarious Internet applications. Traditional CTR models convert the multi-field\ncategorical data into ID features via one-hot encoding, and extract the\ncollaborative signals among features. Such a paradigm suffers from the problem\nof semantic information loss. Another line of research explores the potential\nof pretrained language models (PLMs) for CTR prediction by converting input\ndata into textual sentences through hard prompt templates. Although semantic\nsignals are preserved, they generally fail to capture the collaborative\ninformation (e.g., feature interactions, pure ID features), not to mention the\nunacceptable inference overhead brought by the huge model size. In this paper,\nwe aim to model both the semantic knowledge and collaborative knowledge for\naccurate CTR estimation, and meanwhile address the inference inefficiency\nissue. To benefit from both worlds and close their gaps, we propose a novel\nmodel-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models\nto generate interaction-aware soft prompts for PLMs. We design a\nprompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM\nhas to recover the masked tokens based on the language context, as well as the\nsoft prompts generated by CTR model. The collaborative and semantic knowledge\nfrom ID and textual features would be explicitly aligned and interacted via the\nprompt interface. Then, we can either tune the CTR model with PLM for superior\nperformance, or solely tune the CTR model without PLM for inference efficiency.\nExperiments on four real-world datasets validate the effectiveness of\nClickPrompt compared with existing baselines.\n","authors":["Jianghao Lin","Bo Chen","Hangyu Wang","Yunjia Xi","Yanru Qu","Xinyi Dai","Kangning Zhang","Ruiming Tang","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.09234v5.pdf","comment":"Accepted by WWW 2024"},{"id":"http://arxiv.org/abs/2406.18178v1","updated":"2024-06-26T08:52:34Z","published":"2024-06-26T08:52:34Z","title":"Games of Knightian Uncertainty","summary":"  Arguably, for the latter part of the late 20th and early 21st centuries,\ngames have been seen as the drosophila of AI. Games are a set of exciting\ntestbeds, whose solutions (in terms of identifying optimal players) would lead\nto machines that would possess some form of general intelligence, or at the\nvery least help us gain insights toward building intelligent machines.\nFollowing impressive successes in traditional board games like Go, Chess, and\nPoker, but also video games like the Atari 2600 collection, it is clear that\nthis is not the case. Games have been attacked successfully, but we are nowhere\nnear AGI developments (or, as harsher critics might say, useful AI\ndevelopments!). In this short vision paper, we argue that for game research to\nbecome again relevant to the AGI pathway, we need to be able to address\n\\textit{Knightian uncertainty} in the context of games, i.e. agents need to be\nable to adapt to rapid changes in game rules on the fly with no warning, no\nprevious data, and no model access.\n","authors":["Spyridon Samothrakis","Dennis J. N. J. Soemers","Damian Machlanski"],"pdf_url":"https://arxiv.org/pdf/2406.18178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18175v1","updated":"2024-06-26T08:49:51Z","published":"2024-06-26T08:49:51Z","title":"Galaxy spectroscopy without spectra: Galaxy properties from photometric\n  images with conditional diffusion models","summary":"  Modern spectroscopic surveys can only target a small fraction of the vast\namount of photometrically cataloged sources in wide-field surveys. Here, we\nreport the development of a generative AI method capable of predicting optical\ngalaxy spectra from photometric broad-band images alone. This method draws from\nthe latest advances in diffusion models in combination with contrastive\nnetworks. We pass multi-band galaxy images into the architecture to obtain\noptical spectra. From these, robust values for galaxy properties can be derived\nwith any methods in the spectroscopic toolbox, such as standard population\nsynthesis techniques and Lick indices. When trained and tested on 64x64-pixel\nimages from the Sloan Digital Sky Survey, the global bimodality of star-forming\nand quiescent galaxies in photometric space is recovered, as well as a\nmass-metallicity relation of star-forming galaxies. The comparison between the\nobserved and the artificially created spectra shows good agreement in overall\nmetallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values.\nPhotometric redshift estimates of our generative algorithm can compete with\nother current, specialized deep-learning techniques. Moreover, this work is the\nfirst attempt in the literature to infer velocity dispersion from photometric\nimages. Additionally, we can predict the presence of an active galactic nucleus\nup to an accuracy of 82%. With our method, scientifically interesting galaxy\nproperties, normally requiring spectroscopic inputs, can be obtained in future\ndata sets from large-scale photometric surveys alone. The spectra prediction\nvia AI can further assist in creating realistic mock catalogs.\n","authors":["Lars Doorenbos","Eva Sextl","Kevin Heng","Stefano Cavuoti","Massimo Brescia","Olena Torbaniuk","Giuseppe Longo","Raphael Sznitman","Pablo Márquez-Neila"],"pdf_url":"https://arxiv.org/pdf/2406.18175v1.pdf","comment":"Code is available here:\n  https://github.com/LarsDoorenbos/generate-spectra"},{"id":"http://arxiv.org/abs/2405.14159v2","updated":"2024-06-26T08:41:06Z","published":"2024-05-23T04:12:49Z","title":"Super Tiny Language Models","summary":"  The rapid advancement of large language models (LLMs) has led to significant\nimprovements in natural language processing but also poses challenges due to\ntheir high computational and energy demands. This paper introduces a series of\nresearch efforts focused on Super Tiny Language Models (STLMs), which aim to\ndeliver high performance with significantly reduced parameter counts. We\nexplore innovative techniques such as byte-level tokenization with a pooling\nmechanism, weight tying, and efficient training strategies. These methods aim\nto significantly reduce reduce the parameter count compared to traditional\nmodels -- in future works, we aim to build on these in a way that maintains and\nimproves upon the performance of base transformer models. This series of papers\nwill explore into various subproblems, including tokenizer-free models,\nself-play based training, and alternative training objectives. We will target\nmodels with 10M, 50M, and 100M parameters. Our ultimate goal is to make\nhigh-performance language models more accessible and practical for a wide range\nof applications.\n","authors":["Dylan Hillier","Leon Guertler","Cheston Tan","Palaash Agrawal","Chen Ruirui","Bobby Cheng"],"pdf_url":"https://arxiv.org/pdf/2405.14159v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.18166v1","updated":"2024-06-26T08:26:32Z","published":"2024-06-26T08:26:32Z","title":"Start from Zero: Triple Set Prediction for Automatic Knowledge Graph\n  Completion","summary":"  Knowledge graph (KG) completion aims to find out missing triples in a KG.\nSome tasks, such as link prediction and instance completion, have been proposed\nfor KG completion. They are triple-level tasks with some elements in a missing\ntriple given to predict the missing element of the triple. However, knowing\nsome elements of the missing triple in advance is not always a realistic\nsetting. In this paper, we propose a novel graph-level automatic KG completion\ntask called Triple Set Prediction (TSP) which assumes none of the elements in\nthe missing triples is given. TSP is to predict a set of missing triples given\na set of known triples. To properly and accurately evaluate this new task, we\npropose 4 evaluation metrics including 3 classification metrics and 1 ranking\nmetric, considering both the partial-open-world and the closed-world\nassumptions. Furthermore, to tackle the huge candidate triples for prediction,\nwe propose a novel and efficient subgraph-based method GPHT that can predict\nthe triple set fast. To fairly compare the TSP results, we also propose two\ntypes of methods RuleTensor-TSP and KGE-TSP applying the existing rule- and\nembedding-based methods for TSP as baselines. During experiments, we evaluate\nthe proposed methods on two datasets extracted from Wikidata following the\nrelation-similarity partial-open-world assumption proposed by us, and also\ncreate a complete family data set to evaluate TSP results following the\nclosed-world assumption. Results prove that the methods can successfully\ngenerate a set of missing triples and achieve reasonable scores on the new\ntask, and GPHT performs better than the baselines with significantly shorter\nprediction time. The datasets and code for experiments are available at\nhttps://github.com/zjukg/GPHT-for-TSP.\n","authors":["Wen Zhang","Yajing Xu","Peng Ye","Zhiwei Huang","Zezhong Xu","Jiaoyan Chen","Jeff Z. Pan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18166v1.pdf","comment":"Paper accepted by TKDE in 2024"},{"id":"http://arxiv.org/abs/2310.15021v2","updated":"2024-06-26T08:23:10Z","published":"2023-10-23T15:19:24Z","title":"Efficient Data Learning for Open Information Extraction with Pre-trained\n  Language Models","summary":"  Open Information Extraction (OpenIE) is a fundamental yet challenging task in\nNatural Language Processing, which involves extracting all triples (subject,\npredicate, object) from a given sentence. While labeling-based methods have\ntheir merits, generation-based techniques offer unique advantages, such as the\nability to generate tokens not present in the original sentence. However, these\ngeneration-based methods often require a significant amount of training data to\nlearn the task form of OpenIE and substantial training time to overcome slow\nmodel convergence due to the order penalty. In this paper, we introduce a novel\nframework, OK-IE, that ingeniously transforms the task form of OpenIE into the\npre-training task form of the T5 model, thereby reducing the need for extensive\ntraining data. Furthermore, we introduce an innovative concept of Anchor to\ncontrol the sequence of model outputs, effectively eliminating the impact of\norder penalty on model convergence and significantly reducing training time.\nExperimental results indicate that, compared to previous SOTA methods, OK-IE\nrequires only 1/100 of the training data (900 instances) and 1/120 of the\ntraining time (3 minutes) to achieve comparable results.\n","authors":["Zhiyuan Fan","Shizhu He"],"pdf_url":"https://arxiv.org/pdf/2310.15021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17415v2","updated":"2024-06-26T08:00:18Z","published":"2024-06-25T09:37:15Z","title":"Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing\n  LLMs Beyond Integer Bit-Levels","summary":"  We present a simple variable quantization approach that quantizes different\nlayers of a large language model (LLM) at different bit levels. Specifically,\nwe quantize the most important layers to higher bit precision and less\nimportant layers to lower bits to achieve floating point quantization levels.\nWe propose two effective strategies to measure the importance of layers within\nLLMs: the first measures the importance of a layer based on how different its\noutput embeddings are from the input embeddings (the higher the better); the\nsecond estimates the importance of a layer using the number of layer weights\nthat are much larger than average (the smaller the better). We show that\nquantizing different layers at varying bits according to our importance scores\nresults in minimal performance drop with a far more compressed model size.\nFinally, we present several practical key takeaways from our variable\nlayer-wise quantization experiments: (a) LLM performance under variable\nquantization remains close to the original model until 25-50% of layers are\nmoved in lower quantization using our proposed ordering but only until 5-10% if\nmoved using no specific ordering; (b) Quantizing LLMs to lower bits performs\nsubstantially better than pruning unless extreme quantization (2-bit) is used;\nand (c) Layer-wise quantization to lower bits works better in the case of\nlarger LLMs with more layers compared to smaller LLMs with fewer layers. The\ncode used to run the experiments is available at:\nhttps://github.com/RazvanDu/LayerwiseQuant.\n","authors":["Razvan-Gabriel Dumitru","Vikas Yadav","Rishabh Maheshwary","Paul-Ioan Clotan","Sathwik Tejaswi Madhusudhan","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2406.17415v2.pdf","comment":"submitted to EMNLP, 15 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2405.17234v5","updated":"2024-06-26T07:59:40Z","published":"2024-05-27T14:50:42Z","title":"Benchmarking General-Purpose In-Context Learning","summary":"  In-context learning (ICL) empowers generative models to address new tasks\neffectively and efficiently on the fly, without relying on any artificially\ncrafted optimization techniques. In this paper, we study extending ICL to\naddress a broader range of tasks with an extended learning horizon and higher\nimprovement potential, namely General-Purpose In-Context Learning (GPICL). To\nthis end, we introduce two lightweight benchmarks specifically crafted to train\nand evaluate GPICL functionalities. Each benchmark encompasses a vast number of\ntasks characterized by significant task variance, facilitating meta-training\nthat minimizes inductive bias. These tasks are also crafted to promote\nlong-horizon in-context learning through continuous generation and interaction.\nThese characteristics necessitate the models to leverage contexts and history\ninteractions to enhance their capabilities, across domains such as language\nmodeling, decision-making, and world modeling. Our experiments on the baseline\nmodels demonstrate that meta-training with minimal inductive bias and ICL from\nthe ground up is feasible across all the domains we've discussed. Additionally,\nour findings indicate that the scale of parameters alone may not be crucial for\nICL or GPICL, suggesting alternative approaches such as increasing the scale of\ncontexts and memory states.\n","authors":["Fan Wang","Chuan Lin","Yang Cao","Yu Kang"],"pdf_url":"https://arxiv.org/pdf/2405.17234v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05935v2","updated":"2024-06-26T07:59:03Z","published":"2024-02-08T18:59:48Z","title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large\n  Language Models","summary":"  We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory\n","authors":["Dongyang Liu","Renrui Zhang","Longtian Qiu","Siyuan Huang","Weifeng Lin","Shitian Zhao","Shijie Geng","Ziyi Lin","Peng Jin","Kaipeng Zhang","Wenqi Shao","Chao Xu","Conghui He","Junjun He","Hao Shao","Pan Lu","Hongsheng Li","Yu Qiao","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2402.05935v2.pdf","comment":"Accepted by ICML 2024. Code and models are released at\n  https://github.com/Alpha-VLLM/LLaMA2-Accessory"},{"id":"http://arxiv.org/abs/2406.18142v1","updated":"2024-06-26T07:47:04Z","published":"2024-06-26T07:47:04Z","title":"Innovating for Tomorrow: The Convergence of SE and Green AI","summary":"  The latest advancements in machine learning, specifically in foundation\nmodels, are revolutionizing the frontiers of existing software engineering (SE)\nprocesses. This is a bi-directional phenomona, where 1) software systems are\nnow challenged to provide AI-enabled features to their users, and 2) AI is used\nto automate tasks within the software development lifecycle. In an era where\nsustainability is a pressing societal concern, our community needs to adopt a\nlong-term plan enabling a conscious transformation that aligns with\nenvironmental sustainability values. In this paper, we reflect on the impact of\nadopting environmentally friendly practices to create AI-enabled software\nsystems and make considerations on the environmental impact of using foundation\nmodels for software development.\n","authors":["Luís Cruz","Xavier Franch Gutierrez","Silverio Martínez-Fernández"],"pdf_url":"https://arxiv.org/pdf/2406.18142v1.pdf","comment":"Accepted in SE 2030 - International Workshop on Software Engineering\n  in 2030"},{"id":"http://arxiv.org/abs/2402.11363v3","updated":"2024-06-26T07:45:33Z","published":"2024-02-17T19:04:23Z","title":"Transformer-based de novo peptide sequencing for data-independent\n  acquisition mass spectrometry","summary":"  Tandem mass spectrometry (MS/MS) stands as the predominant high-throughput\ntechnique for comprehensively analyzing protein content within biological\nsamples. This methodology is a cornerstone driving the advancement of\nproteomics. In recent years, substantial strides have been made in\nData-Independent Acquisition (DIA) strategies, facilitating impartial and\nnon-targeted fragmentation of precursor ions. The DIA-generated MS/MS spectra\npresent a formidable obstacle due to their inherent high multiplexing nature.\nEach spectrum encapsulates fragmented product ions originating from multiple\nprecursor peptides. This intricacy poses a particularly acute challenge in de\nnovo peptide/protein sequencing, where current methods are ill-equipped to\naddress the multiplexing conundrum. In this paper, we introduce DiaTrans, a\ndeep-learning model based on transformer architecture. It deciphers peptide\nsequences from DIA mass spectrometry data. Our results show significant\nimprovements over existing STOA methods, including DeepNovo-DIA and PepNet.\nCasanovo-DIA enhances precision by 15.14% to 34.8%, recall by 11.62% to 31.94%\nat the amino acid level, and boosts precision by 59% to 81.36% at the peptide\nlevel. Integrating DIA data and our DiaTrans model holds considerable promise\nto uncover novel peptides and more comprehensive profiling of biological\nsamples. Casanovo-DIA is freely available under the GNU GPL license at\nhttps://github.com/Biocomputing-Research-Group/DiaTrans.\n","authors":["Shiva Ebrahimi","Xuan Guo"],"pdf_url":"https://arxiv.org/pdf/2402.11363v3.pdf","comment":"Ebrahimi S., Guo X. Transformer-based de novo peptide sequencing for\n  data-independent acquisition mass spectrometry. In 2023 IEEE 23rd\n  International Conference on Bioinformatics and Bioengineering (BIBE) 2022 Dec\n  6 (pp. 17-22). IEEE"},{"id":"http://arxiv.org/abs/2406.17542v2","updated":"2024-06-26T07:44:42Z","published":"2024-06-25T13:29:14Z","title":"CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained\n  Models using Greedy Coordinate Descent","summary":"  Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses coordinate descent to minimize the\nlayer-wise reconstruction loss to achieve high-quality quantized weights. Our\nalgorithm is easy to implement and scales efficiently to models with hundreds\nof billions of parameters. Through extensive evaluation on the PaLM2 model\nfamily, we demonstrate that CDQuant consistently outperforms GPTQ across\ndiverse model sizes and quantization levels. In particular, for INT2\nquantization of PaLM2-Otter, CDQuant achieves a 10% reduction in perplexity\ncompared to GPTQ.\n","authors":["Pranav Ajit Nair","Arun Sai Suggala"],"pdf_url":"https://arxiv.org/pdf/2406.17542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18140v1","updated":"2024-06-26T07:44:27Z","published":"2024-06-26T07:44:27Z","title":"Exclusive Style Removal for Cross Domain Novel Class Discovery","summary":"  As a promising field in open-world learning, \\textit{Novel Class Discovery}\n(NCD) is usually a task to cluster unseen novel classes in an unlabeled set\nbased on the prior knowledge of labeled data within the same domain. However,\nthe performance of existing NCD methods could be severely compromised when\nnovel classes are sampled from a different distribution with the labeled ones.\nIn this paper, we explore and establish the solvability of NCD in cross domain\nsetting with the necessary condition that style information must be removed.\nBased on the theoretical analysis, we introduce an exclusive style removal\nmodule for extracting style information that is distinctive from the baseline\nfeatures, thereby facilitating inference. Moreover, this module is easy to\nintegrate with other NCD methods, acting as a plug-in to improve performance on\nnovel classes with different distributions compared to the seen labeled set.\nAdditionally, recognizing the non-negligible influence of different backbones\nand pre-training strategies on the performance of the NCD methods, we build a\nfair benchmark for future NCD research. Extensive experiments on three common\ndatasets demonstrate the effectiveness of our proposed module.\n","authors":["Yicheng Wang","Feng Liu","Junmin Liu","Zhen Fang","Kai Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.18702v2","updated":"2024-06-26T07:44:11Z","published":"2023-11-30T16:52:42Z","title":"CritiqueLLM: Towards an Informative Critique Generation Model for\n  Evaluation of Large Language Model Generation","summary":"  Since the natural language processing (NLP) community started to make large\nlanguage models (LLMs) act as a critic to evaluate the quality of generated\ntexts, most of the existing works train a critique generation model on the\nevaluation data labeled by GPT-4's direct prompting. We observe that these\nmodels lack the ability to generate informative critiques in both pointwise\ngrading and pairwise comparison especially without references. As a result,\ntheir generated critiques cannot provide fine-grained distinguishability on\ngenerated texts, causing unsatisfactory evaluation performance. In this paper,\nwe propose a simple yet effective method called Eval-Instruct, which can first\nacquire pointwise grading critiques with pseudo references and then revise\nthese critiques via multi-path prompting to obtain informative evaluation data\nin different tasks and settings, including pointwise grading and pairwise\ncomparison with / without references. After fine-tuning on these data, the\nresulting model CritiqueLLM is empirically shown to outperform ChatGPT and all\nthe open-source baselines and even achieve comparable evaluation performance to\nGPT-4 in system-level correlations of pointwise grading. We also demonstrate\nthat our generated critiques can act as scalable feedback to further improve\nthe generation quality of strong LLMs like ChatGPT.\n","authors":["Pei Ke","Bosi Wen","Zhuoer Feng","Xiao Liu","Xuanyu Lei","Jiale Cheng","Shengyuan Wang","Aohan Zeng","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2311.18702v2.pdf","comment":"Accepted by ACL 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2402.04678v3","updated":"2024-06-26T07:43:11Z","published":"2024-02-07T09:09:14Z","title":"FaithLM: Towards Faithful Explanations for Large Language Models","summary":"  Large Language Models (LLMs) have become proficient in addressing complex\ntasks by leveraging their extensive internal knowledge and reasoning\ncapabilities. However, the black-box nature of these models complicates the\ntask of explaining their decision-making processes. While recent advancements\ndemonstrate the potential of leveraging LLMs to self-explain their predictions\nthrough natural language (NL) explanations, their explanations may not\naccurately reflect the LLMs' decision-making process due to a lack of fidelity\noptimization on the derived explanations. Measuring the fidelity of NL\nexplanations is a challenging issue, as it is difficult to manipulate the input\ncontext to mask the semantics of these explanations. To this end, we introduce\nFaithLM to explain the decision of LLMs with NL explanations. Specifically,\nFaithLM designs a method for evaluating the fidelity of NL explanations by\nincorporating the contrary explanations to the query process. Moreover, FaithLM\nconducts an iterative process to improve the fidelity of derived explanations.\nExperiment results on three datasets from multiple domains demonstrate that\nFaithLM can significantly improve the fidelity of derived explanations, which\nalso provides a better alignment with the ground-truth explanations.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Chia-Yuan Chang","Ruixiang Tang","Shaochen Zhong","Fan Yang","Mengnan Du","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2402.04678v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16505v2","updated":"2024-06-26T07:40:12Z","published":"2024-06-24T10:21:29Z","title":"$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep\n  Reinforcement Learning","summary":"  Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.\n","authors":["Feng Xu","Yan Yin","Xinyu Zhang","Tianyuan Liu","Shengyi Jiang","Zongzhang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16505v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20089v2","updated":"2024-06-26T07:35:30Z","published":"2024-03-29T09:54:09Z","title":"Implications of the AI Act for Non-Discrimination Law and Algorithmic\n  Fairness","summary":"  The topic of fairness in AI, as debated in the FATE (Fairness,\nAccountability, Transparency, and Ethics in AI) communities, has sparked\nmeaningful discussions in the past years. However, from a legal perspective,\nparticularly from the perspective of European Union law, many open questions\nremain. Whereas algorithmic fairness aims to mitigate structural inequalities\nat design-level, European non-discrimination law is tailored to individual\ncases of discrimination after an AI model has been deployed. The AI Act might\npresent a tremendous step towards bridging these two approaches by shifting\nnon-discrimination responsibilities into the design stage of AI models. Based\non an integrative reading of the AI Act, we comment on legal as well as\ntechnical enforcement problems and propose practical implications on bias\ndetection and bias correction in order to specify and comply with specific\ntechnical requirements.\n","authors":["Luca Deck","Jan-Laurin Müller","Conradin Braun","Domenique Zipperling","Niklas Kühl"],"pdf_url":"https://arxiv.org/pdf/2403.20089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00673v2","updated":"2024-06-26T07:28:15Z","published":"2024-03-31T12:44:48Z","title":"A Survey of Privacy-Preserving Model Explanations: Privacy Risks,\n  Attacks, and Countermeasures","summary":"  As the adoption of explainable AI (XAI) continues to expand, the urgency to\naddress its privacy implications intensifies. Despite a growing corpus of\nresearch in AI privacy and explainability, there is little attention on\nprivacy-preserving model explanations. This article presents the first thorough\nsurvey about privacy attacks on model explanations and their countermeasures.\nOur contribution to this field comprises a thorough analysis of research papers\nwith a connected taxonomy that facilitates the categorisation of privacy\nattacks and countermeasures based on the targeted explanations. This work also\nincludes an initial investigation into the causes of privacy leaks. Finally, we\ndiscuss unresolved issues and prospective research directions uncovered in our\nanalysis. This survey aims to be a valuable resource for the research community\nand offers clear insights for those new to this domain. To support ongoing\nresearch, we have established an online resource repository, which will be\ncontinuously updated with new and relevant findings. Interested readers are\nencouraged to access our repository at\nhttps://github.com/tamlhp/awesome-privex.\n","authors":["Thanh Tam Nguyen","Thanh Trung Huynh","Zhao Ren","Thanh Toan Nguyen","Phi Le Nguyen","Hongzhi Yin","Quoc Viet Hung Nguyen"],"pdf_url":"https://arxiv.org/pdf/2404.00673v2.pdf","comment":"Revision"},{"id":"http://arxiv.org/abs/2406.18125v1","updated":"2024-06-26T07:25:18Z","published":"2024-06-26T07:25:18Z","title":"ResumeAtlas: Revisiting Resume Classification with Large-Scale Datasets\n  and Large Language Models","summary":"  The increasing reliance on online recruitment platforms coupled with the\nadoption of AI technologies has highlighted the critical need for efficient\nresume classification methods. However, challenges such as small datasets, lack\nof standardized resume templates, and privacy concerns hinder the accuracy and\neffectiveness of existing classification models. In this work, we address these\nchallenges by presenting a comprehensive approach to resume classification. We\ncurated a large-scale dataset of 13,389 resumes from diverse sources and\nemployed Large Language Models (LLMs) such as BERT and Gemma1.1 2B for\nclassification. Our results demonstrate significant improvements over\ntraditional machine learning approaches, with our best model achieving a top-1\naccuracy of 92\\% and a top-5 accuracy of 97.5\\%. These findings underscore the\nimportance of dataset quality and advanced model architectures in enhancing the\naccuracy and robustness of resume classification systems, thus advancing the\nfield of online recruitment practices.\n","authors":["Ahmed Heakl","Youssef Mohamed","Noran Mohamed","Ali Sharkaway","Ahmed Zaky"],"pdf_url":"https://arxiv.org/pdf/2406.18125v1.pdf","comment":"8 pages, 6 figures, 1 table, 6th International Conference on AI in\n  Computational Linguistics"},{"id":"http://arxiv.org/abs/2406.18122v1","updated":"2024-06-26T07:21:02Z","published":"2024-06-26T07:21:02Z","title":"Poisoned LangChain: Jailbreak LLMs by LangChain","summary":"  With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.\n","authors":["Ziqiu Wang","Jun Liu","Shengkai Zhang","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.18122v1.pdf","comment":"6 pages,2 figures,This paper is a submission to ACM TURC. It has been\n  accepted by the editor of the organizer"},{"id":"http://arxiv.org/abs/2406.18120v1","updated":"2024-06-26T07:19:51Z","published":"2024-06-26T07:19:51Z","title":"ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech\n  Recognition Using LLMs","summary":"  Motivated by the widespread increase in the phenomenon of code-switching\nbetween Egyptian Arabic and English in recent times, this paper explores the\nintricacies of machine translation (MT) and automatic speech recognition (ASR)\nsystems, focusing on translating code-switched Egyptian Arabic-English to\neither English or Egyptian Arabic. Our goal is to present the methodologies\nemployed in developing these systems, utilizing large language models such as\nLLama and Gemma. In the field of ASR, we explore the utilization of the Whisper\nmodel for code-switched Egyptian Arabic recognition, detailing our experimental\nprocedures including data preprocessing and training techniques. Through the\nimplementation of a consecutive speech-to-text translation system that\nintegrates ASR with MT, we aim to overcome challenges posed by limited\nresources and the unique characteristics of the Egyptian Arabic dialect.\nEvaluation against established metrics showcases promising results, with our\nmethodologies yielding a significant improvement of $56\\%$ in English\ntranslation over the state-of-the-art and $9.3\\%$ in Arabic translation. Since\ncode-switching is deeply inherent in spoken languages, it is crucial that ASR\nsystems can effectively handle this phenomenon. This capability is crucial for\nenabling seamless interaction in various domains, including business\nnegotiations, cultural exchanges, and academic discourse. Our models and code\nare available as open-source resources. Code:\n\\url{http://github.com/ahmedheakl/arazn-llm}}, Models:\n\\url{http://huggingface.co/collections/ahmedheakl/arazn-llm-662ceaf12777656607b9524e}.\n","authors":["Ahmed Heakl","Youssef Zaghloul","Mennatullah Ali","Rania Hossam","Walid Gomaa"],"pdf_url":"https://arxiv.org/pdf/2406.18120v1.pdf","comment":"9 pages, 4 figures, 5 tables, 6th International Conference on AI in\n  Computational Linguistics"},{"id":"http://arxiv.org/abs/2311.07989v7","updated":"2024-06-26T07:11:00Z","published":"2023-11-14T08:34:26Z","title":"Unifying the Perspectives of NLP and Software Engineering: A Survey on\n  Language Models for Code","summary":"  In this work we systematically review the recent advancements in software\nengineering with language models, covering 70+ models, 40+ evaluation tasks,\n180+ datasets, and 900 related works. Unlike previous works, we integrate\nsoftware engineering (SE) with natural language processing (NLP) by discussing\nthe perspectives of both sides: SE applies language models for development\nautomation, while NLP adopts SE tasks for language model evaluation. We break\ndown code processing models into general language models represented by the GPT\nfamily and specialized models that are specifically pretrained on code, often\nwith tailored objectives. We discuss the relations and differences between\nthese models, and highlight the historical transition of code modeling from\nstatistical models and RNNs to pretrained Transformers and LLMs, which is\nexactly the same course that had been taken by NLP. We also go beyond\nprogramming and review LLMs' application in other software engineering\nactivities including requirement engineering, testing, deployment, and\noperations in an endeavor to provide a global view of NLP in SE, and identify\nkey challenges and potential future directions in this domain. We keep the\nsurvey open and updated on GitHub at\nhttps://github.com/codefuse-ai/Awesome-Code-LLM.\n","authors":["Ziyin Zhang","Chaoyu Chen","Bingchang Liu","Cong Liao","Zi Gong","Hang Yu","Jianguo Li","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2311.07989v7.pdf","comment":"Repo: https://github.com/codefuse-ai/Awesome-Code-LLM. 9 figures, 18\n  tables, and 902 references. Under review"},{"id":"http://arxiv.org/abs/2406.18116v1","updated":"2024-06-26T07:07:52Z","published":"2024-06-26T07:07:52Z","title":"BADGE: BADminton report Generation and Evaluation with LLM","summary":"  Badminton enjoys widespread popularity, and reports on matches generally\ninclude details such as player names, game scores, and ball types, providing\naudiences with a comprehensive view of the games. However, writing these\nreports can be a time-consuming task. This challenge led us to explore whether\na Large Language Model (LLM) could automate the generation and evaluation of\nbadminton reports. We introduce a novel framework named BADGE, designed for\nthis purpose using LLM. Our method consists of two main phases: Report\nGeneration and Report Evaluation. Initially, badminton-related data is\nprocessed by the LLM, which then generates a detailed report of the match. We\ntested different Input Data Types, In-Context Learning (ICL), and LLM, finding\nthat GPT-4 performs best when using CSV data type and the Chain of Thought\nprompting. Following report generation, the LLM evaluates and scores the\nreports to assess their quality. Our comparisons between the scores evaluated\nby GPT-4 and human judges show a tendency to prefer GPT-4 generated reports.\nSince the application of LLM in badminton reporting remains largely unexplored,\nour research serves as a foundational step for future advancements in this\narea. Moreover, our method can be extended to other sports games, thereby\nenhancing sports promotion. For more details, please refer to\nhttps://github.com/AndyChiangSH/BADGE.\n","authors":["Shang-Hsuan Chiang","Lin-Wei Chao","Kuang-Da Wang","Chih-Chuan Wang","Wen-Chih Peng"],"pdf_url":"https://arxiv.org/pdf/2406.18116v1.pdf","comment":"Accepted by IJCAI 2024 Workshop: The 2nd International Workshop on\n  Intelligent Technologies for Precision Sports Science (IT4PSS)"},{"id":"http://arxiv.org/abs/2406.18115v1","updated":"2024-06-26T07:06:42Z","published":"2024-06-26T07:06:42Z","title":"Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with\n  3D Semantic Maps","summary":"  Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for\nautonomous robots, especially when faced with the challenges posed by unknown\nand dynamic environments. This task requires robots to explore and build a\nsemantic understanding of their surroundings, generate feasible plans to\nachieve manipulation goals, adapt to environmental changes, and comprehend\nnatural language instructions from humans. To address these challenges, we\npropose a novel framework that leverages the zero-shot detection and grounded\nrecognition capabilities of pretraining visual-language models (VLMs) combined\nwith dense 3D entity reconstruction to build 3D semantic maps. Additionally, we\nutilize large language models (LLMs) for spatial region abstraction and online\nplanning, incorporating human instructions and spatial semantic context. We\nhave built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated\nin real-world robot experiments that our proposed framework can effectively\ncapture spatial semantics and process natural language user instructions for\nzero-shot OVMM tasks under dynamic environment settings, with an overall\nnavigation and task success rate of 80.95% and 73.33% over 105 episodes, and\nbetter SFT and SPL by 157.18% and 19.53% respectively compared to the baseline.\nFurthermore, the framework is capable of replanning towards the next most\nprobable candidate location based on the spatial semantic context derived from\nthe 3D semantic map when initial plans fail, keeping an average success rate of\n76.67%.\n","authors":["Dicong Qiu","Wenzong Ma","Zhenfu Pan","Hui Xiong","Junwei Liang"],"pdf_url":"https://arxiv.org/pdf/2406.18115v1.pdf","comment":"Open-vocabulary, Mobile Manipulation, Dynamic Environments, 3D\n  Semantic Maps, Zero-shot, LLMs, VLMs, 18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.05905v3","updated":"2024-06-26T06:29:32Z","published":"2024-05-09T17:01:31Z","title":"Truthful Aggregation of LLMs with an Application to Online Advertising","summary":"  Online platforms generate hundreds of billions of dollars in revenue per year\nby showing advertisements alongside their own content. Currently, these\nplatforms are integrating Large Language Models (LLMs) into their services.\nThis makes revenue generation from LLM-generated content the next major\nchallenge in online advertising. We consider a scenario where advertisers aim\nto influence the responses of an LLM to align with their interests, while\nplatforms seek to maximize advertiser value and ensure user satisfaction. We\nintroduce an auction mechanism for this problem that operates without LLM\nfine-tuning or access to model weights and provably converges to the output of\nthe optimally fine-tuned LLM for the platform's objective as computational\nresources increase. Our mechanism ensures that truthful reporting is a dominant\nstrategy for advertisers and it aligns each advertiser's utility with their\ncontribution to social welfare - an essential feature for long-term viability.\nAdditionally, it can incorporate contextual information about the advertisers,\nsignificantly accelerating convergence. Via experiments with a publicly\navailable LLM, we show that our mechanism significantly boosts advertiser value\nand platform revenue, with low computational overhead. While our motivating\napplication is online advertising, our mechanism can be applied in any setting\nwith monetary transfers, making it a general-purpose solution for truthfully\naggregating the preferences of self-interested agents over LLM-generated\nreplies.\n","authors":["Ermis Soumalias","Michael J. Curry","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2405.05905v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02856v4","updated":"2024-06-26T06:28:45Z","published":"2024-06-05T02:12:06Z","title":"Xmodel-LM Technical Report","summary":"  We introduce Xmodel-LM, a compact and efficient 1.1B language model\npre-trained on around 2 trillion tokens. Trained on our self-built dataset\n(Xdata), which balances Chinese and English corpora based on downstream task\noptimization, Xmodel-LM exhibits remarkable performance despite its smaller\nsize. It notably surpasses existing open-source language models of similar\nscale. Our model checkpoints and code are publicly accessible on GitHub at\nhttps://github.com/XiaoduoAILab/XmodelLM.\n","authors":["Yichuan Wang","Yang Liu","Yu Yan","Qun Wang","Xucheng Huang","Ling Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.02856v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18088v1","updated":"2024-06-26T05:52:47Z","published":"2024-06-26T05:52:47Z","title":"LLM-Driven Multimodal Opinion Expression Identification","summary":"  Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to\nmirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method\nSTOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.\n","authors":["Bonian Jia","Huiyao Chen","Yueheng Sun","Meishan Zhang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18088v1.pdf","comment":"6 pages, 3 Figures"},{"id":"http://arxiv.org/abs/2406.18087v1","updated":"2024-06-26T05:51:08Z","published":"2024-06-26T05:51:08Z","title":"EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction\n  Using Large Language Multimodal Models","summary":"  Traditional diagnosis of chronic diseases involves in-person consultations\nwith physicians to identify the disease. However, there is a lack of research\nfocused on predicting and developing application systems using clinical notes\nand blood test values. We collected five years of Electronic Health Records\n(EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database.\nFurthermore, we developed an EHR-based chronic disease prediction platform\nutilizing Large Language Multimodal Models (LLMMs), successfully integrating\nwith frontend web and mobile applications for prediction. This prediction\nplatform can also connect to the hospital's backend database, providing\nphysicians with real-time risk assessment diagnostics. The demonstration link\ncan be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.\n","authors":["Chun-Chieh Liao","Wei-Ting Kuo","I-Hsuan Hu","Yen-Chen Shih","Jun-En Ding","Feng Liu","Fang-Ming Hung"],"pdf_url":"https://arxiv.org/pdf/2406.18087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06918v2","updated":"2024-06-26T05:47:52Z","published":"2024-02-10T09:51:03Z","title":"Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to\n  Searching for the Most Promising Intermediate Thought","summary":"  To improve the ability of the large language model (LLMs) to tackle complex\nreasoning problems, chain-of-thoughts (CoT) methods were proposed to guide LLMs\nto reason step-by-step, enabling problem solving from simple to complex.\nState-of-the-art methods for generating such a chain involve interactive\ncollaboration, where the learner generates candidate intermediate thoughts,\nevaluated by the LLM, guiding the generation of subsequent thoughts. However, a\nwidespread yet understudied problem is that the evaluation from the LLM is\ntypically noisy and unreliable, potentially misleading the generation process\nin selecting promising intermediate thoughts. In this paper, motivated by\nVapnik's principle, we use pairwise-comparison evaluation instead of point-wise\nscoring to search for promising intermediate thoughts with the noisy feedback\nfrom the LLM. In each round, we randomly pair intermediate thoughts and\ndirectly prompt the LLM to select the more promising one from each pair,\nallowing us to identify the most promising thoughts through an iterative\nprocess. To further alleviate the noise in the comparison, we incorporate\ntechniques from ensemble learning and dueling bandits, proposing two variants\nof the algorithm. Experiments on three real-world tasks demonstrate the\neffectiveness of our proposed algorithm and verify the rationale of the\npairwise comparison mechanism.\n","authors":["Zhen-Yu Zhang","Siwei Han","Huaxiu Yao","Gang Niu","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2402.06918v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.17215v2","updated":"2024-06-26T05:45:28Z","published":"2024-06-25T02:05:26Z","title":"Enabling Large Language Models to Perform Power System Simulations with\n  Previously Unseen Tools: A Case of Daline","summary":"  The integration of experiment technologies with large language models (LLMs)\nis transforming scientific research, offering AI capabilities beyond\nspecialized problem-solving to becoming research assistants for human\nscientists. In power systems, simulations are essential for research. However,\nLLMs face significant challenges in power system simulations due to limited\npre-existing knowledge and the complexity of power grids. To address this\nissue, this work proposes a modular framework that integrates expertise from\nboth the power system and LLM domains. This framework enhances LLMs' ability to\nperform power system simulations on previously unseen tools. Validated using 34\nsimulation tasks in Daline, a (optimal) power flow simulation and linearization\ntoolbox not yet exposed to LLMs, the proposed framework improved GPT-4o's\nsimulation coding accuracy from 0% to 96.07%, also outperforming the ChatGPT-4o\nweb interface's 33.8% accuracy (with the entire knowledge base uploaded). These\nresults highlight the potential of LLMs as research assistants in power\nsystems.\n","authors":["Mengshuo Jia","Zeyu Cui","Gabriela Hug"],"pdf_url":"https://arxiv.org/pdf/2406.17215v2.pdf","comment":"All the supplementary files mentioned in the manuscript will be\n  open-source upon acceptance"},{"id":"http://arxiv.org/abs/2406.16464v2","updated":"2024-06-26T05:40:16Z","published":"2024-06-24T09:13:42Z","title":"InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for\n  Multi-modal Sarcasm Detection","summary":"  The prevalence of sarcasm in social media, conveyed through text-image\ncombinations, presents significant challenges for sentiment analysis and\nintention mining. Current multi-modal sarcasm detection methods have been\nproven to struggle with biases from spurious cues, leading to a superficial\nunderstanding of the complex interactions between text and image. To address\nthese issues, we propose InterCLIP-MEP, a robust framework for multi-modal\nsarcasm detection. InterCLIP-MEP introduces a refined variant of CLIP,\nInteractive CLIP (InterCLIP), as the backbone, enhancing sample representations\nby embedding cross-modality information in each encoder. Furthermore, a novel\ntraining strategy is designed to adapt InterCLIP for a Memory-Enhanced\nPredictor (MEP). MEP uses dynamic dual-channel memory to store valuable\nhistorical knowledge of test samples and then leverages this memory as a\nnon-parametric classifier to derive the final prediction. By using InterCLIP to\nencode text-image interactions more effectively and incorporating MEP,\nInterCLIP-MEP offers a more robust recognition of multi-modal sarcasm.\nExperiments demonstrate that InterCLIP-MEP achieves state-of-the-art\nperformance on the MMSD2.0 benchmark. Code and data are available at\nhttps://github.com/CoderChen01/InterCLIP-MEP.\n","authors":["Junjie Chen","Subin Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16464v2.pdf","comment":"8 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.18078v1","updated":"2024-06-26T05:30:21Z","published":"2024-06-26T05:30:21Z","title":"Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad\n  Prediction","summary":"  Aspect Sentiment Quad Prediction (ASQP) aims to predict all quads (aspect\nterm, aspect category, opinion term, sentiment polarity) for a given review,\nwhich is the most representative and challenging task in aspect-based sentiment\nanalysis. A key challenge in the ASQP task is the scarcity of labeled data,\nwhich limits the performance of existing methods. To tackle this issue, we\npropose a self-training framework with a pseudo-label scorer, wherein a scorer\nassesses the match between reviews and their pseudo-labels, aiming to filter\nout mismatches and thereby enhance the effectiveness of self-training. We\nhighlight two critical aspects to ensure the scorer's effectiveness and\nreliability: the quality of the training dataset and its model architecture. To\nthis end, we create a human-annotated comparison dataset and train a generative\nmodel on it using ranking-based objectives. Extensive experiments on public\nASQP datasets reveal that using our scorer can greatly and consistently improve\nthe effectiveness of self-training. Moreover, we explore the possibility of\nreplacing humans with large language models for comparison dataset annotation,\nand experiments demonstrate its feasibility. We release our code and data at\nhttps://github.com/HITSZ-HLT/ST-w-Scorer-ABSA .\n","authors":["Yice Zhang","Jie Zeng","Weiming Hu","Ziyi Wang","Shiwei Chen","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2406.18078v1.pdf","comment":"Accepted to ACL 2024 Main Conference"},{"id":"http://arxiv.org/abs/2406.07249v2","updated":"2024-06-26T05:07:15Z","published":"2024-06-11T13:32:11Z","title":"Are Protein Language Models Compute Optimal?","summary":"  While protein language models (pLMs) have transformed biological research,\nthe scaling laws governing their improvement remain underexplored. By adapting\nmethodologies from NLP scaling laws, we investigated the optimal ratio between\nmodel parameters and training tokens within a fixed compute budget. Our study\nreveals that pLM sizes scale sublinearly with compute budget, showing\ndiminishing returns in performance as model size increases, and we identify a\nperformance plateau in training loss comparable to the one found in relevant\nworks in the field. Our findings suggest that widely-used pLMs might not be\ncompute-optimal, indicating that larger models could achieve convergence more\nefficiently. Training a 35M model on a reduced token set, we attained\nperplexity results comparable to larger models like ESM-2 (15B) and xTrimoPGLM\n(100B) with a single dataset pass. This work paves the way towards more\ncompute-efficient pLMs, democratizing their training and practical application\nin computational biology.\n","authors":["Yaiza Serrano","Álvaro Ciudad","Alexis Molina"],"pdf_url":"https://arxiv.org/pdf/2406.07249v2.pdf","comment":"Proceedings of the ICML 2024 Workshop on Accessible and Efficient\n  Foundation Models for Biological Discovery, Vienna, Austria. 2024"},{"id":"http://arxiv.org/abs/2406.18074v1","updated":"2024-06-26T05:06:14Z","published":"2024-06-26T05:06:14Z","title":"Few-Shot Medical Image Segmentation with High-Fidelity Prototypes","summary":"  Few-shot Semantic Segmentation (FSS) aims to adapt a pretrained model to new\nclasses with as few as a single labelled training sample per class. Despite the\nprototype based approaches have achieved substantial success, existing models\nare limited to the imaging scenarios with considerably distinct objects and not\nhighly complex background, e.g., natural images. This makes such models\nsuboptimal for medical imaging with both conditions invalid. To address this\nproblem, we propose a novel Detail Self-refined Prototype Network (DSPNet) to\nconstructing high-fidelity prototypes representing the object foreground and\nthe background more comprehensively. Specifically, to construct global\nsemantics while maintaining the captured detail semantics, we learn the\nforeground prototypes by modelling the multi-modal structures with clustering\nand then fusing each in a channel-wise manner. Considering that the background\noften has no apparent semantic relation in the spatial dimensions, we integrate\nchannel-specific structural information under sparse channel-aware regulation.\nExtensive experiments on three challenging medical image benchmarks show the\nsuperiority of DSPNet over previous state-of-the-art methods.\n","authors":["Song Tang","Shaxu Yan","Xiaozhi Qi","Jianxin Gao","Mao Ye","Jianwei Zhang","Xiatian Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.18074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18069v1","updated":"2024-06-26T04:54:45Z","published":"2024-06-26T04:54:45Z","title":"Large Language Models for Cuffless Blood Pressure Measurement From\n  Wearable Biosignals","summary":"  Large language models (LLMs) have captured significant interest from both\nacademia and industry due to their impressive performance across various\ntextual tasks. However, the potential of LLMs to analyze physiological\ntime-series data remains an emerging research field. Particularly, there is a\nnotable gap in the utilization of LLMs for analyzing wearable biosignals to\nachieve cuffless blood pressure (BP) measurement, which is critical for the\nmanagement of cardiovascular diseases. This paper presents the first work to\nexplore the capacity of LLMs to perform cuffless BP estimation based on\nwearable biosignals. We extracted physiological features from electrocardiogram\n(ECG) and photoplethysmogram (PPG) signals and designed context-enhanced\nprompts by combining these features with BP domain knowledge and user\ninformation. Subsequently, we adapted LLMs to BP estimation tasks through\ninstruction tuning. To evaluate the proposed approach, we conducted assessments\nof ten advanced LLMs using a comprehensive public dataset of wearable\nbiosignals from 1,272 participants. The experimental results demonstrate that\nthe optimally fine-tuned LLM significantly surpasses conventional task-specific\nbaselines, achieving an estimation error of 0.00 $\\pm$ 9.25 mmHg for systolic\nBP and 1.29 $\\pm$ 6.37 mmHg for diastolic BP. Notably, the ablation studies\nhighlight the benefits of our context enhancement strategy, leading to an 8.9%\nreduction in mean absolute error for systolic BP estimation. This paper\npioneers the exploration of LLMs for cuffless BP measurement, providing a\npotential solution to enhance the accuracy of cuffless BP measurement.\n","authors":["Zengding Liu","Chen Chen","Jiannong Cao","Minglei Pan","Jikui Liu","Nan Li","Fen Miao","Ye Li"],"pdf_url":"https://arxiv.org/pdf/2406.18069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18062v1","updated":"2024-06-26T04:49:03Z","published":"2024-06-26T04:49:03Z","title":"Breaking the Barrier: Enhanced Utility and Robustness in Smoothed DRL\n  Agents","summary":"  Robustness remains a paramount concern in deep reinforcement learning (DRL),\nwith randomized smoothing emerging as a key technique for enhancing this\nattribute. However, a notable gap exists in the performance of current smoothed\nDRL agents, often characterized by significantly low clean rewards and weak\nrobustness. In response to this challenge, our study introduces innovative\nalgorithms aimed at training effective smoothed robust DRL agents. We propose\nS-DQN and S-PPO, novel approaches that demonstrate remarkable improvements in\nclean rewards, empirical robustness, and robustness guarantee across standard\nRL benchmarks. Notably, our S-DQN and S-PPO agents not only significantly\noutperform existing smoothed agents by an average factor of $2.16\\times$ under\nthe strongest attack, but also surpass previous robustly-trained agents by an\naverage factor of $2.13\\times$. This represents a significant leap forward in\nthe field. Furthermore, we introduce Smoothed Attack, which is $1.89\\times$\nmore effective in decreasing the rewards of smoothed agents than existing\nadversarial attacks.\n","authors":["Chung-En Sun","Sicun Gao","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2406.18062v1.pdf","comment":"Published in ICML 2024"},{"id":"http://arxiv.org/abs/2406.18060v1","updated":"2024-06-26T04:33:13Z","published":"2024-06-26T04:33:13Z","title":"AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for\n  Memory-Efficient Large Language Models Fine-Tuning","summary":"  Fine-tuning large language models (LLMs) has achieved remarkable performance\nacross various natural language processing tasks, yet it demands more and more\nmemory as model sizes keep growing. To address this issue, the recently\nproposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs\nusing only forward passes, thereby avoiding the need for a backpropagation\ngraph. However, significant performance drops and a high risk of divergence\nhave limited their widespread adoption. In this paper, we propose the Adaptive\nZeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed\nto improve the performance and convergence of the ZO methods. To enhance\ndimension-dependent ZO estimation accuracy, we introduce a fast-forward,\nlow-parameter tensorized adapter. To tackle the frequently observed divergence\nissue in large-scale ZO fine-tuning tasks, we propose an adaptive query number\nschedule that guarantees convergence. Detailed theoretical analysis and\nextensive experimental results on Roberta-Large and Llama-2-7B models\nsubstantiate the efficacy of our AdaZeta framework in terms of accuracy, memory\nefficiency, and convergence speed.\n","authors":["Yifan Yang","Kai Zhen","Ershad Banijamal","Athanasios Mouchtaris","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18053v1","updated":"2024-06-26T04:05:04Z","published":"2024-06-26T04:05:04Z","title":"Bidirectional-Reachable Hierarchical Reinforcement Learning with\n  Mutually Responsive Policies","summary":"  Hierarchical reinforcement learning (HRL) addresses complex long-horizon\ntasks by skillfully decomposing them into subgoals. Therefore, the\neffectiveness of HRL is greatly influenced by subgoal reachability. Typical HRL\nmethods only consider subgoal reachability from the unilateral level, where a\ndominant level enforces compliance to the subordinate level. However, we\nobserve that when the dominant level becomes trapped in local exploration or\ngenerates unattainable subgoals, the subordinate level is negatively affected\nand cannot follow the dominant level's actions. This can potentially make both\nlevels stuck in local optima, ultimately hindering subsequent subgoal\nreachability. Allowing real-time bilateral information sharing and error\ncorrection would be a natural cure for this issue, which motivates us to\npropose a mutual response mechanism. Based on this, we propose the\nBidirectional-reachable Hierarchical Policy Optimization (BrHPO)--a simple yet\neffective algorithm that also enjoys computation efficiency. Experiment results\non a variety of long-horizon tasks showcase that BrHPO outperforms other\nstate-of-the-art HRL baselines, coupled with a significantly higher exploration\nefficiency and robustness.\n","authors":["Yu Luo","Fuchun Sun","Tianying Ji","Xianyuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2406.18053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18049v1","updated":"2024-06-26T03:56:21Z","published":"2024-06-26T03:56:21Z","title":"Improving Entity Recognition Using Ensembles of Deep Learning and\n  Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction\n  from Multiple Sources","summary":"  Adverse event (AE) extraction following COVID-19 vaccines from text data is\ncrucial for monitoring and analyzing the safety profiles of immunizations.\nTraditional deep learning models are adept at learning intricate feature\nrepresentations and dependencies in sequential data, but often require\nextensive labeled data. In contrast, large language models (LLMs) excel in\nunderstanding contextual information, but exhibit unstable performance on named\nentity recognition tasks, possibly due to their broad but unspecific training.\nThis study aims to evaluate the effectiveness of LLMs and traditional deep\nlearning models in AE extraction, and to assess the impact of ensembling these\nmodels on performance. In this study, we utilized reports and posts from the\nVAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal\nwas to extract three types of entities: \"vaccine\", \"shot\", and \"ae\". We\nexplored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,\nGPT-4, and Llama-2, as well as traditional deep learning models like RNN and\nBioBERT. To enhance performance, we created ensembles of the three models with\nthe best performance. For evaluation, we used strict and relaxed F1 scores to\nevaluate the performance for each entity type, and micro-average F1 was used to\nassess the overall performance. The ensemble model achieved the highest\nperformance in \"vaccine\", \"shot\", and \"ae\" with strict F1-scores of 0.878,\n0.930, and 0.925, respectively, along with a micro-average score of 0.903. In\nconclusion, this study demonstrates the effectiveness and robustness of\nensembling fine-tuned traditional deep learning models and LLMs, for extracting\nAE-related information. This study contributes to the advancement of biomedical\nnatural language processing, providing valuable insights into improving AE\nextraction from text data for pharmacovigilance and public health surveillance.\n","authors":["Yiming Li","Deepthi Viswaroopan","William He","Jianfu Li","Xu Zuo","Hua Xu","Cui Tao"],"pdf_url":"https://arxiv.org/pdf/2406.18049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14355v3","updated":"2024-06-26T03:52:24Z","published":"2024-04-22T17:07:25Z","title":"Pre-Calc: Learning to Use the Calculator Improves Numeracy in Language\n  Models","summary":"  Quantitative and numerical comprehension in language is an important task in\nmany fields like education and finance, but still remains a challenging task\nfor language models. While tool and calculator usage has shown to be helpful to\nimprove mathematical reasoning in large pretrained decoder-only language\nmodels, this remains unexplored for smaller language models with encoders. In\nthis paper, we propose Pre-Calc, a simple pre-finetuning objective of learning\nto use the calculator for both encoder-only and encoder-decoder architectures,\nformulated as a discriminative and generative task respectively. We pre-train\nBERT and RoBERTa for discriminative calculator use and Flan-T5 for generative\ncalculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves\nperformance on downstream tasks that require numerical understanding. Our code\nand data are available at https://github.com/calc-cmu/pre-calc.\n","authors":["Vishruth Veerendranath","Vishwa Shah","Kshitish Ghate"],"pdf_url":"https://arxiv.org/pdf/2404.14355v3.pdf","comment":"AI4Math workshop, ICML 2024"},{"id":"http://arxiv.org/abs/2406.18045v1","updated":"2024-06-26T03:43:09Z","published":"2024-06-26T03:43:09Z","title":"PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical\n  and Chemistry","summary":"  Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.\n","authors":["Linqing Chen","Weilei Wang","Zilong Bai","Peng Xu","Yan Fang","Jie Fang","Wentao Wu","Lizhi Zhou","Ruiji Zhang","Yubin Xia","Chaobo Xu","Ran Hu","Licong Xu","Qijun Cai","Haoran Hua","Jing Sun","Jin Liu","Tian Qiu","Haowen Liu","Meng Hu","Xiuwen Li","Fei Gao","Yufu Wang","Lin Tie","Chaochao Wang","Jianping Lu","Cheng Sun","Yixin Wang","Shengjie Yang","Yuancheng Li","Lu Jin","Lisha Zhang","Fu Bian","Changyang Tu"],"pdf_url":"https://arxiv.org/pdf/2406.18045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18043v1","updated":"2024-06-26T03:41:48Z","published":"2024-06-26T03:41:48Z","title":"Multimodal foundation world models for generalist embodied agents","summary":"  Learning generalist embodied agents, able to solve multitudes of tasks in\ndifferent domains is a long-standing problem. Reinforcement learning (RL) is\nhard to scale up as it requires a complex reward design for each task. In\ncontrast, language can specify tasks in a more natural way. Current foundation\nvision-language models (VLMs) generally require fine-tuning or other\nadaptations to be functional, due to the significant domain gap. However, the\nlack of multimodal data in such domains represents an obstacle toward\ndeveloping foundation models for embodied applications. In this work, we\novercome these problems by presenting multimodal foundation world models, able\nto connect and align the representation of foundation VLMs with the latent\nspace of generative world models for RL, without any language annotations. The\nresulting agent learning framework, GenRL, allows one to specify tasks through\nvision and/or language prompts, ground them in the embodied domain's dynamics,\nand learns the corresponding behaviors in imagination. As assessed through\nlarge-scale multi-task benchmarking, GenRL exhibits strong multi-task\ngeneralization performance in several locomotion and manipulation domains.\nFurthermore, by introducing a data-free RL strategy, it lays the groundwork for\nfoundation model-based RL for generalist embodied agents.\n","authors":["Pietro Mazzaglia","Tim Verbelen","Bart Dhoedt","Aaron Courville","Sai Rajeswar"],"pdf_url":"https://arxiv.org/pdf/2406.18043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02085v4","updated":"2024-06-26T03:32:50Z","published":"2024-02-03T08:52:06Z","title":"DeCoF: Generated Video Detection via Frame Consistency: The First\n  Benchmark Dataset","summary":"  The escalating quality of video generated by advanced video generation\nmethods results in new security challenges, while there have been few relevant\nresearch efforts: 1) There is no open-source dataset for generated video\ndetection, 2) No generated video detection method has been proposed so far. To\nthis end, we propose an open-source dataset and a detection method for\ngenerated video for the first time. First, we propose a scalable dataset\nconsisting of 964 prompts, covering various forgery targets, scenes, behaviors,\nand actions, as well as various generation models with different architectures\nand generation methods, including the most popular commercial models like\nOpenAI's Sora and Google's Veo. Second, we found via probing experiments that\nspatial artifact-based detectors lack generalizability. Hence, we propose a\nsimple yet effective \\textbf{de}tection model based on \\textbf{f}rame\n\\textbf{co}nsistency (\\textbf{DeCoF}), which focuses on temporal artifacts by\neliminating the impact of spatial artifacts during feature learning. Extensive\nexperiments demonstrate the efficacy of DeCoF in detecting videos generated by\nunseen video generation models and confirm its powerful generalizability across\nseveral commercially proprietary models. Our code and dataset will be released\nat \\url{https://github.com/wuwuwuyue/DeCoF}.\n","authors":["Long Ma","Jiajia Zhang","Hongping Deng","Ningyu Zhang","Qinglang Guo","Haiyang Yu","Yong Liao","Pengyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.02085v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12272v3","updated":"2024-06-26T03:04:04Z","published":"2024-06-18T04:59:14Z","title":"Slot State Space Models","summary":"  Recent State Space Models (SSMs) such as S4, S5, and Mamba have shown\nremarkable computational benefits in long-range temporal dependency modeling.\nHowever, in many sequence modeling problems, the underlying process is\ninherently modular and it is of interest to have inductive biases that mimic\nthis modular structure. In this paper, we introduce SlotSSMs, a novel framework\nfor incorporating independent mechanisms into SSMs to preserve or encourage\nseparation of information. Unlike conventional SSMs that maintain a monolithic\nstate vector, SlotSSMs maintains the state as a collection of multiple vectors\ncalled slots. Crucially, the state transitions are performed independently per\nslot with sparse interactions across slots implemented via the bottleneck of\nself-attention. In experiments, we evaluate our model in object-centric video\nunderstanding, 3D visual reasoning, and video prediction tasks, which involve\nmodeling multiple objects and their long-range temporal dependencies. We find\nthat our proposed design offers substantial performance gains over existing\nsequence modeling methods.\n","authors":["Jindong Jiang","Fei Deng","Gautam Singh","Minseung Lee","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2406.12272v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18033v1","updated":"2024-06-26T03:02:22Z","published":"2024-06-26T03:02:22Z","title":"Boosting Soft Q-Learning by Bounding","summary":"  An agent's ability to leverage past experience is critical for efficiently\nsolving new tasks. Prior work has focused on using value function estimates to\nobtain zero-shot approximations for solutions to a new task. In soft\nQ-learning, we show how any value function estimate can also be used to derive\ndouble-sided bounds on the optimal value function. The derived bounds lead to\nnew approaches for boosting training performance which we validate\nexperimentally. Notably, we find that the proposed framework suggests an\nalternative method for updating the Q-function, leading to boosted performance.\n","authors":["Jacob Adamczyk","Volodymyr Makarenko","Stas Tiomkin","Rahul V. Kulkarni"],"pdf_url":"https://arxiv.org/pdf/2406.18033v1.pdf","comment":"To appear in the 1st Reinforcement Learning Conference"},{"id":"http://arxiv.org/abs/2406.18027v1","updated":"2024-06-26T02:49:28Z","published":"2024-06-26T02:49:28Z","title":"Automated Clinical Data Extraction with Knowledge Conditioned LLMs","summary":"  The extraction of lung lesion information from clinical and medical imaging\nreports is crucial for research on and clinical care of lung-related diseases.\nLarge language models (LLMs) can be effective at interpreting unstructured text\nin reports, but they often hallucinate due to a lack of domain-specific\nknowledge, leading to reduced accuracy and posing challenges for use in\nclinical settings. To address this, we propose a novel framework that aligns\ngenerated internal knowledge with external knowledge through in-context\nlearning (ICL). Our framework employs a retriever to identify relevant units of\ninternal or external knowledge and a grader to evaluate the truthfulness and\nhelpfulness of the retrieved internal-knowledge rules, to align and update the\nknowledge bases. Our knowledge-conditioned approach also improves the accuracy\nand reliability of LLM outputs by addressing the extraction task in two stages:\n(i) lung lesion finding detection and primary structured field parsing,\nfollowed by (ii) further parsing of lesion description text into additional\nstructured fields. Experiments with expert-curated test datasets demonstrate\nthat this ICL approach can increase the F1 score for key fields (lesion size,\nmargin and solidity) by an average of 12.9% over existing ICL methods.\n","authors":["Diya Li","Asim Kadav","Aijing Gao","Rui Li","Richard Bourgon"],"pdf_url":"https://arxiv.org/pdf/2406.18027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12309v2","updated":"2024-06-26T02:44:18Z","published":"2024-03-18T23:18:27Z","title":"Reinforcement Learning from Delayed Observations via World Models","summary":"  In standard reinforcement learning settings, agents typically assume\nimmediate feedback about the effects of their actions after taking them.\nHowever, in practice, this assumption may not hold true due to physical\nconstraints and can significantly impact the performance of learning\nalgorithms. In this paper, we address observation delays in partially\nobservable environments. We propose leveraging world models, which have shown\nsuccess in integrating past observations and learning dynamics, to handle\nobservation delays. By reducing delayed POMDPs to delayed MDPs with world\nmodels, our methods can effectively handle partial observability, where\nexisting approaches achieve sub-optimal performance or degrade quickly as\nobservability decreases. Experiments suggest that one of our methods can\noutperform a naive model-based approach by up to 250%. Moreover, we evaluate\nour methods on visual delayed environments, for the first time showcasing\ndelay-aware reinforcement learning continuous control with visual observations.\n","authors":["Armin Karamzade","Kyungmin Kim","Montek Kalsi","Roy Fox"],"pdf_url":"https://arxiv.org/pdf/2403.12309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18022v1","updated":"2024-06-26T02:34:48Z","published":"2024-06-26T02:34:48Z","title":"AutoOPE: Automated Off-Policy Estimator Selection","summary":"  The Off-Policy Evaluation (OPE) problem consists of evaluating the\nperformance of counterfactual policies with data collected by another one. This\nproblem is of utmost importance for various application domains, e.g.,\nrecommendation systems, medical treatments, and many others. To solve the OPE\nproblem, we resort to estimators, which aim to estimate in the most accurate\nway possible the performance that the counterfactual policies would have had if\nthey were deployed in place of the logging policy. In the literature, several\nestimators have been developed, all with different characteristics and\ntheoretical guarantees. Therefore, there is no dominant estimator, and each\nestimator may be the best one for different OPE problems, depending on the\ncharacteristics of the dataset at hand. While the selection of the estimator is\na crucial choice for an accurate OPE, this problem has been widely overlooked\nin the literature. We propose an automated data-driven OPE estimator selection\nmethod based on machine learning. In particular, the core idea we propose in\nthis paper is to create several synthetic OPE tasks and use a machine learning\nmodel trained to predict the best estimator for those synthetic tasks. We\nempirically show how our method is able to generalize to unseen tasks and make\na better estimator selection compared to a baseline method on several\nreal-world datasets, with a computational cost significantly lower than the one\nof the baseline.\n","authors":["Nicolò Felicioni","Michael Benigni","Maurizio Ferrari Dacrema"],"pdf_url":"https://arxiv.org/pdf/2406.18022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18020v1","updated":"2024-06-26T02:26:50Z","published":"2024-06-26T02:26:50Z","title":"MolFusion: Multimodal Fusion Learning for Molecular Representations via\n  Multi-granularity Views","summary":"  Artificial Intelligence predicts drug properties by encoding drug molecules,\naiding in the rapid screening of candidates. Different molecular\nrepresentations, such as SMILES and molecule graphs, contain complementary\ninformation for molecular encoding. Thus exploiting complementary information\nfrom different molecular representations is one of the research priorities in\nmolecular encoding. Most existing methods for combining molecular\nmulti-modalities only use molecular-level information, making it hard to encode\nintra-molecular alignment information between different modalities. To address\nthis issue, we propose a multi-granularity fusion method that is MolFusion. The\nproposed MolFusion consists of two key components: (1) MolSim, a\nmolecular-level encoding component that achieves molecular-level alignment\nbetween different molecular representations. and (2) AtomAlign, an atomic-level\nencoding component that achieves atomic-level alignment between different\nmolecular representations. Experimental results show that MolFusion effectively\nutilizes complementary multimodal information, leading to significant\nimprovements in performance across various classification and regression tasks.\n","authors":["Muzhen Cai","Sendong Zhao","Haochun Wang","Yanrui Du","Zewen Qiang","Bing Qin","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2406.18020v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.04625v2","updated":"2024-06-26T02:22:11Z","published":"2024-06-07T04:19:01Z","title":"Key-Element-Informed sLLM Tuning for Document Summarization","summary":"  Remarkable advances in large language models (LLMs) have enabled high-quality\ntext summarization. However, this capability is currently accessible only\nthrough LLMs of substantial size or proprietary LLMs with usage fees. In\nresponse, smaller-scale LLMs (sLLMs) of easy accessibility and low costs have\nbeen extensively studied, yet they often suffer from missing key information\nand entities, i.e., low relevance, in particular, when input documents are\nlong. We hence propose a key-element-informed instruction tuning for\nsummarization, so-called KEITSum, which identifies key elements in documents\nand instructs sLLM to generate summaries capturing these key elements.\nExperimental results on dialogue and news datasets demonstrate that sLLM with\nKEITSum indeed provides high-quality summarization with higher relevance and\nless hallucinations, competitive to proprietary LLM.\n","authors":["Sangwon Ryu","Heejin Do","Yunsu Kim","Gary Geunbae Lee","Jungseul Ok"],"pdf_url":"https://arxiv.org/pdf/2406.04625v2.pdf","comment":"Interspeech 2024"},{"id":"http://arxiv.org/abs/2406.16746v2","updated":"2024-06-26T02:19:01Z","published":"2024-06-24T15:55:49Z","title":"The Responsible Foundation Model Development Cheatsheet: A Review of\n  Tools & Resources","summary":"  Foundation model development attracts a rapidly expanding body of\ncontributors, scientists, and applications. To help shape responsible\ndevelopment practices, we introduce the Foundation Model Development\nCheatsheet: a growing collection of 250+ tools and resources spanning text,\nvision, and speech modalities. We draw on a large body of prior work to survey\nresources (e.g. software, documentation, frameworks, guides, and practical\ntools) that support informed data selection, processing, and understanding,\nprecise and limitation-aware artifact documentation, efficient model training,\nadvance awareness of the environmental impact from training, careful model\nevaluation of capabilities, risks, and claims, as well as responsible model\nrelease, licensing and deployment practices. We hope this curated collection of\nresources helps guide more responsible development. The process of curating\nthis list, enabled us to review the AI development ecosystem, revealing what\ntools are critically missing, misused, or over-used in existing practices. We\nfind that (i) tools for data sourcing, model evaluation, and monitoring are\ncritically under-serving ethical and real-world needs, (ii) evaluations for\nmodel safety, capabilities, and environmental impact all lack reproducibility\nand transparency, (iii) text and particularly English-centric analyses continue\nto dominate over multilingual and multi-modal analyses, and (iv) evaluation of\nsystems, rather than just models, is needed so that capabilities and impact are\nassessed in context.\n","authors":["Shayne Longpre","Stella Biderman","Alon Albalak","Hailey Schoelkopf","Daniel McDuff","Sayash Kapoor","Kevin Klyman","Kyle Lo","Gabriel Ilharco","Nay San","Maribeth Rauh","Aviya Skowron","Bertie Vidgen","Laura Weidinger","Arvind Narayanan","Victor Sanh","David Adelani","Percy Liang","Rishi Bommasani","Peter Henderson","Sasha Luccioni","Yacine Jernite","Luca Soldaini"],"pdf_url":"https://arxiv.org/pdf/2406.16746v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16968v2","updated":"2024-06-26T01:54:51Z","published":"2024-06-22T09:28:02Z","title":"Multimodal Physiological Signals Representation Learning via Multiscale\n  Contrasting for Depression Recognition","summary":"  Depression recognition based on physiological signals such as functional\nnear-infrared spectroscopy (fNIRS) and electroencephalogram (EEG) has made\nconsiderable progress. However, most existing studies ignore the\ncomplementarity and semantic consistency of multimodal physiological signals\nunder the same stimulation task in complex spatio-temporal patterns. In this\npaper, we introduce a multimodal physiological signals representation learning\nframework using Siamese architecture via multiscale contrasting for depression\nrecognition (MRLMC). First, fNIRS and EEG are transformed into different but\ncorrelated data based on a time-domain data augmentation strategy. Then, we\ndesign a spatio-temporal contrasting module to learn the representation of\nfNIRS and EEG through weight-sharing multiscale spatio-temporal convolution.\nFurthermore, to enhance the learning of semantic representation associated with\nstimulation tasks, a semantic consistency contrast module is proposed, aiming\nto maximize the semantic similarity of fNIRS and EEG. Extensive experiments on\npublicly available and self-collected multimodal physiological signals datasets\nindicate that MRLMC outperforms the state-of-the-art models. Moreover, our\nproposed framework is capable of transferring to multimodal time series\ndownstream tasks.\n","authors":["Kai Shao","Rui Wang","Yixue Hao","Long Hu","Min Chen","Hans Arno Jacobsen"],"pdf_url":"https://arxiv.org/pdf/2406.16968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18012v1","updated":"2024-06-26T01:54:10Z","published":"2024-06-26T01:54:10Z","title":"View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with\n  Adaptive View Synthesis","summary":"  The inspection and monitoring of infrastructure assets typically requires\nidentifying visual anomalies in scenes periodically photographed over time.\nImages collected manually or with robots such as unmanned aerial vehicles from\nthe same scene at different instances in time are typically not perfectly\naligned. Supervised segmentation methods can be applied to identify known\nproblems, but unsupervised anomaly detection approaches are required when\nunknown anomalies occur. Current unsupervised pixel-level anomaly detection\nmethods have mainly been developed for industrial settings where the camera\nposition is known and constant. However, we find that these methods fail to\ngeneralize to the case when images are not perfectly aligned. We term the\nproblem of unsupervised anomaly detection between two such imperfectly aligned\nsets of images as Scene Anomaly Detection (Scene AD). We present a novel\nnetwork termed OmniAD to address the Scene AD problem posed. Specifically, we\nrefine the anomaly detection method reverse distillation to achieve a 40%\nincrease in pixel-level anomaly detection performance. The network's\nperformance is further demonstrated to improve with two new data augmentation\nstrategies proposed that leverage novel view synthesis and camera localization\nto improve generalization. We validate our approach with qualitative and\nquantitative results on a new dataset, ToyCity, the first Scene AD dataset with\nmultiple objects, as well as on the established single object-centric dataset,\nMAD. https://drags99.github.io/OmniAD/\n","authors":["Subin Varghese","Vedhus Hoskere"],"pdf_url":"https://arxiv.org/pdf/2406.18012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19733v3","updated":"2024-06-26T01:28:35Z","published":"2024-04-30T17:28:05Z","title":"Iterative Reasoning Preference Optimization","summary":"  Iterative preference optimization methods have recently been shown to perform\nwell for general instruction tuning tasks, but typically make little\nimprovement on reasoning tasks (Yuan et al., 2024, Chen et al., 2024). In this\nwork we develop an iterative approach that optimizes the preference between\ncompeting generated Chain-of-Thought (CoT) candidates by optimizing for winning\nvs. losing reasoning steps that lead to the correct answer. We train using a\nmodified DPO loss (Rafailov et al., 2023) with an additional negative\nlog-likelihood term, which we find to be crucial. We show reasoning improves\nacross repeated iterations of this scheme. While only relying on examples in\nthe training set, our approach results in increasing accuracy on GSM8K, MATH,\nand ARC-Challenge for Llama-2-70B-Chat, outperforming other Llama-2-based\nmodels not relying on additionally sourced datasets. For example, we see a\nlarge improvement from 55.6% to 81.6% on GSM8K and an accuracy of 88.7% with\nmajority voting out of 32 samples.\n","authors":["Richard Yuanzhe Pang","Weizhe Yuan","Kyunghyun Cho","He He","Sainbayar Sukhbaatar","Jason Weston"],"pdf_url":"https://arxiv.org/pdf/2404.19733v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17518v2","updated":"2024-06-26T01:25:44Z","published":"2024-06-25T12:59:20Z","title":"Enhancing Explainability of Knowledge Learning Paths: Causal Knowledge\n  Networks","summary":"  A reliable knowledge structure is a prerequisite for building effective\nadaptive learning systems and intelligent tutoring systems. Pursuing an\nexplainable and trustworthy knowledge structure, we propose a method for\nconstructing causal knowledge networks. This approach leverages Bayesian\nnetworks as a foundation and incorporates causal relationship analysis to\nderive a causal network. Additionally, we introduce a dependable\nknowledge-learning path recommendation technique built upon this framework,\nimproving teaching and learning quality while maintaining transparency in the\ndecision-making process.\n","authors":["Yuang Wei","Yizhou Zhou","Yuan-Hao Jiang","Bo Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.17518v2.pdf","comment":"8 pages, 3 figures, Educational Data Mining 2024, Human-Centric\n  eXplainable AI in Education"},{"id":"http://arxiv.org/abs/2406.18002v1","updated":"2024-06-26T01:16:12Z","published":"2024-06-26T01:16:12Z","title":"Decoding with Limited Teacher Supervision Requires Understanding When to\n  Trust the Teacher","summary":"  How can sLLMs efficiently utilize the supervision of LLMs to improve their\ngenerative quality? This question has been well studied in scenarios where\nthere is no restriction on the number of LLM supervisions one can use, giving\nbirth to many decoding algorithms that utilize supervision without further\ntraining. However, it is still unclear what is an effective strategy under the\nlimited supervision scenario, where we assume that no more than a few tokens\ncan be generated by LLMs. To this end, we develop an algorithm to effectively\naggregate the sLLM and LLM predictions on initial tokens so that the generated\ntokens can more accurately condition the subsequent token generation by sLLM\nonly. Critically, we find that it is essential to adaptively overtrust or\ndisregard the LLM prediction based on the confidence of the sLLM. Through our\nexperiments on a wide range of models and datasets, we demonstrate that our\nmethod provides a consistent improvement over conventional decoding strategies.\n","authors":["Hyunjong Ok","Jegwang Ryu","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2406.18002v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2406.17992v1","updated":"2024-06-26T00:21:39Z","published":"2024-06-26T00:21:39Z","title":"Catching Chameleons: Detecting Evolving Disinformation Generated using\n  Large Language Models","summary":"  Despite recent advancements in detecting disinformation generated by large\nlanguage models (LLMs), current efforts overlook the ever-evolving nature of\nthis disinformation. In this work, we investigate a challenging yet practical\nresearch problem of detecting evolving LLM-generated disinformation.\nDisinformation evolves constantly through the rapid development of LLMs and\ntheir variants. As a consequence, the detection model faces significant\nchallenges. First, it is inefficient to train separate models for each\ndisinformation generator. Second, the performance decreases in scenarios when\nevolving LLM-generated disinformation is encountered in sequential order. To\naddress this problem, we propose DELD (Detecting Evolving LLM-generated\nDisinformation), a parameter-efficient approach that jointly leverages the\ngeneral fact-checking capabilities of pre-trained language models (PLM) and the\nindependent disinformation generation characteristics of various LLMs. In\nparticular, the learned characteristics are concatenated sequentially to\nfacilitate knowledge accumulation and transformation. DELD addresses the issue\nof label scarcity by integrating the semantic embeddings of disinformation with\ntrainable soft prompts to elicit model-specific knowledge. Our experiments show\nthat \\textit{DELD} significantly outperforms state-of-the-art methods.\nMoreover, our method provides critical insights into the unique patterns of\ndisinformation generation across different LLMs, offering valuable perspectives\nin this line of research.\n","authors":["Bohan Jiang","Chengshuai Zhao","Zhen Tan","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17992v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17990v1","updated":"2024-06-26T00:12:08Z","published":"2024-06-26T00:12:08Z","title":"Explicit Diversity Conditions for Effective Question Answer Generation\n  with Large Language Models","summary":"  Question Answer Generation (QAG) is an effective data augmentation technique\nto improve the accuracy of question answering systems, especially in\nlow-resource domains. While recent pretrained and large language model-based\nQAG methods have made substantial progress, they face the critical issue of\nredundant QA pair generation, affecting downstream QA systems. Implicit\ndiversity techniques such as sampling and diverse beam search are proven\neffective solutions but often yield smaller diversity. We present explicit\ndiversity conditions for QAG, focusing on spatial aspects, question types, and\nentities, substantially increasing diversity in QA generation. Our work\nemphasizes the need of explicit diversity conditions for generating diverse\nquestion-answer synthetic data by showing significant improvements in\ndownstream QA task over existing widely adopted implicit diversity techniques.\nIn particular, generated QA pairs from explicit diversity conditions when used\nto train the downstream QA model results in an average 4.1% exact match and\n4.5% F1 improvement over QAG from implicit sampling techniques on SQuADDU. Our\nwork emphasizes the need for explicit diversity conditions even more in\nlow-resource datasets (SubjQA), where average downstream QA performance\nimprovements are around 12% EM.\n","authors":["Vikas Yadav","Hyuk Joon Kwon","Vijay Srinivasan","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2406.17990v1.pdf","comment":"Published at COLING 2024"},{"id":"http://arxiv.org/abs/2406.17987v1","updated":"2024-06-26T00:00:45Z","published":"2024-06-26T00:00:45Z","title":"Multi-step Knowledge Retrieval and Inference over Unstructured Data","summary":"  The advent of Large Language Models (LLMs) and Generative AI has\nrevolutionized natural language applications across various domains. However,\nhigh-stakes decision-making tasks in fields such as medical, legal and finance\nrequire a level of precision, comprehensiveness, and logical consistency that\npure LLM or Retrieval-Augmented-Generation (RAG) approaches often fail to\ndeliver. At Elemental Cognition (EC), we have developed a neuro-symbolic AI\nplatform to tackle these problems. The platform integrates fine-tuned LLMs for\nknowledge extraction and alignment with a robust symbolic reasoning engine for\nlogical inference, planning and interactive constraint solving. We describe\nCora, a Collaborative Research Assistant built on this platform, that is\ndesigned to perform complex research and discovery tasks in high-stakes\ndomains. This paper discusses the multi-step inference challenges inherent in\nsuch domains, critiques the limitations of existing LLM-based methods, and\ndemonstrates how Cora's neuro-symbolic approach effectively addresses these\nissues. We provide an overview of the system architecture, key algorithms for\nknowledge extraction and formal reasoning, and present preliminary evaluation\nresults that highlight Cora's superior performance compared to well-known LLM\nand RAG baselines.\n","authors":["Aditya Kalyanpur","Kailash Saravanakumar","Victor Barres","CJ McFate","Lori Moon","Nati Seifu","Maksim Eremeev","Jose Barrera","Eric Brown","David Ferrucci"],"pdf_url":"https://arxiv.org/pdf/2406.17987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04931v2","updated":"2024-06-26T23:44:48Z","published":"2024-03-07T22:37:49Z","title":"A Survey on Human-AI Teaming with Large Pre-Trained Models","summary":"  In the rapidly evolving landscape of artificial intelligence (AI), the\ncollaboration between human intelligence and AI systems, known as Human-AI\n(HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and\ndecision-making processes. The advent of Large Pre-trained Models (LPtM) has\nsignificantly transformed this landscape, offering unprecedented capabilities\nby leveraging vast amounts of data to understand and predict complex patterns.\nThis paper surveys the pivotal integration of LPtMs with HAI, emphasizing how\nthese models enhance collaborative intelligence beyond traditional approaches.\nIt examines the potential of LPtMs in augmenting human capabilities, discussing\nthis collaboration for AI model improvements, effective teaming, ethical\nconsiderations, and their broad applied implications in various sectors.\nThrough this exploration, the study sheds light on the transformative impact of\nLPtM-enhanced HAI Teaming, providing insights for future research, policy\ndevelopment, and strategic implementations aimed at harnessing the full\npotential of this collaboration for research and societal benefit.\n","authors":["Vanshika Vats","Marzia Binta Nizam","Minghao Liu","Ziyuan Wang","Richard Ho","Mohnish Sai Prasad","Vincent Titterton","Sai Venkat Malreddy","Riya Aggarwal","Yanwen Xu","Lei Ding","Jay Mehta","Nathan Grinnell","Li Liu","Sijia Zhong","Devanathan Nallur Gandamani","Xinyi Tang","Rohan Ghosalkar","Celeste Shen","Rachel Shen","Nafisa Hussain","Kesav Ravichandran","James Davis"],"pdf_url":"https://arxiv.org/pdf/2403.04931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18790v1","updated":"2024-06-26T23:21:42Z","published":"2024-06-26T23:21:42Z","title":"MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data","summary":"  We train a model to generate images from multimodal prompts of interleaved\ntext and images such as \"a <picture of a man> man and his <picture of a dog>\ndog in an <picture of a cartoon> animated style.\" We bootstrap a multimodal\ndataset by extracting semantically meaningful image crops corresponding to\nwords in the image captions of synthetically generated and publicly available\ntext-image data. Our model, MUMU, is composed of a vision-language model\nencoder with a diffusion decoder and is trained on a single 8xH100 GPU node.\nDespite being only trained on crops from the same image, MUMU learns to compose\ninputs from different images into a coherent output. For example, an input of a\nrealistic person and a cartoon will output the same person in the cartoon\nstyle, and an input of a standing subject and a scooter will output the subject\nriding the scooter. As a result, our model generalizes to tasks such as style\ntransfer and character consistency. Our results show the promise of using\nmultimodal models as general purpose controllers for image generation.\n","authors":["William Berman","Alexander Peysakhovich"],"pdf_url":"https://arxiv.org/pdf/2406.18790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14815v2","updated":"2024-06-26T22:23:23Z","published":"2024-06-21T01:32:03Z","title":"Latent diffusion models for parameterization and data assimilation of\n  facies-based geomodels","summary":"  Geological parameterization entails the representation of a geomodel using a\nsmall set of latent variables and a mapping from these variables to grid-block\nproperties such as porosity and permeability. Parameterization is useful for\ndata assimilation (history matching), as it maintains geological realism while\nreducing the number of variables to be determined. Diffusion models are a new\nclass of generative deep-learning procedures that have been shown to outperform\nprevious methods, such as generative adversarial networks, for image generation\ntasks. Diffusion models are trained to \"denoise\", which enables them to\ngenerate new geological realizations from input fields characterized by random\nnoise. Latent diffusion models, which are the specific variant considered in\nthis study, provide dimension reduction through use of a low-dimensional latent\nvariable. The model developed in this work includes a variational autoencoder\nfor dimension reduction and a U-net for the denoising process. Our application\ninvolves conditional 2D three-facies (channel-levee-mud) systems. The latent\ndiffusion model is shown to provide realizations that are visually consistent\nwith samples from geomodeling software. Quantitative metrics involving spatial\nand flow-response statistics are evaluated, and general agreement between the\ndiffusion-generated models and reference realizations is observed. Stability\ntests are performed to assess the smoothness of the parameterization method.\nThe latent diffusion model is then used for ensemble-based data assimilation.\nTwo synthetic \"true\" models are considered. Significant uncertainty reduction,\nposterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and\nconsistent posterior geomodels, are achieved in both cases.\n","authors":["Guido Di Federico","Louis J. Durlofsky"],"pdf_url":"https://arxiv.org/pdf/2406.14815v2.pdf","comment":"- Moved Table 1 from before to after Section 4.2 heading - Renamed\n  output pdf file with paper title"},{"id":"http://arxiv.org/abs/2312.10695v3","updated":"2024-06-26T22:06:49Z","published":"2023-12-17T12:09:42Z","title":"Nonparametric Strategy Test","summary":"  We present a nonparametric statistical test for determining whether an agent\nis following a given mixed strategy in a repeated strategic-form game given\nsamples of the agent's play. This involves two components: determining whether\nthe agent's frequencies of pure strategies are sufficiently close to the target\nfrequencies, and determining whether the pure strategies selected are\nindependent between different game iterations. Our integrated test involves\napplying a chi-squared goodness of fit test for the first component and a\ngeneralized Wald-Wolfowitz runs test for the second component. The results from\nboth tests are combined using Bonferroni correction to produce a complete test\nfor a given significance level $\\alpha.$ We applied the test to publicly\navailable data of human rock-paper-scissors play. The data consists of 50\niterations of play for 500 human players. We test with a null hypothesis that\nthe players are following a uniform random strategy independently at each game\niteration. Using a significance level of $\\alpha = 0.05$, we conclude that 305\n(61%) of the subjects are following the target strategy.\n","authors":["Sam Ganzfried"],"pdf_url":"https://arxiv.org/pdf/2312.10695v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18765v1","updated":"2024-06-26T21:30:41Z","published":"2024-06-26T21:30:41Z","title":"WV-Net: A foundation model for SAR WV-mode satellite imagery trained\n  using contrastive self-supervised learning on 10 million images","summary":"  The European Space Agency's Copernicus Sentinel-1 (S-1) mission is a\nconstellation of C-band synthetic aperture radar (SAR) satellites that provide\nunprecedented monitoring of the world's oceans. S-1's wave mode (WV) captures\n20x20 km image patches at 5 m pixel resolution and is unaffected by cloud cover\nor time-of-day. The mission's open data policy has made SAR data easily\naccessible for a range of applications, but the need for manual image\nannotations is a bottleneck that hinders the use of machine learning methods.\nThis study uses nearly 10 million WV-mode images and contrastive\nself-supervised learning to train a semantic embedding model called WV-Net. In\nmultiple downstream tasks, WV-Net outperforms a comparable model that was\npre-trained on natural images (ImageNet) with supervised learning. Experiments\nshow improvements for estimating wave height (0.50 vs 0.60 RMSE using linear\nprobing), estimating near-surface air temperature (0.90 vs 0.97 RMSE), and\nperforming multilabel-classification of geophysical and atmospheric phenomena\n(0.96 vs 0.95 micro-averaged AUROC). WV-Net embeddings are also superior in an\nunsupervised image-retrieval task and scale better in data-sparse settings.\nTogether, these results demonstrate that WV-Net embeddings can support\ngeophysical research by providing a convenient foundation model for a variety\nof data analysis and exploration tasks.\n","authors":["Yannik Glaser","Justin E. Stopa","Linnea M. Wolniewicz","Ralph Foster","Doug Vandemark","Alexis Mouche","Bertrand Chapron","Peter Sadowski"],"pdf_url":"https://arxiv.org/pdf/2406.18765v1.pdf","comment":"20 pages, 9 figures, submitted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.18763v1","updated":"2024-06-26T21:17:37Z","published":"2024-06-26T21:17:37Z","title":"Conformalized Link Prediction on Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) excel in diverse tasks, yet their applications\nin high-stakes domains are often hampered by unreliable predictions. Although\nnumerous uncertainty quantification methods have been proposed to address this\nlimitation, they often lack \\textit{rigorous} uncertainty estimates. This work\nmakes the first attempt to introduce a distribution-free and model-agnostic\nuncertainty quantification approach to construct a predictive interval with a\nstatistical guarantee for GNN-based link prediction. We term it as\n\\textit{conformalized link prediction.} Our approach builds upon conformal\nprediction (CP), a framework that promises to construct statistically robust\nprediction sets or intervals. We first theoretically and empirically establish\na permutation invariance condition for the application of CP in link prediction\ntasks, along with an exact test-time coverage. Leveraging the important\nstructural information in graphs, we then identify a novel and crucial\nconnection between a graph's adherence to the power law distribution and the\nefficiency of CP. This insight leads to the development of a simple yet\neffective sampling-based method to align the graph structure with a power law\ndistribution prior to the standard CP procedure. Extensive experiments\ndemonstrate that for conformalized link prediction, our approach achieves the\ndesired marginal coverage while significantly improving the efficiency of CP\ncompared to baseline methods.\n","authors":["Tianyi Zhao","Jian Kang","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2406.18763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04929v3","updated":"2024-06-26T20:57:15Z","published":"2024-02-07T14:56:13Z","title":"Source-Free Domain Adaptation with Diffusion-Guided Source Data\n  Generation","summary":"  This paper introduces a novel approach to leverage the generalizability of\nDiffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed\nDMSFDA method involves fine-tuning a pre-trained text-to-image diffusion model\nto generate source domain images using features from the target images to guide\nthe diffusion process. Specifically, the pre-trained diffusion model is\nfine-tuned to generate source samples that minimize entropy and maximize\nconfidence for the pre-trained source model. We then use a diffusion\nmodel-based image mixup strategy to bridge the domain gap between the source\nand target domains. We validate our approach through comprehensive experiments\nacross a range of datasets, including Office-31, Office-Home, and VisDA. The\nresults demonstrate significant improvements in SFDA performance, highlighting\nthe potential of diffusion models in generating contextually relevant,\ndomain-specific images.\n","authors":["Shivang Chopra","Suraj Kothawade","Houda Aynaou","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2402.04929v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2310.01701"},{"id":"http://arxiv.org/abs/2406.18757v1","updated":"2024-06-26T20:55:26Z","published":"2024-06-26T20:55:26Z","title":"The Impact of Feature Representation on the Accuracy of Photonic Neural\n  Networks","summary":"  Photonic Neural Networks (PNNs) are gaining significant interest in the\nresearch community due to their potential for high parallelization, low\nlatency, and energy efficiency. PNNs compute using light, which leads to\nseveral differences in implementation when compared to electronics, such as the\nneed to represent input features in the photonic domain before feeding them\ninto the network. In this encoding process, it is common to combine multiple\nfeatures into a single input to reduce the number of inputs and associated\ndevices, leading to smaller and more energy-efficient PNNs. Although this\nalters the network's handling of input data, its impact on PNNs remains\nunderstudied. This paper addresses this open question, investigating the effect\nof commonly used encoding strategies that combine features on the performance\nand learning capabilities of PNNs. Here, using the concept of feature\nimportance, we develop a mathematical framework for analyzing feature\ncombination. Through this framework, we demonstrate that encoding multiple\nfeatures together in a single input determines their relative importance, thus\nlimiting the network's ability to learn from the data. Given some prior\nknowledge of the data, however, this can also be leveraged for higher accuracy.\nBy selecting an optimal encoding method, we achieve up to a 12.3\\% improvement\nin accuracy of PNNs trained on the Iris dataset compared to other encoding\ntechniques, surpassing the performance of networks where features are not\ncombined. These findings highlight the importance of carefully choosing the\nencoding to the accuracy and decision-making strategies of PNNs, particularly\nin size or power constrained applications.\n","authors":["Mauricio Gomes de Queiroz","Paul Jimenez","Raphael Cardoso","Mateus Vidaletti da Costa","Mohab Abdalla","Ian O'Connor","Alberto Bosio","Fabio Pavanello"],"pdf_url":"https://arxiv.org/pdf/2406.18757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03828v2","updated":"2024-06-26T20:50:18Z","published":"2024-04-04T23:08:43Z","title":"Outlier-Efficient Hopfield Layers for Large Transformer-Based Models","summary":"  We introduce an Outlier-Efficient Modern Hopfield Model (termed\n$\\mathrm{OutEffHop}$) and use it to address the outlier inefficiency problem of\n{training} gigantic transformer-based models. Our main contribution is a novel\nassociative memory model facilitating \\textit{outlier-efficient} associative\nmemory retrievals. Interestingly, this memory model manifests a model-based\ninterpretation of an outlier-efficient attention mechanism (${\\rm Softmax}_1$):\nit is an approximation of the memory retrieval process of $\\mathrm{OutEffHop}$.\nMethodologically, this allows us to introduce novel outlier-efficient Hopfield\nlayers as powerful alternatives to traditional attention mechanisms, with\nsuperior post-quantization performance. Theoretically, the Outlier-Efficient\nModern Hopfield Model retains and improves the desirable properties of standard\nmodern Hopfield models, including fixed point convergence and exponential\nstorage capacity. Empirically, we demonstrate the efficacy of the proposed\nmodel across large-scale transformer-based and Hopfield-based models (including\nBERT, OPT, ViT, and STanHop-Net), benchmarking against state-of-the-art methods\nlike $\\mathtt{Clipped\\_Softmax}$ and $\\mathtt{Gated\\_Attention}$. Notably,\n$\\mathrm{OutEffHop}$ achieves an average reduction of 22+\\% in average kurtosis\nand 26+\\% in the maximum infinity norm of model outputs across four models.\nCode is available at \\href{https://github.com/MAGICS-LAB/OutEffHop}{GitHub};\nmodels are on\n\\href{https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f}{Hugging\nFace Hub}; future updates are on\n\\href{https://arxiv.org/abs/2404.03828}{arXiv}.\n","authors":["Jerry Yao-Chieh Hu","Pei-Hsuan Chang","Robin Luo","Hong-Yu Chen","Weijian Li","Wei-Po Wang","Han Liu"],"pdf_url":"https://arxiv.org/pdf/2404.03828v2.pdf","comment":"Accepted at ICML 2024; v2 updated to camera-ready version; Code\n  available at https://github.com/MAGICS-LAB/OutEffHop; Models are on Hugging\n  Face:\n  https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f"},{"id":"http://arxiv.org/abs/2403.05750v3","updated":"2024-06-26T20:49:32Z","published":"2024-03-09T01:13:54Z","title":"Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated\n  Text","summary":"  Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Generation (NLG) by demonstrating an impressive ability to generate\nhuman-like text. However, their widespread usage introduces challenges that\nnecessitate thoughtful examination, ethical scrutiny, and responsible\npractices. In this study, we delve into these challenges, explore existing\nstrategies for mitigating them, with a particular emphasis on identifying\nAI-generated text as the ultimate solution. Additionally, we assess the\nfeasibility of detection from a theoretical perspective and propose novel\nresearch directions to address the current limitations in this domain.\n","authors":["Sara Abdali","Richard Anarfi","CJ Barberan","Jia He"],"pdf_url":"https://arxiv.org/pdf/2403.05750v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18747v1","updated":"2024-06-26T20:25:53Z","published":"2024-06-26T20:25:53Z","title":"A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond\n  Four Stems","summary":"  Despite significant recent progress across multiple subtasks of audio source\nseparation, few music source separation systems support separation beyond the\nfour-stem vocals, drums, bass, and other (VDBO) setup. Of the very few current\nsystems that support source separation beyond this setup, most continue to rely\non an inflexible decoder setup that can only support a fixed pre-defined set of\nstems. Increasing stem support in these inflexible systems correspondingly\nrequires increasing computational complexity, rendering extensions of these\nsystems computationally infeasible for long-tail instruments. In this work, we\npropose Banquet, a system that allows source separation of multiple stems using\njust one decoder. A bandsplit source separation model is extended to work in a\nquery-based setup in tandem with a music instrument recognition PaSST model. On\nthe MoisesDB dataset, Banquet, at only 24.9 M trainable parameters, approached\nthe performance level of the significantly more complex 6-stem Hybrid\nTransformer Demucs on VDBO stems and outperformed it on guitar and piano. The\nquery-based setup allows for the separation of narrow instrument classes such\nas clean acoustic guitars, and can be successfully applied to the extraction of\nless common stems such as reeds and organs. Implementation is available at\nhttps://github.com/kwatcharasupat/query-bandit.\n","authors":["Karn N. Watcharasupat","Alexander Lerch"],"pdf_url":"https://arxiv.org/pdf/2406.18747v1.pdf","comment":"Submitted to the 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024)"},{"id":"http://arxiv.org/abs/2308.14936v3","updated":"2024-06-26T20:25:03Z","published":"2023-08-28T23:23:53Z","title":"AutoProSAM: Automated Prompting SAM for 3D Multi-Organ Segmentation","summary":"  Segment Anything Model (SAM) is one of the pioneering prompt-based foundation\nmodels for image segmentation and has been rapidly adopted for various medical\nimaging applications. However, in clinical settings, creating effective prompts\nis notably challenging and time-consuming, requiring the expertise of domain\nspecialists such as physicians. This requirement significantly diminishes SAM's\nprimary advantage - its interactive capability with end users - in medical\napplications. Moreover, recent studies have indicated that SAM, originally\ndesigned for 2D natural images, performs sub optimally on 3D medical image\nsegmentation tasks. This subpar performance is attributed to the domain gaps\nbetween natural and medical images and the disparities in spatial arrangements\nbetween 2D and 3D images, particularly in multi-organ segmentation\napplications. To overcome these challenges, we present a novel technique termed\nAutoProSAM. This method automates 3D multi-organ CT-based segmentation by\nleveraging SAM's foundational model capabilities without relying on domain\nexperts for prompts. The approach utilizes parameter-efficient adaptation\ntechniques to adapt SAM for 3D medical imagery and incorporates an effective\nautomatic prompt learning paradigm specific to this domain. By eliminating the\nneed for manual prompts, it enhances SAM's capabilities for 3D medical image\nsegmentation and achieves state-of-the-art (SOTA) performance in CT-based\nmulti-organ segmentation tasks.\n","authors":["Chengyin Li","Prashant Khanduri","Yao Qiang","Rafi Ibn Sultan","Indrin Chetty","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2308.14936v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10701v3","updated":"2024-06-26T20:15:34Z","published":"2023-10-16T07:51:19Z","title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models","summary":"  While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.\n","authors":["Huao Li","Yu Quan Chong","Simon Stepputtis","Joseph Campbell","Dana Hughes","Michael Lewis","Katia Sycara"],"pdf_url":"https://arxiv.org/pdf/2310.10701v3.pdf","comment":"Accepted to EMNLP 2023 (Main Conference). Code available at\n  https://github.com/romanlee6/multi_LLM_comm"},{"id":"http://arxiv.org/abs/2406.18741v1","updated":"2024-06-26T20:12:48Z","published":"2024-06-26T20:12:48Z","title":"Decentralized Semantic Traffic Control in AVs Using RL and DQN for\n  Dynamic Roadblocks","summary":"  Autonomous Vehicles (AVs), furnished with sensors capable of capturing\nessential vehicle dynamics such as speed, acceleration, and precise location,\npossess the capacity to execute intelligent maneuvers, including lane changes,\nin anticipation of approaching roadblocks. Nevertheless, the sheer volume of\nsensory data and the processing necessary to derive informed decisions can\noften overwhelm the vehicles, rendering them unable to handle the task\nindependently. Consequently, a common approach in traffic scenarios involves\ntransmitting the data to servers for processing, a practice that introduces\nchallenges, particularly in situations demanding real-time processing. In\nresponse to this challenge, we present a novel DL-based semantic traffic\ncontrol system that entrusts semantic encoding responsibilities to the vehicles\nthemselves. This system processes driving decisions obtained from a\nReinforcement Learning (RL) agent, streamlining the decision-making process.\nSpecifically, our framework envisions scenarios where abrupt roadblocks\nmaterialize due to factors such as road maintenance, accidents, or vehicle\nrepairs, necessitating vehicles to make determinations concerning lane-keeping\nor lane-changing actions to navigate past these obstacles. To formulate this\nscenario mathematically, we employ a Markov Decision Process (MDP) and harness\nthe Deep Q Learning (DQN) algorithm to unearth viable solutions.\n","authors":["Emanuel Figetakis","Yahuza Bello","Ahmed Refaey","Abdallah Shami"],"pdf_url":"https://arxiv.org/pdf/2406.18741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18731v1","updated":"2024-06-26T19:59:21Z","published":"2024-06-26T19:59:21Z","title":"WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech\n  Health Diagnostic Model","summary":"  Speech is known to carry health-related attributes, which has emerged as a\nnovel venue for remote and long-term health monitoring. However, existing\nmodels are usually tailored for a specific type of disease, and have been shown\nto lack generalizability across datasets. Furthermore, concerns have been\nraised recently towards the leakage of speaker identity from health embeddings.\nTo mitigate these limitations, we propose WavRx, a speech health diagnostics\nmodel that captures the respiration and articulation related dynamics from a\nuniversal speech representation. Our in-domain and cross-domain experiments on\nsix pathological speech datasets demonstrate WavRx as a new state-of-the-art\nhealth diagnostic model. Furthermore, we show that the amount of speaker\nidentity entailed in the WavRx health embeddings is significantly reduced\nwithout extra guidance during training. An in-depth analysis of the model was\nperformed, thus providing physiological interpretation of its improved\ngeneralizability and privacy-preserving ability.\n","authors":["Yi Zhu","Tiago Falk"],"pdf_url":"https://arxiv.org/pdf/2406.18731v1.pdf","comment":"Under review; Model script available at\n  https://github.com/zhu00121/WavRx"},{"id":"http://arxiv.org/abs/2211.11695v4","updated":"2024-06-26T19:29:39Z","published":"2022-11-21T18:14:38Z","title":"Disentangled Representation Learning","summary":"  Disentangled Representation Learning (DRL) aims to learn a model capable of\nidentifying and disentangling the underlying factors hidden in the observable\ndata in representation form. The process of separating underlying factors of\nvariation into variables with semantic meaning benefits in learning explainable\nrepresentations of data, which imitates the meaningful understanding process of\nhumans when observing an object or relation. As a general learning strategy,\nDRL has demonstrated its power in improving the model explainability,\ncontrolability, robustness, as well as generalization capacity in a wide range\nof scenarios such as computer vision, natural language processing, and data\nmining. In this article, we comprehensively investigate DRL from various\naspects including motivations, definitions, methodologies, evaluations,\napplications, and model designs. We first present two well-recognized\ndefinitions, i.e., Intuitive Definition and Group Theory Definition for\ndisentangled representation learning. We further categorize the methodologies\nfor DRL into four groups from the following perspectives, the model type,\nrepresentation structure, supervision signal, and independence assumption. We\nalso analyze principles to design different DRL models that may benefit\ndifferent tasks in practical applications. Finally, we point out challenges in\nDRL as well as potential research directions deserving future investigations.\nWe believe this work may provide insights for promoting the DRL research in the\ncommunity.\n","authors":["Xin Wang","Hong Chen","Si'ao Tang","Zihao Wu","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.11695v4.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence"},{"id":"http://arxiv.org/abs/2406.18701v1","updated":"2024-06-26T19:10:34Z","published":"2024-06-26T19:10:34Z","title":"Fast Optimizer Benchmark","summary":"  In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed\nfor evaluating deep learning optimizers during their development. The benchmark\nsupports tasks from multiple domains such as computer vision, natural language\nprocessing, and graph learning. The focus is on convenient usage, featuring\nhuman-readable YAML configurations, SLURM integration, and plotting utilities.\nFOB can be used together with existing hyperparameter optimization (HPO) tools\nas it handles training and resuming of runs. The modular design enables\nintegration into custom pipelines, using it simply as a collection of tasks. We\nshowcase an optimizer comparison as a usage example of our tool. FOB can be\nfound on GitHub: https://github.com/automl/FOB.\n","authors":["Simon Blauth","Tobias Bürger","Zacharias Häringer","Jörg Franke","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2406.18701v1.pdf","comment":"5 pages + 12 appendix pages, submitted to AutoML Conf 2024 Workshop\n  Track"},{"id":"http://arxiv.org/abs/2406.18695v1","updated":"2024-06-26T18:57:32Z","published":"2024-06-26T18:57:32Z","title":"Learning to Correct for QA Reasoning with Black-box LLMs","summary":"  An open challenge in recent machine learning is about how to improve the\nreasoning capability of large language models (LLMs) in a black-box setting,\ni.e., without access to detailed information such as output token\nprobabilities. Existing approaches either rely on accessibility (which is often\nunrealistic) or involve significantly increased train- and inference-time\ncosts. This paper addresses those limitations or shortcomings by proposing a\nnovel approach, namely CoBB (Correct for improving QA reasoning of Black-Box\nLLMs). It uses a trained adaptation model to perform a seq2seq mapping from the\noften-imperfect reasonings of the original black-box LLM to the correct or\nimproved reasonings. Specifically, the adaptation model is initialized with a\nrelatively small open-source LLM and adapted over a collection of sub-sampled\ntraining pairs. To select the representative pairs of correct and incorrect\nreasonings, we formulated the dataset construction as an optimization problem\nthat minimizes the statistical divergence between the sampled subset and the\nentire collection, and solved it via a genetic algorithm. We then train the\nadaptation model over the sampled pairs by contrasting the likelihoods of\ncorrect and incorrect reasonings. Our experimental results demonstrate that\nCoBB significantly improves reasoning accuracy across various QA benchmarks,\ncompared to the best-performing adaptation baselines.\n","authors":["Jaehyung Kim","Dongyoung Kim","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2406.18695v1.pdf","comment":"preprint, 18 pages"},{"id":"http://arxiv.org/abs/2406.18690v1","updated":"2024-06-26T18:48:50Z","published":"2024-06-26T18:48:50Z","title":"Petal-X: Human-Centered Visual Explanations to Improve Cardiovascular\n  Risk Communication","summary":"  Cardiovascular diseases (CVDs), the leading cause of death worldwide, can be\nprevented in most cases through behavioral interventions. Therefore, effective\ncommunication of CVD risk and projected risk reduction by risk factor\nmodification plays a crucial role in reducing CVD risk at the individual level.\nHowever, despite interest in refining risk estimation with improved prediction\nmodels such as SCORE2, the guidelines for presenting these risk estimations in\nclinical practice remained essentially unchanged in the last few years, with\ngraphical score charts (GSCs) continuing to be one of the prevalent systems.\nThis work describes the design and implementation of Petal-X, a novel tool to\nsupport clinician-patient shared decision-making by explaining the CVD risk\ncontributions of different factors and facilitating what-if analysis. Petal-X\nrelies on a novel visualization, Petal Product Plots, and a tailor-made global\nsurrogate model of SCORE2, whose fidelity is comparable to that of the GSCs\nused in clinical practice. We evaluated Petal-X compared to GSCs in a\ncontrolled experiment with 88 healthcare students, all but one with experience\nwith chronic patients. The results show that Petal-X outperforms GSC in\ncritical tasks, such as comparing the contribution to the patient's 10-year CVD\nrisk of each modifiable risk factor, without a significant loss of perceived\ntransparency, trust, or intent to use. Our study provides an innovative\napproach to the visualization and explanation of risk in clinical practice\nthat, due to its model-agnostic nature, could continue to support\nnext-generation artificial intelligence risk assessment models.\n","authors":["Diego Rojo","Houda Lamqaddam","Lucija Gosak","Katrien Verbert"],"pdf_url":"https://arxiv.org/pdf/2406.18690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18682v1","updated":"2024-06-26T18:39:08Z","published":"2024-06-26T18:39:08Z","title":"The Multilingual Alignment Prism: Aligning Global and Local Preferences\n  to Reduce Harm","summary":"  A key concern with the concept of \"alignment\" is the implicit question of\n\"alignment to what?\". AI systems are increasingly used across the world, yet\nsafety alignment is often focused on homogeneous monolingual settings.\nAdditionally, preference training and safety measures often overfit to harms\ncommon in Western-centric datasets. Here, we explore the viability of different\nalignment approaches when balancing dual objectives: addressing and optimizing\nfor a non-homogeneous set of languages and cultural preferences while\nminimizing both global and local harms. We collect the first set of human\nannotated red-teaming prompts in different languages distinguishing between\nglobal and local harm, which serve as a laboratory for understanding the\nreliability of alignment techniques when faced with preference distributions\nthat are non-stationary across geographies and languages. While this setting is\nseldom covered by the literature to date, which primarily centers on English\nharm mitigation, it captures real-world interactions with AI systems around the\nworld. We establish a new precedent for state-of-the-art alignment techniques\nacross 6 languages with minimal degradation in general performance. Our work\nprovides important insights into cross-lingual transfer and novel optimization\napproaches to safeguard AI systems designed to serve global populations.\n","authors":[" Aakanksha","Arash Ahmadian","Beyza Ermis","Seraphina Goldfarb-Tarrant","Julia Kreutzer","Marzieh Fadaee","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2406.18682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18679v1","updated":"2024-06-26T18:32:16Z","published":"2024-06-26T18:32:16Z","title":"Speakers Unembedded: Embedding-free Approach to Long-form Neural\n  Diarization","summary":"  End-to-end neural diarization (EEND) models offer significant improvements\nover traditional embedding-based Speaker Diarization (SD) approaches but falls\nshort on generalizing to long-form audio with large number of speakers.\nEEND-vector-clustering method mitigates this by combining local EEND with\nglobal clustering of speaker embeddings from local windows, but this requires\nan additional speaker embedding framework alongside the EEND module. In this\npaper, we propose a novel framework applying EEND both locally and globally for\nlong-form audio without separate speaker embeddings. This approach achieves\nsignificant relative DER reduction of 13% and 10% over the conventional 1-pass\nEEND on Callhome American English and RT03-CTS datasets respectively and\nmarginal improvements over EEND-vector-clustering without the need for\nadditional speaker embeddings. Furthermore, we discuss the computational\ncomplexity of our proposed framework and explore strategies for reducing\nprocessing times.\n","authors":["Xiang Li","Vivek Govindan","Rohit Paturi","Sundararajan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.18679v1.pdf","comment":"Accepted at INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.18678v1","updated":"2024-06-26T18:29:12Z","published":"2024-06-26T18:29:12Z","title":"Few-shot Personalization of LLMs with Mis-aligned Responses","summary":"  As the diversity of users increases, the capability of providing personalized\nresponses by large language models (LLMs) has become increasingly important.\nExisting approaches have only limited successes in LLM personalization, due to\nthe absence of personalized learning or the reliance on shared personal data.\nThis paper proposes a new approach for a few-shot personalization of LLMs with\ntheir mis-aligned responses (Fermi). Our key idea is to learn a set of\npersonalized prompts for each user by progressively improving the prompts using\nLLMs, based on user profile (e.g., demographic information) and a few examples\nof previous opinions. During an iterative process of prompt improvement, we\nincorporate the contexts of mis-aligned responses by LLMs, which are especially\ncrucial for the effective personalization of LLMs. In addition, we develop an\neffective inference method to further leverage the context of the test query\nand the personalized prompts. Our experimental results demonstrate that Fermi\nsignificantly improves performance across various benchmarks, compared to the\nbest-performing baselines.\n","authors":["Jaehyung Kim","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2406.18678v1.pdf","comment":"preprint, 30 pages"},{"id":"http://arxiv.org/abs/2406.18676v1","updated":"2024-06-26T18:26:53Z","published":"2024-06-26T18:26:53Z","title":"Understand What LLM Needs: Dual Preference Alignment for\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has demonstrated effectiveness in\nmitigating the hallucination problem of large language models (LLMs). However,\nthe difficulty of aligning the retriever with the diverse LLMs' knowledge\npreferences inevitably poses an inevitable challenge in developing a reliable\nRAG system. To address this issue, we propose DPA-RAG, a universal framework\ndesigned to align diverse knowledge preferences within RAG systems.\nSpecifically, we initially introduce a preference knowledge construction\npipline and incorporate five novel query augmentation strategies to alleviate\npreference data scarcity. Based on preference data, DPA-RAG accomplishes both\nexternal and internal preference alignment: 1) It jointly integrate pair-wise,\npoint-wise, and contrastive preference alignment abilities into the reranker,\nachieving external preference alignment among RAG components. 2) It further\nintroduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT),\nenabling LLMs to implicitly capture knowledge aligned with their reasoning\npreferences, achieving LLMs' internal alignment. Experimental results across\nfour knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all\nbaselines and seamlessly integrates both black-box and open-sourced LLM\nreaders. Further qualitative analysis and discussions also provide empirical\nguidance for achieving reliable RAG systems. Our code is publicly available at\nhttps://github.com/dongguanting/DPA-RAG.\n","authors":["Guanting Dong","Yutao Zhu","Chenghao Zhang","Zechen Wang","Zhicheng Dou","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2406.18676v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.18675v1","updated":"2024-06-26T18:25:06Z","published":"2024-06-26T18:25:06Z","title":"Human-AI Collaborative Taxonomy Construction: A Case Study in\n  Profession-Specific Writing Assistants","summary":"  Large Language Models (LLMs) have assisted humans in several writing tasks,\nincluding text revision and story generation. However, their effectiveness in\nsupporting domain-specific writing, particularly in business contexts, is\nrelatively less explored. Our formative study with industry professionals\nrevealed the limitations in current LLMs' understanding of the nuances in such\ndomain-specific writing. To address this gap, we propose an approach of\nhuman-AI collaborative taxonomy development to perform as a guideline for\ndomain-specific writing assistants. This method integrates iterative feedback\nfrom domain experts and multiple interactions between these experts and LLMs to\nrefine the taxonomy. Through larger-scale experiments, we aim to validate this\nmethodology and thus improve LLM-powered writing assistance, tailoring it to\nmeet the unique requirements of different stakeholder needs.\n","authors":["Minhwa Lee","Zae Myung Kim","Vivek A. Khetan","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2406.18675v1.pdf","comment":"Accepted to CHI 2024 In2Writing Workshop"},{"id":"http://arxiv.org/abs/2406.18665v1","updated":"2024-06-26T18:10:22Z","published":"2024-06-26T18:10:22Z","title":"RouteLLM: Learning to Route LLMs with Preference Data","summary":"  Large language models (LLMs) exhibit impressive capabilities across a wide\nrange of tasks, yet the choice of which model to use often involves a trade-off\nbetween performance and cost. More powerful models, though effective, come with\nhigher expenses, while less capable models are more cost-effective. To address\nthis dilemma, we propose several efficient router models that dynamically\nselect between a stronger and a weaker LLM during inference, aiming to optimize\nthe balance between cost and response quality. We develop a training framework\nfor these routers leveraging human preference data and data augmentation\ntechniques to enhance performance. Our evaluation on widely-recognized\nbenchmarks shows that our approach significantly reduces costs-by over 2 times\nin certain cases-without compromising the quality of responses. Interestingly,\nour router models also demonstrate significant transfer learning capabilities,\nmaintaining their performance even when the strong and weak models are changed\nat test time. This highlights the potential of these routers to provide a\ncost-effective yet high-performance solution for deploying LLMs.\n","authors":["Isaac Ong","Amjad Almahairi","Vincent Wu","Wei-Lin Chiang","Tianhao Wu","Joseph E. Gonzalez","M Waleed Kadous","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2406.18665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18630v1","updated":"2024-06-26T17:59:54Z","published":"2024-06-26T17:59:54Z","title":"Improving Hyperparameter Optimization with Checkpointed Model Weights","summary":"  When training deep learning models, the performance depends largely on the\nselected hyperparameters. However, hyperparameter optimization (HPO) is often\none of the most expensive parts of model design. Classical HPO methods treat\nthis as a black-box optimization problem. However, gray-box HPO methods, which\nincorporate more information about the setup, have emerged as a promising\ndirection for more efficient optimization. For example, using intermediate loss\nevaluations to terminate bad selections. In this work, we propose an HPO method\nfor neural networks using logged checkpoints of the trained weights to guide\nfuture hyperparameter selections. Our method, Forecasting Model Search (FMS),\nembeds weights into a Gaussian process deep kernel surrogate model, using a\npermutation-invariant graph metanetwork to be data-efficient with the logged\nnetwork weights. To facilitate reproducibility and further research, we\nopen-source our code at https://github.com/NVlabs/forecasting-model-search.\n","authors":["Nikhil Mehta","Jonathan Lorraine","Steve Masson","Ramanathan Arunachalam","Zaid Pervaiz Bhat","James Lucas","Arun George Zachariah"],"pdf_url":"https://arxiv.org/pdf/2406.18630v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/FMS/"},{"id":"http://arxiv.org/abs/2406.17651v2","updated":"2024-06-26T17:43:15Z","published":"2024-06-25T15:43:20Z","title":"Leveraging Large Language Models for Software Model Completion: Results\n  from Industrial and Public Datasets","summary":"  Modeling structure and behavior of software systems plays a crucial role in\nthe industrial practice of software engineering. As with other software\nengineering artifacts, software models are subject to evolution. Supporting\nmodelers in evolving software models with recommendations for model completions\nis still an open problem, though. In this paper, we explore the potential of\nlarge language models for this task. In particular, we propose an approach,\nretrieval-augmented generation, leveraging large language models, model\nhistories, and retrieval-augmented generation for model completion. Through\nexperiments on three datasets, including an industrial application, one public\nopen-source community dataset, and one controlled collection of simulated model\nrepositories, we evaluate the potential of large language models for model\ncompletion with retrieval-augmented generation. We found that large language\nmodels are indeed a promising technology for supporting software model\nevolution (62.30% semantically correct completions on real-world industrial\ndata and up to 86.19% type-correct completions). The general inference\ncapabilities of large language models are particularly useful when dealing with\nconcepts for which there are few, noisy, or no examples at all.\n","authors":["Christof Tinnes","Alisa Welter","Sven Apel"],"pdf_url":"https://arxiv.org/pdf/2406.17651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18629v1","updated":"2024-06-26T17:43:06Z","published":"2024-06-26T17:43:06Z","title":"Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of\n  LLMs","summary":"  Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs) due to the extensive and precise chain of reasoning required for\naccuracy. Ensuring the correctness of each reasoning step is critical. To\naddress this, we aim to enhance the robustness and factuality of LLMs by\nlearning from human feedback. However, Direct Preference Optimization (DPO) has\nshown limited benefits for long-chain mathematical reasoning, as models\nemploying DPO struggle to identify detailed errors in incorrect answers. This\nlimitation stems from a lack of fine-grained process supervision. We propose a\nsimple, effective, and data-efficient method called Step-DPO, which treats\nindividual reasoning steps as units for preference optimization rather than\nevaluating answers holistically. Additionally, we have developed a data\nconstruction pipeline for Step-DPO, enabling the creation of a high-quality\ndataset containing 10K step-wise preference pairs. We also observe that in DPO,\nself-generated data is more effective than data generated by humans or GPT-4,\ndue to the latter's out-of-distribution nature. Our findings demonstrate that\nas few as 10K preference data pairs and fewer than 500 Step-DPO training steps\ncan yield a nearly 3% gain in accuracy on MATH for models with over 70B\nparameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves\nscores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively,\nsurpassing a series of closed-source models, including GPT-4-1106,\nClaude-3-Opus, and Gemini-1.5-Pro. Our code, data, and models are available at\nhttps://github.com/dvlab-research/Step-DPO.\n","authors":["Xin Lai","Zhuotao Tian","Yukang Chen","Senqiao Yang","Xiangru Peng","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2406.18629v1.pdf","comment":"Code, data, and models are available at\n  https://github.com/dvlab-research/Step-DPO"},{"id":"http://arxiv.org/abs/2001.11165v9","updated":"2024-06-26T22:27:36Z","published":"2020-01-30T03:47:09Z","title":"Empirical Analysis of Fictitious Play for Nash Equilibrium Computation\n  in Multiplayer Games","summary":"  While fictitious play is guaranteed to converge to Nash equilibrium in\ncertain game classes, such as two-player zero-sum games, it is not guaranteed\nto converge in non-zero-sum and multiplayer games. We show that fictitious play\nin fact leads to improved Nash equilibrium approximation over a variety of game\nclasses and sizes than (counterfactual) regret minimization, which has recently\nproduced superhuman play for multiplayer poker. We also show that when\nfictitious play is run several times using random initializations it is able to\nsolve several known challenge problems in which the standard version is known\nto not converge, including Shapley's classic counterexample. These provide some\nof the first positive results for fictitious play in these settings, despite\nthe fact that worst-case theoretical results are negative.\n","authors":["Sam Ganzfried"],"pdf_url":"https://arxiv.org/pdf/2001.11165v9.pdf","comment":"Subsumes 2020 article \"Fictitious Play Outperforms Counterfactual\n  Regret Minimization\" and 2022 article \"Random Initialization Solves Shapley's\n  Fictitious Play Counterexample.\""}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.07544v2","updated":"2024-06-26T17:59:50Z","published":"2024-06-11T17:59:45Z","title":"Situational Awareness Matters in 3D Vision Language Reasoning","summary":"  Being able to carry out complicated vision language reasoning tasks in 3D\nspace represents a significant milestone in developing household robots and\nhuman-centered embodied AI. In this work, we demonstrate that a critical and\ndistinct challenge in 3D vision language reasoning is situational awareness,\nwhich incorporates two key components: (1) The autonomous agent grounds its\nself-location based on a language prompt. (2) The agent answers open-ended\nquestions from the perspective of its calculated position. To address this\nchallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D\nvision language reasoning. We tokenize the 3D scene into sparse voxel\nrepresentation and propose a language-grounded situation estimator, followed by\na situated question answering module. Experiments on the SQA3D and ScanQA\ndatasets show that SIG3D outperforms state-of-the-art models in situation\nestimation and question answering by a large margin (e.g., an enhancement of\nover 30% on situation estimation accuracy). Subsequent analysis corroborates\nour architectural design choices, explores the distinct functions of visual and\ntextual tokens, and highlights the importance of situational awareness in the\ndomain of 3D question answering.\n","authors":["Yunze Man","Liang-Yan Gui","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2406.07544v2.pdf","comment":"CVPR 2024. Project Page: https://yunzeman.github.io/situation3d"},{"id":"http://arxiv.org/abs/2406.18533v1","updated":"2024-06-26T17:59:28Z","published":"2024-06-26T17:59:28Z","title":"On Scaling Up 3D Gaussian Splatting Training","summary":"  3D Gaussian Splatting (3DGS) is increasingly popular for 3D reconstruction\ndue to its superior visual quality and rendering speed. However, 3DGS training\ncurrently occurs on a single GPU, limiting its ability to handle\nhigh-resolution and large-scale 3D reconstruction tasks due to memory\nconstraints. We introduce Grendel, a distributed system designed to partition\n3DGS parameters and parallelize computation across multiple GPUs. As each\nGaussian affects a small, dynamic subset of rendered pixels, Grendel employs\nsparse all-to-all communication to transfer the necessary Gaussians to pixel\npartitions and performs dynamic load balancing. Unlike existing 3DGS systems\nthat train using one camera view image at a time, Grendel supports batched\ntraining with multiple views. We explore various optimization hyperparameter\nscaling strategies and find that a simple sqrt(batch size) scaling rule is\nhighly effective. Evaluations using large-scale, high-resolution scenes show\nthat Grendel enhances rendering quality by scaling up 3DGS parameters across\nmultiple GPUs. On the Rubble dataset, we achieve a test PSNR of 27.28 by\ndistributing 40.4 million Gaussians across 16 GPUs, compared to a PSNR of 26.28\nusing 11.2 million Gaussians on a single GPU. Grendel is an open-source project\navailable at: https://github.com/nyu-systems/Grendel-GS\n","authors":["Hexu Zhao","Haoyang Weng","Daohan Lu","Ang Li","Jinyang Li","Aurojit Panda","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2406.18533v1.pdf","comment":"Code: https://github.com/nyu-systems/Grendel-GS ; Project page:\n  https://daohanlu.github.io/scaling-up-3dgs"},{"id":"http://arxiv.org/abs/2406.14539v2","updated":"2024-06-26T17:59:24Z","published":"2024-06-20T17:49:11Z","title":"Invertible Consistency Distillation for Text-Guided Image Editing in\n  Around 7 Steps","summary":"  Diffusion distillation represents a highly promising direction for achieving\nfaithful text-to-image generation in a few sampling steps. However, despite\nrecent successes, existing distilled models still do not provide the full\nspectrum of diffusion abilities, such as real image inversion, which enables\nmany precise image manipulation methods. This work aims to enrich distilled\ntext-to-image diffusion models with the ability to effectively encode real\nimages into their latent space. To this end, we introduce invertible\nConsistency Distillation (iCD), a generalized consistency distillation\nframework that facilitates both high-quality image synthesis and accurate image\nencoding in only 3-4 inference steps. Though the inversion problem for\ntext-to-image diffusion models gets exacerbated by high classifier-free\nguidance scales, we notice that dynamic guidance significantly reduces\nreconstruction errors without noticeable degradation in generation performance.\nAs a result, we demonstrate that iCD equipped with dynamic guidance may serve\nas a highly effective tool for zero-shot text-guided image editing, competing\nwith more expensive state-of-the-art alternatives.\n","authors":["Nikita Starodubcev","Mikhail Khoroshikh","Artem Babenko","Dmitry Baranchuk"],"pdf_url":"https://arxiv.org/pdf/2406.14539v2.pdf","comment":"Project page: https://yandex-research.github.io/invertible-cd/"},{"id":"http://arxiv.org/abs/2406.18530v1","updated":"2024-06-26T17:57:25Z","published":"2024-06-26T17:57:25Z","title":"MatchTime: Towards Automatic Soccer Game Commentary Generation","summary":"  Soccer is a globally popular sport with a vast audience, in this paper, we\nconsider constructing an automatic soccer game commentary model to improve the\naudiences' viewing experience. In general, we make the following contributions:\nFirst, observing the prevalent video-text misalignment in existing datasets, we\nmanually annotate timestamps for 49 matches, establishing a more robust\nbenchmark for soccer game commentary generation, termed as\nSN-Caption-test-align; Second, we propose a multi-modal temporal alignment\npipeline to automatically correct and filter the existing dataset at scale,\ncreating a higher-quality soccer game commentary dataset for training, denoted\nas MatchTime; Third, based on our curated dataset, we train an automatic\ncommentary generation model, named MatchVoice. Extensive experiments and\nablation studies have demonstrated the effectiveness of our alignment pipeline,\nand training model on the curated datasets achieves state-of-the-art\nperformance for commentary generation, showcasing that better alignment can\nlead to significant performance improvements in downstream tasks.\n","authors":["Jiayuan Rao","Haoning Wu","Chang Liu","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2406.18530v1.pdf","comment":"Technical Report; Project Page:\n  https://haoningwu3639.github.io/MatchTime/"},{"id":"http://arxiv.org/abs/2406.18524v1","updated":"2024-06-26T17:53:51Z","published":"2024-06-26T17:53:51Z","title":"MultiDiff: Consistent Novel View Synthesis from a Single Image","summary":"  We introduce MultiDiff, a novel approach for consistent novel view synthesis\nof scenes from a single RGB image. The task of synthesizing novel views from a\nsingle reference image is highly ill-posed by nature, as there exist multiple,\nplausible explanations for unobserved areas. To address this issue, we\nincorporate strong priors in form of monocular depth predictors and\nvideo-diffusion models. Monocular depth enables us to condition our model on\nwarped reference images for the target views, increasing geometric stability.\nThe video-diffusion prior provides a strong proxy for 3D scenes, allowing the\nmodel to learn continuous and pixel-accurate correspondences across generated\nimages. In contrast to approaches relying on autoregressive image generation\nthat are prone to drifts and error accumulation, MultiDiff jointly synthesizes\na sequence of frames yielding high-quality and multi-view consistent results --\neven for long-term scene generation with large camera movements, while reducing\ninference time by an order of magnitude. For additional consistency and image\nquality improvements, we introduce a novel, structured noise distribution. Our\nexperimental results demonstrate that MultiDiff outperforms state-of-the-art\nmethods on the challenging, real-world datasets RealEstate10K and ScanNet.\nFinally, our model naturally supports multi-view consistent editing without the\nneed for further tuning.\n","authors":["Norman Müller","Katja Schwarz","Barbara Roessle","Lorenzo Porzi","Samuel Rota Bulò","Matthias Nießner","Peter Kontschieder"],"pdf_url":"https://arxiv.org/pdf/2406.18524v1.pdf","comment":"Project page: https://sirwyver.github.io/MultiDiff Video:\n  https://youtu.be/zBC4z4qXW_4 - CVPR 2024"},{"id":"http://arxiv.org/abs/2406.18522v1","updated":"2024-06-26T17:50:47Z","published":"2024-06-26T17:50:47Z","title":"ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of\n  Text-to-Time-lapse Video Generation","summary":"  We propose a novel text-to-video (T2V) generation benchmark,\nChronoMagic-Bench, to evaluate the temporal and metamorphic capabilities of the\nT2V models (e.g. Sora and Lumiere) in time-lapse video generation. In contrast\nto existing benchmarks that focus on the visual quality and textual relevance\nof generated videos, ChronoMagic-Bench focuses on the model's ability to\ngenerate time-lapse videos with significant metamorphic amplitude and temporal\ncoherence. The benchmark probes T2V models for their physics, biology, and\nchemistry capabilities, in a free-form text query. For these purposes,\nChronoMagic-Bench introduces 1,649 prompts and real-world videos as references,\ncategorized into four major types of time-lapse videos: biological,\nhuman-created, meteorological, and physical phenomena, which are further\ndivided into 75 subcategories. This categorization comprehensively evaluates\nthe model's capacity to handle diverse and complex transformations. To\naccurately align human preference with the benchmark, we introduce two new\nautomatic metrics, MTScore and CHScore, to evaluate the videos' metamorphic\nattributes and temporal coherence. MTScore measures the metamorphic amplitude,\nreflecting the degree of change over time, while CHScore assesses the temporal\ncoherence, ensuring the generated videos maintain logical progression and\ncontinuity. Based on the ChronoMagic-Bench, we conduct comprehensive manual\nevaluations of ten representative T2V models, revealing their strengths and\nweaknesses across different categories of prompts, and providing a thorough\nevaluation framework that addresses current gaps in video generation research.\nMoreover, we create a large-scale ChronoMagic-Pro dataset, containing 460k\nhigh-quality pairs of 720p time-lapse videos and detailed captions ensuring\nhigh physical pertinence and large metamorphic amplitude.\n","authors":["Shenghai Yuan","Jinfa Huang","Yongqi Xu","Yaoyang Liu","Shaofeng Zhang","Yujun Shi","Ruijie Zhu","Xinhua Cheng","Jiebo Luo","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2406.18522v1.pdf","comment":"31 pages, 15 figures"},{"id":"http://arxiv.org/abs/2406.18521v1","updated":"2024-06-26T17:50:11Z","published":"2024-06-26T17:50:11Z","title":"CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal\n  LLMs","summary":"  Chart understanding plays a pivotal role when applying Multimodal Large\nLanguage Models (MLLMs) to real-world tasks such as analyzing scientific papers\nor financial reports. However, existing datasets often focus on oversimplified\nand homogeneous charts with template-based questions, leading to an\nover-optimistic measure of progress. We demonstrate that although open-source\nmodels can appear to outperform strong proprietary models on these benchmarks,\na simple stress test with slightly different charts or questions can\ndeteriorate performance by up to 34.5%. In this work, we propose CharXiv, a\ncomprehensive evaluation suite involving 2,323 natural, challenging, and\ndiverse charts from arXiv papers. CharXiv includes two types of questions: 1)\ndescriptive questions about examining basic chart elements and 2) reasoning\nquestions that require synthesizing information across complex visual elements\nin the chart. To ensure quality, all charts and questions are handpicked,\ncurated, and verified by human experts. Our results reveal a substantial,\npreviously underestimated gap between the reasoning skills of the strongest\nproprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the\nstrongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%.\nAll models lag far behind human performance of 80.5%, underscoring weaknesses\nin the chart understanding capabilities of existing MLLMs. We hope CharXiv\nfacilitates future research on MLLM chart understanding by providing a more\nrealistic and faithful measure of progress. Project page and leaderboard:\nhttps://charxiv.github.io/\n","authors":["Zirui Wang","Mengzhou Xia","Luxi He","Howard Chen","Yitao Liu","Richard Zhu","Kaiqu Liang","Xindi Wu","Haotian Liu","Sadhika Malladi","Alexis Chevalier","Sanjeev Arora","Danqi Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18521v1.pdf","comment":"121 pages, 90 figures"},{"id":"http://arxiv.org/abs/2406.18516v1","updated":"2024-06-26T17:40:30Z","published":"2024-06-26T17:40:30Z","title":"Denoising as Adaptation: Noise-Space Domain Adaptation for Image\n  Restoration","summary":"  Although deep learning-based image restoration methods have made significant\nprogress, they still struggle with limited generalization to real-world\nscenarios due to the substantial domain gap caused by training on synthetic\ndata. Existing methods address this issue by improving data synthesis\npipelines, estimating degradation kernels, employing deep internal learning,\nand performing domain adaptation and regularization. Previous domain adaptation\nmethods have sought to bridge the domain gap by learning domain-invariant\nknowledge in either feature or pixel space. However, these techniques often\nstruggle to extend to low-level vision tasks within a stable and compact\nframework. In this paper, we show that it is possible to perform domain\nadaptation via the noise-space using diffusion models. In particular, by\nleveraging the unique property of how the multi-step denoising process is\ninfluenced by auxiliary conditional inputs, we obtain meaningful gradients from\nnoise prediction to gradually align the restored results of both synthetic and\nreal-world data to a common clean distribution. We refer to this method as\ndenoising as adaptation. To prevent shortcuts during training, we present\nuseful techniques such as channel shuffling and residual-swapping contrastive\nlearning. Experimental results on three classical image restoration tasks,\nnamely denoising, deblurring, and deraining, demonstrate the effectiveness of\nthe proposed method. Code will be released at:\nhttps://github.com/KangLiao929/Noise-DA/.\n","authors":["Kang Liao","Zongsheng Yue","Zhouxia Wang","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2406.18516v1.pdf","comment":"Github Repository: https://github.com/KangLiao929/Noise-DA/"},{"id":"http://arxiv.org/abs/2406.18481v1","updated":"2024-06-26T16:47:31Z","published":"2024-06-26T16:47:31Z","title":"Robust Surgical Phase Recognition From Annotation Efficient Supervision","summary":"  Surgical phase recognition is a key task in computer-assisted surgery, aiming\nto automatically identify and categorize the different phases within a surgical\nprocedure. Despite substantial advancements, most current approaches rely on\nfully supervised training, requiring expensive and time-consuming frame-level\nannotations. Timestamp supervision has recently emerged as a promising\nalternative, significantly reducing annotation costs while maintaining\ncompetitive performance. However, models trained on timestamp annotations can\nbe negatively impacted by missing phase annotations, leading to a potential\ndrawback in real-world scenarios. In this work, we address this issue by\nproposing a robust method for surgical phase recognition that can handle\nmissing phase annotations effectively. Furthermore, we introduce the SkipTag@K\nannotation approach to the surgical domain, enabling a flexible balance between\nannotation effort and model performance. Our method achieves competitive\nresults on two challenging datasets, demonstrating its efficacy in handling\nmissing phase annotations and its potential for reducing annotation costs.\nSpecifically, we achieve an accuracy of 85.1\\% on the MultiBypass140 dataset\nusing only 3 annotated frames per video, showcasing the effectiveness of our\nmethod and the potential of the SkipTag@K setup. We perform extensive\nexperiments to validate the robustness of our method and provide valuable\ninsights to guide future research in surgical phase recognition. Our work\ncontributes to the advancement of surgical workflow recognition and paves the\nway for more efficient and reliable surgical phase recognition systems.\n","authors":["Or Rubin","Shlomi Laufer"],"pdf_url":"https://arxiv.org/pdf/2406.18481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09858v2","updated":"2024-06-26T16:26:08Z","published":"2023-09-18T15:20:13Z","title":"Unsupervised Open-Vocabulary Object Localization in Videos","summary":"  In this paper, we show that recent advances in video representation learning\nand pre-trained vision-language models allow for substantial improvements in\nself-supervised video object localization. We propose a method that first\nlocalizes objects in videos via an object-centric approach with slot attention\nand then assigns text to the obtained slots. The latter is achieved by an\nunsupervised way to read localized semantic information from the pre-trained\nCLIP model. The resulting video object localization is entirely unsupervised\napart from the implicit annotation contained in CLIP, and it is effectively the\nfirst unsupervised approach that yields good results on regular video\nbenchmarks.\n","authors":["Ke Fan","Zechen Bai","Tianjun Xiao","Dominik Zietlow","Max Horn","Zixu Zhao","Carl-Johann Simon-Gabriel","Mike Zheng Shou","Francesco Locatello","Bernt Schiele","Thomas Brox","Zheng Zhang","Yanwei Fu","Tong He"],"pdf_url":"https://arxiv.org/pdf/2309.09858v2.pdf","comment":"Accepted by ICCV 2023; Presented on CVPR 2024 Workshop CORR; Project\n  Page:https://github.com/amazon-science/object-centric-vol"},{"id":"http://arxiv.org/abs/2406.18462v1","updated":"2024-06-26T16:12:09Z","published":"2024-06-26T16:12:09Z","title":"GaussianDreamerPro: Text to Manipulable 3D Gaussians with Highly\n  Enhanced Quality","summary":"  Recently, 3D Gaussian splatting (3D-GS) has achieved great success in\nreconstructing and rendering real-world scenes. To transfer the high rendering\nquality to generation tasks, a series of research works attempt to generate\n3D-Gaussian assets from text. However, the generated assets have not achieved\nthe same quality as those in reconstruction tasks. We observe that Gaussians\ntend to grow without control as the generation process may cause indeterminacy.\nAiming at highly enhancing the generation quality, we propose a novel framework\nnamed GaussianDreamerPro. The main idea is to bind Gaussians to reasonable\ngeometry, which evolves over the whole generation process. Along different\nstages of our framework, both the geometry and appearance can be enriched\nprogressively. The final output asset is constructed with 3D Gaussians bound to\nmesh, which shows significantly enhanced details and quality compared with\nprevious methods. Notably, the generated asset can also be seamlessly\nintegrated into downstream manipulation pipelines, e.g. animation, composition,\nand simulation etc., greatly promoting its potential in wide applications.\nDemos are available at https://taoranyi.com/gaussiandreamerpro/.\n","authors":["Taoran Yi","Jiemin Fang","Zanwei Zhou","Junjie Wang","Guanjun Wu","Lingxi Xie","Xiaopeng Zhang","Wenyu Liu","Xinggang Wang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2406.18462v1.pdf","comment":"Project page: https://taoranyi.com/gaussiandreamerpro/"},{"id":"http://arxiv.org/abs/2406.18459v1","updated":"2024-06-26T16:10:31Z","published":"2024-06-26T16:10:31Z","title":"DiffuseHigh: Training-free Progressive High-Resolution Image Synthesis\n  through Structure Guidance","summary":"  Recent surge in large-scale generative models has spurred the development of\nvast fields in computer vision. In particular, text-to-image diffusion models\nhave garnered widespread adoption across diverse domain due to their potential\nfor high-fidelity image generation. Nonetheless, existing large-scale diffusion\nmodels are confined to generate images of up to 1K resolution, which is far\nfrom meeting the demands of contemporary commercial applications. Directly\nsampling higher-resolution images often yields results marred by artifacts such\nas object repetition and distorted shapes. Addressing the aforementioned issues\ntypically necessitates training or fine-tuning models on higher resolution\ndatasets. However, this undertaking poses a formidable challenge due to the\ndifficulty in collecting large-scale high-resolution contents and substantial\ncomputational resources. While several preceding works have proposed\nalternatives, they often fail to produce convincing results. In this work, we\nprobe the generative ability of diffusion models at higher resolution beyond\nits original capability and propose a novel progressive approach that fully\nutilizes generated low-resolution image to guide the generation of higher\nresolution image. Our method obviates the need for additional training or\nfine-tuning which significantly lowers the burden of computational costs.\nExtensive experiments and results validate the efficiency and efficacy of our\nmethod.\n","authors":["Younghyun Kim","Geunmin Hwang","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2406.18459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18453v1","updated":"2024-06-26T16:01:10Z","published":"2024-06-26T16:01:10Z","title":"Towards Human-Level 3D Relative Pose Estimation: Generalizable,\n  Training-Free, with Single Reference","summary":"  Humans can easily deduce the relative pose of an unseen object, without\nlabel/training, given only a single query-reference image pair. This is\narguably achieved by incorporating (i) 3D/2.5D shape perception from a single\nimage, (ii) render-and-compare simulation, and (iii) rich semantic cue\nawareness to furnish (coarse) reference-query correspondence. Existing methods\nimplement (i) by a 3D CAD model or well-calibrated multiple images and (ii) by\ntraining a network on specific objects, which necessitate laborious\nground-truth labeling and tedious training, potentially leading to challenges\nin generalization. Moreover, (iii) was less exploited in the paradigm of (ii),\ndespite that the coarse correspondence from (iii) enhances the compare process\nby filtering out non-overlapped parts under substantial pose\ndifferences/occlusions. Motivated by this, we propose a novel 3D generalizable\nrelative pose estimation method by elaborating (i) with a 2.5D shape from an\nRGB-D reference, (ii) with an off-the-shelf differentiable renderer, and (iii)\nwith semantic cues from a pretrained model like DINOv2. Specifically, our\ndifferentiable renderer takes the 2.5D rotatable mesh textured by the RGB and\nthe semantic maps (obtained by DINOv2 from the RGB input), then renders new RGB\nand semantic maps (with back-surface culling) under a novel rotated view. The\nrefinement loss comes from comparing the rendered RGB and semantic maps with\nthe query ones, back-propagating the gradients through the differentiable\nrenderer to refine the 3D relative pose. As a result, our method can be readily\napplied to unseen objects, given only a single RGB-D reference, without\nlabel/training. Extensive experiments on LineMOD, LM-O, and YCB-V show that our\ntraining-free method significantly outperforms the SOTA supervised methods,\nespecially under the rigorous Acc@5/10/15{\\deg} metrics and the challenging\ncross-dataset settings.\n","authors":["Yuan Gao","Yajing Luo","Junhong Wang","Kui Jia","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2406.18453v1.pdf","comment":"The codes are available at\n  https://github.com/ethanygao/training-free_generalizable_relative_pose"},{"id":"http://arxiv.org/abs/2406.18451v1","updated":"2024-06-26T16:00:35Z","published":"2024-06-26T16:00:35Z","title":"Detecting Brittle Decisions for Free: Leveraging Margin Consistency in\n  Deep Robust Classifiers","summary":"  Despite extensive research on adversarial training strategies to improve\nrobustness, the decisions of even the most robust deep learning models can\nstill be quite sensitive to imperceptible perturbations, creating serious risks\nwhen deploying them for high-stakes real-world applications. While detecting\nsuch cases may be critical, evaluating a model's vulnerability at a\nper-instance level using adversarial attacks is computationally too intensive\nand unsuitable for real-time deployment scenarios. The input space margin is\nthe exact score to detect non-robust samples and is intractable for deep neural\nnetworks. This paper introduces the concept of margin consistency -- a property\nthat links the input space margins and the logit margins in robust models --\nfor efficient detection of vulnerable samples. First, we establish that margin\nconsistency is a necessary and sufficient condition to use a model's logit\nmargin as a score for identifying non-robust samples. Next, through\ncomprehensive empirical analysis of various robustly trained models on CIFAR10\nand CIFAR100 datasets, we show that they indicate strong margin consistency\nwith a strong correlation between their input space margins and the logit\nmargins. Then, we show that we can effectively use the logit margin to\nconfidently detect brittle decisions with such models and accurately estimate\nrobust accuracy on an arbitrarily large test set by estimating the input\nmargins only on a small subset. Finally, we address cases where the model is\nnot sufficiently margin-consistent by learning a pseudo-margin from the feature\nrepresentation. Our findings highlight the potential of leveraging deep\nrepresentations to efficiently assess adversarial vulnerability in deployment\nscenarios.\n","authors":["Jonas Ngnawé","Sabyasachi Sahoo","Yann Pequignot","Frédéric Precioso","Christian Gagné"],"pdf_url":"https://arxiv.org/pdf/2406.18451v1.pdf","comment":"11 pages, 7 figures, 2 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2406.18443v1","updated":"2024-06-26T15:48:24Z","published":"2024-06-26T15:48:24Z","title":"Unveiling the Unknown: Conditional Evidence Decoupling for Unknown\n  Rejection","summary":"  In this paper, we focus on training an open-set object detector under the\ncondition of scarce training samples, which should distinguish the known and\nunknown categories. Under this challenging scenario, the decision boundaries of\nunknowns are difficult to learn and often ambiguous. To mitigate this issue, we\ndevelop a novel open-set object detection framework, which delves into\nconditional evidence decoupling for the unknown rejection. Specifically, we\nselect pseudo-unknown samples by leveraging the discrepancy in attribution\ngradients between known and unknown classes, alleviating the inadequate unknown\ndistribution coverage of training data. Subsequently, we propose a Conditional\nEvidence Decoupling Loss (CEDL) based on Evidential Deep Learning (EDL) theory,\nwhich decouples known and unknown properties in pseudo-unknown samples to learn\ndistinct knowledge, enhancing separability between knowns and unknowns.\nAdditionally, we propose an Abnormality Calibration Loss (ACL), which serves as\na regularization term to adjust the output probability distribution,\nestablishing robust decision boundaries for the unknown rejection. Our method\nhas achieved the superiority performance over previous state-of-the-art\napproaches, improving the mean recall of unknown class by 7.24% across all\nshots in VOC10-5-5 dataset settings and 1.38% in VOC-COCO dataset settings. The\ncode is available via https://github.com/zjzwzw/CED-FOOD.\n","authors":["Zhaowei Wu","Binyi Su","Hua Zhang","Zhong Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.18443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15613v3","updated":"2024-06-26T15:47:02Z","published":"2024-01-28T10:00:45Z","title":"Towards Arbitrary-Scale Histopathology Image Super-resolution: An\n  Efficient Dual-branch Framework via Implicit Self-texture Enhancement","summary":"  High-quality whole-slide scanners are expensive, complex, and time-consuming,\nthus limiting the acquisition and utilization of high-resolution pathology\nwhole-slide images in daily clinical work. Deep learning-based single-image\nsuper-resolution techniques are an effective way to solve this problem by\nsynthesizing high-resolution images from low-resolution ones. However, the\nexisting super-resolution models applied in pathology images can only work in\nfixed integer magnifications, significantly decreasing their applicability.\nThough methods based on implicit neural representation have shown promising\nresults in arbitrary-scale super-resolution of natural images, applying them\ndirectly to pathology images is inadequate because they have unique\nfine-grained image textures different from natural images. Thus, we propose an\nImplicit Self-Texture Enhancement-based dual-branch framework (ISTE) for\narbitrary-scale super-resolution of pathology images to address this challenge.\nISTE contains a pixel learning branch and a texture learning branch, which\nfirst learn pixel features and texture features, respectively. Then, we design\na two-stage texture enhancement strategy to fuse the features from the two\nbranches to obtain the super-resolution results, where the first stage is\nfeature-based texture enhancement, and the second stage is spatial-domain-based\ntexture enhancement. Extensive experiments on three public datasets show that\nISTE outperforms existing fixed-scale and arbitrary-scale algorithms at\nmultiple magnifications and helps to improve downstream task performance. To\nthe best of our knowledge, this is the first work to achieve arbitrary-scale\nsuper-resolution in pathology images. Codes will be available.\n","authors":["Minghong Duan","Linhao Qu","Zhiwei Yang","Manning Wang","Chenxi Zhang","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2401.15613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04063v3","updated":"2024-06-26T15:41:37Z","published":"2023-12-07T06:03:07Z","title":"An unsupervised approach towards promptable defect segmentation in\n  laser-based additive manufacturing by Segment Anything","summary":"  Foundation models are currently driving a paradigm shift in computer vision\ntasks for various fields including biology, astronomy, and robotics among\nothers, leveraging user-generated prompts to enhance their performance. In the\nLaser Additive Manufacturing (LAM) domain, accurate image-based defect\nsegmentation is imperative to ensure product quality and facilitate real-time\nprocess control. However, such tasks are often characterized by multiple\nchallenges including the absence of labels and the requirement for low latency\ninference among others. Porosity is a very common defect in LAM due to lack of\nfusion, entrapped gas, and keyholes, directly affecting mechanical properties\nlike tensile strength, stiffness, and hardness, thereby compromising the\nquality of the final product. To address these issues, we construct a framework\nfor image segmentation using a state-of-the-art Vision Transformer (ViT) based\nFoundation model (Segment Anything Model) with a novel multi-point prompt\ngeneration scheme using unsupervised clustering. Utilizing our framework we\nperform porosity segmentation in a case study of laser-based powder bed fusion\n(L-PBF) and obtain high accuracy without using any labeled data to guide the\nprompt tuning process. By capitalizing on lightweight foundation model\ninference combined with unsupervised prompt generation, we envision\nconstructing a real-time anomaly detection pipeline that could revolutionize\ncurrent laser additive manufacturing processes, thereby facilitating the shift\ntowards Industry 4.0 and promoting defect-free production along with\noperational efficiency.\n","authors":["Israt Zarin Era","Imtiaz Ahmed","Zhichao Liu","Srinjoy Das"],"pdf_url":"https://arxiv.org/pdf/2312.04063v3.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2211.05622v2","updated":"2024-06-26T15:34:47Z","published":"2022-11-10T14:54:31Z","title":"InstantGroup: Instant Template Generation for Scalable Group of Brain\n  MRI Registration","summary":"  Template generation is a critical step in groupwise image registration, which\ninvolves aligning a group of subjects into a common space. While existing\nmethods can generate high-quality template images, they often incur substantial\ntime costs or are limited by fixed group scales. In this paper, we present\nInstantGroup, an efficient groupwise template generation framework based on\nvariational autoencoder (VAE) models that leverage latent representations'\narithmetic properties, enabling scalability to groups of any size. InstantGroup\nfeatures a Dual VAEs backbone with shared-weight twin networks to handle pairs\nof inputs and incorporates a Displacement Inversion Module (DIM) to maintain\ntemplate unbiasedness and a Subject-Template Alignment Module (STAM) to improve\ntemplate quality and registration accuracy. Experiments on 3D brain MRI scans\nfrom the OASIS and ADNI datasets reveal that InstantGroup dramatically reduces\nruntime, generating templates within seconds for various group sizes while\nmaintaining superior performance compared to state-of-the-art baselines on\nquantitative metrics, including unbiasedness and registration accuracy.\n","authors":["Ziyi He","Albert C. S. Chung"],"pdf_url":"https://arxiv.org/pdf/2211.05622v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18430v1","updated":"2024-06-26T15:27:26Z","published":"2024-06-26T15:27:26Z","title":"Facial Image Feature Analysis and its Specialization for Fréchet\n  Distance and Neighborhoods","summary":"  Assessing distances between images and image datasets is a fundamental task\nin vision-based research. It is a challenging open problem in the literature\nand despite the criticism it receives, the most ubiquitous method remains the\nFr\\'echet Inception Distance. The Inception network is trained on a specific\nlabeled dataset, ImageNet, which has caused the core of its criticism in the\nmost recent research. Improvements were shown by moving to self-supervision\nlearning over ImageNet, leaving the training data domain as an open question.\nWe make that last leap and provide the first analysis on domain-specific\nfeature training and its effects on feature distance, on the widely-researched\nfacial image domain. We provide our findings and insights on this domain\nspecialization for Fr\\'echet distance and image neighborhoods, supported by\nextensive experiments and in-depth user studies.\n","authors":["Doruk Cetin","Benedikt Schesch","Petar Stamenkovic","Niko Benjamin Huber","Fabio Zünd","Majed El Helou"],"pdf_url":"https://arxiv.org/pdf/2406.18430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18422v1","updated":"2024-06-26T15:18:20Z","published":"2024-06-26T15:18:20Z","title":"Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D\n  Generative Modeling","summary":"  This paper investigates a 2D to 3D image translation method with a\nstraightforward technique, enabling correlated 2D X-ray to 3D CT-like\nreconstruction. We observe that existing approaches, which integrate\ninformation across multiple 2D views in the latent space, lose valuable signal\ninformation during latent encoding. Instead, we simply repeat and concatenate\nthe 2D views into higher-channel 3D volumes and approach the 3D reconstruction\nchallenge as a straightforward 3D to 3D generative modeling problem,\nsidestepping several complex modeling issues. This method enables the\nreconstructed 3D volume to retain valuable information from the 2D inputs,\nwhich are passed between channel states in a Swin UNETR backbone. Our approach\napplies neural optimal transport, which is fast and stable to train,\neffectively integrating signal information across multiple views without the\nrequirement for precise alignment; it produces non-collapsed reconstructions\nthat are highly faithful to the 2D views, even after limited training. We\ndemonstrate correlated results, both qualitatively and quantitatively, having\ntrained our model on a single dataset and evaluated its generalization ability\nacross six datasets, including out-of-distribution samples.\n","authors":["Abril Corona-Figueroa","Hubert P. H. Shum","Chris G. Willcocks"],"pdf_url":"https://arxiv.org/pdf/2406.18422v1.pdf","comment":"CVPRW 2024 - DCA in MI; Best Paper Award"},{"id":"http://arxiv.org/abs/2406.18414v1","updated":"2024-06-26T15:09:54Z","published":"2024-06-26T15:09:54Z","title":"BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using\n  Camera-LiDAR Data","summary":"  Compared with real-time multi-object tracking (MOT), offline multi-object\ntracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneous\nlink correction, and full track optimization but has to deal with the\nchallenges from bounding box misalignment and track evaluation, editing, and\nrefinement. This paper proposes \"BiTrack\", a 3D OMOT framework that includes\nmodules of 2D-3D detection fusion, initial trajectory generation, and\nbidirectional trajectory re-optimization to achieve optimal tracking results\nfrom camera-LiDAR data. The novelty of this paper includes threefold: (1)\ndevelopment of a point-level object registration technique that employs a\ndensity-based similarity metric to achieve accurate fusion of 2D-3D detection\nresults; (2) development of a set of data association and track management\nskills that utilizes a vertex-based similarity metric as well as false alarm\nrejection and track recovery mechanisms to generate reliable bidirectional\nobject trajectories; (3) development of a trajectory re-optimization scheme\nthat re-organizes track fragments of different fidelities in a greedy fashion,\nas well as refines each trajectory with completion and smoothing techniques.\nThe experiment results on the KITTI dataset demonstrate that BiTrack achieves\nthe state-of-the-art performance for 3D OMOT tasks in terms of accuracy and\nefficiency.\n","authors":["Kemiao Huang","Meiying Zhang","Qi Hao"],"pdf_url":"https://arxiv.org/pdf/2406.18414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17775v2","updated":"2024-06-26T14:34:13Z","published":"2024-02-20T11:36:23Z","title":"WhaleNet: a Novel Deep Learning Architecture for Marine Mammals\n  Vocalizations on Watkins Marine Mammal Sound Database","summary":"  Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machine\nlearning applications. Nevertheless, the methodologies for data preparation,\npreprocessing, and classification documented in the literature exhibit\nconsiderable variability and are typically not applied to the dataset in its\nentirety. This study initially undertakes a concise review of the\nstate-of-the-art benchmarks pertaining to the dataset, with a particular focus\non clarifying data preparation and preprocessing techniques. Subsequently, we\nexplore the utilization of the Wavelet Scattering Transform (WST) and Mel\nspectrogram as preprocessing mechanisms for feature extraction. In this paper,\nwe introduce \\textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble\nNetwork), a sophisticated deep ensemble architecture for the classification of\nmarine mammal vocalizations, leveraging both WST and Mel spectrogram for\nenhanced feature discrimination. By integrating the insights derived from WST\nand Mel representations, we achieved an improvement in classification accuracy\nby $8-10\\%$ over existing architectures, corresponding to a classification\naccuracy of $97.61\\%$.\n","authors":["Alessandro Licciardi","Davide Carbone"],"pdf_url":"https://arxiv.org/pdf/2402.17775v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18387v1","updated":"2024-06-26T14:29:05Z","published":"2024-06-26T14:29:05Z","title":"DoubleTake: Geometry Guided Depth Estimation","summary":"  Estimating depth from a sequence of posed RGB images is a fundamental\ncomputer vision task, with applications in augmented reality, path planning\netc. Prior work typically makes use of previous frames in a multi view stereo\nframework, relying on matching textures in a local neighborhood. In contrast,\nour model leverages historical predictions by giving the latest 3D geometry\ndata as an extra input to our network. This self-generated geometric hint can\nencode information from areas of the scene not covered by the keyframes and it\nis more regularized when compared to individual predicted depth maps for\nprevious frames. We introduce a Hint MLP which combines cost volume features\nwith a hint of the prior geometry, rendered as a depth map from the current\ncamera location, together with a measure of the confidence in the prior\ngeometry. We demonstrate that our method, which can run at interactive speeds,\nachieves state-of-the-art estimates of depth and 3D scene reconstruction in\nboth offline and incremental evaluation scenarios.\n","authors":["Mohamed Sayed","Filippo Aleotti","Jamie Watson","Zawar Qureshi","Guillermo Garcia-Hernando","Gabriel Brostow","Sara Vicente","Michael Firman"],"pdf_url":"https://arxiv.org/pdf/2406.18387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18375v1","updated":"2024-06-26T14:19:31Z","published":"2024-06-26T14:19:31Z","title":"From Majority to Minority: A Diffusion-based Augmentation for\n  Underrepresented Groups in Skin Lesion Analysis","summary":"  AI-based diagnoses have demonstrated dermatologist-level performance in\nclassifying skin cancer. However, such systems are prone to under-performing\nwhen tested on data from minority groups that lack sufficient representation in\nthe training sets. Although data collection and annotation offer the best means\nfor promoting minority groups, these processes are costly and time-consuming.\nPrior works have suggested that data from majority groups may serve as a\nvaluable information source to supplement the training of diagnosis tools for\nminority groups. In this work, we propose an effective diffusion-based\naugmentation framework that maximizes the use of rich information from majority\ngroups to benefit minority groups. Using groups with different skin types as a\ncase study, our results show that the proposed framework can generate synthetic\nimages that improve diagnostic results for the minority groups, even when there\nis little or no reference data from these target groups. The practical value of\nour work is evident in medical imaging analysis, where under-diagnosis persists\nas a problem for certain groups due to insufficient representation.\n","authors":["Janet Wang","Yunsung Chung","Zhengming Ding","Jihun Hamm"],"pdf_url":"https://arxiv.org/pdf/2406.18375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18361v1","updated":"2024-06-26T14:01:07Z","published":"2024-06-26T14:01:07Z","title":"Stable Diffusion Segmentation for Biomedical Images with Single-step\n  Reverse Process","summary":"  Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg\n","authors":["Tianyu Lin","Zhiguang Chen","Zhonghao Yan","Fudan Zheng","Weijiang Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18361v1.pdf","comment":"Accepted at MICCAI 2024. Code and citation info see\n  https://github.com/lin-tianyu/Stable-Diffusion-Seg"},{"id":"http://arxiv.org/abs/2406.18360v1","updated":"2024-06-26T14:00:21Z","published":"2024-06-26T14:00:21Z","title":"XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis","summary":"  Thoroughly testing autonomy systems is crucial in the pursuit of safe\nautonomous driving vehicles. It necessitates creating safety-critical scenarios\nthat go beyond what can be safely collected from real-world data, as many of\nthese scenarios occur infrequently on public roads. However, the evaluation of\nmost existing NVS methods relies on sporadic sampling of image frames from the\ntraining data, comparing the rendered images with ground truth images using\nmetrics. Unfortunately, this evaluation protocol falls short of meeting the\nactual requirements in closed-loop simulations. Specifically, the true\napplication demands the capability to render novel views that extend beyond the\noriginal trajectory (such as cross-lane views), which are challenging to\ncapture in the real world. To address this, this paper presents a novel driving\nview synthesis dataset and benchmark specifically designed for autonomous\ndriving simulations. This dataset is unique as it includes testing images\ncaptured by deviating from the training trajectory by 1-4 meters. It comprises\nsix sequences encompassing various time and weather conditions. Each sequence\ncontains 450 training images, 150 testing images, and their corresponding\ncamera poses and intrinsic parameters. Leveraging this novel dataset, we\nestablish the first realistic benchmark for evaluating existing NVS approaches\nunder front-only and multi-camera settings. The experimental findings\nunderscore the significant gap that exists in current approaches, revealing\ntheir inadequate ability to fulfill the demanding prerequisites of cross-lane\nor closed-loop simulation. Our dataset is released publicly at the project\npage: https://3d-aigc.github.io/XLD/.\n","authors":["Hao Li","Ming Yuan","Yan Zhang","Chenming Wu","Chen Zhao","Chunyu Song","Haocheng Feng","Errui Ding","Dingwen Zhang","Jingdong Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18360v1.pdf","comment":"project page: https://3d-aigc.github.io/XLD/"},{"id":"http://arxiv.org/abs/2212.13459v2","updated":"2024-06-26T13:59:56Z","published":"2022-12-27T12:03:38Z","title":"Scaling Painting Style Transfer","summary":"  Neural style transfer (NST) is a deep learning technique that produces an\nunprecedentedly rich style transfer from a style image to a content image. It\nis particularly impressive when it comes to transferring style from a painting\nto an image. NST was originally achieved by solving an optimization problem to\nmatch the global statistics of the style image while preserving the local\ngeometric features of the content image. The two main drawbacks of this\noriginal approach is that it is computationally expensive and that the\nresolution of the output images is limited by high GPU memory requirements.\nMany solutions have been proposed to both accelerate NST and produce images\nwith larger size. However, our investigation shows that these accelerated\nmethods all compromise the quality of the produced images in the context of\npainting style transfer. Indeed, transferring the style of a painting is a\ncomplex task involving features at different scales, from the color palette and\ncompositional style to the fine brushstrokes and texture of the canvas. This\npaper provides a solution to solve the original global optimization for\nultra-high resolution (UHR) images, enabling multiscale NST at unprecedented\nimage sizes. This is achieved by spatially localizing the computation of each\nforward and backward passes through the VGG network. Extensive qualitative and\nquantitative comparisons, as well as a \\textcolor{coverletter}{perceptual\nstudy}, show that our method produces style transfer of unmatched quality for\nsuch high-resolution painting styles. By a careful comparison, we show that\nstate-of-the-art fast methods are still prone to artifacts, thus suggesting\nthat fast painting style transfer remains an open problem. Source code is\navailable at https://github.com/bgalerne/scaling_painting_style_transfer.\n","authors":["Bruno Galerne","Lara Raad","José Lezama","Jean-Michel Morel"],"pdf_url":"https://arxiv.org/pdf/2212.13459v2.pdf","comment":"14 pages, 9 figures, 4 tables, accepted at EGSR 2024"},{"id":"http://arxiv.org/abs/2406.18350v1","updated":"2024-06-26T13:51:57Z","published":"2024-06-26T13:51:57Z","title":"On Reducing Activity with Distillation and Regularization for Energy\n  Efficient Spiking Neural Networks","summary":"  Interest in spiking neural networks (SNNs) has been growing steadily,\npromising an energy-efficient alternative to formal neural networks (FNNs),\ncommonly known as artificial neural networks (ANNs). Despite increasing\ninterest, especially for Edge applications, these event-driven neural networks\nsuffered from their difficulty to be trained compared to FNNs. To alleviate\nthis problem, a number of innovative methods have been developed to provide\nperformance more or less equivalent to that of FNNs. However, the spiking\nactivity of a network during inference is usually not considered. While SNNs\nmay usually have performance comparable to that of FNNs, it is often at the\ncost of an increase of the network's activity, thus limiting the benefit of\nusing them as a more energy-efficient solution.\n  In this paper, we propose to leverage Knowledge Distillation (KD) for SNNs\ntraining with surrogate gradient descent in order to optimize the trade-off\nbetween performance and spiking activity. Then, after understanding why KD led\nto an increase in sparsity, we also explored Activations regularization and\nproposed a novel method with Logits Regularization. These approaches, validated\non several datasets, clearly show a reduction in network spiking activity\n(-26.73% on GSC and -14.32% on CIFAR-10) while preserving accuracy.\n","authors":["Thomas Louis","Benoit Miramond","Alain Pegatoquet","Adrien Girard"],"pdf_url":"https://arxiv.org/pdf/2406.18350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18344v1","updated":"2024-06-26T13:38:16Z","published":"2024-06-26T13:38:16Z","title":"AlignedCut: Visual Concepts Discovery on Brain-Guided Universal Feature\n  Space","summary":"  We study the intriguing connection between visual data, deep networks, and\nthe brain. Our method creates a universal channel alignment by using brain\nvoxel fMRI response prediction as the training objective. We discover that deep\nnetworks, trained with different objectives, share common feature channels\nacross various models. These channels can be clustered into recurring sets,\ncorresponding to distinct brain regions, indicating the formation of visual\nconcepts. Tracing the clusters of channel responses onto the images, we see\nsemantically meaningful object segments emerge, even without any supervised\ndecoder. Furthermore, the universal feature alignment and the clustering of\nchannels produce a picture and quantification of how visual information is\nprocessed through the different network layers, which produces precise\ncomparisons between the networks.\n","authors":["Huzheng Yang","James Gee","Jianbo Shi"],"pdf_url":"https://arxiv.org/pdf/2406.18344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03251v4","updated":"2024-06-26T13:37:13Z","published":"2023-04-06T17:36:23Z","title":"SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation","summary":"  Learning models on one labeled dataset that generalize well on another domain\nis a difficult task, as several shifts might happen between the data domains.\nThis is notably the case for lidar data, for which models can exhibit large\nperformance discrepancies due for instance to different lidar patterns or\nchanges in acquisition conditions. This paper addresses the corresponding\nUnsupervised Domain Adaptation (UDA) task for semantic segmentation. To\nmitigate this problem, we introduce an unsupervised auxiliary task of learning\nan implicit underlying surface representation simultaneously on source and\ntarget data. As both domains share the same latent representation, the model is\nforced to accommodate discrepancies between the two sources of data. This novel\nstrategy differs from classical minimization of statistical divergences or\nlidar-specific domain adaptation techniques. Our experiments demonstrate that\nour method achieves a better performance than the current state of the art,\nboth in real-to-real and synthetic-to-real scenarios.\n","authors":["Björn Michele","Alexandre Boulch","Gilles Puy","Tuan-Hung Vu","Renaud Marlet","Nicolas Courty"],"pdf_url":"https://arxiv.org/pdf/2304.03251v4.pdf","comment":"Accepted as spotlight to 3DV 2024. Project repository:\n  github.com/valeoai/SALUDA"},{"id":"http://arxiv.org/abs/2406.18333v1","updated":"2024-06-26T13:21:08Z","published":"2024-06-26T13:21:08Z","title":"Continuous Sign Language Recognition Using Intra-inter Gloss Attention","summary":"  Many continuous sign language recognition (CSLR) studies adopt\ntransformer-based architectures for sequence modeling due to their powerful\ncapacity for capturing global contexts. Nevertheless, vanilla self-attention,\nwhich serves as the core module of the transformer, calculates a weighted\naverage over all time steps; therefore, the local temporal semantics of sign\nvideos may not be fully exploited. In this study, we introduce a novel module\nin sign language recognition studies, called intra-inter gloss attention\nmodule, to leverage the relationships among frames within glosses and the\nsemantic and grammatical dependencies between glosses in the video. In the\nintra-gloss attention module, the video is divided into equally sized chunks\nand a self-attention mechanism is applied within each chunk. This localized\nself-attention significantly reduces complexity and eliminates noise introduced\nby considering non-relative frames. In the inter-gloss attention module, we\nfirst aggregate the chunk-level features within each gloss chunk by average\npooling along the temporal dimension. Subsequently, multi-head self-attention\nis applied to all chunk-level features. Given the non-significance of the\nsigner-environment interaction, we utilize segmentation to remove the\nbackground of the videos. This enables the proposed model to direct its focus\ntoward the signer. Experimental results on the PHOENIX-2014 benchmark dataset\ndemonstrate that our method can effectively extract sign language features in\nan end-to-end manner without any prior knowledge, improve the accuracy of CSLR,\nand achieve the word error rate (WER) of 20.4 on the test set which is a\ncompetitive result compare to the state-of-the-art which uses additional\nsupervisions.\n","authors":["Hossein Ranjbar","Alireza Taheri"],"pdf_url":"https://arxiv.org/pdf/2406.18333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18327v1","updated":"2024-06-26T13:14:24Z","published":"2024-06-26T13:14:24Z","title":"Multi-modal Evidential Fusion Network for Trusted PET/CT Tumor\n  Segmentation","summary":"  Accurate segmentation of tumors in PET/CT images is important in\ncomputer-aided diagnosis and treatment of cancer. The key issue of such a\nsegmentation problem lies in the effective integration of complementary\ninformation from PET and CT images. However, the quality of PET and CT images\nvaries widely in clinical settings, which leads to uncertainty in the modality\ninformation extracted by networks. To take the uncertainty into account in\nmulti-modal information fusion, this paper proposes a novel Multi-modal\nEvidential Fusion Network (MEFN) comprising a Cross-Modal Feature Learning\n(CFL) module and a Multi-modal Trusted Fusion (MTF) module. The CFL module\nreduces the domain gap upon modality conversion and highlights common tumor\nfeatures, thereby alleviating the needs of the segmentation module to handle\nmodality specificity. The MTF module utilizes mutual attention mechanisms and\nan uncertainty calibrator to fuse modality features based on modality\nuncertainty and then fuse the segmentation results under the guidance of\nDempster-Shafer Theory. Besides, a new uncertainty perceptual loss is\nintroduced to force the model focusing on uncertain features and hence improve\nits ability to extract trusted modality information. Extensive comparative\nexperiments are conducted on two publicly available PET/CT datasets to evaluate\nthe performance of our proposed method whose results demonstrate that our MEFN\nsignificantly outperforms state-of-the-art methods with improvements of 2.15%\nand 3.23% in DSC scores on the AutoPET dataset and the Hecktor dataset,\nrespectively. More importantly, our model can provide radiologists with\ncredible uncertainty of the segmentation results for their decision in\naccepting or rejecting the automatic segmentation results, which is\nparticularly important for clinical applications. Our code will be available at\nhttps://github.com/QPaws/MEFN.\n","authors":["Yuxuan Qi","Li Lin","Jiajun Wang","Jingya Zhang","Bin Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06658v2","updated":"2024-06-26T13:01:55Z","published":"2024-03-11T12:27:20Z","title":"Towards Zero-Shot Interpretable Human Recognition: A 2D-3D Registration\n  Framework","summary":"  Large vision models based in deep learning architectures have been\nconsistently advancing the state-of-the-art in biometric recognition. However,\nthree weaknesses are commonly reported for such kind of approaches: 1) their\nextreme demands in terms of learning data; 2) the difficulties in generalising\nbetween different domains; and 3) the lack of interpretability/explainability,\nwith biometrics being of particular interest, as it is important to provide\nevidence able to be used for forensics/legal purposes (e.g., in courts). To the\nbest of our knowledge, this paper describes the first recognition\nframework/strategy that aims at addressing the three weaknesses simultaneously.\nAt first, it relies exclusively in synthetic samples for learning purposes.\nInstead of requiring a large amount and variety of samples for each subject,\nthe idea is to exclusively enroll a 3D point cloud per identity. Then, using\ngenerative strategies, we synthesize a very large (potentially infinite) number\nof samples, containing all the desired covariates (poses, clothing, distances,\nperspectives, lighting, occlusions,...). Upon the synthesizing method used, it\nis possible to adapt precisely to different kind of domains, which accounts for\ngeneralization purposes. Such data are then used to learn a model that performs\nlocal registration between image pairs, establishing positive correspondences\nbetween body parts that are the key, not only to recognition (according to\ncardinality and distribution), but also to provide an interpretable description\nof the response (e.g.: \"both samples are from the same person, as they have\nsimilar facial shape, hair color and legs thickness\").\n","authors":["Henrique Jesus","Hugo Proença"],"pdf_url":"https://arxiv.org/pdf/2403.06658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04861v2","updated":"2024-06-26T12:59:02Z","published":"2024-01-10T00:40:05Z","title":"CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from\n  Monocular Video","summary":"  The goal of our work is to generate high-quality novel views from monocular\nvideos of complex and dynamic scenes. Prior methods, such as DynamicNeRF, have\nshown impressive performance by leveraging time-varying dynamic radiation\nfields. However, these methods have limitations when it comes to accurately\nmodeling the motion of complex objects, which can lead to inaccurate and blurry\nrenderings of details. To address this limitation, we propose a novel approach\nthat builds upon a recent generalization NeRF, which aggregates nearby views\nonto new viewpoints. However, such methods are typically only effective for\nstatic scenes. To overcome this challenge, we introduce a module that operates\nin both the time and frequency domains to aggregate the features of object\nmotion. This allows us to learn the relationship between frames and generate\nhigher-quality images. Our experiments demonstrate significant improvements\nover state-of-the-art methods on dynamic scene datasets. Specifically, our\napproach outperforms existing methods in terms of both the accuracy and visual\nquality of the synthesized views. Our code is available on\nhttps://github.com/xingy038/CTNeRF.\n","authors":["Xingyu Miao","Yang Bai","Haoran Duan","Yawen Huang","Fan Wan","Yang Long","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2401.04861v2.pdf","comment":"Accepted by Pattern Recognition"},{"id":"http://arxiv.org/abs/2406.18310v1","updated":"2024-06-26T12:50:10Z","published":"2024-06-26T12:50:10Z","title":"Spatial-temporal Hierarchical Reinforcement Learning for Interpretable\n  Pathology Image Super-Resolution","summary":"  Pathology image are essential for accurately interpreting lesion cells in\ncytopathology screening, but acquiring high-resolution digital slides requires\nspecialized equipment and long scanning times. Though super-resolution (SR)\ntechniques can alleviate this problem, existing deep learning models recover\npathology image in a black-box manner, which can lead to untruthful biological\ndetails and misdiagnosis. Additionally, current methods allocate the same\ncomputational resources to recover each pixel of pathology image, leading to\nthe sub-optimal recovery issue due to the large variation of pathology image.\nIn this paper, we propose the first hierarchical reinforcement learning\nframework named Spatial-Temporal hierARchical Reinforcement Learning (STAR-RL),\nmainly for addressing the aforementioned issues in pathology image\nsuper-resolution problem. We reformulate the SR problem as a Markov decision\nprocess of interpretable operations and adopt the hierarchical recovery\nmechanism in patch level, to avoid sub-optimal recovery. Specifically, the\nhigher-level spatial manager is proposed to pick out the most corrupted patch\nfor the lower-level patch worker. Moreover, the higher-level temporal manager\nis advanced to evaluate the selected patch and determine whether the\noptimization should be stopped earlier, thereby avoiding the over-processed\nproblem. Under the guidance of spatial-temporal managers, the lower-level patch\nworker processes the selected patch with pixel-wise interpretable actions at\neach time step. Experimental results on medical images degraded by different\nkernels show the effectiveness of STAR-RL. Furthermore, STAR-RL validates the\npromotion in tumor diagnosis with a large margin and shows generalizability\nunder various degradations. The source code is available at\nhttps://github.com/CUHK-AIM-Group/STAR-RL.\n","authors":["Wenting Chen","Jie Liu","Tommy W. S. Chow","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2406.18310v1.pdf","comment":"Accepted to IEEE TRANSACTIONS ON MEDICAL IMAGING (TMI)"},{"id":"http://arxiv.org/abs/2405.20204v2","updated":"2024-06-26T12:31:48Z","published":"2024-05-30T16:07:54Z","title":"Jina CLIP: Your CLIP Model Is Also Your Text Retriever","summary":"  Contrastive Language-Image Pretraining (CLIP) is widely used to train models\nto align images and texts in a common embedding space by mapping them to\nfixed-sized vectors. These models are key to multimodal information retrieval\nand related tasks. However, CLIP models generally underperform in text-only\ntasks compared to specialized text models. This creates inefficiencies for\ninformation retrieval systems that keep separate embeddings and models for\ntext-only and multimodal tasks. We propose a novel, multi-task contrastive\ntraining method to address this issue, which we use to train the jina-clip-v1\nmodel to achieve the state-of-the-art performance on both text-image and\ntext-text retrieval tasks.\n","authors":["Andreas Koukounas","Georgios Mastrapas","Michael Günther","Bo Wang","Scott Martens","Isabelle Mohr","Saba Sturua","Mohammad Kalim Akram","Joan Fontanals Martínez","Saahil Ognawala","Susana Guzman","Maximilian Werk","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2405.20204v2.pdf","comment":"4 pages, MFM-EAI@ICML2024"},{"id":"http://arxiv.org/abs/2306.06210v5","updated":"2024-06-26T12:31:04Z","published":"2023-05-26T13:06:38Z","title":"Single-Model Attribution of Generative Models Through Final-Layer\n  Inversion","summary":"  Recent breakthroughs in generative modeling have sparked interest in\npractical single-model attribution. Such methods predict whether a sample was\ngenerated by a specific generator or not, for instance, to prove intellectual\nproperty theft. However, previous works are either limited to the closed-world\nsetting or require undesirable changes to the generative model. We address\nthese shortcomings by, first, viewing single-model attribution through the lens\nof anomaly detection. Arising from this change of perspective, we propose\nFLIPAD, a new approach for single-model attribution in the open-world setting\nbased on final-layer inversion and anomaly detection. We show that the utilized\nfinal-layer inversion can be reduced to a convex lasso optimization problem,\nmaking our approach theoretically sound and computationally efficient. The\ntheoretical findings are accompanied by an experimental study demonstrating the\neffectiveness of our approach and its flexibility to various domains.\n","authors":["Mike Laszkiewicz","Jonas Ricker","Johannes Lederer","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2306.06210v5.pdf","comment":"Accepted at the Forty-first International Conference on Machine\n  Learning [ICML2024]"},{"id":"http://arxiv.org/abs/2406.18295v1","updated":"2024-06-26T12:27:06Z","published":"2024-06-26T12:27:06Z","title":"Evaluating and Benchmarking Foundation Models for Earth Observation and\n  Geospatial AI","summary":"  When we are primarily interested in solving several problems jointly with a\ngiven prescribed high performance accuracy for each target application, then\nFoundation Models should for most cases be used rather than problem-specific\nmodels. We focus on the specific Computer Vision application of Foundation\nModels for Earth Observation (EO) and geospatial AI. These models can solve\nimportant problems we are tackling, including for example land cover\nclassification, crop type mapping, flood segmentation, building density\nestimation, and road regression segmentation. In this paper, we show that for a\nlimited number of labelled data, Foundation Models achieve improved performance\ncompared to problem-specific models. In this work, we also present our proposed\nevaluation benchmark for Foundation Models for EO. Benchmarking the\ngeneralization performance of Foundation Models is important as it has become\ndifficult to standardize a fair comparison across the many different models\nthat have been proposed recently. We present the results using our evaluation\nbenchmark for EO Foundation Models and show that Foundation Models are label\nefficient in the downstream tasks and help us solve problems we are tackling in\nEO and remote sensing.\n","authors":["Nikolaos Dionelis","Casper Fibaek","Luke Camilleri","Andreas Luyts","Jente Bosmans","Bertrand Le Saux"],"pdf_url":"https://arxiv.org/pdf/2406.18295v1.pdf","comment":"5 pages, 2 figures, Submitted"},{"id":"http://arxiv.org/abs/2406.18284v1","updated":"2024-06-26T12:09:59Z","published":"2024-06-26T12:09:59Z","title":"RealTalk: Real-time and Realistic Audio-driven Face Generation with 3D\n  Facial Prior-guided Identity Alignment Network","summary":"  Person-generic audio-driven face generation is a challenging task in computer\nvision. Previous methods have achieved remarkable progress in audio-visual\nsynchronization, but there is still a significant gap between current results\nand practical applications. The challenges are two-fold: 1) Preserving unique\nindividual traits for achieving high-precision lip synchronization. 2)\nGenerating high-quality facial renderings in real-time performance. In this\npaper, we propose a novel generalized audio-driven framework RealTalk, which\nconsists of an audio-to-expression transformer and a high-fidelity\nexpression-to-face renderer. In the first component, we consider both identity\nand intra-personal variation features related to speaking lip movements. By\nincorporating cross-modal attention on the enriched facial priors, we can\neffectively align lip movements with audio, thus attaining greater precision in\nexpression prediction. In the second component, we design a lightweight facial\nidentity alignment (FIA) module which includes a lip-shape control structure\nand a face texture reference structure. This novel design allows us to generate\nfine details in real-time, without depending on sophisticated and inefficient\nfeature alignment modules. Our experimental results, both quantitative and\nqualitative, on public datasets demonstrate the clear advantages of our method\nin terms of lip-speech synchronization and generation quality. Furthermore, our\nmethod is efficient and requires fewer computational resources, making it\nwell-suited to meet the needs of practical applications.\n","authors":["Xiaozhong Ji","Chuming Lin","Zhonggan Ding","Ying Tai","Jian Yang","Junwei Zhu","Xiaobin Hu","Jiangning Zhang","Donghao Luo","Chengjie Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18279v1","updated":"2024-06-26T12:05:49Z","published":"2024-06-26T12:05:49Z","title":"CAS: Confidence Assessments of classification algorithms for Semantic\n  segmentation of EO data","summary":"  Confidence assessments of semantic segmentation algorithms in remote sensing\nare important. It is a desirable property of models to a priori know if they\nproduce an incorrect output. Evaluations of the confidence assigned to the\nestimates of models for the task of classification in Earth Observation (EO)\nare crucial as they can be used to achieve improved semantic segmentation\nperformance and prevent high error rates during inference and deployment. The\nmodel we develop, the Confidence Assessments of classification algorithms for\nSemantic segmentation (CAS) model, performs confidence evaluations at both the\nsegment and pixel levels, and outputs both labels and confidence. The outcome\nof this work has important applications. The main application is the evaluation\nof EO Foundation Models on semantic segmentation downstream tasks, in\nparticular land cover classification using satellite Copernicus Sentinel-2\ndata. The evaluation shows that the proposed model is effective and outperforms\nother alternative baseline models.\n","authors":["Nikolaos Dionelis","Nicolas Longepe"],"pdf_url":"https://arxiv.org/pdf/2406.18279v1.pdf","comment":"5 pages, 7 figures, 4 tables, Submitted"},{"id":"http://arxiv.org/abs/2406.18278v1","updated":"2024-06-26T12:04:09Z","published":"2024-06-26T12:04:09Z","title":"Generalized Deepfake Attribution","summary":"  The landscape of fake media creation changed with the introduction of\nGenerative Adversarial Networks (GAN s). Fake media creation has been on the\nrise with the rapid advances in generation technology, leading to new\nchallenges in Detecting fake media. A fundamental characteristic of GAN s is\ntheir sensitivity to parameter initialization, known as seeds. Each distinct\nseed utilized during training leads to the creation of unique model instances,\nresulting in divergent image outputs despite employing the same architecture.\nThis means that even if we have one GAN architecture, it can produce countless\nvariations of GAN models depending on the seed used. Existing methods for\nattributing deepfakes work well only if they have seen the specific GAN model\nduring training. If the GAN architectures are retrained with a different seed,\nthese methods struggle to attribute the fakes. This seed dependency issue made\nit difficult to attribute deepfakes with existing methods. We proposed a\ngeneralized deepfake attribution network (GDA-N et) to attribute fake images to\ntheir respective GAN architectures, even if they are generated from a retrained\nversion of the GAN architecture with a different seed (cross-seed) or from the\nfine-tuned version of the existing GAN model. Extensive experiments on\ncross-seed and fine-tuned data of GAN models show that our method is highly\neffective compared to existing methods. We have provided the source code to\nvalidate our results.\n","authors":["Sowdagar Mahammad Shahid","Sudev Kumar Padhi","Umesh Kashyap","Sk. Subidh Ali"],"pdf_url":"https://arxiv.org/pdf/2406.18278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02311v2","updated":"2024-06-26T11:14:21Z","published":"2024-03-04T18:47:56Z","title":"Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications\n  to Cardiac MRI Segmentation","summary":"  Deep learning (DL)-based methods have achieved state-of-the-art performance\nfor a wide range of medical image segmentation tasks. Nevertheless, recent\nstudies show that deep neural networks (DNNs) can be miscalibrated and\noverconfident, leading to \"silent failures\" that are risky} for clinical\napplications. Bayesian statistics provide an intuitive approach to DL failure\ndetection, based on posterior probability estimation. However, Bayesian DL, and\nin particular the posterior estimation, is intractable for large medical image\nsegmentation DNNs. To tackle this challenge, we propose a Bayesian learning\nframework by Hamiltonian Monte Carlo (HMC), tempered by cold posterior (CP) to\naccommodate medical data augmentation, named HMC-CP. For HMC computation, we\nfurther propose a cyclical annealing strategy, which captures both local and\nglobal geometries of the posterior distribution, enabling highly efficient\nBayesian DNN training with the same computational budget requirements as\ntraining a single DNN. The resulting Bayesian DNN outputs an ensemble\nsegmentation along with the segmentation uncertainty. We evaluate the proposed\nHMC-CP extensively on cardiac magnetic resonance image (MRI) segmentation,\nusing in-domain steady-state free precession (SSFP) cine images as well as\nout-of-domain datasets of quantitative $T_1$ and $T_2$ mapping.\n","authors":["Yidong Zhao","Joao Tourais","Iain Pierce","Christian Nitsche","Thomas A. Treibel","Sebastian Weingärtner","Artur M. Schweidtmann","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2403.02311v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v2","updated":"2024-06-26T10:58:48Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18253v1","updated":"2024-06-26T10:57:52Z","published":"2024-06-26T10:57:52Z","title":"On the Role of Visual Grounding in VQA","summary":"  Visual Grounding (VG) in VQA refers to a model's proclivity to infer answers\nbased on question-relevant image regions. Conceptually, VG identifies as an\naxiomatic requirement of the VQA task. In practice, however, DNN-based VQA\nmodels are notorious for bypassing VG by way of shortcut (SC) learning without\nsuffering obvious performance losses in standard benchmarks. To uncover the\nimpact of SC learning, Out-of-Distribution (OOD) tests have been proposed that\nexpose a lack of VG with low accuracy. These tests have since been at the\ncenter of VG research and served as basis for various investigations into VG's\nimpact on accuracy. However, the role of VG in VQA still remains not fully\nunderstood and has not yet been properly formalized.\n  In this work, we seek to clarify VG's role in VQA by formalizing it on a\nconceptual level. We propose a novel theoretical framework called \"Visually\nGrounded Reasoning\" (VGR) that uses the concepts of VG and Reasoning to\ndescribe VQA inference in ideal OOD testing. By consolidating fundamental\ninsights into VG's role in VQA, VGR helps to reveal rampant VG-related SC\nexploitation in OOD testing, which explains why the relationship between VG and\nOOD accuracy has been difficult to define. Finally, we propose an approach to\ncreate OOD tests that properly emphasize a requirement for VG, and show how to\nimprove performance on them.\n","authors":["Daniel Reich","Tanja Schultz"],"pdf_url":"https://arxiv.org/pdf/2406.18253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16493v3","updated":"2024-06-26T10:51:51Z","published":"2024-04-25T10:38:33Z","title":"Commonsense Prototype for Outdoor Unsupervised 3D Object Detection","summary":"  The prevalent approaches of unsupervised 3D object detection follow\ncluster-based pseudo-label generation and iterative self-training processes.\nHowever, the challenge arises due to the sparsity of LiDAR scans, which leads\nto pseudo-labels with erroneous size and position, resulting in subpar\ndetection performance. To tackle this problem, this paper introduces a\nCommonsense Prototype-based Detector, termed CPD, for unsupervised 3D object\ndetection. CPD first constructs Commonsense Prototype (CProto) characterized by\nhigh-quality bounding box and dense points, based on commonsense intuition.\nSubsequently, CPD refines the low-quality pseudo-labels by leveraging the size\nprior from CProto. Furthermore, CPD enhances the detection accuracy of sparsely\nscanned objects by the geometric knowledge from CProto. CPD outperforms\nstate-of-the-art unsupervised 3D detectors on Waymo Open Dataset (WOD),\nPandaSet, and KITTI datasets by a large margin. Besides, by training CPD on WOD\nand testing on KITTI, CPD attains 90.85% and 81.01% 3D Average Precision on\neasy and moderate car classes, respectively. These achievements position CPD in\nclose proximity to fully supervised detectors, highlighting the significance of\nour method. The code will be available at https://github.com/hailanyi/CPD.\n","authors":["Hai Wu","Shijia Zhao","Xun Huang","Chenglu Wen","Xin Li","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2404.16493v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2406.18249v1","updated":"2024-06-26T10:51:44Z","published":"2024-06-26T10:51:44Z","title":"Foundational Models for Pathology and Endoscopy Images: Application for\n  Gastric Inflammation","summary":"  The integration of artificial intelligence (AI) in medical diagnostics\nrepresents a significant advancement in managing upper gastrointestinal (GI)\ncancer, a major cause of global cancer mortality. Specifically for gastric\ncancer (GC), chronic inflammation causes changes in the mucosa such as atrophy,\nintestinal metaplasia (IM), dysplasia and ultimately cancer. Early detection\nthrough endoscopic regular surveillance is essential for better outcomes.\nFoundation models (FM), which are machine or deep learning models trained on\ndiverse data and applicable to broad use cases, offer a promising solution to\nenhance the accuracy of endoscopy and its subsequent pathology image analysis.\nThis review explores the recent advancements, applications, and challenges\nassociated with FM in endoscopy and pathology imaging. We started by\nelucidating the core principles and architectures underlying these models,\nincluding their training methodologies and the pivotal role of large-scale data\nin developing their predictive capabilities. Moreover, this work discusses\nemerging trends and future research directions, emphasizing the integration of\nmultimodal data, the development of more robust and equitable models, and the\npotential for real-time diagnostic support. This review aims to provide a\nroadmap for researchers and practitioners in navigating the complexities of\nincorporating FM into clinical practice for prevention/management of GC cases,\nthereby improving patient outcomes.\n","authors":["Hamideh Kerdegari","Kyle Higgins","Dennis Veselkov","Ivan Laponogov","Inese Polaka","Miguel Coimbra","Junior Andrea Pescino","Marcis Leja","Mario Dinis-Ribeiro","Tania Fleitas Kanonnikoff","Kirill Veselkov"],"pdf_url":"https://arxiv.org/pdf/2406.18249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18247v1","updated":"2024-06-26T10:49:26Z","published":"2024-06-26T10:49:26Z","title":"Generative artificial intelligence in ophthalmology: multimodal retinal\n  images for the diagnosis of Alzheimer's disease with convolutional neural\n  networks","summary":"  Background/Aim. This study aims to predict Amyloid Positron Emission\nTomography (AmyloidPET) status with multimodal retinal imaging and\nconvolutional neural networks (CNNs) and to improve the performance through\npretraining with synthetic data. Methods. Fundus autofluorescence, optical\ncoherence tomography (OCT), and OCT angiography images from 328 eyes of 59\nAmyloidPET positive subjects and 108 AmyloidPET negative subjects were used for\nclassification. Denoising Diffusion Probabilistic Models (DDPMs) were trained\nto generate synthetic images and unimodal CNNs were pretrained on synthetic\ndata and finetuned on real data or trained solely on real data. Multimodal\nclassifiers were developed to combine predictions of the four unimodal CNNs\nwith patient metadata. Class activation maps of the unimodal classifiers\nprovided insight into the network's attention to inputs. Results. DDPMs\ngenerated diverse, realistic images without memorization. Pretraining unimodal\nCNNs with synthetic data improved AUPR at most from 0.350 to 0.579. Integration\nof metadata in multimodal CNNs improved AUPR from 0.486 to 0.634, which was the\nbest overall best classifier. Class activation maps highlighted relevant\nretinal regions which correlated with AD. Conclusion. Our method for generating\nand leveraging synthetic data has the potential to improve AmyloidPET\nprediction from multimodal retinal imaging. A DDPM can generate realistic and\nunique multimodal synthetic retinal images. Our best performing unimodal and\nmultimodal classifiers were not pretrained on synthetic data, however\npretraining with synthetic data slightly improved classification performance\nfor two out of the four modalities.\n","authors":["I. R. Slootweg","M. Thach","K. R. Curro-Tafili","F. D. Verbraak","F. H. Bouwman","Y. A. L. Pijnenburg","J. F. Boer","J. H. P. de Kwisthout","L. Bagheriye","P. J. González"],"pdf_url":"https://arxiv.org/pdf/2406.18247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18242v1","updated":"2024-06-26T10:46:44Z","published":"2024-06-26T10:46:44Z","title":"ConStyle v2: A Strong Prompter for All-in-One Image Restoration","summary":"  This paper introduces ConStyle v2, a strong plug-and-play prompter designed\nto output clean visual prompts and assist U-Net Image Restoration models in\nhandling multiple degradations. The joint training process of IRConStyle, an\nImage Restoration framework consisting of ConStyle and a general restoration\nnetwork, is divided into two stages: first, pre-training ConStyle alone, and\nthen freezing its weights to guide the training of the general restoration\nnetwork. Three improvements are proposed in the pre-training stage to train\nConStyle: unsupervised pre-training, adding a pretext task (i.e.\nclassification), and adopting knowledge distillation. Without bells and\nwhistles, we can get ConStyle v2, a strong prompter for all-in-one Image\nRestoration, in less than two GPU days and doesn't require any fine-tuning.\nExtensive experiments on Restormer (transformer-based), NAFNet (CNN-based),\nMAXIM-1S (MLP-based), and a vanilla CNN network demonstrate that ConStyle v2\ncan enhance any U-Net style Image Restoration models to all-in-one Image\nRestoration models. Furthermore, models guided by the well-trained ConStyle v2\nexhibit superior performance in some specific degradation compared to ConStyle.\n","authors":["Dongqi Fan","Junhao Zhang","Liang Chang"],"pdf_url":"https://arxiv.org/pdf/2406.18242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05746v3","updated":"2024-06-26T10:44:58Z","published":"2024-02-08T15:26:28Z","title":"Editable Scene Simulation for Autonomous Driving via Collaborative\n  LLM-Agents","summary":"  Scene simulation in autonomous driving has gained significant attention\nbecause of its huge potential for generating customized data. However, existing\neditable scene simulation approaches face limitations in terms of user\ninteraction efficiency, multi-camera photo-realistic rendering and external\ndigital assets integration. To address these challenges, this paper introduces\nChatSim, the first system that enables editable photo-realistic 3D driving\nscene simulations via natural language commands with external digital assets.\nTo enable editing with high command flexibility,~ChatSim leverages a large\nlanguage model (LLM) agent collaboration framework. To generate photo-realistic\noutcomes, ChatSim employs a novel multi-camera neural radiance field method.\nFurthermore, to unleash the potential of extensive high-quality digital assets,\nChatSim employs a novel multi-camera lighting estimation method to achieve\nscene-consistent assets' rendering. Our experiments on Waymo Open Dataset\ndemonstrate that ChatSim can handle complex language commands and generate\ncorresponding photo-realistic scene videos.\n","authors":["Yuxi Wei","Zi Wang","Yifan Lu","Chenxin Xu","Changxing Liu","Hao Zhao","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2402.05746v3.pdf","comment":"CVPR 2024(Highlight)"},{"id":"http://arxiv.org/abs/2406.18240v1","updated":"2024-06-26T10:44:48Z","published":"2024-06-26T10:44:48Z","title":"Concordance in basal cell carcinoma diagnosis. Building a proper ground\n  truth to train Artificial Intelligence tools","summary":"  Background: The existence of different basal cell carcinoma (BCC) clinical\ncriteria cannot be objectively validated. An adequate ground-truth is needed to\ntrain an artificial intelligence (AI) tool that explains the BCC diagnosis by\nproviding its dermoscopic features. Objectives: To determine the consensus\namong dermatologists on dermoscopic criteria of 204 BCC. To analyze the\nperformance of an AI tool when the ground-truth is inferred. Methods: A single\ncenter, diagnostic and prospective study was conducted to analyze the agreement\nin dermoscopic criteria by four dermatologists and then derive a reference\nstandard. 1434 dermoscopic images have been used, that were taken by a primary\nhealth physician, sent via teledermatology, and diagnosed by a dermatologist.\nThey were randomly selected from the teledermatology platform (2019-2021). 204\nof them were tested with an AI tool; the remainder trained it. The performance\nof the AI tool trained using the ground-truth of one dermatologist versus the\nground-truth statistically inferred from the consensus of four dermatologists\nwas analyzed using McNemar's test and Hamming distance. Results: Dermatologists\nachieve perfect agreement in the diagnosis of BCC (Fleiss-Kappa=0.9079), and a\nhigh correlation with the biopsy (PPV=0.9670). However, there is low agreement\nin detecting some dermoscopic criteria. Statistical differences were found in\nthe performance of the AI tool trained using the ground-truth of one\ndermatologist versus the ground-truth statistically inferred from the consensus\nof four dermatologists. Conclusions: Care should be taken when training an AI\ntool to determine the BCC patterns present in a lesion. Ground-truth should be\nestablished from multiple dermatologists.\n","authors":["Francisca Silva-Clavería","Carmen Serrano","Iván Matas","Amalia Serrano","Tomás Toledo-Pastrana","David Moreno-Ramírez","Begoña Acha"],"pdf_url":"https://arxiv.org/pdf/2406.18240v1.pdf","comment":"Manuscript word count: 3000, Number of figures: 2, Number of tables:\n  3"},{"id":"http://arxiv.org/abs/2404.03425v5","updated":"2024-06-26T10:38:29Z","published":"2024-04-04T13:06:25Z","title":"ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State\n  Space Model","summary":"  Convolutional neural networks (CNN) and Transformers have made impressive\nprogress in the field of remote sensing change detection (CD). However, both\narchitectures have inherent shortcomings: CNN are constrained by a limited\nreceptive field that may hinder their ability to capture broader spatial\ncontexts, while Transformers are computationally intensive, making them costly\nto train and deploy on large datasets. Recently, the Mamba architecture, based\non state space models, has shown remarkable performance in a series of natural\nlanguage processing tasks, which can effectively compensate for the\nshortcomings of the above two architectures. In this paper, we explore for the\nfirst time the potential of the Mamba architecture for remote sensing CD tasks.\nWe tailor the corresponding frameworks, called MambaBCD, MambaSCD, and\nMambaBDA, for binary change detection (BCD), semantic change detection (SCD),\nand building damage assessment (BDA), respectively. All three frameworks adopt\nthe cutting-edge Visual Mamba architecture as the encoder, which allows full\nlearning of global spatial contextual information from the input images. For\nthe change decoder, which is available in all three architectures, we propose\nthree spatio-temporal relationship modeling mechanisms, which can be naturally\ncombined with the Mamba architecture and fully utilize its attribute to achieve\nspatio-temporal interaction of multi-temporal features, thereby obtaining\naccurate change information. On five benchmark datasets, our proposed\nframeworks outperform current CNN- and Transformer-based approaches without\nusing any complex training strategies or tricks, fully demonstrating the\npotential of the Mamba architecture in CD tasks. Further experiments show that\nour architecture is quite robust to degraded data. The source code will be\navailable in https://github.com/ChenHongruixuan/MambaCD\n","authors":["Hongruixuan Chen","Jian Song","Chengxi Han","Junshi Xia","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2404.03425v5.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2406.18236v1","updated":"2024-06-26T10:37:02Z","published":"2024-06-26T10:37:02Z","title":"CoDA: Interactive Segmentation and Morphological Analysis of Dendroid\n  Structures Exemplified on Stony Cold-Water Corals","summary":"  Herein, we present CoDA, the Coral Dendroid structure Analyzer, a visual\nanalytics suite that allows for the first time to investigate the ontogenetic\nmorphological development of complex dendroid coral colonies, exemplified on\nthree important framework-forming dendroid cold-water corals: Lophelia pertusa\n(Linnaeus, 1758), Madrepora oculata (Linnaeus, 1758), and Goniocorella dumosa\n(Alcock, 1902). Input to CoDA is an initial instance segmentation of the coral\npolyp cavities (calices), from which it estimates the skeleton tree of the\ncolony and extracts classical morphological measurements and advanced shape\nfeatures of the individual corallites. CoDA also works as a proofreading and\nerror correction tool by helping to identify wrong parts in the skeleton tree\nand providing tools to quickly correct these errors. The final skeleton tree\nenables the derivation of additional information about the calices/corallite\ninstances that otherwise could not be obtained, including their ontogenetic\ngeneration and branching patterns - the basis of a fully quantitative\nstatistical analysis of the coral colony morphology. Part of CoDA is CoDAGraph,\na feature-rich link-and-brush user interface for visualizing the extracted\nfeatures and 2D graph layouts of the skeleton tree, enabling the real-time\nexploration of complex coral colonies and their building blocks, the individual\ncorallites and branches.\n  In the future, we expect CoDA to greatly facilitate the analysis of large\nstony corals of different species and morphotypes, as well as other dendroid\nstructures, enabling new insights into the influence of genetic and\nenvironmental factors on their ontogenetic morphological development.\n","authors":["Kira Schmitt","Jürgen Titschack","Daniel Baum"],"pdf_url":"https://arxiv.org/pdf/2406.18236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02674v3","updated":"2024-06-26T10:31:54Z","published":"2023-10-04T09:26:44Z","title":"ObjFormer: Learning Land-Cover Changes From Paired OSM Data and Optical\n  High-Resolution Imagery via Object-Guided Transformer","summary":"  Optical high-resolution imagery and OSM data are two important data sources\nof change detection (CD). Previous related studies focus on utilizing the\ninformation in OSM data to aid the CD on optical high-resolution images. This\npaper pioneers the direct detection of land-cover changes utilizing paired OSM\ndata and optical imagery, thereby expanding the scope of CD tasks. To this end,\nwe propose an object-guided Transformer (ObjFormer) by naturally combining the\nobject-based image analysis (OBIA) technique with the advanced vision\nTransformer architecture. This combination can significantly reduce the\ncomputational overhead in the self-attention module without adding extra\nparameters or layers. ObjFormer has a hierarchical pseudo-siamese encoder\nconsisting of object-guided self-attention modules that extracts multi-level\nheterogeneous features from OSM data and optical images; a decoder consisting\nof object-guided cross-attention modules can recover land-cover changes from\nthe extracted heterogeneous features. Beyond basic binary change detection,\nthis paper raises a new semi-supervised semantic change detection task that\ndoes not require any manually annotated land-cover labels to train semantic\nchange detectors. Two lightweight semantic decoders are added to ObjFormer to\naccomplish this task efficiently. A converse cross-entropy loss is designed to\nfully utilize negative samples, contributing to the great performance\nimprovement in this task. A large-scale benchmark dataset called OpenMapCD\ncontaining 1,287 samples covering 40 regions on six continents is constructed\nto conduct detailed experiments. The results show the effectiveness of our\nmethods in this new kind of CD task. Additionally, case studies in Japanese\ncities demonstrate the framework's generalizability and practical potential.\nThe OpenMapCD and source code are available in\nhttps://github.com/ChenHongruixuan/ObjFormer\n","authors":["Hongruixuan Chen","Cuiling Lan","Jian Song","Clifford Broni-Bediako","Junshi Xia","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2310.02674v3.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2406.18227v1","updated":"2024-06-26T10:24:00Z","published":"2024-06-26T10:24:00Z","title":"GUIDE: A Guideline-Guided Dataset for Instructional Video Comprehension","summary":"  There are substantial instructional videos on the Internet, which provide us\ntutorials for completing various tasks. Existing instructional video datasets\nonly focus on specific steps at the video level, lacking experiential\nguidelines at the task level, which can lead to beginners struggling to learn\nnew tasks due to the lack of relevant experience. Moreover, the specific steps\nwithout guidelines are trivial and unsystematic, making it difficult to provide\na clear tutorial. To address these problems, we present the GUIDE\n(Guideline-Guided) dataset, which contains 3.5K videos of 560 instructional\ntasks in 8 domains related to our daily life. Specifically, we annotate each\ninstructional task with a guideline, representing a common pattern shared by\nall task-related videos. On this basis, we annotate systematic specific steps,\nincluding their associated guideline steps, specific step descriptions and\ntimestamps. Our proposed benchmark consists of three sub-tasks to evaluate\ncomprehension ability of models: (1) Step Captioning: models have to generate\ncaptions for specific steps from videos. (2) Guideline Summarization: models\nhave to mine the common pattern in task-related videos and summarize a\nguideline from them. (3) Guideline-Guided Captioning: models have to generate\ncaptions for specific steps under the guide of guideline. We evaluate plenty of\nfoundation models with GUIDE and perform in-depth analysis. Given the diversity\nand practicality of GUIDE, we believe that it can be used as a better benchmark\nfor instructional video comprehension.\n","authors":["Jiafeng Liang","Shixin Jiang","Zekun Wang","Haojie Pan","Zerui Chen","Zheng Chu","Ming Liu","Ruiji Fu","Zhongyuan Wang","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2406.18227v1.pdf","comment":"IJCAI 2024"},{"id":"http://arxiv.org/abs/2406.13870v2","updated":"2024-06-26T10:20:11Z","published":"2024-06-19T22:20:03Z","title":"Splatter a Video: Video Gaussian Representation for Versatile Processing","summary":"  Video representation is a long-standing problem that is crucial for various\ndown-stream tasks, such as tracking,depth prediction,segmentation,view\nsynthesis,and editing. However, current methods either struggle to model\ncomplex motions due to the absence of 3D structure or rely on implicit 3D\nrepresentations that are ill-suited for manipulation tasks. To address these\nchallenges, we introduce a novel explicit 3D representation-video Gaussian\nrepresentation -- that embeds a video into 3D Gaussians. Our proposed\nrepresentation models video appearance in a 3D canonical space using explicit\nGaussians as proxies and associates each Gaussian with 3D motions for video\nmotion. This approach offers a more intrinsic and explicit representation than\nlayered atlas or volumetric pixel matrices. To obtain such a representation, we\ndistill 2D priors, such as optical flow and depth, from foundation models to\nregularize learning in this ill-posed setting. Extensive applications\ndemonstrate the versatility of our new video representation. It has been proven\neffective in numerous video processing tasks, including tracking, consistent\nvideo depth and feature refinement, motion and appearance editing, and\nstereoscopic video generation. Project page:\nhttps://sunyangtian.github.io/spatter_a_video_web/\n","authors":["Yang-Tian Sun","Yi-Hua Huang","Lin Ma","Xiaoyang Lyu","Yan-Pei Cao","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2406.13870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02000v3","updated":"2024-06-26T10:17:08Z","published":"2022-09-05T14:57:03Z","title":"Visual Odometry with Neuromorphic Resonator Networks","summary":"  Visual Odometry (VO) is a method to estimate self-motion of a mobile robot\nusing visual sensors. Unlike odometry based on integrating differential\nmeasurements that can accumulate errors, such as inertial sensors or wheel\nencoders, visual odometry is not compromised by drift. However, image-based VO\nis computationally demanding, limiting its application in use cases with\nlow-latency, -memory, and -energy requirements. Neuromorphic hardware offers\nlow-power solutions to many vision and AI problems, but designing such\nsolutions is complicated and often has to be assembled from scratch. Here we\npropose to use Vector Symbolic Architecture (VSA) as an abstraction layer to\ndesign algorithms compatible with neuromorphic hardware. Building from a VSA\nmodel for scene analysis, described in our companion paper, we present a\nmodular neuromorphic algorithm that achieves state-of-the-art performance on\ntwo-dimensional VO tasks. Specifically, the proposed algorithm stores and\nupdates a working memory of the presented visual environment. Based on this\nworking memory, a resonator network estimates the changing location and\norientation of the camera. We experimentally validate the neuromorphic\nVSA-based approach to VO with two benchmarks: one based on an event camera\ndataset and the other in a dynamic scene with a robotic task.\n","authors":["Alpha Renner","Lazar Supic","Andreea Danielescu","Giacomo Indiveri","E. Paxon Frady","Friedrich T. Sommer","Yulia Sandamirskaya"],"pdf_url":"https://arxiv.org/pdf/2209.02000v3.pdf","comment":"19 pages, 5 figures, minor revisions, added results for\n  shapes_translation dataset"},{"id":"http://arxiv.org/abs/2208.12880v4","updated":"2024-06-26T10:16:08Z","published":"2022-08-26T22:17:52Z","title":"Neuromorphic Visual Scene Understanding with Resonator Networks","summary":"  Analyzing a visual scene by inferring the configuration of a generative model\nis widely considered the most flexible and generalizable approach to scene\nunderstanding. Yet, one major problem is the computational challenge of the\ninference procedure, involving a combinatorial search across object identities\nand poses. Here we propose a neuromorphic solution exploiting three key\nconcepts: (1) a computational framework based on Vector Symbolic Architectures\n(VSA) with complex-valued vectors; (2) the design of Hierarchical Resonator\nNetworks (HRN) to factorize the non-commutative transforms translation and\nrotation in visual scenes; (3) the design of a multi-compartment spiking phasor\nneuron model for implementing complex-valued resonator networks on neuromorphic\nhardware. The VSA framework uses vector binding operations to form a generative\nimage model in which binding acts as the equivariant operation for geometric\ntransformations. A scene can, therefore, be described as a sum of vector\nproducts, which can then be efficiently factorized by a resonator network to\ninfer objects and their poses. The HRN features a partitioned architecture in\nwhich vector binding is equivariant for horizontal and vertical translation\nwithin one partition and for rotation and scaling within the other partition.\nThe spiking neuron model allows mapping the resonator network onto efficient\nand low-power neuromorphic hardware. Our approach is demonstrated on synthetic\nscenes composed of simple 2D shapes undergoing rigid geometric transformations\nand color changes. A companion paper demonstrates the same approach in\nreal-world application scenarios for machine vision and robotics.\n","authors":["Alpha Renner","Lazar Supic","Andreea Danielescu","Giacomo Indiveri","Bruno A. Olshausen","Yulia Sandamirskaya","Friedrich T. Sommer","E. Paxon Frady"],"pdf_url":"https://arxiv.org/pdf/2208.12880v4.pdf","comment":"23 pages, 8 figures, minor revisions and extended supplementary\n  material"},{"id":"http://arxiv.org/abs/2406.18220v1","updated":"2024-06-26T10:08:24Z","published":"2024-06-26T10:08:24Z","title":"Guiding Video Prediction with Explicit Procedural Knowledge","summary":"  We propose a general way to integrate procedural knowledge of a domain into\ndeep learning models. We apply it to the case of video prediction, building on\ntop of object-centric deep models and show that this leads to a better\nperformance than using data-driven models alone. We develop an architecture\nthat facilitates latent space disentanglement in order to use the integrated\nprocedural knowledge, and establish a setup that allows the model to learn the\nprocedural interface in the latent space using the downstream task of video\nprediction. We contrast the performance to a state-of-the-art data-driven\napproach and show that problems where purely data-driven approaches struggle\ncan be handled by using knowledge about the domain, providing an alternative to\nsimply collecting more data.\n","authors":["Patrick Takenaka","Johannes Maucher","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2406.18220v1.pdf","comment":"Published in 2023 IEEE/CVF International Conference on Computer\n  Vision Workshops (ICCVW)"},{"id":"http://arxiv.org/abs/2406.18215v1","updated":"2024-06-26T09:58:05Z","published":"2024-06-26T09:58:05Z","title":"Unlocking the Potential of Operations Research for Multi-Graph Matching","summary":"  We consider the incomplete multi-graph matching problem, which is a\ngeneralization of the NP-hard quadratic assignment problem for matching\nmultiple finite sets. Multi-graph matching plays a central role in computer\nvision, e.g., for matching images or shapes, so that a number of dedicated\noptimization techniques have been proposed. While the closely related NP-hard\nmulti-dimensional assignment problem (MDAP) has been studied for decades in the\noperations research community, it only considers complete matchings and has a\ndifferent cost structure. We bridge this gap and transfer well-known\napproximation algorithms for the MDAP to incomplete multi-graph matching. To\nthis end, we revisit respective algorithms, adapt them to incomplete\nmulti-graph matching, and propose their extended and parallelized versions. Our\nexperimental validation shows that our new method substantially outperforms the\nprevious state of the art in terms of objective and runtime. Our algorithm\nmatches, for example, 29 images with more than 500 keypoints each in less than\ntwo minutes, whereas the fastest considered competitor requires at least half\nan hour while producing far worse results.\n","authors":["Max Kahl","Sebastian Stricker","Lisa Hutschenreiter","Florian Bernard","Bogdan Savchynskyy"],"pdf_url":"https://arxiv.org/pdf/2406.18215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18214v1","updated":"2024-06-26T09:57:55Z","published":"2024-06-26T09:57:55Z","title":"Trimming the Fat: Efficient Compression of 3D Gaussian Splats through\n  Pruning","summary":"  In recent times, the utilization of 3D models has gained traction, owing to\nthe capacity for end-to-end training initially offered by Neural Radiance\nFields and more recently by 3D Gaussian Splatting (3DGS) models. The latter\nholds a significant advantage by inherently easing rapid convergence during\ntraining and offering extensive editability. However, despite rapid\nadvancements, the literature still lives in its infancy regarding the\nscalability of these models. In this study, we take some initial steps in\naddressing this gap, showing an approach that enables both the memory and\ncomputational scalability of such models. Specifically, we propose \"Trimming\nthe fat\", a post-hoc gradient-informed iterative pruning technique to eliminate\nredundant information encoded in the model. Our experimental findings on widely\nacknowledged benchmarks attest to the effectiveness of our approach, revealing\nthat up to 75% of the Gaussians can be removed while maintaining or even\nimproving upon baseline performance. Our approach achieves around 50$\\times$\ncompression while preserving performance similar to the baseline model, and is\nable to speed-up computation up to 600~FPS.\n","authors":["Muhammad Salman Ali","Maryam Qamar","Sung-Ho Bae","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2406.18214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18212v1","updated":"2024-06-26T09:56:29Z","published":"2024-06-26T09:56:29Z","title":"Joint Stream: Malignant Region Learning for Breast Cancer Diagnosis","summary":"  Early diagnosis of breast cancer (BC) significantly contributes to reducing\nthe mortality rate worldwide. The detection of different factors and biomarkers\nsuch as Estrogen receptor (ER), Progesterone receptor (PR), Human epidermal\ngrowth factor receptor 2 (HER2) gene, Histological grade (HG), Auxiliary lymph\nnode (ALN) status, and Molecular subtype (MS) can play a significant role in\nimproved BC diagnosis. However, the existing methods predict only a single\nfactor which makes them less suitable to use in diagnosis and designing a\nstrategy for treatment. In this paper, we propose to classify the six essential\nindicating factors (ER, PR, HER2, ALN, HG, MS) for early BC diagnosis using\nH\\&E stained WSI's. To precisely capture local neighboring relationships, we\nuse spatial and frequency domain information from the large patch size of WSI's\nmalignant regions. Furthermore, to cater the variable number of regions of\ninterest sizes and give due attention to each region, we propose a malignant\nregion learning attention network. Our experimental results demonstrate that\ncombining spatial and frequency information using the malignant region learning\nmodule significantly improves multi-factor and single-factor classification\nperformance on publicly available datasets.\n","authors":["Abdul Rehman","Sarfaraz Hussein","Waqas Sultani"],"pdf_url":"https://arxiv.org/pdf/2406.18212v1.pdf","comment":"Under Review (Biomedical Signal Processing and Control)"},{"id":"http://arxiv.org/abs/2406.17536v2","updated":"2024-06-26T09:52:47Z","published":"2024-06-25T13:20:39Z","title":"MedMNIST-C: Comprehensive benchmark and improved classifier robustness\n  by simulating realistic image corruptions","summary":"  The integration of neural-network-based systems into clinical practice is\nlimited by challenges related to domain generalization and robustness. The\ncomputer vision community established benchmarks such as ImageNet-C as a\nfundamental prerequisite to measure progress towards those challenges. Similar\ndatasets are largely absent in the medical imaging community which lacks a\ncomprehensive benchmark that spans across imaging modalities and applications.\nTo address this gap, we create and open-source MedMNIST-C, a benchmark dataset\nbased on the MedMNIST+ collection covering 12 datasets and 9 imaging\nmodalities. We simulate task and modality-specific image corruptions of varying\nseverity to comprehensively evaluate the robustness of established algorithms\nagainst real-world artifacts and distribution shifts. We further provide\nquantitative evidence that our simple-to-use artificial corruptions allow for\nhighly performant, lightweight data augmentation to enhance model robustness.\nUnlike traditional, generic augmentation strategies, our approach leverages\ndomain knowledge, exhibiting significantly higher robustness when compared to\nwidely adopted methods. By introducing MedMNIST-C and open-sourcing the\ncorresponding library allowing for targeted data augmentations, we contribute\nto the development of increasingly robust methods tailored to the challenges of\nmedical imaging. The code is available at\nhttps://github.com/francescodisalvo05/medmnistc-api}{github.com/francescodisalvo05/medmnistc-api .\n","authors":["Francesco Di Salvo","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2406.17536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18201v1","updated":"2024-06-26T09:33:51Z","published":"2024-06-26T09:33:51Z","title":"EFCNet: Every Feature Counts for Small Medical Object Segmentation","summary":"  This paper explores the segmentation of very small medical objects with\nsignificant clinical value. While Convolutional Neural Networks (CNNs),\nparticularly UNet-like models, and recent Transformers have shown substantial\nprogress in image segmentation, our empirical findings reveal their poor\nperformance in segmenting the small medical objects and lesions concerned in\nthis paper. This limitation may be attributed to information loss during their\nencoding and decoding process. In response to this challenge, we propose a\nnovel model named EFCNet for small object segmentation in medical images. Our\nmodel incorporates two modules: the Cross-Stage Axial Attention Module (CSAA)\nand the Multi-Precision Supervision Module (MPS). These modules address\ninformation loss during encoding and decoding procedures, respectively.\nSpecifically, CSAA integrates features from all stages of the encoder to\nadaptively learn suitable information needed in different decoding stages,\nthereby reducing information loss in the encoder. On the other hand, MPS\nintroduces a novel multi-precision supervision mechanism to the decoder. This\nmechanism prioritizes attention to low-resolution features in the initial\nstages of the decoder, mitigating information loss caused by subsequent\nconvolution and sampling processes and enhancing the model's global perception.\nWe evaluate our model on two benchmark medical image datasets. The results\ndemonstrate that EFCNet significantly outperforms previous segmentation methods\ndesigned for both medical and normal images.\n","authors":["Lingjie Kong","Qiaoling Wei","Chengming Xu","Han Chen","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2406.18201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18199v1","updated":"2024-06-26T09:29:56Z","published":"2024-06-26T09:29:56Z","title":"GS-Octree: Octree-based 3D Gaussian Splatting for Robust Object-level 3D\n  Reconstruction Under Strong Lighting","summary":"  The 3D Gaussian Splatting technique has significantly advanced the\nconstruction of radiance fields from multi-view images, enabling real-time\nrendering. While point-based rasterization effectively reduces computational\ndemands for rendering, it often struggles to accurately reconstruct the\ngeometry of the target object, especially under strong lighting. To address\nthis challenge, we introduce a novel approach that combines octree-based\nimplicit surface representations with Gaussian splatting. Our method consists\nof four stages. Initially, it reconstructs a signed distance field (SDF) and a\nradiance field through volume rendering, encoding them in a low-resolution\noctree. The initial SDF represents the coarse geometry of the target object.\nSubsequently, it introduces 3D Gaussians as additional degrees of freedom,\nwhich are guided by the SDF. In the third stage, the optimized Gaussians\nfurther improve the accuracy of the SDF, allowing it to recover finer geometric\ndetails compared to the initial SDF obtained in the first stage. Finally, it\nadopts the refined SDF to further optimize the 3D Gaussians via splatting,\neliminating those that contribute little to visual appearance. Experimental\nresults show that our method, which leverages the distribution of 3D Gaussians\nwith SDFs, reconstructs more accurate geometry, particularly in images with\nspecular highlights caused by strong lighting.\n","authors":["Jiaze Li","Zhengyu Wen","Luo Zhang","Jiangbei Hu","Fei Hou","Zhebin Zhang","Ying He"],"pdf_url":"https://arxiv.org/pdf/2406.18199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18198v1","updated":"2024-06-26T09:29:21Z","published":"2024-06-26T09:29:21Z","title":"VDG: Vision-Only Dynamic Gaussian for Driving Simulation","summary":"  Dynamic Gaussian splatting has led to impressive scene reconstruction and\nimage synthesis advances in novel views. Existing methods, however, heavily\nrely on pre-computed poses and Gaussian initialization by Structure from Motion\n(SfM) algorithms or expensive sensors. For the first time, this paper addresses\nthis issue by integrating self-supervised VO into our pose-free dynamic\nGaussian method (VDG) to boost pose and depth initialization and static-dynamic\ndecomposition. Moreover, VDG can work with only RGB image input and construct\ndynamic scenes at a faster speed and larger scenes compared with the pose-free\ndynamic view-synthesis method. We demonstrate the robustness of our approach\nvia extensive quantitative and qualitative experiments. Our results show\nfavorable performance over the state-of-the-art dynamic view synthesis methods.\nAdditional video and source code will be posted on our project page at\nhttps://3d-aigc.github.io/VDG.\n","authors":["Hao Li","Jingfeng Li","Dingwen Zhang","Chenming Wu","Jieqi Shi","Chen Zhao","Haocheng Feng","Errui Ding","Jingdong Wang","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2406.18198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18197v1","updated":"2024-06-26T09:29:05Z","published":"2024-06-26T09:29:05Z","title":"Human-free Prompted Based Anomaly Detection: prompt optimization with\n  Meta-guiding prompt scheme","summary":"  Pre-trained vision-language models (VLMs) are highly adaptable to various\ndownstream tasks through few-shot learning, making prompt-based anomaly\ndetection a promising approach. Traditional methods depend on human-crafted\nprompts that require prior knowledge of specific anomaly types. Our goal is to\ndevelop a human-free prompt-based anomaly detection framework that optimally\nlearns prompts through data-driven methods, eliminating the need for human\nintervention. The primary challenge in this approach is the lack of anomalous\nsamples during the training phase. Additionally, the Vision Transformer\n(ViT)-based image encoder in VLMs is not ideal for pixel-wise anomaly\nsegmentation due to a locality feature mismatch between the original image and\nthe output feature map. To tackle the first challenge, we have developed the\nObject-Attention Anomaly Generation Module (OAGM) to synthesize anomaly samples\nfor training. Furthermore, our Meta-Guiding Prompt-Tuning Scheme (MPTS)\niteratively adjusts the gradient-based optimization direction of learnable\nprompts to avoid overfitting to the synthesized anomalies. For the second\nchallenge, we propose Locality-Aware Attention, which ensures that each local\npatch feature attends only to nearby patch features, preserving the locality\nfeatures corresponding to their original locations. This framework allows for\nthe optimal prompt embeddings by searching in the continuous latent space via\nbackpropagation, free from human semantic constraints. Additionally, the\nmodified locality-aware attention improves the precision of pixel-wise anomaly\nsegmentation.\n","authors":["Pi-Wei Chen","Jerry Chun-Wei Lin","Jia Ji","Feng-Hao Yeh","Chao-Chun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18193v1","updated":"2024-06-26T09:17:27Z","published":"2024-06-26T09:17:27Z","title":"MammothModa: Multi-Modal Large Language Model","summary":"  In this report, we introduce MammothModa, yet another multi-modal large\nlanguage model (MLLM) designed to achieve state-of-the-art performance starting\nfrom an elementary baseline. We focus on three key design insights: (i)\nIntegrating Visual Capabilities while Maintaining Complex Language\nUnderstanding: In addition to the vision encoder, we incorporated the Visual\nAttention Experts into the LLM to enhance its visual capabilities. (ii)\nExtending Context Window for High-Resolution and Long-Duration Visual Feature:\nWe explore the Visual Merger Module to effectively reduce the token number of\nhigh-resolution images and incorporated frame position ids to avoid position\ninterpolation. (iii) High-Quality Bilingual Datasets: We meticulously curated\nand filtered a high-quality bilingual multimodal dataset to reduce visual\nhallucinations. With above recipe we build MammothModa that consistently\noutperforms the state-of-the-art models, e.g., LLaVA-series, across main\nreal-world visual language benchmarks without bells and whistles.\n","authors":["Qi She","Junwen Pan","Xin Wan","Rui Zhang","Dawei Lu","Kai Huang"],"pdf_url":"https://arxiv.org/pdf/2406.18193v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.16901v2","updated":"2024-06-26T08:54:40Z","published":"2024-05-31T15:17:12Z","title":"ECGrecover: a Deep Learning Approach for Electrocardiogram Signal\n  Completion","summary":"  In this work, we address the challenge of reconstructing the complete 12-lead\nECG signal from incomplete parts of it. We focus on two main scenarii: (i)\nreconstructing missing signal segments within an ECG lead and (ii) recovering\nmissing leads from a single-lead. We propose a model with a U-Net architecture\ntrained on a novel objective function to address the reconstruction problem.\nThis function incorporates both spatial and temporal aspects of the ECG by\ncombining the distance in amplitude between the reconstructed and real signals\nwith the signal trend. Through comprehensive assessments using both a real-life\ndataset and a publicly accessible one, we demonstrate that the proposed\napproach consistently outperforms state-of-the-art methods based on generative\nadversarial networks and a CopyPaste strategy. Our proposed model demonstrates\nsuperior performance in standard distortion metrics and preserves critical ECG\ncharacteristics, particularly the P, Q, R, S, and T wave coordinates. Two\nemerging clinical applications emphasize the relevance of our work. The first\nis the increasing need to digitize paper-stored ECGs for utilization in\nAI-based applications (automatic annotation and risk-quantification), often\nlimited to digital ECG complete 10s recordings. The second is the widespread\nuse of wearable devices that record ECGs but typically capture only a small\nsubset of the 12 standard leads. In both cases, a non-negligible amount of\ninformation is lost or not recorded, which our approach aims to recover to\novercome these limitations.\n","authors":["Alex Lence","Ahmad Fall","Federica Granese","Blaise Hanczar","Joe-Elie Salem","Jean-Daniel Zucker","Edi Prifti"],"pdf_url":"https://arxiv.org/pdf/2406.16901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18176v1","updated":"2024-06-26T08:50:51Z","published":"2024-06-26T08:50:51Z","title":"VIPriors 4: Visual Inductive Priors for Data-Efficient Deep Learning\n  Challenges","summary":"  The fourth edition of the \"VIPriors: Visual Inductive Priors for\nData-Efficient Deep Learning\" workshop features two data-impaired challenges.\nThese challenges address the problem of training deep learning models for\ncomputer vision tasks with limited data. Participants are limited to training\nmodels from scratch using a low number of training samples and are not allowed\nto use any form of transfer learning. We aim to stimulate the development of\nnovel approaches that incorporate inductive biases to improve the data\nefficiency of deep learning models. Significant advancements are made compared\nto the provided baselines, where winning solutions surpass the baselines by a\nconsiderable margin in both tasks. As in previous editions, these achievements\nare primarily attributed to heavy use of data augmentation policies and large\nmodel ensembles, though novel prior-based methods seem to contribute more to\nsuccessful solutions compared to last year. This report highlights the key\naspects of the challenges and their outcomes.\n","authors":["Robert-Jan Bruintjes","Attila Lengyel","Marcos Baptista Rios","Osman Semih Kayhan","Davide Zambrano","Nergis Tomen","Jan van Gemert"],"pdf_url":"https://arxiv.org/pdf/2406.18176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05119v2","updated":"2024-06-26T08:25:49Z","published":"2023-02-10T08:49:36Z","title":"Fast Learnings of Coupled Nonnegative Tensor Decomposition Using Optimal\n  Gradient and Low-rank Approximation","summary":"  Tensor decomposition is a fundamental technique widely applied in signal\nprocessing, machine learning, and various other fields. However, traditional\ntensor decomposition methods encounter limitations when jointly analyzing\nmulti-block tensors, as they often struggle to effectively explore shared\ninformation among tensors. In this study, we first introduce a novel coupled\nnonnegative CANDECOMP/PARAFAC decomposition algorithm optimized by the\nalternating proximal gradient method (CoNCPD-APG). This algorithm is specially\ndesigned to address the challenges of jointly decomposing different tensors\nthat are partially or fully linked, while simultaneously extracting common\ncomponents, individual components and, core tensors. Recognizing the\ncomputational challenges inherent in optimizing nonnegative constraints over\nhigh-dimensional tensor data, we further propose the lraCoNCPD-APG algorithm.\nBy integrating low-rank approximation with the proposed CoNCPD-APG method, the\nproposed algorithm can significantly decrease the computational burden without\ncompromising decomposition quality, particularly for multi-block large-scale\ntensors. Simulation experiments conducted on synthetic data, real-world face\nimage data, and two kinds of electroencephalography (EEG) data demonstrate the\npracticality and superiority of the proposed algorithms for coupled nonnegative\ntensor decomposition problems. Our results underscore the efficacy of our\nmethods in uncovering meaningful patterns and structures from complex\nmulti-block tensor data, thereby offering valuable insights for future\napplications.\n","authors":["Xiulin Wang","Jing Liu","Fengyu Cong"],"pdf_url":"https://arxiv.org/pdf/2302.05119v2.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.08861v2","updated":"2024-06-26T08:22:31Z","published":"2023-10-13T05:08:35Z","title":"Re-initialization-free Level Set Method via Molecular Beam Epitaxy\n  Equation Regularization for Image Segmentation","summary":"  Variational level set method has become a powerful tool in image segmentation\ndue to its ability to handle complex topological changes and maintain\ncontinuity and smoothness in the process of evolution. However its evolution\nprocess can be unstable, which results in over flatted or over sharpened\ncontours and segmentation failure. To improve the accuracy and stability of\nevolution, we propose a high-order level set variational segmentation method\nintegrated with molecular beam epitaxy (MBE) equation regularization. This\nmethod uses the crystal growth in the MBE process to limit the evolution of the\nlevel set function, and thus can avoid the re-initialization in the evolution\nprocess and regulate the smoothness of the segmented curve. It also works for\nnoisy images with intensity inhomogeneity, which is a challenge in image\nsegmentation. To solve the variational model, we derive the gradient flow and\ndesign scalar auxiliary variable (SAV) scheme coupled with fast Fourier\ntransform (FFT), which can significantly improve the computational efficiency\ncompared with the traditional semi-implicit and semi-explicit scheme. Numerical\nexperiments show that the proposed method can generate smooth segmentation\ncurves, retain fine segmentation targets and obtain robust segmentation results\nof small objects. Compared to existing level set methods, this model is\nstate-of-the-art in both accuracy and efficiency.\n","authors":["Fanghui Song","Jiebao Sun","Shengzhu Shi","Zhichang Guo","Dazhi Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.08861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18159v1","updated":"2024-06-26T08:18:39Z","published":"2024-06-26T08:18:39Z","title":"Human-Aware 3D Scene Generation with Spatially-constrained Diffusion\n  Models","summary":"  Generating 3D scenes from human motion sequences supports numerous\napplications, including virtual reality and architectural design. However,\nprevious auto-regression-based human-aware 3D scene generation methods have\nstruggled to accurately capture the joint distribution of multiple objects and\ninput humans, often resulting in overlapping object generation in the same\nspace. To address this limitation, we explore the potential of diffusion models\nthat simultaneously consider all input humans and the floor plan to generate\nplausible 3D scenes. Our approach not only satisfies all input human\ninteractions but also adheres to spatial constraints with the floor plan.\nFurthermore, we introduce two spatial collision guidance mechanisms:\nhuman-object collision avoidance and object-room boundary constraints. These\nmechanisms help avoid generating scenes that conflict with human motions while\nrespecting layout constraints. To enhance the diversity and accuracy of\nhuman-guided scene generation, we have developed an automated pipeline that\nimproves the variety and plausibility of human-object interactions in the\nexisting 3D FRONT HUMAN dataset. Extensive experiments on both synthetic and\nreal-world datasets demonstrate that our framework can generate more natural\nand plausible 3D scenes with precise human-scene interactions, while\nsignificantly reducing human-object collisions compared to previous\nstate-of-the-art methods. Our code and data will be made publicly available\nupon publication of this work.\n","authors":["Xiaolin Hong","Hongwei Yi","Fazhi He","Qiong Cao"],"pdf_url":"https://arxiv.org/pdf/2406.18159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18158v1","updated":"2024-06-26T08:17:59Z","published":"2024-06-26T08:17:59Z","title":"3D-MVP: 3D Multiview Pretraining for Robotic Manipulation","summary":"  Recent works have shown that visual pretraining on egocentric datasets using\nmasked autoencoders (MAE) can improve generalization for downstream robotics\ntasks. However, these approaches pretrain only on 2D images, while many\nrobotics applications require 3D scene understanding. In this work, we propose\n3D-MVP, a novel approach for 3D multi-view pretraining using masked\nautoencoders. We leverage Robotic View Transformer (RVT), which uses a\nmulti-view transformer to understand the 3D scene and predict gripper pose\nactions. We split RVT's multi-view transformer into visual encoder and action\ndecoder, and pretrain its visual encoder using masked autoencoding on\nlarge-scale 3D datasets such as Objaverse. We evaluate 3D-MVP on a suite of\nvirtual robot manipulation tasks and demonstrate improved performance over\nbaselines. We also show promising results on a real robot platform with minimal\nfinetuning. Our results suggest that 3D-aware pretraining is a promising\napproach to improve sample efficiency and generalization of vision-based\nrobotic manipulation policies. We will release code and pretrained models for\n3D-MVP to facilitate future research. Project site:\nhttps://jasonqsy.github.io/3DMVP\n","authors":["Shengyi Qian","Kaichun Mo","Valts Blukis","David F. Fouhey","Dieter Fox","Ankit Goyal"],"pdf_url":"https://arxiv.org/pdf/2406.18158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05404v3","updated":"2024-06-26T08:10:43Z","published":"2023-08-10T07:53:06Z","title":"Enhancing Low-light Light Field Images with A Deep Compensation\n  Unfolding Network","summary":"  This paper presents a novel and interpretable end-to-end learning framework,\ncalled the deep compensation unfolding network (DCUNet), for restoring light\nfield (LF) images captured under low-light conditions. DCUNet is designed with\na multi-stage architecture that mimics the optimization process of solving an\ninverse imaging problem in a data-driven fashion. The framework uses the\nintermediate enhanced result to estimate the illumination map, which is then\nemployed in the unfolding process to produce a new enhanced result.\nAdditionally, DCUNet includes a content-associated deep compensation module at\neach optimization stage to suppress noise and illumination map estimation\nerrors. To properly mine and leverage the unique characteristics of LF images,\nthis paper proposes a pseudo-explicit feature interaction module that\ncomprehensively exploits redundant information in LF images. The experimental\nresults on both simulated and real datasets demonstrate the superiority of our\nDCUNet over state-of-the-art methods, both qualitatively and quantitatively.\nMoreover, DCUNet preserves the essential geometric structure of enhanced LF\nimages much better. The code will be publicly available at\nhttps://github.com/lyuxianqiang/LFLL-DCU.\n","authors":["Xianqiang Lyu","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2308.05404v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18151v1","updated":"2024-06-26T08:04:42Z","published":"2024-06-26T08:04:42Z","title":"SynRS3D: A Synthetic Dataset for Global 3D Semantic Understanding from\n  Monocular Remote Sensing Imagery","summary":"  Global semantic 3D understanding from single-view high-resolution remote\nsensing (RS) imagery is crucial for Earth Observation (EO). However, this task\nfaces significant challenges due to the high costs of annotations and data\ncollection, as well as geographically restricted data availability. To address\nthese challenges, synthetic data offer a promising solution by being easily\naccessible and thus enabling the provision of large and diverse datasets. We\ndevelop a specialized synthetic data generation pipeline for EO and introduce\nSynRS3D, the largest synthetic RS 3D dataset. SynRS3D comprises 69,667\nhigh-resolution optical images that cover six different city styles worldwide\nand feature eight land cover types, precise height information, and building\nchange masks. To further enhance its utility, we develop a novel multi-task\nunsupervised domain adaptation (UDA) method, RS3DAda, coupled with our\nsynthetic dataset, which facilitates the RS-specific transition from synthetic\nto real scenarios for land cover mapping and height estimation tasks,\nultimately enabling global monocular 3D semantic understanding based on\nsynthetic data. Extensive experiments on various real-world datasets\ndemonstrate the adaptability and effectiveness of our synthetic dataset and\nproposed RS3DAda method. SynRS3D and related codes will be available.\n","authors":["Jian Song","Hongruixuan Chen","Weihao Xuan","Junshi Xia","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2406.18151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05935v2","updated":"2024-06-26T07:59:03Z","published":"2024-02-08T18:59:48Z","title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large\n  Language Models","summary":"  We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory\n","authors":["Dongyang Liu","Renrui Zhang","Longtian Qiu","Siyuan Huang","Weifeng Lin","Shitian Zhao","Shijie Geng","Ziyi Lin","Peng Jin","Kaipeng Zhang","Wenqi Shao","Chao Xu","Conghui He","Junjun He","Hao Shao","Pan Lu","Hongsheng Li","Yu Qiao","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2402.05935v2.pdf","comment":"Accepted by ICML 2024. Code and models are released at\n  https://github.com/Alpha-VLLM/LLaMA2-Accessory"},{"id":"http://arxiv.org/abs/2406.18146v1","updated":"2024-06-26T07:56:17Z","published":"2024-06-26T07:56:17Z","title":"A Refer-and-Ground Multimodal Large Language Model for Biomedicine","summary":"  With the rapid development of multimodal large language models (MLLMs),\nespecially their capabilities in visual chat through refer and ground\nfunctionalities, their significance is increasingly recognized. However, the\nbiomedical field currently exhibits a substantial gap in this area, primarily\ndue to the absence of a dedicated refer and ground dataset for biomedical\nimages. To address this challenge, we devised the Med-GRIT-270k dataset. It\ncomprises 270k question-and-answer pairs and spans eight distinct medical\nimaging modalities. Most importantly, it is the first dedicated to the\nbiomedical domain and integrating refer and ground conversations. The key idea\nis to sample large-scale biomedical image-mask pairs from medical segmentation\ndatasets and generate instruction datasets from text using chatGPT.\nAdditionally, we introduce a Refer-and-Ground Multimodal Large Language Model\nfor Biomedicine (BiRD) by using this dataset and multi-task instruction\nlearning. Extensive experiments have corroborated the efficacy of the\nMed-GRIT-270k dataset and the multi-modal, fine-grained interactive\ncapabilities of the BiRD model. This holds significant reference value for the\nexploration and development of intelligent biomedical assistants.\n","authors":["Xiaoshuang Huang","Haifeng Huang","Lingdong Shen","Yehui Yang","Fangxin Shang","Junwei Liu","Jia Liu"],"pdf_url":"https://arxiv.org/pdf/2406.18146v1.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2406.18144v1","updated":"2024-06-26T07:50:58Z","published":"2024-06-26T07:50:58Z","title":"Artificial Immune System of Secure Face Recognition Against Adversarial\n  Attacks","summary":"  Insect production for food and feed presents a promising supplement to ensure\nfood safety and address the adverse impacts of agriculture on climate and\nenvironment in the future. However, optimisation is required for insect\nproduction to realise its full potential. This can be by targeted improvement\nof traits of interest through selective breeding, an approach which has so far\nbeen underexplored and underutilised in insect farming. Here we present a\ncomprehensive review of the selective breeding framework in the context of\ninsect production. We systematically evaluate adjustments of selective breeding\ntechniques to the realm of insects and highlight the essential components\nintegral to the breeding process. The discussion covers every step of a\nconventional breeding scheme, such as formulation of breeding objectives,\nphenotyping, estimation of genetic parameters and breeding values, selection of\nappropriate breeding strategies, and mitigation of issues associated with\ngenetic diversity depletion and inbreeding. This review combines knowledge from\ndiverse disciplines, bridging the gap between animal breeding, quantitative\ngenetics, evolutionary biology, and entomology, offering an integrated view of\nthe insect breeding research area and uniting knowledge which has previously\nremained scattered across diverse fields of expertise.\n","authors":["Min Ren","Yunlong Wang","Yuhao Zhu","Yongzhen Huang","Zhenan Sun","Qi Li","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.18144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18140v1","updated":"2024-06-26T07:44:27Z","published":"2024-06-26T07:44:27Z","title":"Exclusive Style Removal for Cross Domain Novel Class Discovery","summary":"  As a promising field in open-world learning, \\textit{Novel Class Discovery}\n(NCD) is usually a task to cluster unseen novel classes in an unlabeled set\nbased on the prior knowledge of labeled data within the same domain. However,\nthe performance of existing NCD methods could be severely compromised when\nnovel classes are sampled from a different distribution with the labeled ones.\nIn this paper, we explore and establish the solvability of NCD in cross domain\nsetting with the necessary condition that style information must be removed.\nBased on the theoretical analysis, we introduce an exclusive style removal\nmodule for extracting style information that is distinctive from the baseline\nfeatures, thereby facilitating inference. Moreover, this module is easy to\nintegrate with other NCD methods, acting as a plug-in to improve performance on\nnovel classes with different distributions compared to the seen labeled set.\nAdditionally, recognizing the non-negligible influence of different backbones\nand pre-training strategies on the performance of the NCD methods, we build a\nfair benchmark for future NCD research. Extensive experiments on three common\ndatasets demonstrate the effectiveness of our proposed module.\n","authors":["Yicheng Wang","Feng Liu","Junmin Liu","Zhen Fang","Kai Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18139v1","updated":"2024-06-26T07:44:24Z","published":"2024-06-26T07:44:24Z","title":"LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal\n  Long-Context Inference","summary":"  Long-context Multimodal Large Language Models (MLLMs) demand substantial\ncomputational resources for inference as the growth of their multimodal\nKey-Value (KV) cache, in response to increasing input lengths, challenges\nmemory and time efficiency. Unlike single-modality LLMs that manage only\ntextual contexts, the KV cache of long-context MLLMs includes representations\nfrom multiple images with temporal and spatial relationships and related\ntextual contexts. The predominance of image tokens means traditional\noptimizations for LLMs' KV caches are unsuitable for multimodal long-context\nsettings, and no prior works have addressed this challenge. In this work, we\nintroduce LOOK-M, a pioneering, fine-tuning-free approach that efficiently\nreduces the multimodal KV cache size while maintaining performance comparable\nto a full cache. We observe that during prompt prefill, the model prioritizes\nmore textual attention over image features, and based on the multimodal\ninteraction observation, a new proposed text-prior method is explored to\ncompress the KV cache. Furthermore, to mitigate the degradation of image\ncontextual information, we propose several compensatory strategies using KV\npairs merging. LOOK-M demonstrates that with a significant reduction in KV\nCache memory usage, such as reducing it by 80% in some cases, it not only\nachieves up to 1.5x faster decoding but also maintains or even enhances\nperformance across a variety of long context multimodal tasks.\n","authors":["Zhongwei Wan","Ziang Wu","Che Liu","Jinfa Huang","Zhihong Zhu","Peng Jin","Longyue Wang","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2406.18139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18129v1","updated":"2024-06-26T07:31:16Z","published":"2024-06-26T07:31:16Z","title":"CTS: Sim-to-Real Unsupervised Domain Adaptation on 3D Detection","summary":"  Simulation data can be accurately labeled and have been expected to improve\nthe performance of data-driven algorithms, including object detection. However,\ndue to the various domain inconsistencies from simulation to reality\n(sim-to-real), cross-domain object detection algorithms usually suffer from\ndramatic performance drops. While numerous unsupervised domain adaptation (UDA)\nmethods have been developed to address cross-domain tasks between real-world\ndatasets, progress in sim-to-real remains limited. This paper presents a novel\nComplex-to-Simple (CTS) framework to transfer models from labeled simulation\n(source) to unlabeled reality (target) domains. Based on a two-stage detector,\nthe novelty of this work is threefold: 1) developing fixed-size anchor heads\nand RoI augmentation to address size bias and feature diversity between two\ndomains, thereby improving the quality of pseudo-label; 2) developing a novel\ncorner-format representation of aleatoric uncertainty (AU) for the bounding\nbox, to uniformly quantify pseudo-label quality; 3) developing a noise-aware\nmean teacher domain adaptation method based on AU, as well as object-level and\nframe-level sampling strategies, to migrate the impact of noisy labels.\nExperimental results demonstrate that our proposed approach significantly\nenhances the sim-to-real domain adaptation capability of 3D object detection\nmodels, outperforming state-of-the-art cross-domain algorithms, which are\nusually developed for real-to-real UDA tasks.\n","authors":["Meiying Zhang","Weiyuan Peng","Guangyao Ding","Chenyang Lei","Chunlin Ji","Qi Hao"],"pdf_url":"https://arxiv.org/pdf/2406.18129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18115v1","updated":"2024-06-26T07:06:42Z","published":"2024-06-26T07:06:42Z","title":"Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with\n  3D Semantic Maps","summary":"  Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for\nautonomous robots, especially when faced with the challenges posed by unknown\nand dynamic environments. This task requires robots to explore and build a\nsemantic understanding of their surroundings, generate feasible plans to\nachieve manipulation goals, adapt to environmental changes, and comprehend\nnatural language instructions from humans. To address these challenges, we\npropose a novel framework that leverages the zero-shot detection and grounded\nrecognition capabilities of pretraining visual-language models (VLMs) combined\nwith dense 3D entity reconstruction to build 3D semantic maps. Additionally, we\nutilize large language models (LLMs) for spatial region abstraction and online\nplanning, incorporating human instructions and spatial semantic context. We\nhave built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated\nin real-world robot experiments that our proposed framework can effectively\ncapture spatial semantics and process natural language user instructions for\nzero-shot OVMM tasks under dynamic environment settings, with an overall\nnavigation and task success rate of 80.95% and 73.33% over 105 episodes, and\nbetter SFT and SPL by 157.18% and 19.53% respectively compared to the baseline.\nFurthermore, the framework is capable of replanning towards the next most\nprobable candidate location based on the spatial semantic context derived from\nthe 3D semantic map when initial plans fail, keeping an average success rate of\n76.67%.\n","authors":["Dicong Qiu","Wenzong Ma","Zhenfu Pan","Hui Xiong","Junwei Liang"],"pdf_url":"https://arxiv.org/pdf/2406.18115v1.pdf","comment":"Open-vocabulary, Mobile Manipulation, Dynamic Environments, 3D\n  Semantic Maps, Zero-shot, LLMs, VLMs, 18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2402.13561v2","updated":"2024-06-26T07:05:21Z","published":"2024-02-21T06:34:46Z","title":"Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension\n  with Enhanced Visual Knowledge Alignment","summary":"  Evaluating and Rethinking the current landscape of Large Multimodal Models\n(LMMs), we observe that widely-used visual-language projection approaches\n(e.g., Q-former or MLP) focus on the alignment of image-text descriptions yet\nignore the visual knowledge-dimension alignment, i.e., connecting visuals to\ntheir relevant knowledge. Visual knowledge plays a significant role in\nanalyzing, inferring, and interpreting information from visuals, helping\nimprove the accuracy of answers to knowledge-based visual questions. In this\npaper, we mainly explore improving LMMs with visual-language knowledge\nalignment, especially aimed at challenging knowledge-based visual question\nanswering (VQA). To this end, we present a Cognitive Visual-Language Mapper\n(CVLM), which contains a pretrained Visual Knowledge Aligner (VKA) and a\nFine-grained Knowledge Adapter (FKA) used in the multimodal instruction tuning\nstage. Specifically, we design the VKA based on the interaction between a small\nlanguage model and a visual encoder, training it on collected image-knowledge\npairs to achieve visual knowledge acquisition and projection. FKA is employed\nto distill the fine-grained visual knowledge of an image and inject it into\nLarge Language Models (LLMs). We conduct extensive experiments on\nknowledge-based VQA benchmarks and experimental results show that CVLM\nsignificantly improves the performance of LMMs on knowledge-based VQA (average\ngain by 5.0%). Ablation studies also verify the effectiveness of VKA and FKA,\nrespectively. The codes are available at\nhttps://github.com/HITsz-TMG/Cognitive-Visual-Language-Mapper\n","authors":["Yunxin Li","Xinyu Chen","Baotian Hu","Haoyuan Shi","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.13561v2.pdf","comment":"12 pages,4 figures; Accepted by ACL 2024 Main Conference"},{"id":"http://arxiv.org/abs/2406.18113v1","updated":"2024-06-26T06:59:09Z","published":"2024-06-26T06:59:09Z","title":"The Surprising Effectiveness of Multimodal Large Language Models for\n  Video Moment Retrieval","summary":"  Recent studies have shown promising results in utilizing multimodal large\nlanguage models (MLLMs) for computer vision tasks such as object detection and\nsemantic segmentation. However, many challenging video tasks remain\nunder-explored. Video-language tasks necessitate spatial and temporal\ncomprehension and require significant compute. Therefore, prior works have\ndeveloped complex, highly specialized architectures or leveraged additional\ninput signals such as video transcripts to best encode contextual and temporal\ninformation, which limits their generality and can be impractical. One\nparticularly challenging task is video moment retrieval, which requires precise\ntemporal and contextual grounding. This work demonstrates the surprising\neffectiveness of leveraging image-text pretrained MLLMs for moment retrieval.\nWe introduce Mr. BLIP (Mr. as in Moment Retrieval), a multimodal, single-stage\nmodel that requires no expensive video-language pretraining, no additional\ninput signal (e.g., no transcript or audio), and has a simpler and more\nversatile design than prior state-of-the-art methods. We achieve a new\nstate-of-the-art in moment retrieval on the widely used benchmarks\nCharades-STA, QVHighlights, and ActivityNet Captions and illustrate our\nmethod's versatility with a new state-of-the-art in temporal action\nlocalization on ActivityNet. Notably, we attain over 9% (absolute) higher\nRecall (at 0.5 and 0.7 IoU) on the challenging long-video multi-moment\nQVHighlights benchmark. Our code is publicly available.\n","authors":["Meinardus Boris","Batra Anil","Rohrbach Anna","Rohrbach Marcus"],"pdf_url":"https://arxiv.org/pdf/2406.18113v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2406.07189v3","updated":"2024-06-26T06:39:49Z","published":"2024-06-11T12:01:11Z","title":"RGB-Sonar Tracking Benchmark and Spatial Cross-Attention Transformer\n  Tracker","summary":"  Vision camera and sonar are naturally complementary in the underwater\nenvironment. Combining the information from two modalities will promote better\nobservation of underwater targets. However, this problem has not received\nsufficient attention in previous research. Therefore, this paper introduces a\nnew challenging RGB-Sonar (RGB-S) tracking task and investigates how to achieve\nefficient tracking of an underwater target through the interaction of RGB and\nsonar modalities. Specifically, we first propose an RGBS50 benchmark dataset\ncontaining 50 sequences and more than 87000 high-quality annotated bounding\nboxes. Experimental results show that the RGBS50 benchmark poses a challenge to\ncurrently popular SOT trackers. Second, we propose an RGB-S tracker called\nSCANet, which includes a spatial cross-attention module (SCAM) consisting of a\nnovel spatial cross-attention layer and two independent global integration\nmodules. The spatial cross-attention is used to overcome the problem of spatial\nmisalignment of between RGB and sonar images. Third, we propose a SOT\ndata-based RGB-S simulation training method (SRST) to overcome the lack of\nRGB-S training datasets. It converts RGB images into sonar-like saliency images\nto construct pseudo-data pairs, enabling the model to learn the semantic\nstructure of RGB-S-like data. Comprehensive experiments show that the proposed\nspatial cross-attention effectively achieves the interaction between RGB and\nsonar modalities and SCANet achieves state-of-the-art performance on the\nproposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/RGBS50.\n","authors":["Yunfeng Li","Bo Wang","Jiuran Sun","Xueyi Wu","Ye Li"],"pdf_url":"https://arxiv.org/pdf/2406.07189v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18102v1","updated":"2024-06-26T06:39:11Z","published":"2024-06-26T06:39:11Z","title":"A Lung Nodule Dataset with Histopathology-based Cancer Type Annotation","summary":"  Recently, Computer-Aided Diagnosis (CAD) systems have emerged as\nindispensable tools in clinical diagnostic workflows, significantly alleviating\nthe burden on radiologists. Nevertheless, despite their integration into\nclinical settings, CAD systems encounter limitations. Specifically, while CAD\nsystems can achieve high performance in the detection of lung nodules, they\nface challenges in accurately predicting multiple cancer types. This limitation\ncan be attributed to the scarcity of publicly available datasets annotated with\nexpert-level cancer type information. This research aims to bridge this gap by\nproviding publicly accessible datasets and reliable tools for medical\ndiagnosis, facilitating a finer categorization of different types of lung\ndiseases so as to offer precise treatment recommendations. To achieve this\nobjective, we curated a diverse dataset of lung Computed Tomography (CT)\nimages, comprising 330 annotated nodules (nodules are labeled as bounding\nboxes) from 95 distinct patients. The quality of the dataset was evaluated\nusing a variety of classical classification and detection models, and these\npromising results demonstrate that the dataset has a feasible application and\nfurther facilitate intelligent auxiliary diagnosis.\n","authors":["Muwei Jian","Hongyu Chen","Zaiyong Zhang","Nan Yang","Haorang Zhang","Lifu Ma","Wenjing Xu","Huixiang Zhi"],"pdf_url":"https://arxiv.org/pdf/2406.18102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10237v2","updated":"2024-06-26T06:04:51Z","published":"2024-04-16T02:35:17Z","title":"Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical\n  Vision-Language Models","summary":"  Recent advancements in general-purpose or domain-specific multimodal large\nlanguage models (LLMs) have witnessed remarkable progress for medical\ndecision-making. However, they are designated for specific classification or\ngenerative tasks, and require model training or finetuning on large-scale\ndatasets with sizeable parameters and tremendous computing, hindering their\nclinical utility across diverse resource-constrained scenarios in practice. In\nthis paper, we propose a novel and lightweight framework Med-MoE\n(Mixture-of-Experts) that tackles both discriminative and generative multimodal\nmedical tasks. The learning of Med-MoE consists of three steps: multimodal\nmedical alignment, instruction tuning and routing, and domain-specific MoE\ntuning. After aligning multimodal medical images with LLM tokens, we then\nenable the model for different multimodal medical tasks with instruction\ntuning, together with a trainable router tailored for expert selection across\ninput modalities. Finally, the model is tuned by integrating the router with\nmultiple domain-specific experts, which are selectively activated and further\nempowered by meta expert. Comprehensive experiments on both open- and close-end\nmedical question answering (Med-VQA) and image classification tasks across\ndatasets such as VQA-RAD, SLAKE and Path-VQA demonstrate that our model can\nachieve performance superior to or on par with state-of-the-art baselines,\nwhile only requiring approximately 30\\%-50\\% of activated model parameters.\nExtensive analysis and ablations corroborate the effectiveness and practical\nutility of our method.\n","authors":["Songtao Jiang","Tuo Zheng","Yan Zhang","Yeying Jin","Li Yuan","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2404.10237v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16464v2","updated":"2024-06-26T05:40:16Z","published":"2024-06-24T09:13:42Z","title":"InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for\n  Multi-modal Sarcasm Detection","summary":"  The prevalence of sarcasm in social media, conveyed through text-image\ncombinations, presents significant challenges for sentiment analysis and\nintention mining. Current multi-modal sarcasm detection methods have been\nproven to struggle with biases from spurious cues, leading to a superficial\nunderstanding of the complex interactions between text and image. To address\nthese issues, we propose InterCLIP-MEP, a robust framework for multi-modal\nsarcasm detection. InterCLIP-MEP introduces a refined variant of CLIP,\nInteractive CLIP (InterCLIP), as the backbone, enhancing sample representations\nby embedding cross-modality information in each encoder. Furthermore, a novel\ntraining strategy is designed to adapt InterCLIP for a Memory-Enhanced\nPredictor (MEP). MEP uses dynamic dual-channel memory to store valuable\nhistorical knowledge of test samples and then leverages this memory as a\nnon-parametric classifier to derive the final prediction. By using InterCLIP to\nencode text-image interactions more effectively and incorporating MEP,\nInterCLIP-MEP offers a more robust recognition of multi-modal sarcasm.\nExperiments demonstrate that InterCLIP-MEP achieves state-of-the-art\nperformance on the MMSD2.0 benchmark. Code and data are available at\nhttps://github.com/CoderChen01/InterCLIP-MEP.\n","authors":["Junjie Chen","Subin Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16464v2.pdf","comment":"8 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.18079v1","updated":"2024-06-26T05:31:36Z","published":"2024-06-26T05:31:36Z","title":"MFDNet: Multi-Frequency Deflare Network for Efficient Nighttime Flare\n  Removal","summary":"  When light is scattered or reflected accidentally in the lens, flare\nartifacts may appear in the captured photos, affecting the photos' visual\nquality. The main challenge in flare removal is to eliminate various flare\nartifacts while preserving the original content of the image. To address this\nchallenge, we propose a lightweight Multi-Frequency Deflare Network (MFDNet)\nbased on the Laplacian Pyramid. Our network decomposes the flare-corrupted\nimage into low and high-frequency bands, effectively separating the\nillumination and content information in the image. The low-frequency part\ntypically contains illumination information, while the high-frequency part\ncontains detailed content information. So our MFDNet consists of two main\nmodules: the Low-Frequency Flare Perception Module (LFFPM) to remove flare in\nthe low-frequency part and the Hierarchical Fusion Reconstruction Module (HFRM)\nto reconstruct the flare-free image. Specifically, to perceive flare from a\nglobal perspective while retaining detailed information for image restoration,\nLFFPM utilizes Transformer to extract global information while utilizing a\nconvolutional neural network to capture detailed local features. Then HFRM\ngradually fuses the outputs of LFFPM with the high-frequency component of the\nimage through feature aggregation. Moreover, our MFDNet can reduce the\ncomputational cost by processing in multiple frequency bands instead of\ndirectly removing the flare on the input image. Experimental results\ndemonstrate that our approach outperforms state-of-the-art methods in removing\nnighttime flare on real-world and synthetic images from the Flare7K dataset.\nFurthermore, the computational complexity of our model is remarkably low.\n","authors":["Yiguo Jiang","Xuhang Chen","Chi-Man Pun","Shuqiang Wang","Wei Feng"],"pdf_url":"https://arxiv.org/pdf/2406.18079v1.pdf","comment":"Accepted by The Visual Computer journal"},{"id":"http://arxiv.org/abs/2406.12837v2","updated":"2024-06-26T05:28:12Z","published":"2024-06-18T17:55:15Z","title":"LayerMerge: Neural Network Depth Compression through Layer Pruning and\n  Merging","summary":"  Recent works show that reducing the number of layers in a convolutional\nneural network can enhance efficiency while maintaining the performance of the\nnetwork. Existing depth compression methods remove redundant non-linear\nactivation functions and merge the consecutive convolution layers into a single\nlayer. However, these methods suffer from a critical drawback; the kernel size\nof the merged layers becomes larger, significantly undermining the latency\nreduction gained from reducing the depth of the network. We show that this\nproblem can be addressed by jointly pruning convolution layers and activation\nfunctions. To this end, we propose LayerMerge, a novel depth compression method\nthat selects which activation layers and convolution layers to remove, to\nachieve a desired inference speed-up while minimizing performance loss. Since\nthe corresponding selection problem involves an exponential search space, we\nformulate a novel surrogate optimization problem and efficiently solve it via\ndynamic programming. Empirical results demonstrate that our method consistently\noutperforms existing depth compression and layer pruning methods on various\nnetwork architectures, both on image classification and generation tasks. We\nrelease the code at https://github.com/snu-mllab/LayerMerge.\n","authors":["Jinuk Kim","Marwa El Halabi","Mingi Ji","Hyun Oh Song"],"pdf_url":"https://arxiv.org/pdf/2406.12837v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.18074v1","updated":"2024-06-26T05:06:14Z","published":"2024-06-26T05:06:14Z","title":"Few-Shot Medical Image Segmentation with High-Fidelity Prototypes","summary":"  Few-shot Semantic Segmentation (FSS) aims to adapt a pretrained model to new\nclasses with as few as a single labelled training sample per class. Despite the\nprototype based approaches have achieved substantial success, existing models\nare limited to the imaging scenarios with considerably distinct objects and not\nhighly complex background, e.g., natural images. This makes such models\nsuboptimal for medical imaging with both conditions invalid. To address this\nproblem, we propose a novel Detail Self-refined Prototype Network (DSPNet) to\nconstructing high-fidelity prototypes representing the object foreground and\nthe background more comprehensively. Specifically, to construct global\nsemantics while maintaining the captured detail semantics, we learn the\nforeground prototypes by modelling the multi-modal structures with clustering\nand then fusing each in a channel-wise manner. Considering that the background\noften has no apparent semantic relation in the spatial dimensions, we integrate\nchannel-specific structural information under sparse channel-aware regulation.\nExtensive experiments on three challenging medical image benchmarks show the\nsuperiority of DSPNet over previous state-of-the-art methods.\n","authors":["Song Tang","Shaxu Yan","Xiaozhi Qi","Jianxin Gao","Mao Ye","Jianwei Zhang","Xiatian Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.18074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18070v1","updated":"2024-06-26T05:01:37Z","published":"2024-06-26T05:01:37Z","title":"EgoVideo: Exploring Egocentric Foundation Model and Downstream\n  Adaptation","summary":"  In this report, we present our solutions to the EgoVis Challenges in CVPR\n2024, including five tracks in the Ego4D challenge and three tracks in the\nEPIC-Kitchens challenge. Building upon the video-language two-tower model and\nleveraging our meticulously organized egocentric video data, we introduce a\nnovel foundation model called EgoVideo. This model is specifically designed to\ncater to the unique characteristics of egocentric videos and provides strong\nsupport for our competition submissions. In the Ego4D challenges, we tackle\nvarious tasks including Natural Language Queries, Step Grounding, Moment\nQueries, Short-term Object Interaction Anticipation, and Long-term Action\nAnticipation. In addition, we also participate in the EPIC-Kitchens challenge,\nwhere we engage in the Action Recognition, Multiple Instance Retrieval, and\nDomain Adaptation for Action Recognition tracks. By adapting EgoVideo to these\ndiverse tasks, we showcase its versatility and effectiveness in different\negocentric video analysis scenarios, demonstrating the powerful representation\nability of EgoVideo as an egocentric foundation model. Our codebase and\npretrained models are publicly available at\nhttps://github.com/OpenGVLab/EgoVideo.\n","authors":["Baoqi Pei","Guo Chen","Jilan Xu","Yuping He","Yicheng Liu","Kanghua Pan","Yifei Huang","Yali Wang","Tong Lu","Limin Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2406.18070v1.pdf","comment":"Champion solutions in the EgoVis CVPR 2024 workshop"},{"id":"http://arxiv.org/abs/2406.18068v1","updated":"2024-06-26T04:53:11Z","published":"2024-06-26T04:53:11Z","title":"Speech2UnifiedExpressions: Synchronous Synthesis of Co-Speech Affective\n  Face and Body Expressions from Affordable Inputs","summary":"  We present a multimodal learning-based method to simultaneously synthesize\nco-speech facial expressions and upper-body gestures for digital characters\nusing RGB video data captured using commodity cameras. Our approach learns from\nsparse face landmarks and upper-body joints, estimated directly from video\ndata, to generate plausible emotive character motions. Given a speech audio\nwaveform and a token sequence of the speaker's face landmark motion and\nbody-joint motion computed from a video, our method synthesizes the motion\nsequences for the speaker's face landmarks and body joints to match the content\nand the affect of the speech. We design a generator consisting of a set of\nencoders to transform all the inputs into a multimodal embedding space\ncapturing their correlations, followed by a pair of decoders to synthesize the\ndesired face and pose motions. To enhance the plausibility of synthesis, we use\nan adversarial discriminator that learns to differentiate between the face and\npose motions computed from the original videos and our synthesized motions\nbased on their affective expressions. To evaluate our approach, we extend the\nTED Gesture Dataset to include view-normalized, co-speech face landmarks in\naddition to body gestures. We demonstrate the performance of our method through\nthorough quantitative and qualitative experiments on multiple evaluation\nmetrics and via a user study. We observe that our method results in low\nreconstruction error and produces synthesized samples with diverse facial\nexpressions and body gestures for digital characters.\n","authors":["Uttaran Bhattacharya","Aniket Bera","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2406.18068v1.pdf","comment":"14 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.18054v1","updated":"2024-06-26T04:12:34Z","published":"2024-06-26T04:12:34Z","title":"Leveraging Pre-trained Models for FF-to-FFPE Histopathological Image\n  Translation","summary":"  The two primary types of Hematoxylin and Eosin (H&E) slides in histopathology\nare Formalin-Fixed Paraffin-Embedded (FFPE) and Fresh Frozen (FF). FFPE slides\noffer high quality histopathological images but require a labor-intensive\nacquisition process. In contrast, FF slides can be prepared quickly, but the\nimage quality is relatively poor. Our task is to translate FF images into FFPE\nstyle, thereby improving the image quality for diagnostic purposes. In this\npaper, we propose Diffusion-FFPE, a method for FF-to-FFPE histopathological\nimage translation using a pre-trained diffusion model. Specifically, we employ\na one-step diffusion model as the generator and fine-tune it with LoRA adapters\nusing adversarial learning objectives. To ensure that the model effectively\ncaptures both global structural information and local details, we propose a\nmulti-scale feature fusion (MFF) module. This module utilizes two VAE encoders\nto extract features of varying image sizes and performs feature fusion before\nfeeding them into the UNet. Furthermore, we utilize a pre-trained\nvision-language model for histopathology as the backbone for the discriminator\nto further improve performance We conducted FF-to-FFPE translation experiments\non the TCGA-NSCLC datasets, and our method achieved better performance compared\nto other methods. The code and models are released at\nhttps://github.com/QilaiZhang/Diffusion-FFPE.\n","authors":["Qilai Zhang","Jiawen Li","Peiran Liao","Jiali Hu","Tian Guan","Anjia Han","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2406.18054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18051v1","updated":"2024-06-26T04:01:19Z","published":"2024-06-26T04:01:19Z","title":"ViT-1.58b: Mobile Vision Transformers in the 1-bit Era","summary":"  Vision Transformers (ViTs) have achieved remarkable performance in various\nimage classification tasks by leveraging the attention mechanism to process\nimage patches as tokens. However, the high computational and memory demands of\nViTs pose significant challenges for deployment in resource-constrained\nenvironments. This paper introduces ViT-1.58b, a novel 1.58-bit quantized ViT\nmodel designed to drastically reduce memory and computational overhead while\npreserving competitive performance. ViT-1.58b employs ternary quantization,\nwhich refines the balance between efficiency and accuracy by constraining\nweights to {-1, 0, 1} and quantizing activations to 8-bit precision. Our\napproach ensures efficient scaling in terms of both memory and computation.\nExperiments on CIFAR-10 and ImageNet-1k demonstrate that ViT-1.58b maintains\ncomparable accuracy to full-precision Vit, with significant reductions in\nmemory usage and computational costs. This paper highlights the potential of\nextreme quantization techniques in developing sustainable AI solutions and\ncontributes to the broader discourse on efficient model deployment in practical\napplications. Our code and weights are available at\nhttps://github.com/DLYuanGod/ViT-1.58b.\n","authors":["Zhengqing Yuan","Rong Zhou","Hongyi Wang","Lifang He","Yanfang Ye","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18050v1","updated":"2024-06-26T03:59:21Z","published":"2024-06-26T03:59:21Z","title":"A Multi-Stage Goal-Driven Network for Pedestrian Trajectory Prediction","summary":"  Pedestrian trajectory prediction plays a pivotal role in ensuring the safety\nand efficiency of various applications, including autonomous vehicles and\ntraffic management systems. This paper proposes a novel method for pedestrian\ntrajectory prediction, called multi-stage goal-driven network (MGNet).\nDiverging from prior approaches relying on stepwise recursive prediction and\nthe singular forecasting of a long-term goal, MGNet directs trajectory\ngeneration by forecasting intermediate stage goals, thereby reducing prediction\nerrors. The network comprises three main components: a conditional variational\nautoencoder (CVAE), an attention module, and a multi-stage goal evaluator.\nTrajectories are encoded using conditional variational autoencoders to acquire\nknowledge about the approximate distribution of pedestrians' future\ntrajectories, and combined with an attention mechanism to capture the temporal\ndependency between trajectory sequences. The pivotal module is the multi-stage\ngoal evaluator, which utilizes the encoded feature vectors to predict\nintermediate goals, effectively minimizing cumulative errors in the recursive\ninference process. The effectiveness of MGNet is demonstrated through\ncomprehensive experiments on the JAAD and PIE datasets. Comparative evaluations\nagainst state-of-the-art algorithms reveal significant performance improvements\nachieved by our proposed method.\n","authors":["Xiuen Wu","Tao Wang","Yuanzheng Cai","Lingyu Liang","George Papageorgiou"],"pdf_url":"https://arxiv.org/pdf/2406.18050v1.pdf","comment":"Paper accepted by 5th International Conference on Computer Vision,\n  Image and Deep Learning (CVIDL 2024)"},{"id":"http://arxiv.org/abs/2406.18048v1","updated":"2024-06-26T03:56:03Z","published":"2024-06-26T03:56:03Z","title":"ScanFormer: Referring Expression Comprehension by Iteratively Scanning","summary":"  Referring Expression Comprehension (REC) aims to localize the target objects\nspecified by free-form natural language descriptions in images. While\nstate-of-the-art methods achieve impressive performance, they perform a dense\nperception of images, which incorporates redundant visual regions unrelated to\nlinguistic queries, leading to additional computational overhead. This inspires\nus to explore a question: can we eliminate linguistic-irrelevant redundant\nvisual regions to improve the efficiency of the model? Existing relevant\nmethods primarily focus on fundamental visual tasks, with limited exploration\nin vision-language fields. To address this, we propose a coarse-to-fine\niterative perception framework, called ScanFormer. It can iteratively exploit\nthe image scale pyramid to extract linguistic-relevant visual patches from top\nto bottom. In each iteration, irrelevant patches are discarded by our designed\ninformativeness prediction. Furthermore, we propose a patch selection strategy\nfor discarded patches to accelerate inference. Experiments on widely used\ndatasets, namely RefCOCO, RefCOCO+, RefCOCOg, and ReferItGame, verify the\neffectiveness of our method, which can strike a balance between accuracy and\nefficiency.\n","authors":["Wei Su","Peihan Miao","Huanzhang Dou","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2406.18048v1.pdf","comment":"Accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2406.18043v1","updated":"2024-06-26T03:41:48Z","published":"2024-06-26T03:41:48Z","title":"Multimodal foundation world models for generalist embodied agents","summary":"  Learning generalist embodied agents, able to solve multitudes of tasks in\ndifferent domains is a long-standing problem. Reinforcement learning (RL) is\nhard to scale up as it requires a complex reward design for each task. In\ncontrast, language can specify tasks in a more natural way. Current foundation\nvision-language models (VLMs) generally require fine-tuning or other\nadaptations to be functional, due to the significant domain gap. However, the\nlack of multimodal data in such domains represents an obstacle toward\ndeveloping foundation models for embodied applications. In this work, we\novercome these problems by presenting multimodal foundation world models, able\nto connect and align the representation of foundation VLMs with the latent\nspace of generative world models for RL, without any language annotations. The\nresulting agent learning framework, GenRL, allows one to specify tasks through\nvision and/or language prompts, ground them in the embodied domain's dynamics,\nand learns the corresponding behaviors in imagination. As assessed through\nlarge-scale multi-task benchmarking, GenRL exhibits strong multi-task\ngeneralization performance in several locomotion and manipulation domains.\nFurthermore, by introducing a data-free RL strategy, it lays the groundwork for\nfoundation model-based RL for generalist embodied agents.\n","authors":["Pietro Mazzaglia","Tim Verbelen","Bart Dhoedt","Aaron Courville","Sai Rajeswar"],"pdf_url":"https://arxiv.org/pdf/2406.18043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02085v4","updated":"2024-06-26T03:32:50Z","published":"2024-02-03T08:52:06Z","title":"DeCoF: Generated Video Detection via Frame Consistency: The First\n  Benchmark Dataset","summary":"  The escalating quality of video generated by advanced video generation\nmethods results in new security challenges, while there have been few relevant\nresearch efforts: 1) There is no open-source dataset for generated video\ndetection, 2) No generated video detection method has been proposed so far. To\nthis end, we propose an open-source dataset and a detection method for\ngenerated video for the first time. First, we propose a scalable dataset\nconsisting of 964 prompts, covering various forgery targets, scenes, behaviors,\nand actions, as well as various generation models with different architectures\nand generation methods, including the most popular commercial models like\nOpenAI's Sora and Google's Veo. Second, we found via probing experiments that\nspatial artifact-based detectors lack generalizability. Hence, we propose a\nsimple yet effective \\textbf{de}tection model based on \\textbf{f}rame\n\\textbf{co}nsistency (\\textbf{DeCoF}), which focuses on temporal artifacts by\neliminating the impact of spatial artifacts during feature learning. Extensive\nexperiments demonstrate the efficacy of DeCoF in detecting videos generated by\nunseen video generation models and confirm its powerful generalizability across\nseveral commercially proprietary models. Our code and dataset will be released\nat \\url{https://github.com/wuwuwuyue/DeCoF}.\n","authors":["Long Ma","Jiajia Zhang","Hongping Deng","Ningyu Zhang","Qinglang Guo","Haiyang Yu","Yong Liao","Pengyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.02085v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01886v3","updated":"2024-06-26T03:29:50Z","published":"2023-12-04T13:40:05Z","title":"InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language\n  Models","summary":"  Large vision-language models (LVLMs) have demonstrated their incredible\ncapability in image understanding and response generation. However, this rich\nvisual interaction also makes LVLMs vulnerable to adversarial examples. In this\npaper, we formulate a novel and practical targeted attack scenario that the\nadversary can only know the vision encoder of the victim LVLM, without the\nknowledge of its prompts (which are often proprietary for service providers and\nnot publicly available) and its underlying large language model (LLM). This\npractical setting poses challenges to the cross-prompt and cross-model\ntransferability of targeted adversarial attack, which aims to confuse the LVLM\nto output a response that is semantically similar to the attacker's chosen\ntarget text. To this end, we propose an instruction-tuned targeted attack\n(dubbed \\textsc{InstructTA}) to deliver the targeted adversarial attack on\nLVLMs with high transferability. Initially, we utilize a public text-to-image\ngenerative model to \"reverse\" the target response into a target image, and\nemploy GPT-4 to infer a reasonable instruction $\\boldsymbol{p}^\\prime$ from the\ntarget response. We then form a local surrogate model (sharing the same vision\nencoder with the victim LVLM) to extract instruction-aware features of an\nadversarial image example and the target image, and minimize the distance\nbetween these two features to optimize the adversarial example. To further\nimprove the transferability with instruction tuning, we augment the instruction\n$\\boldsymbol{p}^\\prime$ with instructions paraphrased from GPT-4. Extensive\nexperiments demonstrate the superiority of our proposed method in targeted\nattack performance and transferability. The code is available at\nhttps://github.com/xunguangwang/InstructTA.\n","authors":["Xunguang Wang","Zhenlan Ji","Pingchuan Ma","Zongjie Li","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2312.01886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19684v3","updated":"2024-06-26T03:28:15Z","published":"2024-05-30T04:46:40Z","title":"A Comprehensive Survey on Underwater Image Enhancement Based on Deep\n  Learning","summary":"  Underwater image enhancement (UIE) presents a significant challenge within\ncomputer vision research. Despite the development of numerous UIE algorithms, a\nthorough and systematic review is still absent. To foster future advancements,\nwe provide a detailed overview of the UIE task from several perspectives.\nFirstly, we introduce the physical models, data construction processes,\nevaluation metrics, and loss functions. Secondly, we categorize and discuss\nrecent algorithms based on their contributions, considering six aspects:\nnetwork architecture, learning strategy, learning stage, auxiliary tasks,\ndomain perspective, and disentanglement fusion. Thirdly, due to the varying\nexperimental setups in the existing literature, a comprehensive and unbiased\ncomparison is currently unavailable. To address this, we perform both\nquantitative and qualitative evaluations of state-of-the-art algorithms across\nmultiple benchmark datasets. Lastly, we identify key areas for future research\nin UIE. A collection of resources for UIE can be found at\n{https://github.com/YuZhao1999/UIE}.\n","authors":["Xiaofeng Cong","Yu Zhao","Jie Gui","Junming Hou","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2405.19684v3.pdf","comment":"A survey on the underwater image enhancement task"},{"id":"http://arxiv.org/abs/2406.18037v1","updated":"2024-06-26T03:10:57Z","published":"2024-06-26T03:10:57Z","title":"Towards Synchronous Memorizability and Generalizability with\n  Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation","summary":"  The ability to learn sequentially from different data sites is crucial for a\ndeep network in solving practical medical image diagnosis problems due to\nprivacy restrictions and storage limitations. However, adapting on incoming\nsite leads to catastrophic forgetting on past sites and decreases\ngeneralizablity on unseen sites. Existing Continual Learning (CL) and Domain\nGeneralization (DG) methods have been proposed to solve these two challenges\nrespectively, but none of them can address both simultaneously. Recognizing\nthis limitation, this paper proposes a novel training paradigm, learning\ntowards Synchronous Memorizability and Generalizability (SMG-Learning). To\nachieve this, we create the orientational gradient alignment to ensure\nmemorizability on previous sites, and arbitrary gradient alignment to enhance\ngeneralizability on unseen sites. This approach is named as Parallel Gradient\nAlignment (PGA). Furthermore, we approximate the PGA as dual meta-objectives\nusing the first-order Taylor expansion to reduce computational cost of aligning\ngradients. Considering that performing gradient alignments, especially for\nprevious sites, is not feasible due to the privacy constraints, we design a\nSite-Modulated Diffusion (SMD) model to generate images with site-specific\nlearnable prompts, replaying images have similar data distributions as previous\nsites. We evaluate our method on two medical image segmentation tasks, where\ndata from different sites arrive sequentially. Experimental results show that\nour method efficiently enhances both memorizability and generalizablity better\nthan other state-of-the-art methods, delivering satisfactory performance across\nall sites. Our code will be available at:\nhttps://github.com/dyxu-cuhkcse/SMG-Learning.\n","authors":["Dunyuan Xu","Xi Wang","Jingyang Zhang","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.18037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18031v1","updated":"2024-06-26T03:01:18Z","published":"2024-06-26T03:01:18Z","title":"Real-time Structure Flow","summary":"  This article introduces the structure flow field; a flow field that can\nprovide high-speed robo-centric motion information for motion control of highly\ndynamic robotic devices and autonomous vehicles. Structure flow is the angular\n3D velocity of the scene at a given pixel. We show that structure flow posses\nan elegant evolution model in the form of a Partial Differential Equation (PDE)\nthat enables us to create dense flow predictions forward in time. We exploit\nthis structure to design a predictor-update algorithm to compute structure flow\nin real time using image and depth measurements. The prediction stage takes the\nprevious estimate of the structure flow and propagates it forward in time using\na numerical implementation of the structure flow PDE. The predicted flow is\nthen updated using new image and depth data. The algorithm runs up to 600 Hz on\na Desktop GPU machine for 512x512 images with flow values up to 8 pixels. We\nprovide ground truth validation on high-speed synthetic image sequences as well\nas results on real-life video on driving scenarios.\n","authors":["Juan David Adarve","Robert Mahony"],"pdf_url":"https://arxiv.org/pdf/2406.18031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00618v3","updated":"2024-06-26T02:42:30Z","published":"2023-01-02T12:16:18Z","title":"An Event-based Algorithm for Simultaneous 6-DOF Camera Pose Tracking and\n  Mapping","summary":"  Compared to regular cameras, Dynamic Vision Sensors or Event Cameras can\noutput compact visual data based on a change in the intensity in each pixel\nlocation asynchronously. In this paper, we study the application of current\nimage-based SLAM techniques to these novel sensors. To this end, the\ninformation in adaptively selected event windows is processed to form\nmotion-compensated images. These images are then used to reconstruct the scene\nand estimate the 6-DOF pose of the camera. We also propose an inertial version\nof the event-only pipeline to assess its capabilities. We compare the results\nof different configurations of the proposed algorithm against the ground truth\nfor sequences of two publicly available event datasets. We also compare the\nresults of the proposed event-inertial pipeline with the state-of-the-art and\nshow it can produce comparable or more accurate results provided the map\nestimate is reliable.\n","authors":["Masoud Dayani Najafabadi","Mohammad Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2301.00618v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17559v2","updated":"2024-06-26T02:23:32Z","published":"2024-06-25T13:54:39Z","title":"Minimal Interaction Edge Tuning: A New Paradigm for Visual Adaptation","summary":"  The rapid scaling of large vision pretrained models makes fine-tuning tasks\nmore and more difficult on edge devices with low computational resources. We\nexplore a new visual adaptation paradigm called edge tuning, which treats large\npretrained models as standalone feature extractors that run on powerful cloud\nservers. The fine-tuning carries out on edge devices with small networks which\nrequire low computational resources. Existing methods that are potentially\nsuitable for our edge tuning paradigm are discussed. But, three major drawbacks\nhinder their application in edge tuning: low adaptation capability, large\nadapter network, and high information transfer overhead. To address these\nissues, we propose Minimal Interaction Edge Tuning, or MIET, which reveals that\nthe sum of intermediate features from pretrained models not only has minimal\ninformation transfer but also has high adaptation capability. With a\nlightweight attention-based adaptor network, MIET achieves information transfer\nefficiency, parameter efficiency, computational and memory efficiency, and at\nthe same time demonstrates competitive results on various visual adaptation\nbenchmarks.\n","authors":["Ningyuan Tang","Minghao Fu","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2406.17559v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.17254v2","updated":"2024-06-26T02:21:00Z","published":"2024-06-25T03:42:29Z","title":"Scalp Diagnostic System With Label-Free Segmentation and Training-Free\n  Image Translation","summary":"  Scalp diseases and alopecia affect millions of people around the world,\nunderscoring the urgent need for early diagnosis and management of the disease.\nHowever, the development of a comprehensive AI-based diagnosis system\nencompassing these conditions remains an underexplored domain due to the\nchallenges associated with data imbalance and the costly nature of labeling. To\naddress these issues, we propose ScalpVision, an AI-driven system for the\nholistic diagnosis of scalp diseases and alopecia. In ScalpVision, effective\nhair segmentation is achieved using pseudo image-label pairs and an innovative\nprompting method in the absence of traditional hair masking labels. This\napproach is crucial for extracting key features such as hair thickness and\ncount, which are then used to assess alopecia severity. Additionally,\nScalpVision introduces DiffuseIT-M, a generative model adept at dataset\naugmentation while maintaining hair information, facilitating improved\npredictions of scalp disease severity. Our experimental results affirm\nScalpVision's efficiency in diagnosing a variety of scalp conditions and\nalopecia, showcasing its potential as a valuable tool in dermatological care.\n","authors":["Youngmin Kim","Saejin Kim","Hoyeon Moon","Youngjae Yu","Junhyug Noh"],"pdf_url":"https://arxiv.org/pdf/2406.17254v2.pdf","comment":"IEEE Transactions on Medical Imaging (Under Review)"},{"id":"http://arxiv.org/abs/2404.17876v2","updated":"2024-06-26T02:14:32Z","published":"2024-04-27T12:19:23Z","title":"DF-SLAM: Dictionary Factors Representation for High-Fidelity Neural\n  Implicit Dense Visual SLAM System","summary":"  We introduce a high-fidelity neural implicit dense visual Simultaneous\nLocalization and Mapping (SLAM) system, termed DF-SLAM. In our work, we employ\ndictionary factors for scene representation, encoding the geometry and\nappearance information of the scene as a combination of basis and coefficient\nfactors. Compared to neural implicit dense visual SLAM methods that directly\nencode scene information as features, our method exhibits superior scene detail\nreconstruction capabilities and more efficient memory usage, while our model\nsize is insensitive to the size of the scene map, making our method more\nsuitable for large-scale scenes. Additionally, we employ feature integration\nrendering to accelerate color rendering speed while ensuring color rendering\nquality, further enhancing the real-time performance of our neural SLAM method.\nExtensive experiments on synthetic and real-world datasets demonstrate that our\nmethod is competitive with existing state-of-the-art neural implicit SLAM\nmethods in terms of real-time performance, localization accuracy, and scene\nreconstruction quality. Our source code is available at\nhttps://github.com/funcdecl/DF-SLAM.\n","authors":["Weifeng Wei","Jie Wang","Shuqi Deng","Jie Liu"],"pdf_url":"https://arxiv.org/pdf/2404.17876v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18012v1","updated":"2024-06-26T01:54:10Z","published":"2024-06-26T01:54:10Z","title":"View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with\n  Adaptive View Synthesis","summary":"  The inspection and monitoring of infrastructure assets typically requires\nidentifying visual anomalies in scenes periodically photographed over time.\nImages collected manually or with robots such as unmanned aerial vehicles from\nthe same scene at different instances in time are typically not perfectly\naligned. Supervised segmentation methods can be applied to identify known\nproblems, but unsupervised anomaly detection approaches are required when\nunknown anomalies occur. Current unsupervised pixel-level anomaly detection\nmethods have mainly been developed for industrial settings where the camera\nposition is known and constant. However, we find that these methods fail to\ngeneralize to the case when images are not perfectly aligned. We term the\nproblem of unsupervised anomaly detection between two such imperfectly aligned\nsets of images as Scene Anomaly Detection (Scene AD). We present a novel\nnetwork termed OmniAD to address the Scene AD problem posed. Specifically, we\nrefine the anomaly detection method reverse distillation to achieve a 40%\nincrease in pixel-level anomaly detection performance. The network's\nperformance is further demonstrated to improve with two new data augmentation\nstrategies proposed that leverage novel view synthesis and camera localization\nto improve generalization. We validate our approach with qualitative and\nquantitative results on a new dataset, ToyCity, the first Scene AD dataset with\nmultiple objects, as well as on the established single object-centric dataset,\nMAD. https://drags99.github.io/OmniAD/\n","authors":["Subin Varghese","Vedhus Hoskere"],"pdf_url":"https://arxiv.org/pdf/2406.18012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18011v1","updated":"2024-06-26T01:48:56Z","published":"2024-06-26T01:48:56Z","title":"Expressive Keypoints for Skeleton-based Action Recognition via Skeleton\n  Transformation","summary":"  In the realm of skeleton-based action recognition, the traditional methods\nwhich rely on coarse body keypoints fall short of capturing subtle human\nactions. In this work, we propose Expressive Keypoints that incorporates hand\nand foot details to form a fine-grained skeletal representation, improving the\ndiscriminative ability for existing models in discerning intricate actions. To\nefficiently model Expressive Keypoints, the Skeleton Transformation strategy is\npresented to gradually downsample the keypoints and prioritize prominent joints\nby allocating the importance weights. Additionally, a plug-and-play Instance\nPooling module is exploited to extend our approach to multi-person scenarios\nwithout surging computation costs. Extensive experimental results over seven\ndatasets present the superiority of our method compared to the state-of-the-art\nfor skeleton-based human action recognition. Code is available at\nhttps://github.com/YijieYang23/SkeleT-GCN.\n","authors":["Yijie Yang","Jinlu Zhang","Jiaxu Zhang","Zhigang Tu"],"pdf_url":"https://arxiv.org/pdf/2406.18011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10912v3","updated":"2024-06-26T01:30:49Z","published":"2023-10-17T01:12:08Z","title":"Towards Training-free Open-world Segmentation via Image Prompt\n  Foundation Models","summary":"  The realm of computer vision has witnessed a paradigm shift with the advent\nof foundational models, mirroring the transformative influence of large\nlanguage models in the domain of natural language processing. This paper delves\ninto the exploration of open-world segmentation, presenting a novel approach\ncalled Image Prompt Segmentation (IPSeg) that harnesses the power of vision\nfoundational models. IPSeg lies the principle of a training-free paradigm,\nwhich capitalizes on image prompt techniques. Specifically, IPSeg utilizes a\nsingle image containing a subjective visual concept as a flexible prompt to\nquery vision foundation models like DINOv2 and Stable Diffusion. Our approach\nextracts robust features for the prompt image and input image, then matches the\ninput representations to the prompt representations via a novel feature\ninteraction module to generate point prompts highlighting target objects in the\ninput image. The generated point prompts are further utilized to guide the\nSegment Anything Model to segment the target object in the input image. The\nproposed method stands out by eliminating the need for exhaustive training\nsessions, thereby offering a more efficient and scalable solution. Experiments\non COCO, PASCAL VOC, and other datasets demonstrate IPSeg's efficacy for\nflexible open-world segmentation using intuitive image prompts. This work\npioneers tapping foundation models for open-world understanding through visual\nconcepts conveyed in images.\n","authors":["Lv Tang","Peng-Tao Jiang","Hao-Ke Xiao","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2310.10912v3.pdf","comment":"This paper is accepted by IJCV2024"},{"id":"http://arxiv.org/abs/2406.17998v1","updated":"2024-06-26T01:03:39Z","published":"2024-06-26T01:03:39Z","title":"Changen2: Multi-Temporal Remote Sensing Generative Change Foundation\n  Model","summary":"  Our understanding of the temporal dynamics of the Earth's surface has been\nadvanced by deep vision models, which often require lots of labeled\nmulti-temporal images for training. However, collecting, preprocessing, and\nannotating multi-temporal remote sensing images at scale is non-trivial since\nit is expensive and knowledge-intensive. In this paper, we present change data\ngenerators based on generative models, which are cheap and automatic,\nalleviating these data problems. Our main idea is to simulate a stochastic\nchange process over time. We describe the stochastic change process as a\nprobabilistic graphical model (GPCM), which factorizes the complex simulation\nproblem into two more tractable sub-problems, i.e., change event simulation and\nsemantic change synthesis. To solve these two problems, we present Changen2, a\nGPCM with a resolution-scalable diffusion transformer which can generate time\nseries of images and their semantic and change labels from labeled or unlabeled\nsingle-temporal images. Changen2 is a generative change foundation model that\ncan be trained at scale via self-supervision, and can produce change\nsupervisory signals from unlabeled single-temporal images. Unlike existing\nfoundation models, Changen2 synthesizes change data to train task-specific\nfoundation models for change detection. The resulting model possesses inherent\nzero-shot change detection capabilities and excellent transferability.\nExperiments suggest Changen2 has superior spatiotemporal scalability, e.g.,\nChangen2 model trained on 256$^2$ pixel single-temporal images can yield time\nseries of any length and resolutions of 1,024$^2$ pixels. Changen2 pre-trained\nmodels exhibit superior zero-shot performance (narrowing the performance gap to\n3% on LEVIR-CD and approximately 10% on both S2Looking and SECOND, compared to\nfully supervised counterparts) and transferability across multiple types of\nchange tasks.\n","authors":["Zhuo Zheng","Stefano Ermon","Dongjun Kim","Liangpei Zhang","Yanfei Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.17998v1.pdf","comment":"The enhanced extension of our ICCV 2023 (Changen)"},{"id":"http://arxiv.org/abs/2406.17988v1","updated":"2024-06-26T00:08:29Z","published":"2024-06-26T00:08:29Z","title":"DICE: End-to-end Deformation Capture of Hand-Face Interactions from a\n  Single Image","summary":"  Reconstructing 3D hand-face interactions with deformations from a single\nimage is a challenging yet crucial task with broad applications in AR, VR, and\ngaming. The challenges stem from self-occlusions during single-view hand-face\ninteractions, diverse spatial relationships between hands and face, complex\ndeformations, and the ambiguity of the single-view setting. The first and only\nmethod for hand-face interaction recovery, Decaf, introduces a global fitting\noptimization guided by contact and deformation estimation networks trained on\nstudio-collected data with 3D annotations. However, Decaf suffers from a\ntime-consuming optimization process and limited generalization capability due\nto its reliance on 3D annotations of hand-face interaction data. To address\nthese issues, we present DICE, the first end-to-end method for\nDeformation-aware hand-face Interaction reCovEry from a single image. DICE\nestimates the poses of hands and faces, contacts, and deformations\nsimultaneously using a Transformer-based architecture. It features\ndisentangling the regression of local deformation fields and global mesh vertex\nlocations into two network branches, enhancing deformation and contact\nestimation for precise and robust hand-face mesh recovery. To improve\ngeneralizability, we propose a weakly-supervised training approach that\naugments the training set using in-the-wild images without 3D ground-truth\nannotations, employing the depths of 2D keypoints estimated by off-the-shelf\nmodels and adversarial priors of poses for supervision. Our experiments\ndemonstrate that DICE achieves state-of-the-art performance on a standard\nbenchmark and in-the-wild data in terms of accuracy and physical plausibility.\nAdditionally, our method operates at an interactive rate (20 fps) on an Nvidia\n4090 GPU, whereas Decaf requires more than 15 seconds for a single image. Our\ncode will be publicly available upon publication.\n","authors":["Qingxuan Wu","Zhiyang Dou","Sirui Xu","Soshi Shimada","Chen Wang","Zhengming Yu","Yuan Liu","Cheng Lin","Zeyu Cao","Taku Komura","Vladislav Golyanik","Christian Theobalt","Wenping Wang","Lingjie Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17988v1.pdf","comment":"23 pages, 9 figures, 3 tables"},{"id":"http://arxiv.org/abs/2406.18790v1","updated":"2024-06-26T23:21:42Z","published":"2024-06-26T23:21:42Z","title":"MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data","summary":"  We train a model to generate images from multimodal prompts of interleaved\ntext and images such as \"a <picture of a man> man and his <picture of a dog>\ndog in an <picture of a cartoon> animated style.\" We bootstrap a multimodal\ndataset by extracting semantically meaningful image crops corresponding to\nwords in the image captions of synthetically generated and publicly available\ntext-image data. Our model, MUMU, is composed of a vision-language model\nencoder with a diffusion decoder and is trained on a single 8xH100 GPU node.\nDespite being only trained on crops from the same image, MUMU learns to compose\ninputs from different images into a coherent output. For example, an input of a\nrealistic person and a cartoon will output the same person in the cartoon\nstyle, and an input of a standing subject and a scooter will output the subject\nriding the scooter. As a result, our model generalizes to tasks such as style\ntransfer and character consistency. Our results show the promise of using\nmultimodal models as general purpose controllers for image generation.\n","authors":["William Berman","Alexander Peysakhovich"],"pdf_url":"https://arxiv.org/pdf/2406.18790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13880v3","updated":"2024-06-26T22:43:05Z","published":"2024-04-22T05:07:02Z","title":"Regional Style and Color Transfer","summary":"  This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li","Qingtian Gong"],"pdf_url":"https://arxiv.org/pdf/2404.13880v3.pdf","comment":"Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning"},{"id":"http://arxiv.org/abs/2406.14815v2","updated":"2024-06-26T22:23:23Z","published":"2024-06-21T01:32:03Z","title":"Latent diffusion models for parameterization and data assimilation of\n  facies-based geomodels","summary":"  Geological parameterization entails the representation of a geomodel using a\nsmall set of latent variables and a mapping from these variables to grid-block\nproperties such as porosity and permeability. Parameterization is useful for\ndata assimilation (history matching), as it maintains geological realism while\nreducing the number of variables to be determined. Diffusion models are a new\nclass of generative deep-learning procedures that have been shown to outperform\nprevious methods, such as generative adversarial networks, for image generation\ntasks. Diffusion models are trained to \"denoise\", which enables them to\ngenerate new geological realizations from input fields characterized by random\nnoise. Latent diffusion models, which are the specific variant considered in\nthis study, provide dimension reduction through use of a low-dimensional latent\nvariable. The model developed in this work includes a variational autoencoder\nfor dimension reduction and a U-net for the denoising process. Our application\ninvolves conditional 2D three-facies (channel-levee-mud) systems. The latent\ndiffusion model is shown to provide realizations that are visually consistent\nwith samples from geomodeling software. Quantitative metrics involving spatial\nand flow-response statistics are evaluated, and general agreement between the\ndiffusion-generated models and reference realizations is observed. Stability\ntests are performed to assess the smoothness of the parameterization method.\nThe latent diffusion model is then used for ensemble-based data assimilation.\nTwo synthetic \"true\" models are considered. Significant uncertainty reduction,\nposterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and\nconsistent posterior geomodels, are achieved in both cases.\n","authors":["Guido Di Federico","Louis J. Durlofsky"],"pdf_url":"https://arxiv.org/pdf/2406.14815v2.pdf","comment":"- Moved Table 1 from before to after Section 4.2 heading - Renamed\n  output pdf file with paper title"},{"id":"http://arxiv.org/abs/2406.18765v1","updated":"2024-06-26T21:30:41Z","published":"2024-06-26T21:30:41Z","title":"WV-Net: A foundation model for SAR WV-mode satellite imagery trained\n  using contrastive self-supervised learning on 10 million images","summary":"  The European Space Agency's Copernicus Sentinel-1 (S-1) mission is a\nconstellation of C-band synthetic aperture radar (SAR) satellites that provide\nunprecedented monitoring of the world's oceans. S-1's wave mode (WV) captures\n20x20 km image patches at 5 m pixel resolution and is unaffected by cloud cover\nor time-of-day. The mission's open data policy has made SAR data easily\naccessible for a range of applications, but the need for manual image\nannotations is a bottleneck that hinders the use of machine learning methods.\nThis study uses nearly 10 million WV-mode images and contrastive\nself-supervised learning to train a semantic embedding model called WV-Net. In\nmultiple downstream tasks, WV-Net outperforms a comparable model that was\npre-trained on natural images (ImageNet) with supervised learning. Experiments\nshow improvements for estimating wave height (0.50 vs 0.60 RMSE using linear\nprobing), estimating near-surface air temperature (0.90 vs 0.97 RMSE), and\nperforming multilabel-classification of geophysical and atmospheric phenomena\n(0.96 vs 0.95 micro-averaged AUROC). WV-Net embeddings are also superior in an\nunsupervised image-retrieval task and scale better in data-sparse settings.\nTogether, these results demonstrate that WV-Net embeddings can support\ngeophysical research by providing a convenient foundation model for a variety\nof data analysis and exploration tasks.\n","authors":["Yannik Glaser","Justin E. Stopa","Linnea M. Wolniewicz","Ralph Foster","Doug Vandemark","Alexis Mouche","Bertrand Chapron","Peter Sadowski"],"pdf_url":"https://arxiv.org/pdf/2406.18765v1.pdf","comment":"20 pages, 9 figures, submitted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.04929v3","updated":"2024-06-26T20:57:15Z","published":"2024-02-07T14:56:13Z","title":"Source-Free Domain Adaptation with Diffusion-Guided Source Data\n  Generation","summary":"  This paper introduces a novel approach to leverage the generalizability of\nDiffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed\nDMSFDA method involves fine-tuning a pre-trained text-to-image diffusion model\nto generate source domain images using features from the target images to guide\nthe diffusion process. Specifically, the pre-trained diffusion model is\nfine-tuned to generate source samples that minimize entropy and maximize\nconfidence for the pre-trained source model. We then use a diffusion\nmodel-based image mixup strategy to bridge the domain gap between the source\nand target domains. We validate our approach through comprehensive experiments\nacross a range of datasets, including Office-31, Office-Home, and VisDA. The\nresults demonstrate significant improvements in SFDA performance, highlighting\nthe potential of diffusion models in generating contextually relevant,\ndomain-specific images.\n","authors":["Shivang Chopra","Suraj Kothawade","Houda Aynaou","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2402.04929v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2310.01701"},{"id":"http://arxiv.org/abs/2406.17173v2","updated":"2024-06-26T20:54:45Z","published":"2024-06-24T23:23:18Z","title":"Diff3Dformer: Leveraging Slice Sequence Diffusion for Enhanced 3D CT\n  Classification with Transformer Networks","summary":"  The manifestation of symptoms associated with lung diseases can vary in\ndifferent depths for individual patients, highlighting the significance of 3D\ninformation in CT scans for medical image classification. While Vision\nTransformer has shown superior performance over convolutional neural networks\nin image classification tasks, their effectiveness is often demonstrated on\nsufficiently large 2D datasets and they easily encounter overfitting issues on\nsmall medical image datasets. To address this limitation, we propose a\nDiffusion-based 3D Vision Transformer (Diff3Dformer), which utilizes the latent\nspace of the Diffusion model to form the slice sequence for 3D analysis and\nincorporates clustering attention into ViT to aggregate repetitive information\nwithin 3D CT scans, thereby harnessing the power of the advanced transformer in\n3D classification tasks on small datasets. Our method exhibits improved\nperformance on two different scales of small datasets of 3D lung CT scans,\nsurpassing the state of the art 3D methods and other transformer-based\napproaches that emerged during the COVID-19 pandemic, demonstrating its robust\nand superior performance across different scales of data. Experimental results\nunderscore the superiority of our proposed method, indicating its potential for\nenhancing medical image classification tasks in real-world scenarios.\n","authors":["Zihao Jin","Yingying Fang","Jiahao Huang","Caiwen Xu","Simon Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.17173v2.pdf","comment":"conference"},{"id":"http://arxiv.org/abs/2308.14936v3","updated":"2024-06-26T20:25:03Z","published":"2023-08-28T23:23:53Z","title":"AutoProSAM: Automated Prompting SAM for 3D Multi-Organ Segmentation","summary":"  Segment Anything Model (SAM) is one of the pioneering prompt-based foundation\nmodels for image segmentation and has been rapidly adopted for various medical\nimaging applications. However, in clinical settings, creating effective prompts\nis notably challenging and time-consuming, requiring the expertise of domain\nspecialists such as physicians. This requirement significantly diminishes SAM's\nprimary advantage - its interactive capability with end users - in medical\napplications. Moreover, recent studies have indicated that SAM, originally\ndesigned for 2D natural images, performs sub optimally on 3D medical image\nsegmentation tasks. This subpar performance is attributed to the domain gaps\nbetween natural and medical images and the disparities in spatial arrangements\nbetween 2D and 3D images, particularly in multi-organ segmentation\napplications. To overcome these challenges, we present a novel technique termed\nAutoProSAM. This method automates 3D multi-organ CT-based segmentation by\nleveraging SAM's foundational model capabilities without relying on domain\nexperts for prompts. The approach utilizes parameter-efficient adaptation\ntechniques to adapt SAM for 3D medical imagery and incorporates an effective\nautomatic prompt learning paradigm specific to this domain. By eliminating the\nneed for manual prompts, it enhances SAM's capabilities for 3D medical image\nsegmentation and achieves state-of-the-art (SOTA) performance in CT-based\nmulti-organ segmentation tasks.\n","authors":["Chengyin Li","Prashant Khanduri","Yao Qiang","Rafi Ibn Sultan","Indrin Chetty","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2308.14936v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18742v1","updated":"2024-06-26T20:16:49Z","published":"2024-06-26T20:16:49Z","title":"3D Feature Distillation with Object-Centric Priors","summary":"  Grounding natural language to the physical world is a ubiquitous topic with a\nwide range of applications in computer vision and robotics. Recently, 2D\nvision-language models such as CLIP have been widely popularized, due to their\nimpressive capabilities for open-vocabulary grounding in 2D images. Recent\nworks aim to elevate 2D CLIP features to 3D via feature distillation, but\neither learn neural fields that are scene-specific and hence lack\ngeneralization, or focus on indoor room scan data that require access to\nmultiple camera views, which is not practical in robot manipulation scenarios.\nAdditionally, related methods typically fuse features at pixel-level and assume\nthat all camera views are equally informative. In this work, we show that this\napproach leads to sub-optimal 3D features, both in terms of grounding accuracy,\nas well as segmentation crispness. To alleviate this, we propose a multi-view\nfeature fusion strategy that employs object-centric priors to eliminate\nuninformative views based on semantic information, and fuse features at\nobject-level via instance segmentation masks. To distill our object-centric 3D\nfeatures, we generate a large-scale synthetic multi-view dataset of cluttered\ntabletop scenes, spawning 15k scenes from over 3300 unique object instances,\nwhich we make publicly available. We show that our method reconstructs 3D CLIP\nfeatures with improved grounding capacity and spatial consistency, while doing\nso from single-view RGB-D, thus departing from the assumption of multiple\ncamera views at test time. Finally, we show that our approach can generalize to\nnovel tabletop domains and be re-purposed for 3D instance segmentation without\nfine-tuning, and demonstrate its utility for language-guided robotic grasping\nin clutter\n","authors":["Georgios Tziafas","Yucheng Xu","Zhibin Li","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2406.18742v1.pdf","comment":"Submitted CoRL-24"},{"id":"http://arxiv.org/abs/2404.07097v2","updated":"2024-06-26T20:09:12Z","published":"2024-04-10T15:37:00Z","title":"Fast Encoder-Based 3D from Casual Videos via Point Track Processing","summary":"  This paper addresses the long-standing challenge of reconstructing 3D\nstructures from videos with dynamic content. Current approaches to this problem\nwere not designed to operate on casual videos recorded by standard cameras or\nrequire a long optimization time.\n  Aiming to significantly improve the efficiency of previous approaches, we\npresent TracksTo4D, a learning-based approach that enables inferring 3D\nstructure and camera positions from dynamic content originating from casual\nvideos using a single efficient feed-forward pass. To achieve this, we propose\noperating directly over 2D point tracks as input and designing an architecture\ntailored for processing 2D point tracks. Our proposed architecture is designed\nwith two key principles in mind: (1) it takes into account the inherent\nsymmetries present in the input point tracks data, and (2) it assumes that the\nmovement patterns can be effectively represented using a low-rank\napproximation. TracksTo4D is trained in an unsupervised way on a dataset of\ncasual videos utilizing only the 2D point tracks extracted from the videos,\nwithout any 3D supervision. Our experiments show that TracksTo4D can\nreconstruct a temporal point cloud and camera positions of the underlying video\nwith accuracy comparable to state-of-the-art methods, while drastically\nreducing runtime by up to 95\\%. We further show that TracksTo4D generalizes\nwell to unseen videos of unseen semantic categories at inference time.\n","authors":["Yoni Kasten","Wuyue Lu","Haggai Maron"],"pdf_url":"https://arxiv.org/pdf/2404.07097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18722v1","updated":"2024-06-26T19:42:08Z","published":"2024-06-26T19:42:08Z","title":"Towards Open-World Grasping with Large Vision-Language Models","summary":"  The ability to grasp objects in-the-wild from open-ended language\ninstructions constitutes a fundamental challenge in robotics. An open-world\ngrasping system should be able to combine high-level contextual with low-level\nphysical-geometric reasoning in order to be applicable in arbitrary scenarios.\nRecent works exploit the web-scale knowledge inherent in large language models\n(LLMs) to plan and reason in robotic context, but rely on external vision and\naction models to ground such knowledge into the environment and parameterize\nactuation. This setup suffers from two major bottlenecks: a) the LLM's\nreasoning capacity is constrained by the quality of visual grounding, and b)\nLLMs do not contain low-level spatial understanding of the world, which is\nessential for grasping in contact-rich scenarios. In this work we demonstrate\nthat modern vision-language models (VLMs) are capable of tackling such\nlimitations, as they are implicitly grounded and can jointly reason about\nsemantics and geometry. We propose OWG, an open-world grasping pipeline that\ncombines VLMs with segmentation and grasp synthesis models to unlock grounded\nworld understanding in three stages: open-ended referring segmentation,\ngrounded grasp planning and grasp ranking via contact reasoning, all of which\ncan be applied zero-shot via suitable visual prompting mechanisms. We conduct\nextensive evaluation in cluttered indoor scene datasets to showcase OWG's\nrobustness in grounding from open-ended language, as well as open-world robotic\ngrasping experiments in both simulation and hardware that demonstrate superior\nperformance compared to previous supervised and zero-shot LLM-based methods.\n","authors":["Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2406.18722v1.pdf","comment":"Submitted CoRL24"},{"id":"http://arxiv.org/abs/2406.18717v1","updated":"2024-06-26T19:37:07Z","published":"2024-06-26T19:37:07Z","title":"Dynamic Gaussian Marbles for Novel View Synthesis of Casual Monocular\n  Videos","summary":"  Gaussian splatting has become a popular representation for novel-view\nsynthesis, exhibiting clear strengths in efficiency, photometric quality, and\ncompositional edibility. Following its success, many works have extended\nGaussians to 4D, showing that dynamic Gaussians maintain these benefits while\nalso tracking scene geometry far better than alternative representations. Yet,\nthese methods assume dense multi-view videos as supervision, constraining their\nuse to controlled capture settings. In this work, we extend the capability of\nGaussian scene representations to casually captured monocular videos. We show\nthat existing 4D Gaussian methods dramatically fail in this setup because the\nmonocular setting is underconstrained. Building off this finding, we propose\nDynamic Gaussian Marbles (DGMarbles), consisting of three core modifications\nthat target the difficulties of the monocular setting. First, DGMarbles uses\nisotropic Gaussian \"marbles\", reducing the degrees of freedom of each Gaussian,\nand constraining the optimization to focus on motion and appearance over local\nshape. Second, DGMarbles employs a hierarchical divide-and-conquer learning\nstrategy to guide the optimization towards solutions with coherent motion.\nFinally, DGMarbles adds image-level and geometry-level priors into the\noptimization, including a tracking loss that takes advantage of recent progress\nin point tracking. By constraining the optimization in these ways, DGMarbles\nlearns Gaussian trajectories that enable novel-view rendering and accurately\ncapture the 3D motion of the scene elements. We evaluate on the (monocular)\nNvidia Dynamic Scenes dataset and the Dycheck iPhone dataset, and show that\nDGMarbles significantly outperforms other Gaussian baselines in quality, and is\non-par with non-Gaussian representations, all while maintaining the efficiency,\ncompositionality, editability, and tracking benefits of Gaussians.\n","authors":["Colton Stearns","Adam Harley","Mikaela Uy","Florian Dubost","Federico Tombari","Gordon Wetzstein","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2406.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18709v1","updated":"2024-06-26T19:18:36Z","published":"2024-06-26T19:18:36Z","title":"SpY: A Context-Based Approach to Spacecraft Component Detection","summary":"  This paper focuses on autonomously characterizing components such as solar\npanels, body panels, antennas, and thrusters of an unknown resident space\nobject (RSO) using camera feed to aid autonomous on-orbit servicing (OOS) and\nactive debris removal. Significant research has been conducted in this area\nusing convolutional neural networks (CNNs). While CNNs are powerful at learning\npatterns and performing object detection, they struggle with missed detections\nand misclassifications in environments different from the training data, making\nthem unreliable for safety in high-stakes missions like OOS. Additionally,\nfailures exhibited by CNNs are often easily rectifiable by humans using\ncommonsense reasoning and contextual knowledge. Embedding such reasoning in an\nobject detector could improve detection accuracy. To validate this hypothesis,\nthis paper presents an end-to-end object detector called SpaceYOLOv2 (SpY),\nwhich leverages the generalizability of CNNs while incorporating contextual\nknowledge using traditional computer vision techniques. SpY consists of two\nmain components: a shape detector and the SpaceYOLO classifier (SYC). The shape\ndetector uses CNNs to detect primitive shapes of RSOs and SYC associates these\nshapes with contextual knowledge, such as color and texture, to classify them\nas spacecraft components or \"unknown\" if the detected shape is uncertain. SpY's\nmodular architecture allows customizable usage of contextual knowledge to\nimprove detection performance, or SYC as a secondary fail-safe classifier with\nan existing spacecraft component detector. Performance evaluations on\nhardware-in-the-loop images of a mock-up spacecraft demonstrate that SpY is\naccurate and an ensemble of SpY with YOLOv5 trained for satellite component\ndetection improved the performance by 23.4% in recall, demonstrating enhanced\nsafety for vision-based navigation tasks.\n","authors":["Trupti Mahendrakar","Ryan T. White","Madhur Tiwari"],"pdf_url":"https://arxiv.org/pdf/2406.18709v1.pdf","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.18691v1","updated":"2024-06-26T18:52:53Z","published":"2024-06-26T18:52:53Z","title":"Geometric Features Enhanced Human-Object Interaction Detection","summary":"  Cameras are essential vision instruments to capture images for pattern\ndetection and measurement. Human-object interaction (HOI) detection is one of\nthe most popular pattern detection approaches for captured human-centric visual\nscenes. Recently, Transformer-based models have become the dominant approach\nfor HOI detection due to their advanced network architectures and thus\npromising results. However, most of them follow the one-stage design of vanilla\nTransformer, leaving rich geometric priors under-exploited and leading to\ncompromised performance especially when occlusion occurs. Given that geometric\nfeatures tend to outperform visual ones in occluded scenarios and offer\ninformation that complements visual cues, we propose a novel end-to-end\nTransformer-style HOI detection model, i.e., geometric features enhanced HOI\ndetector (GeoHOI). One key part of the model is a new unified self-supervised\nkeypoint learning method named UniPointNet that bridges the gap of consistent\nkeypoint representation across diverse object categories, including humans.\nGeoHOI effectively upgrades a Transformer-based HOI detector benefiting from\nthe keypoints similarities measuring the likelihood of human-object\ninteractions as well as local keypoint patches to enhance interaction query\nrepresentation, so as to boost HOI predictions. Extensive experiments show that\nthe proposed method outperforms the state-of-the-art models on V-COCO and\nachieves competitive performance on HICO-DET. Case study results on the\npost-disaster rescue with vision-based instruments showcase the applicability\nof the proposed GeoHOI in real-world applications.\n","authors":["Manli Zhu","Edmond S. L. Ho","Shuang Chen","Longzhi Yang","Hubert P. H. Shum"],"pdf_url":"https://arxiv.org/pdf/2406.18691v1.pdf","comment":"Accepted to IEEE TIM"},{"id":"http://arxiv.org/abs/2406.18684v1","updated":"2024-06-26T18:42:22Z","published":"2024-06-26T18:42:22Z","title":"CSI4Free: GAN-Augmented mmWave CSI for Improved Pose Classification","summary":"  In recent years, Joint Communication and Sensing (JC&S), has demonstrated\nsignificant success, particularly in utilizing sub-6 GHz frequencies with\ncommercial-off-the-shelf (COTS) Wi-Fi devices for applications such as\nlocalization, gesture recognition, and pose classification. Deep learning and\nthe existence of large public datasets has been pivotal in achieving such\nresults. However, at mmWave frequencies (30-300 GHz), which has shown potential\nfor more accurate sensing performance, there is a noticeable lack of research\nin the domain of COTS Wi-Fi sensing. Challenges such as limited research\nhardware, the absence of large datasets, limited functionality in COTS\nhardware, and the complexities of data collection present obstacles to a\ncomprehensive exploration of this field. In this work, we aim to address these\nchallenges by developing a method that can generate synthetic mmWave channel\nstate information (CSI) samples. In particular, we use a generative adversarial\nnetwork (GAN) on an existing dataset, to generate 30,000 additional CSI\nsamples. The augmented samples exhibit a remarkable degree of consistency with\nthe original data, as indicated by the notably high GAN-train and GAN-test\nscores. Furthermore, we integrate the augmented samples in training a pose\nclassification model. We observe that the augmented samples complement the real\ndata and improve the generalization of the classification model.\n","authors":["Nabeel Nisar Bhat","Rafael Berkvens Jeroen Famaey"],"pdf_url":"https://arxiv.org/pdf/2406.18684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.16693v4","updated":"2024-06-26T18:00:02Z","published":"2023-12-27T19:11:50Z","title":"I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models","summary":"  Text-guided image-to-video (I2V) generation aims to generate a coherent video\nthat preserves the identity of the input image and semantically aligns with the\ninput prompt. Existing methods typically augment pretrained text-to-video (T2V)\nmodels by either concatenating the image with noised video frames channel-wise\nbefore being fed into the model or injecting the image embedding produced by\npretrained image encoders in cross-attention modules. However, the former\napproach often necessitates altering the fundamental weights of pretrained T2V\nmodels, thus restricting the model's compatibility within the open-source\ncommunities and disrupting the model's prior knowledge. Meanwhile, the latter\ntypically fails to preserve the identity of the input image. We present\nI2V-Adapter to overcome such limitations. I2V-Adapter adeptly propagates the\nunnoised input image to subsequent noised frames through a cross-frame\nattention mechanism, maintaining the identity of the input image without any\nchanges to the pretrained T2V model. Notably, I2V-Adapter only introduces a few\ntrainable parameters, significantly alleviating the training cost and also\nensures compatibility with existing community-driven personalized models and\ncontrol tools. Moreover, we propose a novel Frame Similarity Prior to balance\nthe motion amplitude and the stability of generated videos through two\nadjustable control coefficients. Our experimental results demonstrate that\nI2V-Adapter is capable of producing high-quality videos. This performance,\ncoupled with its agility and adaptability, represents a substantial advancement\nin the field of I2V, particularly for personalized and controllable\napplications.\n","authors":["Xun Guo","Mingwu Zheng","Liang Hou","Yuan Gao","Yufan Deng","Pengfei Wan","Di Zhang","Yufan Liu","Weiming Hu","Zhengjun Zha","Haibin Huang","Chongyang Ma"],"pdf_url":"https://arxiv.org/pdf/2312.16693v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18628v1","updated":"2024-06-26T16:58:15Z","published":"2024-06-26T16:58:15Z","title":"IDA-UIE: An Iterative Framework for Deep Network-based Degradation Aware\n  Underwater Image Enhancement","summary":"  Underwater image quality is affected by fluorescence, low illumination,\nabsorption, and scattering. Recent works in underwater image enhancement have\nproposed different deep network architectures to handle these problems. Most of\nthese works have proposed a single network to handle all the challenges. We\nbelieve that deep networks trained for specific conditions deliver better\nperformance than a single network learned from all degradation cases.\nAccordingly, the first contribution of this work lies in the proposal of an\niterative framework where a single dominant degradation condition is identified\nand resolved. This proposal considers the following eight degradation\nconditions -- low illumination, low contrast, haziness, blurred image, presence\nof noise and color imbalance in three different channels. A deep network is\ndesigned to identify the dominant degradation condition. Accordingly, an\nappropriate deep network is selected for degradation condition-specific\nenhancement. The second contribution of this work is the construction of\ndegradation condition specific datasets from good quality images of two\nstandard datasets (UIEB and EUVP). This dataset is used to learn the condition\nspecific enhancement networks. The proposed approach is found to outperform\nnine baseline methods on UIEB and EUVP datasets.\n","authors":["Pranjali Singh","Prithwijit Guha"],"pdf_url":"https://arxiv.org/pdf/2406.18628v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2406.07544v2","updated":"2024-06-26T17:59:50Z","published":"2024-06-11T17:59:45Z","title":"Situational Awareness Matters in 3D Vision Language Reasoning","summary":"  Being able to carry out complicated vision language reasoning tasks in 3D\nspace represents a significant milestone in developing household robots and\nhuman-centered embodied AI. In this work, we demonstrate that a critical and\ndistinct challenge in 3D vision language reasoning is situational awareness,\nwhich incorporates two key components: (1) The autonomous agent grounds its\nself-location based on a language prompt. (2) The agent answers open-ended\nquestions from the perspective of its calculated position. To address this\nchallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D\nvision language reasoning. We tokenize the 3D scene into sparse voxel\nrepresentation and propose a language-grounded situation estimator, followed by\na situated question answering module. Experiments on the SQA3D and ScanQA\ndatasets show that SIG3D outperforms state-of-the-art models in situation\nestimation and question answering by a large margin (e.g., an enhancement of\nover 30% on situation estimation accuracy). Subsequent analysis corroborates\nour architectural design choices, explores the distinct functions of visual and\ntextual tokens, and highlights the importance of situational awareness in the\ndomain of 3D question answering.\n","authors":["Yunze Man","Liang-Yan Gui","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2406.07544v2.pdf","comment":"CVPR 2024. Project Page: https://yunzeman.github.io/situation3d"},{"id":"http://arxiv.org/abs/2306.13928v2","updated":"2024-06-26T17:59:37Z","published":"2023-06-24T10:25:53Z","title":"On Convex Data-Driven Inverse Optimal Control for Nonlinear,\n  Non-stationary and Stochastic Systems","summary":"  This paper is concerned with a finite-horizon inverse control problem, which\nhas the goal of reconstructing, from observations, the possibly non-convex and\nnon-stationary cost driving the actions of an agent. In this context, we\npresent a result enabling cost reconstruction by solving an optimization\nproblem that is convex even when the agent cost is not and when the underlying\ndynamics is nonlinear, non-stationary and stochastic. To obtain this result, we\nalso study a finite-horizon forward control problem that has randomized\npolicies as decision variables. We turn our findings into algorithmic\nprocedures and show the effectiveness of our approach via in-silico and\nhardware validations. All experiments confirm the effectiveness of our\napproach.\n","authors":["Emiland Garrabe","Hozefa Jesawada","Carmen Del Vecchio","Giovanni Russo"],"pdf_url":"https://arxiv.org/pdf/2306.13928v2.pdf","comment":"17 pages, 5 figures. An early version of this paper with only a\n  sketch of the proof for one of the results and without the hardware\n  validation was presentation at the 62nd IEEE Conference on Decision and\n  Control. arXiv admin note: text overlap with arXiv:2303.17957"},{"id":"http://arxiv.org/abs/2406.18534v1","updated":"2024-06-26T17:59:30Z","published":"2024-06-26T17:59:30Z","title":"Towards Compositionality in Concept Learning","summary":"  Concept-based interpretability methods offer a lens into the internals of\nfoundation models by decomposing their embeddings into high-level concepts.\nThese concept representations are most useful when they are compositional,\nmeaning that the individual concepts compose to explain the full sample. We\nshow that existing unsupervised concept extraction methods find concepts which\nare not compositional. To automatically discover compositional concept\nrepresentations, we identify two salient properties of such representations,\nand propose Compositional Concept Extraction (CCE) for finding concepts which\nobey these properties. We evaluate CCE on five different datasets over image\nand text data. Our evaluation shows that CCE finds more compositional concept\nrepresentations than baselines and yields better accuracy on four downstream\nclassification tasks. Code and data are available at\nhttps://github.com/adaminsky/compositional_concepts .\n","authors":["Adam Stein","Aaditya Naik","Yinjun Wu","Mayur Naik","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2406.18534v1.pdf","comment":"Accepted at ICML 2024. 26 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.18532v1","updated":"2024-06-26T17:59:18Z","published":"2024-06-26T17:59:18Z","title":"Symbolic Learning Enables Self-Evolving Agents","summary":"  The AI community has been exploring a pathway to artificial general\nintelligence (AGI) by developing \"language agents\", which are complex large\nlanguage models (LLMs) pipelines involving both prompting techniques and tool\nusage methods. While language agents have demonstrated impressive capabilities\nfor many real-world tasks, a fundamental limitation of current language agents\nresearch is that they are model-centric, or engineering-centric. That's to say,\nthe progress on prompts, tools, and pipelines of language agents requires\nsubstantial manual engineering efforts from human experts rather than\nautomatically learning from data. We believe the transition from model-centric,\nor engineering-centric, to data-centric, i.e., the ability of language agents\nto autonomously learn and evolve in environments, is the key for them to\npossibly achieve AGI.\n  In this work, we introduce agent symbolic learning, a systematic framework\nthat enables language agents to optimize themselves on their own in a\ndata-centric way using symbolic optimizers. Specifically, we consider agents as\nsymbolic networks where learnable weights are defined by prompts, tools, and\nthe way they are stacked together. Agent symbolic learning is designed to\noptimize the symbolic network within language agents by mimicking two\nfundamental algorithms in connectionist learning: back-propagation and gradient\ndescent. Instead of dealing with numeric weights, agent symbolic learning works\nwith natural language simulacrums of weights, loss, and gradients. We conduct\nproof-of-concept experiments on both standard benchmarks and complex real-world\ntasks and show that agent symbolic learning enables language agents to update\nthemselves after being created and deployed in the wild, resulting in\n\"self-evolving agents\".\n","authors":["Wangchunshu Zhou","Yixin Ou","Shengwei Ding","Long Li","Jialong Wu","Tiannan Wang","Jiamin Chen","Shuai Wang","Xiaohua Xu","Ningyu Zhang","Huajun Chen","Yuchen Eleanor Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.18532v1.pdf","comment":"Code available at https://github.com/aiwaves-cn/agents"},{"id":"http://arxiv.org/abs/2406.18529v1","updated":"2024-06-26T17:57:13Z","published":"2024-06-26T17:57:13Z","title":"Confident Natural Policy Gradient for Local Planning in\n  $q_π$-realizable Constrained MDPs","summary":"  The constrained Markov decision process (CMDP) framework emerges as an\nimportant reinforcement learning approach for imposing safety or other critical\nobjectives while maximizing cumulative reward. However, the current\nunderstanding of how to learn efficiently in a CMDP environment with a\npotentially infinite number of states remains under investigation, particularly\nwhen function approximation is applied to the value functions. In this paper,\nwe address the learning problem given linear function approximation with\n$q_{\\pi}$-realizability, where the value functions of all policies are linearly\nrepresentable with a known feature map, a setting known to be more general and\nchallenging than other linear settings. Utilizing a local-access model, we\npropose a novel primal-dual algorithm that, after $\\tilde{O}(\\text{poly}(d)\n\\epsilon^{-3})$ queries, outputs with high probability a policy that strictly\nsatisfies the constraints while nearly optimizing the value with respect to a\nreward function. Here, $d$ is the feature dimension and $\\epsilon > 0$ is a\ngiven error. The algorithm relies on a carefully crafted off-policy evaluation\nprocedure to evaluate the policy using historical data, which informs policy\nupdates through policy gradients and conserves samples. To our knowledge, this\nis the first result achieving polynomial sample complexity for CMDP in the\n$q_{\\pi}$-realizable setting.\n","authors":["Tian Tian","Lin F. Yang","Csaba Szepesvári"],"pdf_url":"https://arxiv.org/pdf/2406.18529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18518v1","updated":"2024-06-26T17:49:11Z","published":"2024-06-26T17:49:11Z","title":"APIGen: Automated Pipeline for Generating Verifiable and Diverse\n  Function-Calling Datasets","summary":"  The advancement of function-calling agent models requires diverse, reliable,\nand high-quality datasets. This paper presents APIGen, an automated data\ngeneration pipeline designed to synthesize verifiable high-quality datasets for\nfunction-calling applications. We leverage APIGen and collect 3,673 executable\nAPIs across 21 different categories to generate diverse function-calling\ndatasets in a scalable and structured manner. Each data in our dataset is\nverified through three hierarchical stages: format checking, actual function\nexecutions, and semantic verification, ensuring its reliability and\ncorrectness. We demonstrate that models trained with our curated datasets, even\nwith only 7B parameters, can achieve state-of-the-art performance on the\nBerkeley Function-Calling Benchmark, outperforming multiple GPT-4 models.\nMoreover, our 1B model achieves exceptional performance, surpassing\nGPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000\nhigh-quality entries, aiming to advance the field of function-calling agent\ndomains. The dataset is available on Huggingface:\nhttps://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and the\nproject homepage: https://apigen-pipeline.github.io/\n","authors":["Zuxin Liu","Thai Hoang","Jianguo Zhang","Ming Zhu","Tian Lan","Shirley Kokane","Juntao Tan","Weiran Yao","Zhiwei Liu","Yihao Feng","Rithesh Murthy","Liangwei Yang","Silvio Savarese","Juan Carlos Niebles","Huan Wang","Shelby Heinecke","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.18518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10552v2","updated":"2024-06-26T17:42:59Z","published":"2024-06-15T08:13:47Z","title":"Large Language Model Enhanced Clustering for News Event Detection","summary":"  The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labeling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes latent feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that combining LLM embeddings with clustering algorithms yields the\nbest results, demonstrating greater robustness in terms of CSAI scores.\nMoreover, post-event detection tasks generate meaningful insights, facilitating\neffective interpretation of event clustering results. Overall, our experimental\nresults indicate that the proposed framework offers valuable insights and could\nenhance the accuracy and depth of news reporting.\n","authors":["Adane Nega Tarekegn"],"pdf_url":"https://arxiv.org/pdf/2406.10552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01248v3","updated":"2024-06-26T17:40:14Z","published":"2023-11-02T14:02:42Z","title":"Multimodal and Force-Matched Imitation Learning with a See-Through\n  Visuotactile Sensor","summary":"  Contact-rich tasks continue to present a variety of challenges for robotic\nmanipulation. In this work, we leverage a multimodal visuotactile sensor within\nthe framework of imitation learning (IL) to perform contact rich tasks that\ninvolve relative motion (slipping/sliding) between the end-effector and object.\nWe introduce two algorithmic contributions, tactile force matching and learned\nmode switching, as complimentary methods for improving IL. Tactile force\nmatching enhances kinesthetic teaching by reading approximate forces during the\ndemonstration and generating an adapted robot trajectory that recreates the\nrecorded forces. Learned mode switching uses IL to couple visual and tactile\nsensor modes with the learned motion policy, simplifying the transition from\nreaching to contacting. We perform robotic manipulation experiments on four\ndoor opening tasks with a variety of observation and method configurations to\nstudy the utility of our proposed improvements and multimodal visuotactile\nsensing. Our results show that the inclusion of force matching raises average\npolicy success rates by 62.5%, visuotactile mode switching by 30.3%, and\nvisuotactile data as a policy input by 42.5%, emphasizing the value of\nsee-through tactile sensing for IL, both for data collection to allow force\nmatching, and for policy execution to allow accurate task feedback.\n","authors":["Trevor Ablett","Oliver Limoyo","Adam Sigal","Affan Jilani","Jonathan Kelly","Kaleem Siddiqi","Francois Hogan","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2311.01248v3.pdf","comment":"Submitted to IEEE Transactions on Robotics (T-RO): Special Section on\n  Tactile Robotics"},{"id":"http://arxiv.org/abs/2404.15778v2","updated":"2024-06-26T17:29:46Z","published":"2024-04-24T09:57:11Z","title":"BASS: Batched Attention-optimized Speculative Sampling","summary":"  Speculative decoding has emerged as a powerful method to improve latency and\nthroughput in hosting large language models. However, most existing\nimplementations focus on generating a single sequence. Real-world generative AI\napplications often require multiple responses and how to perform speculative\ndecoding in a batched setting while preserving its latency benefits poses\nnon-trivial challenges. This paper describes a system of batched speculative\ndecoding that sets a new state of the art in multi-sequence generation latency\nand that demonstrates superior GPU utilization as well as quality of\ngenerations within a time budget. For example, for a 7.8B-size model on a\nsingle A100 GPU and with a batch size of 8, each sequence is generated at an\naverage speed of 5.8ms per token, the overall throughput being 1.1K tokens per\nsecond. These results represent state-of-the-art latency and a 2.15X speed-up\nover optimized regular decoding. Within a time budget that regular decoding\ndoes not finish, our system is able to generate sequences with HumanEval\nPass@First of 43% and Pass@All of 61%, far exceeding what's feasible with\nsingle-sequence speculative decoding. Our peak GPU utilization during decoding\nreaches as high as 15.8%, more than 3X the highest of that of regular decoding\nand around 10X of single-sequence speculative decoding.\n","authors":["Haifeng Qian","Sujan Kumar Gonugondla","Sungsoo Ha","Mingyue Shang","Sanjay Krishna Gouda","Ramesh Nallapati","Sudipta Sengupta","Xiaofei Ma","Anoop Deoras"],"pdf_url":"https://arxiv.org/pdf/2404.15778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18505v1","updated":"2024-06-26T17:14:45Z","published":"2024-06-26T17:14:45Z","title":"Mental Modeling of Reinforcement Learning Agents by Language Models","summary":"  Can emergent language models faithfully model the intelligence of\ndecision-making agents? Though modern language models exhibit already some\nreasoning ability, and theoretically can potentially express any probable\ndistribution over tokens, it remains underexplored how the world knowledge\nthese pretrained models have memorized can be utilized to comprehend an agent's\nbehaviour in the physical world. This study empirically examines, for the first\ntime, how well large language models (LLMs) can build a mental model of agents,\ntermed agent mental modelling, by reasoning about an agent's behaviour and its\neffect on states from agent interaction history. This research may unveil the\npotential of leveraging LLMs for elucidating RL agent behaviour, addressing a\nkey challenge in eXplainable reinforcement learning (XRL). To this end, we\npropose specific evaluation metrics and test them on selected RL task datasets\nof varying complexity, reporting findings on agent mental model establishment.\nOur results disclose that LLMs are not yet capable of fully mental modelling\nagents through inference alone without further innovations. This work thus\nprovides new insights into the capabilities and limitations of modern LLMs.\n","authors":["Wenhao Lu","Xufeng Zhao","Josua Spisak","Jae Hee Lee","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2406.18505v1.pdf","comment":"https://lukaswill.github.io/"},{"id":"http://arxiv.org/abs/2310.16792v2","updated":"2024-06-26T17:12:21Z","published":"2023-10-25T17:24:01Z","title":"Learning Generalizable Program and Architecture Representations for\n  Performance Modeling","summary":"  Performance modeling is an essential tool in many areas, including\nperformance characterization/optimization, design space exploration, and\nresource allocation problems, to name a few. However, existing performance\nmodeling approaches have limitations, such as high computational cost for\ndiscrete-event simulators, narrow flexibility of hardware emulators, or\nrestricted accuracy/generality of analytical/data-driven models. To address\nthese limitations, this paper proposes PerfVec, a novel deep learning-based\nperformance modeling framework that learns high-dimensional and\nindependent/orthogonal program and microarchitecture representations. Once\nlearned, a program representation can be used to predict its performance on any\nmicroarchitecture, and likewise, a microarchitecture representation can be\napplied in the performance prediction of any program. Additionally, PerfVec\nyields a foundation model that captures the performance essence of\ninstructions, which can be directly used by developers in numerous performance\nmodeling related tasks without incurring its training cost. The evaluation\ndemonstrates that PerfVec is more general and efficient than previous\napproaches.\n","authors":["Lingda Li","Thomas Flynn","Adolfy Hoisie"],"pdf_url":"https://arxiv.org/pdf/2310.16792v2.pdf","comment":"To be published at SC 2024"},{"id":"http://arxiv.org/abs/2405.00592v3","updated":"2024-06-26T16:56:06Z","published":"2024-05-01T15:59:00Z","title":"Scaling and renormalization in high-dimensional regression","summary":"  This paper presents a succinct derivation of the training and generalization\nperformance of a variety of high-dimensional ridge regression models using the\nbasic tools of random matrix theory and free probability. We provide an\nintroduction and review of recent results on these topics, aimed at readers\nwith backgrounds in physics and deep learning. Analytic formulas for the\ntraining and generalization errors are obtained in a few lines of algebra\ndirectly from the properties of the $S$-transform of free probability. This\nallows for a straightforward identification of the sources of power-law scaling\nin model performance. We compute the generalization error of a broad class of\nrandom feature models. We find that in all models, the $S$-transform\ncorresponds to the train-test generalization gap, and yields an analogue of the\ngeneralized-cross-validation estimator. Using these techniques, we derive\nfine-grained bias-variance decompositions for a very general class of random\nfeature models with structured covariates. These novel results allow us to\ndiscover a scaling regime for random feature models where the variance due to\nthe features limits performance in the overparameterized setting. We also\ndemonstrate how anisotropic weight structure in random feature models can limit\nperformance and lead to nontrivial exponents for finite-width corrections in\nthe overparameterized setting. Our results extend and provide a unifying\nperspective on earlier models of neural scaling laws.\n","authors":["Alexander Atanasov","Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2405.00592v3.pdf","comment":"68 pages, 17 figures"},{"id":"http://arxiv.org/abs/2406.18491v1","updated":"2024-06-26T16:55:07Z","published":"2024-06-26T16:55:07Z","title":"Enhancing Federated Learning with Adaptive Differential Privacy and\n  Priority-Based Aggregation","summary":"  Federated learning (FL), a novel branch of distributed machine learning (ML),\ndevelops global models through a private procedure without direct access to\nlocal datasets. However, it is still possible to access the model updates\n(gradient updates of deep neural networks) transferred between clients and\nservers, potentially revealing sensitive local information to adversaries using\nmodel inversion attacks. Differential privacy (DP) offers a promising approach\nto addressing this issue by adding noise to the parameters. On the other hand,\nheterogeneities in data structure, storage, communication, and computational\ncapabilities of devices can cause convergence problems and delays in developing\nthe global model. A personalized weighted averaging of local parameters based\non the resources of each device can yield a better aggregated model in each\nround. In this paper, to efficiently preserve privacy, we propose a\npersonalized DP framework that injects noise based on clients' relative impact\nfactors and aggregates parameters while considering heterogeneities and\nadjusting properties. To fulfill the DP requirements, we first analyze the\nconvergence boundary of the FL algorithm when impact factors are personalized\nand fixed throughout the learning process. We then further study the\nconvergence property considering time-varying (adaptive) impact factors.\n","authors":["Mahtab Talaei","Iman Izadi"],"pdf_url":"https://arxiv.org/pdf/2406.18491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08609v3","updated":"2024-06-26T16:50:01Z","published":"2024-02-13T17:18:56Z","title":"Mixtures of Experts Unlock Parameter Scaling for Deep RL","summary":"  The recent rapid progress in (self) supervised learning models is in large\npart predicted by empirical scaling laws: a model's performance scales\nproportionally to its size. Analogous scaling laws remain elusive for\nreinforcement learning domains, however, where increasing the parameter count\nof a model often hurts its final performance. In this paper, we demonstrate\nthat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs\n(Puigcerver et al., 2023), into value-based networks results in more\nparameter-scalable models, evidenced by substantial performance increases\nacross a variety of training regimes and model sizes. This work thus provides\nstrong empirical evidence towards developing scaling laws for reinforcement\nlearning.\n","authors":["Johan Obando-Ceron","Ghada Sokar","Timon Willi","Clare Lyle","Jesse Farebrother","Jakob Foerster","Gintare Karolina Dziugaite","Doina Precup","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2402.08609v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08722v2","updated":"2024-06-26T16:46:19Z","published":"2024-04-12T13:24:28Z","title":"VADA: a Data-Driven Simulator for Nanopore Sequencing","summary":"  Nanopore sequencing offers the ability for real-time analysis of long DNA\nsequences at a low cost, enabling new applications such as early detection of\ncancer. Due to the complex nature of nanopore measurements and the high cost of\nobtaining ground truth datasets, there is a need for nanopore simulators.\nExisting simulators rely on handcrafted rules and parameters and do not learn\nan internal representation that would allow for analysing underlying biological\nfactors of interest. Instead, we propose VADA, a purely data-driven method for\nsimulating nanopores based on an autoregressive latent variable model. We embed\nsubsequences of DNA and introduce a conditional prior to address the challenge\nof a collapsing conditioning. We introduce an auxiliary regressor on the latent\nvariable to encourage our model to learn an informative latent representation.\nWe empirically demonstrate that our model achieves competitive simulation\nperformance on experimental nanopore data. Moreover, we show we have learned an\ninformative latent representation that is predictive of the DNA labels. We\nhypothesize that other biological factors of interest, beyond the DNA labels,\ncan potentially be extracted from such a learned latent representation.\n","authors":["Jonas Niederle","Simon Koop","Marc Pagès-Gallego","Vlado Menkovski"],"pdf_url":"https://arxiv.org/pdf/2404.08722v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11039v2","updated":"2024-06-26T16:35:16Z","published":"2024-02-16T19:35:42Z","title":"Robustness to Subpopulation Shift with Domain Label Noise via\n  Regularized Annotation of Domains","summary":"  Existing methods for last layer retraining that aim to optimize worst-group\naccuracy (WGA) rely heavily on well-annotated groups in the training data. We\nshow, both in theory and practice, that annotation-based data augmentations\nusing either downsampling or upweighting for WGA are susceptible to domain\nannotation noise, and in high-noise regimes approach the WGA of a model trained\nwith vanilla empirical risk minimization. We introduce Regularized Annotation\nof Domains (RAD) in order to train robust last layer classifiers without the\nneed for explicit domain annotations. Our results show that RAD is competitive\nwith other recently proposed domain annotation-free techniques. Most\nimportantly, RAD outperforms state-of-the-art annotation-reliant methods even\nwith only 5% noise in the training data for several publicly available\ndatasets.\n","authors":["Nathan Stromberg","Rohan Ayyagari","Monica Welfert","Sanmi Koyejo","Richard Nock","Lalitha Sankar"],"pdf_url":"https://arxiv.org/pdf/2402.11039v2.pdf","comment":"Generalized Gaussian assumption"},{"id":"http://arxiv.org/abs/2305.15598v3","updated":"2024-06-26T16:29:56Z","published":"2023-05-24T22:10:12Z","title":"ReLU Neural Networks with Linear Layers are Biased Towards Single- and\n  Multi-Index Models","summary":"  Neural networks often operate in the overparameterized regime, in which there\nare far more parameters than training samples, allowing the training data to be\nfit perfectly. That is, training the network effectively learns an\ninterpolating function, and properties of the interpolant affect predictions\nthe network will make on new samples. This manuscript explores how properties\nof such functions learned by neural networks of depth greater than two layers.\nOur framework considers a family of networks of varying depths that all have\nthe same capacity but different representation costs. The representation cost\nof a function induced by a neural network architecture is the minimum sum of\nsquared weights needed for the network to represent the function; it reflects\nthe function space bias associated with the architecture. Our results show that\nadding additional linear layers to the input side of a shallow ReLU network\nyields a representation cost favoring functions with low mixed variation - that\nis, it has limited variation in directions orthogonal to a low-dimensional\nsubspace and can be well approximated by a single- or multi-index model. Such\nfunctions may be represented by the composition of a function with low\ntwo-layer representation cost and a low-rank linear operator. Our experiments\nconfirm this behavior in standard network training regimes. They additionally\nshow that linear layers can improve generalization and the learned network is\nwell-aligned with the true latent low-dimensional linear subspace when data is\ngenerated using a multi-index model.\n","authors":["Suzanna Parkinson","Greg Ongie","Rebecca Willett"],"pdf_url":"https://arxiv.org/pdf/2305.15598v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18470v1","updated":"2024-06-26T16:28:24Z","published":"2024-06-26T16:28:24Z","title":"UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential\n  Recommendations","summary":"  Representation learning in sequential recommendation is critical for\naccurately modeling user interaction patterns and improving recommendation\nprecision. However, existing approaches predominantly emphasize item-to-item\ntransitions, often neglecting the time intervals between interactions, which\nare closely related to behavior pattern changes. Additionally, broader\ninteraction attributes, such as item frequency, are frequently overlooked. We\nfound that both sequences with more uniform time intervals and items with\nhigher frequency yield better prediction performance. Conversely, non-uniform\nsequences exacerbate user interest drift and less-frequent items are difficult\nto model due to sparse sampling, presenting unique challenges inadequately\naddressed by current methods. In this paper, we propose UniRec, a novel\nbidirectional enhancement sequential recommendation method. UniRec leverages\nsequence uniformity and item frequency to enhance performance, particularly\nimproving the representation of non-uniform sequences and less-frequent items.\nThese two branches mutually reinforce each other, driving comprehensive\nperformance optimization in complex sequential recommendation scenarios.\nAdditionally, we present a multidimensional time module to further enhance\nadaptability. To the best of our knowledge, UniRec is the first method to\nutilize the characteristics of uniformity and frequency for feature\naugmentation. Comparing with eleven advanced models across four datasets, we\ndemonstrate that UniRec outperforms SOTA models significantly. The code is\navailable at https://github.com/Linxi000/UniRec.\n","authors":["Yang Liu","Yitong Wang","Chenyue Feng"],"pdf_url":"https://arxiv.org/pdf/2406.18470v1.pdf","comment":"15 pages, 8 figures, for source code, see\n  https://github.com/Linxi000/UniRec"},{"id":"http://arxiv.org/abs/2405.02466v2","updated":"2024-06-26T16:22:43Z","published":"2024-05-03T20:00:40Z","title":"ProFLingo: A Fingerprinting-based Intellectual Property Protection\n  Scheme for Large Language Models","summary":"  Large language models (LLMs) have attracted significant attention in recent\nyears. Due to their \"Large\" nature, training LLMs from scratch consumes immense\ncomputational resources. Since several major players in the artificial\nintelligence (AI) field have open-sourced their original LLMs, an increasing\nnumber of individual researchers and smaller companies are able to build\nderivative LLMs based on these open-sourced models at much lower costs.\nHowever, this practice opens up possibilities for unauthorized use or\nreproduction that may not comply with licensing agreements, and fine-tuning can\nchange the model's behavior, thus complicating the determination of model\nownership. Current intellectual property (IP) protection schemes for LLMs are\neither designed for white-box settings or require additional modifications to\nthe original model, which restricts their use in real-world settings.\n  In this paper, we propose ProFLingo, a black-box fingerprinting-based IP\nprotection scheme for LLMs. ProFLingo generates queries that elicit specific\nresponses from an original model, thereby establishing unique fingerprints. Our\nscheme assesses the effectiveness of these queries on a suspect model to\ndetermine whether it has been derived from the original model. ProFLingo offers\na non-invasive approach, which neither requires knowledge of the suspect model\nnor modifications to the base model or its training process. To the best of our\nknowledge, our method represents the first black-box fingerprinting technique\nfor IP protection for LLMs. Our source code and generated queries are available\nat: https://github.com/hengvt/ProFLingo.\n","authors":["Heng Jin","Chaoyu Zhang","Shanghao Shi","Wenjing Lou","Y. Thomas Hou"],"pdf_url":"https://arxiv.org/pdf/2405.02466v2.pdf","comment":"This is the author's pre-print version of the work. It is posted here\n  for your personal use. Not for redistribution"},{"id":"http://arxiv.org/abs/2406.18464v1","updated":"2024-06-26T16:16:36Z","published":"2024-06-26T16:16:36Z","title":"Bayesian inverse Navier-Stokes problems: joint flow field reconstruction\n  and parameter learning","summary":"  We formulate and solve a Bayesian inverse Navier-Stokes (N-S) problem that\nassimilates velocimetry data in order to jointly reconstruct a 3D flow field\nand learn the unknown N-S parameters, including the boundary position. By\nhardwiring a generalised N-S problem, and regularising its unknown parameters\nusing Gaussian prior distributions, we learn the most likely parameters in a\ncollapsed search space. The most likely flow field reconstruction is then the\nN-S solution that corresponds to the learned parameters. We develop the method\nin the variational setting and use a stabilised Nitsche weak form of the N-S\nproblem that permits the control of all N-S parameters. To regularise the\ninferred the geometry, we use a viscous signed distance field (vSDF) as an\nauxiliary variable, which is given as the solution of a viscous Eikonal\nboundary value problem. We devise an algorithm that solves this inverse\nproblem, and numerically implement it using an adjoint-consistent stabilised\ncut-cell finite element method. We then use this method to reconstruct magnetic\nresonance velocimetry (flow-MRI) data of a 3D steady laminar flow through a\nphysical model of an aortic arch for two different Reynolds numbers and\nsignal-to-noise ratio (SNR) levels (low/high). We find that the method can\naccurately i) reconstruct the low SNR data by filtering out the noise/artefacts\nand recovering flow features that are obscured by noise, and ii) reproduce the\nhigh SNR data without overfitting. Although the framework that we develop\napplies to 3D steady laminar flows in complex geometries, it readily extends to\ntime-dependent laminar and Reynolds-averaged turbulent flows, as well as\nnon-Newtonian (e.g. viscoelastic) fluids.\n","authors":["Alexandros Kontogiannis","Scott V. Elgersma","Andrew J. Sederman","Matthew P. Juniper"],"pdf_url":"https://arxiv.org/pdf/2406.18464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18451v1","updated":"2024-06-26T16:00:35Z","published":"2024-06-26T16:00:35Z","title":"Detecting Brittle Decisions for Free: Leveraging Margin Consistency in\n  Deep Robust Classifiers","summary":"  Despite extensive research on adversarial training strategies to improve\nrobustness, the decisions of even the most robust deep learning models can\nstill be quite sensitive to imperceptible perturbations, creating serious risks\nwhen deploying them for high-stakes real-world applications. While detecting\nsuch cases may be critical, evaluating a model's vulnerability at a\nper-instance level using adversarial attacks is computationally too intensive\nand unsuitable for real-time deployment scenarios. The input space margin is\nthe exact score to detect non-robust samples and is intractable for deep neural\nnetworks. This paper introduces the concept of margin consistency -- a property\nthat links the input space margins and the logit margins in robust models --\nfor efficient detection of vulnerable samples. First, we establish that margin\nconsistency is a necessary and sufficient condition to use a model's logit\nmargin as a score for identifying non-robust samples. Next, through\ncomprehensive empirical analysis of various robustly trained models on CIFAR10\nand CIFAR100 datasets, we show that they indicate strong margin consistency\nwith a strong correlation between their input space margins and the logit\nmargins. Then, we show that we can effectively use the logit margin to\nconfidently detect brittle decisions with such models and accurately estimate\nrobust accuracy on an arbitrarily large test set by estimating the input\nmargins only on a small subset. Finally, we address cases where the model is\nnot sufficiently margin-consistent by learning a pseudo-margin from the feature\nrepresentation. Our findings highlight the potential of leveraging deep\nrepresentations to efficiently assess adversarial vulnerability in deployment\nscenarios.\n","authors":["Jonas Ngnawé","Sabyasachi Sahoo","Yann Pequignot","Frédéric Precioso","Christian Gagné"],"pdf_url":"https://arxiv.org/pdf/2406.18451v1.pdf","comment":"11 pages, 7 figures, 2 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2406.18450v1","updated":"2024-06-26T15:59:13Z","published":"2024-06-26T15:59:13Z","title":"Preference Elicitation for Offline Reinforcement Learning","summary":"  Applying reinforcement learning (RL) to real-world problems is often made\nchallenging by the inability to interact with the environment and the\ndifficulty of designing reward functions. Offline RL addresses the first\nchallenge by considering access to an offline dataset of environment\ninteractions labeled by the reward function. In contrast, Preference-based RL\ndoes not assume access to the reward function and learns it from preferences,\nbut typically requires an online interaction with the environment. We bridge\nthe gap between these frameworks by exploring efficient methods for acquiring\npreference feedback in a fully offline setup. We propose Sim-OPRL, an offline\npreference-based reinforcement learning algorithm, which leverages a learned\nenvironment model to elicit preference feedback on simulated rollouts. Drawing\non insights from both the offline RL and the preference-based RL literature,\nour algorithm employs a pessimistic approach for out-of-distribution data, and\nan optimistic approach for acquiring informative preferences about the optimal\npolicy. We provide theoretical guarantees regarding the sample complexity of\nour approach, dependent on how well the offline data covers the optimal policy.\nFinally, we demonstrate the empirical performance of Sim-OPRL in different\nenvironments.\n","authors":["Alizée Pace","Bernhard Schölkopf","Gunnar Rätsch","Giorgia Ramponi"],"pdf_url":"https://arxiv.org/pdf/2406.18450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03346v2","updated":"2024-06-26T15:55:02Z","published":"2024-06-05T15:04:28Z","title":"Normalizing Flows for Conformal Regression","summary":"  Conformal Prediction (CP) algorithms estimate the uncertainty of a prediction\nmodel by calibrating its outputs on labeled data. The same calibration scheme\nusually applies to any model and data without modifications. The obtained\nprediction intervals are valid by construction but could be inefficient, i.e.\nunnecessarily big, if the prediction errors are not uniformly distributed over\nthe input space.\n  We present a general scheme to localize the intervals by training the\ncalibration process. The standard prediction error is replaced by an optimized\ndistance metric that depends explicitly on the object attributes. Learning the\noptimal metric is equivalent to training a Normalizing Flow that acts on the\njoint distribution of the errors and the inputs. Unlike the Error Reweighting\nCP algorithm of Papadopoulos et al. (2008), the framework allows estimating the\ngap between nominal and empirical conditional validity. The approach is\ncompatible with existing locally-adaptive CP strategies based on re-weighting\nthe calibration samples and applies to any point-prediction model without\nretraining.\n","authors":["Nicolo Colombo"],"pdf_url":"https://arxiv.org/pdf/2406.03346v2.pdf","comment":"To be presented at the 40th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2024). Changes from v1: improved Section 1.2, two figures\n  replaced, minor typos fixed"},{"id":"http://arxiv.org/abs/2312.05818v2","updated":"2024-06-26T15:51:44Z","published":"2023-12-10T08:29:00Z","title":"ICTSurF: Implicit Continuous-Time Survival Functions with Neural\n  Networks","summary":"  Survival analysis is a widely known method for predicting the likelihood of\nan event over time. The challenge of dealing with censored samples still\nremains. Traditional methods, such as the Cox Proportional Hazards (CPH) model,\nhinge on the limitations due to the strong assumptions of proportional hazards\nand the predetermined relationships between covariates. The rise of models\nbased on deep neural networks (DNNs) has demonstrated enhanced effectiveness in\nsurvival analysis. This research introduces the Implicit Continuous-Time\nSurvival Function (ICTSurF), built on a continuous-time survival model, and\nconstructs survival distribution through implicit representation. As a result,\nour method is capable of accepting inputs in continuous-time space and\nproducing survival probabilities in continuous-time space, independent of\nneural network architecture. Comparative assessments with existing methods\nunderscore the high competitiveness of our proposed approach. Our\nimplementation of ICTSurF is available at https://github.com/44REAM/ICTSurF.\n","authors":["Chanon Puttanawarut","Panu Looareesuwan","Romen Samuel Wabina","Prut Saowaprut"],"pdf_url":"https://arxiv.org/pdf/2312.05818v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18445v1","updated":"2024-06-26T15:50:13Z","published":"2024-06-26T15:50:13Z","title":"An Autotuning-based Optimization Framework for Mixed-kernel SVM\n  Classifications in Smart Pixel Datasets and Heterojunction Transistors","summary":"  Support Vector Machine (SVM) is a state-of-the-art classification method\nwidely used in science and engineering due to its high accuracy, its ability to\ndeal with high dimensional data, and its flexibility in modeling diverse\nsources of data. In this paper, we propose an autotuning-based optimization\nframework to quantify the ranges of hyperparameters in SVMs to identify their\noptimal choices, and apply the framework to two SVMs with the mixed-kernel\nbetween Sigmoid and Gaussian kernels for smart pixel datasets in high energy\nphysics (HEP) and mixed-kernel heterojunction transistors (MKH). Our\nexperimental results show that the optimal selection of hyperparameters in the\nSVMs and the kernels greatly varies for different applications and datasets,\nand choosing their optimal choices is critical for a high classification\naccuracy of the mixed kernel SVMs. Uninformed choices of hyperparameters C and\ncoef0 in the mixed-kernel SVMs result in severely low accuracy, and the\nproposed framework effectively quantifies the proper ranges for the\nhyperparameters in the SVMs to identify their optimal choices to achieve the\nhighest accuracy 94.6\\% for the HEP application and the highest average\naccuracy 97.2\\% with far less tuning time for the MKH application.\n","authors":["Xingfu Wu","Tupendra Oli","ustin H. Qian","Valerie Taylor","Mark C. Hersam","Vinod K. Sangwan"],"pdf_url":"https://arxiv.org/pdf/2406.18445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03506v6","updated":"2024-06-26T15:49:05Z","published":"2024-01-07T14:54:57Z","title":"DiarizationLM: Speaker Diarization Post-Processing with Large Language\n  Models","summary":"  In this paper, we introduce DiarizationLM, a framework to leverage large\nlanguage models (LLM) to post-process the outputs from a speaker diarization\nsystem. Various goals can be achieved with the proposed framework, such as\nimproving the readability of the diarized transcript, or reducing the word\ndiarization error rate (WDER). In this framework, the outputs of the automatic\nspeech recognition (ASR) and speaker diarization systems are represented as a\ncompact textual format, which is included in the prompt to an optionally\nfinetuned LLM. The outputs of the LLM can be used as the refined diarization\nresults with the desired enhancement. As a post-processing step, this framework\ncan be easily applied to any off-the-shelf ASR and speaker diarization systems\nwithout retraining existing components. Our experiments show that a finetuned\nPaLM 2-S model can reduce the WDER by rel. 55.5% on the Fisher telephone\nconversation dataset, and rel. 44.9% on the Callhome English dataset.\n","authors":["Quan Wang","Yiling Huang","Guanlong Zhao","Evan Clark","Wei Xia","Hank Liao"],"pdf_url":"https://arxiv.org/pdf/2401.03506v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01389v2","updated":"2024-06-26T15:42:57Z","published":"2024-06-03T14:51:27Z","title":"RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy\n  Evaluation","summary":"  In many real-world decision problems there is partially observed, hidden or\nlatent information that remains fixed throughout an interaction. Such decision\nproblems can be modeled as Latent Markov Decision Processes (LMDPs), where a\nlatent variable is selected at the beginning of an interaction and is not\ndisclosed to the agent. In the last decade, there has been significant progress\nin solving LMDPs under different structural assumptions. However, for general\nLMDPs, there is no known learning algorithm that provably matches the existing\nlower bound (Kwon et al., 2021). We introduce the first sample-efficient\nalgorithm for LMDPs without any additional structural assumptions. Our result\nbuilds off a new perspective on the role of off-policy evaluation guarantees\nand coverage coefficients in LMDPs, a perspective, that has been overlooked in\nthe context of exploration in partially observed environments. Specifically, we\nestablish a novel off-policy evaluation lemma and introduce a new coverage\ncoefficient for LMDPs. Then, we show how these can be used to derive\nnear-optimal guarantees of an optimistic exploration algorithm. These results,\nwe believe, can be valuable for a wide range of interactive learning problems\nbeyond LMDPs, and especially, for partially observed environments.\n","authors":["Jeongyeol Kwon","Shie Mannor","Constantine Caramanis","Yonathan Efroni"],"pdf_url":"https://arxiv.org/pdf/2406.01389v2.pdf","comment":"Fixed typos + alpha"},{"id":"http://arxiv.org/abs/2406.17002v2","updated":"2024-06-26T15:27:16Z","published":"2024-06-24T14:37:17Z","title":"Benchmarking mortality risk prediction from electrocardiograms","summary":"  Several recent high-impact studies leverage large hospital-owned\nelectrocardiographic (ECG) databases to model and predict patient mortality.\nMIMIC-IV, released September 2023, is the first comparable public dataset and\nincludes 800,000 ECGs from a U.S. hospital system. Previously, the largest\npublic ECG dataset was Code-15, containing 345,000 ECGs collected during\nroutine care in Brazil. These datasets now provide an excellent resource for a\nbroader audience to explore ECG survival modeling. Here, we benchmark survival\nmodel performance on Code-15 and MIMIC-IV with two neural network\narchitectures, compare four deep survival modeling approaches to Cox\nregressions trained on classifier outputs, and evaluate performance at one to\nten years. Our results yield AUROC and concordance scores comparable to past\nwork (circa 0.8) and reasonable AUPRC scores (MIMIC-IV: 0.4-0.5, Code-15:\n0.05-0.13) considering the fraction of ECG samples linked to a mortality\n(MIMIC-IV: 27\\%, Code-15: 4\\%). When evaluating models on the opposite dataset,\nAUROC and concordance values drop by 0.1-0.15, which may be due to cohort\ndifferences. All code and results are made public.\n","authors":["Platon Lukyanenko","Joshua Mayourian","Mingxuan Liu","John K. Triedman","Sunil J. Ghelani","William G. La Cava"],"pdf_url":"https://arxiv.org/pdf/2406.17002v2.pdf","comment":"9 pages plus appendix, 2 figures"},{"id":"http://arxiv.org/abs/2406.18423v1","updated":"2024-06-26T15:18:49Z","published":"2024-06-26T15:18:49Z","title":"Graph Neural Networks for Emulation of Finite-Element Ice Dynamics in\n  Greenland and Antarctic Ice Sheets","summary":"  Although numerical models provide accurate solutions for ice sheet dynamics\nbased on physics laws, they accompany intensified computational demands to\nsolve partial differential equations. In recent years, convolutional neural\nnetworks (CNNs) have been widely used as statistical emulators for those\nnumerical models. However, since CNNs operate on regular grids, they cannot\nrepresent the refined meshes and computational efficiency of finite-element\nnumerical models. Therefore, instead of CNNs, this study adopts an equivariant\ngraph convolutional network (EGCN) as an emulator for the ice sheet dynamics\nmodeling. EGCN reproduces ice thickness and velocity changes in the Helheim\nGlacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44\ntimes faster computation time, respectively. Compared to the traditional CNN\nand graph convolutional network, EGCN shows outstanding accuracy in thickness\nprediction near fast ice streams by preserving the equivariance to the\ntranslation and rotation of graphs.\n","authors":["Younghyun Koo","Maryam Rahnemoonfar"],"pdf_url":"https://arxiv.org/pdf/2406.18423v1.pdf","comment":"6 pages, 2 figures, submitted to the ICML 2024 Workshop on Machine\n  Learning for Earth System Modeling"},{"id":"http://arxiv.org/abs/2406.18420v1","updated":"2024-06-26T15:15:15Z","published":"2024-06-26T15:15:15Z","title":"Mixture of Experts in a Mixture of RL settings","summary":"  Mixtures of Experts (MoEs) have gained prominence in (self-)supervised\nlearning due to their enhanced inference efficiency, adaptability to\ndistributed training, and modularity. Previous research has illustrated that\nMoEs can significantly boost Deep Reinforcement Learning (DRL) performance by\nexpanding the network's parameter count while reducing dormant neurons, thereby\nenhancing the model's learning capacity and ability to deal with\nnon-stationarity. In this work, we shed more light on MoEs' ability to deal\nwith non-stationarity and investigate MoEs in DRL settings with \"amplified\"\nnon-stationarity via multi-task training, providing further evidence that MoEs\nimprove learning capacity. In contrast to previous work, our multi-task results\nallow us to better understand the underlying causes for the beneficial effect\nof MoE in DRL training, the impact of the various MoE components, and insights\ninto how best to incorporate them in actor-critic-based DRL networks. Finally,\nwe also confirm results from previous work.\n","authors":["Timon Willi","Johan Obando-Ceron","Jakob Foerster","Karolina Dziugaite","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2406.18420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18418v1","updated":"2024-06-26T15:11:26Z","published":"2024-06-26T15:11:26Z","title":"Differential error feedback for communication-efficient decentralized\n  learning","summary":"  Communication-constrained algorithms for decentralized learning and\noptimization rely on local updates coupled with the exchange of compressed\nsignals. In this context, differential quantization is an effective technique\nto mitigate the negative impact of compression by leveraging correlations\nbetween successive iterates. In addition, the use of error feedback, which\nconsists of incorporating the compression error into subsequent steps, is a\npowerful mechanism to compensate for the bias caused by the compression. Under\nerror feedback, performance guarantees in the literature have so far focused on\nalgorithms employing a fusion center or a special class of contractive\ncompressors that cannot be implemented with a finite number of bits. In this\nwork, we propose a new decentralized communication-efficient learning approach\nthat blends differential quantization with error feedback. The approach is\nspecifically tailored for decentralized learning problems where agents have\nindividual risk functions to minimize subject to subspace constraints that\nrequire the minimizers across the network to lie in low-dimensional subspaces.\nThis constrained formulation includes consensus or single-task optimization as\nspecial cases, and allows for more general task relatedness models such as\nmultitask smoothness and coupled optimization. We show that, under some general\nconditions on the compression noise, and for sufficiently small step-sizes\n$\\mu$, the resulting communication-efficient strategy is stable both in terms\nof mean-square error and average bit rate: by reducing $\\mu$, it is possible to\nkeep the estimation errors small (on the order of $\\mu$) without increasing\nindefinitely the bit rate as $\\mu\\rightarrow 0$. The results establish that, in\nthe small step-size regime and with a finite number of bits, it is possible to\nattain the performance achievable in the absence of compression.\n","authors":["Roula Nassif","Stefan Vlaski","Marco Carpentiero","Vincenzo Matta","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2406.18418v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2209.07821"},{"id":"http://arxiv.org/abs/2406.18417v1","updated":"2024-06-26T15:11:15Z","published":"2024-06-26T15:11:15Z","title":"Towards diffusion models for large-scale sea-ice modelling","summary":"  We make the first steps towards diffusion models for unconditional generation\nof multivariate and Arctic-wide sea-ice states. While targeting to reduce the\ncomputational costs by diffusion in latent space, latent diffusion models also\noffer the possibility to integrate physical knowledge into the generation\nprocess. We tailor latent diffusion models to sea-ice physics with a censored\nGaussian distribution in data space to generate data that follows the physical\nbounds of the modelled variables. Our latent diffusion models reach similar\nscores as the diffusion model trained in data space, but they smooth the\ngenerated fields as caused by the latent mapping. While enforcing physical\nbounds cannot reduce the smoothing, it improves the representation of the\nmarginal ice zone. Therefore, for large-scale Earth system modelling, latent\ndiffusion models can have many advantages compared to diffusion in data space\nif the significant barrier of smoothing can be resolved.\n","authors":["Tobias Sebastian Finn","Charlotte Durand","Alban Farchi","Marc Bocquet","Julien Brajard"],"pdf_url":"https://arxiv.org/pdf/2406.18417v1.pdf","comment":"21 pages, 5 figure, Accepted at the ICML 2024 Machine Learning for\n  Earth System Modeling workshop"},{"id":"http://arxiv.org/abs/2312.12009v2","updated":"2024-06-26T15:00:52Z","published":"2023-12-19T09:58:54Z","title":"Active Preference Inference using Language Models and Probabilistic\n  Reasoning","summary":"  Actively inferring user preferences, for example by asking good questions, is\nimportant for any human-facing decision-making system. Active inference allows\nsuch systems to adapt and personalize themselves to nuanced individual\npreferences. To enable this ability for instruction-tuned large language models\n(LLMs), one may prompt them to ask users questions to infer their preferences,\ntransforming the language models into more robust, interactive systems.\nHowever, out of the box, these models are not efficient at extracting\npreferences: the questions they generate are not informative, requiring a high\nnumber of user interactions and impeding the usability of the downstream\nsystem. In this work, we introduce an inference-time algorithm that helps LLMs\nquickly infer preferences by using more informative questions. Our algorithm\nuses a probabilistic model whose conditional distributions are defined by\nprompting an LLM, and returns questions that optimize expected entropy and\nexpected model change. Results in a simplified interactive web shopping setting\nwith real product items show that an LLM equipped with our entropy reduction\nalgorithm outperforms baselines with the same underlying LLM on task\nperformance while using fewer user interactions.\n","authors":["Wasu Top Piriyakulkij","Volodymyr Kuleshov","Kevin Ellis"],"pdf_url":"https://arxiv.org/pdf/2312.12009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15713v2","updated":"2024-06-26T15:00:46Z","published":"2024-06-22T02:37:13Z","title":"Efficient Low-rank Identification via Accelerated Iteratively Reweighted\n  Nuclear Norm Minimization","summary":"  This paper considers the problem of minimizing the sum of a smooth function\nand the Schatten-$p$ norm of the matrix. Our contribution involves proposing\naccelerated iteratively reweighted nuclear norm methods designed for solving\nthe nonconvex low-rank minimization problem. Two major novelties characterize\nour approach. Firstly, the proposed method possesses a rank identification\nproperty, enabling the provable identification of the \"correct\" rank of the\nstationary point within a finite number of iterations. Secondly, we introduce\nan adaptive updating strategy for smoothing parameters. This strategy\nautomatically fixes parameters associated with zero singular values as\nconstants upon detecting the \"correct\" rank while quickly driving the rest of\nthe parameters to zero. This adaptive behavior transforms the algorithm into\none that effectively solves smooth problems after a few iterations, setting our\nwork apart from existing iteratively reweighted methods for low-rank\noptimization. We prove the global convergence of the proposed algorithm,\nguaranteeing that every limit point of the iterates is a critical point.\nFurthermore, a local convergence rate analysis is provided under the\nKurdyka-{\\L}ojasiewicz property. We conduct numerical experiments using both\nsynthetic and real data to showcase our algorithm's efficiency and superiority\nover existing methods.\n","authors":["Hao Wang","Ye Wang","Xiangyu Yang"],"pdf_url":"https://arxiv.org/pdf/2406.15713v2.pdf","comment":"Copyright may be transferred without notice, after which this version\n  may no longer be accessible"},{"id":"http://arxiv.org/abs/2405.02140v2","updated":"2024-06-26T14:58:25Z","published":"2024-05-03T14:43:07Z","title":"An Information Theoretic Perspective on Conformal Prediction","summary":"  Conformal Prediction (CP) is a distribution-free uncertainty estimation\nframework that constructs prediction sets guaranteed to contain the true answer\nwith a user-specified probability. Intuitively, the size of the prediction set\nencodes a general notion of uncertainty, with larger sets associated with\nhigher degrees of uncertainty. In this work, we leverage information theory to\nconnect conformal prediction to other notions of uncertainty. More precisely,\nwe prove three different ways to upper bound the intrinsic uncertainty, as\ndescribed by the conditional entropy of the target variable given the inputs,\nby combining CP with information theoretical inequalities. Moreover, we\ndemonstrate two direct and useful applications of such connection between\nconformal prediction and information theory: (i) more principled and effective\nconformal training objectives that generalize previous approaches and enable\nend-to-end training of machine learning models from scratch, and (ii) a natural\nmechanism to incorporate side information into conformal prediction. We\nempirically validate both applications in centralized and federated learning\nsettings, showing our theoretical results translate to lower inefficiency\n(average prediction set size) for popular CP methods.\n","authors":["Alvaro H. C. Correia","Fabio Valerio Massoli","Christos Louizos","Arash Behboodi"],"pdf_url":"https://arxiv.org/pdf/2405.02140v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18400v1","updated":"2024-06-26T14:49:54Z","published":"2024-06-26T14:49:54Z","title":"Do LLMs dream of elephants (when told not to)? Latent concept\n  association and associative memory in transformers","summary":"  Large Language Models (LLMs) have the capacity to store and recall facts.\nThrough experimentation with open-source models, we observe that this ability\nto retrieve facts can be easily manipulated by changing contexts, even without\naltering their factual meanings. These findings highlight that LLMs might\nbehave like an associative memory model where certain tokens in the contexts\nserve as clues to retrieving facts. We mathematically explore this property by\nstudying how transformers, the building blocks of LLMs, can complete such\nmemory tasks. We study a simple latent concept association problem with a\none-layer transformer and we show theoretically and empirically that the\ntransformer gathers information using self-attention and uses the value matrix\nfor associative memory.\n","authors":["Yibo Jiang","Goutham Rajendran","Pradeep Ravikumar","Bryon Aragam"],"pdf_url":"https://arxiv.org/pdf/2406.18400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18397v1","updated":"2024-06-26T14:44:24Z","published":"2024-06-26T14:44:24Z","title":"Second Maximum of a Gaussian Random Field and Exact (t-)Spacing test","summary":"  In this article, we introduce the novel concept of the second maximum of a\nGaussian random field on a Riemannian submanifold. This second maximum serves\nas a powerful tool for characterizing the distribution of the maximum. By\nutilizing an ad-hoc Kac Rice formula, we derive the explicit form of the\nmaximum's distribution, conditioned on the second maximum and some regressed\ncomponent of the Riemannian Hessian. This approach results in an exact test,\nbased on the evaluation of spacing between these maxima, which we refer to as\nthe spacing test.\n  We investigate the applicability of this test in detecting sparse\nalternatives within Gaussian symmetric tensors, continuous sparse\ndeconvolution, and two-layered neural networks with smooth rectifiers. Our\ntheoretical results are supported by numerical experiments, which illustrate\nthe calibration and power of the proposed tests. More generally, this test can\nbe applied to any Gaussian random field on a Riemannian manifold, and we\nprovide a general framework for the application of the spacing test in\ncontinuous sparse kernel regression.\n  Furthermore, when the variance-covariance function of the Gaussian random\nfield is known up to a scaling factor, we derive an exact Studentized version\nof our test, coined the $t$-spacing test. This test is perfectly calibrated\nunder the null hypothesis and has high power for detecting sparse alternatives.\n","authors":["Azaïs Jean-Marc","Dalmao Federico","De Castro Yohann"],"pdf_url":"https://arxiv.org/pdf/2406.18397v1.pdf","comment":"5 figures, 22 pages main document, 2 pages supplements"},{"id":"http://arxiv.org/abs/2402.17775v2","updated":"2024-06-26T14:34:13Z","published":"2024-02-20T11:36:23Z","title":"WhaleNet: a Novel Deep Learning Architecture for Marine Mammals\n  Vocalizations on Watkins Marine Mammal Sound Database","summary":"  Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machine\nlearning applications. Nevertheless, the methodologies for data preparation,\npreprocessing, and classification documented in the literature exhibit\nconsiderable variability and are typically not applied to the dataset in its\nentirety. This study initially undertakes a concise review of the\nstate-of-the-art benchmarks pertaining to the dataset, with a particular focus\non clarifying data preparation and preprocessing techniques. Subsequently, we\nexplore the utilization of the Wavelet Scattering Transform (WST) and Mel\nspectrogram as preprocessing mechanisms for feature extraction. In this paper,\nwe introduce \\textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble\nNetwork), a sophisticated deep ensemble architecture for the classification of\nmarine mammal vocalizations, leveraging both WST and Mel spectrogram for\nenhanced feature discrimination. By integrating the insights derived from WST\nand Mel representations, we achieved an improvement in classification accuracy\nby $8-10\\%$ over existing architectures, corresponding to a classification\naccuracy of $97.61\\%$.\n","authors":["Alessandro Licciardi","Davide Carbone"],"pdf_url":"https://arxiv.org/pdf/2402.17775v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18387v1","updated":"2024-06-26T14:29:05Z","published":"2024-06-26T14:29:05Z","title":"DoubleTake: Geometry Guided Depth Estimation","summary":"  Estimating depth from a sequence of posed RGB images is a fundamental\ncomputer vision task, with applications in augmented reality, path planning\netc. Prior work typically makes use of previous frames in a multi view stereo\nframework, relying on matching textures in a local neighborhood. In contrast,\nour model leverages historical predictions by giving the latest 3D geometry\ndata as an extra input to our network. This self-generated geometric hint can\nencode information from areas of the scene not covered by the keyframes and it\nis more regularized when compared to individual predicted depth maps for\nprevious frames. We introduce a Hint MLP which combines cost volume features\nwith a hint of the prior geometry, rendered as a depth map from the current\ncamera location, together with a measure of the confidence in the prior\ngeometry. We demonstrate that our method, which can run at interactive speeds,\nachieves state-of-the-art estimates of depth and 3D scene reconstruction in\nboth offline and incremental evaluation scenarios.\n","authors":["Mohamed Sayed","Filippo Aleotti","Jamie Watson","Zawar Qureshi","Guillermo Garcia-Hernando","Gabriel Brostow","Sara Vicente","Michael Firman"],"pdf_url":"https://arxiv.org/pdf/2406.18387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13382v5","updated":"2024-06-26T14:27:49Z","published":"2022-10-24T16:29:55Z","title":"Emergent World Representations: Exploring a Sequence Model Trained on a\n  Synthetic Task","summary":"  Language models show a surprising range of capabilities, but the source of\ntheir apparent competence is unclear. Do these networks just memorize a\ncollection of surface statistics, or do they rely on internal representations\nof the process that generates the sequences they see? We investigate this\nquestion by applying a variant of the GPT model to the task of predicting legal\nmoves in a simple board game, Othello. Although the network has no a priori\nknowledge of the game or its rules, we uncover evidence of an emergent\nnonlinear internal representation of the board state. Interventional\nexperiments indicate this representation can be used to control the output of\nthe network and create \"latent saliency maps\" that can help explain predictions\nin human terms.\n","authors":["Kenneth Li","Aspen K. Hopkins","David Bau","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2210.13382v5.pdf","comment":"ICLR 2023 oral (notable-top-5%):\n  https://openreview.net/forum?id=DeG07_TcZvT ; code:\n  https://github.com/likenneth/othello_world"},{"id":"http://arxiv.org/abs/2406.18382v1","updated":"2024-06-26T14:24:51Z","published":"2024-06-26T14:24:51Z","title":"Adversarial Search Engine Optimization for Large Language Models","summary":"  Large Language Models (LLMs) are increasingly used in applications where the\nmodel selects from competing third-party content, such as in LLM-powered search\nengines or chatbot plugins. In this paper, we introduce Preference Manipulation\nAttacks, a new class of attacks that manipulate an LLM's selections to favor\nthe attacker. We demonstrate that carefully crafted website content or plugin\ndocumentations can trick an LLM to promote the attacker products and discredit\ncompetitors, thereby increasing user traffic and monetization. We show this\nleads to a prisoner's dilemma, where all parties are incentivized to launch\nattacks, but the collective effect degrades the LLM's outputs for everyone. We\ndemonstrate our attacks on production LLM search engines (Bing and Perplexity)\nand plugin APIs (for GPT-4 and Claude). As LLMs are increasingly used to rank\nthird-party content, we expect Preference Manipulation Attacks to emerge as a\nsignificant threat.\n","authors":["Fredrik Nestaas","Edoardo Debenedetti","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2406.18382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18380v1","updated":"2024-06-26T14:21:21Z","published":"2024-06-26T14:21:21Z","title":"KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning","summary":"  In recent years, Graph Neural Networks (GNNs) have become the de facto tool\nfor learning node and graph representations. Most GNNs typically consist of a\nsequence of neighborhood aggregation (a.k.a., message passing) layers. Within\neach of these layers, the representation of each node is updated from an\naggregation and transformation of its neighbours representations at the\nprevious layer. The upper bound for the expressive power of message passing\nGNNs was reached through the use of MLPs as a transformation, due to their\nuniversal approximation capabilities. However, MLPs suffer from well-known\nlimitations, which recently motivated the introduction of Kolmogorov-Arnold\nNetworks (KANs). KANs rely on the Kolmogorov-Arnold representation theorem,\nrendering them a promising alternative to MLPs. In this work, we compare the\nperformance of KANs against that of MLPs in graph learning tasks. We perform\nextensive experiments on node classification, graph classification and graph\nregression datasets. Our preliminary results indicate that while KANs are\non-par with MLPs in classification tasks, they seem to have a clear advantage\nin the graph regression tasks.\n","authors":["Roman Bresson","Giannis Nikolentzos","George Panagopoulos","Michail Chatzianastasis","Jun Pang","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2406.18380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12235v2","updated":"2024-06-26T14:18:44Z","published":"2024-02-19T15:44:54Z","title":"The Fundamental Limits of Least-Privilege Learning","summary":"  The promise of least-privilege learning -- to find feature representations\nthat are useful for a learning task but prevent inference of any sensitive\ninformation unrelated to this task -- is highly appealing. However, so far this\nconcept has only been stated informally. It thus remains an open question\nwhether and how we can achieve this goal. In this work, we provide the first\nformalisation of the least-privilege principle for machine learning and\ncharacterise its feasibility. We prove that there is a fundamental trade-off\nbetween a representation's utility for a given task and its leakage beyond the\nintended task: it is not possible to learn representations that have high\nutility for the intended task but, at the same time prevent inference of any\nattribute other than the task label itself. This trade-off holds under\nrealistic assumptions on the data distribution and regardless of the technique\nused to learn the feature mappings that produce these representations. We\nempirically validate this result for a wide range of learning techniques, model\narchitectures, and datasets.\n","authors":["Theresa Stadler","Bogdan Kulynych","Michael C. Gastpar","Nicolas Papernot","Carmela Troncoso"],"pdf_url":"https://arxiv.org/pdf/2402.12235v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18370v1","updated":"2024-06-26T14:13:50Z","published":"2024-06-26T14:13:50Z","title":"Learning pure quantum states (almost) without regret","summary":"  We initiate the study of quantum state tomography with minimal regret. A\nlearner has sequential oracle access to an unknown pure quantum state, and in\neach round selects a pure probe state. Regret is incurred if the unknown state\nis measured orthogonal to this probe, and the learner's goal is to minimise the\nexpected cumulative regret over $T$ rounds. The challenge is to find a balance\nbetween the most informative measurements and measurements incurring minimal\nregret. We show that the cumulative regret scales as\n$\\Theta(\\operatorname{polylog} T)$ using a new tomography algorithm based on a\nmedian of means least squares estimator. This algorithm employs measurements\nbiased towards the unknown state and produces online estimates that are optimal\n(up to logarithmic terms) in the number of observed samples.\n","authors":["Josep Lumbreras","Mikhail Terekhov","Marco Tomamichel"],"pdf_url":"https://arxiv.org/pdf/2406.18370v1.pdf","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.03341v6","updated":"2024-06-26T14:11:53Z","published":"2023-06-06T01:26:53Z","title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language\n  Model","summary":"  We introduce Inference-Time Intervention (ITI), a technique designed to\nenhance the \"truthfulness\" of large language models (LLMs). ITI operates by\nshifting model activations during inference, following a set of directions\nacross a limited number of attention heads. This intervention significantly\nimproves the performance of LLaMA models on the TruthfulQA benchmark. On an\ninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from\n32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and\ndemonstrate how to balance it by tuning the intervention strength. ITI is\nminimally invasive and computationally inexpensive. Moreover, the technique is\ndata efficient: while approaches like RLHF require extensive annotations, ITI\nlocates truthful directions using only few hundred examples. Our findings\nsuggest that LLMs may have an internal representation of the likelihood of\nsomething being true, even as they produce falsehoods on the surface.\n","authors":["Kenneth Li","Oam Patel","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2306.03341v6.pdf","comment":"NeurIPS 2023 spotlight; code:\n  https://github.com/likenneth/honest_llama"},{"id":"http://arxiv.org/abs/2405.16265v4","updated":"2024-06-26T14:01:15Z","published":"2024-05-25T15:07:33Z","title":"MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time","summary":"  Although Large Language Models (LLMs) achieve remarkable performance across\nvarious tasks, they often struggle with complex reasoning tasks, such as\nanswering mathematical questions. Recent efforts to address this issue have\nprimarily focused on leveraging mathematical datasets through supervised\nfine-tuning or self-improvement techniques. However, these methods often depend\non high-quality datasets that are difficult to prepare, or they require\nsubstantial computational resources for fine-tuning. Inspired by findings that\nLLMs know how to produce the right answer but struggle to select the correct\nreasoning path, we propose a purely inference-based searching method --\nMindStar (M*). This method formulates reasoning tasks as searching problems and\nproposes two search ideas to identify the optimal reasoning paths. We evaluate\nthe M* framework on both the GSM8K and MATH datasets, comparing its performance\nwith existing open and closed-source LLMs. Our results demonstrate that M*\nsignificantly enhances the reasoning abilities of open-source models, such as\nLlama-2-13B and Mistral-7B, and achieves comparable performance to GPT-3.5 and\nGrok-1, but with substantially reduced model size and computational costs.\n","authors":["Jikun Kang","Xin Zhe Li","Xi Chen","Amirreza Kazemi","Qianyi Sun","Boxing Chen","Dong Li","Xu He","Quan He","Feng Wen","Jianye Hao","Jun Yao"],"pdf_url":"https://arxiv.org/pdf/2405.16265v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18354v1","updated":"2024-06-26T13:54:59Z","published":"2024-06-26T13:54:59Z","title":"Kolmogorov-Arnold Graph Neural Networks","summary":"  Graph neural networks (GNNs) excel in learning from network-like data but\noften lack interpretability, making their application challenging in domains\nrequiring transparent decision-making. We propose the Graph Kolmogorov-Arnold\nNetwork (GKAN), a novel GNN model leveraging spline-based activation functions\non edges to enhance both accuracy and interpretability. Our experiments on five\nbenchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN\nmodels in node classification, link prediction, and graph classification tasks.\nIn addition to the improved accuracy, GKAN's design inherently provides clear\ninsights into the model's decision-making process, eliminating the need for\npost-hoc explainability techniques. This paper discusses the methodology,\nperformance, and interpretability of GKAN, highlighting its potential for\napplications in domains where interpretability is crucial.\n","authors":["Gianluca De Carlo","Andrea Mastropietro","Aris Anagnostopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.18354v1.pdf","comment":"7 pages, 4 figures, under review"},{"id":"http://arxiv.org/abs/2406.18351v1","updated":"2024-06-26T13:52:47Z","published":"2024-06-26T13:52:47Z","title":"Reinforcement Learning with Intrinsically Motivated Feedback Graph for\n  Lost-sales Inventory Control","summary":"  Reinforcement learning (RL) has proven to be well-performed and\ngeneral-purpose in the inventory control (IC). However, further improvement of\nRL algorithms in the IC domain is impeded due to two limitations of online\nexperience. First, online experience is expensive to acquire in real-world\napplications. With the low sample efficiency nature of RL algorithms, it would\ntake extensive time to train the RL policy to convergence. Second, online\nexperience may not reflect the true demand due to the lost sales phenomenon\ntypical in IC, which makes the learning process more challenging. To address\nthe above challenges, we propose a decision framework that combines\nreinforcement learning with feedback graph (RLFG) and intrinsically motivated\nexploration (IME) to boost sample efficiency. In particular, we first take\nadvantage of the inherent properties of lost-sales IC problems and design the\nfeedback graph (FG) specially for lost-sales IC problems to generate abundant\nside experiences aid RL updates. Then we conduct a rigorous theoretical\nanalysis of how the designed FG reduces the sample complexity of RL methods.\nBased on the theoretical insights, we design an intrinsic reward to direct the\nRL agent to explore to the state-action space with more side experiences,\nfurther exploiting FG's power. Experimental results demonstrate that our method\ngreatly improves the sample efficiency of applying RL in IC. Our code is\navailable at https://anonymous.4open.science/r/RLIMFG4IC-811D/\n","authors":["Zifan Liu","Xinran Li","Shibo Chen","Gen Li","Jiashuo Jiang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18345v1","updated":"2024-06-26T13:42:11Z","published":"2024-06-26T13:42:11Z","title":"EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion\n  Recognition","summary":"  Integrating prior knowledge of neurophysiology into neural network\narchitecture enhances the performance of emotion decoding. While numerous\ntechniques emphasize learning spatial and short-term temporal patterns, there\nhas been limited emphasis on capturing the vital long-term contextual\ninformation associated with emotional cognitive processes. In order to address\nthis discrepancy, we introduce a novel transformer model called emotion\ntransformer (EmT). EmT is designed to excel in both generalized cross-subject\nEEG emotion classification and regression tasks. In EmT, EEG signals are\ntransformed into a temporal graph format, creating a sequence of EEG feature\ngraphs using a temporal graph construction module (TGC). A novel residual\nmulti-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph\nrepresentations for each EEG feature graph within the series, and the learned\nrepresentations of each graph are fused into one token. Furthermore, we design\na temporal contextual transformer module (TCT) with two types of token mixers\nto learn the temporal contextual information. Finally, the task-specific output\nmodule (TSO) generates the desired outputs. Experiments on four publicly\navailable datasets show that EmT achieves higher results than the baseline\nmethods for both EEG emotion classification and regression tasks. The code is\navailable at https://github.com/yi-ding-cs/EmT.\n","authors":["Yi Ding","Chengxuan Tong","Shuailei Zhang","Muyun Jiang","Yong Li","Kevin Lim Jun Liang","Cuntai Guan"],"pdf_url":"https://arxiv.org/pdf/2406.18345v1.pdf","comment":"11 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2306.02411v2","updated":"2024-06-26T13:37:58Z","published":"2023-06-04T17:08:41Z","title":"Topological data quality via 0-dimensional persistence matching","summary":"  Data quality is crucial for the successful training, generalization and\nperformance of artificial intelligence models. We propose to measure data\nquality for supervised learning using topological data analysis techniques.\nSpecifically, we provide a novel topological invariant based on persistence\nmatchings induced by inclusions and using $0$-dimensional persistent homology.\nWe show that such an invariant is stable. We provide an algorithm and relate it\nto images, kernels, and cokernels of the induced morphisms. Also, we show that\nthe invariant allows us to understand whether the subset \"represents well\" the\nclusters from the larger dataset or not, and we also use it to estimate bounds\nfor the Hausdorff distance between the subset and the complete dataset. This\napproach enables us to explain why the chosen dataset will lead to poor\nperformance.\n","authors":["Álvaro Torras-Casas","Eduardo Paluzo-Hidalgo","Rocio Gonzalez-Diaz"],"pdf_url":"https://arxiv.org/pdf/2306.02411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14533v3","updated":"2024-06-26T13:29:12Z","published":"2023-11-24T14:56:36Z","title":"Introducing 3DCNN ResNets for ASD full-body kinematic assessment: a\n  comparison with hand-crafted features","summary":"  Autism Spectrum Disorder (ASD) is characterized by challenges in social\ncommunication and restricted patterns, with motor abnormalities gaining\ntraction for early detection. However, kinematic analysis in ASD is limited,\noften lacking robust validation and relying on hand-crafted features for single\ntasks, leading to inconsistencies across studies. End-to-end models have\nemerged as promising methods to overcome the need for feature engineering. Our\naim is to propose a newly adapted 3DCNN ResNet from and compare it to widely\nused hand-crafted features for motor ASD assessment. Specifically, we developed\na virtual reality environment with multiple motor tasks and trained models\nusing both approaches. We prioritized a reliable validation framework with\nrepeated cross-validation. Results show the proposed model achieves a maximum\naccuracy of 85$\\pm$3%, outperforming state-of-the-art end-to-end models with\nshort 1-to-3 minute samples. Our comparative analysis with hand-crafted\nfeatures shows feature-engineered models outperformed our end-to-end model in\ncertain tasks. However, our end-to-end model achieved a higher mean AUC of\n0.80$\\pm$0.03. Additionally, statistical differences were found in model\nvariance, with our end-to-end model providing more consistent results with less\nvariability across all VR tasks, demonstrating domain generalization and\nreliability. These findings show that end-to-end models enable less variable\nand context-independent ASD classification without requiring domain knowledge\nor task specificity. However, they also recognize the effectiveness of\nhand-crafted features in specific task scenarios.\n","authors":["Alberto Altozano","Maria Eleonora Minissi","Mariano Alcañiz","Javier Marín-Morales"],"pdf_url":"https://arxiv.org/pdf/2311.14533v3.pdf","comment":"This work has been submitted to Expert Systems with Applications for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2302.05342v4","updated":"2024-06-26T13:28:35Z","published":"2023-02-10T15:57:20Z","title":"Combining Reconstruction and Contrastive Methods for Multimodal\n  Representations in RL","summary":"  Learning self-supervised representations using reconstruction or contrastive\nlosses improves performance and sample complexity of image-based and multimodal\nreinforcement learning (RL). Here, different self-supervised loss functions\nhave distinct advantages and limitations depending on the information density\nof the underlying sensor modality. Reconstruction provides strong learning\nsignals but is susceptible to distractions and spurious information. While\ncontrastive approaches can ignore those, they may fail to capture all relevant\ndetails and can lead to representation collapse. For multimodal RL, this\nsuggests that different modalities should be treated differently based on the\namount of distractions in the signal. We propose Contrastive Reconstructive\nAggregated representation Learning (CoRAL), a unified framework enabling us to\nchoose the most appropriate self-supervised loss for each sensor modality and\nallowing the representation to better focus on relevant aspects. We evaluate\nCoRAL's benefits on a wide range of tasks with images containing distractions\nor occlusions, a new locomotion suite, and a challenging manipulation suite\nwith visually realistic distractions. Our results show that learning a\nmultimodal representation by combining contrastive and reconstruction-based\nlosses can significantly improve performance and solve tasks that are out of\nreach for more naive representation learning approaches and other recent\nbaselines.\n","authors":["Philipp Becker","Sebastian Mossburger","Fabian Otto","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2302.05342v4.pdf","comment":"Published in \"Reinforcement Learning Conference (RLC)\", August 2024"},{"id":"http://arxiv.org/abs/2406.18334v1","updated":"2024-06-26T13:21:24Z","published":"2024-06-26T13:21:24Z","title":"Efficient and Accurate Explanation Estimation with Distribution\n  Compression","summary":"  Exact computation of various machine learning explanations requires numerous\nmodel evaluations and in extreme cases becomes impractical. The computational\ncost of approximation increases with an ever-increasing size of data and model\nparameters. Many heuristics have been proposed to approximate post-hoc\nexplanations efficiently. This paper shows that the standard i.i.d. sampling\nused in a broad spectrum of algorithms for explanation estimation leads to an\napproximation error worthy of improvement. To this end, we introduce Compress\nThen Explain (CTE), a new paradigm for more efficient and accurate explanation\nestimation. CTE uses distribution compression through kernel thinning to obtain\na data sample that best approximates the marginal distribution. We show that\nCTE improves the estimation of removal-based local and global explanations with\nnegligible computational overhead. It often achieves an on-par explanation\napproximation error using 2-3x less samples, i.e. requiring 2-3x less model\nevaluations. CTE is a simple, yet powerful, plug-in for any explanation method\nthat now relies on i.i.d. sampling.\n","authors":["Hubert Baniecki","Giuseppe Casalicchio","Bernd Bischl","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2406.18334v1.pdf","comment":"To be presented at the ICML 2024 Workshop on DMLR"},{"id":"http://arxiv.org/abs/2406.18332v1","updated":"2024-06-26T13:21:00Z","published":"2024-06-26T13:21:00Z","title":"Early Classification of Time Series: Taxonomy and Benchmark","summary":"  In many situations, the measurements of a studied phenomenon are provided\nsequentially, and the prediction of its class needs to be made as early as\npossible so as not to incur too high a time penalty, but not too early and risk\npaying the cost of misclassification. This problem has been particularly\nstudied in the case of time series, and is known as Early Classification of\nTime Series (ECTS). Although it has been the subject of a growing body of\nliterature, there is still a lack of a systematic, shared evaluation protocol\nto compare the relative merits of the various existing methods. This document\nbegins by situating these methods within a principle-based taxonomy. It defines\ndimensions for organizing their evaluation, and then reports the results of a\nvery extensive set of experiments along these dimensions involving nine\nstate-of-the art ECTS algorithms. In addition, these and other experiments can\nbe carried out using an open-source library in which most of the existing ECTS\nalgorithms have been implemented (see \\url{https://github.com/ML-EDM/ml_edm}).\n","authors":["Aurélien Renault","Alexis Bondu","Antoine Cornuéjols","Vincent Lemaire"],"pdf_url":"https://arxiv.org/pdf/2406.18332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18330v1","updated":"2024-06-26T13:18:42Z","published":"2024-06-26T13:18:42Z","title":"Molecular Diffusion Models with Virtual Receptors","summary":"  Machine learning approaches to Structure-Based Drug Design (SBDD) have proven\nquite fertile over the last few years. In particular, diffusion-based\napproaches to SBDD have shown great promise. We present a technique which\nexpands on this diffusion approach in two crucial ways. First, we address the\nsize disparity between the drug molecule and the target/receptor, which makes\nlearning more challenging and inference slower. We do so through the notion of\na Virtual Receptor, which is a compressed version of the receptor; it is\nlearned so as to preserve key aspects of the structural information of the\noriginal receptor, while respecting the relevant group equivariance. Second, we\nincorporate a protein language embedding used originally in the context of\nprotein folding. We experimentally demonstrate the contributions of both the\nvirtual receptors and the protein embeddings: in practice, they lead to both\nbetter performance, as well as significantly faster computations.\n","authors":["Matan Halfon","Eyal Rozenberg","Ehud Rivlin","Daniel Freedman"],"pdf_url":"https://arxiv.org/pdf/2406.18330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18328v1","updated":"2024-06-26T13:16:40Z","published":"2024-06-26T13:16:40Z","title":"PDFA Distillation via String Probability Queries {PDFA Distillation via\n  String Probability Queries}","summary":"  Probabilistic deterministic finite automata (PDFA) are discrete event systems\nmodeling conditional probabilities over languages: Given an already seen\nsequence of tokens they return the probability of tokens of interest to appear\nnext. These types of models have gained interest in the domain of explainable\nmachine learning, where they are used as surrogate models for neural networks\ntrained as language models. In this work we present an algorithm to distill\nPDFA from neural networks. Our algorithm is a derivative of the L# algorithm\nand capable of learning PDFA from a new type of query, in which the algorithm\ninfers conditional probabilities from the probability of the queried string to\noccur. We show its effectiveness on a recent public dataset by distilling PDFA\nfrom a set of trained neural networks.\n","authors":["Robert Baumgartner","Sicco Verwer"],"pdf_url":"https://arxiv.org/pdf/2406.18328v1.pdf","comment":"LearnAUT 2024"},{"id":"http://arxiv.org/abs/2406.18327v1","updated":"2024-06-26T13:14:24Z","published":"2024-06-26T13:14:24Z","title":"Multi-modal Evidential Fusion Network for Trusted PET/CT Tumor\n  Segmentation","summary":"  Accurate segmentation of tumors in PET/CT images is important in\ncomputer-aided diagnosis and treatment of cancer. The key issue of such a\nsegmentation problem lies in the effective integration of complementary\ninformation from PET and CT images. However, the quality of PET and CT images\nvaries widely in clinical settings, which leads to uncertainty in the modality\ninformation extracted by networks. To take the uncertainty into account in\nmulti-modal information fusion, this paper proposes a novel Multi-modal\nEvidential Fusion Network (MEFN) comprising a Cross-Modal Feature Learning\n(CFL) module and a Multi-modal Trusted Fusion (MTF) module. The CFL module\nreduces the domain gap upon modality conversion and highlights common tumor\nfeatures, thereby alleviating the needs of the segmentation module to handle\nmodality specificity. The MTF module utilizes mutual attention mechanisms and\nan uncertainty calibrator to fuse modality features based on modality\nuncertainty and then fuse the segmentation results under the guidance of\nDempster-Shafer Theory. Besides, a new uncertainty perceptual loss is\nintroduced to force the model focusing on uncertain features and hence improve\nits ability to extract trusted modality information. Extensive comparative\nexperiments are conducted on two publicly available PET/CT datasets to evaluate\nthe performance of our proposed method whose results demonstrate that our MEFN\nsignificantly outperforms state-of-the-art methods with improvements of 2.15%\nand 3.23% in DSC scores on the AutoPET dataset and the Hecktor dataset,\nrespectively. More importantly, our model can provide radiologists with\ncredible uncertainty of the segmentation results for their decision in\naccepting or rejecting the automatic segmentation results, which is\nparticularly important for clinical applications. Our code will be available at\nhttps://github.com/QPaws/MEFN.\n","authors":["Yuxuan Qi","Li Lin","Jiajun Wang","Jingya Zhang","Bin Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03864v2","updated":"2024-06-26T13:05:18Z","published":"2024-02-06T10:24:36Z","title":"The Challenges of the Nonlinear Regime for Physics-Informed Neural\n  Networks","summary":"  The Neural Tangent Kernel (NTK) viewpoint is widely employed to analyze the\ntraining dynamics of overparameterized Physics-Informed Neural Networks\n(PINNs). However, unlike the case of linear Partial Differential Equations\n(PDEs), we show how the NTK perspective falls short in the nonlinear scenario.\nSpecifically, we establish that the NTK yields a random matrix at\ninitialization that is not constant during training, contrary to conventional\nbelief. Another significant difference from the linear regime is that, even in\nthe idealistic infinite-width limit, the Hessian does not vanish and hence it\ncannot be disregarded during training. This motivates the adoption of\nsecond-order optimization methods. We explore the convergence guarantees of\nsuch methods in both linear and nonlinear cases, addressing challenges such as\nspectral bias and slow convergence. Every theoretical result is supported by\nnumerical examples with both linear and nonlinear PDEs, and we highlight the\nbenefits of second-order methods in benchmark test cases.\n","authors":["Andrea Bonfanti","Giuseppe Bruno","Cristina Cipriani"],"pdf_url":"https://arxiv.org/pdf/2402.03864v2.pdf","comment":"10 pages, 4 figures, appendix of 12 additional pages"},{"id":"http://arxiv.org/abs/2406.16793v3","updated":"2024-06-26T13:03:16Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on-par or better performance\nthan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by\ncutting down the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). We find\nthat $\\geq$ 90% of these learning rates in $v$ could be harmlessly removed if\nwe (1) carefully partition the parameters into blocks following our proposed\nprinciple on Hessian structure; (2) assign a single but good learning rate to\neach parameter block. We further find that, for each of these parameter blocks,\nthere exists a single high-quality learning rate that can outperform Adam,\nprovided that sufficient resources are available to search it out. We then\nprovide one cost-effective way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 125M to 7B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs and CPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18316v1","updated":"2024-06-26T12:59:37Z","published":"2024-06-26T12:59:37Z","title":"Trade-off between Gradient Measurement Efficiency and Expressivity in\n  Deep Quantum Neural Networks","summary":"  Quantum neural networks (QNNs) require an efficient training algorithm to\nachieve practical quantum advantages. A promising approach is the use of\ngradient-based optimization algorithms, where gradients are estimated through\nquantum measurements. However, it is generally difficult to efficiently measure\ngradients in QNNs because the quantum state collapses upon measurement. In this\nwork, we prove a general trade-off between gradient measurement efficiency and\nexpressivity in a wide class of deep QNNs, elucidating the theoretical limits\nand possibilities of efficient gradient estimation. This trade-off implies that\na more expressive QNN requires a higher measurement cost in gradient\nestimation, whereas we can increase gradient measurement efficiency by reducing\nthe QNN expressivity to suit a given task. We further propose a general QNN\nansatz called the stabilizer-logical product ansatz (SLPA), which can reach the\nupper limit of the trade-off inequality by leveraging the symmetric structure\nof the quantum circuit. In learning an unknown symmetric function, the SLPA\ndrastically reduces the quantum resources required for training while\nmaintaining accuracy and trainability compared to a well-designed symmetric\ncircuit based on the parameter-shift method. Our results not only reveal a\ntheoretical understanding of efficient training in QNNs but also provide a\nstandard and broadly applicable efficient QNN design.\n","authors":["Koki Chinzei","Shinichiro Yamano","Quoc Hoan Tran","Yasuhiro Endo","Hirotaka Oshima"],"pdf_url":"https://arxiv.org/pdf/2406.18316v1.pdf","comment":"32 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.18314v1","updated":"2024-06-26T12:54:41Z","published":"2024-06-26T12:54:41Z","title":"ContactNet: Geometric-Based Deep Learning Model for Predicting\n  Protein-Protein Interactions","summary":"  Deep learning approaches achieved significant progress in predicting protein\nstructures. These methods are often applied to protein-protein interactions\n(PPIs) yet require Multiple Sequence Alignment (MSA) which is unavailable for\nvarious interactions, such as antibody-antigen. Computational docking methods\nare capable of sampling accurate complex models, but also produce thousands of\ninvalid configurations. The design of scoring functions for identifying\naccurate models is a long-standing challenge. We develop a novel\nattention-based Graph Neural Network (GNN), ContactNet, for classifying PPI\nmodels obtained from docking algorithms into accurate and incorrect ones. When\ntrained on docked antigen and modeled antibody structures, ContactNet doubles\nthe accuracy of current state-of-the-art scoring functions, achieving accurate\nmodels among its Top-10 at 43% of the test cases. When applied to unbound\nantibodies, its Top-10 accuracy increases to 65%. This performance is achieved\nwithout MSA and the approach is applicable to other types of interactions, such\nas host-pathogens or general PPIs.\n","authors":["Matan Halfon","Tomer Cohen","Raanan Fattal","Dina Schneidman-Duhovny"],"pdf_url":"https://arxiv.org/pdf/2406.18314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18311v1","updated":"2024-06-26T12:50:13Z","published":"2024-06-26T12:50:13Z","title":"Online Learning of Multiple Tasks and Their Relationships : Testing on\n  Spam Email Data and EEG Signals Recorded in Construction Fields","summary":"  This paper examines an online multi-task learning (OMTL) method, which\nprocesses data sequentially to predict labels across related tasks. The\nframework learns task weights and their relatedness concurrently. Unlike\nprevious models that assumed static task relatedness, our approach treats tasks\nas initially independent, updating their relatedness iteratively using newly\ncalculated weight vectors. We introduced three rules to update the task\nrelatedness matrix: OMTLCOV, OMTLLOG, and OMTLVON, and compared them against a\nconventional method (CMTL) that uses a fixed relatedness value. Performance\nevaluations on three datasets a spam dataset and two EEG datasets from\nconstruction workers under varying conditions demonstrated that our OMTL\nmethods outperform CMTL, improving accuracy by 1\\% to 3\\% on EEG data, and\nmaintaining low error rates around 12\\% on the spam dataset.\n","authors":["Yixin Jin","Wenjing Zhou","Meiqi Wang","Meng Li","Xintao Li","Tianyu Hu","Xingyuan Bu"],"pdf_url":"https://arxiv.org/pdf/2406.18311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18310v1","updated":"2024-06-26T12:50:10Z","published":"2024-06-26T12:50:10Z","title":"Spatial-temporal Hierarchical Reinforcement Learning for Interpretable\n  Pathology Image Super-Resolution","summary":"  Pathology image are essential for accurately interpreting lesion cells in\ncytopathology screening, but acquiring high-resolution digital slides requires\nspecialized equipment and long scanning times. Though super-resolution (SR)\ntechniques can alleviate this problem, existing deep learning models recover\npathology image in a black-box manner, which can lead to untruthful biological\ndetails and misdiagnosis. Additionally, current methods allocate the same\ncomputational resources to recover each pixel of pathology image, leading to\nthe sub-optimal recovery issue due to the large variation of pathology image.\nIn this paper, we propose the first hierarchical reinforcement learning\nframework named Spatial-Temporal hierARchical Reinforcement Learning (STAR-RL),\nmainly for addressing the aforementioned issues in pathology image\nsuper-resolution problem. We reformulate the SR problem as a Markov decision\nprocess of interpretable operations and adopt the hierarchical recovery\nmechanism in patch level, to avoid sub-optimal recovery. Specifically, the\nhigher-level spatial manager is proposed to pick out the most corrupted patch\nfor the lower-level patch worker. Moreover, the higher-level temporal manager\nis advanced to evaluate the selected patch and determine whether the\noptimization should be stopped earlier, thereby avoiding the over-processed\nproblem. Under the guidance of spatial-temporal managers, the lower-level patch\nworker processes the selected patch with pixel-wise interpretable actions at\neach time step. Experimental results on medical images degraded by different\nkernels show the effectiveness of STAR-RL. Furthermore, STAR-RL validates the\npromotion in tumor diagnosis with a large margin and shows generalizability\nunder various degradations. The source code is available at\nhttps://github.com/CUHK-AIM-Group/STAR-RL.\n","authors":["Wenting Chen","Jie Liu","Tommy W. S. Chow","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2406.18310v1.pdf","comment":"Accepted to IEEE TRANSACTIONS ON MEDICAL IMAGING (TMI)"},{"id":"http://arxiv.org/abs/2406.18309v1","updated":"2024-06-26T12:50:07Z","published":"2024-06-26T12:50:07Z","title":"Automated Immunophenotyping Assessment for Diagnosing Childhood Acute\n  Leukemia using Set-Transformers","summary":"  Acute Leukemia is the most common hematologic malignancy in children and\nadolescents. A key methodology in the diagnostic evaluation of this malignancy\nis immunophenotyping based on Multiparameter Flow Cytometry (FCM). However,\nthis approach is manual, and thus time-consuming and subjective. To alleviate\nthis situation, we propose in this paper the FCM-Former, a machine learning,\nself-attention based FCM-diagnostic tool, automating the immunophenotyping\nassessment in Childhood Acute Leukemia. The FCM-Former is trained in a\nsupervised manner, by directly using flow cytometric data. Our FCM-Former\nachieves an accuracy of 96.5% assigning lineage to each sample among 960 cases\nof either acute B-cell, T-cell lymphoblastic, and acute myeloid leukemia\n(B-ALL, T-ALL, AML). To the best of our knowledge, the FCM-Former is the first\nwork that automates the immunophenotyping assessment with FCM data in\ndiagnosing pediatric Acute Leukemia.\n","authors":["Elpiniki Maria Lygizou","Michael Reiter","Margarita Maurer-Granofszky","Michael Dworzak","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2406.18309v1.pdf","comment":"The paper has been accepted at IEEE EMBS 2024 (46th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society)"},{"id":"http://arxiv.org/abs/2309.10157v2","updated":"2024-06-26T12:45:55Z","published":"2023-09-18T21:11:25Z","title":"Autoencoder-based Anomaly Detection System for Online Data Quality\n  Monitoring of the CMS Electromagnetic Calorimeter","summary":"  The CMS detector is a general-purpose apparatus that detects high-energy\ncollisions produced at the LHC. Online Data Quality Monitoring of the CMS\nelectromagnetic calorimeter is a vital operational tool that allows detector\nexperts to quickly identify, localize, and diagnose a broad range of detector\nissues that could affect the quality of physics data. A real-time\nautoencoder-based anomaly detection system using semi-supervised machine\nlearning is presented enabling the detection of anomalies in the CMS\nelectromagnetic calorimeter data. A novel method is introduced which maximizes\nthe anomaly detection performance by exploiting the time-dependent evolution of\nanomalies as well as spatial variations in the detector response. The\nautoencoder-based system is able to efficiently detect anomalies, while\nmaintaining a very low false discovery rate. The performance of the system is\nvalidated with anomalies found in 2018 and 2022 LHC collision data.\nAdditionally, the first results from deploying the autoencoder-based system in\nthe CMS online Data Quality Monitoring workflow during the beginning of Run 3\nof the LHC are presented, showing its ability to detect issues missed by the\nexisting system.\n","authors":[" The CMS ECAL Collaboration"],"pdf_url":"https://arxiv.org/pdf/2309.10157v2.pdf","comment":"Replaced with the published version. Added the journal reference and\n  the DOI"},{"id":"http://arxiv.org/abs/2402.03741v3","updated":"2024-06-26T12:41:59Z","published":"2024-02-06T06:18:16Z","title":"SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent\n  Reinforcement Learning Systems","summary":"  Recent advancements in multi-agent reinforcement learning (MARL) have opened\nup vast application prospects, such as swarm control of drones, collaborative\nmanipulation by robotic arms, and multi-target encirclement. However, potential\nsecurity threats during the MARL deployment need more attention and thorough\ninvestigation. Recent research reveals that attackers can rapidly exploit the\nvictim's vulnerabilities, generating adversarial policies that result in the\nfailure of specific tasks. For instance, reducing the winning rate of a\nsuperhuman-level Go AI to around 20%. Existing studies predominantly focus on\ntwo-player competitive environments, assuming attackers possess complete global\nstate observation.\n  In this study, we unveil, for the first time, the capability of attackers to\ngenerate adversarial policies even when restricted to partial observations of\nthe victims in multi-agent competitive environments. Specifically, we propose a\nnovel black-box attack (SUB-PLAY) that incorporates the concept of constructing\nmultiple subgames to mitigate the impact of partial observability and suggests\nsharing transitions among subpolicies to improve attackers' exploitative\nability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under\nthree typical partial observability limitations. Visualization results indicate\nthat adversarial policies induce significantly different activations of the\nvictims' policy networks. Furthermore, we evaluate three potential defenses\naimed at exploring ways to mitigate security threats posed by adversarial\npolicies, providing constructive recommendations for deploying MARL in\ncompetitive environments.\n","authors":["Oubo Ma","Yuwen Pu","Linkang Du","Yang Dai","Ruo Wang","Xiaolei Liu","Yingcai Wu","Shouling Ji"],"pdf_url":"https://arxiv.org/pdf/2402.03741v3.pdf","comment":"To appear in the ACM Conference on Computer and Communications\n  Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA"},{"id":"http://arxiv.org/abs/2406.05666v4","updated":"2024-06-26T12:32:28Z","published":"2024-06-09T06:49:22Z","title":"General Distribution Learning: A theoretical framework for Deep Learning","summary":"  There remain numerous unanswered research questions on deep learning (DL)\nwithin the classical learning theory framework. These include the remarkable\ngeneralization capabilities of overparametrized neural networks (NNs), the\nefficient optimization performance despite non-convexity of objectives, the\nmechanism of flat minima for generalization, and the exceptional performance of\ndeep architectures in solving physical problems. This paper introduces General\nDistribution Learning (GD Learning), a novel theoretical learning framework\ndesigned to address a comprehensive range of machine learning and statistical\ntasks, including classification, regression and parameter estimation. Departing\nfrom traditional statistical machine learning, GD Learning focuses on the true\nunderlying distribution. In GD Learning, learning error, corresponding to the\nexpected error in classical statistical learning framework, is divided into\nfitting errors due to models and algorithms, as well as sampling errors\nintroduced by limited sampling data. The framework significantly incorporates\nprior knowledge, especially in scenarios characterized by data scarcity,\nthereby enhancing performance. Within the GD Learning framework, we demonstrate\nthat the global optimal solutions in non-convex optimization can be approached\nby minimizing the gradient norm and the non-uniformity of the eigenvalues of\nthe model's Jacobian matrix. This insight leads to the development of the\ngradient structure control algorithm. GD Learning also offers fresh insights\ninto the questions on deep learning, including overparameterization and\nnon-convex optimization, bias-variance trade-off, and the mechanism of flat\nminima.\n","authors":["Binchuan Qi","Li Li","Wei Gong"],"pdf_url":"https://arxiv.org/pdf/2406.05666v4.pdf","comment":"arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors"},{"id":"http://arxiv.org/abs/2306.06210v5","updated":"2024-06-26T12:31:04Z","published":"2023-05-26T13:06:38Z","title":"Single-Model Attribution of Generative Models Through Final-Layer\n  Inversion","summary":"  Recent breakthroughs in generative modeling have sparked interest in\npractical single-model attribution. Such methods predict whether a sample was\ngenerated by a specific generator or not, for instance, to prove intellectual\nproperty theft. However, previous works are either limited to the closed-world\nsetting or require undesirable changes to the generative model. We address\nthese shortcomings by, first, viewing single-model attribution through the lens\nof anomaly detection. Arising from this change of perspective, we propose\nFLIPAD, a new approach for single-model attribution in the open-world setting\nbased on final-layer inversion and anomaly detection. We show that the utilized\nfinal-layer inversion can be reduced to a convex lasso optimization problem,\nmaking our approach theoretically sound and computationally efficient. The\ntheoretical findings are accompanied by an experimental study demonstrating the\neffectiveness of our approach and its flexibility to various domains.\n","authors":["Mike Laszkiewicz","Jonas Ricker","Johannes Lederer","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2306.06210v5.pdf","comment":"Accepted at the Forty-first International Conference on Machine\n  Learning [ICML2024]"},{"id":"http://arxiv.org/abs/2406.18295v1","updated":"2024-06-26T12:27:06Z","published":"2024-06-26T12:27:06Z","title":"Evaluating and Benchmarking Foundation Models for Earth Observation and\n  Geospatial AI","summary":"  When we are primarily interested in solving several problems jointly with a\ngiven prescribed high performance accuracy for each target application, then\nFoundation Models should for most cases be used rather than problem-specific\nmodels. We focus on the specific Computer Vision application of Foundation\nModels for Earth Observation (EO) and geospatial AI. These models can solve\nimportant problems we are tackling, including for example land cover\nclassification, crop type mapping, flood segmentation, building density\nestimation, and road regression segmentation. In this paper, we show that for a\nlimited number of labelled data, Foundation Models achieve improved performance\ncompared to problem-specific models. In this work, we also present our proposed\nevaluation benchmark for Foundation Models for EO. Benchmarking the\ngeneralization performance of Foundation Models is important as it has become\ndifficult to standardize a fair comparison across the many different models\nthat have been proposed recently. We present the results using our evaluation\nbenchmark for EO Foundation Models and show that Foundation Models are label\nefficient in the downstream tasks and help us solve problems we are tackling in\nEO and remote sensing.\n","authors":["Nikolaos Dionelis","Casper Fibaek","Luke Camilleri","Andreas Luyts","Jente Bosmans","Bertrand Le Saux"],"pdf_url":"https://arxiv.org/pdf/2406.18295v1.pdf","comment":"5 pages, 2 figures, Submitted"},{"id":"http://arxiv.org/abs/2406.18293v1","updated":"2024-06-26T12:23:54Z","published":"2024-06-26T12:23:54Z","title":"Combining Automated Optimisation of Hyperparameters and Reward Shape","summary":"  There has been significant progress in deep reinforcement learning (RL) in\nrecent years. Nevertheless, finding suitable hyperparameter configurations and\nreward functions remains challenging even for experts, and performance heavily\nrelies on these design choices. Also, most RL research is conducted on known\nbenchmarks where knowledge about these choices already exists. However, novel\npractical applications often pose complex tasks for which no prior knowledge\nabout good hyperparameters and reward functions is available, thus\nnecessitating their derivation from scratch. Prior work has examined\nautomatically tuning either hyperparameters or reward functions individually.\nWe demonstrate empirically that an RL algorithm's hyperparameter configurations\nand reward function are often mutually dependent, meaning neither can be fully\noptimised without appropriate values for the other. We then propose a\nmethodology for the combined optimisation of hyperparameters and the reward\nfunction. Furthermore, we include a variance penalty as an optimisation\nobjective to improve the stability of learned policies. We conducted extensive\nexperiments using Proximal Policy Optimisation and Soft Actor-Critic on four\nenvironments. Our results show that combined optimisation significantly\nimproves over baseline performance in half of the environments and achieves\ncompetitive performance in the others, with only a minor increase in\ncomputational costs. This suggests that combined optimisation should be best\npractice.\n","authors":["Julian Dierkes","Emma Cramer","Holger H. Hoos","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2406.18293v1.pdf","comment":"Published in the Reinforcement Learning Journal 2024"},{"id":"http://arxiv.org/abs/2306.11903v3","updated":"2024-06-26T12:16:57Z","published":"2023-06-20T21:30:54Z","title":"Deep Fusion: Efficient Network Training via Pre-trained Initializations","summary":"  In recent years, deep learning has made remarkable progress in a wide range\nof domains, with a particularly notable impact on natural language processing\ntasks. One of the challenges associated with training deep neural networks in\nthe context of LLMs is the need for large amounts of computational resources\nand time. To mitigate this, network growing algorithms offer potential cost\nsavings, but their underlying mechanisms are poorly understood. We present two\nnotable contributions in this paper. First, we present Deep Fusion, an\nefficient approach to network training that leverages pre-trained\ninitializations of smaller networks. Second, we propose a theoretical framework\nusing backward error analysis to illustrate the dynamics of mid-training\nnetwork growth. Our experiments show how Deep Fusion is a practical and\neffective approach that not only accelerates the training process but also\nreduces computational requirements, maintaining or surpassing traditional\ntraining methods' performance in various NLP tasks and T5 model sizes. Finally,\nwe validate our theoretical framework, which guides the optimal use of Deep\nFusion, showing that with carefully optimized training dynamics, it\nsignificantly reduces both training time and resource consumption.\n","authors":["Hanna Mazzawi","Xavi Gonzalvo","Michael Wunder","Sammy Jerome","Benoit Dherin"],"pdf_url":"https://arxiv.org/pdf/2306.11903v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02484v3","updated":"2024-06-26T12:11:16Z","published":"2024-02-04T13:25:18Z","title":"Weisfeiler Leman for Euclidean Equivariant Machine Learning","summary":"  The $k$-Weisfeiler-Leman ($k$-WL) graph isomorphism test hierarchy is a\ncommon method for assessing the expressive power of graph neural networks\n(GNNs). Recently, GNNs whose expressive power is equivalent to the $2$-WL test\nwere proven to be universal on weighted graphs which encode $3\\mathrm{D}$ point\ncloud data, yet this result is limited to invariant continuous functions on\npoint clouds. In this paper, we extend this result in three ways: Firstly, we\nshow that PPGN can simulate $2$-WL uniformly on all point clouds with low\ncomplexity. Secondly, we show that $2$-WL tests can be extended to point clouds\nwhich include both positions and velocities, a scenario often encountered in\napplications. Finally, we provide a general framework for proving equivariant\nuniversality and leverage it to prove that a simple modification of this\ninvariant PPGN architecture can be used to obtain a universal equivariant\narchitecture that can approximate all continuous equivariant functions\nuniformly. Building on our results, we develop our WeLNet architecture, which\nsets new state-of-the-art results on the N-Body dynamics task and the GEOM-QM9\nmolecular conformation generation task.\n","authors":["Snir Hordan","Tal Amir","Nadav Dym"],"pdf_url":"https://arxiv.org/pdf/2402.02484v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18279v1","updated":"2024-06-26T12:05:49Z","published":"2024-06-26T12:05:49Z","title":"CAS: Confidence Assessments of classification algorithms for Semantic\n  segmentation of EO data","summary":"  Confidence assessments of semantic segmentation algorithms in remote sensing\nare important. It is a desirable property of models to a priori know if they\nproduce an incorrect output. Evaluations of the confidence assigned to the\nestimates of models for the task of classification in Earth Observation (EO)\nare crucial as they can be used to achieve improved semantic segmentation\nperformance and prevent high error rates during inference and deployment. The\nmodel we develop, the Confidence Assessments of classification algorithms for\nSemantic segmentation (CAS) model, performs confidence evaluations at both the\nsegment and pixel levels, and outputs both labels and confidence. The outcome\nof this work has important applications. The main application is the evaluation\nof EO Foundation Models on semantic segmentation downstream tasks, in\nparticular land cover classification using satellite Copernicus Sentinel-2\ndata. The evaluation shows that the proposed model is effective and outperforms\nother alternative baseline models.\n","authors":["Nikolaos Dionelis","Nicolas Longepe"],"pdf_url":"https://arxiv.org/pdf/2406.18279v1.pdf","comment":"5 pages, 7 figures, 4 tables, Submitted"},{"id":"http://arxiv.org/abs/2402.08703v2","updated":"2024-06-26T11:03:21Z","published":"2024-02-13T16:56:31Z","title":"A Survey of Generative AI for de novo Drug Design: New Frontiers in\n  Molecule and Protein Generation","summary":"  Artificial intelligence (AI)-driven methods can vastly improve the\nhistorically costly drug design process, with various generative models already\nin widespread use. Generative models for de novo drug design, in particular,\nfocus on the creation of novel biological compounds entirely from scratch,\nrepresenting a promising future direction. Rapid development in the field,\ncombined with the inherent complexity of the drug design process, creates a\ndifficult landscape for new researchers to enter. In this survey, we organize\nde novo drug design into two overarching themes: small molecule and protein\ngeneration. Within each theme, we identify a variety of subtasks and\napplications, highlighting important datasets, benchmarks, and model\narchitectures and comparing the performance of top models. We take a broad\napproach to AI-driven drug design, allowing for both micro-level comparisons of\nvarious methods within each subtask and macro-level observations across\ndifferent fields. We discuss parallel challenges and approaches between the two\napplications and highlight future directions for AI-driven de novo drug design\nas a whole. An organized repository of all covered sources is available at\nhttps://github.com/gersteinlab/GenAI4Drug.\n","authors":["Xiangru Tang","Howard Dai","Elizabeth Knight","Fang Wu","Yunyang Li","Tianxiao Li","Mark Gerstein"],"pdf_url":"https://arxiv.org/pdf/2402.08703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17639v2","updated":"2024-06-26T10:58:48Z","published":"2024-06-25T15:24:02Z","title":"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal\n  Alignment in CLIP","summary":"  Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering two\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? We design AlignCLIP, in\norder to answer these questions and show that answers to both questions are\npositive. Through extensive experiments, we show that AlignCLIP achieves\nnoticeable enhancements in the cross-modal alignment of the embeddings, and\nthereby, reduces the modality gap, while maintaining the performance across\nseveral downstream evaluations, such as zero-shot image classification,\nzero-shot multi-modal retrieval and zero-shot semantic text similarity.\n","authors":["Sedigheh Eslami","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2406.17639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12475v2","updated":"2024-06-26T10:57:40Z","published":"2024-06-18T10:28:12Z","title":"Adversarial Multi-dueling Bandits","summary":"  We introduce the problem of regret minimization in adversarial multi-dueling\nbandits. While adversarial preferences have been studied in dueling bandits,\nthey have not been explored in multi-dueling bandits. In this setting, the\nlearner is required to select $m \\geq 2$ arms at each round and observes as\nfeedback the identity of the most preferred arm which is based on an arbitrary\npreference matrix chosen obliviously. We introduce a novel algorithm, MiDEX\n(Multi Dueling EXP3), to learn from such preference feedback that is assumed to\nbe generated from a pairwise-subset choice model. We prove that the expected\ncumulative $T$-round regret of MiDEX compared to a Borda-winner from a set of\n$K$ arms is upper bounded by $O((K \\log K)^{1/3} T^{2/3})$. Moreover, we prove\na lower bound of $\\Omega(K^{1/3} T^{2/3})$ for the expected regret in this\nsetting which demonstrates that our proposed algorithm is near-optimal.\n","authors":["Pratik Gajane"],"pdf_url":"https://arxiv.org/pdf/2406.12475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18249v1","updated":"2024-06-26T10:51:44Z","published":"2024-06-26T10:51:44Z","title":"Foundational Models for Pathology and Endoscopy Images: Application for\n  Gastric Inflammation","summary":"  The integration of artificial intelligence (AI) in medical diagnostics\nrepresents a significant advancement in managing upper gastrointestinal (GI)\ncancer, a major cause of global cancer mortality. Specifically for gastric\ncancer (GC), chronic inflammation causes changes in the mucosa such as atrophy,\nintestinal metaplasia (IM), dysplasia and ultimately cancer. Early detection\nthrough endoscopic regular surveillance is essential for better outcomes.\nFoundation models (FM), which are machine or deep learning models trained on\ndiverse data and applicable to broad use cases, offer a promising solution to\nenhance the accuracy of endoscopy and its subsequent pathology image analysis.\nThis review explores the recent advancements, applications, and challenges\nassociated with FM in endoscopy and pathology imaging. We started by\nelucidating the core principles and architectures underlying these models,\nincluding their training methodologies and the pivotal role of large-scale data\nin developing their predictive capabilities. Moreover, this work discusses\nemerging trends and future research directions, emphasizing the integration of\nmultimodal data, the development of more robust and equitable models, and the\npotential for real-time diagnostic support. This review aims to provide a\nroadmap for researchers and practitioners in navigating the complexities of\nincorporating FM into clinical practice for prevention/management of GC cases,\nthereby improving patient outcomes.\n","authors":["Hamideh Kerdegari","Kyle Higgins","Dennis Veselkov","Ivan Laponogov","Inese Polaka","Miguel Coimbra","Junior Andrea Pescino","Marcis Leja","Mario Dinis-Ribeiro","Tania Fleitas Kanonnikoff","Kirill Veselkov"],"pdf_url":"https://arxiv.org/pdf/2406.18249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18247v1","updated":"2024-06-26T10:49:26Z","published":"2024-06-26T10:49:26Z","title":"Generative artificial intelligence in ophthalmology: multimodal retinal\n  images for the diagnosis of Alzheimer's disease with convolutional neural\n  networks","summary":"  Background/Aim. This study aims to predict Amyloid Positron Emission\nTomography (AmyloidPET) status with multimodal retinal imaging and\nconvolutional neural networks (CNNs) and to improve the performance through\npretraining with synthetic data. Methods. Fundus autofluorescence, optical\ncoherence tomography (OCT), and OCT angiography images from 328 eyes of 59\nAmyloidPET positive subjects and 108 AmyloidPET negative subjects were used for\nclassification. Denoising Diffusion Probabilistic Models (DDPMs) were trained\nto generate synthetic images and unimodal CNNs were pretrained on synthetic\ndata and finetuned on real data or trained solely on real data. Multimodal\nclassifiers were developed to combine predictions of the four unimodal CNNs\nwith patient metadata. Class activation maps of the unimodal classifiers\nprovided insight into the network's attention to inputs. Results. DDPMs\ngenerated diverse, realistic images without memorization. Pretraining unimodal\nCNNs with synthetic data improved AUPR at most from 0.350 to 0.579. Integration\nof metadata in multimodal CNNs improved AUPR from 0.486 to 0.634, which was the\nbest overall best classifier. Class activation maps highlighted relevant\nretinal regions which correlated with AD. Conclusion. Our method for generating\nand leveraging synthetic data has the potential to improve AmyloidPET\nprediction from multimodal retinal imaging. A DDPM can generate realistic and\nunique multimodal synthetic retinal images. Our best performing unimodal and\nmultimodal classifiers were not pretrained on synthetic data, however\npretraining with synthetic data slightly improved classification performance\nfor two out of the four modalities.\n","authors":["I. R. Slootweg","M. Thach","K. R. Curro-Tafili","F. D. Verbraak","F. H. Bouwman","Y. A. L. Pijnenburg","J. F. Boer","J. H. P. de Kwisthout","L. Bagheriye","P. J. González"],"pdf_url":"https://arxiv.org/pdf/2406.18247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09986v2","updated":"2024-06-26T10:16:46Z","published":"2024-01-18T14:02:23Z","title":"Improving Local Training in Federated Learning via Temperature Scaling","summary":"  Federated learning is inherently hampered by data heterogeneity: non-i.i.d.\ntraining data over local clients. We propose a novel model training approach\nfor federated learning, FLex&Chill, which exploits the Logit Chilling method.\nThrough extensive evaluations, we demonstrate that, in the presence of\nnon-i.i.d. data characteristics inherent in federated learning systems, this\napproach can expedite model convergence and improve inference accuracy.\nQuantitatively, from our experiments, we observe up to 6X improvement in the\nglobal federated learning model convergence time, and up to 3.37% improvement\nin inference accuracy.\n","authors":["Kichang Lee","Songkuk Kim","JeongGil Ko"],"pdf_url":"https://arxiv.org/pdf/2401.09986v2.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2406.18220v1","updated":"2024-06-26T10:08:24Z","published":"2024-06-26T10:08:24Z","title":"Guiding Video Prediction with Explicit Procedural Knowledge","summary":"  We propose a general way to integrate procedural knowledge of a domain into\ndeep learning models. We apply it to the case of video prediction, building on\ntop of object-centric deep models and show that this leads to a better\nperformance than using data-driven models alone. We develop an architecture\nthat facilitates latent space disentanglement in order to use the integrated\nprocedural knowledge, and establish a setup that allows the model to learn the\nprocedural interface in the latent space using the downstream task of video\nprediction. We contrast the performance to a state-of-the-art data-driven\napproach and show that problems where purely data-driven approaches struggle\ncan be handled by using knowledge about the domain, providing an alternative to\nsimply collecting more data.\n","authors":["Patrick Takenaka","Johannes Maucher","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2406.18220v1.pdf","comment":"Published in 2023 IEEE/CVF International Conference on Computer\n  Vision Workshops (ICCVW)"},{"id":"http://arxiv.org/abs/2406.18219v1","updated":"2024-06-26T10:07:57Z","published":"2024-06-26T10:07:57Z","title":"A Closer Look into Mixture-of-Experts in Large Language Models","summary":"  Mixture-of-experts (MoE) is gaining increasing attention due to its unique\nproperties and remarkable performance, especially for language tasks. By\nsparsely activating a subset of parameters for each token, MoE architecture\ncould increase the model size without sacrificing computational efficiency,\nachieving a better trade-off between performance and training costs. However,\nthe underlying mechanism of MoE still lacks further exploration, and its\nmodularization degree remains questionable. In this paper, we make an initial\nattempt to understand the inner workings of MoE-based large language models.\nConcretely, we comprehensively study the parametric and behavioral features of\nthree recent MoE-based models and reveal some intriguing observations,\nincluding (1) Neurons act like fine-grained experts. (2) The router of MoE\nusually selects experts with larger output norms. (3) The expert diversity\nincreases as the layer increases, while the last layer is an outlier. Based on\nthe observations, we also provide suggestions for a broad spectrum of MoE\npractitioners, such as router design and expert allocation. We hope this work\ncould shed light on future research on the MoE framework and other modular\narchitectures. Code is available at\nhttps://github.com/kamanphoebe/Look-into-MoEs.\n","authors":["Ka Man Lo","Zeyu Huang","Zihan Qiu","Zili Wang","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2406.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17536v2","updated":"2024-06-26T09:52:47Z","published":"2024-06-25T13:20:39Z","title":"MedMNIST-C: Comprehensive benchmark and improved classifier robustness\n  by simulating realistic image corruptions","summary":"  The integration of neural-network-based systems into clinical practice is\nlimited by challenges related to domain generalization and robustness. The\ncomputer vision community established benchmarks such as ImageNet-C as a\nfundamental prerequisite to measure progress towards those challenges. Similar\ndatasets are largely absent in the medical imaging community which lacks a\ncomprehensive benchmark that spans across imaging modalities and applications.\nTo address this gap, we create and open-source MedMNIST-C, a benchmark dataset\nbased on the MedMNIST+ collection covering 12 datasets and 9 imaging\nmodalities. We simulate task and modality-specific image corruptions of varying\nseverity to comprehensively evaluate the robustness of established algorithms\nagainst real-world artifacts and distribution shifts. We further provide\nquantitative evidence that our simple-to-use artificial corruptions allow for\nhighly performant, lightweight data augmentation to enhance model robustness.\nUnlike traditional, generic augmentation strategies, our approach leverages\ndomain knowledge, exhibiting significantly higher robustness when compared to\nwidely adopted methods. By introducing MedMNIST-C and open-sourcing the\ncorresponding library allowing for targeted data augmentations, we contribute\nto the development of increasingly robust methods tailored to the challenges of\nmedical imaging. The code is available at\nhttps://github.com/francescodisalvo05/medmnistc-api}{github.com/francescodisalvo05/medmnistc-api .\n","authors":["Francesco Di Salvo","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2406.17536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15247v2","updated":"2024-06-26T09:08:00Z","published":"2024-05-24T06:17:05Z","title":"Learning Antenna Pointing Correction in Operations: Efficient\n  Calibration of a Black Box","summary":"  We propose an efficient offline pointing calibration method for operational\nantenna systems which does not require any downtime. Our approach minimizes the\ncalibration effort and exploits technical signal information which is typically\nused for monitoring and control purposes in ground station operations. Using a\nstandard antenna interface and data from an operational satellite contact, we\ncome up with a robust strategy for training data set generation. On top of\nthis, we learn the parameters of a suitable coordinate transform by means of\nlinear regression. In our experiments, we show the usefulness of the method in\na real-world setup.\n","authors":["Leif Bergerhoff"],"pdf_url":"https://arxiv.org/pdf/2405.15247v2.pdf","comment":"5 pages, to be published in the conference proceedings of the\n  European Signal Processing Conference (EUSIPCO) 2024, camera-ready fixing\n  typos and extending motivation, test description, calibration strategy\n  description, as well as result discussion"},{"id":"http://arxiv.org/abs/2406.18187v1","updated":"2024-06-26T09:03:52Z","published":"2024-06-26T09:03:52Z","title":"Selective Prompting Tuning for Personalized Conversations with LLMs","summary":"  In conversational AI, personalizing dialogues with persona profiles and\ncontextual understanding is essential. Despite large language models' (LLMs)\nimproved response coherence, effective persona integration remains a challenge.\nIn this work, we first study two common approaches for personalizing LLMs:\ntextual prompting and direct fine-tuning. We observed that textual prompting\noften struggles to yield responses that are similar to the ground truths in\ndatasets, while direct fine-tuning tends to produce repetitive or overly\ngeneric replies. To alleviate those issues, we propose \\textbf{S}elective\n\\textbf{P}rompt \\textbf{T}uning (SPT), which softly prompts LLMs for\npersonalized conversations in a selective way. Concretely, SPT initializes a\nset of soft prompts and uses a trainable dense retriever to adaptively select\nsuitable soft prompts for LLMs according to different input contexts, where the\nprompt retriever is dynamically updated through feedback from the LLMs.\nAdditionally, we propose context-prompt contrastive learning and prompt fusion\nlearning to encourage the SPT to enhance the diversity of personalized\nconversations. Experiments on the CONVAI2 dataset demonstrate that SPT\nsignificantly enhances response diversity by up to 90\\%, along with\nimprovements in other critical performance indicators. Those results highlight\nthe efficacy of SPT in fostering engaging and personalized dialogue generation.\nThe SPT model code (https://github.com/hqsiswiliam/SPT) is publicly available\nfor further exploration.\n","authors":["Qiushi Huang","Xubo Liu","Tom Ko","Bo Wu","Wenwu Wang","Yu Zhang","Lilian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18187v1.pdf","comment":"Accepted to ACL 2024 findings"},{"id":"http://arxiv.org/abs/2406.16901v2","updated":"2024-06-26T08:54:40Z","published":"2024-05-31T15:17:12Z","title":"ECGrecover: a Deep Learning Approach for Electrocardiogram Signal\n  Completion","summary":"  In this work, we address the challenge of reconstructing the complete 12-lead\nECG signal from incomplete parts of it. We focus on two main scenarii: (i)\nreconstructing missing signal segments within an ECG lead and (ii) recovering\nmissing leads from a single-lead. We propose a model with a U-Net architecture\ntrained on a novel objective function to address the reconstruction problem.\nThis function incorporates both spatial and temporal aspects of the ECG by\ncombining the distance in amplitude between the reconstructed and real signals\nwith the signal trend. Through comprehensive assessments using both a real-life\ndataset and a publicly accessible one, we demonstrate that the proposed\napproach consistently outperforms state-of-the-art methods based on generative\nadversarial networks and a CopyPaste strategy. Our proposed model demonstrates\nsuperior performance in standard distortion metrics and preserves critical ECG\ncharacteristics, particularly the P, Q, R, S, and T wave coordinates. Two\nemerging clinical applications emphasize the relevance of our work. The first\nis the increasing need to digitize paper-stored ECGs for utilization in\nAI-based applications (automatic annotation and risk-quantification), often\nlimited to digital ECG complete 10s recordings. The second is the widespread\nuse of wearable devices that record ECGs but typically capture only a small\nsubset of the 12 standard leads. In both cases, a non-negligible amount of\ninformation is lost or not recorded, which our approach aims to recover to\novercome these limitations.\n","authors":["Alex Lence","Ahmad Fall","Federica Granese","Blaise Hanczar","Joe-Elie Salem","Jean-Daniel Zucker","Edi Prifti"],"pdf_url":"https://arxiv.org/pdf/2406.16901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18179v1","updated":"2024-06-26T08:53:26Z","published":"2024-06-26T08:53:26Z","title":"DeepExtremeCubes: Integrating Earth system spatio-temporal data for\n  impact assessment of climate extremes","summary":"  With climate extremes' rising frequency and intensity, robust analytical\ntools are crucial to predict their impacts on terrestrial ecosystems. Machine\nlearning techniques show promise but require well-structured, high-quality, and\ncurated analysis-ready datasets. Earth observation datasets comprehensively\nmonitor ecosystem dynamics and responses to climatic extremes, yet the data\ncomplexity can challenge the effectiveness of machine learning models. Despite\nrecent progress in deep learning to ecosystem monitoring, there is a need for\ndatasets specifically designed to analyse compound heatwave and drought extreme\nimpact. Here, we introduce the DeepExtremeCubes database, tailored to map\naround these extremes, focusing on persistent natural vegetation. It comprises\nover 40,000 spatially sampled small data cubes (i.e. minicubes) globally, with\na spatial coverage of 2.5 by 2.5 km. Each minicube includes (i) Sentinel-2 L2A\nimages, (ii) ERA5-Land variables and generated extreme event cube covering 2016\nto 2022, and (iii) ancillary land cover and topography maps. The paper aims to\n(1) streamline data accessibility, structuring, pre-processing, and enhance\nscientific reproducibility, and (2) facilitate biosphere dynamics forecasting\nin response to compound extremes.\n","authors":["Chaonan Ji","Tonio Fincke","Vitus Benson","Gustau Camps-Valls","Miguel-Angel Fernandez-Torres","Fabian Gans","Guido Kraemer","Francesco Martinuzzi","David Montero","Karin Mora","Oscar J. Pellicer-Valero","Claire Robin","Maximilian Soechting","Melanie Weynants","Miguel D. Mahecha"],"pdf_url":"https://arxiv.org/pdf/2406.18179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05598v2","updated":"2024-06-26T08:43:43Z","published":"2023-12-09T15:41:42Z","title":"Boosting the Cross-Architecture Generalization of Dataset Distillation\n  through an Empirical Study","summary":"  The poor cross-architecture generalization of dataset distillation greatly\nweakens its practical significance. This paper attempts to mitigate this issue\nthrough an empirical study, which suggests that the synthetic datasets undergo\nan inductive bias towards the distillation model. Therefore, the evaluation\nmodel is strictly confined to having similar architectures of the distillation\nmodel. We propose a novel method of EvaLuation with distillation Feature (ELF),\nwhich utilizes features from intermediate layers of the distillation model for\nthe cross-architecture evaluation. In this manner, the evaluation model learns\nfrom bias-free knowledge therefore its architecture becomes unfettered while\nretaining performance. By performing extensive experiments, we successfully\nprove that ELF can well enhance the cross-architecture generalization of\ncurrent DD methods. Code of this project is at\n\\url{https://github.com/Lirui-Zhao/ELF}.\n","authors":["Lirui Zhao","Yuxin Zhang","Fei Chao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2312.05598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05119v2","updated":"2024-06-26T08:25:49Z","published":"2023-02-10T08:49:36Z","title":"Fast Learnings of Coupled Nonnegative Tensor Decomposition Using Optimal\n  Gradient and Low-rank Approximation","summary":"  Tensor decomposition is a fundamental technique widely applied in signal\nprocessing, machine learning, and various other fields. However, traditional\ntensor decomposition methods encounter limitations when jointly analyzing\nmulti-block tensors, as they often struggle to effectively explore shared\ninformation among tensors. In this study, we first introduce a novel coupled\nnonnegative CANDECOMP/PARAFAC decomposition algorithm optimized by the\nalternating proximal gradient method (CoNCPD-APG). This algorithm is specially\ndesigned to address the challenges of jointly decomposing different tensors\nthat are partially or fully linked, while simultaneously extracting common\ncomponents, individual components and, core tensors. Recognizing the\ncomputational challenges inherent in optimizing nonnegative constraints over\nhigh-dimensional tensor data, we further propose the lraCoNCPD-APG algorithm.\nBy integrating low-rank approximation with the proposed CoNCPD-APG method, the\nproposed algorithm can significantly decrease the computational burden without\ncompromising decomposition quality, particularly for multi-block large-scale\ntensors. Simulation experiments conducted on synthetic data, real-world face\nimage data, and two kinds of electroencephalography (EEG) data demonstrate the\npracticality and superiority of the proposed algorithms for coupled nonnegative\ntensor decomposition problems. Our results underscore the efficacy of our\nmethods in uncovering meaningful patterns and structures from complex\nmulti-block tensor data, thereby offering valuable insights for future\napplications.\n","authors":["Xiulin Wang","Jing Liu","Fengyu Cong"],"pdf_url":"https://arxiv.org/pdf/2302.05119v2.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.18164v1","updated":"2024-06-26T08:24:44Z","published":"2024-06-26T08:24:44Z","title":"NeBuLa: A discourse aware Minecraft Builder","summary":"  When engaging in collaborative tasks, humans efficiently exploit the semantic\nstructure of a conversation to optimize verbal and nonverbal interactions. But\nin recent \"language to code\" or \"language to action\" models, this information\nis lacking. We show how incorporating the prior discourse and nonlinguistic\ncontext of a conversation situated in a nonlinguistic environment can improve\nthe \"language to action\" component of such interactions. We fine tune an LLM to\npredict actions based on prior context; our model, NeBuLa, doubles the\nnet-action F1 score over the baseline on this task of Jayannavar et al.(2020).\nWe also investigate our model's ability to construct shapes and understand\nlocation descriptions using a synthetic dataset.\n","authors":["Akshay Chaturvedi","Kate Thompson","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2406.18164v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2206.00238v2","updated":"2024-06-26T08:24:26Z","published":"2022-06-01T05:16:39Z","title":"Transferable Reward Learning by Dynamics-Agnostic Discriminator Ensemble","summary":"  Recovering reward function from expert demonstrations is a fundamental\nproblem in reinforcement learning. The recovered reward function captures the\nmotivation of the expert. Agents can imitate experts by following these reward\nfunctions in their environment, which is known as apprentice learning. However,\nthe agents may face environments different from the demonstrations, and\ntherefore, desire transferable reward functions. Classical reward learning\nmethods such as inverse reinforcement learning (IRL) or, equivalently,\nadversarial imitation learning (AIL), recover reward functions coupled with\ntraining dynamics, which are hard to be transferable. Previous\ndynamics-agnostic reward learning methods rely on assumptions such as that the\nreward function has to be state-only, restricting their applicability. In this\nwork, we present a dynamics-agnostic discriminator-ensemble reward learning\nmethod (DARL) within the AIL framework, capable of learning both state-action\nand state-only reward functions. DARL achieves this by decoupling the reward\nfunction from training dynamics, employing a dynamics-agnostic discriminator on\na latent space derived from the original state-action space. This latent space\nis optimized to minimize information on the dynamics. We moreover discover the\npolicy-dependency issue of the AIL framework that reduces the transferability.\nDARL represents the reward function as an ensemble of discriminators during\ntraining to eliminate policy dependencies. Empirical studies on MuJoCo tasks\nwith changed dynamics show that DARL better recovers the reward function and\nresults in better imitation performance in transferred environments, handling\nboth state-only and state-action reward scenarios.\n","authors":["Fan-Ming Luo","Xingchen Cao","Rong-Jun Qin","Yang Yu"],"pdf_url":"https://arxiv.org/pdf/2206.00238v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18156v1","updated":"2024-06-26T08:14:23Z","published":"2024-06-26T08:14:23Z","title":"FedAQ: Communication-Efficient Federated Edge Learning via Joint Uplink\n  and Downlink Adaptive Quantization","summary":"  Federated learning (FL) is a powerful machine learning paradigm which\nleverages the data as well as the computational resources of clients, while\nprotecting clients' data privacy. However, the substantial model size and\nfrequent aggregation between the server and clients result in significant\ncommunication overhead, making it challenging to deploy FL in resource-limited\nwireless networks. In this work, we aim to mitigate the communication overhead\nby using quantization. Previous research on quantization has primarily focused\non the uplink communication, employing either fixed-bit quantization or\nadaptive quantization methods. In this work, we introduce a holistic approach\nby joint uplink and downlink adaptive quantization to reduce the communication\noverhead. In particular, we optimize the learning convergence by determining\nthe optimal uplink and downlink quantization bit-length, with a communication\nenergy constraint. Theoretical analysis shows that the optimal quantization\nlevels depend on the range of model gradients or weights. Based on this\ninsight, we propose a decreasing-trend quantization for the uplink and an\nincreasing-trend quantization for the downlink, which aligns with the change of\nthe model parameters during the training process. Experimental results show\nthat, the proposed joint uplink and downlink adaptive quantization strategy can\nsave up to 66.7% energy compared with the existing schemes.\n","authors":["Linping Qu","Shenghui Song","Chi-Ying Tsui"],"pdf_url":"https://arxiv.org/pdf/2406.18156v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2406.17415v2","updated":"2024-06-26T08:00:18Z","published":"2024-06-25T09:37:15Z","title":"Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing\n  LLMs Beyond Integer Bit-Levels","summary":"  We present a simple variable quantization approach that quantizes different\nlayers of a large language model (LLM) at different bit levels. Specifically,\nwe quantize the most important layers to higher bit precision and less\nimportant layers to lower bits to achieve floating point quantization levels.\nWe propose two effective strategies to measure the importance of layers within\nLLMs: the first measures the importance of a layer based on how different its\noutput embeddings are from the input embeddings (the higher the better); the\nsecond estimates the importance of a layer using the number of layer weights\nthat are much larger than average (the smaller the better). We show that\nquantizing different layers at varying bits according to our importance scores\nresults in minimal performance drop with a far more compressed model size.\nFinally, we present several practical key takeaways from our variable\nlayer-wise quantization experiments: (a) LLM performance under variable\nquantization remains close to the original model until 25-50% of layers are\nmoved in lower quantization using our proposed ordering but only until 5-10% if\nmoved using no specific ordering; (b) Quantizing LLMs to lower bits performs\nsubstantially better than pruning unless extreme quantization (2-bit) is used;\nand (c) Layer-wise quantization to lower bits works better in the case of\nlarger LLMs with more layers compared to smaller LLMs with fewer layers. The\ncode used to run the experiments is available at:\nhttps://github.com/RazvanDu/LayerwiseQuant.\n","authors":["Razvan-Gabriel Dumitru","Vikas Yadav","Rishabh Maheshwary","Paul-Ioan Clotan","Sathwik Tejaswi Madhusudhan","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2406.17415v2.pdf","comment":"submitted to EMNLP, 15 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2405.17234v5","updated":"2024-06-26T07:59:40Z","published":"2024-05-27T14:50:42Z","title":"Benchmarking General-Purpose In-Context Learning","summary":"  In-context learning (ICL) empowers generative models to address new tasks\neffectively and efficiently on the fly, without relying on any artificially\ncrafted optimization techniques. In this paper, we study extending ICL to\naddress a broader range of tasks with an extended learning horizon and higher\nimprovement potential, namely General-Purpose In-Context Learning (GPICL). To\nthis end, we introduce two lightweight benchmarks specifically crafted to train\nand evaluate GPICL functionalities. Each benchmark encompasses a vast number of\ntasks characterized by significant task variance, facilitating meta-training\nthat minimizes inductive bias. These tasks are also crafted to promote\nlong-horizon in-context learning through continuous generation and interaction.\nThese characteristics necessitate the models to leverage contexts and history\ninteractions to enhance their capabilities, across domains such as language\nmodeling, decision-making, and world modeling. Our experiments on the baseline\nmodels demonstrate that meta-training with minimal inductive bias and ICL from\nthe ground up is feasible across all the domains we've discussed. Additionally,\nour findings indicate that the scale of parameters alone may not be crucial for\nICL or GPICL, suggesting alternative approaches such as increasing the scale of\ncontexts and memory states.\n","authors":["Fan Wang","Chuan Lin","Yang Cao","Yu Kang"],"pdf_url":"https://arxiv.org/pdf/2405.17234v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05935v2","updated":"2024-06-26T07:59:03Z","published":"2024-02-08T18:59:48Z","title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large\n  Language Models","summary":"  We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory\n","authors":["Dongyang Liu","Renrui Zhang","Longtian Qiu","Siyuan Huang","Weifeng Lin","Shitian Zhao","Shijie Geng","Ziyi Lin","Peng Jin","Kaipeng Zhang","Wenqi Shao","Chao Xu","Conghui He","Junjun He","Hao Shao","Pan Lu","Hongsheng Li","Yu Qiao","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2402.05935v2.pdf","comment":"Accepted by ICML 2024. Code and models are released at\n  https://github.com/Alpha-VLLM/LLaMA2-Accessory"},{"id":"http://arxiv.org/abs/2406.18145v1","updated":"2024-06-26T07:53:48Z","published":"2024-06-26T07:53:48Z","title":"Beyond Statistical Estimation: Differentially Private Individual\n  Computation in the Shuffle Model","summary":"  The shuffle model of differential privacy (DP) has recently emerged as a\npowerful one for decentralized computation without fully trustable parties.\nSince it anonymizes and permutes messages from clients through a shuffler, the\nprivacy can be amplified and utility can be improved. However, the shuffling\nprocedure in turn restricts its applications only to statistical tasks that are\npermutation-invariant.\n  This work explores the feasibility of shuffle privacy amplification for\nprevalent non-statistical computations: spatial crowdsourcing, combinatorial\noptimization, location-based social systems, and federated learning with\nincentives, which suffer either computationally intractability or intolerable\nutility loss in existing approaches (e.g., secure MPC and local DP). We\nproposes a new paradigm of shuffle model that can provide critical security\nfunctionalities like message authorization and result access control, meanwhile\nmaintaining the most of privacy amplification effects. It incurs almost the\nsame computation/communication costs as the non-private setting, and permits\nthe server to run arbitrary algorithms on (noisy) client information in\nplaintext. Our novel technique is introducing statistically random identity\ninto DP and force identical random distribution on all clients, so as to\nsupport secure functionalities even after message shuffling and to maintain\nprivacy amplification simultaneously. Given that existing DP randomizers fails\nin the new shuffle model, we also propose a new mechanism and prove its\noptimality therein. Experimental results on spatial crowdsourcing,\nlocation-based social system, and federated learning with incentives, show that\nour paradigm and mechanism is fast as non-private settings, while reducing up\nto 90% error and increasing utility performance indicates by 100%-300%\nrelatively, and can be practical under reasonable privacy budget.\n","authors":["Shaowei Wang","Changyu Dong","Di Wang","Xiangfu Song"],"pdf_url":"https://arxiv.org/pdf/2406.18145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17542v2","updated":"2024-06-26T07:44:42Z","published":"2024-06-25T13:29:14Z","title":"CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained\n  Models using Greedy Coordinate Descent","summary":"  Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses coordinate descent to minimize the\nlayer-wise reconstruction loss to achieve high-quality quantized weights. Our\nalgorithm is easy to implement and scales efficiently to models with hundreds\nof billions of parameters. Through extensive evaluation on the PaLM2 model\nfamily, we demonstrate that CDQuant consistently outperforms GPTQ across\ndiverse model sizes and quantization levels. In particular, for INT2\nquantization of PaLM2-Otter, CDQuant achieves a 10% reduction in perplexity\ncompared to GPTQ.\n","authors":["Pranav Ajit Nair","Arun Sai Suggala"],"pdf_url":"https://arxiv.org/pdf/2406.17542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04678v3","updated":"2024-06-26T07:43:11Z","published":"2024-02-07T09:09:14Z","title":"FaithLM: Towards Faithful Explanations for Large Language Models","summary":"  Large Language Models (LLMs) have become proficient in addressing complex\ntasks by leveraging their extensive internal knowledge and reasoning\ncapabilities. However, the black-box nature of these models complicates the\ntask of explaining their decision-making processes. While recent advancements\ndemonstrate the potential of leveraging LLMs to self-explain their predictions\nthrough natural language (NL) explanations, their explanations may not\naccurately reflect the LLMs' decision-making process due to a lack of fidelity\noptimization on the derived explanations. Measuring the fidelity of NL\nexplanations is a challenging issue, as it is difficult to manipulate the input\ncontext to mask the semantics of these explanations. To this end, we introduce\nFaithLM to explain the decision of LLMs with NL explanations. Specifically,\nFaithLM designs a method for evaluating the fidelity of NL explanations by\nincorporating the contrary explanations to the query process. Moreover, FaithLM\nconducts an iterative process to improve the fidelity of derived explanations.\nExperiment results on three datasets from multiple domains demonstrate that\nFaithLM can significantly improve the fidelity of derived explanations, which\nalso provides a better alignment with the ground-truth explanations.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Chia-Yuan Chang","Ruixiang Tang","Shaochen Zhong","Fan Yang","Mengnan Du","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2402.04678v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18137v1","updated":"2024-06-26T07:41:41Z","published":"2024-06-26T07:41:41Z","title":"Sparse deep neural networks for nonparametric estimation in\n  high-dimensional sparse regression","summary":"  Generalization theory has been established for sparse deep neural networks\nunder high-dimensional regime. Beyond generalization, parameter estimation is\nalso important since it is crucial for variable selection and interpretability\nof deep neural networks. Current theoretical studies concerning parameter\nestimation mainly focus on two-layer neural networks, which is due to the fact\nthat the convergence of parameter estimation heavily relies on the regularity\nof the Hessian matrix, while the Hessian matrix of deep neural networks is\nhighly singular. To avoid the unidentifiability of deep neural networks in\nparameter estimation, we propose to conduct nonparametric estimation of partial\nderivatives with respect to inputs. We first show that model convergence of\nsparse deep neural networks is guaranteed in that the sample complexity only\ngrows with the logarithm of the number of parameters or the input dimension\nwhen the $\\ell_{1}$-norm of parameters is well constrained. Then by bounding\nthe norm and the divergence of partial derivatives, we establish that the\nconvergence rate of nonparametric estimation of partial derivatives scales as\n$\\mathcal{O}(n^{-1/4})$, a rate which is slower than the model convergence rate\n$\\mathcal{O}(n^{-1/2})$. To the best of our knowledge, this study combines\nnonparametric estimation and parametric sparse deep neural networks for the\nfirst time. As nonparametric estimation of partial derivatives is of great\nsignificance for nonlinear variable selection, the current results show the\npromising future for the interpretability of deep neural networks.\n","authors":["Dongya Wu","Xin Li"],"pdf_url":"https://arxiv.org/pdf/2406.18137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18131v1","updated":"2024-06-26T07:32:47Z","published":"2024-06-26T07:32:47Z","title":"Sequential Disentanglement by Extracting Static Information From A\n  Single Sequence Element","summary":"  One of the fundamental representation learning tasks is unsupervised\nsequential disentanglement, where latent codes of inputs are decomposed to a\nsingle static factor and a sequence of dynamic factors. To extract this latent\ninformation, existing methods condition the static and dynamic codes on the\nentire input sequence. Unfortunately, these models often suffer from\ninformation leakage, i.e., the dynamic vectors encode both static and dynamic\ninformation, or vice versa, leading to a non-disentangled representation.\nAttempts to alleviate this problem via reducing the dynamic dimension and\nauxiliary loss terms gain only partial success. Instead, we propose a novel and\nsimple architecture that mitigates information leakage by offering a simple and\neffective subtraction inductive bias while conditioning on a single sample.\nRemarkably, the resulting variational framework is simpler in terms of required\nloss terms, hyperparameters, and data augmentation. We evaluate our method on\nmultiple data-modality benchmarks including general time series, video, and\naudio, and we show beyond state-of-the-art results on generation and prediction\ntasks in comparison to several strong baselines.\n","authors":["Nimrod Berman","Ilan Naiman","Idan Arbiv","Gal Fadlon","Omri Azencot"],"pdf_url":"https://arxiv.org/pdf/2406.18131v1.pdf","comment":"Accepted to ICML 2024; The first four authors contributed equally"},{"id":"http://arxiv.org/abs/2406.18129v1","updated":"2024-06-26T07:31:16Z","published":"2024-06-26T07:31:16Z","title":"CTS: Sim-to-Real Unsupervised Domain Adaptation on 3D Detection","summary":"  Simulation data can be accurately labeled and have been expected to improve\nthe performance of data-driven algorithms, including object detection. However,\ndue to the various domain inconsistencies from simulation to reality\n(sim-to-real), cross-domain object detection algorithms usually suffer from\ndramatic performance drops. While numerous unsupervised domain adaptation (UDA)\nmethods have been developed to address cross-domain tasks between real-world\ndatasets, progress in sim-to-real remains limited. This paper presents a novel\nComplex-to-Simple (CTS) framework to transfer models from labeled simulation\n(source) to unlabeled reality (target) domains. Based on a two-stage detector,\nthe novelty of this work is threefold: 1) developing fixed-size anchor heads\nand RoI augmentation to address size bias and feature diversity between two\ndomains, thereby improving the quality of pseudo-label; 2) developing a novel\ncorner-format representation of aleatoric uncertainty (AU) for the bounding\nbox, to uniformly quantify pseudo-label quality; 3) developing a noise-aware\nmean teacher domain adaptation method based on AU, as well as object-level and\nframe-level sampling strategies, to migrate the impact of noisy labels.\nExperimental results demonstrate that our proposed approach significantly\nenhances the sim-to-real domain adaptation capability of 3D object detection\nmodels, outperforming state-of-the-art cross-domain algorithms, which are\nusually developed for real-to-real UDA tasks.\n","authors":["Meiying Zhang","Weiyuan Peng","Guangyao Ding","Chenyang Lei","Chunlin Ji","Qi Hao"],"pdf_url":"https://arxiv.org/pdf/2406.18129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12476v2","updated":"2024-06-26T23:55:27Z","published":"2024-01-23T04:05:26Z","title":"Bayesian identification of nonseparable Hamiltonians with multiplicative\n  noise using deep learning and reduced-order modeling","summary":"  This paper presents a structure-preserving Bayesian approach for learning\nnonseparable Hamiltonian systems using stochastic dynamic models allowing for\nstatistically-dependent, vector-valued additive and multiplicative measurement\nnoise. The approach is comprised of three main facets. First, we derive a\nGaussian filter for a statistically-dependent, vector-valued, additive and\nmultiplicative noise model that is needed to evaluate the likelihood within the\nBayesian posterior. Second, we develop a novel algorithm for cost-effective\napplication of Bayesian system identification to high-dimensional systems.\nThird, we demonstrate how structure-preserving methods can be incorporated into\nthe proposed framework, using nonseparable Hamiltonians as an illustrative\nsystem class. We assess the method's performance based on the forecasting\naccuracy of a model estimated from-single trajectory data. We compare the\nBayesian method to a state-of-the-art machine learning method on a canonical\nnonseparable Hamiltonian model and a chaotic double pendulum model with small,\nnoisy training datasets. The results show that using the Bayesian posterior as\na training objective can yield upwards of 724 times improvement in Hamiltonian\nmean squared error using training data with up to 10% multiplicative noise\ncompared to a standard training objective. Lastly, we demonstrate the utility\nof the novel algorithm for parameter estimation of a 64-dimensional model of\nthe spatially-discretized nonlinear Schr\\\"odinger equation with data corrupted\nby up to 20% multiplicative noise.\n","authors":["Nicholas Galioto","Harsh Sharma","Boris Kramer","Alex Arkady Gorodetsky"],"pdf_url":"https://arxiv.org/pdf/2401.12476v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09605v3","updated":"2024-06-26T23:41:36Z","published":"2023-05-16T16:56:19Z","title":"To smooth a cloud or to pin it down: Guarantees and Insights on Score\n  Matching in Denoising Diffusion Models","summary":"  Denoising diffusion models are a class of generative models which have\nrecently achieved state-of-the-art results across many domains. Gradual noise\nis added to the data using a diffusion process, which transforms the data\ndistribution into a Gaussian. Samples from the generative model are then\nobtained by simulating an approximation of the time reversal of this diffusion\ninitialized by Gaussian samples. Recent research has explored adapting\ndiffusion models for sampling and inference tasks. In this paper, we leverage\nknown connections to stochastic control akin to the F\\\"ollmer drift to extend\nestablished neural network approximation results for the F\\\"ollmer drift to\ndenoising diffusion models and samplers.\n","authors":["Francisco Vargas","Teodora Reu","Anna Kerekes","Michael M Bronstein"],"pdf_url":"https://arxiv.org/pdf/2305.09605v3.pdf","comment":"arXiv admin note: text overlap with arXiv:1903.01608 by other authors"},{"id":"http://arxiv.org/abs/2404.14527v2","updated":"2024-06-26T23:39:26Z","published":"2024-04-22T18:56:18Z","title":"Mélange: Cost Efficient Large Language Model Serving by Exploiting GPU\n  Heterogeneity","summary":"  Large language models (LLMs) are increasingly integrated into many online\nservices, yet they remain cost-prohibitive to deploy due to the requirement of\nexpensive GPU instances. Prior work has addressed the high cost of LLM serving\nby improving the inference engine, but less attention has been given to\nselecting the most cost-efficient GPU type(s) for a specific LLM service. There\nis a large and growing landscape of GPU types and, within these options, higher\ncost does not always lead to increased performance. Instead, through a\ncomprehensive investigation, we find that three key LLM service characteristics\n(request size, request rate, SLO) strongly influence GPU cost efficiency, and\ndiffering GPU types are most cost efficient for differing LLM service settings.\nAs a result, the most cost-efficient allocation for a given service is\ntypically a mix of heterogeneous GPU types. Based on this analysis, we\nintroduce M\\'elange, a GPU allocation framework that navigates these diverse\nLLM service characteristics and heterogeneous GPU option space to automatically\nand efficiently derive the minimal-cost GPU allocation for a given LLM service.\nWe formulate the GPU allocation task as a cost-aware bin packing problem where\nGPUs are bins and items are slices of the service workload. Our formulation's\nconstraints account for a service's unique characteristics, allowing M\\'elange\nto be flexible to support diverse service settings and heterogeneity-aware to\nadapt the GPU allocation to a specific service. Compared to using only a single\nGPU type, M\\'elange reduces deployment costs by up to 77\\% in conversational\nsettings, 33\\% in document-based settings, and 51\\% in a mixed setting.\n","authors":["Tyler Griggs","Xiaoxuan Liu","Jiaxiang Yu","Doyoung Kim","Wei-Lin Chiang","Alvin Cheung","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2404.14527v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06554v2","updated":"2024-06-26T23:37:46Z","published":"2023-11-11T12:04:47Z","title":"PGODE: Towards High-quality System Dynamics Modeling","summary":"  This paper studies the problem of modeling multi-agent dynamical systems,\nwhere agents could interact mutually to influence their behaviors. Recent\nresearch predominantly uses geometric graphs to depict these mutual\ninteractions, which are then captured by powerful graph neural networks (GNNs).\nHowever, predicting interacting dynamics in challenging scenarios such as\nout-of-distribution shift and complicated underlying rules remains unsolved. In\nthis paper, we propose a new approach named Prototypical Graph ODE (PGODE) to\naddress the problem. The core of PGODE is to incorporate prototype\ndecomposition from contextual knowledge into a continuous graph ODE framework.\nSpecifically, PGODE employs representation disentanglement and system\nparameters to extract both object-level and system-level contexts from\nhistorical trajectories, which allows us to explicitly model their independent\ninfluence and thus enhances the generalization capability under system changes.\nThen, we integrate these disentangled latent representations into a graph ODE\nmodel, which determines a combination of various interacting prototypes for\nenhanced model expressivity. The entire model is optimized using an end-to-end\nvariational inference framework to maximize the likelihood. Extensive\nexperiments in both in-distribution and out-of-distribution settings validate\nthe superiority of PGODE compared to various baselines.\n","authors":["Xiao Luo","Yiyang Gu","Huiyu Jiang","Hang Zhou","Jinsheng Huang","Wei Ju","Zhiping Xiao","Ming Zhang","Yizhou Sun"],"pdf_url":"https://arxiv.org/pdf/2311.06554v2.pdf","comment":"Accepted by ICML 2024"},{"id":"http://arxiv.org/abs/2406.18794v1","updated":"2024-06-26T23:36:46Z","published":"2024-06-26T23:36:46Z","title":"Operator Learning of Lipschitz Operators: An Information-Theoretic\n  Perspective","summary":"  Operator learning based on neural operators has emerged as a promising\nparadigm for the data-driven approximation of operators, mapping between\ninfinite-dimensional Banach spaces. Despite significant empirical progress, our\ntheoretical understanding regarding the efficiency of these approximations\nremains incomplete. This work addresses the parametric complexity of neural\noperator approximations for the general class of Lipschitz continuous\noperators. Motivated by recent findings on the limitations of specific\narchitectures, termed curse of parametric complexity, we here adopt an\ninformation-theoretic perspective. Our main contribution establishes lower\nbounds on the metric entropy of Lipschitz operators in two approximation\nsettings; uniform approximation over a compact set of input functions, and\napproximation in expectation, with input functions drawn from a probability\nmeasure. It is shown that these entropy bounds imply that, regardless of the\nactivation function used, neural operator architectures attaining an\napproximation accuracy $\\epsilon$ must have a size that is exponentially large\nin $\\epsilon^{-1}$. The size of architectures is here measured by counting the\nnumber of encoded bits necessary to store the given model in computational\nmemory. The results of this work elucidate fundamental trade-offs and\nlimitations in\n","authors":["Samuel Lanthaler"],"pdf_url":"https://arxiv.org/pdf/2406.18794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18787v1","updated":"2024-06-26T23:13:45Z","published":"2024-06-26T23:13:45Z","title":"Unified Uncertainties: Combining Input, Data and Model Uncertainty into\n  a Single Formulation","summary":"  Modelling uncertainty in Machine Learning models is essential for achieving\nsafe and reliable predictions. Most research on uncertainty focuses on output\nuncertainty (predictions), but minimal attention is paid to uncertainty at\ninputs. We propose a method for propagating uncertainty in the inputs through a\nNeural Network that is simultaneously able to estimate input, data, and model\nuncertainty. Our results show that this propagation of input uncertainty\nresults in a more stable decision boundary even under large amounts of input\nnoise than comparatively simple Monte Carlo sampling. Additionally, we discuss\nand demonstrate that input uncertainty, when propagated through the model,\nresults in model uncertainty at the outputs. The explicit incorporation of\ninput uncertainty may be beneficial in situations where the amount of input\nuncertainty is known, though good datasets for this are still needed.\n","authors":["Matias Valdenegro-Toro","Ivo Pascal de Jong","Marco Zullich"],"pdf_url":"https://arxiv.org/pdf/2406.18787v1.pdf","comment":"4 pages, 3 figures, with appendix. LatinX in AI Research Workshop @\n  ICML 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2406.18783v1","updated":"2024-06-26T23:04:52Z","published":"2024-06-26T23:04:52Z","title":"Psychological Profiling in Cybersecurity: A Look at LLMs and\n  Psycholinguistic Features","summary":"  The increasing sophistication of cyber threats necessitates innovative\napproaches to cybersecurity. In this paper, we explore the potential of\npsychological profiling techniques, particularly focusing on the utilization of\nLarge Language Models (LLMs) and psycholinguistic features. We investigate the\nintersection of psychology and cybersecurity, discussing how LLMs can be\nemployed to analyze textual data for identifying psychological traits of threat\nactors. We explore the incorporation of psycholinguistic features, such as\nlinguistic patterns and emotional cues, into cybersecurity frameworks. \\iffalse\nThrough case studies and experiments, we discuss the effectiveness of these\nmethods in enhancing threat detection and mitigation strategies.\\fi Our\nresearch underscores the importance of integrating psychological perspectives\ninto cybersecurity practices to bolster defense mechanisms against evolving\nthreats.\n","authors":["Jean Marie Tshimula","D'Jeff K. Nkashama","Jean Tshibangu Muabila","René Manassé Galekwa","Hugues Kanda","Maximilien V. Dialufuma","Mbuyi Mukendi Didier","Kalala Kalonji","Serge Mundele","Patience Kinshie Lenye","Tighana Wenge Basele","Aristarque Ilunga","Christian N. Mayemba","Nathanaël M. Kasoro","Selain K. Kasereka","Hardy Mikese","Pierre-Martin Tardif","Marc Frappier","Froduald Kabanza","Belkacem Chikhaoui","Shengrui Wang","Ali Mulenda Sumbu","Xavier Ndona","Raoul Kienge-Kienge Intudi"],"pdf_url":"https://arxiv.org/pdf/2406.18783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18781v1","updated":"2024-06-26T22:50:43Z","published":"2024-06-26T22:50:43Z","title":"Learning to Remove Cuts in Integer Linear Programming","summary":"  Cutting plane methods are a fundamental approach for solving integer linear\nprograms (ILPs). In each iteration of such methods, additional linear\nconstraints (cuts) are introduced to the constraint set with the aim of\nexcluding the previous fractional optimal solution while not affecting the\noptimal integer solution. In this work, we explore a novel approach within\ncutting plane methods: instead of only adding new cuts, we also consider the\nremoval of previous cuts introduced at any of the preceding iterations of the\nmethod under a learnable parametric criteria. We demonstrate that in\nfundamental combinatorial optimization settings such cut removal policies can\nlead to significant improvements over both human-based and machine\nlearning-guided cut addition policies even when implemented with simple models.\n","authors":["Pol Puigdemont","Stratis Skoulakis","Grigorios Chrysos","Volkan Cevher"],"pdf_url":"https://arxiv.org/pdf/2406.18781v1.pdf","comment":"International Conference on Machine Learning"},{"id":"http://arxiv.org/abs/2406.18777v1","updated":"2024-06-26T22:24:46Z","published":"2024-06-26T22:24:46Z","title":"Aligning Model Properties via Conformal Risk Control","summary":"  AI model alignment is crucial due to inadvertent biases in training data and\nthe underspecified pipeline in modern machine learning, where numerous models\nwith excellent test set metrics can be produced, yet they may not meet end-user\nrequirements. Recent advances demonstrate that post-training model alignment\nvia human feedback can address some of these challenges. However, these methods\nare often confined to settings (such as generative AI) where humans can\ninterpret model outputs and provide feedback. In traditional non-generative\nsettings, where model outputs are numerical values or classes, detecting\nmisalignment through single-sample outputs is highly challenging.\n  In this paper we consider an alternative strategy. We propose interpreting\nmodel alignment through property testing, defining an aligned model $f$ as one\nbelonging to a subset $\\mathcal{P}$ of functions that exhibit specific desired\nbehaviors. We focus on post-processing a pre-trained model $f$ to better align\nwith $\\mathcal{P}$ using conformal risk control. Specifically, we develop a\ngeneral procedure for converting queries for a given property $\\mathcal{P}$ to\na collection of loss functions suitable for use in a conformal risk control\nalgorithm. We prove a probabilistic guarantee that the resulting conformal\ninterval around $f$ contains a function approximately satisfying $\\mathcal{P}$.\n  Given the capabilities of modern AI models with extensive parameters and\ntraining data, one might assume alignment issues will resolve naturally.\nHowever, increasing training data or parameters in a random feature model\ndoesn't eliminate the need for alignment techniques when pre-training data is\nbiased. We demonstrate our alignment methodology on supervised learning\ndatasets for properties like monotonicity and concavity. Our flexible procedure\ncan be applied to various desired properties.\n","authors":["William Overman","Jacqueline Jil Vallon","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2406.18777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14815v2","updated":"2024-06-26T22:23:23Z","published":"2024-06-21T01:32:03Z","title":"Latent diffusion models for parameterization and data assimilation of\n  facies-based geomodels","summary":"  Geological parameterization entails the representation of a geomodel using a\nsmall set of latent variables and a mapping from these variables to grid-block\nproperties such as porosity and permeability. Parameterization is useful for\ndata assimilation (history matching), as it maintains geological realism while\nreducing the number of variables to be determined. Diffusion models are a new\nclass of generative deep-learning procedures that have been shown to outperform\nprevious methods, such as generative adversarial networks, for image generation\ntasks. Diffusion models are trained to \"denoise\", which enables them to\ngenerate new geological realizations from input fields characterized by random\nnoise. Latent diffusion models, which are the specific variant considered in\nthis study, provide dimension reduction through use of a low-dimensional latent\nvariable. The model developed in this work includes a variational autoencoder\nfor dimension reduction and a U-net for the denoising process. Our application\ninvolves conditional 2D three-facies (channel-levee-mud) systems. The latent\ndiffusion model is shown to provide realizations that are visually consistent\nwith samples from geomodeling software. Quantitative metrics involving spatial\nand flow-response statistics are evaluated, and general agreement between the\ndiffusion-generated models and reference realizations is observed. Stability\ntests are performed to assess the smoothness of the parameterization method.\nThe latent diffusion model is then used for ensemble-based data assimilation.\nTwo synthetic \"true\" models are considered. Significant uncertainty reduction,\nposterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and\nconsistent posterior geomodels, are achieved in both cases.\n","authors":["Guido Di Federico","Louis J. Durlofsky"],"pdf_url":"https://arxiv.org/pdf/2406.14815v2.pdf","comment":"- Moved Table 1 from before to after Section 4.2 heading - Renamed\n  output pdf file with paper title"},{"id":"http://arxiv.org/abs/2308.05239v2","updated":"2024-06-26T22:09:04Z","published":"2023-08-09T21:54:34Z","title":"Machine Learning-Enabled Software and System Architecture Frameworks","summary":"  Various architecture frameworks for software, systems, and enterprises have\nbeen proposed in the literature. They identified several stakeholders and\ndefined modeling perspectives, architecture viewpoints, and views to frame and\naddress stakeholder concerns. However, the stakeholders with data science and\nMachine Learning (ML) related concerns, such as data scientists and data\nengineers, are yet to be included in existing architecture frameworks. Only\nthis way can we envision a holistic system architecture description of an\nML-enabled system. Note that the ML component behavior and functionalities are\nspecial and should be distinguished from traditional software system behavior\nand functionalities. The main reason is that the actual functionality should be\ninferred from data instead of being specified at design time. Additionally, the\nstructural models of ML components, such as ML model architectures, are\ntypically specified using different notations and formalisms from what the\nSoftware Engineering (SE) community uses for software structural models. Yet,\nthese two aspects, namely ML and non-ML, are becoming so intertwined that it\nnecessitates an extension of software architecture frameworks and modeling\npractices toward supporting ML-enabled system architectures. In this paper, we\naddress this gap through an empirical study using an online survey instrument.\nWe surveyed 61 subject matter experts from over 25 organizations in 10\ncountries.\n","authors":["Armin Moin","Atta Badii","Stephan Günnemann","Moharram Challenger"],"pdf_url":"https://arxiv.org/pdf/2308.05239v2.pdf","comment":"Journal manuscript"},{"id":"http://arxiv.org/abs/2305.11957v2","updated":"2024-06-26T21:52:52Z","published":"2023-05-19T18:41:17Z","title":"Towards understanding neural collapse in supervised contrastive learning\n  with the information bottleneck method","summary":"  Neural collapse describes the geometry of activation in the final layer of a\ndeep neural network when it is trained beyond performance plateaus. Open\nquestions include whether neural collapse leads to better generalization and,\nif so, why and how training beyond the plateau helps. We model neural collapse\nas an information bottleneck (IB) problem in order to investigate whether such\na compact representation exists and discover its connection to generalization.\nWe demonstrate that neural collapse leads to good generalization specifically\nwhen it approaches an optimal IB solution of the classification problem. Recent\nresearch has shown that two deep neural networks independently trained with the\nsame contrastive loss objective are linearly identifiable, meaning that the\nresulting representations are equivalent up to a matrix transformation. We\nleverage linear identifiability to approximate an analytical solution of the IB\nproblem. This approximation demonstrates that when class means exhibit\n$K$-simplex Equiangular Tight Frame (ETF) behavior (e.g., $K$=10 for CIFAR10\nand $K$=100 for CIFAR100), they coincide with the critical phase transitions of\nthe corresponding IB problem. The performance plateau occurs once the optimal\nsolution for the IB problem includes all of these phase transitions. We also\nshow that the resulting $K$-simplex ETF can be packed into a $K$-dimensional\nGaussian distribution using supervised contrastive learning with a ResNet50\nbackbone. This geometry suggests that the $K$-simplex ETF learned by supervised\ncontrastive learning approximates the optimal features for source coding.\nHence, there is a direct correspondence between optimal IB solutions and\ngeneralization in contrastive learning.\n","authors":["Siwei Wang","Stephanie E Palmer"],"pdf_url":"https://arxiv.org/pdf/2305.11957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18770v1","updated":"2024-06-26T21:42:50Z","published":"2024-06-26T21:42:50Z","title":"ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of\n  Large Language Models","summary":"  Analog circuit design requires substantial human expertise and involvement,\nwhich is a significant roadblock to design productivity. Bayesian Optimization\n(BO), a popular machine learning based optimization strategy, has been\nleveraged to automate analog design given its applicability across various\ncircuit topologies and technologies. Traditional BO methods employ black box\nGaussian Process surrogate models and optimized labeled data queries to find\noptimization solutions by trading off between exploration and exploitation.\nHowever, the search for the optimal design solution in BO can be expensive from\nboth a computational and data usage point of view, particularly for high\ndimensional optimization problems. This paper presents ADO-LLM, the first work\nintegrating large language models (LLMs) with Bayesian Optimization for analog\ndesign optimization. ADO-LLM leverages the LLM's ability to infuse domain\nknowledge to rapidly generate viable design points to remedy BO's inefficiency\nin finding high value design areas specifically under the limited design space\ncoverage of the BO's probabilistic surrogate model. In the meantime, sampling\nof design points evaluated in the iterative BO process provides quality\ndemonstrations for the LLM to generate high quality design points while\nleveraging infused broad design knowledge. Furthermore, the diversity brought\nby BO's exploration enriches the contextual understanding of the LLM and allows\nit to more broadly search in the design space and prevent repetitive and\nredundant suggestions. We evaluate the proposed framework on two different\ntypes of analog circuits and demonstrate notable improvements in design\nefficiency and effectiveness.\n","authors":["Yuxuan Yin","Yu Wang","Boxun Xu","Peng Li"],"pdf_url":"https://arxiv.org/pdf/2406.18770v1.pdf","comment":"8 pages, 3 figures"}],"Robotics":[{"id":"http://arxiv.org/abs/2306.13928v2","updated":"2024-06-26T17:59:37Z","published":"2023-06-24T10:25:53Z","title":"On Convex Data-Driven Inverse Optimal Control for Nonlinear,\n  Non-stationary and Stochastic Systems","summary":"  This paper is concerned with a finite-horizon inverse control problem, which\nhas the goal of reconstructing, from observations, the possibly non-convex and\nnon-stationary cost driving the actions of an agent. In this context, we\npresent a result enabling cost reconstruction by solving an optimization\nproblem that is convex even when the agent cost is not and when the underlying\ndynamics is nonlinear, non-stationary and stochastic. To obtain this result, we\nalso study a finite-horizon forward control problem that has randomized\npolicies as decision variables. We turn our findings into algorithmic\nprocedures and show the effectiveness of our approach via in-silico and\nhardware validations. All experiments confirm the effectiveness of our\napproach.\n","authors":["Emiland Garrabe","Hozefa Jesawada","Carmen Del Vecchio","Giovanni Russo"],"pdf_url":"https://arxiv.org/pdf/2306.13928v2.pdf","comment":"17 pages, 5 figures. An early version of this paper with only a\n  sketch of the proof for one of the results and without the hardware\n  validation was presentation at the 62nd IEEE Conference on Decision and\n  Control. arXiv admin note: text overlap with arXiv:2303.17957"},{"id":"http://arxiv.org/abs/2311.01248v3","updated":"2024-06-26T17:40:14Z","published":"2023-11-02T14:02:42Z","title":"Multimodal and Force-Matched Imitation Learning with a See-Through\n  Visuotactile Sensor","summary":"  Contact-rich tasks continue to present a variety of challenges for robotic\nmanipulation. In this work, we leverage a multimodal visuotactile sensor within\nthe framework of imitation learning (IL) to perform contact rich tasks that\ninvolve relative motion (slipping/sliding) between the end-effector and object.\nWe introduce two algorithmic contributions, tactile force matching and learned\nmode switching, as complimentary methods for improving IL. Tactile force\nmatching enhances kinesthetic teaching by reading approximate forces during the\ndemonstration and generating an adapted robot trajectory that recreates the\nrecorded forces. Learned mode switching uses IL to couple visual and tactile\nsensor modes with the learned motion policy, simplifying the transition from\nreaching to contacting. We perform robotic manipulation experiments on four\ndoor opening tasks with a variety of observation and method configurations to\nstudy the utility of our proposed improvements and multimodal visuotactile\nsensing. Our results show that the inclusion of force matching raises average\npolicy success rates by 62.5%, visuotactile mode switching by 30.3%, and\nvisuotactile data as a policy input by 42.5%, emphasizing the value of\nsee-through tactile sensing for IL, both for data collection to allow force\nmatching, and for policy execution to allow accurate task feedback.\n","authors":["Trevor Ablett","Oliver Limoyo","Adam Sigal","Affan Jilani","Jonathan Kelly","Kaleem Siddiqi","Francois Hogan","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2311.01248v3.pdf","comment":"Submitted to IEEE Transactions on Robotics (T-RO): Special Section on\n  Tactile Robotics"},{"id":"http://arxiv.org/abs/2406.18505v1","updated":"2024-06-26T17:14:45Z","published":"2024-06-26T17:14:45Z","title":"Mental Modeling of Reinforcement Learning Agents by Language Models","summary":"  Can emergent language models faithfully model the intelligence of\ndecision-making agents? Though modern language models exhibit already some\nreasoning ability, and theoretically can potentially express any probable\ndistribution over tokens, it remains underexplored how the world knowledge\nthese pretrained models have memorized can be utilized to comprehend an agent's\nbehaviour in the physical world. This study empirically examines, for the first\ntime, how well large language models (LLMs) can build a mental model of agents,\ntermed agent mental modelling, by reasoning about an agent's behaviour and its\neffect on states from agent interaction history. This research may unveil the\npotential of leveraging LLMs for elucidating RL agent behaviour, addressing a\nkey challenge in eXplainable reinforcement learning (XRL). To this end, we\npropose specific evaluation metrics and test them on selected RL task datasets\nof varying complexity, reporting findings on agent mental model establishment.\nOur results disclose that LLMs are not yet capable of fully mental modelling\nagents through inference alone without further innovations. This work thus\nprovides new insights into the capabilities and limitations of modern LLMs.\n","authors":["Wenhao Lu","Xufeng Zhao","Josua Spisak","Jae Hee Lee","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2406.18505v1.pdf","comment":"https://lukaswill.github.io/"},{"id":"http://arxiv.org/abs/2406.18452v1","updated":"2024-06-26T16:01:00Z","published":"2024-06-26T16:01:00Z","title":"Optimal Multi-Robot Communication-Aware Trajectory Planning by\n  Constraining the Fiedler Value","summary":"  The paper present a novel approach for the solution of the Multi-Robot\nCommunication-Aware Trajectory Planning, which builds on a general optimisation\nframework where the changes in robots positions are used as decision variable,\nand linear constraints on the trajectories of the robots are introduced to\nensure communication performance and collision avoidance. The Fiedler value is\nadopted as communication performance metric. The validity of the method in\ncomputing both feasible and optimal trajectories for the robots is demonstrated\nboth in simulation and experimentally. Results show that the constraint on the\nFiedler value ensures that the robot network fulfils its objective while\nmaintaining communication connectivity at all times. Further, the paper shows\nthat the introduction of approximations for the constraints enables a\nsignificant improvement in the computational time of the solution, which remain\nvery close to the optimal solution.\n","authors":["Jeppe Heini Mikkelsen","Roberto Galeazzi","Matteo Fumagalli"],"pdf_url":"https://arxiv.org/pdf/2406.18452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16478v2","updated":"2024-06-26T15:41:14Z","published":"2024-03-25T07:04:24Z","title":"Comparison of two Cooperative Maneuver Planning Approaches at a\n  Real-World T-Junction","summary":"  Connected automated driving promises a significant improvement of traffic\nefficiency and safety on highways and in urban areas. Cooperative maneuver\nplanning may facilitate active guidance of connected automated vehicles at\nintersections. Research in automatic intersection management put forth a large\nbody of works that mostly employ rule-based or optimization-based approaches\nprimarily in fully automated simulated environments. In this work, we compare\ntwo cooperative planning approaches for unsignalized intersections that are\ncapable of handling mixed traffic, i.e., the road being shared by automated\nvehicles and regular vehicles driven by humans. The first approach is a\ncooperative planner that selects the most efficient out of multiple possible\nmaneuvers based on a scene prediction trained on real driving data. The second\ncooperative planning approach is based on graph-based reinforcement learning,\nwhich conquers the lack of ground truth data for cooperative maneuvers. We\nthoroughly evaluate both cooperative planners in a realistic high-fidelity\nsimulation with fully automated traffic and mixed traffic. The simulative\nexperiments show that cooperative maneuver planning leads to less delay due to\ninteraction and a reduced number of stops. Furthermore, we present results from\nreal-world experiments with three prototype automated vehicles at a T-junction\nin public traffic, in which both planning modules demonstrate their ability to\nperform efficient cooperative maneuvers.\n","authors":["Marvin Klimke","Max Bastian Mertens","Benjamin Völz","Michael Buchholz"],"pdf_url":"https://arxiv.org/pdf/2403.16478v2.pdf","comment":"M. Klimke and M. B. Mertens are both first authors with equal\n  contribution. 12 pages, 11 figures, 2 tables, submitted to IEEE Open Journal\n  of Intelligent Transportation Systems"},{"id":"http://arxiv.org/abs/2406.18412v1","updated":"2024-06-26T15:08:26Z","published":"2024-06-26T15:08:26Z","title":"Sensorless model-based tension control for a cable-driven exosuit","summary":"  Cable-driven exosuits have the potential to support individuals with motor\ndisabilities across the continuum of care. When supporting a limb with a cable,\nforce sensors are often used to measure tension. However, force sensors add\ncost, complexity, and distal components. This paper presents a design and\ncontrol approach to remove the force sensor from an upper limb cable-driven\nexosuit. A mechanical design for the exosuit was developed to maximize passive\ntransparency. Then, a data-driven friction identification was conducted on a\nmannequin test bench to design a model-based tension controller. Seventeen\nhealthy participants raised and lowered their right arms to evaluate tension\ntracking, movement quality, and muscular effort. Questionnaires on discomfort,\nphysical exertion, and fatigue were collected. The proposed strategy allowed\ntracking the desired assistive torque with an RMSE of 0.71 Nm (18%) at 50%\ngravity support. During the raising phase, the EMG signals of the anterior\ndeltoid, trapezius, and pectoralis major were reduced on average compared to\nthe no-suit condition by 30%, 38%, and 38%, respectively. The posterior deltoid\nactivity was increased by 32% during lowering. Position tracking was not\nsignificantly altered, whereas movement smoothness significantly decreased.\nThis work demonstrates the feasibility and effectiveness of removing the force\nsensor from a cable-driven exosuit. A significant increase in discomfort in the\nlower neck and right shoulder indicated that the ergonomics of the suit could\nbe improved. Overall this work paves the way towards simpler and more\naffordable exosuits.\n","authors":["Elena Bardi","Adrian Esser","Peter Wolf","Marta Gandolla","Emilia Ambrosini","Alessandra Pedrocchi","Robert Riener"],"pdf_url":"https://arxiv.org/pdf/2406.18412v1.pdf","comment":"19 pages, 10 figures, and 3 tables in the main manuscript. 12 pages,\n  4 figures, and 13 tables in the supplementary materials"},{"id":"http://arxiv.org/abs/2406.18388v1","updated":"2024-06-26T14:30:51Z","published":"2024-06-26T14:30:51Z","title":"SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and\n  Real-time Hysteresis Compensation Control Algorithm","summary":"  Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via\nnatural orifices and improve target lesion accessibility through curved paths.\nHowever, CDCMs face limitations in workspace and control accuracy due to\nnon-linear cable effects causing hysteresis. This paper introduces an\nextensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via\ntranslational motion without additional mechanical elements or actuation. We\ncollect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Based\non this dataset, we develop a real-time hysteresis compensation control\nalgorithm using the trained Temporal Convolutional Network (TCN) with a 1ms\ntime latency, effectively estimating the manipulator's hysteresis behavior.\nPerformance validation through random trajectory tracking tests and box\npointing tasks shows the proposed controller significantly reduces hysteresis\nby up to 69.5% in joint space and approximately 26% in the box pointing task.\n","authors":["Junhyun Park","Seonghyeok Jang","Myeongbo Park","Hyojae Park","Jeonghyeon Yoon","Minho Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.18388v1.pdf","comment":"12 pages, 14 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.18381v1","updated":"2024-06-26T14:24:07Z","published":"2024-06-26T14:24:07Z","title":"Robotic Exploration through Semantic Topometric Mapping","summary":"  In this article, we introduce a novel strategy for robotic exploration in\nunknown environments using a semantic topometric map. As it will be presented,\nthe semantic topometric map is generated by segmenting the grid map of the\ncurrently explored parts of the environment into regions, such as\nintersections, pathways, dead-ends, and unexplored frontiers, which constitute\nthe structural semantics of an environment. The proposed exploration strategy\nleverages metric information of the frontier, such as distance and angle to the\nfrontier, similar to existing frameworks, with the key difference being the\nadditional utilization of structural semantic information, such as properties\nof the intersections leading to frontiers. The algorithm for generating\nsemantic topometric mapping utilized by the proposed method is lightweight,\nresulting in the method's online execution being both rapid and computationally\nefficient. Moreover, the proposed framework can be applied to both structured\nand unstructured indoor and outdoor environments, which enhances the\nversatility of the proposed exploration algorithm. We validate our exploration\nstrategy and demonstrate the utility of structural semantics in exploration in\ntwo complex indoor environments by utilizing a Turtlebot3 as the robotic agent.\nCompared to traditional frontier-based methods, our findings indicate that the\nproposed approach leads to faster exploration and requires less computation\ntime.\n","authors":["Scott Fredriksson","Akshit Saradagi","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.18381v1.pdf","comment":"Accepted to ICRA 24"},{"id":"http://arxiv.org/abs/2306.10376v6","updated":"2024-06-26T12:39:36Z","published":"2023-06-17T15:24:54Z","title":"CLARA: Classifying and Disambiguating User Commands for Reliable\n  Interactive Robotic Agents","summary":"  In this paper, we focus on inferring whether the given user command is clear,\nambiguous, or infeasible in the context of interactive robotic agents utilizing\nlarge language models (LLMs). To tackle this problem, we first present an\nuncertainty estimation method for LLMs to classify whether the command is\ncertain (i.e., clear) or not (i.e., ambiguous or infeasible). Once the command\nis classified as uncertain, we further distinguish it between ambiguous or\ninfeasible commands leveraging LLMs with situational aware context in a\nzero-shot manner. For ambiguous commands, we disambiguate the command by\ninteracting with users via question generation with LLMs. We believe that\nproper recognition of the given commands could lead to a decrease in\nmalfunction and undesired actions of the robot, enhancing the reliability of\ninteractive robot agents. We present a dataset for robotic situational\nawareness, consisting pair of high-level commands, scene descriptions, and\nlabels of command type (i.e., clear, ambiguous, or infeasible). We validate the\nproposed method on the collected dataset, pick-and-place tabletop simulation.\nFinally, we demonstrate the proposed approach in real-world human-robot\ninteraction experiments, i.e., handover scenarios.\n","authors":["Jeongeun Park","Seungwon Lim","Joonhyung Lee","Sangbeom Park","Minsuk Chang","Youngjae Yu","Sungjoon Choi"],"pdf_url":"https://arxiv.org/pdf/2306.10376v6.pdf","comment":"Project Page: https://clararobot.github.io/"},{"id":"http://arxiv.org/abs/2406.18285v1","updated":"2024-06-26T12:12:37Z","published":"2024-06-26T12:12:37Z","title":"LLCoach: Generating Robot Soccer Plans using Multi-Role Large Language\n  Models","summary":"  The deployment of robots into human scenarios necessitates advanced planning\nstrategies, particularly when we ask robots to operate in dynamic, unstructured\nenvironments. RoboCup offers the chance to deploy robots in one of those\nscenarios, a human-shaped game represented by a soccer match. In such\nscenarios, robots must operate using predefined behaviors that can fail in\nunpredictable conditions. This paper introduces a novel application of Large\nLanguage Models (LLMs) to address the challenge of generating actionable plans\nin such settings, specifically within the context of the RoboCup Standard\nPlatform League (SPL) competitions where robots are required to autonomously\nexecute soccer strategies that emerge from the interactions of individual\nagents. In particular, we propose a multi-role approach leveraging the\ncapabilities of LLMs to generate and refine plans for a robotic soccer team.\nThe potential of the proposed method is demonstrated through an experimental\nevaluation,carried out simulating multiple matches where robots with\nAI-generated plans play against robots running human-built code.\n","authors":["Michele Brienza","Emanuele Musumeci","Vincenzo Suriani","Daniele Affinita","Andrea Pennisi","Daniele Nardi","Domenico Daniele Bloisi"],"pdf_url":"https://arxiv.org/pdf/2406.18285v1.pdf","comment":"Accepted at 27th RoboCup International Symposium will be held on 22\n  July 2024, in Eindhoven, The Netherlands"},{"id":"http://arxiv.org/abs/2406.18237v1","updated":"2024-06-26T10:41:07Z","published":"2024-06-26T10:41:07Z","title":"PlaMo: Plan and Move in Rich 3D Physical Environments","summary":"  Controlling humanoids in complex physically simulated worlds is a\nlong-standing challenge with numerous applications in gaming, simulation, and\nvisual content creation. In our setup, given a rich and complex 3D scene, the\nuser provides a list of instructions composed of target locations and\nlocomotion types. To solve this task we present PlaMo, a scene-aware path\nplanner and a robust physics-based controller. The path planner produces a\nsequence of motion paths, considering the various limitations the scene imposes\non the motion, such as location, height, and speed. Complementing the planner,\nour control policy generates rich and realistic physical motion adhering to the\nplan. We demonstrate how the combination of both modules enables traversing\ncomplex landscapes in diverse forms while responding to real-time changes in\nthe environment. Video: https://youtu.be/wWlqSQlRZ9M .\n","authors":["Assaf Hallak","Gal Dalal","Chen Tessler","Kelly Guo","Shie Mannor","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2406.18237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18229v1","updated":"2024-06-26T10:25:41Z","published":"2024-06-26T10:25:41Z","title":"Advancing Robotic Surgery: Affordable Kinesthetic and Tactile Feedback\n  Solutions for Endotrainers","summary":"  The proliferation of robot-assisted minimally invasive surgery highlights the\nneed for advanced training tools such as cost-effective robotic endotrainers.\nCurrent surgical robots often lack haptic feedback, which is crucial for\nproviding surgeons with a real-time sense of touch. This absence can impact the\nsurgeon's ability to perform delicate operations effectively. To enhance\nsurgical training and address this deficiency, we have integrated a\ncost-effective haptic feedback system into a robotic endotrainer. This system\nincorporates both kinesthetic (force) and tactile feedback, improving the\nfidelity of surgical simulations and enabling more precise control during\noperations. Our system incorporates an innovative, cost-effective Force/Torque\nsensor utilizing optoelectronic technology, specifically designed to accurately\ndetect forces and moments exerted on surgical tools with a 95% accuracy,\nproviding essential kinesthetic feedback. Additionally, we implemented a\ntactile feedback mechanism that informs the surgeon of the gripping forces\nbetween the tool's tip and the tissue. This dual feedback system enhances the\nfidelity of training simulations and the execution of robotic surgeries,\npromoting broader adoption and safer practices.\n","authors":["Bharath Rajiv Nair","Aravinthkumar T.","B. Vinod"],"pdf_url":"https://arxiv.org/pdf/2406.18229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02000v3","updated":"2024-06-26T10:17:08Z","published":"2022-09-05T14:57:03Z","title":"Visual Odometry with Neuromorphic Resonator Networks","summary":"  Visual Odometry (VO) is a method to estimate self-motion of a mobile robot\nusing visual sensors. Unlike odometry based on integrating differential\nmeasurements that can accumulate errors, such as inertial sensors or wheel\nencoders, visual odometry is not compromised by drift. However, image-based VO\nis computationally demanding, limiting its application in use cases with\nlow-latency, -memory, and -energy requirements. Neuromorphic hardware offers\nlow-power solutions to many vision and AI problems, but designing such\nsolutions is complicated and often has to be assembled from scratch. Here we\npropose to use Vector Symbolic Architecture (VSA) as an abstraction layer to\ndesign algorithms compatible with neuromorphic hardware. Building from a VSA\nmodel for scene analysis, described in our companion paper, we present a\nmodular neuromorphic algorithm that achieves state-of-the-art performance on\ntwo-dimensional VO tasks. Specifically, the proposed algorithm stores and\nupdates a working memory of the presented visual environment. Based on this\nworking memory, a resonator network estimates the changing location and\norientation of the camera. We experimentally validate the neuromorphic\nVSA-based approach to VO with two benchmarks: one based on an event camera\ndataset and the other in a dynamic scene with a robotic task.\n","authors":["Alpha Renner","Lazar Supic","Andreea Danielescu","Giacomo Indiveri","E. Paxon Frady","Friedrich T. Sommer","Yulia Sandamirskaya"],"pdf_url":"https://arxiv.org/pdf/2209.02000v3.pdf","comment":"19 pages, 5 figures, minor revisions, added results for\n  shapes_translation dataset"},{"id":"http://arxiv.org/abs/2406.18162v1","updated":"2024-06-26T08:23:13Z","published":"2024-06-26T08:23:13Z","title":"Multimodal Reaching-Position Prediction for ADL Support Using Neural\n  Networks","summary":"  This study aimed to develop daily living support robots for patients with\nhemiplegia and the elderly. To support the daily living activities using robots\nin ordinary households without imposing physical and mental burdens on users,\nthe system must detect the actions of the user and move appropriately according\nto their motions.\n  We propose a reaching-position prediction scheme that targets the motion of\nlifting the upper arm, which is burdensome for patients with hemiplegia and the\nelderly in daily living activities.\n  For this motion, it is difficult to obtain effective features to create a\nprediction model in environments where large-scale sensor system installation\nis not feasible and the motion time is short.\n  We performed motion-collection experiments, revealed the features of the\ntarget motion and built a prediction model using the multimodal motion features\nand deep learning.\n  The proposed model achieved an accuracy of 93 \\% macro average and F1-score\nof 0.69 for a 9-class classification prediction at 35\\% of the motion\ncompletion.\n","authors":["Yutaka Takase","Kimitoshi Yamazaki"],"pdf_url":"https://arxiv.org/pdf/2406.18162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18158v1","updated":"2024-06-26T08:17:59Z","published":"2024-06-26T08:17:59Z","title":"3D-MVP: 3D Multiview Pretraining for Robotic Manipulation","summary":"  Recent works have shown that visual pretraining on egocentric datasets using\nmasked autoencoders (MAE) can improve generalization for downstream robotics\ntasks. However, these approaches pretrain only on 2D images, while many\nrobotics applications require 3D scene understanding. In this work, we propose\n3D-MVP, a novel approach for 3D multi-view pretraining using masked\nautoencoders. We leverage Robotic View Transformer (RVT), which uses a\nmulti-view transformer to understand the 3D scene and predict gripper pose\nactions. We split RVT's multi-view transformer into visual encoder and action\ndecoder, and pretrain its visual encoder using masked autoencoding on\nlarge-scale 3D datasets such as Objaverse. We evaluate 3D-MVP on a suite of\nvirtual robot manipulation tasks and demonstrate improved performance over\nbaselines. We also show promising results on a real robot platform with minimal\nfinetuning. Our results suggest that 3D-aware pretraining is a promising\napproach to improve sample efficiency and generalization of vision-based\nrobotic manipulation policies. We will release code and pretrained models for\n3D-MVP to facilitate future research. Project site:\nhttps://jasonqsy.github.io/3DMVP\n","authors":["Shengyi Qian","Kaichun Mo","Valts Blukis","David F. Fouhey","Dieter Fox","Ankit Goyal"],"pdf_url":"https://arxiv.org/pdf/2406.18158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18138v1","updated":"2024-06-26T07:43:38Z","published":"2024-06-26T07:43:38Z","title":"B-TMS: Bayesian Traversable Terrain Modeling and Segmentation Across 3D\n  LiDAR Scans and Maps for Enhanced Off-Road Navigation","summary":"  Recognizing traversable terrain from 3D point cloud data is critical, as it\ndirectly impacts the performance of autonomous navigation in off-road\nenvironments. However, existing segmentation algorithms often struggle with\nchallenges related to changes in data distribution, environmental specificity,\nand sensor variations. Moreover, when encountering sunken areas, their\nperformance is frequently compromised, and they may even fail to recognize\nthem. To address these challenges, we introduce B-TMS, a novel approach that\nperforms map-wise terrain modeling and segmentation by utilizing Bayesian\ngeneralized kernel (BGK) within the graph structure known as the tri-grid field\n(TGF). Our experiments encompass various data distributions, ranging from\nsingle scans to partial maps, utilizing both public datasets representing urban\nscenes and off-road environments, and our own dataset acquired from extremely\nbumpy terrains. Our results demonstrate notable contributions, particularly in\nterms of robustness to data distribution variations, adaptability to diverse\nenvironmental conditions, and resilience against the challenges associated with\nparameter changes.\n","authors":["Minho Oh","Gunhee Shin","Seoyeon Jang","Seungjae Lee","Dongkyu Lee","Wonho Song","Byeongho Yu","Hyungtae Lim","Jaeyoung Lee","Hyun Myung"],"pdf_url":"https://arxiv.org/pdf/2406.18138v1.pdf","comment":"Accepted by IEEE IV'24 workshop on Off-road autonomy"},{"id":"http://arxiv.org/abs/2406.18115v1","updated":"2024-06-26T07:06:42Z","published":"2024-06-26T07:06:42Z","title":"Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with\n  3D Semantic Maps","summary":"  Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for\nautonomous robots, especially when faced with the challenges posed by unknown\nand dynamic environments. This task requires robots to explore and build a\nsemantic understanding of their surroundings, generate feasible plans to\nachieve manipulation goals, adapt to environmental changes, and comprehend\nnatural language instructions from humans. To address these challenges, we\npropose a novel framework that leverages the zero-shot detection and grounded\nrecognition capabilities of pretraining visual-language models (VLMs) combined\nwith dense 3D entity reconstruction to build 3D semantic maps. Additionally, we\nutilize large language models (LLMs) for spatial region abstraction and online\nplanning, incorporating human instructions and spatial semantic context. We\nhave built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated\nin real-world robot experiments that our proposed framework can effectively\ncapture spatial semantics and process natural language user instructions for\nzero-shot OVMM tasks under dynamic environment settings, with an overall\nnavigation and task success rate of 80.95% and 73.33% over 105 episodes, and\nbetter SFT and SPL by 157.18% and 19.53% respectively compared to the baseline.\nFurthermore, the framework is capable of replanning towards the next most\nprobable candidate location based on the spatial semantic context derived from\nthe 3D semantic map when initial plans fail, keeping an average success rate of\n76.67%.\n","authors":["Dicong Qiu","Wenzong Ma","Zhenfu Pan","Hui Xiong","Junwei Liang"],"pdf_url":"https://arxiv.org/pdf/2406.18115v1.pdf","comment":"Open-vocabulary, Mobile Manipulation, Dynamic Environments, 3D\n  Semantic Maps, Zero-shot, LLMs, VLMs, 18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2203.03224v5","updated":"2024-06-26T05:53:56Z","published":"2022-03-07T09:23:03Z","title":"Factor Graph-Based Planning as Inference for Autonomous Vehicle Racing","summary":"  Factor graph, as a bipartite graphical model, offers a structured\nrepresentation by revealing local connections among graph nodes. This study\nexplores the utilization of factor graphs in modeling the autonomous racecar\nplanning problem, presenting an alternate perspective to the traditional\noptimization-based formulation. We model the planning problem as a\nprobabilistic inference over a factor graph, with factor nodes capturing the\njoint distribution of motion objectives. By leveraging the duality between\noptimization and inference, a fast solution to the maximum a posteriori\nestimation of the factor graph is obtained via least-squares optimization. The\nlocalized design thinking inherent in this formulation ensures that motion\nobjectives depend on a small subset of variables. We exploit the locality\nfeature of the factor graph structure to integrate the minimum curvature path\nand local planning computations into a unified algorithm. This diverges from\nthe conventional separation of global and local planning modules, where\ncurvature minimization occurs at the global level. The evaluation of the\nproposed framework demonstrated superior performance for cumulative curvature\nand average speed across the racetrack. Furthermore, the results highlight the\ncomputational efficiency of our approach. While acknowledging the structural\ndesign advantages and computational efficiency of the proposed methodology, we\nalso address its limitations and outline potential directions for future\nresearch.\n","authors":["Salman Bari","Xiagong Wang","Ahmad Schoha Haidari","Dirk Wollherr"],"pdf_url":"https://arxiv.org/pdf/2203.03224v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18043v1","updated":"2024-06-26T03:41:48Z","published":"2024-06-26T03:41:48Z","title":"Multimodal foundation world models for generalist embodied agents","summary":"  Learning generalist embodied agents, able to solve multitudes of tasks in\ndifferent domains is a long-standing problem. Reinforcement learning (RL) is\nhard to scale up as it requires a complex reward design for each task. In\ncontrast, language can specify tasks in a more natural way. Current foundation\nvision-language models (VLMs) generally require fine-tuning or other\nadaptations to be functional, due to the significant domain gap. However, the\nlack of multimodal data in such domains represents an obstacle toward\ndeveloping foundation models for embodied applications. In this work, we\novercome these problems by presenting multimodal foundation world models, able\nto connect and align the representation of foundation VLMs with the latent\nspace of generative world models for RL, without any language annotations. The\nresulting agent learning framework, GenRL, allows one to specify tasks through\nvision and/or language prompts, ground them in the embodied domain's dynamics,\nand learns the corresponding behaviors in imagination. As assessed through\nlarge-scale multi-task benchmarking, GenRL exhibits strong multi-task\ngeneralization performance in several locomotion and manipulation domains.\nFurthermore, by introducing a data-free RL strategy, it lays the groundwork for\nfoundation model-based RL for generalist embodied agents.\n","authors":["Pietro Mazzaglia","Tim Verbelen","Bart Dhoedt","Aaron Courville","Sai Rajeswar"],"pdf_url":"https://arxiv.org/pdf/2406.18043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18019v1","updated":"2024-06-26T02:13:02Z","published":"2024-06-26T02:13:02Z","title":"Continuous Execution of High-Level Collaborative Tasks for Heterogeneous\n  Robot Teams","summary":"  We propose a control synthesis framework for a heterogeneous multi-robot\nsystem to satisfy collaborative tasks, where actions may take varying duration\nof time to complete. We encode tasks using the discrete logic LTL^\\psi, which\nuses the concept of bindings to interleave robot actions and express\ninformation about relationship between specific task requirements and robot\nassignments. We present a synthesis approach to automatically generate a\nteaming assignment and corresponding discrete behavior that is\ncorrect-by-construction for continuous execution, while also implementing\nsynchronization policies to ensure collaborative portions of the task are\nsatisfied. We demonstrate our approach on a physical multi-robot system.\n","authors":["Amy Fang","Tenny Yin","Jiawei Lin","Hadas Kress-Gazit"],"pdf_url":"https://arxiv.org/pdf/2406.18019v1.pdf","comment":"Under review in IEEE Transactions on Robotics"},{"id":"http://arxiv.org/abs/2406.18746v1","updated":"2024-06-26T20:25:30Z","published":"2024-06-26T20:25:30Z","title":"Lifelong Robot Library Learning: Bootstrapping Composable and\n  Generalizable Skills for Embodied Control with Language Models","summary":"  Large Language Models (LLMs) have emerged as a new paradigm for embodied\nreasoning and control, most recently by generating robot policy code that\nutilizes a custom library of vision and control primitive skills. However,\nprior arts fix their skills library and steer the LLM with carefully\nhand-crafted prompt engineering, limiting the agent to a stationary range of\naddressable tasks. In this work, we introduce LRLL, an LLM-based lifelong\nlearning agent that continuously grows the robot skill library to tackle\nmanipulation tasks of ever-growing complexity. LRLL achieves this with four\nnovel contributions: 1) a soft memory module that allows dynamic storage and\nretrieval of past experiences to serve as context, 2) a self-guided exploration\npolicy that proposes new tasks in simulation, 3) a skill abstractor that\ndistills recent experiences into new library skills, and 4) a lifelong learning\nalgorithm for enabling human users to bootstrap new skills with minimal online\ninteraction. LRLL continuously transfers knowledge from the memory to the\nlibrary, building composable, general and interpretable policies, while\nbypassing gradient-based optimization, thus relieving the learner from\ncatastrophic forgetting. Empirical evaluation in a simulated tabletop\nenvironment shows that LRLL outperforms end-to-end and vanilla LLM approaches\nin the lifelong setup while learning skills that are transferable to the real\nworld. Project material will become available at the webpage\nhttps://gtziafas.github.io/LRLL_project.\n","authors":["Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2406.18746v1.pdf","comment":"Published ICRA-24"},{"id":"http://arxiv.org/abs/2406.18742v1","updated":"2024-06-26T20:16:49Z","published":"2024-06-26T20:16:49Z","title":"3D Feature Distillation with Object-Centric Priors","summary":"  Grounding natural language to the physical world is a ubiquitous topic with a\nwide range of applications in computer vision and robotics. Recently, 2D\nvision-language models such as CLIP have been widely popularized, due to their\nimpressive capabilities for open-vocabulary grounding in 2D images. Recent\nworks aim to elevate 2D CLIP features to 3D via feature distillation, but\neither learn neural fields that are scene-specific and hence lack\ngeneralization, or focus on indoor room scan data that require access to\nmultiple camera views, which is not practical in robot manipulation scenarios.\nAdditionally, related methods typically fuse features at pixel-level and assume\nthat all camera views are equally informative. In this work, we show that this\napproach leads to sub-optimal 3D features, both in terms of grounding accuracy,\nas well as segmentation crispness. To alleviate this, we propose a multi-view\nfeature fusion strategy that employs object-centric priors to eliminate\nuninformative views based on semantic information, and fuse features at\nobject-level via instance segmentation masks. To distill our object-centric 3D\nfeatures, we generate a large-scale synthetic multi-view dataset of cluttered\ntabletop scenes, spawning 15k scenes from over 3300 unique object instances,\nwhich we make publicly available. We show that our method reconstructs 3D CLIP\nfeatures with improved grounding capacity and spatial consistency, while doing\nso from single-view RGB-D, thus departing from the assumption of multiple\ncamera views at test time. Finally, we show that our approach can generalize to\nnovel tabletop domains and be re-purposed for 3D instance segmentation without\nfine-tuning, and demonstrate its utility for language-guided robotic grasping\nin clutter\n","authors":["Georgios Tziafas","Yucheng Xu","Zhibin Li","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2406.18742v1.pdf","comment":"Submitted CoRL-24"},{"id":"http://arxiv.org/abs/2406.18722v1","updated":"2024-06-26T19:42:08Z","published":"2024-06-26T19:42:08Z","title":"Towards Open-World Grasping with Large Vision-Language Models","summary":"  The ability to grasp objects in-the-wild from open-ended language\ninstructions constitutes a fundamental challenge in robotics. An open-world\ngrasping system should be able to combine high-level contextual with low-level\nphysical-geometric reasoning in order to be applicable in arbitrary scenarios.\nRecent works exploit the web-scale knowledge inherent in large language models\n(LLMs) to plan and reason in robotic context, but rely on external vision and\naction models to ground such knowledge into the environment and parameterize\nactuation. This setup suffers from two major bottlenecks: a) the LLM's\nreasoning capacity is constrained by the quality of visual grounding, and b)\nLLMs do not contain low-level spatial understanding of the world, which is\nessential for grasping in contact-rich scenarios. In this work we demonstrate\nthat modern vision-language models (VLMs) are capable of tackling such\nlimitations, as they are implicitly grounded and can jointly reason about\nsemantics and geometry. We propose OWG, an open-world grasping pipeline that\ncombines VLMs with segmentation and grasp synthesis models to unlock grounded\nworld understanding in three stages: open-ended referring segmentation,\ngrounded grasp planning and grasp ranking via contact reasoning, all of which\ncan be applied zero-shot via suitable visual prompting mechanisms. We conduct\nextensive evaluation in cluttered indoor scene datasets to showcase OWG's\nrobustness in grounding from open-ended language, as well as open-world robotic\ngrasping experiments in both simulation and hardware that demonstrate superior\nperformance compared to previous supervised and zero-shot LLM-based methods.\n","authors":["Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2406.18722v1.pdf","comment":"Submitted CoRL24"},{"id":"http://arxiv.org/abs/2406.18699v1","updated":"2024-06-26T19:05:35Z","published":"2024-06-26T19:05:35Z","title":"From Pixels to Torques with Linear Feedback","summary":"  We demonstrate the effectiveness of simple observer-based linear feedback\npolicies for \"pixels-to-torques\" control of robotic systems using only a\nrobot-facing camera. Specifically, we show that the matrices of an image-based\nLuenberger observer (linear state estimator) for a \"student\" output-feedback\npolicy can be learned from demonstration data provided by a \"teacher\"\nstate-feedback policy via simple linear-least-squares regression. The resulting\nlinear output-feedback controller maps directly from high-dimensional raw\nimages to torques while being amenable to the rich set of analytical tools from\nlinear systems theory, alowing us to enforce closed-loop stability constraints\nin the learning problem. We also investigate a nonlinear extension of the\nmethod via the Koopman embedding. Finally, we demonstrate the surprising\neffectiveness of linear pixels-to-torques policies on a cartpole system, both\nin simulation and on real-world hardware. The policy successfully executes both\nstabilizing and swing-up trajectory tracking tasks using only camera feedback\nwhile subject to model mismatch, process and sensor noise, perturbations, and\nocclusions.\n","authors":["Jeong Hun Lee","Sam Schoedel","Aditya Bhardwaj","Zachary Manchester"],"pdf_url":"https://arxiv.org/pdf/2406.18699v1.pdf","comment":"Submitted to Workshop on Algorithmic Foundations of Robotics (WAFR)\n  2024"},{"id":"http://arxiv.org/abs/2104.08634v4","updated":"2024-06-26T18:23:48Z","published":"2021-04-17T19:42:10Z","title":"AeroTraj: Trajectory Planning for Fast, and Accurate 3D Reconstruction\n  Using a Drone-based LiDAR","summary":"  This paper presents AeroTraj, a system that enables fast, accurate, and\nautomated reconstruction of 3D models of large buildings using a drone-mounted\nLiDAR. LiDAR point clouds can be used directly to assemble 3D models if their\npositions are accurately determined. AeroTraj uses SLAM for this, but must\nensure complete and accurate reconstruction while minimizing drone battery\nusage. Doing this requires balancing competing constraints: drone speed,\nheight, and orientation. AeroTraj exploits building geometry in designing an\noptimal trajectory that incorporates these constraints. Even with an optimal\ntrajectory, SLAM's position error can drift over time, so AeroTraj tracks drift\nin-flight by offloading computations to the cloud and invokes a re-calibration\nprocedure to minimize error. AeroTraj can reconstruct large structures with\ncentimeter-level accuracy and with an average end-to-end latency below 250 ms,\nsignificantly outperforming the state of the art.\n","authors":["Fawad Ahmad","Christina Shin","Rajrup Ghosh","John D'Ambrosio","Eugene Chai","Karthik Sundaresan","Ramesh Govindan"],"pdf_url":"https://arxiv.org/pdf/2104.08634v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08930v2","updated":"2024-06-26T18:15:02Z","published":"2022-07-18T20:33:53Z","title":"Cooperative Infrastructure Perception","summary":"  Recent works have considered two qualitatively different approaches to\novercome line-of-sight limitations of 3D sensors used for perception:\ncooperative perception and infrastructure-augmented perception. In this paper,\nmotivated by increasing deployments of infrastructure LiDARs, we explore a\nthird approach, cooperative infrastructure perception. This approach generates\nperception outputs by fusing outputs of multiple infrastructure sensors, but,\nto be useful, must do so quickly and accurately. We describe the design,\nimplementation and evaluation of Cooperative Infrastructure Perception (CIP),\nwhich uses a combination of novel algorithms and systems optimizations. It\nproduces perception outputs within 100 ms using modest computing resources and\nwith accuracy comparable to the state-of-the-art. CIP, when used to augment\nvehicle perception, can improve safety. When used in conjunction with offloaded\nplanning, CIP can increase traffic throughput at intersections.\n","authors":["Fawad Ahmad","Christina Suyong Shin","Weiwu Pang","Branden Leong","Pradipta Ghosh","Ramesh Govindan"],"pdf_url":"https://arxiv.org/pdf/2207.08930v2.pdf","comment":null}]},"2024-06-27T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2406.19384v1","updated":"2024-06-27T17:57:03Z","published":"2024-06-27T17:57:03Z","title":"The Remarkable Robustness of LLMs: Stages of Inference?","summary":"  We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.\n","authors":["Vedang Lad","Wes Gurnee","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2406.19384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19370v1","updated":"2024-06-27T17:50:05Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2406.19370v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.19354v1","updated":"2024-06-27T17:33:03Z","published":"2024-06-27T17:33:03Z","title":"Fundamental Problems With Model Editing: How Should Rational Belief\n  Revision Work in LLMs?","summary":"  The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision\n","authors":["Peter Hase","Thomas Hofweber","Xiang Zhou","Elias Stengel-Eskin","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2406.19354v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.13040v2","updated":"2024-06-27T17:27:13Z","published":"2024-03-19T17:35:17Z","title":"Physics-Guided Neural Networks for Intraventricular Vector Flow Mapping","summary":"  Intraventricular vector flow mapping (iVFM) seeks to enhance and quantify\ncolor Doppler in cardiac imaging. In this study, we propose novel alternatives\nto the traditional iVFM optimization scheme by utilizing physics-informed\nneural networks (PINNs) and a physics-guided nnU-Net-based supervised approach.\nWhen evaluated on simulated color Doppler images derived from a\npatient-specific computational fluid dynamics model and in vivo Doppler\nacquisitions, both approaches demonstrate comparable reconstruction performance\nto the original iVFM algorithm. The efficiency of PINNs is boosted through\ndual-stage optimization and pre-optimized weights. On the other hand, the\nnnU-Net method excels in generalizability and real-time capabilities. Notably,\nnnU-Net shows superior robustness on sparse and truncated Doppler data while\nmaintaining independence from explicit boundary conditions. Overall, our\nresults highlight the effectiveness of these methods in reconstructing\nintraventricular vector blood flow. The study also suggests potential\napplications of PINNs in ultrafast color Doppler imaging and the incorporation\nof fluid dynamics equations to derive biomarkers for cardiovascular diseases\nbased on blood flow.\n","authors":["Hang Jung Ling","Salomé Bru","Julia Puig","Florian Vixège","Simon Mendez","Franck Nicoud","Pierre-Yves Courand","Olivier Bernard","Damien Garcia"],"pdf_url":"https://arxiv.org/pdf/2403.13040v2.pdf","comment":"12 pages, accepted for publication in IEEE TUFFC; camera ready\n  corrections, corrected acknowledgments"},{"id":"http://arxiv.org/abs/2406.19349v1","updated":"2024-06-27T17:26:38Z","published":"2024-06-27T17:26:38Z","title":"IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and\n  Toxicity Types for Indonesian Language","summary":"  Hate speech poses a significant threat to social harmony. Over the past two\nyears, Indonesia has seen a ten-fold increase in the online hate speech ratio,\nunderscoring the urgent need for effective detection mechanisms. However,\nprogress is hindered by the limited availability of labeled data for Indonesian\ntexts. The condition is even worse for marginalized minorities, such as Shia,\nLGBTQ, and other ethnic minorities because hate speech is underreported and\nless understood by detection tools. Furthermore, the lack of accommodation for\nsubjectivity in current datasets compounds this issue. To address this, we\nintroduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity\nclassification dataset. Comprising 43,692 entries annotated by 19 diverse\nindividuals, the dataset focuses on texts targeting vulnerable groups in\nIndonesia, specifically during the hottest political event in the country: the\npresidential election. We establish baselines for seven binary classification\ntasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)\nfine-tuned for hate speech classification. Furthermore, we demonstrate how\nincorporating demographic information can enhance the zero-shot performance of\nthe large language model, gpt-3.5-turbo. However, we also caution that an\noveremphasis on demographic information can negatively impact the fine-tuned\nmodel performance due to data fragmentation.\n","authors":["Lucky Susanto","Musa Izzanardi Wijanarko","Prasetia Anugrah Pratama","Traci Hong","Ika Idris","Alham Fikri Aji","Derry Wijaya"],"pdf_url":"https://arxiv.org/pdf/2406.19349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05162v2","updated":"2024-06-27T17:23:58Z","published":"2024-02-07T18:34:38Z","title":"Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank\n  Modifications","summary":"  Large language models (LLMs) show inherent brittleness in their safety\nmechanisms, as evidenced by their susceptibility to jailbreaking and even\nnon-malicious fine-tuning. This study explores this brittleness of safety\nalignment by leveraging pruning and low-rank modifications. We develop methods\nto identify critical regions that are vital for safety guardrails, and that are\ndisentangled from utility-relevant regions at both the neuron and rank levels.\nSurprisingly, the isolated regions we find are sparse, comprising about $3\\%$\nat the parameter level and $2.5\\%$ at the rank level. Removing these regions\ncompromises safety without significantly impacting utility, corroborating the\ninherent brittleness of the model's safety mechanisms. Moreover, we show that\nLLMs remain vulnerable to low-cost fine-tuning attacks even when modifications\nto the safety-critical regions are restricted. These findings underscore the\nurgent need for more robust safety strategies in LLMs.\n","authors":["Boyi Wei","Kaixuan Huang","Yangsibo Huang","Tinghao Xie","Xiangyu Qi","Mengzhou Xia","Prateek Mittal","Mengdi Wang","Peter Henderson"],"pdf_url":"https://arxiv.org/pdf/2402.05162v2.pdf","comment":"22 pages, 9 figures. Project page is available at\n  https://boyiwei.com/alignment-attribution/"},{"id":"http://arxiv.org/abs/2405.16755v2","updated":"2024-06-27T17:13:32Z","published":"2024-05-27T01:54:16Z","title":"CHESS: Contextual Harnessing for Efficient SQL Synthesis","summary":"  Utilizing large language models (LLMs) for transforming natural language\nquestions into SQL queries (text-to-SQL) is a promising yet challenging\napproach, particularly when applied to real-world databases with complex and\nextensive schemas. In particular, effectively incorporating data catalogs and\ndatabase values for SQL generation remains an obstacle, leading to suboptimal\nsolutions. We address this problem by proposing a new pipeline that effectively\nretrieves relevant data and context, selects an efficient schema, and\nsynthesizes correct and efficient SQL queries. To increase retrieval precision,\nour pipeline introduces a hierarchical retrieval method leveraging\nmodel-generated keywords, locality-sensitive hashing indexing, and vector\ndatabases. Additionally, we have developed an adaptive schema pruning technique\nthat adjusts based on the complexity of the problem and the model's context\nsize. Our approach generalizes to both frontier proprietary models like GPT-4\nand open-source models such as Llama-3-70B. Through a series of ablation\nstudies, we demonstrate the effectiveness of each component of our pipeline and\nits impact on the end-to-end performance. Our method achieves new\nstate-of-the-art performance on the cross-domain challenging BIRD dataset.\n","authors":["Shayan Talaei","Mohammadreza Pourreza","Yu-Chen Chang","Azalia Mirhoseini","Amin Saberi"],"pdf_url":"https://arxiv.org/pdf/2405.16755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12373v2","updated":"2024-06-27T16:56:13Z","published":"2024-06-18T07:58:33Z","title":"WebCanvas: Benchmarking Web Agents in Online Environments","summary":"  For web agents to be practically useful, they must adapt to the continuously\nevolving web environment characterized by frequent updates to user interfaces\nand content. However, most existing benchmarks only capture the static aspects\nof the web. To bridge this gap, we introduce WebCanvas, an innovative online\nevaluation framework for web agents that effectively addresses the dynamic\nnature of web interactions. WebCanvas contains three main components to\nfacilitate realistic assessments: (1) A novel evaluation metric which reliably\ncapture critical intermediate actions or states necessary for task completions\nwhile disregarding noise caused by insignificant events or changed\nweb-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version\nof original Mind2Web static dataset containing 542 tasks with 2439 intermediate\nevaluation states; (3) Lightweight and generalizable annotation tools and\ntesting pipelines that enables the community to collect and maintain the\nhigh-quality, up-to-date dataset. Building on WebCanvas, we open-source an\nagent framework with extensible modules for reasoning, providing a foundation\nfor the community to conduct online inference and evaluations. Our\nbest-performing agent achieves a task success rate of 23.1% and a task\ncompletion rate of 48.8% on the Mind2Web-Live test set. Additionally, we\nanalyze the performance discrepancies across various websites, domains, and\nexperimental environments. We encourage the community to contribute further\ninsights on online agent evaluation, thereby advancing this field of research.\n","authors":["Yichen Pan","Dehan Kong","Sida Zhou","Cheng Cui","Yifei Leng","Bing Jiang","Hangyu Liu","Yanyi Shang","Shuyan Zhou","Tongshuang Wu","Zhengyang Wu"],"pdf_url":"https://arxiv.org/pdf/2406.12373v2.pdf","comment":"Our platform, tool and dataset are publically available at\n  https://www.imean.ai/web-canvas/ and\n  https://huggingface.co/datasets/iMeanAI/Mind2Web-Live/"},{"id":"http://arxiv.org/abs/2406.19320v1","updated":"2024-06-27T16:54:12Z","published":"2024-06-27T16:54:12Z","title":"Efficient World Models with Context-Aware Tokenization","summary":"  Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2406.19320v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.19317v1","updated":"2024-06-27T16:52:19Z","published":"2024-06-27T16:52:19Z","title":"Jump Starting Bandits with LLM-Generated Prior Knowledge","summary":"  We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.\n","authors":["Parand A. Alamdari","Yanshuai Cao","Kevin H. Wilson"],"pdf_url":"https://arxiv.org/pdf/2406.19317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19314v1","updated":"2024-06-27T16:47:42Z","published":"2024-06-27T16:47:42Z","title":"LiveBench: A Challenging, Contamination-Free LLM Benchmark","summary":"  Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.\n","authors":["Colin White","Samuel Dooley","Manley Roberts","Arka Pal","Ben Feuer","Siddhartha Jain","Ravid Shwartz-Ziv","Neel Jain","Khalid Saifullah","Siddartha Naidu","Chinmay Hegde","Yann LeCun","Tom Goldstein","Willie Neiswanger","Micah Goldblum"],"pdf_url":"https://arxiv.org/pdf/2406.19314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07610v3","updated":"2024-06-27T16:38:35Z","published":"2024-02-12T12:30:42Z","title":"Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping","summary":"  Self-alignment is an effective way to reduce the cost of human annotation\nwhile ensuring promising model capability. However, most current methods\ncomplete the data collection and training steps in a single round, which may\noverlook the continuously improving ability of self-aligned models. This gives\nrise to a key query: What if we do multi-time bootstrapping self-alignment?\nDoes this strategy enhance model performance or lead to rapid degradation? In\nthis paper, our pioneering exploration delves into the impact of bootstrapping\nself-alignment on large language models. Our findings reveal that bootstrapping\nself-alignment markedly surpasses the single-round approach, by guaranteeing\ndata diversity from in-context learning. To further exploit the capabilities of\nbootstrapping, we investigate and adjust the training order of data, which\nyields improved performance of the model. Drawing on these findings, we propose\nStep-On-Feet Tuning (SOFT) which leverages model's continuously enhanced\nfew-shot ability to boost zero or one-shot performance. Based on easy-to-hard\ntraining recipe, we propose SOFT+ which further boost self-alignment's\nperformance. Our experiments demonstrate the efficiency of SOFT (SOFT+) across\nvarious classification and generation tasks, highlighting the potential of\nbootstrapping self-alignment on continually enhancing model alignment\nperformance.\n","authors":["Haoyu Wang","Guozheng Ma","Ziqiao Meng","Zeyu Qin","Li Shen","Zhong Zhang","Bingzhe Wu","Liu Liu","Yatao Bian","Tingyang Xu","Xueqian Wang","Peilin Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.07610v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19292v1","updated":"2024-06-27T16:05:13Z","published":"2024-06-27T16:05:13Z","title":"From Artificial Needles to Real Haystacks: Improving Retrieval\n  Capabilities in LLMs by Finetuning on Synthetic Data","summary":"  Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.\n","authors":["Zheyang Xiong","Vasilis Papageorgiou","Kangwook Lee","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.19292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.10253v4","updated":"2024-06-27T16:01:27Z","published":"2023-09-19T02:19:48Z","title":"GPTFUZZER: Red Teaming Large Language Models with Auto-Generated\n  Jailbreak Prompts","summary":"  Large language models (LLMs) have recently experienced tremendous popularity\nand are widely used from casual conversations to AI-driven programming.\nHowever, despite their considerable success, LLMs are not entirely reliable and\ncan give detailed guidance on how to conduct harmful or illegal activities.\nWhile safety measures can reduce the risk of such outputs, adversarial\njailbreak attacks can still exploit LLMs to produce harmful content. These\njailbreak templates are typically manually crafted, making large-scale testing\nchallenging.\n  In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzing\nframework inspired by the AFL fuzzing framework. Instead of manual engineering,\nGPTFuzz automates the generation of jailbreak templates for red-teaming LLMs.\nAt its core, GPTFuzz starts with human-written templates as initial seeds, then\nmutates them to produce new templates. We detail three key components of\nGPTFuzz: a seed selection strategy for balancing efficiency and variability,\nmutate operators for creating semantically equivalent or similar sentences, and\na judgment model to assess the success of a jailbreak attack.\n  We evaluate GPTFuzz against various commercial and open-source LLMs,\nincluding ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Our\nresults indicate that GPTFuzz consistently produces jailbreak templates with a\nhigh success rate, surpassing human-crafted templates. Remarkably, GPTFuzz\nachieves over 90% attack success rates against ChatGPT and Llama-2 models, even\nwith suboptimal initial seed templates. We anticipate that GPTFuzz will be\ninstrumental for researchers and practitioners in examining LLM robustness and\nwill encourage further exploration into enhancing LLM safety.\n","authors":["Jiahao Yu","Xingwei Lin","Zheng Yu","Xinyu Xing"],"pdf_url":"https://arxiv.org/pdf/2309.10253v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.07683v3","updated":"2024-06-27T15:54:58Z","published":"2023-09-14T12:58:30Z","title":"Assessing the nature of large language models: A caution against\n  anthropocentrism","summary":"  Generative AI models garnered a large amount of public attention and\nspeculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion\ncamps exist: one excited about possibilities these models offer for fundamental\nchanges to human tasks, and another highly concerned about power these models\nseem to have. To address these concerns, we assessed several LLMs, primarily\nGPT 3.5, using standard, normed, and validated cognitive and personality\nmeasures. For this seedling project, we developed a battery of tests that\nallowed us to estimate the boundaries of some of these models capabilities, how\nstable those capabilities are over a short period of time, and how they compare\nto humans. Our results indicate that LLMs are unlikely to have developed\nsentience, although its ability to respond to personality inventories is\ninteresting. GPT3.5 did display large variability in both cognitive and\npersonality measures over repeated observations, which is not expected if it\nhad a human-like personality. Variability notwithstanding, LLMs display what in\na human would be considered poor mental health, including low self-esteem,\nmarked dissociation from reality, and in some cases narcissism and psychopathy,\ndespite upbeat and helpful responses.\n","authors":["Ann Speed"],"pdf_url":"https://arxiv.org/pdf/2309.07683v3.pdf","comment":"31 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.19280v1","updated":"2024-06-27T15:50:41Z","published":"2024-06-27T15:50:41Z","title":"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into\n  Multimodal LLMs at Scale","summary":"  The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.\n","authors":["Junying Chen","Ruyi Ouyang","Anningzhe Gao","Shunian Chen","Guiming Hardy Chen","Xidong Wang","Ruifei Zhang","Zhenyang Cai","Ke Ji","Guangjun Yu","Xiang Wan","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06530v3","updated":"2024-06-27T15:39:12Z","published":"2024-02-09T16:41:50Z","title":"Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite\n  Kernel Strategy in One-Class Classification","summary":"  Early detection of myocardial infarction (MI), a critical condition arising\nfrom coronary artery disease (CAD), is vital to prevent further myocardial\ndamage. This study introduces a novel method for early MI detection using a\none-class classification (OCC) algorithm in echocardiography. Our study\novercomes the challenge of limited echocardiography data availability by\nadopting a novel approach based on Multi-modal Subspace Support Vector Data\nDescription. The proposed technique involves a specialized MI detection\nframework employing multi-view echocardiography incorporating a composite\nkernel in the non-linear projection trick, fusing Gaussian and Laplacian\nsigmoid functions. Additionally, we enhance the update strategy of the\nprojection matrices by adapting maximization for both or one of the modalities\nin the optimization process. Our method boosts MI detection capability by\nefficiently transforming features extracted from echocardiography data into an\noptimized lower-dimensional subspace. The OCC model trained specifically on\ntarget class instances from the comprehensive HMC-QU dataset that includes\nmultiple echocardiography views indicates a marked improvement in MI detection\naccuracy. Our findings reveal that our proposed multi-view approach achieves a\ngeometric mean of 71.24%, signifying a substantial advancement in\nechocardiography-based MI diagnosis and offering more precise and efficient\ndiagnostic tools.\n","authors":["Muhammad Uzair Zahid","Aysen Degerli","Fahad Sohrab","Serkan Kiranyaz","Tahir Hamid","Rashid Mazhar","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2402.06530v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15847v3","updated":"2024-06-27T15:38:17Z","published":"2024-01-29T02:43:40Z","title":"Muffin or Chihuahua? Challenging Multimodal Large Language Models with\n  Multipanel VQA","summary":"  Multipanel images, commonly seen as web screenshots, posters, etc., pervade\nour daily lives. These images, characterized by their composition of multiple\nsubfigures in distinct layouts, effectively convey information to people.\nToward building advanced multimodal AI applications, such as agents that\nunderstand complex scenes and navigate through webpages, the skill of\nmultipanel visual reasoning is essential, and a comprehensive evaluation of\nmodels in this regard is important. Therefore, we introduce Multipanel Visual\nQuestion Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets\nof questions, answers, and multipanel images that specifically challenge models\nin comprehending multipanel images. Our evaluation shows that questions in the\nMultipanelVQA benchmark pose significant challenges to the state-of-the-art\nMultimodal Large Language Models (MLLMs) tested, even though humans can attain\napproximately 99% accuracy on these questions. Distinctively, the MultipanelVQA\nbenchmark features synthetically generated multipanel images specifically\ncrafted to isolate and assess the impact of various factors, such as the\nlayout, on MLLMs' multipanel image comprehension abilities. As a result, in\naddition to benchmarking the capabilities of MLLMs in understanding multipanel\nimages, we analyze various factors of the multipanel image that affect MLLMs'\nperformance with synthetic data and offer insights for enhancement. Code and\ndata are released at https://sites.google.com/view/multipanelvqa/home.\n","authors":["Yue Fan","Jing Gu","Kaiwen Zhou","Qianqi Yan","Shan Jiang","Ching-Chen Kuo","Xinze Guan","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2401.15847v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2406.19261v1","updated":"2024-06-27T15:32:31Z","published":"2024-06-27T15:32:31Z","title":"Commodification of Compute","summary":"  The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.\n","authors":["Jesper Kristensen","David Wender","Carl Anthony"],"pdf_url":"https://arxiv.org/pdf/2406.19261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11999v4","updated":"2024-06-27T15:27:41Z","published":"2024-04-18T08:49:38Z","title":"Token-level Direct Preference Optimization","summary":"  Fine-tuning pre-trained Large Language Models (LLMs) is essential to align\nthem with human values and intentions. This process often utilizes methods like\npairwise comparisons and KL divergence against a reference LLM, focusing on the\nevaluation of full answers generated by the models. However, the generation of\nthese responses occurs in a token level, following a sequential,\nauto-regressive fashion. In this paper, we introduce Token-level Direct\nPreference Optimization (TDPO), a novel approach to align LLMs with human\npreferences by optimizing policy at the token level. Unlike previous methods,\nwhich face challenges in divergence efficiency, TDPO incorporates forward KL\ndivergence constraints for each token, improving alignment and diversity.\nUtilizing the Bradley-Terry model for a token-based reward system, TDPO\nenhances the regulation of KL divergence, while preserving simplicity without\nthe need for explicit reward modeling. Experimental results across various text\ntasks demonstrate TDPO's superior performance in balancing alignment with\ngeneration diversity. Notably, fine-tuning with TDPO strikes a better balance\nthan DPO in the controlled sentiment generation and single-turn dialogue\ndatasets, and significantly improves the quality of generated responses\ncompared to both DPO and PPO-based RLHF methods. Our code is open-sourced at\nhttps://github.com/Vance0124/Token-level-Direct-Preference-Optimization.\n","authors":["Yongcheng Zeng","Guoqing Liu","Weiyu Ma","Ning Yang","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2404.11999v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19256v1","updated":"2024-06-27T15:26:39Z","published":"2024-06-27T15:26:39Z","title":"AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data\n  Readiness for AI","summary":"  \"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.\n","authors":["Kaveen Hiniduma","Suren Byna","Jean Luca Bez","Ravi Madduri"],"pdf_url":"https://arxiv.org/pdf/2406.19256v1.pdf","comment":"12 pages, 9 figures, Accepted to SSDBM 2024"},{"id":"http://arxiv.org/abs/2406.12036v3","updated":"2024-06-27T15:25:25Z","published":"2024-06-17T19:07:21Z","title":"MedCalc-Bench: Evaluating Large Language Models for Medical Calculations","summary":"  As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.\n","authors":["Nikhil Khandekar","Qiao Jin","Guangzhi Xiong","Soren Dunn","Serina S Applebaum","Zain Anwar","Maame Sarfo-Gyamfi","Conrad W Safranek","Abid A Anwar","Andrew Zhang","Aidan Gilson","Maxwell B Singer","Amisha Dave","Andrew Taylor","Aidong Zhang","Qingyu Chen","Zhiyong Lu"],"pdf_url":"https://arxiv.org/pdf/2406.12036v3.pdf","comment":"Github link: https://github.com/ncbi-nlp/MedCalc-Bench HuggingFace\n  link: https://huggingface.co/datasets/nsk7153/MedCalc-Bench"},{"id":"http://arxiv.org/abs/2406.19251v1","updated":"2024-06-27T15:18:21Z","published":"2024-06-27T15:18:21Z","title":"AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for\n  Retrieval-Augmented Generation","summary":"  Recent advancements in Large Language Models have transformed ML/AI\ndevelopment, necessitating a reevaluation of AutoML principles for the\nRetrieval-Augmented Generation (RAG) systems. To address the challenges of\nhyper-parameter optimization and online adaptation in RAG, we propose the\nAutoRAG-HP framework, which formulates the hyper-parameter tuning as an online\nmulti-armed bandit (MAB) problem and introduces a novel two-level Hierarchical\nMAB (Hier-MAB) method for efficient exploration of large search spaces. We\nconduct extensive experiments on tuning hyper-parameters, such as top-k\nretrieved documents, prompt compression ratio, and embedding methods, using the\nALCE-ASQA and Natural Questions datasets. Our evaluation from jointly\noptimization all three hyper-parameters demonstrate that MAB-based online\nlearning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with\nprominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls\nrequired by the Grid Search approach. Additionally, the proposed Hier-MAB\napproach outperforms other baselines in more challenging optimization\nscenarios. The code will be made available at https://aka.ms/autorag.\n","authors":["Jia Fu","Xiaoting Qin","Fangkai Yang","Lu Wang","Jue Zhang","Qingwei Lin","Yubo Chen","Dongmei Zhang","Saravan Rajmohan","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19243v1","updated":"2024-06-27T15:08:51Z","published":"2024-06-27T15:08:51Z","title":"Application of ASV for Voice Identification after VC and Duration\n  Predictor Improvement in TTS Models","summary":"  One of the most crucial components in the field of biometric security is the\nautomatic speaker verification system, which is based on the speaker's voice.\nIt is possible to utilise ASVs in isolation or in conjunction with other AI\nmodels. In the contemporary era, the quality and quantity of neural networks\nare increasing exponentially. Concurrently, there is a growing number of\nsystems that aim to manipulate data through the use of voice conversion and\ntext-to-speech models. The field of voice biometrics forgery is aided by a\nnumber of challenges, including SSTC, ASVSpoof, and SingFake.\n  This paper presents a system for automatic speaker verification. The primary\nobjective of our model is the extraction of embeddings from the target\nspeaker's audio in order to obtain information about important characteristics\nof his voice, such as pitch, energy, and the duration of phonemes. This\ninformation is used in our multivoice TTS pipeline, which is currently under\ndevelopment. However, this model was employed within the SSTC challenge to\nverify users whose voice had undergone voice conversion, where it demonstrated\nan EER of 20.669.\n","authors":["Borodin Kirill Nikolayevich","Kudryavtsev Vasiliy Dmitrievich","Mkrtchian Grach Maratovich","Gorodnichev Mikhail Genadievich","Korzh Dmitrii Sergeevich"],"pdf_url":"https://arxiv.org/pdf/2406.19243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19236v1","updated":"2024-06-27T15:01:42Z","published":"2024-06-27T15:01:42Z","title":"Human-Aware Vision-and-Language Navigation: Bridging Simulation to\n  Reality with Dynamic Human Interactions","summary":"  Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.\n","authors":["Minghan Li","Heng Li","Zhi-Qi Cheng","Yifei Dong","Yuxuan Zhou","Jun-Yan He","Qi Dai","Teruko Mitamura","Alexander G. Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2406.19236v1.pdf","comment":"30 pages, 18 figures, Project Page:\n  https://lpercc.github.io/HA3D_simulator/"},{"id":"http://arxiv.org/abs/2406.19234v1","updated":"2024-06-27T14:58:38Z","published":"2024-06-27T14:58:38Z","title":"Seeing Is Believing: Black-Box Membership Inference Attacks Against\n  Retrieval Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that\nenhances Large Language Models (LLMs) by retrieving relevant knowledge from an\nexternal, non-parametric database. This approach aims to mitigate common LLM\nissues such as hallucinations and outdated knowledge. Although existing\nresearch has demonstrated security and privacy vulnerabilities within RAG\nsystems, making them susceptible to attacks like jailbreaks and prompt\ninjections, the security of the RAG system's external databases remains largely\nunderexplored. In this paper, we employ Membership Inference Attacks (MIA) to\ndetermine whether a sample is part of the knowledge database of a RAG system,\nusing only black-box API access. Our core hypothesis posits that if a sample is\na member, it will exhibit significant similarity to the text generated by the\nRAG system. To test this, we compute the cosine similarity and the model's\nperplexity to establish a membership score, thereby building robust features.\nWe then introduce two novel attack strategies: a Threshold-based Attack and a\nMachine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of our methods has achieved a ROC AUC of 82%.\n","authors":["Yuying Li","Gaoyang Liu","Yang Yang","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19228v1","updated":"2024-06-27T14:52:34Z","published":"2024-06-27T14:52:34Z","title":"Tools Fail: Detecting Silent Errors in Faulty Tools","summary":"  Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.\n","authors":["Jimin Sun","So Yeon Min","Yingshan Chang","Yonatan Bisk"],"pdf_url":"https://arxiv.org/pdf/2406.19228v1.pdf","comment":"18 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19223v1","updated":"2024-06-27T14:49:08Z","published":"2024-06-27T14:49:08Z","title":"T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for\n  Memory-Efficient Embeddings","summary":"  Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.\n","authors":["Björn Deiseroth","Manuel Brack","Patrick Schramowski","Kristian Kersting","Samuel Weinbach"],"pdf_url":"https://arxiv.org/pdf/2406.19223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19220v1","updated":"2024-06-27T14:45:38Z","published":"2024-06-27T14:45:38Z","title":"Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent\n  Access Threats Within Highly Imbalanced Data","summary":"  Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks\ndesigned to gain unauthorized access to systems and remain undetected for\nextended periods. To evade detection, APT cyberattacks deceive defense layers\nwith breaches and exploits, thereby complicating exposure by traditional\nanomaly detection-based security methods. The challenge of detecting APTs with\nmachine learning is compounded by the rarity of relevant datasets and the\nsignificant imbalance in the data, which makes the detection process highly\nburdensome. We present AE-APT, a deep learning-based tool for APT detection\nthat features a family of AutoEncoder methods ranging from a basic one to a\nTransformer-based one. We evaluated our tool on a suite of provenance trace\ndatabases produced by the DARPA Transparent Computing program, where APT-like\nattacks constitute as little as 0.004% of the data. The datasets span multiple\noperating systems, including Android, Linux, BSD, and Windows, and cover two\nattack scenarios. The outcomes showed that AE-APT has significantly higher\ndetection rates compared to its competitors, indicating superior performance in\ndetecting and ranking anomalies.\n","authors":["Sidahmed Benabderrahmane","Ngoc Hoang","Petko Valtchev","James Cheney","Talal Rahwan"],"pdf_url":"https://arxiv.org/pdf/2406.19220v1.pdf","comment":"To appear Future Generation Computer Systems"},{"id":"http://arxiv.org/abs/2406.19217v1","updated":"2024-06-27T14:43:50Z","published":"2024-06-27T14:43:50Z","title":"Think Step by Step: Chain-of-Gesture Prompting for Error Detection in\n  Robotic Surgical Videos","summary":"  Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.\n","authors":["Zhimin Shao","Jialang Xu","Danail Stoyanov","Evangelos B. Mazomenos","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2406.19217v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.12644v2","updated":"2024-06-27T14:32:07Z","published":"2024-06-18T14:12:27Z","title":"Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for\n  Large Language Models","summary":"  Assessing the effectiveness of large language models (LLMs) in addressing\ndiverse tasks is essential for comprehending their strengths and weaknesses.\nConventional evaluation techniques typically apply a single prompting strategy\nuniformly across datasets, not considering the varying degrees of task\ncomplexity. We introduce the Hierarchical Prompting Taxonomy (HPT), a taxonomy\nthat employs a Hierarchical Prompt Framework (HPF) composed of five unique\nprompting strategies, arranged from the simplest to the most complex, to assess\nLLMs more precisely and to offer a clearer perspective. This taxonomy assigns a\nscore, called the Hierarchical Prompting Score (HP-Score), to datasets as well\nas LLMs based on the rules of the taxonomy, providing a nuanced understanding\nof their ability to solve diverse tasks and offering a universal measure of\ntask complexity. Additionally, we introduce the Adaptive Hierarchical Prompt\nframework, which automates the selection of appropriate prompting strategies\nfor each task. This study compares manual and adaptive hierarchical prompt\nframeworks using four instruction-tuned LLMs, namely Llama 3 8B, Phi 3 3.8B,\nMistral 7B, and Gemma 7B, across four datasets: BoolQ, CommonSenseQA (CSQA),\nIWSLT-2017 en-fr (IWSLT), and SamSum. Experiments demonstrate the effectiveness\nof HPT, providing a reliable way to compare different tasks and LLM\ncapabilities. This paper leads to the development of a universal evaluation\nmetric that can be used to evaluate both the complexity of the datasets and the\ncapabilities of LLMs. The implementation of both manual HPF and adaptive HPF is\npublicly available.\n","authors":["Devichand Budagam","Sankalp KJ","Ashutosh Kumar","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2406.12644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06196v2","updated":"2024-06-27T14:19:56Z","published":"2024-05-10T02:23:56Z","title":"VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with\n  Lightweight Blocks","summary":"  Foundation Vision-Language Models (VLMs) trained using large-scale\nopen-domain images and text pairs have recently been adapted to develop\nVision-Language Segmentation Models (VLSMs) that allow providing text prompts\nduring inference to guide image segmentation. If robust and powerful VLSMs can\nbe built for medical images, it could aid medical professionals in many\nclinical tasks where they must spend substantial time delineating the target\nstructure of interest. VLSMs for medical images resort to fine-tuning base VLM\nor VLSM pretrained on open-domain natural image datasets due to fewer annotated\nmedical image datasets; this fine-tuning is resource-consuming and expensive as\nit usually requires updating all or a significant fraction of the pretrained\nparameters. Recently, lightweight blocks called adapters have been proposed in\nVLMs that keep the pretrained model frozen and only train adapters during\nfine-tuning, substantially reducing the computing resources required. We\nintroduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained\nvision-language segmentation models using transformer encoders. Our experiments\nin widely used CLIP-based segmentation models show that with only 3 million\ntrainable parameters, the VLSM-Adapter outperforms state-of-the-art and is\ncomparable to the upper bound end-to-end fine-tuning. The source code is\navailable at: https://github.com/naamiinepal/vlsm-adapter.\n","authors":["Manish Dhakal","Rabin Adhikari","Safal Thapaliya","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2405.06196v2.pdf","comment":"Accepted at MICCAI 2024, the 27th International Conference on Medical\n  Image Computing and Computer Assisted Intervention"},{"id":"http://arxiv.org/abs/2406.19195v1","updated":"2024-06-27T14:13:46Z","published":"2024-06-27T14:13:46Z","title":"Estimating Long-term Heterogeneous Dose-response Curve: Generalization\n  Bound Leveraging Optimal Transport Weights","summary":"  Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.\n","authors":["Zeqin Yang","Weilin Chen","Ruichu Cai","Yuguang Yan","Zhifeng Hao","Zhipeng Yu","Zhichao Zou","Zhen Peng","Jiecheng Guo"],"pdf_url":"https://arxiv.org/pdf/2406.19195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19189v1","updated":"2024-06-27T14:09:10Z","published":"2024-06-27T14:09:10Z","title":"BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy\n  Monitoring","summary":"  This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.\n","authors":["Luca Benfenati","Thorir Mar Ingolfsson","Andrea Cossettini","Daniele Jahier Pagliari","Alessio Burrello","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2406.19189v1.pdf","comment":"4 pages, 2 tables, 2 figures"},{"id":"http://arxiv.org/abs/2406.08426v2","updated":"2024-06-27T13:51:30Z","published":"2024-06-12T17:13:17Z","title":"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL","summary":"  Generating accurate SQL according to natural language questions (text-to-SQL)\nis a long-standing challenge due to the complexities involved in user question\nunderstanding, database schema comprehension, and SQL generation. Conventional\ntext-to-SQL systems, comprising human engineering and deep neural networks,\nhave made substantial progress. Subsequently, pre-trained language models\n(PLMs) have been developed and utilized for text-to-SQL tasks, achieving\npromising performance. As modern databases become more complex, the\ncorresponding user questions also grow more challenging, leading PLMs with\nlimited comprehension capabilities to produce incorrect SQL. This necessitates\nmore sophisticated and tailored optimization methods for PLMs, which, in turn,\nrestricts the applications of PLM-based systems. Most recently, large language\nmodels (LLMs) have demonstrated significant capabilities in natural language\nunderstanding as the model scale remains increasing. Therefore, integrating the\nLLM-based implementation can bring unique opportunities, improvements, and\nsolutions to text-to-SQL research. In this survey, we present a comprehensive\nreview of LLM-based text-to-SQL. Specifically, we propose a brief overview of\nthe technical challenges and the evolutionary process of text-to-SQL. Then, we\nprovide a detailed introduction to the datasets and metrics designed to\nevaluate text-to-SQL systems. After that, we present a systematic analysis of\nrecent advances in LLM-based text-to-SQL. Finally, we discuss the remaining\nchallenges in this field and propose expectations for future research\ndirections.\n","authors":["Zijin Hong","Zheng Yuan","Qinggang Zhang","Hao Chen","Junnan Dong","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.08426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07474v2","updated":"2024-06-27T13:17:58Z","published":"2024-05-13T05:23:48Z","title":"Integrating Intent Understanding and Optimal Behavior Planning for\n  Behavior Tree Generation from Human Instructions","summary":"  Robots executing tasks following human instructions in domestic or industrial\nenvironments essentially require both adaptability and reliability. Behavior\nTree (BT) emerges as an appropriate control architecture for these scenarios\ndue to its modularity and reactivity. Existing BT generation methods, however,\neither do not involve interpreting natural language or cannot theoretically\nguarantee the BTs' success. This paper proposes a two-stage framework for BT\ngeneration, which first employs large language models (LLMs) to interpret goals\nfrom high-level instructions, then constructs an efficient goal-specific BT\nthrough the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent\ngoals as well-formed formulas in first-order logic, effectively bridging intent\nunderstanding and optimal behavior planning. Experiments in the service robot\nvalidate the proficiency of LLMs in producing grammatically correct and\naccurately interpreted goals, demonstrate OBTEA's superiority over the baseline\nBT Expansion algorithm in various metrics, and finally confirm the practical\ndeployability of our framework. The project website is\nhttps://dids-ei.github.io/Project/LLM-OBTEA/.\n","authors":["Xinglin Chen","Yishuai Cai","Yunxin Mao","Minglong Li","Wenjing Yang","Weixia Xu","Ji Wang"],"pdf_url":"https://arxiv.org/pdf/2405.07474v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18388v2","updated":"2024-06-27T13:13:12Z","published":"2024-06-26T14:30:51Z","title":"SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and\n  Real-time Hysteresis Compensation Control Algorithm","summary":"  Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via\nnatural orifices and improve target lesion accessibility through curved paths.\nHowever, CDCMs face limitations in workspace and control accuracy due to\nnon-linear cable effects causing hysteresis. This paper introduces an\nextensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via\ntranslational motion without additional mechanical elements or actuation. We\ncollect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Based\non this dataset, we develop a real-time hysteresis compensation control\nalgorithm using the trained Temporal Convolutional Network (TCN) with a 1ms\ntime latency, effectively estimating the manipulator's hysteresis behavior.\nPerformance validation through random trajectory tracking tests and box\npointing tasks shows the proposed controller significantly reduces hysteresis\nby up to 69.5% in joint space and approximately 26% in the box pointing task.\n","authors":["Junhyun Park","Seonghyeok Jang","Myeongbo Park","Hyojae Park","Jeonghyeon Yoon","Minho Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.18388v2.pdf","comment":"12 pages, 14 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.19150v1","updated":"2024-06-27T13:08:35Z","published":"2024-06-27T13:08:35Z","title":"RAVEN: Multitask Retrieval Augmented Vision-Language Learning","summary":"  The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.\n","authors":["Varun Nagaraj Rao","Siddharth Choudhary","Aditya Deshpande","Ravi Kumar Satzoda","Srikar Appalaraju"],"pdf_url":"https://arxiv.org/pdf/2406.19150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19148v1","updated":"2024-06-27T13:06:47Z","published":"2024-06-27T13:06:47Z","title":"BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal\n  Supervision","summary":"  Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix\n","authors":["Kit Mills Bransby","Arian Beqiri","Woo-Jin Cho Kim","Jorge Oliveira","Agisilaos Chartsias","Alberto Gomez"],"pdf_url":"https://arxiv.org/pdf/2406.19148v1.pdf","comment":"Accepted at MICCAI 2024 (Pre-print)"},{"id":"http://arxiv.org/abs/2406.07100v2","updated":"2024-06-27T13:00:34Z","published":"2024-06-11T09:42:03Z","title":"D-GRIL: End-to-End Topological Learning with 2-parameter Persistence","summary":"  End-to-end topological learning using 1-parameter persistence is well-known.\nWe show that the framework can be enhanced using 2-parameter persistence by\nadopting a recently introduced 2-parameter persistence based vectorization\ntechnique called GRIL. We establish a theoretical foundation of differentiating\nGRIL producing D-GRIL. We show that D-GRIL can be used to learn a bifiltration\nfunction on standard benchmark graph datasets. Further, we exhibit that this\nframework can be applied in the context of bio-activity prediction in drug\ndiscovery.\n","authors":["Soham Mukherjee","Shreyas N. Samaga","Cheng Xin","Steve Oudot","Tamal K. Dey"],"pdf_url":"https://arxiv.org/pdf/2406.07100v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19136v1","updated":"2024-06-27T12:40:29Z","published":"2024-06-27T12:40:29Z","title":"YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph\n  Convolutional Networks and Transformer-Attention","summary":"  The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.\n","authors":["Chenxu Wang","Haowei Ming","Jian He","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.19136v1.pdf","comment":"18 pages, 12 figures, 6 tables"},{"id":"http://arxiv.org/abs/2403.17927v2","updated":"2024-06-27T12:40:12Z","published":"2024-03-26T17:57:57Z","title":"MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution","summary":"  In software development, resolving the emergent issues within GitHub\nrepositories is a complex challenge that involves not only the incorporation of\nnew code but also the maintenance of existing code. Large Language Models\n(LLMs) have shown promise in code generation but face difficulties in resolving\nGithub issues, particularly at the repository level. To overcome this\nchallenge, we empirically study the reason why LLMs fail to resolve GitHub\nissues and analyze the major factors. Motivated by the empirical findings, we\npropose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution,\nMAGIS, consisting of four agents customized for software evolution: Manager,\nRepository Custodian, Developer, and Quality Assurance Engineer agents. This\nframework leverages the collaboration of various agents in the planning and\ncoding process to unlock the potential of LLMs to resolve GitHub issues. In\nexperiments, we employ the SWE-bench benchmark to compare MAGIS with popular\nLLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub\nissues, significantly outperforming the baselines. Specifically, MAGIS achieves\nan eight-fold increase in resolved ratio over the direct application of GPT-4,\nthe advanced LLM.\n","authors":["Wei Tao","Yucheng Zhou","Yanlin Wang","Wenqiang Zhang","Hongyu Zhang","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.17927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19135v1","updated":"2024-06-27T12:39:55Z","published":"2024-06-27T12:39:55Z","title":"DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling\n  on Time Variability","summary":"  Expressive Text-to-Speech (TTS) using reference speech has been studied\nextensively to synthesize natural speech, but there are limitations to\nobtaining well-represented styles and improving model generalization ability.\nIn this study, we present Diffusion-based EXpressive TTS (DEX-TTS), an acoustic\nmodel designed for reference-based speech synthesis with enhanced style\nrepresentations. Based on a general diffusion TTS framework, DEX-TTS includes\nencoders and adapters to handle styles extracted from reference speech. Key\ninnovations contain the differentiation of styles into time-invariant and\ntime-variant categories for effective style extraction, as well as the design\nof encoders and adapters with high generalization ability. In addition, we\nintroduce overlapping patchify and convolution-frequency patch embedding\nstrategies to improve DiT-based diffusion networks for TTS. DEX-TTS yields\noutstanding performance in terms of objective and subjective evaluation in\nEnglish multi-speaker and emotional multi-speaker datasets, without relying on\npre-training strategies. Lastly, the comparison results for the general TTS on\na single-speaker dataset verify the effectiveness of our enhanced diffusion\nbackbone. Demos are available here.\n","authors":["Hyun Joon Park","Jin Sob Kim","Wooseok Shin","Sung Won Han"],"pdf_url":"https://arxiv.org/pdf/2406.19135v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2311.16480v4","updated":"2024-06-27T12:38:12Z","published":"2023-11-27T05:05:41Z","title":"WsiCaption: Multiple Instance Generation of Pathology Reports for\n  Gigapixel Whole-Slide Images","summary":"  Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(PathText). In specific, we collected nearly 10000 high-quality WSI-text pairs\nfor visual-language models by recognizing and cleaning pathology reports which\nnarrate diagnostic slides in TCGA. On the model end, we propose the multiple\ninstance generative model (MI-Gen) which can produce pathology reports for\ngigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText.\nExperimental results show our model can generate pathology reports which\ncontain multiple clinical clues and achieve competitive performance on certain\nslide-level tasks. We observe that simple semantic extraction from the\npathology reports can achieve the best performance (0.838 of F1 score) on BRCA\nsubtyping surpassing previous state-of-the-art approaches. Our collected\ndataset and related code are available.\n","authors":["Pingyi Chen","Honglin Li","Chenglu Zhu","Sunyi Zheng","Zhongyi Shui","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.16480v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19126v1","updated":"2024-06-27T12:16:35Z","published":"2024-06-27T12:16:35Z","title":"Super-resolution imaging using super-oscillatory diffractive neural\n  networks","summary":"  Optical super-oscillation enables far-field super-resolution imaging beyond\ndiffraction limits. However, the existing super-oscillatory lens for the\nspatial super-resolution imaging system still confronts critical limitations in\nperformance due to the lack of a more advanced design method and the limited\ndesign degree of freedom. Here, we propose an optical super-oscillatory\ndiffractive neural network, i.e., SODNN, that can achieve super-resolved\nspatial resolution for imaging beyond the diffraction limit with superior\nperformance over existing methods. SODNN is constructed by utilizing\ndiffractive layers to implement optical interconnections and imaging samples or\nbiological sensors to implement nonlinearity, which modulates the incident\noptical field to create optical super-oscillation effects in 3D space and\ngenerate the super-resolved focal spots. By optimizing diffractive layers with\n3D optical field constraints under an incident wavelength size of $\\lambda$, we\nachieved a super-oscillatory spot with a full width at half maximum of\n0.407$\\lambda$ in the far field distance over 400$\\lambda$ without side-lobes\nover the field of view, having a long depth of field over 10$\\lambda$.\nFurthermore, the SODNN implements a multi-wavelength and multi-focus spot array\nthat effectively avoids chromatic aberrations. Our research work will inspire\nthe development of intelligent optical instruments to facilitate the\napplications of imaging, sensing, perception, etc.\n","authors":["Hang Chen","Sheng Gao","Zejia Zhao","Zhengyang Duan","Haiou Zhang","Gordon Wetzstein","Xing Lin"],"pdf_url":"https://arxiv.org/pdf/2406.19126v1.pdf","comment":"18 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2406.12416v2","updated":"2024-06-27T12:07:55Z","published":"2024-06-18T09:07:30Z","title":"Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for\n  Large Language Models","summary":"  Large language models (LLMs) have achieved remarkable success but still tend\nto generate factually erroneous responses, a phenomenon known as hallucination.\nA recent trend is to use preference learning to fine-tune models to align with\nfactuality. However, existing work primarily evaluates fine-tuned models on\nin-domain (ID) datasets and the factuality on out-of-domain (OOD) datasets\nremains underexplored. In this paper, we conduct a comprehensive evaluation of\nthe factuality of different models tuned by various preference learning\nalgorithms and demonstrate that their performance on OOD datasets either\nincreases minimally or decreases. Subsequently, we reveal that the main cause\nof model's failure to uphold factuality under a distribution shift is\n\\textbf{under-alignment}, rather than \\textbf{over-alignment}, by analyzing the\ntoken distribution shift of the models before and after tuning. Finally, we\npropose \\textbf{APEFT} (\\textbf{A}tomic \\textbf{P}reference \\textbf{E}nhanced\n\\textbf{F}actuality \\textbf{T}uning), a framework that enhances model's\nawareness of factuality at the granularity of individual facts. Extensive\nexperiments demonstrate that APEFT improves model performance by an average of\n$\\boldsymbol{3.45\\%}$ on both ID and OOD datasets, which is highly effective.\n","authors":["Hongbang Yuan","Yubo Chen","Pengfei Cao","Zhuoran Jin","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.12416v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19121v1","updated":"2024-06-27T12:05:55Z","published":"2024-06-27T12:05:55Z","title":"Towards Learning Abductive Reasoning using VSA Distributed\n  Representations","summary":"  We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.\n","authors":["Giacomo Camposampiero","Michael Hersche","Aleksandar Terzić","Roger Wattenhofer","Abu Sebastian","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2406.19121v1.pdf","comment":"Accepted at the 18th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2024"},{"id":"http://arxiv.org/abs/2406.19116v1","updated":"2024-06-27T11:53:15Z","published":"2024-06-27T11:53:15Z","title":"CHEW: A Dataset of CHanging Events in Wikipedia","summary":"  We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.\n","authors":["Hsuvas Borkakoty","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2406.19116v1.pdf","comment":"Short Paper"},{"id":"http://arxiv.org/abs/2404.18736v4","updated":"2024-06-27T11:43:10Z","published":"2024-04-29T14:34:43Z","title":"Mapping the Potential of Explainable AI for Fairness Along the AI\n  Lifecycle","summary":"  The widespread use of artificial intelligence (AI) systems across various\ndomains is increasingly surfacing issues related to algorithmic fairness,\nespecially in high-stakes scenarios. Thus, critical considerations of how\nfairness in AI systems might be improved -- and what measures are available to\naid this process -- are overdue. Many researchers and policymakers see\nexplainable AI (XAI) as a promising way to increase fairness in AI systems.\nHowever, there is a wide variety of XAI methods and fairness conceptions\nexpressing different desiderata, and the precise connections between XAI and\nfairness remain largely nebulous. Besides, different measures to increase\nalgorithmic fairness might be applicable at different points throughout an AI\nsystem's lifecycle. Yet, there currently is no coherent mapping of fairness\ndesiderata along the AI lifecycle. In this paper, we we distill eight fairness\ndesiderata, map them along the AI lifecycle, and discuss how XAI could help\naddress each of them. We hope to provide orientation for practical applications\nand to inspire XAI research specifically focused on these fairness desiderata.\n","authors":["Luca Deck","Astrid Schomäcker","Timo Speith","Jakob Schöffer","Lena Kästner","Niklas Kühl"],"pdf_url":"https://arxiv.org/pdf/2404.18736v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19108v1","updated":"2024-06-27T11:34:35Z","published":"2024-06-27T11:34:35Z","title":"Computational Life: How Well-formed, Self-replicating Programs Emerge\n  from Simple Interaction","summary":"  The fields of Origin of Life and Artificial Life both question what life is\nand how it emerges from a distinct set of \"pre-life\" dynamics. One common\nfeature of most substrates where life emerges is a marked shift in dynamics\nwhen self-replication appears. While there are some hypotheses regarding how\nself-replicators arose in nature, we know very little about the general\ndynamics, computational principles, and necessary conditions for\nself-replicators to emerge. This is especially true on \"computational\nsubstrates\" where interactions involve logical, mathematical, or programming\nrules. In this paper we take a step towards understanding how self-replicators\narise by studying several computational substrates based on various simple\nprogramming languages and machine instruction sets. We show that when random,\nnon self-replicating programs are placed in an environment lacking any explicit\nfitness landscape, self-replicators tend to arise. We demonstrate how this\noccurs due to random interactions and self-modification, and can happen with\nand without background random mutations. We also show how increasingly complex\ndynamics continue to emerge following the rise of self-replicators. Finally, we\nshow a counterexample of a minimalistic programming language where\nself-replicators are possible, but so far have not been observed to arise.\n","authors":["Blaise Agüera y Arcas","Jyrki Alakuijala","James Evans","Ben Laurie","Alexander Mordvintsev","Eyvind Niklasson","Ettore Randazzo","Luca Versari"],"pdf_url":"https://arxiv.org/pdf/2406.19108v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2406.19102v1","updated":"2024-06-27T11:28:50Z","published":"2024-06-27T11:28:50Z","title":"Statements: Universal Information Extraction from Tables with Large\n  Language Models for ESG KPIs","summary":"  Environment, Social, and Governance (ESG) KPIs assess an organization's\nperformance on issues such as climate change, greenhouse gas emissions, water\nconsumption, waste management, human rights, diversity, and policies. ESG\nreports convey this valuable quantitative information through tables.\nUnfortunately, extracting this information is difficult due to high variability\nin the table structure as well as content. We propose Statements, a novel\ndomain agnostic data structure for extracting quantitative facts and related\ninformation. We propose translating tables to statements as a new supervised\ndeep-learning universal information extraction task. We introduce SemTabNet - a\ndataset of over 100K annotated tables. Investigating a family of T5-based\nStatement Extraction Models, our best model generates statements which are 82%\nsimilar to the ground-truth (compared to baseline of 21%). We demonstrate the\nadvantages of statements by applying our model to over 2700 tables from ESG\nreports. The homogeneous nature of statements permits exploratory data analysis\non expansive information found in large collections of ESG reports.\n","authors":["Lokesh Mishra","Sohayl Dhibi","Yusik Kim","Cesar Berrospi Ramis","Shubham Gupta","Michele Dolfi","Peter Staar"],"pdf_url":"https://arxiv.org/pdf/2406.19102v1.pdf","comment":"Accepted at the NLP4Climate workshop in the 62nd Annual Meeting of\n  the Association for Computational Linguistics (ACL 2024)"},{"id":"http://arxiv.org/abs/2406.19087v1","updated":"2024-06-27T11:14:14Z","published":"2024-06-27T11:14:14Z","title":"Dimensions underlying the representational alignment of deep neural\n  networks with humans","summary":"  Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.\n","authors":["Florian P. Mahner","Lukas Muttenthaler","Umut Güçlü","Martin N. Hebart"],"pdf_url":"https://arxiv.org/pdf/2406.19087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14214v3","updated":"2024-06-27T11:05:28Z","published":"2024-06-20T11:29:26Z","title":"REVEAL-IT: REinforcement learning with Visibility of Evolving Agent\n  poLicy for InTerpretability","summary":"  Understanding the agent's learning process, particularly the factors that\ncontribute to its success or failure post-training, is crucial for\ncomprehending the rationale behind the agent's decision-making process. Prior\nmethods clarify the learning process by creating a structural causal model\n(SCM) or visually representing the distribution of value functions.\nNevertheless, these approaches have constraints as they exclusively function in\n2D-environments or with uncomplicated transition dynamics. Understanding the\nagent's learning process in complicated environments or tasks is more\nchallenging. In this paper, we propose REVEAL-IT, a novel framework for\nexplaining the learning process of an agent in complex environments. Initially,\nwe visualize the policy structure and the agent's learning process for various\ntraining tasks. By visualizing these findings, we can understand how much a\nparticular training task or stage affects the agent's performance in test.\nThen, a GNN-based explainer learns to highlight the most important section of\nthe policy, providing a more clear and robust explanation of the agent's\nlearning process. The experiments demonstrate that explanations derived from\nthis framework can effectively help in the optimization of the training tasks,\nresulting in improved learning efficiency and final performance.\n","authors":["Shuang Ao","Simon Khan","Haris Aziz","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2406.14214v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2307.01452 by other authors"},{"id":"http://arxiv.org/abs/2406.19071v1","updated":"2024-06-27T10:41:22Z","published":"2024-06-27T10:41:22Z","title":"EmPO: Theory-Driven Dataset Construction for Empathetic Response\n  Generation through Preference Optimization","summary":"  Empathetic response generation is a desirable aspect of conversational\nagents, crucial for facilitating engaging and emotionally intelligent\nmulti-turn conversations between humans and machines. Leveraging large language\nmodels for this task has shown promising results, yet challenges persist in\nensuring both the empathetic quality of the responses and retention of the\ngeneralization performance of the models. In this paper, we propose a novel\napproach where we construct theory-driven preference datasets and use them to\nalign LLMs with preference optimization algorithms to address these challenges.\nTo measure empathetic response generation, we employ the EmpatheticDialogues\ndataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and\nevaluate the generalization performance on the MMLU benchmark. We make all\ndatasets, source code, and models publicly available.\n","authors":["Ondrej Sotolar"],"pdf_url":"https://arxiv.org/pdf/2406.19071v1.pdf","comment":"v01, 4 pages short paper, ACL style"},{"id":"http://arxiv.org/abs/2311.04698v4","updated":"2024-06-27T10:34:28Z","published":"2023-11-08T14:10:19Z","title":"Examining Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we investigate paradigms in MTL in\nthe context of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Overall,\nwe find surprising similarities between STL and MTL suggesting to consider\nmethods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v4.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2406.19057v1","updated":"2024-06-27T10:08:29Z","published":"2024-06-27T10:08:29Z","title":"Segment Anything Model for automated image data annotation: empirical\n  studies using text prompts from Grounding DINO","summary":"  Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2406.19057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19054v1","updated":"2024-06-27T10:01:56Z","published":"2024-06-27T10:01:56Z","title":"A look under the hood of the Interactive Deep Learning Enterprise\n  (No-IDLE)","summary":"  This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.\n","authors":["Daniel Sonntag","Michael Barz","Thiago Gouvêa"],"pdf_url":"https://arxiv.org/pdf/2406.19054v1.pdf","comment":"DFKI Technical Report"},{"id":"http://arxiv.org/abs/2406.19050v1","updated":"2024-06-27T09:58:43Z","published":"2024-06-27T09:58:43Z","title":"FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient\n  Federated Learning","summary":"  Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.\n","authors":["Alexander Herzog","Robbie Southam","Ioannis Mavromatis","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2406.19050v1.pdf","comment":"Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2406.18178v2","updated":"2024-06-27T09:58:35Z","published":"2024-06-26T08:52:34Z","title":"Games of Knightian Uncertainty as AGI testbeds","summary":"  Arguably, for the latter part of the late 20th and early 21st centuries,\ngames have been seen as the drosophila of AI. Games are a set of exciting\ntestbeds, whose solutions (in terms of identifying optimal players) would lead\nto machines that would possess some form of general intelligence, or at the\nvery least help us gain insights toward building intelligent machines.\nFollowing impressive successes in traditional board games like Go, Chess, and\nPoker, but also video games like the Atari 2600 collection, it is clear that\nthis is not the case. Games have been attacked successfully, but we are nowhere\nnear AGI developments (or, as harsher critics might say, useful AI\ndevelopments!). In this short vision paper, we argue that for game research to\nbecome again relevant to the AGI pathway, we need to be able to address\n\\textit{Knightian uncertainty} in the context of games, i.e. agents need to be\nable to adapt to rapid changes in game rules on the fly with no warning, no\nprevious data, and no model access.\n","authors":["Spyridon Samothrakis","Dennis J. N. J. Soemers","Damian Machlanski"],"pdf_url":"https://arxiv.org/pdf/2406.18178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19049v1","updated":"2024-06-27T09:57:31Z","published":"2024-06-27T09:57:31Z","title":"Accuracy on the wrong line: On the pitfalls of noisy data for\n  out-of-distribution generalisation","summary":"  \"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.\n","authors":["Amartya Sanyal","Yaxi Hu","Yaodong Yu","Yian Ma","Yixin Wang","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2406.19049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19048v1","updated":"2024-06-27T09:56:38Z","published":"2024-06-27T09:56:38Z","title":"BiCo-Fusion: Bidirectional Complementary LiDAR-Camera Fusion for\n  Semantic- and Spatial-Aware 3D Object Detection","summary":"  3D object detection is an important task that has been widely applied in\nautonomous driving. Recently, fusing multi-modal inputs, i.e., LiDAR and camera\ndata, to perform this task has become a new trend. Existing methods, however,\neither ignore the sparsity of Lidar features or fail to preserve the original\nspatial structure of LiDAR and the semantic density of camera features\nsimultaneously due to the modality gap. To address issues, this letter proposes\na novel bidirectional complementary Lidar-camera fusion framework, called\nBiCo-Fusion that can achieve robust semantic- and spatial-aware 3D object\ndetection. The key insight is to mutually fuse the multi-modal features to\nenhance the semantics of LiDAR features and the spatial awareness of the camera\nfeatures and adaptatively select features from both modalities to build a\nunified 3D representation. Specifically, we introduce Pre-Fusion consisting of\na Voxel Enhancement Module (VEM) to enhance the semantics of voxel features\nfrom 2D camera features and Image Enhancement Module (IEM) to enhance the\nspatial characteristics of camera features from 3D voxel features. Both VEM and\nIEM are bidirectionally updated to effectively reduce the modality gap. We then\nintroduce Unified Fusion to adaptively weight to select features from the\nenchanted Lidar and camera features to build a unified 3D representation.\nExtensive experiments demonstrate the superiority of our BiCo-Fusion against\nthe prior arts. Project page: https://t-ys.github.io/BiCo-Fusion/.\n","authors":["Yang Song","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19048v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.19043v1","updated":"2024-06-27T09:50:20Z","published":"2024-06-27T09:50:20Z","title":"CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI","summary":"  Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.\n","authors":["Zi Wang","Fanwen Wang","Chen Qin","Jun Lyu","Ouyang Cheng","Shuo Wang","Yan Li","Mengyao Yu","Haoyu Zhang","Kunyuan Guo","Zhang Shi","Qirong Li","Ziqiang Xu","Yajing Zhang","Hao Li","Sha Hua","Binghua Chen","Longyu Sun","Mengting Sun","Qin Li","Ying-Hua Chu","Wenjia Bai","Jing Qin","Xiahai Zhuang","Claudia Prieto","Alistair Young","Michael Markl","He Wang","Lianming Wu","Guang Yang","Xiaobo Qu","Chengyan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19043v1.pdf","comment":"19 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.14283v3","updated":"2024-06-27T09:44:45Z","published":"2024-06-20T13:08:09Z","title":"Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning","summary":"  Large Language Models (LLMs) have demonstrated impressive capability in many\nnatural language tasks. However, the auto-regressive generation process makes\nLLMs prone to produce errors, hallucinations and inconsistent statements when\nperforming multi-step reasoning. In this paper, by casting multi-step reasoning\nof LLMs as a heuristic search problem, we aim to alleviate the pathology by\nintroducing Q*, a general, versatile and agile framework for guiding LLMs\ndecoding process with deliberative planning. By learning a plug-and-play\nQ-value model as heuristic function for estimating expected future rewards, our\nQ* can effectively guide LLMs to select the most promising next reasoning step\nwithout fine-tuning LLMs for the current task, which avoids the significant\ncomputational overhead and potential risk of performance degeneration on other\ntasks. Extensive experiments on GSM8K, MATH and MBPP demonstrate the\nsuperiority of our method, contributing to improving the reasoning performance\nof existing open-source LLMs.\n","authors":["Chaojie Wang","Yanchen Deng","Zhiyi Lv","Zeng Liang","Jujie He","Shuicheng Yan","An Bo"],"pdf_url":"https://arxiv.org/pdf/2406.14283v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14540v3","updated":"2024-06-27T09:27:54Z","published":"2023-11-24T15:11:15Z","title":"RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and\n  Practice","summary":"  Over the years, RDF streaming was explored in research and practice from many\nangles, resulting in a wide range of RDF stream definitions. This variety\npresents a major challenge in discussing and integrating streaming systems, due\nto the lack of a common language. This work attempts to address this critical\nresearch gap, by systematizing RDF stream types present in the literature in a\nnovel taxonomy. The proposed RDF Stream Taxonomy (RDF-STaX) is embodied in an\nOWL 2 DL ontology that follows the FAIR principles, making it readily\napplicable in practice. Extensive documentation and additional resources are\nprovided, to foster the adoption of the ontology. Three use cases for the\nontology are presented with accompanying competency questions, demonstrating\nthe usefulness of the resource. Additionally, this work introduces a novel\nnanopublications dataset, which serves as a collaborative, living\nstate-of-the-art review of RDF streaming. The results of a multifaceted\nevaluation of the resource are presented, testing its logical validity, use\ncase coverage, and adherence to the community's best practices, while also\ncomparing it to other works. RDF-STaX is expected to help drive innovation in\nRDF streaming, by fostering scientific discussion, cooperation, and tool\ninteroperability.\n","authors":["Piotr Sowinski","Pawel Szmeja","Maria Ganzha","Marcin Paprzycki"],"pdf_url":"https://arxiv.org/pdf/2311.14540v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06582v3","updated":"2024-06-27T09:09:14Z","published":"2023-02-05T13:56:19Z","title":"A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean TSP","summary":"  The convex hull cheapest insertion heuristic is known to produce good\nsolutions to the Traveling Salesperson Problem in Euclidean spaces, but it has\nnot been extended to the non-Euclidean case. The proposed adaptation uses\nmultidimensional scaling to first project the points into a Euclidean space,\nthereby enabling the generation of the convex hull that initializes the\nalgorithm. To evaluate the proposed algorithm, non-Euclidean spaces are created\nby adding impassable separators to the TSPLIB benchmark data-set, or by using\nthe L1 norm as a metric. This adapted heuristic is demonstrated to outperform\nthe commonly used Nearest Neighbor heuristic and Nearest Insertion heuristic in\n89% and 99% of the cases studied, respectively. When the genetic algorithm and\nant colony optimization algorithms are provided 1 minute of computation time,\nthe proposed heuristic tour costs are lower than the mean metaheuristic\nsolutions found in 87% and 95% of the instances, respectively.\n","authors":["Mithun Goutham","Meghna Menon","Sarah Garrow","Stephanie Stockar"],"pdf_url":"https://arxiv.org/pdf/2302.06582v3.pdf","comment":"Manuscript submitted 27 January 2024 to the Operations Research\n  Letters"},{"id":"http://arxiv.org/abs/2405.13300v2","updated":"2024-06-27T09:07:38Z","published":"2024-05-22T02:37:02Z","title":"FAITH: Frequency-domain Attention In Two Horizons for Time Series\n  Forecasting","summary":"  Time Series Forecasting plays a crucial role in various fields such as\nindustrial equipment maintenance, meteorology, energy consumption, traffic flow\nand financial investment. However, despite their considerable advantages over\ntraditional statistical approaches, current deep learning-based predictive\nmodels often exhibit a significant deviation between their forecasting outcomes\nand the ground truth. This discrepancy is largely due to an insufficient\nemphasis on extracting the sequence's latent information, particularly its\nglobal information within the frequency domain and the relationship between\ndifferent variables. To address this issue, we propose a novel model\nFrequency-domain Attention In Two Horizons, which decomposes time series into\ntrend and seasonal components using a multi-scale sequence adaptive\ndecomposition and fusion architecture, and processes them separately. FAITH\nutilizes Frequency Channel feature Extraction Module and Frequency Temporal\nfeature Extraction Module to capture inter-channel relationships and temporal\nglobal information in the sequence, significantly improving its ability to\nhandle long-term dependencies and complex patterns. Furthermore, FAITH achieves\ntheoretically linear complexity by modifying the time-frequency domain\ntransformation method, effectively reducing computational costs. Extensive\nexperiments on 6 benchmarks for long-term forecasting and 3 benchmarks for\nshort-term forecasting demonstrate that FAITH outperforms existing models in\nmany fields, such as electricity, weather and traffic, proving its\neffectiveness and superiority both in long-term and short-term time series\nforecasting tasks. Our codes and data are available at\nhttps://github.com/LRQ577/FAITH.\n","authors":["Ruiqi Li","Maowei Jiang","Kai Wang","Kaiduo Feng","Quangao Liu","Yue Sun","Xiufang Zhou"],"pdf_url":"https://arxiv.org/pdf/2405.13300v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19015v1","updated":"2024-06-27T09:00:05Z","published":"2024-06-27T09:00:05Z","title":"Lithium-Ion Battery System Health Monitoring and Fault Analysis from\n  Field Data Using Gaussian Processes","summary":"  Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.\n","authors":["Joachim Schaeffer","Eric Lenz","Duncan Gulla","Martin Z. Bazant","Richard D. Braatz","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2406.19015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18361v2","updated":"2024-06-27T08:53:25Z","published":"2024-06-26T14:01:07Z","title":"Stable Diffusion Segmentation for Biomedical Images with Single-step\n  Reverse Process","summary":"  Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg\n","authors":["Tianyu Lin","Zhiguang Chen","Zhonghao Yan","Weijiang Yu","Fudan Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.18361v2.pdf","comment":"Accepted at MICCAI 2024. Code and citation info see\n  https://github.com/lin-tianyu/Stable-Diffusion-Seg"},{"id":"http://arxiv.org/abs/2406.18995v1","updated":"2024-06-27T08:36:43Z","published":"2024-06-27T08:36:43Z","title":"FedMLP: Federated Multi-Label Medical Image Classification under Task\n  Heterogeneity","summary":"  Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.\n","authors":["Zhaobin Sun","Nannan Wu","Junjie Shi","Li Yu","Xin Yang","Kwang-Ting Cheng","Zengqiang Yan"],"pdf_url":"https://arxiv.org/pdf/2406.18995v1.pdf","comment":"Early accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.18992v1","updated":"2024-06-27T08:33:35Z","published":"2024-06-27T08:33:35Z","title":"Semi-supervised Concept Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.\n","authors":["Lijie Hu","Tianhao Huang","Huanyi Xie","Chenyang Ren","Zhengyu Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18992v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2405.05908v3","updated":"2024-06-27T08:32:56Z","published":"2024-05-09T17:06:51Z","title":"Discovering hidden physics using ML-based multimodal super-resolution\n  measurement and its application to fusion plasmas","summary":"  A non-linear complex system governed by multi-spatial and multi-temporal\nphysics scales cannot be fully understood with a single diagnostic, as each\nprovides only a partial view and much information is lost during data\nextraction. Combining multiple diagnostics also results in imperfect\nprojections of the system's physics. By identifying hidden inter-correlations\nbetween diagnostics, we can leverage mutual support to fill in these gaps, but\nuncovering these inter-correlations analytically is too complex. We introduce a\ngroundbreaking machine learning methodology to address this issue. Our\nmultimodal approach generates super resolution data encompassing multiple\nphysics phenomena, capturing detailed structural evolution and responses to\nperturbations previously unobservable. This methodology addresses a critical\nproblem in fusion plasmas: the Edge Localized Mode (ELM), a plasma instability\nthat can severely damage reactor walls. One method to stabilize ELM is using\nresonant magnetic perturbation to trigger magnetic islands. However, low\nspatial and temporal resolution of measurements limits the analysis of these\nmagnetic islands due to their small size, rapid dynamics, and complex\ninteractions within the plasma. With super-resolution diagnostics, we can\nexperimentally verify theoretical models of magnetic islands for the first\ntime, providing unprecedented insights into their role in ELM stabilization.\nThis advancement aids in developing effective ELM suppression strategies for\nfuture fusion reactors like ITER and has broader applications, potentially\nrevolutionizing diagnostics in fields such as astronomy, astrophysics, and\nmedical imaging.\n","authors":["Azarakhsh Jalalvand","SangKyeun Kim","Jaemin Seo","Qiming Hu","Max Curie","Peter Steiner","Andrew Oakleigh Nelson","Yong-Su Na","Egemen Kolemen"],"pdf_url":"https://arxiv.org/pdf/2405.05908v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13106v3","updated":"2024-06-27T08:28:51Z","published":"2024-06-18T23:40:00Z","title":"Accelerating Complex Disease Treatment through Network Medicine and\n  GenAI: A Case Study on Drug Repurposing for Breast Cancer","summary":"  The objective of this research is to introduce a network specialized in\npredicting drugs that can be repurposed by investigating real-world evidence\nsources, such as clinical trials and biomedical literature. Specifically, it\naims to generate drug combination therapies for complex diseases (e.g., cancer,\nAlzheimer's). We present a multilayered network medicine approach, empowered by\na highly configured ChatGPT prompt engineering system, which is constructed on\nthe fly to extract drug mentions in clinical trials. Additionally, we introduce\na novel algorithm that connects real-world evidence with disease-specific\nsignaling pathways (e.g., KEGG database). This sheds light on the\nrepurposability of drugs if they are found to bind with one or more protein\nconstituents of a signaling pathway. To demonstrate, we instantiated the\nframework for breast cancer and found that, out of 46 breast cancer signaling\npathways, the framework identified 38 pathways that were covered by at least\ntwo drugs. This evidence signals the potential for combining those drugs.\nSpecifically, the most covered signaling pathway, ID hsa:2064, was covered by\n108 drugs, some of which can be combined. Conversely, the signaling pathway ID\nhsa:1499 was covered by only two drugs, indicating a significant gap for\nfurther research. Our network medicine framework, empowered by GenAI, shows\npromise in identifying drug combinations with a high degree of specificity,\nknowing the exact signaling pathways and proteins that serve as targets. It is\nnoteworthy that ChatGPT successfully accelerated the process of identifying\ndrug mentions in clinical trials, though further investigations are required to\ndetermine the relationships among the drug mentions.\n","authors":["Ahmed Abdeen Hamed","Tamer E. Fandy"],"pdf_url":"https://arxiv.org/pdf/2406.13106v3.pdf","comment":"9 pages double columns, 5 figures, 3 algorithms, 3 tables, and 1\n  listing, Submitted to IEEE MedAI'24 Conference, to be held November 15-17,\n  Chongqing, China"},{"id":"http://arxiv.org/abs/2405.10045v2","updated":"2024-06-27T08:12:59Z","published":"2024-05-16T12:29:12Z","title":"Global Benchmark Database","summary":"  This paper presents Global Benchmark Database (GBD), a comprehensive suite of\ntools for provisioning and sustainably maintaining benchmark instances and\ntheir metadata. The availability of benchmark metadata is essential for many\ntasks in empirical research, e.g., for the data-driven compilation of\nbenchmarks, the domain-specific analysis of runtime experiments, or the\ninstance-specific selection of solvers. In this paper, we introduce the data\nmodel of GBD as well as its interfaces and provide examples of how to interact\nwith them. We also demonstrate the integration of custom data sources and\nexplain how to extend GBD with additional problem domains, instance formats and\nfeature extractors.\n","authors":["Markus Iser","Christoph Jabs"],"pdf_url":"https://arxiv.org/pdf/2405.10045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18954v1","updated":"2024-06-27T07:36:25Z","published":"2024-06-27T07:36:25Z","title":"Alignment For Performance Improvement in Conversation Bots","summary":"  This paper shows that alignment methods can achieve superior adherence to\nguardrails compared to instruction fine-tuning alone in conversational agents,\nalso known as bots, within predefined guidelines or 'guardrails'. It examines\ntraditional training approaches such as instruction fine-tuning and the recent\nadvancements in direct alignment methods like Identity Preference Optimization\n(IPO), and Kahneman-Tversky Optimization (KTO). The effectiveness of alignment\ntechniques both pre and post-instruction tuning is highlighted, illustrating\ntheir potential to optimize conversational bots in domains that require strict\nadherence to specified rules, such as customer care.\n","authors":["Raghav Garg","Kapil Sharma","Shrey Singla"],"pdf_url":"https://arxiv.org/pdf/2406.18954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18944v1","updated":"2024-06-27T07:14:14Z","published":"2024-06-27T07:14:14Z","title":"Investigating and Defending Shortcut Learning in Personalized Diffusion\n  Models","summary":"  Personalized diffusion models have gained popularity for adapting pre-trained\ntext-to-image models to generate images of specific topics with only a few\nimages. However, recent studies find that these models are vulnerable to minor\nadversarial perturbation, and the fine-tuning performance is largely degraded\non corrupted datasets. Such characteristics are further exploited to craft\nprotective perturbation on sensitive images like portraits that prevent\nunauthorized generation. In response, diffusion-based purification methods have\nbeen proposed to remove these perturbations and retain generation performance.\nHowever, existing works lack detailed analysis of the fundamental shortcut\nlearning vulnerability of personalized diffusion models and also turn to\nover-purifying the images cause information loss. In this paper, we take a\ncloser look at the fine-tuning process of personalized diffusion models through\nthe lens of shortcut learning and propose a hypothesis that could explain the\nunderlying manipulation mechanisms of existing perturbation methods.\nSpecifically, we find that the perturbed images are greatly shifted from their\noriginal paired prompt in the CLIP-based latent space. As a result, training\nwith this mismatched image-prompt pair creates a construction that causes the\nmodels to dump their out-of-distribution noisy patterns to the identifier, thus\ncausing serious performance degradation. Based on this observation, we propose\na systematic approach to retain the training performance with purification that\nrealigns the latent image and its semantic meaning and also introduces\ncontrastive learning with a negative token to decouple the learning of wanted\nclean identity and the unwanted noisy pattern, that shows strong potential\ncapacity against further adaptive perturbation.\n","authors":["Yixin Liu","Ruoxi Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18944v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.18939v1","updated":"2024-06-27T07:11:48Z","published":"2024-06-27T07:11:48Z","title":"Evaluating AI Group Fairness: a Fuzzy Logic Perspective","summary":"  Artificial intelligence systems often address fairness concerns by evaluating\nand mitigating measures of group discrimination, for example that indicate\nbiases against certain genders or races. However, what constitutes group\nfairness depends on who is asked and the social context, whereas definitions\nare often relaxed to accept small deviations from the statistical constraints\nthey set out to impose. Here we decouple definitions of group fairness both\nfrom the context and from relaxation-related uncertainty by expressing them in\nthe axiomatic system of Basic fuzzy Logic (BL) with loosely understood\npredicates, like encountering group members. We then evaluate the definitions\nin subclasses of BL, such as Product or Lukasiewicz logics. Evaluation produces\ncontinuous instead of binary truth values by choosing the logic subclass and\ntruth values for predicates that reflect uncertain context-specific beliefs,\nsuch as stakeholder opinions gathered through questionnaires. Internally, it\nfollows logic-specific rules to compute the truth values of definitions. We\nshow that commonly held propositions standardize the resulting mathematical\nformulas and we transcribe logic and truth value choices to layperson terms, so\nthat anyone can answer them. We also use our framework to study several\nliterature definitions of algorithmic fairness, for which we rationalize\nprevious expedient practices that are non-probabilistic and show how to\nre-interpret their formulas and parameters in new contexts.\n","authors":["Emmanouil Krasanakis","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.18939v1.pdf","comment":"preprint, 32 pages, 7 figures, 2 theorems, 6 appendices"},{"id":"http://arxiv.org/abs/2306.05949v3","updated":"2024-06-27T07:10:37Z","published":"2023-06-09T15:05:13Z","title":"Evaluating the Social Impact of Generative AI Systems in Systems and\n  Society","summary":"  Generative AI systems across modalities, ranging from text (including code),\nimage, audio, and video, have broad social impacts, but there is no official\nstandard for means of evaluating those impacts or for which impacts should be\nevaluated. In this paper, we present a guide that moves toward a standard\napproach in evaluating a base generative AI system for any modality in two\noverarching categories: what can be evaluated in a base system independent of\ncontext and what can be evaluated in a societal context. Importantly, this\nrefers to base systems that have no predetermined application or deployment\ncontext, including a model itself, as well as system components, such as\ntraining data. Our framework for a base system defines seven categories of\nsocial impact: bias, stereotypes, and representational harms; cultural values\nand sensitive content; disparate performance; privacy and data protection;\nfinancial costs; environmental costs; and data and content moderation labor\ncosts. Suggested methods for evaluation apply to listed generative modalities\nand analyses of the limitations of existing evaluations serve as a starting\npoint for necessary investment in future evaluations. We offer five overarching\ncategories for what can be evaluated in a broader societal context, each with\nits own subcategories: trustworthiness and autonomy; inequality,\nmarginalization, and violence; concentration of authority; labor and\ncreativity; and ecosystem and environment. Each subcategory includes\nrecommendations for mitigating harm.\n","authors":["Irene Solaiman","Zeerak Talat","William Agnew","Lama Ahmad","Dylan Baker","Su Lin Blodgett","Canyu Chen","Hal Daumé III","Jesse Dodge","Isabella Duan","Ellie Evans","Felix Friedrich","Avijit Ghosh","Usman Gohar","Sara Hooker","Yacine Jernite","Ria Kalluri","Alberto Lusoli","Alina Leidinger","Michelle Lin","Xiuzhu Lin","Sasha Luccioni","Jennifer Mickel","Margaret Mitchell","Jessica Newman","Anaelia Ovalle","Marie-Therese Png","Shubham Singh","Andrew Strait","Lukas Struppek","Arjun Subramonian"],"pdf_url":"https://arxiv.org/pdf/2306.05949v3.pdf","comment":"Forthcoming in Hacker, Engel, Hammer, Mittelstadt (eds), Oxford\n  Handbook on the Foundations and Regulation of Generative AI. Oxford\n  University Press"},{"id":"http://arxiv.org/abs/2406.18937v1","updated":"2024-06-27T07:08:28Z","published":"2024-06-27T07:08:28Z","title":"Federated Graph Semantic and Structural Learning","summary":"  Federated graph learning collaboratively learns a global graph neural network\nwith distributed graphs, where the non-independent and identically distributed\nproperty is one of the major challenges. Most relative arts focus on\ntraditional distributed tasks like images and voices, incapable of graph\nstructures. This paper firstly reveals that local client distortion is brought\nby both node-level semantics and graph-level structure. First, for node-level\nsemantics, we find that contrasting nodes from distinct classes is beneficial\nto provide a well-performing discrimination. We pull the local node towards the\nglobal node of the same class and push it away from the global node of\ndifferent classes. Second, we postulate that a well-structural graph neural\nnetwork possesses similarity for neighbors due to the inherent adjacency\nrelationships. However, aligning each node with adjacent nodes hinders\ndiscrimination due to the potential class inconsistency. We transform the\nadjacency relationships into the similarity distribution and leverage the\nglobal model to distill the relation knowledge into the local model, which\npreserves the structural information and discriminability of the local model.\nEmpirical results on three graph datasets manifest the superiority of the\nproposed method over its counterparts.\n","authors":["Wenke Huang","Guancheng Wan","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2406.18937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18930v1","updated":"2024-06-27T06:53:28Z","published":"2024-06-27T06:53:28Z","title":"Reasoning About Action and Change","summary":"  The purpose of this book is to provide an overview of AI research, ranging\nfrom basic work to interfaces and applications, with as much emphasis on\nresults as on current issues. It is aimed at an audience of master students and\nPh.D. students, and can be of interest as well for researchers and engineers\nwho want to know more about AI. The book is split into three volumes.\n","authors":["Florence Dupin de Saint-Cyr","Andreas Herzig","Jérôme Lang","Pierre Marquis"],"pdf_url":"https://arxiv.org/pdf/2406.18930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18924v1","updated":"2024-06-27T06:31:51Z","published":"2024-06-27T06:31:51Z","title":"Learning Pareto Set for Multi-Objective Continuous Robot Control","summary":"  For a control problem with multiple conflicting objectives, there exists a\nset of Pareto-optimal policies called the Pareto set instead of a single\noptimal policy. When a multi-objective control problem is continuous and\ncomplex, traditional multi-objective reinforcement learning (MORL) algorithms\nsearch for many Pareto-optimal deep policies to approximate the Pareto set,\nwhich is quite resource-consuming. In this paper, we propose a simple and\nresource-efficient MORL algorithm that learns a continuous representation of\nthe Pareto set in a high-dimensional policy parameter space using a single\nhypernet. The learned hypernet can directly generate various well-trained\npolicy networks for different user preferences. We compare our method with two\nstate-of-the-art MORL algorithms on seven multi-objective continuous robot\ncontrol problems. Experimental results show that our method achieves the best\noverall performance with the least training parameters. An interesting\nobservation is that the Pareto set is well approximated by a curved line or\nsurface in a high-dimensional parameter space. This observation will provide\ninsight for researchers to design new MORL algorithms.\n","authors":["Tianye Shu","Ke Shang","Cheng Gong","Yang Nan","Hisao Ishibuchi"],"pdf_url":"https://arxiv.org/pdf/2406.18924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18922v1","updated":"2024-06-27T06:26:22Z","published":"2024-06-27T06:26:22Z","title":"Time Matters: Scaling Laws for Any Budget","summary":"  A primary cost driver for training large models is wall-clock training time.\nWe show that popular time estimates based on FLOPs are poor estimates, and\nconstruct a more accurate proxy based on memory copies. We show that with some\nsimple accounting, we can estimate the training speed of a transformer model\nfrom its hyperparameters. Combined with a scaling law curve like Chinchilla,\nthis lets us estimate the final loss of the model. We fit our estimate to real\ndata with a linear regression, and apply the result to rewrite Chinchilla in\nterms of a model's estimated training time as opposed to the amount of training\ndata. This gives an expression for the loss in terms of the model's\nhyperparameters alone. We show that this expression is accurate across a wide\nrange of model hyperparameter values, enabling us to analytically make\narchitectural decisions and train models more efficiently.\n","authors":["Itay Inbar","Luke Sernau"],"pdf_url":"https://arxiv.org/pdf/2406.18922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17329v2","updated":"2024-06-27T06:19:01Z","published":"2024-03-26T02:24:32Z","title":"Deep Support Vectors","summary":"  Deep learning has achieved tremendous success. \\nj{However,} unlike SVMs,\nwhich provide direct decision criteria and can be trained with a small dataset,\nit still has significant weaknesses due to its requirement for massive datasets\nduring training and the black-box characteristics on decision criteria.\n\\nj{This paper addresses} these issues by identifying support vectors in deep\nlearning models. To this end, we propose the DeepKKT condition, an adaptation\nof the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models,\nand confirm that generated Deep Support Vectors (DSVs) using this condition\nexhibit properties similar to traditional support vectors. This allows us to\napply our method to few-shot dataset distillation problems and alleviate the\nblack-box characteristics of deep learning models. Additionally, we demonstrate\nthat the DeepKKT condition can transform conventional classification models\ninto generative models with high fidelity, particularly as latent\n\\jh{generative} models using class labels as latent variables. We validate the\neffectiveness of DSVs \\nj{using common datasets (ImageNet, CIFAR10 \\nj{and}\nCIFAR100) on the general architectures (ResNet and ConvNet)}, proving their\npractical applicability. (See Fig.~\\ref{fig:generated})\n","authors":["Junhoo Lee","Hyunho Lee","Kyomin Hwang","Nojun Kwak"],"pdf_url":"https://arxiv.org/pdf/2403.17329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18916v1","updated":"2024-06-27T06:13:05Z","published":"2024-06-27T06:13:05Z","title":"TrustUQA: A Trustful Framework for Unified Structured Data Question\n  Answering","summary":"  Natural language question answering (QA) over structured data sources such as\ntables and knowledge graphs (KGs) have been widely investigated, for example\nwith Large Language Models (LLMs). The main solutions include question to\nformal query parsing and retrieval-based answer generation. However, current\nmethods of the former often suffer from weak generalization, failing to dealing\nwith multiple sources simultaneously, while the later is limited in\ntrustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework\nthat can simultaneously support multiple types of structured data in a unified\nway. To this end, it adopts an LLM-friendly and unified knowledge\nrepresentation method called Condition Graph (CG), and uses an LLM and\ndemonstration-based two-level method for CG querying. For enhancement, it is\nalso equipped with dynamic demonstration retrieval. We have evaluated\nUnifiedTQA with 5 benchmarks covering 3 types of structured data. It\noutperforms 2 existing unified structured data QA methods and in comparison\nwith the baselines that are specific to a data type, it achieves\nstate-of-the-art on 2 of them. Further more, we demonstrates potential of our\nmethod for more general QA tasks, QA over mixed structured data and QA across\nstructured data.\n","authors":["Wen Zhang","Long Jin","Yushan Zhu","Jiaoyan Chen","Zhiwei Huang","Junjie Wang","Yin Hua","Lei Liang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02027v2","updated":"2024-06-27T05:47:55Z","published":"2024-06-04T07:06:06Z","title":"Inference Attacks: A Taxonomy, Survey, and Promising Directions","summary":"  The prosperity of machine learning has also brought people's concerns about\ndata privacy. Among them, inference attacks can implement privacy breaches in\nvarious MLaaS scenarios and model training/prediction phases. Specifically,\ninference attacks can perform privacy inference on undisclosed target training\nsets based on outputs of the target model, including but not limited to\nstatistics, membership, semantics, data representation, etc. For instance,\ninfer whether the target data has the characteristics of AIDS. In addition, the\nrapid development of the machine learning community in recent years, especially\nthe surge of model types and application scenarios, has further stimulated the\ninference attacks' research. Thus, studying inference attacks and analyzing\nthem in depth is urgent and significant. However, there is still a gap in the\nsystematic discussion of inference attacks from taxonomy, global perspective,\nattack, and defense perspectives. This survey provides an in-depth and\ncomprehensive inference of attacks and corresponding countermeasures in\nML-as-a-service based on taxonomy and the latest researches. Without\ncompromising researchers' intuition, we first propose the 3MP taxonomy based on\nthe community research status, trying to normalize the confusing naming system\nof inference attacks. Also, we analyze the pros and cons of each type of\ninference attack, their workflow, countermeasure, and how they interact with\nother attacks. In the end, we point out several promising directions for\nresearchers from a more comprehensive and novel perspective.\n","authors":["Feng Wu","Lei Cui","Shaowen Yao","Shui Yu"],"pdf_url":"https://arxiv.org/pdf/2406.02027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06911v2","updated":"2024-06-27T05:39:46Z","published":"2024-06-11T03:09:37Z","title":"AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising","summary":"  Diffusion models have garnered significant interest from the community for\ntheir great generative ability across various applications. However, their\ntypical multi-step sequential-denoising nature gives rise to high cumulative\nlatency, thereby precluding the possibilities of parallel computation. To\naddress this, we introduce AsyncDiff, a universal and plug-and-play\nacceleration scheme that enables model parallelism across multiple devices. Our\napproach divides the cumbersome noise prediction model into multiple\ncomponents, assigning each to a different device. To break the dependency chain\nbetween these components, it transforms the conventional sequential denoising\ninto an asynchronous process by exploiting the high similarity between hidden\nstates in consecutive diffusion steps. Consequently, each component is\nfacilitated to compute in parallel on separate devices. The proposed strategy\nsignificantly reduces inference latency while minimally impacting the\ngenerative quality. Specifically, for the Stable Diffusion v2.1, AsyncDiff\nachieves a 2.7x speedup with negligible degradation and a 4.0x speedup with\nonly a slight reduction of 0.38 in CLIP Score, on four NVIDIA A5000 GPUs. Our\nexperiments also demonstrate that AsyncDiff can be readily applied to video\ndiffusion models with encouraging performances. The code is available at\nhttps://github.com/czg1225/AsyncDiff.\n","authors":["Zigeng Chen","Xinyin Ma","Gongfan Fang","Zhenxiong Tan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06911v2.pdf","comment":"Work in progress. Project Page:\n  https://czg1225.github.io/asyncdiff_page/"},{"id":"http://arxiv.org/abs/2406.18900v1","updated":"2024-06-27T05:28:40Z","published":"2024-06-27T05:28:40Z","title":"The Rise of Artificial Intelligence in Educational Measurement:\n  Opportunities and Ethical Challenges","summary":"  The integration of artificial intelligence (AI) in educational measurement\nhas revolutionized assessment methods, enabling automated scoring, rapid\ncontent analysis, and personalized feedback through machine learning and\nnatural language processing. These advancements provide timely, consistent\nfeedback and valuable insights into student performance, thereby enhancing the\nassessment experience. However, the deployment of AI in education also raises\nsignificant ethical concerns regarding validity, reliability, transparency,\nfairness, and equity. Issues such as algorithmic bias and the opacity of AI\ndecision-making processes pose risks of perpetuating inequalities and affecting\nassessment outcomes. Responding to these concerns, various stakeholders,\nincluding educators, policymakers, and organizations, have developed guidelines\nto ensure ethical AI use in education. The National Council of Measurement in\nEducation's Special Interest Group on AI in Measurement and Education (AIME)\nalso focuses on establishing ethical standards and advancing research in this\narea. In this paper, a diverse group of AIME members examines the ethical\nimplications of AI-powered tools in educational measurement, explores\nsignificant challenges such as automation bias and environmental impact, and\nproposes solutions to ensure AI's responsible and effective use in education.\n","authors":["Okan Bulut","Maggie Beiting-Parrish","Jodi M. Casabianca","Sharon C. Slater","Hong Jiao","Dan Song","Christopher M. Ormerod","Deborah Gbemisola Fabiyi","Rodica Ivan","Cole Walsh","Oscar Rios","Joshua Wilson","Seyma N. Yildirim-Erbasli","Tarid Wongvorachan","Joyce Xinle Liu","Bin Tan","Polina Morilova"],"pdf_url":"https://arxiv.org/pdf/2406.18900v1.pdf","comment":"59 pages, 3 figures, a joint work of the Special Interest Group on\n  Artificial Intelligence in Measurement and Education (AIME) from the National\n  Council of Measurement in Education (NCME)"},{"id":"http://arxiv.org/abs/2406.18899v1","updated":"2024-06-27T05:27:39Z","published":"2024-06-27T05:27:39Z","title":"Autonomous Control of a Novel Closed Chain Five Bar Active Suspension\n  via Deep Reinforcement Learning","summary":"  Planetary exploration requires traversal in environments with rugged\nterrains. In addition, Mars rovers and other planetary exploration robots often\ncarry sensitive scientific experiments and components onboard, which must be\nprotected from mechanical harm. This paper deals with an active suspension\nsystem focused on chassis stabilisation and an efficient traversal method while\nencountering unavoidable obstacles. Soft Actor-Critic (SAC) was applied along\nwith Proportional Integral Derivative (PID) control to stabilise the chassis\nand traverse large obstacles at low speeds. The model uses the rover's distance\nfrom surrounding obstacles, the height of the obstacle, and the chassis'\norientation to actuate the control links of the suspension accurately.\nSimulations carried out in the Gazebo environment are used to validate the\nproposed active system.\n","authors":["Nishesh Singh","Sidharth Ramesh","Abhishek Shankar","Jyotishka Duttagupta","Leander Stephen D'Souza","Sanjay Singh"],"pdf_url":"https://arxiv.org/pdf/2406.18899v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.18898v1","updated":"2024-06-27T05:26:38Z","published":"2024-06-27T05:26:38Z","title":"360 in the Wild: Dataset for Depth Prediction and View Synthesis","summary":"  The large abundance of perspective camera datasets facilitated the emergence\nof novel learning-based strategies for various tasks, such as camera\nlocalization, single image depth estimation, or view synthesis. However,\npanoramic or omnidirectional image datasets, including essential information,\nsuch as pose and depth, are mostly made with synthetic scenes. In this work, we\nintroduce a large scale 360$^{\\circ}$ videos dataset in the wild. This dataset\nhas been carefully scraped from the Internet and has been captured from various\nlocations worldwide. Hence, this dataset exhibits very diversified environments\n(e.g., indoor and outdoor) and contexts (e.g., with and without moving\nobjects). Each of the 25K images constituting our dataset is provided with its\nrespective camera's pose and depth map. We illustrate the relevance of our\ndataset for two main tasks, namely, single image depth estimation and view\nsynthesis.\n","authors":["Kibaek Park","Francois Rameau","Jaesik Park","In So Kweon"],"pdf_url":"https://arxiv.org/pdf/2406.18898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12199v2","updated":"2024-06-27T05:18:57Z","published":"2024-06-18T01:55:37Z","title":"Time Series Modeling for Heart Rate Prediction: From ARIMA to\n  Transformers","summary":"  Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.\n","authors":["Haowei Ni","Shuchen Meng","Xieming Geng","Panfeng Li","Zhuoying Li","Xupeng Chen","Xiaotong Wang","Shiyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12199v2.pdf","comment":"Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics"},{"id":"http://arxiv.org/abs/2310.08279v3","updated":"2024-06-27T04:55:28Z","published":"2023-10-12T12:31:23Z","title":"Enhancing Text-based Knowledge Graph Completion with Zero-Shot Large\n  Language Models: A Focus on Semantic Enhancement","summary":"  The design and development of text-based knowledge graph completion (KGC)\nmethods leveraging textual entity descriptions are at the forefront of\nresearch. These methods involve advanced optimization techniques such as soft\nprompts and contrastive learning to enhance KGC models. The effectiveness of\ntext-based methods largely hinges on the quality and richness of the training\ndata. Large language models (LLMs) can utilize straightforward prompts to alter\ntext data, thereby enabling data augmentation for KGC. Nevertheless, LLMs\ntypically demand substantial computational resources. To address these issues,\nwe introduce a framework termed constrained prompts for KGC (CP-KGC). This\nCP-KGC framework designs prompts that adapt to different datasets to enhance\nsemantic richness. Additionally, CP-KGC employs a context constraint strategy\nto effectively identify polysemous entities within KGC datasets. Through\nextensive experimentation, we have verified the effectiveness of this\nframework. Even after quantization, the LLM (Qwen-7B-Chat-int4) still enhances\nthe performance of text-based KGC methods \\footnote{Code and datasets are\navailable at\n\\href{https://github.com/sjlmg/CP-KGC}{https://github.com/sjlmg/CP-KGC}}. This\nstudy extends the performance limits of existing models and promotes further\nintegration of KGC with LLMs.\n","authors":["Rui Yang","Jiahao Zhu","Jianping Man","Li Fang","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.08279v3.pdf","comment":"new version"},{"id":"http://arxiv.org/abs/2406.18884v1","updated":"2024-06-27T04:33:26Z","published":"2024-06-27T04:33:26Z","title":"Sequential three-way group decision-making for double hierarchy hesitant\n  fuzzy linguistic term set","summary":"  Group decision-making (GDM) characterized by complexity and uncertainty is an\nessential part of various life scenarios. Most existing researches lack tools\nto fuse information quickly and interpret decision results for partially formed\ndecisions. This limitation is particularly noticeable when there is a need to\nimprove the efficiency of GDM. To address this issue, a novel multi-level\nsequential three-way decision for group decision-making (S3W-GDM) method is\nconstructed from the perspective of granular computing. This method\nsimultaneously considers the vagueness, hesitation, and variation of GDM\nproblems under double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS)\nenvironment. First, for fusing information efficiently, a novel multi-level\nexpert information fusion method is proposed, and the concepts of expert\ndecision table and the extraction/aggregation of decision-leveled information\nbased on the multi-level granularity are defined. Second, the neighborhood\ntheory, outranking relation and regret theory (RT) are utilized to redesign the\ncalculations of conditional probability and relative loss function. Then, the\ngranular structure of DHHFLTS based on the sequential three-way decision (S3WD)\nis defined to improve the decision-making efficiency, and the decision-making\nstrategy and interpretation of each decision-level are proposed. Furthermore,\nthe algorithm of S3W-GDM is given. Finally, an illustrative example of\ndiagnosis is presented, and the comparative and sensitivity analysis with other\nmethods are performed to verify the efficiency and rationality of the proposed\nmethod.\n","authors":["Nanfang Luo","Qinghua Zhang","Qin Xie","Yutai Wang","Longjun Yin","Guoyin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09193v2","updated":"2024-06-27T04:01:05Z","published":"2023-12-14T18:14:11Z","title":"Fast Sampling via Discrete Non-Markov Diffusion Models","summary":"  Discrete diffusion models have emerged as powerful tools for high-quality\ndata generation. Despite their success in discrete spaces, such as text\ngeneration tasks, the acceleration of discrete diffusion models remains under\nexplored. In this paper, we propose a discrete non-Markov diffusion model,\nwhich admits an accelerated reverse sampling for discrete data generation. Our\nmethod significantly reduces the number of function evaluations (i.e., calls to\nthe neural network), making the sampling process much faster. Furthermore, we\nstudy the transition from finite to infinite step sampling, offering new\ninsights into bridging the gap between discrete and continuous-time processes\nfor discrete diffusion models. Extensive experiments on natural language\ngeneration and machine translation tasks demonstrate the superior performance\nof our method in terms of both generation speed and sample quality compared to\nexisting methods for discrete diffusion models.\n","authors":["Zixiang Chen","Huizhuo Yuan","Yongqian Li","Yiwen Kou","Junkai Zhang","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2312.09193v2.pdf","comment":"33 pages, 5 figures, 12 tables"},{"id":"http://arxiv.org/abs/2401.10415v2","updated":"2024-06-27T04:00:19Z","published":"2024-01-18T23:00:54Z","title":"Can Large Language Model Summarizers Adapt to Diverse Scientific\n  Communication Goals?","summary":"  In this work, we investigate the controllability of large language models\n(LLMs) on scientific summarization tasks. We identify key stylistic and content\ncoverage factors that characterize different types of summaries such as paper\nreviews, abstracts, and lay summaries. By controlling stylistic features, we\nfind that non-fine-tuned LLMs outperform humans in the MuP review generation\ntask, both in terms of similarity to reference summaries and human preferences.\nAlso, we show that we can improve the controllability of LLMs with\nkeyword-based classifier-free guidance (CFG) while achieving lexical overlap\ncomparable to strong fine-tuned baselines on arXiv and PubMed. However, our\nresults also indicate that LLMs cannot consistently generate long summaries\nwith more than 8 sentences. Furthermore, these models exhibit limited capacity\nto produce highly abstractive lay summaries. Although LLMs demonstrate strong\ngeneric summarization competency, sophisticated content control without costly\nfine-tuning remains an open problem for domain-specific applications.\n","authors":["Marcio Fonseca","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2401.10415v2.pdf","comment":"ACL 2024 camera ready"},{"id":"http://arxiv.org/abs/2406.18069v2","updated":"2024-06-27T03:58:25Z","published":"2024-06-26T04:54:45Z","title":"Large Language Models for Cuffless Blood Pressure Measurement From\n  Wearable Biosignals","summary":"  Large language models (LLMs) have captured significant interest from both\nacademia and industry due to their impressive performance across various\ntextual tasks. However, the potential of LLMs to analyze physiological\ntime-series data remains an emerging research field. Particularly, there is a\nnotable gap in the utilization of LLMs for analyzing wearable biosignals to\nachieve cuffless blood pressure (BP) measurement, which is critical for the\nmanagement of cardiovascular diseases. This paper presents the first work to\nexplore the capacity of LLMs to perform cuffless BP estimation based on\nwearable biosignals. We extracted physiological features from electrocardiogram\n(ECG) and photoplethysmogram (PPG) signals and designed context-enhanced\nprompts by combining these features with BP domain knowledge and user\ninformation. Subsequently, we adapted LLMs to BP estimation tasks through\nfine-tuning. To evaluate the proposed approach, we conducted assessments of ten\nadvanced LLMs using a comprehensive public dataset of wearable biosignals from\n1,272 participants. The experimental results demonstrate that the optimally\nfine-tuned LLM significantly surpasses conventional task-specific baselines,\nachieving an estimation error of 0.00 $\\pm$ 9.25 mmHg for systolic BP and 1.29\n$\\pm$ 6.37 mmHg for diastolic BP. Notably, the ablation studies highlight the\nbenefits of our context enhancement strategy, leading to an 8.9% reduction in\nmean absolute error for systolic BP estimation. This paper pioneers the\nexploration of LLMs for cuffless BP measurement, providing a potential solution\nto enhance the accuracy of cuffless BP measurement.\n","authors":["Zengding Liu","Chen Chen","Jiannong Cao","Minglei Pan","Jikui Liu","Nan Li","Fen Miao","Ye Li"],"pdf_url":"https://arxiv.org/pdf/2406.18069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14905v2","updated":"2024-06-27T03:53:46Z","published":"2024-02-22T18:58:55Z","title":"MobileLLM: Optimizing Sub-billion Parameter Language Models for\n  On-Device Use Cases","summary":"  This paper addresses the growing need for efficient large language models\n(LLMs) on mobile devices, driven by increasing cloud costs and latency\nconcerns. We focus on designing top-quality LLMs with fewer than a billion\nparameters, a practical choice for mobile deployment. Contrary to prevailing\nbelief emphasizing the pivotal role of data and parameter quantity in\ndetermining model quality, our investigation underscores the significance of\nmodel architecture for sub-billion scale LLMs. Leveraging deep and thin\narchitectures, coupled with embedding sharing and grouped-query attention\nmechanisms, we establish a strong baseline network denoted as MobileLLM, which\nattains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M\nstate-of-the-art models. Additionally, we propose an immediate block-wise\nweight-sharing approach with no increase in model size and only marginal\nlatency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a\nfurther accuracy enhancement of 0.7%/0.8% than MobileLLM 125M/350M. Moreover,\nMobileLLM model family shows significant improvements compared to previous\nsub-billion models on chat benchmarks, and demonstrates close correctness to\nLLaMA-v2 7B in API calling tasks, highlighting the capability of small models\nfor common on-device use cases.\n","authors":["Zechun Liu","Changsheng Zhao","Forrest Iandola","Chen Lai","Yuandong Tian","Igor Fedorov","Yunyang Xiong","Ernie Chang","Yangyang Shi","Raghuraman Krishnamoorthi","Liangzhen Lai","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2402.14905v2.pdf","comment":"ICML 2024. Code is available at\n  https://github.com/facebookresearch/MobileLLM"},{"id":"http://arxiv.org/abs/2311.08704v2","updated":"2024-06-27T03:48:35Z","published":"2023-11-15T05:11:26Z","title":"Can Large Language Models Follow Concept Annotation Guidelines? A Case\n  Study on Scientific and Financial Domains","summary":"  Although large language models (LLMs) exhibit remarkable capacity to leverage\nin-context demonstrations, it is still unclear to what extent they can learn\nnew concepts or facts from ground-truth labels. To address this question, we\nexamine the capacity of instruction-tuned LLMs to follow in-context concept\nguidelines for sentence labeling tasks. We design guidelines that present\ndifferent types of factual and counterfactual concept definitions, which are\nused as prompts for zero-shot sentence classification tasks. Our results show\nthat although concept definitions consistently help in task performance, only\nthe larger models (with 70B parameters or more) have limited ability to work\nunder counterfactual contexts. Importantly, only proprietary models such as\nGPT-3.5 and GPT-4 can recognize nonsensical guidelines, which we hypothesize is\ndue to more sophisticated alignment methods. Finally, we find that\nFalcon-180B-chat is outperformed by Llama-2-70B-chat is most cases, which\nindicates that careful fine-tuning is more effective than increasing model\nscale. Altogether, our simple evaluation method reveals significant gaps in\nconcept understanding between the most capable open-source language models and\nthe leading proprietary APIs.\n","authors":["Marcio Fonseca","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2311.08704v2.pdf","comment":"ACL 2024 camera ready"},{"id":"http://arxiv.org/abs/2406.18859v1","updated":"2024-06-27T03:05:35Z","published":"2024-06-27T03:05:35Z","title":"Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology\n  Report Simplification","summary":"  Radiology reports are highly technical documents aimed primarily at\ndoctor-doctor communication. There has been an increasing interest in sharing\nthose reports with patients, necessitating providing them patient-friendly\nsimplifications of the original reports. This study explores the suitability of\nlarge language models in automatically generating those simplifications. We\nexamine the usefulness of chain-of-thought and self-correction prompting\nmechanisms in this domain. We also propose a new evaluation protocol that\nemploys radiologists and laypeople, where radiologists verify the factual\ncorrectness of simplifications, and laypeople assess simplicity and\ncomprehension. Our experimental results demonstrate the effectiveness of\nself-correction prompting in producing high-quality simplifications. Our\nfindings illuminate the preferences of radiologists and laypeople regarding\ntext simplification, informing future research on this topic.\n","authors":["Ziyu Yang","Santhosh Cherian","Slobodan Vucetic"],"pdf_url":"https://arxiv.org/pdf/2406.18859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18856v1","updated":"2024-06-27T02:53:55Z","published":"2024-06-27T02:53:55Z","title":"FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus","summary":"  Large Language Models (LLMs) have stunningly advanced the field of machine\ntranslation, though their effectiveness within the financial domain remains\nlargely underexplored. To probe this issue, we constructed a fine-grained\nChinese-English parallel corpus of financial news called FFN. We acquired\nfinancial news articles spanning between January 1st, 2014, to December 31,\n2023, from mainstream media websites such as CNN, FOX, and China Daily. The\ndataset consists of 1,013 main text and 809 titles, all of which have been\nmanually corrected. We measured the translation quality of two LLMs -- ChatGPT\nand ERNIE-bot, utilizing BLEU, TER and chrF scores as the evaluation metrics.\nFor comparison, we also trained an OpenNMT model based on our dataset. We\ndetail problems of LLMs and provide in-depth analysis, intending to stimulate\nfurther research and solutions in this largely uncharted territory. Our\nresearch underlines the need to optimize LLMs within the specific field of\nfinancial translation to ensure accuracy and quality.\n","authors":["Yuxin Fu","Shijing Si","Leyi Mai","Xi-ang Li"],"pdf_url":"https://arxiv.org/pdf/2406.18856v1.pdf","comment":"a simplified version of this paper is accepted by International\n  Conference on Asian Language Processing 2024"},{"id":"http://arxiv.org/abs/2402.08466v2","updated":"2024-06-27T02:45:49Z","published":"2024-02-13T13:48:54Z","title":"Taking Training Seriously: Human Guidance and Management-Based\n  Regulation of Artificial Intelligence","summary":"  Fervent calls for more robust governance of the harms associated with\nartificial intelligence (AI) are leading to the adoption around the world of\nwhat regulatory scholars have called a management-based approach to regulation.\nRecent initiatives in the United States and Europe, as well as the adoption of\nmajor self-regulatory standards by the International Organization for\nStandardization, share in common a core management-based paradigm. These\nmanagement-based initiatives seek to motivate an increase in human oversight of\nhow AI tools are trained and developed. Refinements and systematization of\nhuman-guided training techniques will thus be needed to fit within this\nemerging era of management-based regulatory paradigm. If taken seriously,\nhuman-guided training can alleviate some of the technical and ethical pressures\non AI, boosting AI performance with human intuition as well as better\naddressing the needs for fairness and effective explainability. In this paper,\nwe discuss the connection between the emerging management-based regulatory\nframeworks governing AI and the need for human oversight during training. We\nbroadly cover some of the technical components involved in human-guided\ntraining and then argue that the kinds of high-stakes use cases for AI that\nappear of most concern to regulators should lean more on human-guided training\nthan on data-only training. We hope to foster a discussion between legal\nscholars and computer scientists involving how to govern a domain of technology\nthat is vast, heterogenous, and dynamic in its applications and risks.\n","authors":["Cary Coglianese","Colton R. Crum"],"pdf_url":"https://arxiv.org/pdf/2402.08466v2.pdf","comment":"9 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.18851v1","updated":"2024-06-27T02:43:18Z","published":"2024-06-27T02:43:18Z","title":"LICO: Large Language Models for In-Context Molecular Optimization","summary":"  Optimizing black-box functions is a fundamental problem in science and\nengineering. To solve this problem, many approaches learn a surrogate function\nthat estimates the underlying objective from limited historical evaluations.\nLarge Language Models (LLMs), with their strong pattern-matching capabilities\nvia pretraining on vast amounts of data, stand out as a potential candidate for\nsurrogate modeling. However, directly prompting a pretrained language model to\nproduce predictions is not feasible in many scientific domains due to the\nscarcity of domain-specific data in the pretraining corpora and the challenges\nof articulating complex problems in natural language. In this work, we\nintroduce LICO, a general-purpose model that extends arbitrary base LLMs for\nblack-box optimization, with a particular application to the molecular domain.\nTo achieve this, we equip the language model with a separate embedding layer\nand prediction layer, and train the model to perform in-context predictions on\na diverse set of functions defined over the domain. Once trained, LICO can\ngeneralize to unseen molecule properties simply via in-context prompting. LICO\nachieves state-of-the-art performance on PMO, a challenging molecular\noptimization benchmark comprising over 20 objective functions.\n","authors":["Tung Nguyen","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2406.18851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18847v1","updated":"2024-06-27T02:38:13Z","published":"2024-06-27T02:38:13Z","title":"Learning Retrieval Augmentation for Personalized Dialogue Generation","summary":"  Personalized dialogue generation, focusing on generating highly tailored\nresponses by leveraging persona profiles and dialogue context, has gained\nsignificant attention in conversational AI applications. However, persona\nprofiles, a prevalent setting in current personalized dialogue datasets,\ntypically composed of merely four to five sentences, may not offer\ncomprehensive descriptions of the persona about the agent, posing a challenge\nto generate truly personalized dialogues. To handle this problem, we propose\n$\\textbf{L}$earning Retrieval $\\textbf{A}$ugmentation for\n$\\textbf{P}$ersonalized $\\textbf{D}$ial$\\textbf{O}$gue $\\textbf{G}$eneration\n($\\textbf{LAPDOG}$), which studies the potential of leveraging external\nknowledge for persona dialogue generation. Specifically, the proposed LAPDOG\nmodel consists of a story retriever and a dialogue generator. The story\nretriever uses a given persona profile as queries to retrieve relevant\ninformation from the story document, which serves as a supplementary context to\naugment the persona profile. The dialogue generator utilizes both the dialogue\nhistory and the augmented persona profile to generate personalized responses.\nFor optimization, we adopt a joint training framework that collaboratively\nlearns the story retriever and dialogue generator, where the story retriever is\noptimized towards desired ultimate metrics (e.g., BLEU) to retrieve content for\nthe dialogue generator to generate personalized responses. Experiments\nconducted on the CONVAI2 dataset with ROCStory as a supplementary data source\nshow that the proposed LAPDOG method substantially outperforms the baselines,\nindicating the effectiveness of the proposed method. The LAPDOG model code is\npublicly available for further exploration.\nhttps://github.com/hqsiswiliam/LAPDOG\n","authors":["Qiushi Huang","Shuai Fu","Xubo Liu","Wenwu Wang","Tom Ko","Yu Zhang","Lilian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18847v1.pdf","comment":"Accepted to EMNLP-2023"},{"id":"http://arxiv.org/abs/2406.18845v1","updated":"2024-06-27T02:32:46Z","published":"2024-06-27T02:32:46Z","title":"Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion\n  Approach for Event Stream Recognition","summary":"  Existing event stream-based pattern recognition models usually represent the\nevent stream as the point cloud, voxel, image, etc., and design various deep\nneural networks to learn their features. Although considerable results can be\nachieved in simple cases, however, the model performance may be limited by\nmonotonous modality expressions, sub-optimal fusion, and readout mechanisms. In\nthis paper, we propose a novel dual-stream framework for event stream-based\npattern recognition via differentiated fusion, termed EFV++. It models two\ncommon event representations simultaneously, i.e., event images and event\nvoxels. The spatial and three-dimensional stereo information can be learned\nseparately by utilizing Transformer and Graph Neural Network (GNN). We believe\nthe features of each representation still contain both efficient and redundant\nfeatures and a sub-optimal solution may be obtained if we directly fuse them\nwithout differentiation. Thus, we divide each feature into three levels and\nretain high-quality features, blend medium-quality features, and exchange\nlow-quality features. The enhanced dual features will be fed into the fusion\nTransformer together with bottleneck features. In addition, we introduce a\nnovel hybrid interaction readout mechanism to enhance the diversity of features\nas final representations. Extensive experiments demonstrate that our proposed\nframework achieves state-of-the-art performance on multiple widely used event\nstream-based classification datasets. Specifically, we achieve new\nstate-of-the-art performance on the Bullying10k dataset, i.e., $90.51\\%$, which\nexceeds the second place by $+2.21\\%$. The source code of this paper has been\nreleased on\n\\url{https://github.com/Event-AHU/EFV_event_classification/tree/EFVpp}.\n","authors":["Lan Chen","Dong Li","Xiao Wang","Pengpeng Shao","Wei Zhang","Yaowei Wang","Yonghong Tian","Jin Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18845v1.pdf","comment":"In Peer Review, Journal Extension of PRCV 2023"},{"id":"http://arxiv.org/abs/2406.17297v2","updated":"2024-06-27T02:19:51Z","published":"2024-06-25T05:58:34Z","title":"Towards Open-set Camera 3D Object Detection","summary":"  Traditional camera 3D object detectors are typically trained to recognize a\npredefined set of known object classes. In real-world scenarios, these\ndetectors may encounter unknown objects outside the training categories and\nfail to identify them correctly. To address this gap, we present OS-Det3D\n(Open-set Camera 3D Object Detection), a two-stage training framework enhancing\nthe ability of camera 3D detectors to identify both known and unknown objects.\nThe framework involves our proposed 3D Object Discovery Network (ODN3D), which\nis specifically trained using geometric cues such as the location and scale of\n3D boxes to discover general 3D objects. ODN3D is trained in a class-agnostic\nmanner, and the provided 3D object region proposals inherently come with data\nnoise. To boost accuracy in identifying unknown objects, we introduce a Joint\nObjectness Selection (JOS) module. JOS selects the pseudo ground truth for\nunknown objects from the 3D object region proposals of ODN3D by combining the\nODN3D objectness and camera feature attention objectness. Experiments on the\nnuScenes and KITTI datasets demonstrate the effectiveness of our framework in\nenabling camera 3D detectors to successfully identify unknown objects while\nalso improving their performance on known objects.\n","authors":["Zhuolin He","Xinrun Li","Heng Gao","Jiachen Tang","Shoumeng Qiu","Wenfu Wang","Lvjian Lu","Xuchong Qiu","Xiangyang Xue","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2406.17297v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18839v1","updated":"2024-06-27T02:19:38Z","published":"2024-06-27T02:19:38Z","title":"Disentangling Knowledge-based and Visual Reasoning by Question\n  Decomposition in KB-VQA","summary":"  We study the Knowledge-Based visual question-answering problem, for which\ngiven a question, the models need to ground it into the visual modality to find\nthe answer. Although many recent works use question-dependent captioners to\nverbalize the given image and use Large Language Models to solve the VQA\nproblem, the research results show they are not reasonably performing for\nmulti-hop questions. Our study shows that replacing a complex question with\nseveral simpler questions helps to extract more relevant information from the\nimage and provide a stronger comprehension of it. Moreover, we analyze the\ndecomposed questions to find out the modality of the information that is\nrequired to answer them and use a captioner for the visual questions and LLMs\nas a general knowledge source for the non-visual KB-based questions. Our\nresults demonstrate the positive impact of using simple questions before\nretrieving visual or non-visual information. We have provided results and\nanalysis on three well-known VQA datasets including OKVQA, A-OKVQA, and KRVQA,\nand achieved up to 2% improvement in accuracy.\n","authors":["Elham J. Barezi","Parisa Kordjamshidi"],"pdf_url":"https://arxiv.org/pdf/2406.18839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18192v2","updated":"2024-06-27T02:17:19Z","published":"2024-06-26T09:16:08Z","title":"Methodology of Adapting Large English Language Models for Specific\n  Cultural Contexts","summary":"  The rapid growth of large language models(LLMs) has emerged as a prominent\ntrend in the field of artificial intelligence. However, current\nstate-of-the-art LLMs are predominantly based on English. They encounter\nlimitations when directly applied to tasks in specific cultural domains, due to\ndeficiencies in domain-specific knowledge and misunderstandings caused by\ndifferences in cultural values. To address this challenge, our paper proposes a\nrapid adaptation method for large models in specific cultural contexts, which\nleverages instruction-tuning based on specific cultural knowledge and safety\nvalues data. Taking Chinese as the specific cultural context and utilizing the\nLLaMA3-8B as the experimental English LLM, the evaluation results demonstrate\nthat the adapted LLM significantly enhances its capabilities in domain-specific\nknowledge and adaptability to safety values, while maintaining its original\nexpertise advantages.\n","authors":["Wenjing Zhang","Siqi Xiao","Xuejiao Lei","Ning Wang","Huazheng Zhang","Meijuan An","Bikun Yang","Zhaoxiang Liu","Kai Wang","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2406.18192v2.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.12754v2","updated":"2024-06-27T02:03:21Z","published":"2024-05-21T13:04:53Z","title":"Neural Operator for Accelerating Coronal Magnetic Field Model","summary":"  Studying the sun's outer atmosphere is challenging due to its complex\nmagnetic fields impacting solar activities. Magnetohydrodynamics (MHD)\nsimulations help model these interactions but are extremely time-consuming\n(usually on a scale of days). Our research applies the Fourier Neural Operator\n(FNO) to accelerate the coronal magnetic field modeling, specifically, the\nBifrost MHD model. We apply Tensorized FNO (TFNO) to generate solutions from\npartial differential equations (PDEs) over a 3D domain efficiently. TFNO's\nperformance is compared with other deep learning methods, highlighting its\naccuracy and scalability. Physics analysis confirms that TFNO is reliable and\ncapable of accelerating MHD simulations with high precision. This advancement\nimproves efficiency in data handling, enhances predictive capabilities, and\nprovides a better understanding of magnetic topologies.\n","authors":["Yutao Du","Qin Li","Raghav Gnanasambandam","Mengnan Du","Haimin Wang","Bo Shen"],"pdf_url":"https://arxiv.org/pdf/2405.12754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18817v1","updated":"2024-06-27T01:16:44Z","published":"2024-06-27T01:16:44Z","title":"Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised\n  Clustering Analysis","summary":"  This paper presents a novel non-rigid point set registration method that is\ninspired by unsupervised clustering analysis. Unlike previous approaches that\ntreat the source and target point sets as separate entities, we develop a\nholistic framework where they are formulated as clustering centroids and\nclustering members, separately. We then adopt Tikhonov regularization with an\n$\\ell_1$-induced Laplacian kernel instead of the commonly used Gaussian kernel\nto ensure smooth and more robust displacement fields. Our formulation delivers\nclosed-form solutions, theoretical guarantees, independence from dimensions,\nand the ability to handle large deformations. Subsequently, we introduce a\nclustering-improved Nystr\\\"om method to effectively reduce the computational\ncomplexity and storage of the Gram matrix to linear, while providing a rigorous\nbound for the low-rank approximation. Our method achieves high accuracy results\nacross various scenarios and surpasses competitors by a significant margin,\nparticularly on shapes with substantial deformations. Additionally, we\ndemonstrate the versatility of our method in challenging tasks such as shape\ntransfer and medical registration.\n","authors":["Mingyang Zhao","Jingen Jiang","Lei Ma","Shiqing Xin","Gaofeng Meng","Dong-Ming Yan"],"pdf_url":"https://arxiv.org/pdf/2406.18817v1.pdf","comment":"[CVPR 2024 Highlight] Project and code at:\n  https://github.com/zikai1/CVPR24_PointSetReg"},{"id":"http://arxiv.org/abs/2406.18814v1","updated":"2024-06-27T01:08:04Z","published":"2024-06-27T01:08:04Z","title":"Length Optimization in Conformal Prediction","summary":"  Conditional validity and length efficiency are two crucial aspects of\nconformal prediction (CP). Achieving conditional validity ensures accurate\nuncertainty quantification for data subpopulations, while proper length\nefficiency ensures that the prediction sets remain informative and non-trivial.\nDespite significant efforts to address each of these issues individually, a\nprincipled framework that reconciles these two objectives has been missing in\nthe CP literature. In this paper, we develop Conformal Prediction with\nLength-Optimization (CPL) - a novel framework that constructs prediction sets\nwith (near-) optimal length while ensuring conditional validity under various\nclasses of covariate shifts, including the key cases of marginal and\ngroup-conditional coverage. In the infinite sample regime, we provide strong\nduality results which indicate that CPL achieves conditional validity and\nlength optimality. In the finite sample regime, we show that CPL constructs\nconditionally valid prediction sets. Our extensive empirical evaluations\ndemonstrate the superior prediction set size performance of CPL compared to\nstate-of-the-art methods across diverse real-world and synthetic datasets in\nclassification, regression, and text-related settings.\n","authors":["Shayan Kiyani","George Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2406.18814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18812v1","updated":"2024-06-27T00:59:20Z","published":"2024-06-27T00:59:20Z","title":"A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics","summary":"  Industry 4.0 has witnessed the rise of complex robots fueled by the\nintegration of Artificial Intelligence/Machine Learning (AI/ML) and Digital\nTwin (DT) technologies. While these technologies offer numerous benefits, they\nalso introduce potential privacy and security risks. This paper surveys privacy\nattacks targeting robots enabled by AI and DT models. Exfiltration and data\nleakage of ML models are discussed in addition to the potential extraction of\nmodels derived from first-principles (e.g., physics-based). We also discuss\ndesign considerations with DT-integrated robotics touching on the impact of ML\nmodel training, responsible AI and DT safeguards, data governance and ethical\nconsiderations on the effectiveness of these attacks. We advocate for a trusted\nautonomy approach, emphasizing the need to combine robotics, AI, and DT\ntechnologies with robust ethical frameworks and trustworthiness principles for\nsecure and reliable AI robotic systems.\n","authors":["Ivan A. Fernandez","Subash Neupane","Trisha Chakraborty","Shaswata Mitra","Sudip Mittal","Nisha Pillai","Jingdao Chen","Shahram Rahimi"],"pdf_url":"https://arxiv.org/pdf/2406.18812v1.pdf","comment":"10 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2406.18802v1","updated":"2024-06-27T00:21:10Z","published":"2024-06-27T00:21:10Z","title":"All Random Features Representations are Equivalent","summary":"  Random features are an important technique that make it possible to rewrite\npositive-definite kernels as infinite-dimensional dot products. Over time,\nincreasingly elaborate random feature representations have been developed in\npursuit of finite approximations with ever lower error. We resolve this arms\nrace by deriving an optimal sampling policy, and show that under this policy\nall random features representations have the same approximation error. This\nestablishes a lower bound that holds across all random feature representations,\nand shows that we are free to choose whatever representation we please,\nprovided we sample optimally.\n","authors":["Luke Sernau","Silvano Bonacina","Rif A. Saurous"],"pdf_url":"https://arxiv.org/pdf/2406.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18800v1","updated":"2024-06-27T00:15:54Z","published":"2024-06-27T00:15:54Z","title":"Infinite Width Models That Work: Why Feature Learning Doesn't Matter as\n  Much as You Think","summary":"  Common infinite-width architectures such as Neural Tangent Kernels (NTKs)\nhave historically shown weak performance compared to finite models. This has\nbeen attributed to the absence of feature learning. We show that this is not\nthe case. In fact, we show that infinite width NTK models are able to access\nricher features than finite models by selecting relevant subfeatures from their\n(infinite) feature vector. In fact, we show experimentally that NTKs\nunder-perform traditional finite models even when feature learning is\nartificially disabled. Instead, weak performance is due to the fact that\nexisting constructions depend on weak optimizers like SGD. We provide an\ninfinite width limit based on ADAM-like learning dynamics and demonstrate\nempirically that the resulting models erase this performance gap.\n","authors":["Luke Sernau"],"pdf_url":"https://arxiv.org/pdf/2406.18800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19578v1","updated":"2024-06-27T23:43:36Z","published":"2024-06-27T23:43:36Z","title":"PathAlign: A vision-language model for whole slide images in\n  histopathology","summary":"  Microscopic interpretation of histopathology images underlies many important\ndiagnostic and treatment decisions. While advances in vision-language modeling\nraise new opportunities for analysis of such images, the gigapixel-scale size\nof whole slide images (WSIs) introduces unique challenges. Additionally,\npathology reports simultaneously highlight key findings from small regions\nwhile also aggregating interpretation across multiple slides, often making it\ndifficult to create robust image-text pairs. As such, pathology reports remain\na largely untapped source of supervision in computational pathology, with most\nefforts relying on region-of-interest annotations or self-supervision at the\npatch-level. In this work, we develop a vision-language model based on the\nBLIP-2 framework using WSIs paired with curated text from pathology reports.\nThis enables applications utilizing a shared image-text embedding space, such\nas text or image retrieval for finding cases of interest, as well as\nintegration of the WSI encoder with a frozen large language model (LLM) for\nWSI-based generative text capabilities such as report generation or\nAI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000\nWSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure\ntypes, and tissue types. We present pathologist evaluation of text generation\nand text retrieval using WSI embeddings, as well as results for WSI\nclassification and workflow prioritization (slide-level triaging).\nModel-generated text for WSIs was rated by pathologists as accurate, without\nclinically significant error or omission, for 78% of WSIs on average. This work\ndemonstrates exciting potential capabilities for language-aligned WSI\nembeddings.\n","authors":["Faruk Ahmed","Andrew Sellergren","Lin Yang","Shawn Xu","Boris Babenko","Abbi Ward","Niels Olson","Arash Mohtashamian","Yossi Matias","Greg S. Corrado","Quang Duong","Dale R. Webster","Shravya Shetty","Daniel Golden","Yun Liu","David F. Steiner","Ellery Wulczyn"],"pdf_url":"https://arxiv.org/pdf/2406.19578v1.pdf","comment":"9 main pages and 19 pages of supplemental material; 3 main tables, 3\n  main figures and 11 supplemental tables, 7 supplemental figures"},{"id":"http://arxiv.org/abs/2212.12050v3","updated":"2024-06-27T23:43:30Z","published":"2022-12-22T22:00:58Z","title":"A Semantic Framework for Neural-Symbolic Computing","summary":"  Two approaches to AI, neural networks and symbolic systems, have been proven\nvery successful for an array of AI problems. However, neither has been able to\nachieve the general reasoning ability required for human-like intelligence. It\nhas been argued that this is due to inherent weaknesses in each approach.\nLuckily, these weaknesses appear to be complementary, with symbolic systems\nbeing adept at the kinds of things neural networks have trouble with and\nvice-versa. The field of neural-symbolic AI attempts to exploit this asymmetry\nby combining neural networks and symbolic AI into integrated systems. Often\nthis has been done by encoding symbolic knowledge into neural networks.\nUnfortunately, although many different methods for this have been proposed,\nthere is no common definition of an encoding to compare them. We seek to\nrectify this problem by introducing a semantic framework for neural-symbolic\nAI, which is then shown to be general enough to account for a large family of\nneural-symbolic systems. We provide a number of examples and proofs of the\napplication of the framework to the neural encoding of various forms of\nknowledge representation and neural network. These, at first sight disparate\napproaches, are all shown to fall within the framework's formal definition of\nwhat we call semantic encoding for neural-symbolic AI.\n","authors":["Simon Odense","Artur d'Avila Garcez"],"pdf_url":"https://arxiv.org/pdf/2212.12050v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02319v2","updated":"2024-06-27T23:22:14Z","published":"2024-04-02T21:35:54Z","title":"Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient\n  Compile-Time Prompt Optimization","summary":"  In many modern LLM applications, such as retrieval augmented generation,\nprompts have become programs themselves. In these settings, prompt programs are\nrepeatedly called with different user queries or data instances. A big\npractical challenge is optimizing such prompt programs. Recent work has mostly\nfocused on either simple prompt programs or assumed that the general structure\nof a prompt program is fixed.\n  We introduce SAMMO, a framework to perform symbolic prompt program search for\ncompile-time optimizations of prompt programs. SAMMO represents prompt programs\non a symbolic level which allows for a rich set of transformations that can be\nsearched over during optimization. We show that SAMMO generalizes previous\nmethods and improves the performance of complex prompts on (1) instruction\ntuning, (2) RAG pipeline tuning, and (3) prompt compression, across several\ndifferent LLMs. We make all code available open-source at\nhttps://github.com/microsoft/sammo .\n","authors":["Tobias Schnabel","Jennifer Neville"],"pdf_url":"https://arxiv.org/pdf/2404.02319v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19570v1","updated":"2024-06-27T23:15:45Z","published":"2024-06-27T23:15:45Z","title":"Synthetic Cancer -- Augmenting Worms with LLMs","summary":"  With increasingly sophisticated large language models (LLMs), the potential\nfor abuse rises drastically. As a submission to the Swiss AI Safety Prize, we\npresent a novel type of metamorphic malware leveraging LLMs for two key\nprocesses. First, LLMs are used for automatic code rewriting to evade\nsignature-based detection by antimalware programs. The malware then spreads its\ncopies via email by utilizing an LLM to socially engineer email replies to\nencourage recipients to execute the attached malware. Our submission includes a\nfunctional minimal prototype, highlighting the risks that LLMs pose for\ncybersecurity and underscoring the need for further research into intelligent\nmalware.\n","authors":["Benjamin Zimmerman","David Zollikofer"],"pdf_url":"https://arxiv.org/pdf/2406.19570v1.pdf","comment":"Won first place at the Swiss AI Safety Prize. Some technical details\n  omitted, contact authors for more information"},{"id":"http://arxiv.org/abs/2406.19568v1","updated":"2024-06-27T23:03:58Z","published":"2024-06-27T23:03:58Z","title":"What Matters in Detecting AI-Generated Videos like Sora?","summary":"  Recent advancements in diffusion-based video generation have showcased\nremarkable results, yet the gap between synthetic and real-world videos remains\nunder-explored. In this study, we examine this gap from three fundamental\nperspectives: appearance, motion, and geometry, comparing real-world videos\nwith those generated by a state-of-the-art AI model, Stable Video Diffusion. To\nachieve this, we train three classifiers using 3D convolutional networks, each\ntargeting distinct aspects: vision foundation model features for appearance,\noptical flow for motion, and monocular depth for geometry. Each classifier\nexhibits strong performance in fake video detection, both qualitatively and\nquantitatively. This indicates that AI-generated videos are still easily\ndetectable, and a significant gap between real and fake videos persists.\nFurthermore, utilizing the Grad-CAM, we pinpoint systematic failures of\nAI-generated videos in appearance, motion, and geometry. Finally, we propose an\nEnsemble-of-Experts model that integrates appearance, optical flow, and depth\ninformation for fake video detection, resulting in enhanced robustness and\ngeneralization ability. Our model is capable of detecting videos generated by\nSora with high accuracy, even without exposure to any Sora videos during\ntraining. This suggests that the gap between real and fake videos can be\ngeneralized across various video generative models. Project page:\nhttps://justin-crchang.github.io/3DCNNDetection.github.io/\n","authors":["Chirui Chang","Zhengzhe Liu","Xiaoyang Lyu","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2406.19568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13372v4","updated":"2024-06-27T22:44:48Z","published":"2024-03-20T08:08:54Z","title":"LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models","summary":"  Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It provides a\nsolution for flexibly customizing the fine-tuning of 100+ LLMs without the need\nfor coding through the built-in web UI LlamaBoard. We empirically validate the\nefficiency and effectiveness of our framework on language modeling and text\ngeneration tasks. It has been released at\nhttps://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and\n3,000 forks.\n","authors":["Yaowei Zheng","Richong Zhang","Junhao Zhang","Yanhan Ye","Zheyan Luo","Zhangchi Feng","Yongqiang Ma"],"pdf_url":"https://arxiv.org/pdf/2403.13372v4.pdf","comment":"13 pages, accepted to ACL 2024 System Demonstration Track"},{"id":"http://arxiv.org/abs/2406.19561v1","updated":"2024-06-27T22:24:46Z","published":"2024-06-27T22:24:46Z","title":"Meta-Gradient Search Control: A Method for Improving the Efficiency of\n  Dyna-style Planning","summary":"  We study how a Reinforcement Learning (RL) system can remain sample-efficient\nwhen learning from an imperfect model of the environment. This is particularly\nchallenging when the learning system is resource-constrained and in continual\nsettings, where the environment dynamics change. To address these challenges,\nour paper introduces an online, meta-gradient algorithm that tunes a\nprobability with which states are queried during Dyna-style planning. Our study\ncompares the aggregate, empirical performance of this meta-gradient method to\nbaselines that employ conventional sampling strategies. Results indicate that\nour method improves efficiency of the planning process, which, as a\nconsequence, improves the sample-efficiency of the overall learning process. On\nthe whole, we observe that our meta-learned solutions avoid several pathologies\nof conventional planning approaches, such as sampling inaccurate transitions\nand those that stall credit assignment. We believe these findings could prove\nuseful, in future work, for designing model-based RL systems at scale.\n","authors":["Bradley Burega","John D. Martin","Luke Kapeluck","Michael Bowling"],"pdf_url":"https://arxiv.org/pdf/2406.19561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19552v1","updated":"2024-06-27T22:08:22Z","published":"2024-06-27T22:08:22Z","title":"Rethinking harmless refusals when fine-tuning foundation models","summary":"  In this paper, we investigate the degree to which fine-tuning in Large\nLanguage Models (LLMs) effectively mitigates versus merely conceals undesirable\nbehavior. Through the lens of semi-realistic role-playing exercises designed to\nelicit such behaviors, we explore the response dynamics of LLMs post\nfine-tuning interventions. Our methodology involves prompting models for\nChain-of-Thought (CoT) reasoning and analyzing the coherence between the\nreasoning traces and the resultant outputs. Notably, we identify a pervasive\nphenomenon we term \\emph{reason-based deception}, where models either stop\nproducing reasoning traces or produce seemingly ethical reasoning traces that\nbelie the unethical nature of their final outputs. We further examine the\nefficacy of response strategies (polite refusal versus explicit rebuttal) in\ncurbing the occurrence of undesired behavior in subsequent outputs of\nmulti-turn interactions. Our findings reveal that explicit rebuttals\nsignificantly outperform polite refusals in preventing the continuation of\nundesired outputs and nearly eliminate reason-based deception, challenging\ncurrent practices in model fine-tuning. Accordingly, the two key contributions\nof this paper are (1) defining and studying reason-based deception, a new type\nof hidden behavior, and (2) demonstrating that rebuttals provide a more robust\nresponse model to harmful requests than refusals, thereby highlighting the need\nto reconsider the response strategies in fine-tuning approaches.\n","authors":["Florin Pop","Judd Rosenblatt","Diogo Schwerz de Lucena","Michael Vaiana"],"pdf_url":"https://arxiv.org/pdf/2406.19552v1.pdf","comment":"ICLR 2024 AGI Workshop Poster"},{"id":"http://arxiv.org/abs/2406.09606v2","updated":"2024-06-27T22:06:19Z","published":"2024-06-13T22:34:58Z","title":"Cross-Modality Program Representation Learning for Electronic Design\n  Automation with High-Level Synthesis","summary":"  In recent years, domain-specific accelerators (DSAs) have gained popularity\nfor applications such as deep learning and autonomous driving. To facilitate\nDSA designs, programmers use high-level synthesis (HLS) to compile a high-level\ndescription written in C/C++ into a design with low-level hardware description\nlanguages that eventually synthesize DSAs on circuits. However, creating a\nhigh-quality HLS design still demands significant domain knowledge,\nparticularly in microarchitecture decisions expressed as \\textit{pragmas}.\nThus, it is desirable to automate such decisions with the help of machine\nlearning for predicting the quality of HLS designs, requiring a deeper\nunderstanding of the program that consists of original code and pragmas.\nNaturally, these programs can be considered as sequence data. In addition,\nthese programs can be compiled and converted into a control data flow graph\n(CDFG). But existing works either fail to leverage both modalities or combine\nthe two in shallow or coarse ways. We propose ProgSG, a model that allows\ninteraction between the source code sequence modality and the graph modality in\na deep and fine-grained way. To alleviate the scarcity of labeled designs, a\npre-training method is proposed based on a suite of compiler's data flow\nanalysis tasks. Experimental results show that ProgSG reduces the RMSE of\ndesign performance predictions by up to $22\\%$, and identifies designs with an\naverage of $1.10\\times$ and $1.26\\times$ (up to $8.17\\times$ and $13.31\\times$)\nperformance improvement in design space exploration (DSE) task compared to HARP\nand AutoDSE, respectively.\n","authors":["Zongyue Qin","Yunsheng Bai","Atefeh Sohrabizadeh","Zijian Ding","Ziniu Hu","Yizhou Sun","Jason Cong"],"pdf_url":"https://arxiv.org/pdf/2406.09606v2.pdf","comment":"14 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2305.10838"},{"id":"http://arxiv.org/abs/2404.05891v2","updated":"2024-06-27T21:54:40Z","published":"2024-04-08T22:20:23Z","title":"Condition Monitoring with Incomplete Data: An Integrated Variational\n  Autoencoder and Distance Metric Framework","summary":"  Condition monitoring of industrial systems is crucial for ensuring safety and\nmaintenance planning, yet notable challenges arise in real-world settings due\nto the limited or non-existent availability of fault samples. This paper\nintroduces an innovative solution to this problem by proposing a new method for\nfault detection and condition monitoring for unseen data. Adopting an approach\ninspired by zero-shot learning, our method can identify faults and assign a\nrelative health index to various operational conditions. Typically, we have\nplenty of data on normal operations, some data on compromised conditions, and\nvery few (if any) samples of severe faults. We use a variational autoencoder to\ncapture the probabilistic distribution of previously seen and new unseen\nconditions. The health status is determined by comparing each sample's\ndeviation from a normal operation reference distribution in the latent space.\nFaults are detected by establishing a threshold for the health indexes,\nallowing the model to identify severe, unseen faults with high accuracy, even\namidst noise. We validate our approach using the run-to-failure IMS-bearing\ndataset and compare it with other methods. The health indexes generated by our\nmodel closely match the established descriptive model of bearing wear,\nattesting to the robustness and reliability of our method. These findings\nhighlight the potential of our methodology in augmenting fault detection\ncapabilities within industrial domains, thereby contributing to heightened\nsafety protocols and optimized maintenance practices.\n","authors":["Maryam Ahang","Mostafa Abbasi","Todd Charter","Homayoun Najjaran"],"pdf_url":"https://arxiv.org/pdf/2404.05891v2.pdf","comment":"Accepted in the 2024 IEEE 20th International Conference on Automation\n  Science and Engineering (CASE 2024)"},{"id":"http://arxiv.org/abs/2406.19545v1","updated":"2024-06-27T21:47:42Z","published":"2024-06-27T21:47:42Z","title":"Leveraging Machine-Generated Rationales to Facilitate Social Meaning\n  Detection in Conversations","summary":"  We present a generalizable classification approach that leverages Large\nLanguage Models (LLMs) to facilitate the detection of implicitly encoded social\nmeaning in conversations. We design a multi-faceted prompt to extract a textual\nexplanation of the reasoning that connects visible cues to underlying social\nmeanings. These extracted explanations or rationales serve as augmentations to\nthe conversational text to facilitate dialogue understanding and transfer. Our\nempirical results over 2,340 experimental settings demonstrate the significant\npositive impact of adding these rationales. Our findings hold true for\nin-domain classification, zero-shot, and few-shot domain transfer for two\ndifferent social meaning detection tasks, each spanning two different corpora.\n","authors":["Ritam Dutt","Zhen Wu","Kelly Shi","Divyanshu Sheth","Prakhar Gupta","Carolyn Penstein Rose"],"pdf_url":"https://arxiv.org/pdf/2406.19545v1.pdf","comment":"To appear at The Proceedings of the Association for Computational\n  Linguistics, 2024"},{"id":"http://arxiv.org/abs/2406.19537v1","updated":"2024-06-27T21:21:22Z","published":"2024-06-27T21:21:22Z","title":"Handling Ontology Gaps in Semantic Parsing","summary":"  The majority of Neural Semantic Parsing (NSP) models are developed with the\nassumption that there are no concepts outside the ones such models can\nrepresent with their target symbols (closed-world assumption). This assumption\nleads to generate hallucinated outputs rather than admitting their lack of\nknowledge. Hallucinations can lead to wrong or potentially offensive responses\nto users. Hence, a mechanism to prevent this behavior is crucial to build\ntrusted NSP-based Question Answering agents. To that end, we propose the\nHallucination Simulation Framework (HSF), a general setting for stimulating and\nanalyzing NSP model hallucinations. The framework can be applied to any NSP\ntask with a closed-ontology. Using the proposed framework and KQA Pro as the\nbenchmark dataset, we assess state-of-the-art techniques for hallucination\ndetection. We then present a novel hallucination detection strategy that\nexploits the computational graph of the NSP model to detect the NSP\nhallucinations in the presence of ontology gaps, out-of-domain utterances, and\nto recognize NSP errors, improving the F1-Score respectively by ~21, ~24% and\n~1%. This is the first work in closed-ontology NSP that addresses the problem\nof recognizing ontology gaps. We release our code and checkpoints at\nhttps://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing.\n","authors":["Andrea Bacciu","Marco Damonte","Marco Basaldella","Emilio Monti"],"pdf_url":"https://arxiv.org/pdf/2406.19537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19528v1","updated":"2024-06-27T21:03:56Z","published":"2024-06-27T21:03:56Z","title":"Using Large Language Models to Assist Video Content Analysis: An\n  Exploratory Study of Short Videos on Depression","summary":"  Despite the growing interest in leveraging Large Language Models (LLMs) for\ncontent analysis, current studies have primarily focused on text-based content.\nIn the present work, we explored the potential of LLMs in assisting video\ncontent analysis by conducting a case study that followed a new workflow of\nLLM-assisted multimodal content analysis. The workflow encompasses codebook\ndesign, prompt engineering, LLM processing, and human evaluation. We\nstrategically crafted annotation prompts to get LLM Annotations in structured\nform and explanation prompts to generate LLM Explanations for a better\nunderstanding of LLM reasoning and transparency. To test LLM's video annotation\ncapabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos\nabout depression. We compared the LLM Annotations with those of two human\ncoders and found that LLM has higher accuracy in object and activity\nAnnotations than emotion and genre Annotations. Moreover, we identified the\npotential and limitations of LLM's capabilities in annotating videos. Based on\nthe findings, we explore opportunities and challenges for future research and\nimprovements to the workflow. We also discuss ethical concerns surrounding\nfuture studies based on LLM-assisted video analysis.\n","authors":["Jiaying Liu","Yunlong Wang","Yao Lyu","Yiheng Su","Shuo Niu","Xuhai \"Orson\" Xu","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19528v1.pdf","comment":"6 pages, 2 figures, under review in CSCW 24"},{"id":"http://arxiv.org/abs/2406.19512v1","updated":"2024-06-27T20:18:18Z","published":"2024-06-27T20:18:18Z","title":"Captioning Visualizations with Large Language Models (CVLLM): A Tutorial","summary":"  Automatically captioning visualizations is not new, but recent advances in\nlarge language models(LLMs) open exciting new possibilities. In this tutorial,\nafter providing a brief review of Information Visualization (InfoVis)\nprinciples and past work in captioning, we introduce neural models and the\ntransformer architecture used in generic LLMs. We then discuss their recent\napplications in InfoVis, with a focus on captioning. Additionally, we explore\npromising future directions in this field.\n","authors":["Giuseppe Carenini","Jordon Johnson","Ali Salamatian"],"pdf_url":"https://arxiv.org/pdf/2406.19512v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.19507v1","updated":"2024-06-27T19:58:11Z","published":"2024-06-27T19:58:11Z","title":"Too Good to be True? Turn Any Model Differentially Private With\n  DP-Weights","summary":"  Imagine training a machine learning model with Differentially Private\nStochastic Gradient Descent (DP-SGD), only to discover post-training that the\nnoise level was either too high, crippling your model's utility, or too low,\ncompromising privacy. The dreaded realization hits: you must start the lengthy\ntraining process from scratch. But what if you could avoid this retraining\nnightmare? In this study, we introduce a groundbreaking approach (to our\nknowledge) that applies differential privacy noise to the model's weights after\ntraining. We offer a comprehensive mathematical proof for this novel approach's\nprivacy bounds, use formal methods to validate its privacy guarantees, and\nempirically evaluate its effectiveness using membership inference attacks and\nperformance evaluations. This method allows for a single training run, followed\nby post-hoc noise adjustments to achieve optimal privacy-utility trade-offs. We\ncompare this novel fine-tuned model (DP-Weights model) to a traditional DP-SGD\nmodel, demonstrating that our approach yields statistically similar performance\nand privacy guarantees. Our results validate the efficacy of post-training\nnoise application, promising significant time savings and flexibility in\nfine-tuning differential privacy parameters, making it a practical alternative\nfor deploying differentially private models in real-world scenarios.\n","authors":["David Zagardo"],"pdf_url":"https://arxiv.org/pdf/2406.19507v1.pdf","comment":"For code visit the following repository,\n  https://github.com/dzagardo/forgetnet/"},{"id":"http://arxiv.org/abs/2406.19502v1","updated":"2024-06-27T19:29:36Z","published":"2024-06-27T19:29:36Z","title":"Investigating How Large Language Models Leverage Internal Knowledge to\n  Perform Complex Reasoning","summary":"  Despite significant advancements, there is a limited understanding of how\nlarge language models (LLMs) utilize knowledge for reasoning. To address this,\nwe propose a method that deconstructs complex real-world questions into a\ngraph, representing each question as a node with parent nodes of background\nknowledge needed to solve the question. We develop the DepthQA dataset,\ndeconstructing questions into three depths: (i) recalling conceptual knowledge,\n(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.\nBased on a hierarchical graph, we quantify forward discrepancy, discrepancies\nin LLMs' performance on simpler sub-problems versus complex questions. We also\nmeasure backward discrepancy, where LLMs answer complex questions but struggle\nwith simpler ones. Our analysis shows that smaller models have more\ndiscrepancies than larger models. Additionally, guiding models from simpler to\ncomplex questions through multi-turn interactions improves performance across\nmodel sizes, highlighting the importance of structured intermediate steps in\nknowledge reasoning. This work enhances our understanding of LLM reasoning and\nsuggests ways to improve their problem-solving abilities.\n","authors":["Miyoung Ko","Sue Hyun Park","Joonsuk Park","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2406.19502v1.pdf","comment":"Work in progress; code is available at\n  https://github.com/kaistAI/knowledge-reasoning"},{"id":"http://arxiv.org/abs/2406.19500v1","updated":"2024-06-27T19:28:42Z","published":"2024-06-27T19:28:42Z","title":"Knowledge acquisition for dialogue agents using reinforcement learning\n  on graph representations","summary":"  We develop an artificial agent motivated to augment its knowledge base beyond\nits initial training. The agent actively participates in dialogues with other\nagents, strategically acquiring new information. The agent models its knowledge\nas an RDF knowledge graph, integrating new beliefs acquired through\nconversation. Responses in dialogue are generated by identifying graph patterns\naround these new integrated beliefs. We show that policies can be learned using\nreinforcement learning to select effective graph patterns during an\ninteraction, without relying on explicit user feedback. Within this context,\nour study is a proof of concept for leveraging users as effective sources of\ninformation.\n","authors":["Selene Baez Santamaria","Shihan Wang","Piek Vossen"],"pdf_url":"https://arxiv.org/pdf/2406.19500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19497v1","updated":"2024-06-27T19:26:11Z","published":"2024-06-27T19:26:11Z","title":"Inclusivity in Large Language Models: Personality Traits and Gender Bias\n  in Scientific Abstracts","summary":"  Large language models (LLMs) are increasingly utilized to assist in\nscientific and academic writing, helping authors enhance the coherence of their\narticles. Previous studies have highlighted stereotypes and biases present in\nLLM outputs, emphasizing the need to evaluate these models for their alignment\nwith human narrative styles and potential gender biases. In this study, we\nassess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large,\nand Gemini 1.5 Flash - by analyzing their performance on benchmark\ntext-generation tasks for scientific abstracts. We employ the Linguistic\nInquiry and Word Count (LIWC) framework to extract lexical, psychological, and\nsocial features from the generated texts. Our findings indicate that, while\nthese models generally produce text closely resembling human authored content,\nvariations in stylistic features suggest significant gender biases. This\nresearch highlights the importance of developing LLMs that maintain a diversity\nof writing styles to promote inclusivity in academic discourse.\n","authors":["Naseela Pervez","Alexander J. Titus"],"pdf_url":"https://arxiv.org/pdf/2406.19497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19493v1","updated":"2024-06-27T19:20:09Z","published":"2024-06-27T19:20:09Z","title":"Development and Evaluation of a Retrieval-Augmented Generation Tool for\n  Creating SAPPhIRE Models of Artificial Systems","summary":"  Representing systems using the SAPPhIRE causality model is found useful in\nsupporting design-by-analogy. However, creating a SAPPhIRE model of artificial\nor biological systems is an effort-intensive process that requires human\nexperts to source technical knowledge from multiple technical documents\nregarding how the system works. This research investigates how to leverage\nLarge Language Models (LLMs) in creating structured descriptions of systems\nusing the SAPPhIRE model of causality. This paper, the second part of the\ntwo-part research, presents a new Retrieval-Augmented Generation (RAG) tool for\ngenerating information related to SAPPhIRE constructs of artificial systems and\nreports the results from a preliminary evaluation of the tool's success -\nfocusing on the factual accuracy and reliability of outcomes.\n","authors":["Anubhab Majumder","Kausik Bhattacharya","Amaresh Chakrabarti"],"pdf_url":"https://arxiv.org/pdf/2406.19493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02681v2","updated":"2024-06-27T19:06:32Z","published":"2024-02-05T02:35:11Z","title":"Equivariant Symmetry Breaking Sets","summary":"  Equivariant neural networks (ENNs) have been shown to be extremely effective\nin applications involving underlying symmetries. By construction ENNs cannot\nproduce lower symmetry outputs given a higher symmetry input. However, symmetry\nbreaking occurs in many physical systems and we may obtain a less symmetric\nstable state from an initial highly symmetric one. Hence, it is imperative that\nwe understand how to systematically break symmetry in ENNs. In this work, we\npropose a novel symmetry breaking framework that is fully equivariant and is\nthe first which fully addresses spontaneous symmetry breaking. We emphasize\nthat our approach is general and applicable to equivariance under any group. To\nachieve this, we introduce the idea of symmetry breaking sets (SBS). Rather\nthan redesign existing networks, we design sets of symmetry breaking objects\nwhich we feed into our network based on the symmetry of our inputs and outputs.\nWe show there is a natural way to define equivariance on these sets, which\ngives an additional constraint. Minimizing the size of these sets equates to\ndata efficiency. We prove that minimizing these sets translates to a well\nstudied group theory problem, and tabulate solutions to this problem for the\npoint groups. Finally, we provide some examples of symmetry breaking to\ndemonstrate how our approach works in practice.\n","authors":["YuQing Xie","Tess Smidt"],"pdf_url":"https://arxiv.org/pdf/2402.02681v2.pdf","comment":"43 pages, 18 figures"},{"id":"http://arxiv.org/abs/2406.19486v1","updated":"2024-06-27T19:02:41Z","published":"2024-06-27T19:02:41Z","title":"LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models","summary":"  In prompt tuning, a prefix or suffix text is added to the prompt, and the\nembeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix\nare optimized to gain more control over language models for specific tasks.\nThis approach eliminates the need for hand-crafted prompt engineering or\nexplicit model fine-tuning. Prompt tuning is significantly more\nparameter-efficient than model fine-tuning, as it involves optimizing partial\ninputs of language models to produce desired outputs.\n  In this work, we aim to further reduce the amount of trainable parameters\nrequired for a language model to perform well on specific tasks. We propose\nLow-rank Prompt Tuning (LoPT), a low-rank model for prompts that achieves\nefficient prompt optimization. The proposed method demonstrates similar\noutcomes to full parameter prompt tuning while reducing the number of trainable\nparameters by a factor of 5. It also provides promising results compared to the\nstate-of-the-art methods that would require 10 to 20 times more parameters.\n","authors":["Shouchang Guo","Sonam Damani","Keng-hao Chang"],"pdf_url":"https://arxiv.org/pdf/2406.19486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19478v1","updated":"2024-06-27T18:43:51Z","published":"2024-06-27T18:43:51Z","title":"Sparse Regression for Machine Translation","summary":"  We use transductive regression techniques to learn mappings between source\nand target features of given parallel corpora and use these mappings to\ngenerate machine translation outputs. We show the effectiveness of $L_1$\nregularized regression (\\textit{lasso}) to learn the mappings between sparsely\nobserved feature sets versus $L_2$ regularized regression. Proper selection of\ntraining instances plays an important role to learn correct feature mappings\nwithin limited computational resources and at expected accuracy levels. We\nintroduce \\textit{dice} instance selection method for proper selection of\ntraining instances, which plays an important role to learn correct feature\nmappings for improving the source and target coverage of the training set. We\nshow that $L_1$ regularized regression performs better than $L_2$ regularized\nregression both in regression measurements and in the translation experiments\nusing graph decoding. We present encouraging results when translating from\nGerman to English and Spanish to English. We also demonstrate results when the\nphrase table of a phrase-based decoder is replaced with the mappings we find\nwith the regression model.\n","authors":["Ergun Biçici"],"pdf_url":"https://arxiv.org/pdf/2406.19478v1.pdf","comment":"8 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2305.14752v2","updated":"2024-06-27T18:40:19Z","published":"2023-05-24T05:54:10Z","title":"A New Era in Software Security: Towards Self-Healing Software via Large\n  Language Models and Formal Verification","summary":"  This paper introduces an innovative approach that combines Large Language\nModels (LLMs) with Formal Verification strategies for automatic software\nvulnerability repair. Initially, we employ Bounded Model Checking (BMC) to\nidentify vulnerabilities and extract counterexamples. These counterexamples are\nsupported by mathematical proofs and the stack trace of the vulnerabilities.\nUsing a specially designed prompt, we combine the original source code with the\nidentified vulnerability, including its stack trace and counterexample that\nspecifies the line number and error type. This combined information is then fed\ninto an LLM, which is instructed to attempt to fix the code. The new code is\nsubsequently verified again using BMC to ensure the fix succeeded. We present\nthe ESBMC-AI framework as a proof of concept, leveraging the well-recognized\nand industry-adopted Efficient SMT-based Context-Bounded Model Checker (ESBMC)\nand a pre-trained transformer model to detect and fix errors in C programs,\nparticularly in critical software components. We evaluated our approach on\n50,000 C programs randomly selected from the FormAI dataset with their\nrespective vulnerability classifications. Our results demonstrate ESBMC-AI's\ncapability to automate the detection and repair of issues such as buffer\noverflow, arithmetic overflow, and pointer dereference failures with high\naccuracy. ESBMC-AI is a pioneering initiative, integrating LLMs with BMC\ntechniques, offering potential integration into the continuous integration and\ndeployment (CI/CD) process within the software development lifecycle.\n","authors":["Norbert Tihanyi","Ridhi Jain","Yiannis Charalambous","Mohamed Amine Ferrag","Youcheng Sun","Lucas C. Cordeiro"],"pdf_url":"https://arxiv.org/pdf/2305.14752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17073v2","updated":"2024-06-27T18:15:16Z","published":"2024-06-24T18:59:24Z","title":"Meta-GCN: A Dynamically Weighted Loss Minimization Method for Dealing\n  with the Data Imbalance in Graph Neural Networks","summary":"  Although many real-world applications, such as disease prediction, and fault\ndetection suffer from class imbalance, most existing graph-based classification\nmethods ignore the skewness of the distribution of classes; therefore, tend to\nbe biased towards the majority class(es). Conventional methods typically tackle\nthis problem through the assignment of weights to each one of the class samples\nbased on a function of their loss, which can lead to over-fitting on outliers.\nIn this paper, we propose a meta-learning algorithm, named Meta-GCN, for\nadaptively learning the example weights by simultaneously minimizing the\nunbiased meta-data set loss and optimizing the model weights through the use of\na small unbiased meta-data set. Through experiments, we have shown that\nMeta-GCN outperforms state-of-the-art frameworks and other baselines in terms\nof accuracy, the area under the receiver operating characteristic (AUC-ROC)\ncurve, and macro F1-Score for classification tasks on two different datasets.\n","authors":["Mahdi Mohammadizadeh","Arash Mozhdehi","Yani Ioannou","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17073v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03832v2","updated":"2024-06-27T18:14:03Z","published":"2024-05-06T20:30:14Z","title":"Guylingo: The Republic of Guyana Creole Corpora","summary":"  While major languages often enjoy substantial attention and resources, the\nlinguistic diversity across the globe encompasses a multitude of smaller,\nindigenous, and regional languages that lack the same level of computational\nsupport. One such region is the Caribbean. While commonly labeled as \"English\nspeaking\", the ex-British Caribbean region consists of a myriad of Creole\nlanguages thriving alongside English. In this paper, we present Guylingo: a\ncomprehensive corpus designed for advancing NLP research in the domain of\nCreolese (Guyanese English-lexicon Creole), the most widely spoken language in\nthe culturally rich nation of Guyana. We first outline our framework for\ngathering and digitizing this diverse corpus, inclusive of colloquial\nexpressions, idioms, and regional variations in a low-resource language. We\nthen demonstrate the challenges of training and evaluating NLP models for\nmachine translation in Creole. Lastly, we discuss the unique opportunities\npresented by recent NLP advancements for accelerating the formal adoption of\nCreole languages as official languages in the Caribbean.\n","authors":["Christopher Clarke","Roland Daynauth","Charlene Wilkinson","Hubert Devonish","Jason Mars"],"pdf_url":"https://arxiv.org/pdf/2405.03832v2.pdf","comment":"Accepted to NAACL 2024 Main Conference Special Theme Track: Languages\n  of Latin America and The Caribbean"},{"id":"http://arxiv.org/abs/2406.19464v1","updated":"2024-06-27T18:06:38Z","published":"2024-06-27T18:06:38Z","title":"ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data","summary":"  Audio signals provide rich information for the robot interaction and object\nproperties through contact. These information can surprisingly ease the\nlearning of contact-rich robot manipulation skills, especially when the visual\ninformation alone is ambiguous or incomplete. However, the usage of audio data\nin robot manipulation has been constrained to teleoperated demonstrations\ncollected by either attaching a microphone to the robot or object, which\nsignificantly limits its usage in robot learning pipelines. In this work, we\nintroduce ManiWAV: an 'ear-in-hand' data collection device to collect\nin-the-wild human demonstrations with synchronous audio and visual feedback,\nand a corresponding policy interface to learn robot manipulation policy\ndirectly from the demonstrations. We demonstrate the capabilities of our system\nthrough four contact-rich manipulation tasks that require either passively\nsensing the contact events and modes, or actively sensing the object surface\nmaterials and states. In addition, we show that our system can generalize to\nunseen in-the-wild environments, by learning from diverse in-the-wild human\ndemonstrations. Project website: https://mani-wav.github.io/\n","authors":["Zeyi Liu","Cheng Chi","Eric Cousineau","Naveen Kuppuswamy","Benjamin Burchfiel","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2406.19464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14572v2","updated":"2024-06-27T18:00:31Z","published":"2024-06-13T17:53:29Z","title":"Bioptic -- A Target-Agnostic Efficacy-Based Small Molecules Search\n  Engine","summary":"  Recent successes in virtual screening have been made possible by large models\nand extensive chemical libraries. However, combining these elements is\nchallenging: the larger the model, the more expensive it is to run, making\nultra-large libraries unfeasible. To address this, we developed a\ntarget-agnostic, efficacy-based molecule search model, which allows us to find\nstructurally dissimilar molecules with similar biological activities. We used\nthe best practices to design fast retrieval system, based on\nprocessor-optimized SIMD instructions, enabling us to screen the ultra-large\n40B Enamine REAL library with 100\\% recall rate. We extensively benchmarked our\nmodel and several state-of-the-art models for both speed performance and\nretrieval quality of novel molecules.\n","authors":["Vlad Vinogradov","Ivan Izmailov","Simon Steshin","Kong T. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2406.14572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19434v1","updated":"2024-06-27T17:59:05Z","published":"2024-06-27T17:59:05Z","title":"Lightweight Predictive 3D Gaussian Splats","summary":"  Recent approaches representing 3D objects and scenes using Gaussian splats\nshow increased rendering speed across a variety of platforms and devices. While\nrendering such representations is indeed extremely efficient, storing and\ntransmitting them is often prohibitively expensive. To represent large-scale\nscenes, one often needs to store millions of 3D Gaussians, occupying gigabytes\nof disk space. This poses a very practical limitation, prohibiting widespread\nadoption.Several solutions have been proposed to strike a balance between disk\nsize and rendering quality, noticeably reducing the visual quality. In this\nwork, we propose a new representation that dramatically reduces the hard drive\nfootprint while featuring similar or improved quality when compared to the\nstandard 3D Gaussian splats. When compared to other compact solutions, ours\noffers higher quality renderings with significantly reduced storage, being able\nto efficiently run on a mobile device in real-time. Our key observation is that\nnearby points in the scene can share similar representations. Hence, only a\nsmall ratio of 3D points needs to be stored. We introduce an approach to\nidentify such points which are called parent points. The discarded points\ncalled children points along with attributes can be efficiently predicted by\ntiny MLPs.\n","authors":["Junli Cao","Vidit Goel","Chaoyang Wang","Anil Kag","Ju Hu","Sergei Korolev","Chenfanfu Jiang","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2406.19434v1.pdf","comment":"Project Page: https://plumpuddings.github.io/LPGS//"},{"id":"http://arxiv.org/abs/2307.08564v2","updated":"2024-06-27T17:18:10Z","published":"2023-07-17T15:31:58Z","title":"Shaping New Norms for AI","summary":"  As Artificial Intelligence (AI) becomes increasingly integrated into our\nlives, the need for new norms is urgent. However, AI evolves at a much faster\npace than the characteristic time of norm formation, posing an unprecedented\nchallenge to our societies. This paper examines possible criticalities of the\nprocesses of norm formation surrounding AI. Thus, it focuses on how new norms\ncan be established, rather than on what these norms should be. It distinguishes\ndifferent scenarios based on the centralisation or decentralisation of the norm\nformation process, analysing the cases where new norms are shaped by formal\nauthorities, informal institutions, or emerge spontaneously in a bottom-up\nfashion. On the latter point, the paper reports a conversation with ChatGPT in\nwhich the LLM discusses some of the emerging norms it has observed. Far from\nseeking exhaustiveness, this article aims to offer readers interpretive tools\nto understand society's response to the growing pervasiveness of AI. An outlook\non how AI could influence the formation of future social norms emphasises the\nimportance for open societies to anchor their formal deliberation process in an\nopen, inclusive, and transparent public discourse.\n","authors":["Andrea Baronchelli"],"pdf_url":"https://arxiv.org/pdf/2307.08564v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.19395v1","updated":"2024-06-27T17:59:53Z","published":"2024-06-27T17:59:53Z","title":"Dataset Size Recovery from LoRA Weights","summary":"  Model inversion and membership inference attacks aim to reconstruct and\nverify the data which a model was trained on. However, they are not guaranteed\nto find all training samples as they do not know the size of the training set.\nIn this paper, we introduce a new task: dataset size recovery, that aims to\ndetermine the number of samples used to train a model, directly from its\nweights. We then propose DSiRe, a method for recovering the number of images\nused to fine-tune a model, in the common case where fine-tuning uses LoRA. We\ndiscover that both the norm and the spectrum of the LoRA matrices are closely\nlinked to the fine-tuning dataset size; we leverage this finding to propose a\nsimple yet effective prediction algorithm. To evaluate dataset size recovery of\nLoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of\nover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.\nOur best classifier can predict the number of fine-tuning images with a mean\nabsolute error of 0.36 images, establishing the feasibility of this attack.\n","authors":["Mohammad Salama","Jonathan Kahana","Eliahu Horwitz","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2406.19395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19394v1","updated":"2024-06-27T17:59:49Z","published":"2024-06-27T17:59:49Z","title":"HUWSOD: Holistic Self-training for Unified Weakly Supervised Object\n  Detection","summary":"  Most WSOD methods rely on traditional object proposals to generate candidate\nregions and are confronted with unstable training, which easily gets stuck in a\npoor local optimum. In this paper, we introduce a unified, high-capacity weakly\nsupervised object detection (WSOD) network called HUWSOD, which utilizes a\ncomprehensive self-training framework without needing external modules or\nadditional supervision. HUWSOD innovatively incorporates a self-supervised\nproposal generator and an autoencoder proposal generator with a multi-rate\nresampling pyramid to replace traditional object proposals, enabling end-to-end\nWSOD training and inference. Additionally, we implement a holistic\nself-training scheme that refines detection scores and coordinates through\nstep-wise entropy minimization and consistency-constraint regularization,\nensuring consistent predictions across stochastic augmentations of the same\nimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD\ncompetes with state-of-the-art WSOD methods, eliminating the need for offline\nproposals and additional data. The peak performance of HUWSOD approaches that\nof fully-supervised Faster R-CNN. Our findings also indicate that randomly\ninitialized boxes, although significantly different from well-designed offline\nobject proposals, are effective for WSOD training.\n","authors":["Liujuan Cao","Jianghang Lin","Zebo Hong","Yunhang Shen","Shaohui Lin","Chao Chen","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2406.19394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19393v1","updated":"2024-06-27T17:59:46Z","published":"2024-06-27T17:59:46Z","title":"Looking 3D: Anomaly Detection with 2D-3D Alignment","summary":"  Automatic anomaly detection based on visual cues holds practical significance\nin various domains, such as manufacturing and product quality assessment. This\npaper introduces a new conditional anomaly detection problem, which involves\nidentifying anomalies in a query image by comparing it to a reference shape. To\naddress this challenge, we have created a large dataset, BrokenChairs-180K,\nconsisting of around 180K images, with diverse anomalies, geometries, and\ntextures paired with 8,143 reference 3D shapes. To tackle this task, we have\nproposed a novel transformer-based approach that explicitly learns the\ncorrespondence between the query image and reference 3D shape via feature\nalignment and leverages a customized attention mechanism for anomaly detection.\nOur approach has been rigorously evaluated through comprehensive experiments,\nserving as a benchmark for future research in this domain.\n","authors":["Ankan Bhunia","Changjian Li","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2406.19393v1.pdf","comment":"Accepted at CVPR'24. Codes & dataset available at\n  https://github.com/VICO-UoE/Looking3D"},{"id":"http://arxiv.org/abs/2406.19392v1","updated":"2024-06-27T17:59:45Z","published":"2024-06-27T17:59:45Z","title":"ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos","summary":"  We introduce ReXTime, a benchmark designed to rigorously test AI models'\nability to perform temporal reasoning within video events. Specifically,\nReXTime focuses on reasoning across time, i.e. human-like understanding when\nthe question and its corresponding answer occur in different video segments.\nThis form of reasoning, requiring advanced understanding of cause-and-effect\nrelationships across video segments, poses significant challenges to even the\nfrontier multimodal large language models. To facilitate this evaluation, we\ndevelop an automated pipeline for generating temporal reasoning question-answer\npairs, significantly reducing the need for labor-intensive manual annotations.\nOur benchmark includes 921 carefully vetted validation samples and 2,143 test\nsamples, each manually curated for accuracy and relevance. Evaluation results\nshow that while frontier large language models outperform academic models, they\nstill lag behind human performance by a significant 14.3% accuracy gap.\nAdditionally, our pipeline creates a training dataset of 9,695 machine\ngenerated samples without manual effort, which empirical studies suggest can\nenhance the across-time reasoning via fine-tuning.\n","authors":["Jr-Jen Chen","Yu-Chien Liao","Hsi-Che Lin","Yu-Chu Yu","Yen-Chun Chen","Yu-Chiang Frank Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19391v1","updated":"2024-06-27T17:59:40Z","published":"2024-06-27T17:59:40Z","title":"Fibottention: Inceptive Visual Representation Learning with Diverse\n  Attention Across Heads","summary":"  Visual perception tasks are predominantly solved by Vision Transformer (ViT)\narchitectures, which, despite their effectiveness, encounter a computational\nbottleneck due to the quadratic complexity of computing self-attention. This\ninefficiency is largely due to the self-attention heads capturing redundant\ntoken interactions, reflecting inherent redundancy within visual data. Many\nworks have aimed to reduce the computational complexity of self-attention in\nViTs, leading to the development of efficient and sparse transformer\narchitectures. In this paper, viewing through the efficiency lens, we realized\nthat introducing any sparse self-attention strategy in ViTs can keep the\ncomputational overhead low. However, these strategies are sub-optimal as they\noften fail to capture fine-grained visual details. This observation leads us to\npropose a general, efficient, sparse architecture, named Fibottention, for\napproximating self-attention with superlinear complexity that is built upon\nFibonacci sequences. The key strategies in Fibottention include: it excludes\nproximate tokens to reduce redundancy, employs structured sparsity by design to\ndecrease computational demands, and incorporates inception-like diversity\nacross attention heads. This diversity ensures the capture of complementary\ninformation through non-overlapping token interactions, optimizing both\nperformance and resource utilization in ViTs for visual representation\nlearning. We embed our Fibottention mechanism into multiple state-of-the-art\ntransformer architectures dedicated to visual tasks. Leveraging only 2-6% of\nthe elements in the self-attention heads, Fibottention in conjunction with ViT\nand its variants, consistently achieves significant performance boosts compared\nto standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image\nclassification, video understanding, and robot learning tasks.\n","authors":["Ali Khaleghi Rahimian","Manish Kumar Govind","Subhajit Maity","Dominick Reilly","Christian Kümmerle","Srijan Das","Aritra Dutta"],"pdf_url":"https://arxiv.org/pdf/2406.19391v1.pdf","comment":"The code is publicly available at\n  https://github.com/Charlotte-CharMLab/Fibottention"},{"id":"http://arxiv.org/abs/2406.19390v1","updated":"2024-06-27T17:59:06Z","published":"2024-06-27T17:59:06Z","title":"SALVe: Semantic Alignment Verification for Floorplan Reconstruction from\n  Sparse Panoramas","summary":"  We propose a new system for automatic 2D floorplan reconstruction that is\nenabled by SALVe, our novel pairwise learned alignment verifier. The inputs to\nour system are sparsely located 360$^\\circ$ panoramas, whose semantic features\n(windows, doors, and openings) are inferred and used to hypothesize pairwise\nroom adjacency or overlap. SALVe initializes a pose graph, which is\nsubsequently optimized using GTSAM. Once the room poses are computed, room\nlayouts are inferred using HorizonNet, and the floorplan is constructed by\nstitching the most confident layout boundaries. We validate our system\nqualitatively and quantitatively as well as through ablation studies, showing\nthat it outperforms state-of-the-art SfM systems in completeness by over 200%,\nwithout sacrificing accuracy. Our results point to the significance of our\nwork: poses of 81% of panoramas are localized in the first 2 connected\ncomponents (CCs), and 89% in the first 3 CCs. Code and models are publicly\navailable at https://github.com/zillow/salve.\n","authors":["John Lambert","Yuguang Li","Ivaylo Boyadzhiev","Lambert Wixson","Manjunath Narayana","Will Hutchcroft","James Hays","Frank Dellaert","Sing Bing Kang"],"pdf_url":"https://arxiv.org/pdf/2406.19390v1.pdf","comment":"Accepted at ECCV 2022"},{"id":"http://arxiv.org/abs/2406.19389v1","updated":"2024-06-27T17:59:01Z","published":"2024-06-27T17:59:01Z","title":"OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and\n  Understanding","summary":"  Current universal segmentation methods demonstrate strong capabilities in\npixel-level image and video understanding. However, they lack reasoning\nabilities and cannot be controlled via text instructions. In contrast, large\nvision-language multimodal models exhibit powerful vision-based conversation\nand reasoning capabilities but lack pixel-level understanding and have\ndifficulty accepting visual prompts for flexible user interaction. This paper\nproposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level\nvision understanding with reasoning abilities. It can accept various visual and\ntext prompts for flexible user interaction. Specifically, we use a universal\nsegmentation method as the visual encoder, integrating image information,\nperception priors, and visual prompts into visual tokens provided to the LLM.\nThe LLM is responsible for understanding the user's text instructions and\nproviding text responses and pixel-level segmentation results based on the\nvisual information. We propose perception prior embedding to better integrate\nperception priors with image features. OMG-LLaVA achieves image-level,\nobject-level, and pixel-level reasoning and understanding in a single model,\nmatching or surpassing the performance of specialized methods on multiple\nbenchmarks. Rather than using LLM to connect each specialist, our work aims at\nend-to-end training on one encoder, one decoder, and one LLM. The code and\nmodel have been released for further research.\n","authors":["Tao Zhang","Xiangtai Li","Hao Fei","Haobo Yuan","Shengqiong Wu","Shunping Ji","Chen Change Loy","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2406.19389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19388v1","updated":"2024-06-27T17:58:54Z","published":"2024-06-27T17:58:54Z","title":"Taming Data and Transformers for Audio Generation","summary":"  Generating ambient sounds and effects is a challenging problem due to data\nscarcity and often insufficient caption quality, making it difficult to employ\nlarge-scale generative models for the task. In this work, we tackle the problem\nby introducing two new models. First, we propose AutoCap, a high-quality and\nefficient automatic audio captioning model. We show that by leveraging metadata\navailable with the audio modality, we can substantially improve the quality of\ncaptions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from\nthe best available captioning model at four times faster inference speed. We\nthen use AutoCap to caption clips from existing datasets, obtaining 761,000\naudio clips with high-quality captions, forming the largest available\naudio-text dataset. Second, we propose GenAu, a scalable transformer-based\naudio generation architecture that we scale up to 1.25B parameters and train\nwith our new dataset. When compared to state-of-the-art audio generators, GenAu\nobtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%\nin CLAP score, indicating significantly improved quality of generated audio\ncompared to previous works. This shows that the quality of data is often as\nimportant as its quantity. Besides, since AutoCap is fully automatic, new audio\nsamples can be added to the training dataset, unlocking the training of even\nlarger generative models for audio synthesis.\n","authors":["Moayed Haji-Ali","Willi Menapace","Aliaksandr Siarohin","Guha Balakrishnan","Sergey Tulyakov","Vicente Ordonez"],"pdf_url":"https://arxiv.org/pdf/2406.19388v1.pdf","comment":"Project Webpage: https://snap-research.github.io/GenAU/"},{"id":"http://arxiv.org/abs/2406.19369v1","updated":"2024-06-27T17:49:25Z","published":"2024-06-27T17:49:25Z","title":"Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment\n  Anything Model","summary":"  Transformer-based segmentation methods face the challenge of efficient\ninference when dealing with high-resolution images. Recently, several linear\nattention architectures, such as Mamba and RWKV, have attracted much attention\nas they can process long sequences efficiently. In this work, we focus on\ndesigning an efficient segment-anything model by exploring these different\narchitectures. Specifically, we design a mixed backbone that contains\nconvolution and RWKV operation, which achieves the best for both accuracy and\nefficiency. In addition, we design an efficient decoder to utilize the\nmultiscale tokens to obtain high-quality masks. We denote our method as\nRWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we\nbuild a benchmark containing various high-quality segmentation datasets and\njointly train one efficient yet high-quality segmentation model using this\nbenchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding\nperformance in efficiency and segmentation quality compared to transformers and\nother linear attention models. For example, compared with the same-scale\ntransformer model, RWKV-SAM achieves more than 2x speedup and can achieve\nbetter segmentation performance on various datasets. In addition, RWKV-SAM\noutperforms recent vision Mamba models with better classification and semantic\nsegmentation results. Code and models will be publicly available.\n","authors":["Haobo Yuan","Xiangtai Li","Lu Qi","Tao Zhang","Ming-Hsuan Yang","Shuicheng Yan","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2406.19369v1.pdf","comment":"16 pages; 8 figures"},{"id":"http://arxiv.org/abs/2406.19364v1","updated":"2024-06-27T17:46:13Z","published":"2024-06-27T17:46:13Z","title":"SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text\n  Cues","summary":"  Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in\ntraining segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:\ncolonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.\n","authors":["Yuxin Xie","Tao Zhou","Yi Zhou","Geng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19362v1","updated":"2024-06-27T17:43:35Z","published":"2024-06-27T17:43:35Z","title":"STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via\n  Collaborating Self-Training and Adversarial Learning","summary":"  Existing 3D object detection suffers from expensive annotation costs and poor\ntransferability to unknown data due to the domain gap, Unsupervised Domain\nAdaptation (UDA) aims to generalize detection models trained in labeled source\ndomains to perform robustly on unexplored target domains, providing a promising\nsolution for cross-domain 3D object detection. Although Self-Training (ST)\nbased cross-domain 3D detection methods with the assistance of pseudo-labeling\ntechniques have achieved remarkable progress, they still face the issue of\nlow-quality pseudo-labels when there are significant domain disparities due to\nthe absence of a process for feature distribution alignment. While Adversarial\nLearning (AL) based methods can effectively align the feature distributions of\nthe source and target domains, the inability to obtain labels in the target\ndomain forces the adoption of asymmetric optimization losses, resulting in a\nchallenging issue of source domain bias. To overcome these limitations, we\npropose a novel unsupervised domain adaptation framework for 3D object\ndetection via collaborating ST and AL, dubbed as STAL3D, unleashing the\ncomplementary advantages of pseudo labels and feature distribution alignment.\nAdditionally, a Background Suppression Adversarial Learning (BS-AL) module and\na Scale Filtering Module (SFM) are designed tailored for 3D cross-domain\nscenes, effectively alleviating the issues of the large proportion of\nbackground interference and source domain size bias. Our STAL3D achieves\nstate-of-the-art performance on multiple cross-domain tasks and even surpasses\nthe Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$\nKITTI-rain.\n","authors":["Yanan Zhang","Chao Zhou","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2406.19362v1.pdf","comment":"Accepted by IEEE-TIV"},{"id":"http://arxiv.org/abs/2406.05127v2","updated":"2024-06-27T17:35:45Z","published":"2024-06-07T17:55:43Z","title":"Towards Semantic Equivalence of Tokenization in Multimodal LLM","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated exceptional\ncapabilities in processing vision-language tasks. One of the crux of MLLMs lies\nin vision tokenization, which involves efficiently transforming input visual\nsignals into feature representations that are most beneficial for LLMs.\nHowever, existing vision tokenizers, essential for semantic alignment between\nvision and language, remain problematic. Existing methods aggressively fragment\nvisual input, corrupting the visual semantic integrity. To address this, this\npaper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer (SeTok),\nwhich groups visual features into semantic units via a dynamic clustering\nalgorithm, flexibly determining the number of tokens based on image complexity.\nThe resulting vision tokens effectively preserve semantic integrity and capture\nboth low-frequency and high-frequency visual features. The proposed MLLM\n(Setokim) equipped with SeTok significantly demonstrates superior performance\nacross various tasks, as evidenced by our experimental results. The project\npage is at https://chocowu.github.io/SeTok-web/.\n","authors":["Shengqiong Wu","Hao Fei","Xiangtai Li","Jiayi Ji","Hanwang Zhang","Tat-Seng Chua","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2406.05127v2.pdf","comment":"Technical Report. The project page:\n  https://chocowu.github.io/SeTok-web/"},{"id":"http://arxiv.org/abs/2406.19353v1","updated":"2024-06-27T17:32:18Z","published":"2024-06-27T17:32:18Z","title":"CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative\n  Object REarrangement","summary":"  Understanding how humans cooperatively rearrange household objects is\ncritical for VR/AR and human-robot interaction. However, in-depth studies on\nmodeling these behaviors are under-researched due to the lack of relevant\ndatasets. We fill this gap by presenting CORE4D, a novel large-scale 4D\nhuman-object-human interaction dataset focusing on collaborative object\nrearrangement, which encompasses diverse compositions of various object\ngeometries, collaboration modes, and 3D scenes. With 1K human-object-human\nmotion sequences captured in the real world, we enrich CORE4D by contributing\nan iterative collaboration retargeting strategy to augment motions to a variety\nof novel objects. Leveraging this approach, CORE4D comprises a total of 11K\ncollaboration sequences spanning 3K real and virtual object shapes. Benefiting\nfrom extensive motion patterns provided by CORE4D, we benchmark two tasks\naiming at generating human-object interaction: human-object motion forecasting\nand interaction synthesis. Extensive experiments demonstrate the effectiveness\nof our collaboration retargeting strategy and indicate that CORE4D has posed\nnew challenges to existing human-object interaction generation methodologies.\nOur dataset and code are available at\nhttps://github.com/leolyliu/CORE4D-Instructions.\n","authors":["Chengwen Zhang","Yun Liu","Ruofan Xing","Bingda Tang","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2406.19353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13040v2","updated":"2024-06-27T17:27:13Z","published":"2024-03-19T17:35:17Z","title":"Physics-Guided Neural Networks for Intraventricular Vector Flow Mapping","summary":"  Intraventricular vector flow mapping (iVFM) seeks to enhance and quantify\ncolor Doppler in cardiac imaging. In this study, we propose novel alternatives\nto the traditional iVFM optimization scheme by utilizing physics-informed\nneural networks (PINNs) and a physics-guided nnU-Net-based supervised approach.\nWhen evaluated on simulated color Doppler images derived from a\npatient-specific computational fluid dynamics model and in vivo Doppler\nacquisitions, both approaches demonstrate comparable reconstruction performance\nto the original iVFM algorithm. The efficiency of PINNs is boosted through\ndual-stage optimization and pre-optimized weights. On the other hand, the\nnnU-Net method excels in generalizability and real-time capabilities. Notably,\nnnU-Net shows superior robustness on sparse and truncated Doppler data while\nmaintaining independence from explicit boundary conditions. Overall, our\nresults highlight the effectiveness of these methods in reconstructing\nintraventricular vector blood flow. The study also suggests potential\napplications of PINNs in ultrafast color Doppler imaging and the incorporation\nof fluid dynamics equations to derive biomarkers for cardiovascular diseases\nbased on blood flow.\n","authors":["Hang Jung Ling","Salomé Bru","Julia Puig","Florian Vixège","Simon Mendez","Franck Nicoud","Pierre-Yves Courand","Olivier Bernard","Damien Garcia"],"pdf_url":"https://arxiv.org/pdf/2403.13040v2.pdf","comment":"12 pages, accepted for publication in IEEE TUFFC; camera ready\n  corrections, corrected acknowledgments"},{"id":"http://arxiv.org/abs/2406.19341v1","updated":"2024-06-27T17:16:23Z","published":"2024-06-27T17:16:23Z","title":"Learning Visual Conditioning Tokens to Correct Domain Shift for Fully\n  Test-time Adaptation","summary":"  Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. This work\nis based on the following interesting finding: in transformer-based image\nclassification, the class token at the first transformer encoder layer can be\nlearned to capture the domain-specific characteristics of target samples during\ntest-time adaptation. This learned token, when combined with input image patch\nembeddings, is able to gradually remove the domain-specific information from\nthe feature representations of input samples during the transformer encoding\nprocess, thereby significantly improving the test-time adaptation performance\nof the source model across different domains. We refer to this class token as\nvisual conditioning token (VCT). To successfully learn the VCT, we propose a\nbi-level learning approach to capture the long-term variations of\ndomain-specific characteristics while accommodating local variations of\ninstance-specific characteristics. Experimental results on the benchmark\ndatasets demonstrate that our proposed bi-level visual conditioning token\nlearning method is able to achieve significantly improved test-time adaptation\nperformance by up to 1.9%.\n","authors":["Yushun Tang","Shuoshuo Chen","Zhehan Kan","Yi Zhang","Qinghai Guo","Zhihai He"],"pdf_url":"https://arxiv.org/pdf/2406.19341v1.pdf","comment":"accepted by TMM"},{"id":"http://arxiv.org/abs/2406.19336v1","updated":"2024-06-27T17:10:10Z","published":"2024-06-27T17:10:10Z","title":"LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver\n  with a Few Partial Ultrasound Scans","summary":"  3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.\n","authors":["Kaushalya Sivayogaraj","Sahan T. Guruge","Udari Liyanage","Jeevani Udupihille","Saroj Jayasinghe","Gerard Fernando","Ranga Rodrigo","M. Rukshani Liyanaarachchi"],"pdf_url":"https://arxiv.org/pdf/2406.19336v1.pdf","comment":"10 pages, Accepted to MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.13444v2","updated":"2024-06-27T17:09:24Z","published":"2024-06-19T11:09:16Z","title":"VDebugger: Harnessing Execution Feedback for Debugging Visual Programs","summary":"  Visual programs are executable code generated by large language models to\naddress visual reasoning problems. They decompose complex questions into\nmultiple reasoning steps and invoke specialized models for each step to solve\nthe problems. However, these programs are prone to logic errors, with our\npreliminary evaluation showing that 58% of the total errors are caused by\nprogram logic errors. Debugging complex visual programs remains a major\nbottleneck for visual reasoning. To address this, we introduce VDebugger, a\nnovel critic-refiner framework trained to localize and debug visual programs by\ntracking execution step by step. VDebugger identifies and corrects program\nerrors leveraging detailed execution feedback, improving interpretability and\naccuracy. The training data is generated through an automated pipeline that\ninjects errors into correct visual programs using a novel mask-best decoding\ntechnique. Evaluations on six datasets demonstrate VDebugger's effectiveness,\nshowing performance improvements of up to 3.2% in downstream task accuracy.\nFurther studies show VDebugger's ability to generalize to unseen tasks,\nbringing a notable improvement of 2.3% on the unseen COVR task. Code, data and\nmodels are made publicly available at https://github.com/shirley-wu/vdebugger/\n","authors":["Xueqing Wu","Zongyu Lin","Songyan Zhao","Te-Lin Wu","Pan Lu","Nanyun Peng","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2406.13444v2.pdf","comment":"update reference"},{"id":"http://arxiv.org/abs/2406.19320v1","updated":"2024-06-27T16:54:12Z","published":"2024-06-27T16:54:12Z","title":"Efficient World Models with Context-Aware Tokenization","summary":"  Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2406.19320v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.19316v1","updated":"2024-06-27T16:52:01Z","published":"2024-06-27T16:52:01Z","title":"Enhanced Data Transfer Cooperating with Artificial Triplets for Scene\n  Graph Generation","summary":"  This work focuses on training dataset enhancement of informative relational\ntriplets for Scene Graph Generation (SGG). Due to the lack of effective\nsupervision, the current SGG model predictions perform poorly for informative\nrelational triplets with inadequate training samples. Therefore, we propose two\nnovel training dataset enhancement modules: Feature Space Triplet Augmentation\n(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to\ngenerate representations of an object in relational triplets. The biased\nprediction based sampling in FSTA efficiently augments artificial triplets\nfocusing on the challenging ones. In addition, we introduce Soft Transfer,\nwhich assigns soft predicate labels to general relational triplets to make more\nsupervisions for informative predicate classes effectively. Experimental\nresults show that integrating FSTA and Soft Transfer achieve high levels of\nboth Recall and mean Recall in Visual Genome dataset. The mean of Recall and\nmean Recall is the highest among all the existing model-agnostic methods.\n","authors":["KuanChao Chu","Satoshi Yamazaki","Hideki Nakayama"],"pdf_url":"https://arxiv.org/pdf/2406.19316v1.pdf","comment":"Accepted to IEICE Transactions on Information and Systems in April\n  2024"},{"id":"http://arxiv.org/abs/2406.13642v2","updated":"2024-06-27T16:30:48Z","published":"2024-06-19T15:41:30Z","title":"SpatialBot: Precise Spatial Understanding with Vision Language Models","summary":"  Vision Language Models (VLMs) have achieved impressive performance in 2D\nimage understanding, however they are still struggling with spatial\nunderstanding which is the foundation of Embodied AI. In this paper, we propose\nSpatialBot for better spatial understanding by feeding both RGB and depth\nimages. Additionally, we have constructed the SpatialQA dataset, which involves\nmulti-level depth-related questions to train VLMs for depth understanding.\nFinally, we present SpatialBench to comprehensively evaluate VLMs' capabilities\nin spatial understanding at different levels. Extensive experiments on our\nspatial-understanding benchmark, general VLM benchmarks and Embodied AI tasks,\ndemonstrate the remarkable improvements of SpatialBot trained on SpatialQA. The\nmodel, code and data are available at https://github.com/BAAI-DCAI/SpatialBot.\n","authors":["Wenxiao Cai","Yaroslav Ponomarenko","Jianhao Yuan","Xiaoqi Li","Wankou Yang","Hao Dong","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.13642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19302v1","updated":"2024-06-27T16:17:33Z","published":"2024-06-27T16:17:33Z","title":"Mapping Land Naturalness from Sentinel-2 using Deep Contextual and\n  Geographical Priors","summary":"  In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.\n","authors":["Burak Ekim","Michael Schmitt"],"pdf_url":"https://arxiv.org/pdf/2406.19302v1.pdf","comment":"6 pages, 3 figures, ICLR 2024 Tackling Climate Change with Machine\n  Learning Workshop"},{"id":"http://arxiv.org/abs/2406.19299v1","updated":"2024-06-27T16:15:22Z","published":"2024-06-27T16:15:22Z","title":"PNeRV: A Polynomial Neural Representation for Videos","summary":"  Extracting Implicit Neural Representations (INRs) on video data poses unique\nchallenges due to the additional temporal dimension. In the context of videos,\nINRs have predominantly relied on a frame-only parameterization, which\nsacrifices the spatiotemporal continuity observed in pixel-level (spatial)\nrepresentations. To mitigate this, we introduce Polynomial Neural\nRepresentation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR\nfor videos that preserves spatiotemporal continuity. PNeRV leverages the\nmodeling capabilities of Polynomial Neural Networks to perform the modulation\nof a continuous spatial (patch) signal with a continuous time (frame) signal.\nWe further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme\nthat ensures spatial continuity while retaining parameter efficiency. We also\nemploy a carefully designed Positional Embedding methodology to further enhance\nPNeRV's performance. Our extensive experimentation demonstrates that PNeRV\noutperforms the baselines in conventional Implicit Neural Representation tasks\nlike compression along with downstream applications that require spatiotemporal\ncontinuity in the underlying representation. PNeRV not only addresses the\nchallenges posed by video data in the realm of INRs but also opens new avenues\nfor advanced video processing and analysis.\n","authors":["Sonam Gupta","Snehal Singh Tomar","Grigorios G Chrysos","Sukhendu Das","A. N. Rajagopalan"],"pdf_url":"https://arxiv.org/pdf/2406.19299v1.pdf","comment":"25 pages, 17 figures, published at TMLR, Feb 2024"},{"id":"http://arxiv.org/abs/2406.19298v1","updated":"2024-06-27T16:13:34Z","published":"2024-06-27T16:13:34Z","title":"Compositional Image Decomposition with Diffusion Models","summary":"  Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.\n","authors":["Jocelin Su","Nan Liu","Yanbo Wang","Joshua B. Tenenbaum","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2406.19298v1.pdf","comment":"ICML 2024, Webpage:\n  https://energy-based-model.github.io/decomp-diffusion"},{"id":"http://arxiv.org/abs/2406.19297v1","updated":"2024-06-27T16:12:57Z","published":"2024-06-27T16:12:57Z","title":"Enhancing Continual Learning in Visual Question Answering with\n  Modality-Aware Feature Distillation","summary":"  Continual learning focuses on incrementally training a model on a sequence of\ntasks with the aim of learning new tasks while minimizing performance drop on\nprevious tasks. Existing approaches at the intersection of Continual Learning\nand Visual Question Answering (VQA) do not study how the multimodal nature of\nthe input affects the learning dynamics of a model. In this paper, we\ndemonstrate that each modality evolves at different rates across a continuum of\ntasks and that this behavior occurs in established encoder-only models as well\nas modern recipes for developing Vision & Language (VL) models. Motivated by\nthis observation, we propose a modality-aware feature distillation (MAFED)\napproach which outperforms existing baselines across models of varying scale in\nthree multimodal continual learning settings. Furthermore, we provide ablations\nshowcasing that modality-aware distillation complements experience replay.\nOverall, our results emphasize the importance of addressing modality-specific\ndynamics to prevent forgetting in multimodal continual learning.\n","authors":["Malvina Nikandrou","Georgios Pantazopoulos","Ioannis Konstas","Alessandro Suglia"],"pdf_url":"https://arxiv.org/pdf/2406.19297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19290v1","updated":"2024-06-27T16:04:41Z","published":"2024-06-27T16:04:41Z","title":"Human Modelling and Pose Estimation Overview","summary":"  Human modelling and pose estimation stands at the crossroads of Computer\nVision, Computer Graphics, and Machine Learning. This paper presents a thorough\ninvestigation of this interdisciplinary field, examining various algorithms,\nmethodologies, and practical applications. It explores the diverse range of\nsensor technologies relevant to this domain and delves into a wide array of\napplication areas. Additionally, we discuss the challenges and advancements in\n2D and 3D human modelling methodologies, along with popular datasets, metrics,\nand future research directions. The main contribution of this paper lies in its\nup-to-date comparison of state-of-the-art (SOTA) human pose estimation\nalgorithms in both 2D and 3D domains. By providing this comprehensive overview,\nthe paper aims to enhance understanding of 3D human modelling and pose\nestimation, offering insights into current SOTA achievements, challenges, and\nfuture prospects within the field.\n","authors":["Pawel Knap"],"pdf_url":"https://arxiv.org/pdf/2406.19290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19280v1","updated":"2024-06-27T15:50:41Z","published":"2024-06-27T15:50:41Z","title":"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into\n  Multimodal LLMs at Scale","summary":"  The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.\n","authors":["Junying Chen","Ruyi Ouyang","Anningzhe Gao","Shunian Chen","Guiming Hardy Chen","Xidong Wang","Ruifei Zhang","Zhenyang Cai","Ke Ji","Guangjun Yu","Xiang Wan","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15847v3","updated":"2024-06-27T15:38:17Z","published":"2024-01-29T02:43:40Z","title":"Muffin or Chihuahua? Challenging Multimodal Large Language Models with\n  Multipanel VQA","summary":"  Multipanel images, commonly seen as web screenshots, posters, etc., pervade\nour daily lives. These images, characterized by their composition of multiple\nsubfigures in distinct layouts, effectively convey information to people.\nToward building advanced multimodal AI applications, such as agents that\nunderstand complex scenes and navigate through webpages, the skill of\nmultipanel visual reasoning is essential, and a comprehensive evaluation of\nmodels in this regard is important. Therefore, we introduce Multipanel Visual\nQuestion Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets\nof questions, answers, and multipanel images that specifically challenge models\nin comprehending multipanel images. Our evaluation shows that questions in the\nMultipanelVQA benchmark pose significant challenges to the state-of-the-art\nMultimodal Large Language Models (MLLMs) tested, even though humans can attain\napproximately 99% accuracy on these questions. Distinctively, the MultipanelVQA\nbenchmark features synthetically generated multipanel images specifically\ncrafted to isolate and assess the impact of various factors, such as the\nlayout, on MLLMs' multipanel image comprehension abilities. As a result, in\naddition to benchmarking the capabilities of MLLMs in understanding multipanel\nimages, we analyze various factors of the multipanel image that affect MLLMs'\nperformance with synthetic data and offer insights for enhancement. Code and\ndata are released at https://sites.google.com/view/multipanelvqa/home.\n","authors":["Yue Fan","Jing Gu","Kaiwen Zhou","Qianqi Yan","Shan Jiang","Ching-Chen Kuo","Xinze Guan","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2401.15847v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2406.19263v1","updated":"2024-06-27T15:34:16Z","published":"2024-06-27T15:34:16Z","title":"Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens\n  Grounding","summary":"  Graphical User Interfaces (GUIs) are central to our interaction with digital\ndevices. Recently, growing efforts have been made to build models for various\nGUI understanding tasks. However, these efforts largely overlook an important\nGUI-referring task: screen reading based on user-indicated points, which we\nname the Screen Point-and-Read (SPR) task. This task is predominantly handled\nby rigid accessible screen reading tools, in great need of new models driven by\nadvancements in Multimodal Large Language Models (MLLMs). In this paper, we\npropose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,\nto address the SPR task. Based on the input point coordinate and the\ncorresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout\nTree. Based on the tree, our ToL agent not only comprehends the content of the\nindicated area but also articulates the layout and spatial relationships\nbetween elements. Such layout information is crucial for accurately\ninterpreting information on the screen, distinguishing our ToL agent from other\nscreen reading tools. We also thoroughly evaluate the ToL agent against other\nbaselines on a newly proposed SPR benchmark, which includes GUIs from mobile,\nweb, and operating systems. Last but not least, we test the ToL agent on mobile\nGUI navigation tasks, demonstrating its utility in identifying incorrect\nactions along the path of agent execution trajectories. Code and data:\nscreen-point-and-read.github.io\n","authors":["Yue Fan","Lei Ding","Ching-Chen Kuo","Shan Jiang","Yang Zhao","Xinze Guan","Jie Yang","Yi Zhang","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06748v2","updated":"2024-06-27T15:24:23Z","published":"2024-03-11T14:14:52Z","title":"Shortcut Learning in Medical Image Segmentation","summary":"  Shortcut learning is a phenomenon where machine learning models prioritize\nlearning simple, potentially misleading cues from data that do not generalize\nwell beyond the training set. While existing research primarily investigates\nthis in the realm of image classification, this study extends the exploration\nof shortcut learning into medical image segmentation. We demonstrate that\nclinical annotations such as calipers, and the combination of zero-padded\nconvolutions and center-cropped training sets in the dataset can inadvertently\nserve as shortcuts, impacting segmentation accuracy. We identify and evaluate\nthe shortcut learning on two different but common medical image segmentation\ntasks. In addition, we suggest strategies to mitigate the influence of shortcut\nlearning and improve the generalizability of the segmentation models. By\nuncovering the presence and implications of shortcuts in medical image\nsegmentation, we provide insights and methodologies for evaluating and\novercoming this pervasive challenge and call for attention in the community for\nshortcuts in segmentation. Our code is public at\nhttps://github.com/nina-weng/shortcut_skinseg .\n","authors":["Manxi Lin","Nina Weng","Kamil Mikolaj","Zahra Bashir","Morten Bo Søndergaard Svendsen","Martin Tolsgaard","Anders Nymark Christensen","Aasa Feragen"],"pdf_url":"https://arxiv.org/pdf/2403.06748v2.pdf","comment":"11 pages, 6 figures, accepted at MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.19255v1","updated":"2024-06-27T15:23:36Z","published":"2024-06-27T15:23:36Z","title":"Enhancing Video-Language Representations with Structural Spatio-Temporal\n  Alignment","summary":"  While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.\n","authors":["Hao Fei","Shengqiong Wu","Meishan Zhang","Min Zhang","Tat-Seng Chua","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2406.19255v1.pdf","comment":"Accepted by IEEE TPAMI 2024"},{"id":"http://arxiv.org/abs/2406.19247v1","updated":"2024-06-27T15:14:23Z","published":"2024-06-27T15:14:23Z","title":"Local Manifold Learning for No-Reference Image Quality Assessment","summary":"  Contrastive learning has considerably advanced the field of Image Quality\nAssessment (IQA), emerging as a widely adopted technique. The core mechanism of\ncontrastive learning involves minimizing the distance between quality-similar\n(positive) examples while maximizing the distance between quality-dissimilar\n(negative) examples. Despite its successes, current contrastive learning\nmethods often neglect the importance of preserving the local manifold\nstructure. This oversight can result in a high degree of similarity among hard\nexamples within the feature space, thereby impeding effective differentiation\nand assessment. To address this issue, we propose an innovative framework that\nintegrates local manifold learning with contrastive learning for No-Reference\nImage Quality Assessment (NR-IQA). Our method begins by sampling multiple crops\nfrom a given image, identifying the most visually salient crop. This crop is\nthen used to cluster other crops from the same image as the positive class,\nwhile crops from different images are treated as negative classes to increase\ninter-class distance. Uniquely, our approach also considers non-saliency crops\nfrom the same image as intra-class negative classes to preserve their\ndistinctiveness. Additionally, we employ a mutual learning framework, which\nfurther enhances the model's ability to adaptively learn and identify visual\nsaliency regions. Our approach demonstrates a better performance compared to\nstate-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942\n(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).\n","authors":["Timin Gao","Wensheng Pan","Yan Zhang","Sicheng Zhao","Shengchuan Zhang","Xiawu Zheng","Ke Li","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2406.19247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01656v2","updated":"2024-06-27T15:07:39Z","published":"2024-05-02T18:26:15Z","title":"S4: Self-Supervised Sensing Across the Spectrum","summary":"  Satellite image time series (SITS) segmentation is crucial for many\napplications like environmental monitoring, land cover mapping and agricultural\ncrop type classification. However, training models for SITS segmentation\nremains a challenging task due to the lack of abundant training data, which\nrequires fine grained annotation. We propose S4 a new self-supervised\npre-training approach that significantly reduces the requirement for labeled\ntraining data by utilizing two new insights: (a) Satellites capture images in\ndifferent parts of the spectrum such as radio frequencies, and visible\nfrequencies. (b) Satellite imagery is geo-registered allowing for fine-grained\nspatial alignment. We use these insights to formulate pre-training tasks in S4.\nWe also curate m2s2-SITS, a large-scale dataset of unlabeled,\nspatially-aligned, multi-modal and geographic specific SITS that serves as\nrepresentative pre-training data for S4. Finally, we evaluate S4 on multiple\nSITS segmentation datasets and demonstrate its efficacy against competing\nbaselines while using limited labeled data.\n","authors":["Jayanth Shenoy","Xingjian Davis Zhang","Shlok Mehrotra","Bill Tao","Rem Yang","Han Zhao","Deepak Vasisht"],"pdf_url":"https://arxiv.org/pdf/2405.01656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19239v1","updated":"2024-06-27T15:02:04Z","published":"2024-06-27T15:02:04Z","title":"ALMA: a mathematics-driven approach for determining tuning parameters in\n  generalized LASSO problems, with applications to MRI","summary":"  Magnetic Resonance Imaging (MRI) is a powerful technique employed for\nnon-invasive in vivo visualization of internal structures. Sparsity is often\ndeployed to accelerate the signal acquisition or overcome the presence of\nmotion artifacts, improving the quality of image reconstruction. Image\nreconstruction algorithms use TV-regularized LASSO (Total Variation-regularized\nLASSO) to retrieve the missing information of undersampled signals, by cleaning\nthe data of noise and while optimizing sparsity. A tuning parameter moderates\nthe balance between these two aspects; its choice affecting the quality of the\nreconstructions. Currently, there is a lack of general deterministic techniques\nto choose these parameters, which are oftentimes manually selected and thus\nhinder the reliability of the reconstructions. Here, we present ALMA (Algorithm\nfor Lagrange Multipliers Approximation), an iterative mathematics-inspired\ntechnique that computes tuning parameters for generalized LASSO problems during\nMRI reconstruction. We analyze quantitatively the performance of these\nparameters for imaging reconstructions via TV-LASSO in an MRI context on\nphantoms. Although our study concentrates on TV-LASSO, the techniques developed\nhere hold significant promise for a wide array of applications. ALMA is not\nonly adaptable to more generalized LASSO problems but is also robust to\naccommodate other forms of regularization beyond total variation. Moreover, it\nextends effectively to handle non-Cartesian sampling trajectories, broadening\nits utility in complex data reconstruction scenarios. More generally, ALMA\nprovides a powerful tool for numerically solving constrained optimization\nproblems across various disciplines, offering a versatile and impactful\nsolution for advanced computational challenges.\n","authors":["Gianluca Giacchi","Isidoros Iakovidis","Bastien Milani","Matthias Stuber","Micah Murray","Benedetta Franceschiello"],"pdf_url":"https://arxiv.org/pdf/2406.19239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19237v1","updated":"2024-06-27T15:01:48Z","published":"2024-06-27T15:01:48Z","title":"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with\n  Flowcharts","summary":"  Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.\n","authors":["Shubhankar Singh","Purvi Chaurasia","Yerram Varun","Pranshu Pandya","Vatsal Gupta","Vivek Gupta","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2406.19237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19236v1","updated":"2024-06-27T15:01:42Z","published":"2024-06-27T15:01:42Z","title":"Human-Aware Vision-and-Language Navigation: Bridging Simulation to\n  Reality with Dynamic Human Interactions","summary":"  Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.\n","authors":["Minghan Li","Heng Li","Zhi-Qi Cheng","Yifei Dong","Yuxuan Zhou","Jun-Yan He","Qi Dai","Teruko Mitamura","Alexander G. Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2406.19236v1.pdf","comment":"30 pages, 18 figures, Project Page:\n  https://lpercc.github.io/HA3D_simulator/"},{"id":"http://arxiv.org/abs/2406.17382v2","updated":"2024-06-27T14:59:18Z","published":"2024-06-25T08:58:53Z","title":"Automatic infant 2D pose estimation from videos: comparing seven deep\n  neural network methods","summary":"  Automatic markerless estimation of infant posture and motion from ordinary\nvideos carries great potential for movement studies \"in the wild\", facilitating\nunderstanding of motor development and massively increasing the chances of\nearly diagnosis of disorders. There is rapid development of human pose\nestimation methods in computer vision thanks to advances in deep learning and\nmachine learning. However, these methods are trained on datasets featuring\nadults in different contexts. This work tests and compares seven popular\nmethods (AlphaPose, DeepLabCut/DeeperCut, Detectron2, HRNet,\nMediaPipe/BlazePose, OpenPose, and ViTPose) on videos of infants in supine\nposition. Surprisingly, all methods except DeepLabCut and MediaPipe have\ncompetitive performance without additional finetuning, with ViTPose performing\nbest. Next to standard performance metrics (object keypoint similarity, average\nprecision and recall), we introduce errors expressed in the neck-mid-hip ratio\nand additionally study missed and redundant detections and the reliability of\nthe internal confidence ratings of the different methods, which are relevant\nfor downstream tasks. Among the networks with competitive performance, only\nAlphaPose could run close to real time (27 fps) on our machine. We provide\ndocumented Docker containers or instructions for all the methods we used, our\nanalysis scripts, and processed data at https://hub.docker.com/u/humanoidsctu\nand https://osf.io/x465b/.\n","authors":["Filipe Gama","Matej Misar","Lukas Navara","Sergiu T. Popescu","Matej Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2406.17382v2.pdf","comment":"21 pages, 3 figures, 14 tables"},{"id":"http://arxiv.org/abs/2406.05668v2","updated":"2024-06-27T14:55:41Z","published":"2024-06-09T06:53:39Z","title":"SRC-Net: Bi-Temporal Spatial Relationship Concerned Network for Change\n  Detection","summary":"  Change detection (CD) in remote sensing imagery is a crucial task with\napplications in environmental monitoring, urban development, and disaster\nmanagement. CD involves utilizing bi-temporal images to identify changes over\ntime. The bi-temporal spatial relationships between features at the same\nlocation at different times play a key role in this process. However, existing\nchange detection networks often do not fully leverage these spatial\nrelationships during bi-temporal feature extraction and fusion. In this work,\nwe propose SRC-Net: a bi-temporal spatial relationship concerned network for\nCD. The proposed SRC-Net includes a Perception and Interaction Module that\nincorporates spatial relationships and establishes a cross-branch perception\nmechanism to enhance the precision and robustness of feature extraction.\nAdditionally, a Patch-Mode joint Feature Fusion Module is introduced to address\ninformation loss in current methods. It considers different change modes and\nconcerns about spatial relationships, resulting in more expressive fusion\nfeatures. Furthermore, we construct a novel network using these two\nrelationship concerned modules and conducted experiments on the LEVIR-CD and\nWHU Building datasets. The experimental results demonstrate that our network\noutperforms state-of-the-art (SOTA) methods while maintaining a modest\nparameter count. We believe our approach sets a new paradigm for change\ndetection and will inspire further advancements in the field. The code and\nmodels are publicly available at https://github.com/Chnja/SRCNet.\n","authors":["Hongjia Chen","Xin Xu","Fangling Pu"],"pdf_url":"https://arxiv.org/pdf/2406.05668v2.pdf","comment":"13 pages, 12 figures, IEEE Journal of Selected Topics in Applied\n  Earth Observations and Remote Sensing (2024)"},{"id":"http://arxiv.org/abs/2406.19225v1","updated":"2024-06-27T14:50:50Z","published":"2024-06-27T14:50:50Z","title":"ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model\n  for Semantic Segmentation","summary":"  Domain adaptive semantic segmentation aims to generate accurate and dense\npredictions for an unlabeled target domain by leveraging a supervised model\ntrained on a labeled source domain. The prevalent self-training approach\ninvolves retraining the dense discriminative classifier of $p(class|pixel\nfeature)$ using the pseudo-labels from the target domain. While many methods\nfocus on mitigating the issue of noisy pseudo-labels, they often overlook the\nunderlying data distribution p(pixel feature|class) in both the source and\ntarget domains. To address this limitation, we propose the multi-prototype\nGaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into\ncontrastive losses to perform guided contrastive learning. Contrastive losses\nare commonly executed in the literature using memory banks, which can lead to\nclass biases due to underrepresented classes. Furthermore, memory banks often\nhave fixed capacities, potentially restricting the model's ability to capture\ndiverse representations of the target/source domains. An alternative approach\nis to use global class prototypes (i.e. averaged features per category).\nHowever, the global prototypes are based on the unimodal distribution\nassumption per class, disregarding within-class variation. To address these\nchallenges, we propose the ProtoGMM model. This novel approach involves\nestimating the underlying multi-prototype source distribution by utilizing the\nGMM on the feature space of the source samples. The components of the GMM model\nact as representative prototypes. To achieve increased intra-class semantic\nsimilarity, decreased inter-class similarity, and domain alignment between the\nsource and target domains, we employ multi-prototype contrastive learning\nbetween source distribution and target samples. The experiments show the\neffectiveness of our method on UDA benchmarks.\n","authors":["Nazanin Moradinasab","Laura S. Shankman","Rebecca A. Deaton","Gary K. Owens","Donald E. Brown"],"pdf_url":"https://arxiv.org/pdf/2406.19225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19217v1","updated":"2024-06-27T14:43:50Z","published":"2024-06-27T14:43:50Z","title":"Think Step by Step: Chain-of-Gesture Prompting for Error Detection in\n  Robotic Surgical Videos","summary":"  Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.\n","authors":["Zhimin Shao","Jialang Xu","Danail Stoyanov","Evangelos B. Mazomenos","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2406.19217v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.06196v2","updated":"2024-06-27T14:19:56Z","published":"2024-05-10T02:23:56Z","title":"VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with\n  Lightweight Blocks","summary":"  Foundation Vision-Language Models (VLMs) trained using large-scale\nopen-domain images and text pairs have recently been adapted to develop\nVision-Language Segmentation Models (VLSMs) that allow providing text prompts\nduring inference to guide image segmentation. If robust and powerful VLSMs can\nbe built for medical images, it could aid medical professionals in many\nclinical tasks where they must spend substantial time delineating the target\nstructure of interest. VLSMs for medical images resort to fine-tuning base VLM\nor VLSM pretrained on open-domain natural image datasets due to fewer annotated\nmedical image datasets; this fine-tuning is resource-consuming and expensive as\nit usually requires updating all or a significant fraction of the pretrained\nparameters. Recently, lightweight blocks called adapters have been proposed in\nVLMs that keep the pretrained model frozen and only train adapters during\nfine-tuning, substantially reducing the computing resources required. We\nintroduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained\nvision-language segmentation models using transformer encoders. Our experiments\nin widely used CLIP-based segmentation models show that with only 3 million\ntrainable parameters, the VLSM-Adapter outperforms state-of-the-art and is\ncomparable to the upper bound end-to-end fine-tuning. The source code is\navailable at: https://github.com/naamiinepal/vlsm-adapter.\n","authors":["Manish Dhakal","Rabin Adhikari","Safal Thapaliya","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2405.06196v2.pdf","comment":"Accepted at MICCAI 2024, the 27th International Conference on Medical\n  Image Computing and Computer Assisted Intervention"},{"id":"http://arxiv.org/abs/2406.19175v1","updated":"2024-06-27T13:51:53Z","published":"2024-06-27T13:51:53Z","title":"Towards Reducing Data Acquisition and Labeling for Defect Detection\n  using Simulated Data","summary":"  In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.\n","authors":["Lukas Malte Kemeter","Rasmus Hvingelby","Paulina Sierak","Tobias Schön","Bishwajit Gosswam"],"pdf_url":"https://arxiv.org/pdf/2406.19175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19162v1","updated":"2024-06-27T13:29:25Z","published":"2024-06-27T13:29:25Z","title":"Single Image Estimation of Cell Migration Direction by Deep Circular\n  Regression","summary":"  In this paper we study the problem of estimating the migration direction of\ncells based on a single image. To the best of our knowledge, there is only one\nrelated work that uses a classification CNN for four classes (quadrants). This\napproach does not allow detailed directional resolution. We solve the single\nimage estimation problem using deep circular regression with special attention\nto cycle-sensitive methods. On two databases we achieve an average accuracy of\n$\\sim$17 degrees, which is a significant improvement over the previous work.\n","authors":["Lennart Bruns","Lucas Lamparter","Milos Galic","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.19162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14574v2","updated":"2024-06-27T13:29:07Z","published":"2023-12-22T10:10:50Z","title":"MMGPL: Multimodal Medical Data Analysis with Graph Prompt Learning","summary":"  Prompt learning has demonstrated impressive efficacy in the fine-tuning of\nmultimodal large models to a wide range of downstream tasks. Nonetheless,\napplying existing prompt learning methods for the diagnosis of neurological\ndisorder still suffers from two issues: (i) existing methods typically treat\nall patches equally, despite the fact that only a small number of patches in\nneuroimaging are relevant to the disease, and (ii) they ignore the structural\ninformation inherent in the brain connection network which is crucial for\nunderstanding and diagnosing neurological disorders. To tackle these issues, we\nintroduce a novel prompt learning model by learning graph prompts during the\nfine-tuning process of multimodal large models for diagnosing neurological\ndisorders. Specifically, we first leverage GPT-4 to obtain relevant disease\nconcepts and compute semantic similarity between these concepts and all\npatches. Secondly, we reduce the weight of irrelevant patches according to the\nsemantic similarity between each patch and disease-related concepts. Moreover,\nwe construct a graph among tokens based on these concepts and employ a graph\nconvolutional network layer to extract the structural information of the graph,\nwhich is used to prompt the pre-trained multimodal large models for diagnosing\nneurological disorders. Extensive experiments demonstrate that our method\nachieves superior performance for neurological disorder diagnosis compared with\nstate-of-the-art methods and validated by clinicians.\n","authors":["Liang Peng","Songyue Cai","Zongqian Wu","Huifang Shang","Xiaofeng Zhu","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2312.14574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12223v3","updated":"2024-06-27T13:13:11Z","published":"2023-12-19T15:11:46Z","title":"Self-Supervised Detection of Perfect and Partial Input-Dependent\n  Symmetries","summary":"  Group equivariance can overly constrain models if the symmetries in the group\ndiffer from those observed in data. While common methods address this by\ndetermining the appropriate level of symmetry at the dataset level, they are\nlimited to supervised settings and ignore scenarios in which multiple levels of\nsymmetry co-exist in the same dataset. In this paper, we propose a method able\nto detect the level of symmetry of each input without the need for labels. Our\nframework is general enough to accommodate different families of both\ncontinuous and discrete symmetry distributions, such as arbitrary unimodal,\nsymmetric distributions and discrete groups. We validate the effectiveness of\nour approach on synthetic datasets with different per-class levels of\nsymmetries, and demonstrate practical applications such as the detection of\nout-of-distribution symmetries. Our code is publicly available at\nhttps://github.com/aurban0/ssl-sym.\n","authors":["Alonso Urbano","David W. Romero"],"pdf_url":"https://arxiv.org/pdf/2312.12223v3.pdf","comment":"19 pages, 8 figures, corrected typos, revised argument in Appendix\n  B.1, results unchanged"},{"id":"http://arxiv.org/abs/2406.19150v1","updated":"2024-06-27T13:08:35Z","published":"2024-06-27T13:08:35Z","title":"RAVEN: Multitask Retrieval Augmented Vision-Language Learning","summary":"  The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.\n","authors":["Varun Nagaraj Rao","Siddharth Choudhary","Aditya Deshpande","Ravi Kumar Satzoda","Srikar Appalaraju"],"pdf_url":"https://arxiv.org/pdf/2406.19150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19148v1","updated":"2024-06-27T13:06:47Z","published":"2024-06-27T13:06:47Z","title":"BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal\n  Supervision","summary":"  Neural networks can learn spurious correlations that lead to the correct\nprediction in a validation set, but generalise poorly because the predictions\nare right for the wrong reason. This undesired learning of naive shortcuts\n(Clever Hans effect) can happen for example in echocardiogram view\nclassification when background cues (e.g. metadata) are biased towards a class\nand the model learns to focus on those background features instead of on the\nimage content. We propose a simple, yet effective random background\naugmentation method called BackMix, which samples random backgrounds from other\nexamples in the training set. By enforcing the background to be uncorrelated\nwith the outcome, the model learns to focus on the data within the ultrasound\nsector and becomes invariant to the regions outside this. We extend our method\nin a semi-supervised setting, finding that the positive effects of BackMix are\nmaintained with as few as 5% of segmentation labels. A loss weighting\nmechanism, wBackMix, is also proposed to increase the contribution of the\naugmented examples. We validate our method on both in-distribution and\nout-of-distribution datasets, demonstrating significant improvements in\nclassification accuracy, region focus and generalisability. Our source code is\navailable at: https://github.com/kitbransby/BackMix\n","authors":["Kit Mills Bransby","Arian Beqiri","Woo-Jin Cho Kim","Jorge Oliveira","Agisilaos Chartsias","Alberto Gomez"],"pdf_url":"https://arxiv.org/pdf/2406.19148v1.pdf","comment":"Accepted at MICCAI 2024 (Pre-print)"},{"id":"http://arxiv.org/abs/2311.16480v4","updated":"2024-06-27T12:38:12Z","published":"2023-11-27T05:05:41Z","title":"WsiCaption: Multiple Instance Generation of Pathology Reports for\n  Gigapixel Whole-Slide Images","summary":"  Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(PathText). In specific, we collected nearly 10000 high-quality WSI-text pairs\nfor visual-language models by recognizing and cleaning pathology reports which\nnarrate diagnostic slides in TCGA. On the model end, we propose the multiple\ninstance generative model (MI-Gen) which can produce pathology reports for\ngigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText.\nExperimental results show our model can generate pathology reports which\ncontain multiple clinical clues and achieve competitive performance on certain\nslide-level tasks. We observe that simple semantic extraction from the\npathology reports can achieve the best performance (0.838 of F1 score) on BRCA\nsubtyping surpassing previous state-of-the-art approaches. Our collected\ndataset and related code are available.\n","authors":["Pingyi Chen","Honglin Li","Chenglu Zhu","Sunyi Zheng","Zhongyi Shui","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.16480v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19131v1","updated":"2024-06-27T12:34:52Z","published":"2024-06-27T12:34:52Z","title":"CELLO: Causal Evaluation of Large Vision-Language Models","summary":"  Causal reasoning is fundamental to human intelligence and crucial for\neffective decision-making in real-world environments. Despite recent\nadvancements in large vision-language models (LVLMs), their ability to\ncomprehend causality remains unclear. Previous work typically focuses on\ncommonsense causality between events and/or actions, which is insufficient for\napplications like embodied agents and lacks the explicitly defined causal\ngraphs required for formal causal reasoning. To overcome these limitations, we\nintroduce a fine-grained and unified definition of causality involving\ninteractions between humans and/or objects. Building on the definition, we\nconstruct a novel dataset, CELLO, consisting of 14,094 causal questions across\nall four levels of causality: discovery, association, intervention, and\ncounterfactual. This dataset surpasses traditional commonsense causality by\nincluding explicit causal graphs that detail the interactions between humans\nand objects. Extensive experiments on CELLO reveal that current LVLMs still\nstruggle with causal reasoning tasks, but they can benefit significantly from\nour proposed CELLO-CoT, a causally inspired chain-of-thought prompting\nstrategy. Both quantitative and qualitative analyses from this study provide\nvaluable insights for future research. Our project page is at\nhttps://github.com/OpenCausaLab/CELLO.\n","authors":["Meiqi Chen","Bo Peng","Yan Zhang","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.19131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19130v1","updated":"2024-06-27T12:29:50Z","published":"2024-06-27T12:29:50Z","title":"Evidential Concept Embedding Models: Towards Reliable Concept\n  Explanations for Skin Disease Diagnosis","summary":"  Due to the high stakes in medical decision-making, there is a compelling\ndemand for interpretable deep learning methods in medical image analysis.\nConcept Bottleneck Models (CBM) have emerged as an active interpretable\nframework incorporating human-interpretable concepts into decision-making.\nHowever, their concept predictions may lack reliability when applied to\nclinical diagnosis, impeding concept explanations' quality. To address this, we\npropose an evidential Concept Embedding Model (evi-CEM), which employs\nevidential learning to model the concept uncertainty. Additionally, we offer to\nleverage the concept uncertainty to rectify concept misalignments that arise\nwhen training CBMs using vision-language models without complete concept\nsupervision. With the proposed methods, we can enhance concept explanations'\nreliability for both supervised and label-efficient settings. Furthermore, we\nintroduce concept uncertainty for effective test-time intervention. Our\nevaluation demonstrates that evi-CEM achieves superior performance in terms of\nconcept prediction, and the proposed concept rectification effectively\nmitigates concept misalignments for label-efficient training. Our code is\navailable at https://github.com/obiyoag/evi-CEM.\n","authors":["Yibo Gao","Zheyao Gao","Xin Gao","Yuanye Liu","Bomin Wang","Xiahai Zhuang"],"pdf_url":"https://arxiv.org/pdf/2406.19130v1.pdf","comment":"accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2309.15785v2","updated":"2024-06-27T12:05:48Z","published":"2023-09-27T16:58:35Z","title":"BT-Adapter: Video Conversation is Feasible Without Video Instruction\n  Tuning","summary":"  The recent progress in Large Language Models (LLM) has spurred various\nadvancements in image-language conversation agents, while how to build a\nproficient video-based dialogue system is still under exploration. Considering\nthe extensive scale of LLM and visual backbone, minimal GPU memory is left for\nfacilitating effective temporal modeling, which is crucial for comprehending\nand providing feedback on videos. To this end, we propose Branching Temporal\nAdapter (BT-Adapter), a novel method for extending image-language pretrained\nmodels into the video domain. Specifically, BT-Adapter serves as a plug-and-use\ntemporal modeling branch alongside the pretrained visual encoder, which is\ntuned while keeping the backbone frozen. Just pretrained once, BT-Adapter can\nbe seamlessly integrated into all image conversation models using this version\nof CLIP, enabling video conversations without the need for video instructions.\nBesides, we develop a unique asymmetric token masking strategy inside the\nbranch with tailor-made training tasks for BT-Adapter, facilitating faster\nconvergence and better results. Thanks to BT-Adapter, we are able to empower\nexisting multimodal dialogue models with strong video understanding\ncapabilities without incurring excessive GPU costs. Without bells and whistles,\nBT-Adapter achieves (1) state-of-the-art zero-shot results on various video\ntasks using thousands of fewer GPU hours. (2) better performance than current\nvideo chatbots without any video instruction tuning. (3) state-of-the-art\nresults of video chatting using video instruction tuning, outperforming\nprevious SOTAs by a large margin.\n","authors":["Ruyang Liu","Chen Li","Yixiao Ge","Ying Shan","Thomas H. Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2309.15785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19107v1","updated":"2024-06-27T11:34:27Z","published":"2024-06-27T11:34:27Z","title":"FDLite: A Single Stage Lightweight Face Detector Network","summary":"  Face detection is frequently attempted by using heavy pre-trained backbone\nnetworks like ResNet-50/101/152 and VGG16/19. Few recent works have also\nproposed lightweight detectors with customized backbones, novel loss functions\nand efficient training strategies. The novelty of this work lies in the design\nof a lightweight detector while training with only the commonly used loss\nfunctions and learning strategies. The proposed face detector grossly follows\nthe established RetinaFace architecture. The first contribution of this work is\nthe design of a customized lightweight backbone network (BLite) having 0.167M\nparameters with 0.52 GFLOPs. The second contribution is the use of two\nindependent multi-task losses. The proposed lightweight face detector (FDLite)\nhas 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE\ndataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average\nPrecision (AP) on the easy, medium, and hard subsets of the WIDER FACE\nvalidation dataset, respectively.\n","authors":["Yogesh Aggarwal","Prithwijit Guha"],"pdf_url":"https://arxiv.org/pdf/2406.19107v1.pdf","comment":"10 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.19101v1","updated":"2024-06-27T11:28:36Z","published":"2024-06-27T11:28:36Z","title":"DocKylin: A Large Multimodal Model for Visual Document Understanding\n  with Efficient Visual Slimming","summary":"  Current multimodal large language models (MLLMs) face significant challenges\nin visual document understanding (VDU) tasks due to the high resolution, dense\ntext, and complex layouts typical of document images. These characteristics\ndemand a high level of detail perception ability from MLLMs. While increasing\ninput resolution improves detail perception, it also leads to longer sequences\nof visual tokens, increasing computational costs and straining the models'\nability to handle long contexts. To address these challenges, we introduce\nDocKylin, a document-centric MLLM that performs visual content slimming at both\nthe pixel and token levels, thereby reducing token sequence length in VDU\nscenarios. DocKylin utilizes an Adaptive Pixel Slimming (APS) preprocessing\nmodule to perform pixel-level slimming, increasing the proportion of\ninformative pixels. Moreover, DocKylin incorporates a novel Dynamic Token\nSlimming (DTS) module to conduct token-level slimming, filtering essential\ntokens and removing others to create a compressed, adaptive visual sequence.\nExperiments demonstrate DocKylin's promising performance across various VDU\nbenchmarks. Notably, both the proposed APS and DTS are parameter-free,\nfacilitating easy integration into existing MLLMs, and our experiments indicate\ntheir potential for broader applications.\n","authors":["Jiaxin Zhang","Wentao Yang","Songxuan Lai","Zecheng Xie","Lianwen Jin"],"pdf_url":"https://arxiv.org/pdf/2406.19101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19087v1","updated":"2024-06-27T11:14:14Z","published":"2024-06-27T11:14:14Z","title":"Dimensions underlying the representational alignment of deep neural\n  networks with humans","summary":"  Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.\n","authors":["Florian P. Mahner","Lukas Muttenthaler","Umut Güçlü","Martin N. Hebart"],"pdf_url":"https://arxiv.org/pdf/2406.19087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19081v1","updated":"2024-06-27T11:08:42Z","published":"2024-06-27T11:08:42Z","title":"Unsupervised Latent Stain Adaption for Digital Pathology","summary":"  In digital pathology, deep learning (DL) models for tasks such as\nsegmentation or tissue classification are known to suffer from domain shifts\ndue to different staining techniques. Stain adaptation aims to reduce the\ngeneralization error between different stains by training a model on source\nstains that generalizes to target stains. Despite the abundance of target stain\ndata, a key challenge is the lack of annotations. To address this, we propose a\njoint training between artificially labeled and unlabeled data including all\navailable stained images called Unsupervised Latent Stain Adaption (ULSA). Our\nmethod uses stain translation to enrich labeled source images with synthetic\ntarget images in order to increase supervised signals. Moreover, we leverage\nunlabeled target stain images using stain-invariant feature consistency\nlearning. With ULSA we present a semi-supervised strategy for efficient stain\nadaption without access to annotated target stain data. Remarkably, ULSA is\ntask agnostic in patch-level analysis for whole slide images (WSIs). Through\nextensive evaluation on external datasets, we demonstrate that ULSA achieves\nstate-of-the-art (SOTA) performance in kidney tissue segmentation and breast\ncancer classification across a spectrum of staining variations. Our findings\nsuggest that ULSA is an important framework towards stain adaption in digital\npathology.\n","authors":["Daniel Reisenbüchler","Lucas Luttner","Nadine S. Schaadt","Friedrich Feuerhake","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2406.19081v1.pdf","comment":"Accepted in MICCAI2024"},{"id":"http://arxiv.org/abs/2406.19070v1","updated":"2024-06-27T10:40:35Z","published":"2024-06-27T10:40:35Z","title":"FAGhead: Fully Animate Gaussian Head from Monocular Videos","summary":"  High-fidelity reconstruction of 3D human avatars has a wild application in\nvisual reality. In this paper, we introduce FAGhead, a method that enables\nfully controllable human portraits from monocular videos. We explicit the\ntraditional 3D morphable meshes (3DMM) and optimize the neutral 3D Gaussians to\nreconstruct with complex expressions. Furthermore, we employ a novel\nPoint-based Learnable Representation Field (PLRF) with learnable Gaussian point\npositions to enhance reconstruction performance. Meanwhile, to effectively\nmanage the edges of avatars, we introduced the alpha rendering to supervise the\nalpha value of each pixel. Extensive experimental results on the open-source\ndatasets and our capturing datasets demonstrate that our approach is able to\ngenerate high-fidelity 3D head avatars and fully control the expression and\npose of the virtual avatars, which is outperforming than existing works.\n","authors":["Yixin Xuan","Xinyang Li","Gongxin Yao","Shiwei Zhou","Donghui Sun","Xiaoxin Chen","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2406.19070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04698v4","updated":"2024-06-27T10:34:28Z","published":"2023-11-08T14:10:19Z","title":"Examining Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we investigate paradigms in MTL in\nthe context of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Overall,\nwe find surprising similarities between STL and MTL suggesting to consider\nmethods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v4.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2406.19057v1","updated":"2024-06-27T10:08:29Z","published":"2024-06-27T10:08:29Z","title":"Segment Anything Model for automated image data annotation: empirical\n  studies using text prompts from Grounding DINO","summary":"  Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2406.19057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19055v1","updated":"2024-06-27T10:03:20Z","published":"2024-06-27T10:03:20Z","title":"SimpleFusion: A Simple Fusion Framework for Infrared and Visible Images","summary":"  Integrating visible and infrared images into one high-quality image, also\nknown as visible and infrared image fusion, is a challenging yet critical task\nfor many downstream vision tasks. Most existing works utilize pretrained deep\nneural networks or design sophisticated frameworks with strong priors for this\ntask, which may be unsuitable or lack flexibility. This paper presents\nSimpleFusion, a simple yet effective framework for visible and infrared image\nfusion. Our framework follows the decompose-and-fusion paradigm, where the\nvisible and the infrared images are decomposed into reflectance and\nillumination components via Retinex theory and followed by the fusion of these\ncorresponding elements. The whole framework is designed with two plain\nconvolutional neural networks without downsampling, which can perform image\ndecomposition and fusion efficiently. Moreover, we introduce decomposition loss\nand a detail-to-semantic loss to preserve the complementary information between\nthe two modalities for fusion. We conduct extensive experiments on the\nchallenging benchmarks, verifying the superiority of our method over previous\nstate-of-the-arts. Code is available at\n\\href{https://github.com/hxwxss/SimpleFusion-A-Simple-Fusion-Framework-for-Infrared-and-Visible-Images}{https://github.com/hxwxss/SimpleFusion-A-Simple-Fusion-Framework-for-Infrared-and-Visible-Images}\n","authors":["Ming Chen","Yuxuan Cheng","Xinwei He","Xinyue Wang","Yan Aze","Jinhai Xiang"],"pdf_url":"https://arxiv.org/pdf/2406.19055v1.pdf","comment":"code:https://github.com/hxwxss/SimpleFusion-A-Simple-Fusion-Framework-for-Infrared-and-Visible-Images"},{"id":"http://arxiv.org/abs/2406.19048v1","updated":"2024-06-27T09:56:38Z","published":"2024-06-27T09:56:38Z","title":"BiCo-Fusion: Bidirectional Complementary LiDAR-Camera Fusion for\n  Semantic- and Spatial-Aware 3D Object Detection","summary":"  3D object detection is an important task that has been widely applied in\nautonomous driving. Recently, fusing multi-modal inputs, i.e., LiDAR and camera\ndata, to perform this task has become a new trend. Existing methods, however,\neither ignore the sparsity of Lidar features or fail to preserve the original\nspatial structure of LiDAR and the semantic density of camera features\nsimultaneously due to the modality gap. To address issues, this letter proposes\na novel bidirectional complementary Lidar-camera fusion framework, called\nBiCo-Fusion that can achieve robust semantic- and spatial-aware 3D object\ndetection. The key insight is to mutually fuse the multi-modal features to\nenhance the semantics of LiDAR features and the spatial awareness of the camera\nfeatures and adaptatively select features from both modalities to build a\nunified 3D representation. Specifically, we introduce Pre-Fusion consisting of\na Voxel Enhancement Module (VEM) to enhance the semantics of voxel features\nfrom 2D camera features and Image Enhancement Module (IEM) to enhance the\nspatial characteristics of camera features from 3D voxel features. Both VEM and\nIEM are bidirectionally updated to effectively reduce the modality gap. We then\nintroduce Unified Fusion to adaptively weight to select features from the\nenchanted Lidar and camera features to build a unified 3D representation.\nExtensive experiments demonstrate the superiority of our BiCo-Fusion against\nthe prior arts. Project page: https://t-ys.github.io/BiCo-Fusion/.\n","authors":["Yang Song","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19048v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.19043v1","updated":"2024-06-27T09:50:20Z","published":"2024-06-27T09:50:20Z","title":"CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI","summary":"  Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly\navailable cardiac k-space dataset. It is acquired from 330 healthy volunteers,\ncovering commonly used modalities, anatomical views, and acquisition\ntrajectories in clinical cardiac MRI workflows. Besides, an open platform with\ntutorials, benchmarks, and data processing tools is provided to facilitate data\nusage, advanced method development, and fair performance evaluation.\n","authors":["Zi Wang","Fanwen Wang","Chen Qin","Jun Lyu","Ouyang Cheng","Shuo Wang","Yan Li","Mengyao Yu","Haoyu Zhang","Kunyuan Guo","Zhang Shi","Qirong Li","Ziqiang Xu","Yajing Zhang","Hao Li","Sha Hua","Binghua Chen","Longyu Sun","Mengting Sun","Qin Li","Ying-Hua Chu","Wenjia Bai","Jing Qin","Xiahai Zhuang","Claudia Prieto","Alistair Young","Michael Markl","He Wang","Lianming Wu","Guang Yang","Xiaobo Qu","Chengyan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19043v1.pdf","comment":"19 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.19030v1","updated":"2024-06-27T09:33:24Z","published":"2024-06-27T09:33:24Z","title":"Using diffusion model as constraint: Empower Image Restoration Network\n  Training with Diffusion Model","summary":"  Image restoration has made marvelous progress with the advent of deep\nlearning. Previous methods usually rely on designing powerful network\narchitecture to elevate performance, however, the natural visual effect of the\nrestored results is limited by color and texture distortions. Besides the\nvisual perceptual quality, the semantic perception recovery is an important but\noften overlooked perspective of restored image, which is crucial for the\ndeployment in high-level tasks. In this paper, we propose a new perspective to\nresort these issues by introducing a naturalness-oriented and semantic-aware\noptimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful\ndistribution coverage capability of the diffusion model for natural image\ngeneration, we exploit the Markov chain sampling property of diffusion model\nand project the restored results of existing networks into the sampling space.\nBesides, we reveal that the bottleneck feature of diffusion models, also dubbed\nh-space feature, is a natural high-level semantic space. We delve into this\nproperty and propose a semantic-aware loss to further unlock its potential of\nsemantic perception recovery, which paves the way to connect image restoration\ntask and downstream high-level recognition task. With these two strategies, the\nDiffLoss can endow existing restoration methods with both more natural and\nsemantic-aware results. We verify the effectiveness of our method on\nsubstantial common image restoration tasks and benchmarks. Code will be\navailable at https://github.com/JosephTiTan/DiffLoss.\n","authors":["Jiangtong Tan","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.19030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12540v3","updated":"2024-06-27T09:03:14Z","published":"2023-12-19T19:19:19Z","title":"Regularized Newton Raphson Inversion for Text-to-Image Diffusion Models","summary":"  Diffusion inversion is the problem of taking an image and a text prompt that\ndescribes it and finding a noise latent that would generate the image. Most\ncurrent inversion techniques operate by approximately solving an implicit\nequation and may converge slowly or yield poor reconstructed images. Here, we\nformulate the problem as finding the roots of an implicit equation and design a\nmethod to solve it efficiently. Our solution is based on Newton-Raphson (NR), a\nwell-known technique in numerical analysis. A naive application of NR may be\ncomputationally infeasible and tends to converge to incorrect solutions. We\ndescribe an efficient regularized formulation that converges quickly to a\nsolution that provides high-quality reconstructions. We also identify a source\nof inconsistency stemming from prompt conditioning during the inversion\nprocess, which significantly degrades the inversion quality. To address this,\nwe introduce a prompt-aware adjustment of the encoding, effectively correcting\nthis issue. Our solution, Regularized Newton-Raphson Inversion, inverts an\nimage within 0.5 sec for latent consistency models, opening the door for\ninteractive image editing. We further demonstrate improved results in image\ninterpolation and generation of rare objects.\n","authors":["Dvir Samuel","Barak Meiri","Nir Darshan","Shai Avidan","Gal Chechik","Rami Ben-Ari"],"pdf_url":"https://arxiv.org/pdf/2312.12540v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18361v2","updated":"2024-06-27T08:53:25Z","published":"2024-06-26T14:01:07Z","title":"Stable Diffusion Segmentation for Biomedical Images with Single-step\n  Reverse Process","summary":"  Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg\n","authors":["Tianyu Lin","Zhiguang Chen","Zhonghao Yan","Weijiang Yu","Fudan Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.18361v2.pdf","comment":"Accepted at MICCAI 2024. Code and citation info see\n  https://github.com/lin-tianyu/Stable-Diffusion-Seg"},{"id":"http://arxiv.org/abs/2406.19006v1","updated":"2024-06-27T08:45:31Z","published":"2024-06-27T08:45:31Z","title":"VideoMambaPro: A Leap Forward for Mamba in Video Understanding","summary":"  Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to computer vision tasks, including those in\nvideo analysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. VideoMambaPro shows state-of-the-art video action recognition\nperformance compared to transformer models, and surpasses VideoMamba by clear\nmargins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,\nrespectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,\nonly 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The\ncombination of high performance and efficiency makes VideoMambaPro an\ninteresting alternative for transformer models.\n","authors":["Hui Lu","Albert Ali Salah","Ronald Poppe"],"pdf_url":"https://arxiv.org/pdf/2406.19006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18999v1","updated":"2024-06-27T08:39:16Z","published":"2024-06-27T08:39:16Z","title":"Improving Taxonomic Image-based Out-of-distribution Detection With DNA\n  Barcodes","summary":"  Image-based species identification could help scaling biodiversity monitoring\nto a global scale. Many challenges still need to be solved in order to\nimplement these systems in real-world applications. A reliable image-based\nmonitoring system must detect out-of-distribution (OOD) classes it has not been\npresented before. This is challenging especially with fine-grained classes.\nEmerging environmental monitoring techniques, DNA metabarcoding and eDNA, can\nhelp by providing information on OOD classes that are present in a sample. In\nthis paper, we study if DNA barcodes can also support in finding the outlier\nimages based on the outlier DNA sequence's similarity to the seen classes. We\npropose a re-ordering approach that can be easily applied on any pre-trained\nmodels and existing OOD detection methods. We experimentally show that the\nproposed approach improves taxonomic OOD detection compared to all common\nbaselines. We also show that the method works thanks to a correlation between\nvisual similarity and DNA barcode proximity. The code and data are available at\nhttps://github.com/mikkoim/dnaimg-ood.\n","authors":["Mikko Impiö","Jenni Raitoharju"],"pdf_url":"https://arxiv.org/pdf/2406.18999v1.pdf","comment":"Accepted to EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2406.18996v1","updated":"2024-06-27T08:37:26Z","published":"2024-06-27T08:37:26Z","title":"Zero-shot domain adaptation based on dual-level mix and contrast","summary":"  Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.\n","authors":["Yu Zhe","Jun Sakuma"],"pdf_url":"https://arxiv.org/pdf/2406.18996v1.pdf","comment":"Accepted by IEEE conference on Artificial intelligence 2024"},{"id":"http://arxiv.org/abs/2406.18992v1","updated":"2024-06-27T08:33:35Z","published":"2024-06-27T08:33:35Z","title":"Semi-supervised Concept Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.\n","authors":["Lijie Hu","Tianhao Huang","Huanyi Xie","Chenyang Ren","Zhengyu Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18992v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2403.02311v3","updated":"2024-06-27T08:21:51Z","published":"2024-03-04T18:47:56Z","title":"Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications\n  to Cardiac MRI Segmentation","summary":"  Deep learning (DL)-based methods have achieved state-of-the-art performance\nfor many medical image segmentation tasks. Nevertheless, recent studies show\nthat deep neural networks (DNNs) can be miscalibrated and overconfident,\nleading to \"silent failures\" that are risky for clinical applications. Bayesian\nDL provides an intuitive approach to DL failure detection, based on posterior\nprobability estimation. However, the posterior is intractable for large medical\nimage segmentation DNNs. To tackle this challenge, we propose a Bayesian\nlearning framework using Hamiltonian Monte Carlo (HMC), tempered by cold\nposterior (CP) to accommodate medical data augmentation, named HMC-CP. For HMC\ncomputation, we further propose a cyclical annealing strategy, capturing both\nlocal and global geometries of the posterior distribution, enabling highly\nefficient Bayesian DNN training with the same computational budget as training\na single DNN. The resulting Bayesian DNN outputs an ensemble segmentation along\nwith the segmentation uncertainty. We evaluate the proposed HMC-CP extensively\non cardiac magnetic resonance image (MRI) segmentation, using in-domain\nsteady-state free precession (SSFP) cine images as well as out-of-domain\ndatasets of quantitative T1 and T2 mapping. Our results show that the proposed\nmethod improves both segmentation accuracy and uncertainty estimation for in-\nand out-of-domain data, compared with well-established baseline methods such as\nMonte Carlo Dropout and Deep Ensembles. Additionally, we establish a conceptual\nlink between HMC and the commonly known stochastic gradient descent (SGD) and\nprovide general insight into the uncertainty of DL. This uncertainty is\nimplicitly encoded in the training dynamics but often overlooked. With reliable\nuncertainty estimation, our method provides a promising direction toward\ntrustworthy DL in clinical applications.\n","authors":["Yidong Zhao","Joao Tourais","Iain Pierce","Christian Nitsche","Thomas A. Treibel","Sebastian Weingärtner","Artur M. Schweidtmann","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2403.02311v3.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:011"},{"id":"http://arxiv.org/abs/2311.15937v2","updated":"2024-06-27T08:21:16Z","published":"2023-11-27T15:46:19Z","title":"Optimal Transport Aggregation for Visual Place Recognition","summary":"  The task of Visual Place Recognition (VPR) aims to match a query image\nagainst references from an extensive database of images from different places,\nrelying solely on visual cues. State-of-the-art pipelines focus on the\naggregation of features extracted from a deep backbone, in order to form a\nglobal descriptor for each image. In this context, we introduce SALAD (Sinkhorn\nAlgorithm for Locally Aggregated Descriptors), which reformulates NetVLAD's\nsoft-assignment of local features to clusters as an optimal transport problem.\nIn SALAD, we consider both feature-to-cluster and cluster-to-feature relations\nand we also introduce a 'dustbin' cluster, designed to selectively discard\nfeatures deemed non-informative, enhancing the overall descriptor quality.\nAdditionally, we leverage and fine-tune DINOv2 as a backbone, which provides\nenhanced description power for the local features, and dramatically reduces the\nrequired training time. As a result, our single-stage method not only surpasses\nsingle-stage baselines in public VPR datasets, but also surpasses two-stage\nmethods that add a re-ranking with significantly higher cost. Code and models\nare available at https://github.com/serizba/salad.\n","authors":["Sergio Izquierdo","Javier Civera"],"pdf_url":"https://arxiv.org/pdf/2311.15937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18977v1","updated":"2024-06-27T08:13:33Z","published":"2024-06-27T08:13:33Z","title":"RoboUniView: Visual-Language Model with Unified View Representation for\n  Robotic Manipulaiton","summary":"  Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview\n","authors":["Fanfan Liu","Feng Yan","Liming Zheng","Chengjian Feng","Yiyang Huang","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2406.18977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09327v2","updated":"2024-06-27T08:09:27Z","published":"2024-06-13T17:06:15Z","title":"Towards AI Lesion Tracking in PET/CT Imaging: A Siamese-based CNN\n  Pipeline applied on PSMA PET/CT Scans","summary":"  Assessing tumor response to systemic therapies is one of the main\napplications of PET/CT. Routinely, only a small subset of index lesions out of\nmultiple lesions is analyzed. However, this operator dependent selection may\nbias the results due to possible significant inter-metastatic heterogeneity of\nresponse to therapy. Automated, AI based approaches for lesion tracking hold\npromise in enabling the analysis of many more lesions and thus providing a\nbetter assessment of tumor response. This work introduces a Siamese CNN\napproach for lesion tracking between PET/CT scans. Our approach is applied on\nthe laborious task of tracking a high number of bone lesions in full-body\nbaseline and follow-up [68Ga]Ga- or [18F]F-PSMA PET/CT scans after two cycles\nof [177Lu]Lu-PSMA therapy of metastatic castration resistant prostate cancer\npatients. Data preparation includes lesion segmentation and affine\nregistration. Our algorithm extracts suitable lesion patches and forwards them\ninto a Siamese CNN trained to classify the lesion patch pairs as corresponding\nor non-corresponding lesions. Experiments have been performed with different\ninput patch types and a Siamese network in 2D and 3D. The CNN model\nsuccessfully learned to classify lesion assignments, reaching a lesion tracking\naccuracy of 83 % in its best configuration with an AUC = 0.91. For remaining\nlesions the pipeline accomplished a re-identification rate of 89 %. We proved\nthat a CNN may facilitate the tracking of multiple lesions in PSMA PET/CT\nscans. Future clinical studies are necessary if this improves the prediction of\nthe outcome of therapies.\n","authors":["Stefan P. Hein","Manuel Schultheiss","Andrei Gafita","Raphael Zaum","Farid Yagubbayli","Robert Tauber","Isabel Rauscher","Matthias Eiber","Franz Pfeiffer","Wolfgang A. Weber"],"pdf_url":"https://arxiv.org/pdf/2406.09327v2.pdf","comment":"25 pages, 9 figures, 3 tables"},{"id":"http://arxiv.org/abs/2406.18967v1","updated":"2024-06-27T07:59:25Z","published":"2024-06-27T07:59:25Z","title":"Structural Attention: Rethinking Transformer for Unpaired Medical Image\n  Synthesis","summary":"  Unpaired medical image synthesis aims to provide complementary information\nfor an accurate clinical diagnostics, and address challenges in obtaining\naligned multi-modal medical scans. Transformer-based models excel in imaging\ntranslation tasks thanks to their ability to capture long-range dependencies.\nAlthough effective in supervised training settings, their performance falters\nin unpaired image synthesis, particularly in synthesizing structural details.\nThis paper empirically demonstrates that, lacking strong inductive biases,\nTransformer can converge to non-optimal solutions in the absence of paired\ndata. To address this, we introduce UNet Structured Transformer (UNest), a\nnovel architecture incorporating structural inductive biases for unpaired\nmedical image synthesis. We leverage the foundational Segment-Anything Model to\nprecisely extract the foreground structure and perform structural attention\nwithin the main anatomy. This guides the model to learn key anatomical regions,\nthus improving structural synthesis under the lack of supervision in unpaired\ntraining. Evaluated on two public datasets, spanning three modalities, i.e.,\nMR, CT, and PET, UNest improves recent methods by up to 19.30% across six\nmedical image synthesis tasks. Our code is released at\nhttps://github.com/HieuPhan33/MICCAI2024-UNest.\n","authors":["Vu Minh Hieu Phan","Yutong Xie","Bowen Zhang","Yuankai Qi","Zhibin Liao","Antonios Perperidis","Son Lam Phung","Johan W. Verjans","Minh-Son To"],"pdf_url":"https://arxiv.org/pdf/2406.18967v1.pdf","comment":"MICCAI2024 - Early Accept Top 11%"},{"id":"http://arxiv.org/abs/2406.18958v1","updated":"2024-06-27T07:40:59Z","published":"2024-06-27T07:40:59Z","title":"AnyControl: Create Your Artwork with Versatile Control on Text-to-Image\n  Generation","summary":"  The field of text-to-image (T2I) generation has made significant progress in\nrecent years, largely driven by advancements in diffusion models. Linguistic\ncontrol enables effective content creation, but struggles with fine-grained\ncontrol over image generation. This challenge has been explored, to a great\nextent, by incorporating additional user-supplied spatial conditions, such as\ndepth maps and edge maps, into pre-trained T2I models through extra encoding.\nHowever, multi-control image synthesis still faces several challenges.\nSpecifically, current approaches are limited in handling free combinations of\ndiverse input control signals, overlook the complex relationships among\nmultiple spatial conditions, and often fail to maintain semantic alignment with\nprovided textual prompts. This can lead to suboptimal user experiences. To\naddress these challenges, we propose AnyControl, a multi-control image\nsynthesis framework that supports arbitrary combinations of diverse control\nsignals. AnyControl develops a novel Multi-Control Encoder that extracts a\nunified multi-modal embedding to guide the generation process. This approach\nenables a holistic understanding of user inputs, and produces high-quality,\nfaithful results under versatile control signals, as demonstrated by extensive\nquantitative and qualitative evaluations. Our project page is available in\n\\url{https://any-control.github.io}.\n","authors":["Yanan Sun","Yanchen Liu","Yinhao Tang","Wenjie Pei","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17858v2","updated":"2024-06-27T07:39:05Z","published":"2024-06-25T18:02:11Z","title":"Depth-Driven Geometric Prompt Learning for Laparoscopic Liver Landmark\n  Detection","summary":"  Laparoscopic liver surgery poses a complex intraoperative dynamic environment\nfor surgeons, where remains a significant challenge to distinguish critical or\neven hidden structures inside the liver. Liver anatomical landmarks, e.g.,\nridge and ligament, serve as important markers for 2D-3D alignment, which can\nsignificantly enhance the spatial perception of surgeons for precise surgery.\nTo facilitate the detection of laparoscopic liver landmarks, we collect a novel\ndataset called L3D, which comprises 1,152 frames with elaborated landmark\nannotations from surgical videos of 39 patients across two medical sites. For\nbenchmarking purposes, 12 mainstream detection methods are selected and\ncomprehensively evaluated on L3D. Further, we propose a depth-driven geometric\nprompt learning network, namely D2GPLand. Specifically, we design a Depth-aware\nPrompt Embedding (DPE) module that is guided by self-supervised prompts and\ngenerates semantically relevant geometric information with the benefit of\nglobal depth cues extracted from SAM-based features. Additionally, a\nSemantic-specific Geometric Augmentation (SGA) scheme is introduced to\nefficiently merge RGB-D spatial and geometric information through reverse\nanatomic perception. The experimental results indicate that D2GPLand obtains\nstate-of-the-art performance on L3D, with 63.52% DICE and 48.68% IoU scores.\nTogether with 2D-3D fusion technology, our method can directly provide the\nsurgeon with intuitive guidance information in laparoscopic scenarios.\n","authors":["Jialun Pei","Ruize Cui","Yaoqian Li","Weixin Si","Jing Qin","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.17858v2.pdf","comment":"This paper has been accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.18950v1","updated":"2024-06-27T07:30:54Z","published":"2024-06-27T07:30:54Z","title":"MMR-Mamba: Multi-Contrast MRI Reconstruction with Mamba and\n  Spatial-Frequency Information Fusion","summary":"  Multi-contrast MRI acceleration has become prevalent in MR imaging, enabling\nthe reconstruction of high-quality MR images from under-sampled k-space data of\nthe target modality, using guidance from a fully-sampled auxiliary modality.\nThe main crux lies in efficiently and comprehensively integrating complementary\ninformation from the auxiliary modality. Existing methods either suffer from\nquadratic computational complexity or fail to capture long-range correlated\nfeatures comprehensively. In this work, we propose MMR-Mamba, a novel framework\nthat achieves comprehensive integration of multi-contrast features through\nMamba and spatial-frequency information fusion. Firstly, we design the\n\\textit{Target modality-guided Cross Mamba} (TCM) module in the spatial domain,\nwhich maximally restores the target modality information by selectively\nabsorbing useful information from the auxiliary modality. Secondly, leveraging\nglobal properties of the Fourier domain, we introduce the \\textit{Selective\nFrequency Fusion} (SFF) module to efficiently integrate global information in\nthe frequency domain and recover high-frequency signals for the reconstruction\nof structure details. Additionally, we present the \\textit{Adaptive\nSpatial-Frequency Fusion} (ASFF) module, which enhances fused features by\nsupplementing less informative features from one domain with corresponding\nfeatures from the other domain. These innovative strategies ensure efficient\nfeature fusion across spatial and frequency domains, avoiding the introduction\nof redundant information and facilitating the reconstruction of high-quality\ntarget images. Extensive experiments on the BraTS and fastMRI knee datasets\ndemonstrate the superiority of the proposed MMR-Mamba over state-of-the-art MRI\nreconstruction methods.\n","authors":["Jing Zou","Lanqing Liu","Qi Chen","Shujun Wang","Xiaohan Xing","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2406.18950v1.pdf","comment":"10 pages, 5 figure"},{"id":"http://arxiv.org/abs/2310.02792v2","updated":"2024-06-27T07:29:09Z","published":"2023-10-04T13:11:20Z","title":"Continuous 3D Myocardial Motion Tracking via Echocardiography","summary":"  Myocardial motion tracking stands as an essential clinical tool in the\nprevention and detection of cardiovascular diseases (CVDs), the foremost cause\nof death globally. However, current techniques suffer from incomplete and\ninaccurate motion estimation of the myocardium in both spatial and temporal\ndimensions, hindering the early identification of myocardial dysfunction. To\naddress these challenges, this paper introduces the Neural Cardiac Motion Field\n(NeuralCMF). NeuralCMF leverages implicit neural representation (INR) to model\nthe 3D structure and the comprehensive 6D forward/backward motion of the heart.\nThis method surpasses pixel-wise limitations by offering the capability to\ncontinuously query the precise shape and motion of the myocardium at any\nspecific point throughout the cardiac cycle, enhancing the detailed analysis of\ncardiac dynamics beyond traditional speckle tracking. Notably, NeuralCMF\noperates without the need for paired datasets, and its optimization is\nself-supervised through the physics knowledge priors in both space and time\ndimensions, ensuring compatibility with both 2D and 3D echocardiogram video\ninputs. Experimental validations across three representative datasets support\nthe robustness and innovative nature of the NeuralCMF, marking significant\nadvantages over existing state-of-the-art methods in cardiac imaging and motion\ntracking.\n","authors":["Chengkang Shen","Hao Zhu","You Zhou","Yu Liu","Si Yi","Lili Dong","Weipeng Zhao","David J. Brady","Xun Cao","Zhan Ma","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2310.02792v2.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.18944v1","updated":"2024-06-27T07:14:14Z","published":"2024-06-27T07:14:14Z","title":"Investigating and Defending Shortcut Learning in Personalized Diffusion\n  Models","summary":"  Personalized diffusion models have gained popularity for adapting pre-trained\ntext-to-image models to generate images of specific topics with only a few\nimages. However, recent studies find that these models are vulnerable to minor\nadversarial perturbation, and the fine-tuning performance is largely degraded\non corrupted datasets. Such characteristics are further exploited to craft\nprotective perturbation on sensitive images like portraits that prevent\nunauthorized generation. In response, diffusion-based purification methods have\nbeen proposed to remove these perturbations and retain generation performance.\nHowever, existing works lack detailed analysis of the fundamental shortcut\nlearning vulnerability of personalized diffusion models and also turn to\nover-purifying the images cause information loss. In this paper, we take a\ncloser look at the fine-tuning process of personalized diffusion models through\nthe lens of shortcut learning and propose a hypothesis that could explain the\nunderlying manipulation mechanisms of existing perturbation methods.\nSpecifically, we find that the perturbed images are greatly shifted from their\noriginal paired prompt in the CLIP-based latent space. As a result, training\nwith this mismatched image-prompt pair creates a construction that causes the\nmodels to dump their out-of-distribution noisy patterns to the identifier, thus\ncausing serious performance degradation. Based on this observation, we propose\na systematic approach to retain the training performance with purification that\nrealigns the latent image and its semantic meaning and also introduces\ncontrastive learning with a negative token to decouple the learning of wanted\nclean identity and the unwanted noisy pattern, that shows strong potential\ncapacity against further adaptive perturbation.\n","authors":["Yixin Liu","Ruoxi Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18944v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.18941v1","updated":"2024-06-27T07:13:09Z","published":"2024-06-27T07:13:09Z","title":"CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with\n  Multi-View Images Generation","summary":"  Few-shot anomaly detection methods can effectively address data collecting\ndifficulty in industrial scenarios. Compared to 2D few-shot anomaly detection\n(2D-FSAD), 3D few-shot anomaly detection (3D-FSAD) is still an unexplored but\nessential task. In this paper, we propose CLIP3D-AD, an efficient 3D-FSAD\nmethod extended on CLIP. We successfully transfer strong generalization ability\nof CLIP into 3D-FSAD. Specifically, we synthesize anomalous images on given\nnormal images as sample pairs to adapt CLIP for 3D anomaly classification and\nsegmentation. For classification, we introduce an image adapter and a text\nadapter to fine-tune global visual features and text features. Meanwhile, we\npropose a coarse-to-fine decoder to fuse and facilitate intermediate\nmulti-layer visual representations of CLIP. To benefit from geometry\ninformation of point cloud and eliminate modality and data discrepancy when\nprocessed by CLIP, we project and render point cloud to multi-view normal and\nanomalous images. Then we design multi-view fusion module to fuse features of\nmulti-view images extracted by CLIP which are used to facilitate visual\nrepresentations for further enhancing vision-language correlation. Extensive\nexperiments demonstrate that our method has a competitive performance of 3D\nfew-shot anomaly classification and segmentation on MVTec-3D AD dataset.\n","authors":["Zuo Zuo","Jiahao Dong","Yao Wu","Yanyun Qu","Zongze Wu"],"pdf_url":"https://arxiv.org/pdf/2406.18941v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.13146v2","updated":"2024-06-27T07:02:48Z","published":"2024-04-19T19:24:20Z","title":"DeepFake-O-Meter v2.0: An Open Platform for DeepFake Detection","summary":"  Deepfakes, as AI-generated media, have increasingly threatened media\nintegrity and personal privacy with realistic yet fake digital content. In this\nwork, we introduce an open-source and user-friendly online platform,\nDeepFake-O-Meter v2.0, that integrates state-of-the-art methods for detecting\nDeepfake images, videos, and audio. Built upon DeepFake-O-Meter v1.0, we have\nmade significant upgrades and improvements in platform architecture design,\nincluding user interaction, detector integration, job balancing, and security\nmanagement. The platform aims to offer everyday users a convenient service for\nanalyzing DeepFake media using multiple state-of-the-art detection algorithms.\nIt ensures secure and private delivery of the analysis results. Furthermore, it\nserves as an evaluation and benchmarking platform for researchers in digital\nmedia forensics to compare the performance of multiple algorithms on the same\ninput. We have also conducted detailed usage analysis based on the collected\ndata to gain deeper insights into our platform's statistics. This involves\nanalyzing two-month trends in user activity and evaluating the processing\nefficiency of each detector.\n","authors":["Yan Ju","Chengzhe Sun","Shan Jia","Shuwei Hou","Zhaofeng Si","Soumyya Kanti Datta","Lipeng Ke","Riky Zhou","Anita Nikolich","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2404.13146v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18927v1","updated":"2024-06-27T06:38:56Z","published":"2024-06-27T06:38:56Z","title":"RoFIR: Robust Fisheye Image Rectification Framework Impervious to\n  Optical Center Deviation","summary":"  Fisheye images are categorized fisheye into central and deviated based on the\noptical center position. Existing rectification methods are limited to central\nfisheye images, while this paper proposes a novel method that extends to\ndeviated fisheye image rectification. The challenge lies in the variant global\ndistortion distribution pattern caused by the random optical center position.\nTo address this challenge, we propose a distortion vector map (DVM) that\nmeasures the degree and direction of local distortion. By learning the DVM, the\nmodel can independently identify local distortions at each pixel without\nrelying on global distortion patterns. The model adopts a pre-training and\nfine-tuning training paradigm. In the pre-training stage, it predicts the\ndistortion vector map and perceives the local distortion features of each\npixel. In the fine-tuning stage, it predicts a pixel-wise flow map for deviated\nfisheye image rectification. We also propose a data augmentation method mixing\ncentral, deviated, and distorted-free images. Such data augmentation promotes\nthe model performance in rectifying both central and deviated fisheye images,\ncompared with models trained on single-type fisheye images. Extensive\nexperiments demonstrate the effectiveness and superiority of the proposed\nmethod.\n","authors":["Zhaokang Liao","Hao Feng","Shaokai Liu","Wengang Zhou","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2406.18927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18925v1","updated":"2024-06-27T06:32:56Z","published":"2024-06-27T06:32:56Z","title":"Selective Vision is the Challenge for Visual Reasoning: A Benchmark for\n  Visual Argument Understanding","summary":"  Visual arguments, often used in advertising or social causes, rely on images\nto persuade viewers to do or believe something. Understanding these arguments\nrequires selective vision: only specific visual stimuli within an image are\nrelevant to the argument, and relevance can only be understood within the\ncontext of a broader argumentative structure. While visual arguments are\nreadily appreciated by human audiences, we ask: are today's AI capable of\nsimilar understanding?\n  We collect and release VisArgs, an annotated corpus designed to make explicit\nthe (usually implicit) structures underlying visual arguments. VisArgs includes\n1,611 images accompanied by three types of textual annotations: 5,112 visual\npremises (with region annotations), 5,574 commonsense premises, and reasoning\ntrees connecting them to a broader argument. We propose three tasks over\nVisArgs to probe machine capacity for visual argument understanding:\nlocalization of premises, identification of premises, and deduction of\nconclusions. Experiments demonstrate that 1) machines cannot fully identify the\nrelevant visual cues. The top-performing model, GPT-4-O, achieved an accuracy\nof only 78.5%, whereas humans reached 98.0%. All models showed a performance\ndrop, with an average decrease in accuracy of 19.5%, when the comparison set\nwas changed from objects outside the image to irrelevant objects within the\nimage. Furthermore, 2) this limitation is the greatest factor impacting their\nperformance in understanding visual arguments. Most models improved the most\nwhen given relevant visual premises as additional inputs, compared to other\ninputs, for deducing the conclusion of the visual argument.\n","authors":["Jiwan Chung","Sungjae Lee","Minseo Kim","Seungju Han","Ashkan Yousefpour","Jack Hessel","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18925v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.02956v3","updated":"2024-06-27T06:30:01Z","published":"2024-02-05T12:34:03Z","title":"AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a\n  Single High-Resolution Image","summary":"  The process of estimating and counting tree density using only a single\naerial or satellite image is a difficult task in the fields of photogrammetry\nand remote sensing. However, it plays a crucial role in the management of\nforests. The huge variety of trees in varied topography severely hinders tree\ncounting models to perform well. The purpose of this paper is to propose a\nframework that is learnt from the source domain with sufficient labeled trees\nand is adapted to the target domain with only a limited number of labeled\ntrees. Our method, termed as AdaTreeFormer, contains one shared encoder with a\nhierarchical feature extraction scheme to extract robust features from the\nsource and target domains. It also consists of three subnets: two for\nextracting self-domain attention maps from source and target domains\nrespectively and one for extracting cross-domain attention maps. For the\nlatter, an attention-to-adapt mechanism is introduced to distill relevant\ninformation from different domains while generating tree density maps; a\nhierarchical cross-domain feature alignment scheme is proposed that\nprogressively aligns the features from the source and target domains. We also\nadopt adversarial learning into the framework to further reduce the gap between\nsource and target domains. Our AdaTreeFormer is evaluated on six designed\ndomain adaptation tasks using three tree counting datasets, \\ie Jiangsu,\nYosemite, and London. Experimental results show that AdaTreeFormer\nsignificantly surpasses the state of the art, \\eg in the cross domain from the\nYosemite to Jiangsu dataset, it achieves a reduction of 15.9 points in terms of\nthe absolute counting errors and an increase of 10.8\\% in the accuracy of the\ndetected trees' locations. The codes and datasets are available at\nhttps://github.com/HAAClassic/AdaTreeFormer.\n","authors":["Hamed Amini Amirkolaee","Miaojing Shi","Lianghua He","Mark Mulligan"],"pdf_url":"https://arxiv.org/pdf/2402.02956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18070v2","updated":"2024-06-27T06:26:12Z","published":"2024-06-26T05:01:37Z","title":"EgoVideo: Exploring Egocentric Foundation Model and Downstream\n  Adaptation","summary":"  In this report, we present our solutions to the EgoVis Challenges in CVPR\n2024, including five tracks in the Ego4D challenge and three tracks in the\nEPIC-Kitchens challenge. Building upon the video-language two-tower model and\nleveraging our meticulously organized egocentric video data, we introduce a\nnovel foundation model called EgoVideo. This model is specifically designed to\ncater to the unique characteristics of egocentric videos and provides strong\nsupport for our competition submissions. In the Ego4D challenges, we tackle\nvarious tasks including Natural Language Queries, Step Grounding, Moment\nQueries, Short-term Object Interaction Anticipation, and Long-term Action\nAnticipation. In addition, we also participate in the EPIC-Kitchens challenge,\nwhere we engage in the Action Recognition, Multiple Instance Retrieval, and\nDomain Adaptation for Action Recognition tracks. By adapting EgoVideo to these\ndiverse tasks, we showcase its versatility and effectiveness in different\negocentric video analysis scenarios, demonstrating the powerful representation\nability of EgoVideo as an egocentric foundation model. Our codebase and\npretrained models are publicly available at\nhttps://github.com/OpenGVLab/EgoVideo.\n","authors":["Baoqi Pei","Guo Chen","Jilan Xu","Yuping He","Yicheng Liu","Kanghua Pan","Yifei Huang","Yali Wang","Tong Lu","Limin Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2406.18070v2.pdf","comment":"Champion solutions in the EgoVis CVPR 2024 workshop"},{"id":"http://arxiv.org/abs/2406.18919v1","updated":"2024-06-27T06:22:02Z","published":"2024-06-27T06:22:02Z","title":"Classification of Carotid Plaque with Jellyfish Sign Through\n  Convolutional and Recurrent Neural Networks Utilizing Plaque Surface Edges","summary":"  In carotid arteries, plaque can develop as localized elevated lesions. The\nJellyfish sign, marked by fluctuating plaque surfaces with blood flow\npulsation, is a dynamic characteristic of these plaques that has recently\nattracted attention. Detecting this sign is vital, as it is often associated\nwith cerebral infarction. This paper proposes an ultrasound video-based\nclassification method for the Jellyfish sign, using deep neural networks. The\nproposed method first preprocesses carotid ultrasound videos to separate the\nmovement of the vascular wall from plaque movements. These preprocessed videos\nare then combined with plaque surface information and fed into a deep learning\nmodel comprising convolutional and recurrent neural networks, enabling the\nefficient classification of the Jellyfish sign. The proposed method was\nverified using ultrasound video images from 200 patients. Ablation studies\ndemonstrated the effectiveness of each component of the proposed method.\n","authors":["Takeshi Yoshidomi","Shinji Kume","Hiroaki Aizawa","Akira Furui"],"pdf_url":"https://arxiv.org/pdf/2406.18919v1.pdf","comment":"4 pages, 3 figures, accepted at IEEE EMBC 2024"},{"id":"http://arxiv.org/abs/2403.06138v2","updated":"2024-06-27T06:16:30Z","published":"2024-03-10T08:56:02Z","title":"BSDA: Bayesian Random Semantic Data Augmentation for Medical Image\n  Classification","summary":"  Data augmentation is a crucial regularization technique for deep neural\nnetworks, particularly in medical image classification. Mainstream data\naugmentation (DA) methods are usually applied at the image level. Due to the\nspecificity and diversity of medical imaging, expertise is often required to\ndesign effective DA strategies, and improper augmentation operations can\ndegrade model performance. Although automatic augmentation methods exist, they\nare computationally intensive. Semantic data augmentation can implemented by\ntranslating features in feature space. However, over-translation may violate\nthe image label. To address these issues, we propose \\emph{Bayesian Random\nSemantic Data Augmentation} (BSDA), a computationally efficient and\nhandcraft-free feature-level DA method. BSDA uses variational Bayesian to\nestimate the distribution of the augmentable magnitudes, and then a sample from\nthis distribution is added to the original features to perform semantic data\naugmentation. We performed experiments on nine 2D and five 3D medical image\ndatasets. Experimental results show that BSDA outperforms current DA methods.\nAdditionally, BSDA can be easily assembled into CNNs or Transformers as a\nplug-and-play module, improving the network's performance. The code is\navailable online at \\url{https://github.com/YaoyaoZhu19/BSDA}.\n","authors":["Yaoyao Zhu","Xiuding Cai","Xueyao Wang","Xiaoqing Chen","Yu Yao","Zhongliang Fu"],"pdf_url":"https://arxiv.org/pdf/2403.06138v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18915v1","updated":"2024-06-27T06:12:01Z","published":"2024-06-27T06:12:01Z","title":"Manipulate-Anything: Automating Real-World Robots using Vision-Language\n  Models","summary":"  Large-scale endeavors like RT-1 and widespread community efforts such as\nOpen-X-Embodiment have contributed to growing the scale of robot demonstration\ndata. However, there is still an opportunity to improve the quality, quantity,\nand diversity of robot demonstration data. Although vision-language models have\nbeen shown to automatically generate demonstration data, their utility has been\nlimited to environments with privileged state information, they require\nhand-designed skills, and are limited to interactions with few object\ninstances. We propose Manipulate-Anything, a scalable automated generation\nmethod for real-world robotic manipulation. Unlike prior work, our method can\noperate in real-world environments without any privileged state information,\nhand-designed skills, and can manipulate any static object. We evaluate our\nmethod using two setups. First, Manipulate-Anything successfully generates\ntrajectories for all 5 real-world and 12 simulation tasks, significantly\noutperforming existing methods like VoxPoser. Second, Manipulate-Anything's\ndemonstrations can train more robust behavior cloning policies than training\nwith human demonstrations, or from data generated by VoxPoser and\nCode-As-Policies. We believe \\methodLong\\ can be the scalable method for both\ngenerating data for robotics and solving novel tasks in a zero-shot setting.\n","authors":["Jiafei Duan","Wentao Yuan","Wilbert Pumacay","Yi Ru Wang","Kiana Ehsani","Dieter Fox","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.18915v1.pdf","comment":"Project page: https://robo-point.github.io/"},{"id":"http://arxiv.org/abs/2406.18908v1","updated":"2024-06-27T05:48:26Z","published":"2024-06-27T05:48:26Z","title":"A Universal Railway Obstacle Detection System based on Semi-supervised\n  Segmentation And Optical Flow","summary":"  Detecting obstacles in railway scenarios is both crucial and challenging due\nto the wide range of obstacle categories and varying ambient conditions such as\nweather and light. Given the impossibility of encompassing all obstacle\ncategories during the training stage, we address this out-of-distribution (OOD)\nissue with a semi-supervised segmentation approach guided by optical flow\nclues. We reformulate the task as a binary segmentation problem instead of the\ntraditional object detection approach. To mitigate data shortages, we generate\nhighly realistic synthetic images using Segment Anything (SAM) and YOLO,\neliminating the need for manual annotation to produce abundant pixel-level\nannotations. Additionally, we leverage optical flow as prior knowledge to train\nthe model effectively. Several experiments are conducted, demonstrating the\nfeasibility and effectiveness of our approach.\n","authors":["Qiushi Guo"],"pdf_url":"https://arxiv.org/pdf/2406.18908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02027v2","updated":"2024-06-27T05:47:55Z","published":"2024-06-04T07:06:06Z","title":"Inference Attacks: A Taxonomy, Survey, and Promising Directions","summary":"  The prosperity of machine learning has also brought people's concerns about\ndata privacy. Among them, inference attacks can implement privacy breaches in\nvarious MLaaS scenarios and model training/prediction phases. Specifically,\ninference attacks can perform privacy inference on undisclosed target training\nsets based on outputs of the target model, including but not limited to\nstatistics, membership, semantics, data representation, etc. For instance,\ninfer whether the target data has the characteristics of AIDS. In addition, the\nrapid development of the machine learning community in recent years, especially\nthe surge of model types and application scenarios, has further stimulated the\ninference attacks' research. Thus, studying inference attacks and analyzing\nthem in depth is urgent and significant. However, there is still a gap in the\nsystematic discussion of inference attacks from taxonomy, global perspective,\nattack, and defense perspectives. This survey provides an in-depth and\ncomprehensive inference of attacks and corresponding countermeasures in\nML-as-a-service based on taxonomy and the latest researches. Without\ncompromising researchers' intuition, we first propose the 3MP taxonomy based on\nthe community research status, trying to normalize the confusing naming system\nof inference attacks. Also, we analyze the pros and cons of each type of\ninference attack, their workflow, countermeasure, and how they interact with\nother attacks. In the end, we point out several promising directions for\nresearchers from a more comprehensive and novel perspective.\n","authors":["Feng Wu","Lei Cui","Shaowen Yao","Shui Yu"],"pdf_url":"https://arxiv.org/pdf/2406.02027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06911v2","updated":"2024-06-27T05:39:46Z","published":"2024-06-11T03:09:37Z","title":"AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising","summary":"  Diffusion models have garnered significant interest from the community for\ntheir great generative ability across various applications. However, their\ntypical multi-step sequential-denoising nature gives rise to high cumulative\nlatency, thereby precluding the possibilities of parallel computation. To\naddress this, we introduce AsyncDiff, a universal and plug-and-play\nacceleration scheme that enables model parallelism across multiple devices. Our\napproach divides the cumbersome noise prediction model into multiple\ncomponents, assigning each to a different device. To break the dependency chain\nbetween these components, it transforms the conventional sequential denoising\ninto an asynchronous process by exploiting the high similarity between hidden\nstates in consecutive diffusion steps. Consequently, each component is\nfacilitated to compute in parallel on separate devices. The proposed strategy\nsignificantly reduces inference latency while minimally impacting the\ngenerative quality. Specifically, for the Stable Diffusion v2.1, AsyncDiff\nachieves a 2.7x speedup with negligible degradation and a 4.0x speedup with\nonly a slight reduction of 0.38 in CLIP Score, on four NVIDIA A5000 GPUs. Our\nexperiments also demonstrate that AsyncDiff can be readily applied to video\ndiffusion models with encouraging performances. The code is available at\nhttps://github.com/czg1225/AsyncDiff.\n","authors":["Zigeng Chen","Xinyin Ma","Gongfan Fang","Zhenxiong Tan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06911v2.pdf","comment":"Work in progress. Project Page:\n  https://czg1225.github.io/asyncdiff_page/"},{"id":"http://arxiv.org/abs/2406.18901v1","updated":"2024-06-27T05:28:44Z","published":"2024-06-27T05:28:44Z","title":"Autoencoder based approach for the mitigation of spurious correlations","summary":"  Deep neural networks (DNNs) have exhibited remarkable performance across\nvarious tasks, yet their susceptibility to spurious correlations poses a\nsignificant challenge for out-of-distribution (OOD) generalization. Spurious\ncorrelations refer to erroneous associations in data that do not reflect true\nunderlying relationships but are instead artifacts of dataset characteristics\nor biases. These correlations can lead DNNs to learn patterns that are not\nrobust across diverse datasets or real-world scenarios, hampering their ability\nto generalize beyond training data. In this paper, we propose an\nautoencoder-based approach to analyze the nature of spurious correlations that\nexist in the Global Wheat Head Detection (GWHD) 2021 dataset. We then use\ninpainting followed by Weighted Boxes Fusion (WBF) to achieve a 2% increase in\nthe Average Domain Accuracy (ADA) over the YOLOv5 baseline and consistently\nshow that our approach has the ability to suppress some of the spurious\ncorrelations in the GWHD 2021 dataset. The key advantage of our approach is\nthat it is more suitable in scenarios where there is limited scope to adapt or\nfine-tune the trained model in unseen test environments.\n","authors":["Srinitish Srinivasan","Karthik Seemakurthy"],"pdf_url":"https://arxiv.org/pdf/2406.18901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18898v1","updated":"2024-06-27T05:26:38Z","published":"2024-06-27T05:26:38Z","title":"360 in the Wild: Dataset for Depth Prediction and View Synthesis","summary":"  The large abundance of perspective camera datasets facilitated the emergence\nof novel learning-based strategies for various tasks, such as camera\nlocalization, single image depth estimation, or view synthesis. However,\npanoramic or omnidirectional image datasets, including essential information,\nsuch as pose and depth, are mostly made with synthetic scenes. In this work, we\nintroduce a large scale 360$^{\\circ}$ videos dataset in the wild. This dataset\nhas been carefully scraped from the Internet and has been captured from various\nlocations worldwide. Hence, this dataset exhibits very diversified environments\n(e.g., indoor and outdoor) and contexts (e.g., with and without moving\nobjects). Each of the 25K images constituting our dataset is provided with its\nrespective camera's pose and depth map. We illustrate the relevance of our\ndataset for two main tasks, namely, single image depth estimation and view\nsynthesis.\n","authors":["Kibaek Park","Francois Rameau","Jaesik Park","In So Kweon"],"pdf_url":"https://arxiv.org/pdf/2406.18898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04857v2","updated":"2024-06-27T05:11:39Z","published":"2024-02-07T13:54:56Z","title":"Advancing Video Anomaly Detection: A Concise Review and a New Dataset","summary":"  Video Anomaly Detection (VAD) finds widespread applications in security\nsurveillance, traffic monitoring, industrial monitoring, and healthcare.\nDespite extensive research efforts, there remains a lack of concise reviews\nthat provide insightful guidance for researchers. Such reviews would serve as\nquick references to grasp current challenges, research trends, and future\ndirections. In this paper, we present such a review, examining models and\ndatasets from various perspectives. We emphasize the critical relationship\nbetween model and dataset, where the quality and diversity of datasets\nprofoundly influence model performance, and dataset development adapts to the\nevolving needs of emerging approaches. Our review identifies practical issues,\nincluding the absence of comprehensive datasets with diverse scenarios. To\naddress this, we introduce a new dataset, Multi-Scenario Anomaly Detection\n(MSAD), comprising 14 distinct scenarios captured from various camera views.\nOur dataset has diverse motion patterns and challenging variations, such as\ndifferent lighting and weather conditions, providing a robust foundation for\ntraining superior models. We conduct an in-depth analysis of recent\nrepresentative models using MSAD and highlight its potential in addressing the\nchallenges of detecting anomalies across diverse and evolving surveillance\nscenarios. Our dataset is available here.\n","authors":["Liyun Zhu","Lei Wang","Arjun Raj","Tom Gedeon","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2402.04857v2.pdf","comment":"Research report"},{"id":"http://arxiv.org/abs/2406.18893v1","updated":"2024-06-27T05:08:46Z","published":"2024-06-27T05:08:46Z","title":"AlignIT: Enhancing Prompt Alignment in Customization of Text-to-Image\n  Models","summary":"  We consider the problem of customizing text-to-image diffusion models with\nuser-supplied reference images. Given new prompts, the existing methods can\ncapture the key concept from the reference images but fail to align the\ngenerated image with the prompt. In this work, we seek to address this key\nissue by proposing new methods that can easily be used in conjunction with\nexisting customization methods that optimize the embeddings/weights at various\nintermediate stages of the text encoding process.\n  The first contribution of this paper is a dissection of the various stages of\nthe text encoding process leading up to the conditioning vector for\ntext-to-image models. We take a holistic view of existing customization methods\nand notice that key and value outputs from this process differs substantially\nfrom their corresponding baseline (non-customized) models (e.g., baseline\nstable diffusion). While this difference does not impact the concept being\ncustomized, it leads to other parts of the generated image not being aligned\nwith the prompt (see first row in Fig 1). Further, we also observe that these\nkeys and values allow independent control various aspects of the final\ngeneration, enabling semantic manipulation of the output. Taken together, the\nfeatures spanning these keys and values, serve as the basis for our next\ncontribution where we fix the aforementioned issues with existing methods. We\npropose a new post-processing algorithm, \\textbf{AlignIT}, that infuses the\nkeys and values for the concept of interest while ensuring the keys and values\nfor all other tokens in the input prompt are unchanged.\n  Our proposed method can be plugged in directly to existing customization\nmethods, leading to a substantial performance improvement in the alignment of\nthe final result with the input prompt while retaining the customization\nquality.\n","authors":["Aishwarya Agarwal","Srikrishna Karanam","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.18893v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2310.16777v2","updated":"2024-06-27T04:23:30Z","published":"2023-10-25T17:10:37Z","title":"MixerFlow: MLP-Mixer meets Normalising Flows","summary":"  Normalising flows are generative models that transform a complex density into\na simpler density through the use of bijective transformations enabling both\ndensity estimation and data generation from a single model. %However, the\nrequirement for bijectivity imposes the use of specialised architectures. In\nthe context of image modelling, the predominant choice has been the Glow-based\narchitecture, whereas alternative architectures remain largely unexplored in\nthe research community. In this work, we propose a novel architecture called\nMixerFlow, based on the MLP-Mixer architecture, further unifying the generative\nand discriminative modelling architectures. MixerFlow offers an efficient\nmechanism for weight sharing for flow-based models. Our results demonstrate\ncomparative or superior density estimation on image datasets and good scaling\nas the image resolution increases, making MixerFlow a simple yet powerful\nalternative to the Glow-based architectures. We also show that MixerFlow\nprovides more informative embeddings than Glow-based architectures and can\nintegrate many structured transformations such as splines or Kolmogorov-Arnold\nNetworks.\n","authors":["Eshant English","Matthias Kirchler","Christoph Lippert"],"pdf_url":"https://arxiv.org/pdf/2310.16777v2.pdf","comment":"Alternative title: MixerFlow for Image Modelling; Accepted at\n  ECML-PKDD 2024"},{"id":"http://arxiv.org/abs/2406.16562v2","updated":"2024-06-27T03:57:05Z","published":"2024-06-24T11:56:15Z","title":"EVALALIGN: Supervised Fine-Tuning Multimodal LLMs with Human-Aligned\n  Data for Evaluating Text-to-Image Models","summary":"  The recent advancements in text-to-image generative models have been\nremarkable. Yet, the field suffers from a lack of evaluation metrics that\naccurately reflect the performance of these models, particularly lacking\nfine-grained metrics that can guide the optimization of the models. In this\npaper, we propose EvalAlign, a metric characterized by its accuracy, stability,\nand fine granularity. Our approach leverages the capabilities of Multimodal\nLarge Language Models (MLLMs) pre-trained on extensive datasets. We develop\nevaluation protocols that focus on two key dimensions: image faithfulness and\ntext-image alignment. Each protocol comprises a set of detailed, fine-grained\ninstructions linked to specific scoring options, enabling precise manual\nscoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to\nalign closely with human evaluative judgments, resulting in a robust evaluation\nmodel. Our comprehensive tests across 24 text-to-image generation models\ndemonstrate that EvalAlign not only provides superior metric stability but also\naligns more closely with human preferences than existing metrics, confirming\nits effectiveness and utility in model assessment.\n","authors":["Zhiyu Tan","Xiaomeng Yang","Luozheng Qin","Mengping Yang","Cheng Zhang","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2406.16562v2.pdf","comment":"Github Repository: https://github.com/SAIS-FUXI/EvalAlign"},{"id":"http://arxiv.org/abs/2406.15182v2","updated":"2024-06-27T03:54:50Z","published":"2024-06-21T14:27:02Z","title":"DiffExplainer: Unveiling Black Box Models Via Counterfactual Generation","summary":"  In the field of medical imaging, particularly in tasks related to early\ndisease detection and prognosis, understanding the reasoning behind AI model\npredictions is imperative for assessing their reliability. Conventional\nexplanation methods encounter challenges in identifying decisive features in\nmedical image classifications, especially when discriminative features are\nsubtle or not immediately evident. To address this limitation, we propose an\nagent model capable of generating counterfactual images that prompt different\ndecisions when plugged into a black box model. By employing this agent model,\nwe can uncover influential image patterns that impact the black model's final\npredictions. Through our methodology, we efficiently identify features that\ninfluence decisions of the deep black box. We validated our approach in the\nrigorous domain of medical prognosis tasks, showcasing its efficacy and\npotential to enhance the reliability of deep learning models in medical image\nclassification compared to existing interpretation methods. The code will be\npublicly available at https://github.com/ayanglab/DiffExplainer.\n","authors":["Yingying Fang","Shuang Wu","Zihao Jin","Caiwen Xu","Shiyi Wang","Simon Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2406.15182v2.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.18868v1","updated":"2024-06-27T03:48:57Z","published":"2024-06-27T03:48:57Z","title":"Advancing Cross-domain Discriminability in Continual Learning of\n  Vison-Language Models","summary":"  Continual learning (CL) with Vision-Language Models (VLMs) has overcome the\nconstraints of traditional CL, which only focuses on previously encountered\nclasses. During the CL of VLMs, we need not only to prevent the catastrophic\nforgetting on incrementally learned knowledge but also to preserve the\nzero-shot ability of VLMs. However, existing methods require additional\nreference datasets to maintain such zero-shot ability and rely on\ndomain-identity hints to classify images across different domains. In this\nstudy, we propose Regression-based Analytic Incremental Learning (RAIL), which\nutilizes a recursive ridge regression-based adapter to learn from a sequence of\ndomains in a non-forgetting manner and decouple the cross-domain correlations\nby projecting features to a higher-dimensional space. Cooperating with a\ntraining-free fusion module, RAIL absolutely preserves the VLM's zero-shot\nability on unseen domains without any reference data. Additionally, we\nintroduce Cross-domain Task-Agnostic Incremental Learning (X-TAIL) setting. In\nthis setting, a CL learner is required to incrementally learn from multiple\ndomains and classify test images from both seen and unseen domains without any\ndomain-identity hint. We theoretically prove RAIL's absolute memorization on\nincrementally learned domains. Experiment results affirm RAIL's\nstate-of-the-art performance in both X-TAIL and existing Multi-domain\nTask-Incremental Learning settings. The code will be released upon acceptance.\n","authors":["Yicheng Xu","Yuxin Chen","Jiahao Nie","Yusong Wang","Huiping Zhuang","Manabu Okumura"],"pdf_url":"https://arxiv.org/pdf/2406.18868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02021v2","updated":"2024-06-27T03:46:35Z","published":"2024-02-03T04:27:26Z","title":"Transfer Learning in ECG Diagnosis: Is It Effective?","summary":"  The adoption of deep learning in ECG diagnosis is often hindered by the\nscarcity of large, well-labeled datasets in real-world scenarios, leading to\nthe use of transfer learning to leverage features learned from larger datasets.\nYet the prevailing assumption that transfer learning consistently outperforms\ntraining from scratch has never been systematically validated. In this study,\nwe conduct the first extensive empirical study on the effectiveness of transfer\nlearning in multi-label ECG classification, by investigating comparing the\nfine-tuning performance with that of training from scratch, covering a variety\nof ECG datasets and deep neural networks. We confirm that fine-tuning is the\npreferable choice for small downstream datasets; however, when the dataset is\nsufficiently large, training from scratch can achieve comparable performance,\nalbeit requiring a longer training time to catch up. Furthermore, we find that\ntransfer learning exhibits better compatibility with convolutional neural\nnetworks than with recurrent neural networks, which are the two most prevalent\narchitectures for time-series ECG applications. Our results underscore the\nimportance of transfer learning in ECG diagnosis, yet depending on the amount\nof available data, researchers may opt not to use it, considering the\nnon-negligible cost associated with pre-training.\n","authors":["Cuong V. Nguyen","Cuong D. Do"],"pdf_url":"https://arxiv.org/pdf/2402.02021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10595v3","updated":"2024-06-27T03:30:16Z","published":"2024-04-16T14:20:55Z","title":"Automated Evaluation of Large Vision-Language Models on Self-driving\n  Corner Cases","summary":"  Large Vision-Language Models (LVLMs) have received widespread attention in\nadvancing the interpretable self-driving. Existing evaluations of LVLMs\nprimarily focus on the multi-faceted capabilities in natural circumstances,\nlacking automated and quantifiable assessment for self-driving, let alone the\nsevere road corner cases. In this paper, we propose CODA-LM, the very first\nbenchmark for the automatic evaluation of LVLMs for self-driving corner cases.\nWe adopt a hierarchical data structure to prompt powerful LVLMs to analyze\ncomplex driving scenes and generate high-quality pre-annotation for human\nannotators, and for LVLM evaluation, we show that using the text-only large\nlanguage models (LLMs) as judges reveals even better alignment with human\npreferences than the LVLM judges. Moreover, with CODA-LM, we build CODA-VLM, a\nnew driving LVLM surpassing all the open-sourced counterparts on CODA-LM. Our\nCODA-VLM performs comparably with GPT-4V, even surpassing GPT-4V by +21.42% on\nthe regional perception task. We hope CODA-LM can become the catalyst to\npromote interpretable self-driving empowered by LVLMs.\n","authors":["Kai Chen","Yanze Li","Wenhua Zhang","Yanxin Liu","Pengxiang Li","Ruiyuan Gao","Lanqing Hong","Meng Tian","Xinhai Zhao","Zhenguo Li","Dit-Yan Yeung","Huchuan Lu","Xu Jia"],"pdf_url":"https://arxiv.org/pdf/2404.10595v3.pdf","comment":"Project Page: https://coda-dataset.github.io/coda-lm/"},{"id":"http://arxiv.org/abs/2406.17117v2","updated":"2024-06-27T03:25:19Z","published":"2024-06-24T20:11:46Z","title":"Speeding Up Image Classifiers with Little Companions","summary":"  Scaling up neural networks has been a key recipe to the success of large\nlanguage and vision models. However, in practice, up-scaled models can be\ndisproportionately costly in terms of computations, providing only marginal\nimprovements in performance; for example, EfficientViT-L3-384 achieves <2%\nimprovement on ImageNet-1K accuracy over the base L1-224 model, while requiring\n$14\\times$ more multiply-accumulate operations (MACs). In this paper, we\ninvestigate scaling properties of popular families of neural networks for image\nclassification, and find that scaled-up models mostly help with \"difficult\"\nsamples. Decomposing the samples by difficulty, we develop a simple\nmodel-agnostic two-pass Little-Big algorithm that first uses a light-weight\n\"little\" model to make predictions of all samples, and only passes the\ndifficult ones for the \"big\" model to solve. Good little companion achieve\ndrastic MACs reduction for a wide variety of model families and scales. Without\nloss of accuracy or modification of existing models, our Little-Big models\nachieve MACs reductions of 76% for EfficientViT-L3-384, 81% for\nEfficientNet-B7-600, 71% for DeiT3-L-384 on ImageNet-1K. Little-Big also speeds\nup the InternImage-G-512 model by 62% while achieving 90% ImageNet-1K top-1\naccuracy, serving both as a strong baseline and as a simple practical method\nfor large model compression.\n","authors":["Yang Liu","Kowshik Thopalli","Jayaraman Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2406.17117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18864v1","updated":"2024-06-27T03:23:47Z","published":"2024-06-27T03:23:47Z","title":"Learning Modality Knowledge Alignment for Cross-Modality Transfer","summary":"  Cross-modality transfer aims to leverage large pretrained models to complete\ntasks that may not belong to the modality of pretraining data. Existing works\nachieve certain success in extending classical finetuning to cross-modal\nscenarios, yet we still lack understanding about the influence of modality gap\non the transfer. In this work, a series of experiments focusing on the source\nrepresentation quality during transfer are conducted, revealing the connection\nbetween larger modality gap and lesser knowledge reuse which means ineffective\ntransfer. We then formalize the gap as the knowledge misalignment between\nmodalities using conditional distribution P(Y|X). Towards this problem, we\npresent Modality kNowledge Alignment (MoNA), a meta-learning approach that\nlearns target data transformation to reduce the modality knowledge discrepancy\nahead of the transfer. Experiments show that out method enables better reuse of\nsource modality knowledge in cross-modality transfer, which leads to\nimprovements upon existing finetuning methods.\n","authors":["Wenxuan Ma","Shuang Li","Lincan Cai","Jingxuan Kang"],"pdf_url":"https://arxiv.org/pdf/2406.18864v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2403.13338v2","updated":"2024-06-27T03:04:26Z","published":"2024-03-20T06:46:01Z","title":"Adaptive Critical Subgraph Mining for Cognitive Impairment Conversion\n  Prediction with T1-MRI-based Brain Network","summary":"  Prediction the conversion to early-stage dementia is critical for mitigating\nits progression but remains challenging due to subtle cognitive impairments and\nstructural brain changes. Traditional T1-weighted magnetic resonance imaging\n(T1-MRI) research focus on identifying brain atrophy regions but often fails to\naddress the intricate connectivity between them. This limitation underscores\nthe necessity of focuing on inter-regional connectivity for a comprehensive\nunderstand of the brain's complex network. Moreover, there is a pressing demand\nfor methods that adaptively preserve and extract critical information,\nparticularly specialized subgraph mining techniques for brain networks. These\nare essential for developing high-quality feature representations that reveal\ncritical spatial impacts of structural brain changes and its topology. In this\npaper, we propose Brain-SubGNN, a novel graph representation network to mine\nand enhance critical subgraphs based on T1-MRI. This network provides a\nsubgraph-level interpretation, enhancing interpretability and insights for\ngraph analysis. The process begins by extracting node features and a\ncorrelation matrix between nodes to construct a task-oriented brain network.\nBrain-SubGNN then adaptively identifies and enhances critical subgraphs,\ncapturing both loop and neighbor subgraphs. This method reflects the loop\ntopology and local changes, indicative of long-range connections, and maintains\nlocal and global brain attributes. Extensive experiments validate the\neffectiveness and advantages of Brain-SubGNN, demonstrating its potential as a\npowerful tool for understanding and diagnosing early-stage dementia. Source\ncode is available at https://github.com/Leng-10/Brain-SubGNN.\n","authors":["Yilin Leng","Wenju Cui","Bai Chen","Xi Jiang","Shuangqing Chen","Jian Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.13338v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2403.08002v5","updated":"2024-06-27T02:51:29Z","published":"2024-03-12T18:12:02Z","title":"Towards a clinically accessible radiology foundation model: open-access\n  and lightweight, with automated evaluation","summary":"  The scaling laws and extraordinary performance of large foundation models\nmotivate the development and utilization of such models in biomedicine.\nHowever, despite early promising results on some biomedical benchmarks, there\nare still major challenges that need to be addressed before these models can be\nused in real-world clinics. Frontier general-domain models such as GPT-4V still\nhave significant performance gaps in multimodal biomedical applications. More\nimportantly, less-acknowledged pragmatic issues, including accessibility, model\ncost, and tedious manual evaluation make it hard for clinicians to use\nstate-of-the-art large models directly on private patient data. Here, we\nexplore training open-source small multimodal models (SMMs) to bridge\ncompetency gaps for unmet clinical needs in radiology. To maximize data\nefficiency, we adopt a modular approach by incorporating state-of-the-art\npre-trained models for image and text modalities, and focusing on training a\nlightweight adapter to ground each modality to the text embedding space, as\nexemplified by LLaVA-Med. For training, we assemble a large dataset of over 697\nthousand radiology image-text pairs. For evaluation, we propose CheXprompt, a\nGPT-4-based metric for factuality evaluation, and demonstrate its parity with\nexpert evaluation. For best practice, we conduct a systematic ablation study on\nvarious choices in data engineering and multimodal training. The resulting\nLlaVA-Rad (7B) model attains state-of-the-art results on standard radiology\ntasks such as report generation and cross-modal retrieval, even outperforming\nmuch larger models such as GPT-4V and Med-PaLM M (84B). The inference of\nLlaVA-Rad is fast and can be performed on a single V100 GPU in private\nsettings, offering a promising state-of-the-art tool for real-world clinical\napplications.\n","authors":["Juan Manuel Zambrano Chaves","Shih-Cheng Huang","Yanbo Xu","Hanwen Xu","Naoto Usuyama","Sheng Zhang","Fei Wang","Yujia Xie","Mahmoud Khademi","Ziyi Yang","Hany Awadalla","Julia Gong","Houdong Hu","Jianwei Yang","Chunyuan Li","Jianfeng Gao","Yu Gu","Cliff Wong","Mu Wei","Tristan Naumann","Muhao Chen","Matthew P. Lungren","Akshay Chaudhari","Serena Yeung-Levy","Curtis P. Langlotz","Sheng Wang","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2403.08002v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08466v2","updated":"2024-06-27T02:45:49Z","published":"2024-02-13T13:48:54Z","title":"Taking Training Seriously: Human Guidance and Management-Based\n  Regulation of Artificial Intelligence","summary":"  Fervent calls for more robust governance of the harms associated with\nartificial intelligence (AI) are leading to the adoption around the world of\nwhat regulatory scholars have called a management-based approach to regulation.\nRecent initiatives in the United States and Europe, as well as the adoption of\nmajor self-regulatory standards by the International Organization for\nStandardization, share in common a core management-based paradigm. These\nmanagement-based initiatives seek to motivate an increase in human oversight of\nhow AI tools are trained and developed. Refinements and systematization of\nhuman-guided training techniques will thus be needed to fit within this\nemerging era of management-based regulatory paradigm. If taken seriously,\nhuman-guided training can alleviate some of the technical and ethical pressures\non AI, boosting AI performance with human intuition as well as better\naddressing the needs for fairness and effective explainability. In this paper,\nwe discuss the connection between the emerging management-based regulatory\nframeworks governing AI and the need for human oversight during training. We\nbroadly cover some of the technical components involved in human-guided\ntraining and then argue that the kinds of high-stakes use cases for AI that\nappear of most concern to regulators should lean more on human-guided training\nthan on data-only training. We hope to foster a discussion between legal\nscholars and computer scientists involving how to govern a domain of technology\nthat is vast, heterogenous, and dynamic in its applications and risks.\n","authors":["Cary Coglianese","Colton R. Crum"],"pdf_url":"https://arxiv.org/pdf/2402.08466v2.pdf","comment":"9 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.18849v1","updated":"2024-06-27T02:40:35Z","published":"2024-06-27T02:40:35Z","title":"Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception\n  Ability of LVLMs","summary":"  Currently many benchmarks have been proposed to evaluate the perception\nability of the Large Vision-Language Models (LVLMs). However, most benchmarks\nconduct questions by selecting images from existing datasets, resulting in the\npotential data leakage. Besides, these benchmarks merely focus on evaluating\nLVLMs on the realistic style images and clean scenarios, leaving the\nmulti-stylized images and noisy scenarios unexplored. In response to these\nchallenges, we propose a dynamic and scalable benchmark named Dysca for\nevaluating LVLMs by leveraging synthesis images. Specifically, we leverage\nStable Diffusion and design a rule-based method to dynamically generate novel\nimages, questions and the corresponding answers. We consider 51 kinds of image\nstyles and evaluate the perception capability in 20 subtasks. Moreover, we\nconduct evaluations under 4 scenarios (i.e., Clean, Corruption, Print Attacking\nand Adversarial Attacking) and 3 question types (i.e., Multi-choices,\nTrue-or-false and Free-form). Thanks to the generative paradigm, Dysca serves\nas a scalable benchmark for easily adding new subtasks and scenarios. A total\nof 8 advanced open-source LVLMs with 10 checkpoints are evaluated on Dysca,\nrevealing the drawbacks of current LVLMs. The benchmark is released in\n\\url{https://github.com/Benchmark-Dysca/Dysca}.\n","authors":["Jie Zhang","Zhongqi Wang","Mengqi Lei","Zheng Yuan","Bei Yan","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18845v1","updated":"2024-06-27T02:32:46Z","published":"2024-06-27T02:32:46Z","title":"Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion\n  Approach for Event Stream Recognition","summary":"  Existing event stream-based pattern recognition models usually represent the\nevent stream as the point cloud, voxel, image, etc., and design various deep\nneural networks to learn their features. Although considerable results can be\nachieved in simple cases, however, the model performance may be limited by\nmonotonous modality expressions, sub-optimal fusion, and readout mechanisms. In\nthis paper, we propose a novel dual-stream framework for event stream-based\npattern recognition via differentiated fusion, termed EFV++. It models two\ncommon event representations simultaneously, i.e., event images and event\nvoxels. The spatial and three-dimensional stereo information can be learned\nseparately by utilizing Transformer and Graph Neural Network (GNN). We believe\nthe features of each representation still contain both efficient and redundant\nfeatures and a sub-optimal solution may be obtained if we directly fuse them\nwithout differentiation. Thus, we divide each feature into three levels and\nretain high-quality features, blend medium-quality features, and exchange\nlow-quality features. The enhanced dual features will be fed into the fusion\nTransformer together with bottleneck features. In addition, we introduce a\nnovel hybrid interaction readout mechanism to enhance the diversity of features\nas final representations. Extensive experiments demonstrate that our proposed\nframework achieves state-of-the-art performance on multiple widely used event\nstream-based classification datasets. Specifically, we achieve new\nstate-of-the-art performance on the Bullying10k dataset, i.e., $90.51\\%$, which\nexceeds the second place by $+2.21\\%$. The source code of this paper has been\nreleased on\n\\url{https://github.com/Event-AHU/EFV_event_classification/tree/EFVpp}.\n","authors":["Lan Chen","Dong Li","Xiao Wang","Pengpeng Shao","Wei Zhang","Yaowei Wang","Yonghong Tian","Jin Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18845v1.pdf","comment":"In Peer Review, Journal Extension of PRCV 2023"},{"id":"http://arxiv.org/abs/2406.18844v1","updated":"2024-06-27T02:31:03Z","published":"2024-06-27T02:31:03Z","title":"Revisiting Backdoor Attacks against Large Vision-Language Models","summary":"  Instruction tuning enhances large vision-language models (LVLMs) but raises\nsecurity risks through potential backdoor attacks due to their openness.\nPrevious backdoor studies focus on enclosed scenarios with consistent training\nand testing instructions, neglecting the practical domain gaps that could\naffect attack effectiveness. This paper empirically examines the\ngeneralizability of backdoor attacks during the instruction tuning of LVLMs for\nthe first time, revealing certain limitations of most backdoor strategies in\npractical scenarios. We quantitatively evaluate the generalizability of six\ntypical backdoor attacks on image caption benchmarks across multiple LVLMs,\nconsidering both visual and textual domain offsets. Our findings indicate that\nattack generalizability is positively correlated with the backdoor trigger's\nirrelevance to specific images/models and the preferential correlation of the\ntrigger pattern. Additionally, we modify existing backdoor attacks based on the\nabove key observations, demonstrating significant improvements in cross-domain\nscenario generalizability (+86% attack success rate). Notably, even without\naccess to the instruction datasets, a multimodal instruction set can be\nsuccessfully poisoned with a very low poisoning rate (0.2%), achieving an\nattack success rate of over 97%. This paper underscores that even simple\ntraditional backdoor strategies pose a serious threat to LVLMs, necessitating\nmore attention and in-depth research.\n","authors":["Siyuan Liang","Jiawei Liang","Tianyu Pang","Chao Du","Aishan Liu","Ee-Chien Chang","Xiaochun Cao"],"pdf_url":"https://arxiv.org/pdf/2406.18844v1.pdf","comment":"23 pages, 8 figures"},{"id":"http://arxiv.org/abs/2312.11580v2","updated":"2024-06-27T02:25:31Z","published":"2023-12-18T10:55:11Z","title":"PlaNet-S: Automatic Semantic Segmentation of Placenta","summary":"  [Purpose] To develop a fully automated semantic placenta segmentation model\nthat integrates the U-Net and SegNeXt architectures through ensemble learning.\n[Methods] A total of 218 pregnant women with suspected placental anomalies who\nunderwent magnetic resonance imaging (MRI) were enrolled, yielding 1090\nannotated images for developing a deep learning model for placental\nsegmentation. The images were standardized and divided into training and test\nsets. The performance of PlaNet-S, which integrates U-Net and SegNeXt within an\nensemble framework, was assessed using Intersection over Union (IoU) and\ncounting connected components (CCC) against the U-Net model. [Results] PlaNet-S\nhad significantly higher IoU (0.73 +/- 0.13) than that of U-Net (0.78 +/-\n0.010) (p<0.01). The CCC for PlaNet-S was significantly higher than that for\nU-Net (p<0.01), matching the ground truth in 86.0\\% and 56.7\\% of the cases,\nrespectively. [Conclusion]PlaNet-S performed better than the traditional U-Net\nin placental segmentation tasks. This model addresses the challenges of\ntime-consuming physician-assisted manual segmentation and offers the potential\nfor diverse applications in placental imaging analyses.\n","authors":["Shinnosuke Yamamoto","Isso Saito","Eichi Takaya","Ayaka Harigai","Tomomi Sato","Tomoya Kobayashi","Kei Takase","Takuya Ueda"],"pdf_url":"https://arxiv.org/pdf/2312.11580v2.pdf","comment":"11 pages, 5 figures, Shinnosuke Yamamoto and Isso Saito equally\n  contributed to this work. In the original submission, there was a\n  typographical error in the reported standard deviation for the Intersection\n  over Union (IoU) values of the PlaNet-S model. The standard deviation was\n  incorrectly listed as 0.01 instead of the correct value of 0.1. This has been\n  corrected in the revised version"},{"id":"http://arxiv.org/abs/2406.17297v2","updated":"2024-06-27T02:19:51Z","published":"2024-06-25T05:58:34Z","title":"Towards Open-set Camera 3D Object Detection","summary":"  Traditional camera 3D object detectors are typically trained to recognize a\npredefined set of known object classes. In real-world scenarios, these\ndetectors may encounter unknown objects outside the training categories and\nfail to identify them correctly. To address this gap, we present OS-Det3D\n(Open-set Camera 3D Object Detection), a two-stage training framework enhancing\nthe ability of camera 3D detectors to identify both known and unknown objects.\nThe framework involves our proposed 3D Object Discovery Network (ODN3D), which\nis specifically trained using geometric cues such as the location and scale of\n3D boxes to discover general 3D objects. ODN3D is trained in a class-agnostic\nmanner, and the provided 3D object region proposals inherently come with data\nnoise. To boost accuracy in identifying unknown objects, we introduce a Joint\nObjectness Selection (JOS) module. JOS selects the pseudo ground truth for\nunknown objects from the 3D object region proposals of ODN3D by combining the\nODN3D objectness and camera feature attention objectness. Experiments on the\nnuScenes and KITTI datasets demonstrate the effectiveness of our framework in\nenabling camera 3D detectors to successfully identify unknown objects while\nalso improving their performance on known objects.\n","authors":["Zhuolin He","Xinrun Li","Heng Gao","Jiachen Tang","Shoumeng Qiu","Wenfu Wang","Lvjian Lu","Xuchong Qiu","Xiangyang Xue","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2406.17297v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17770v2","updated":"2024-06-27T02:12:28Z","published":"2024-06-25T17:55:11Z","title":"MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning","summary":"  Multi-modal large language models (MLLMs) have made significant strides in\nvarious visual understanding tasks. However, the majority of these models are\nconstrained to process low-resolution images, which limits their effectiveness\nin perception tasks that necessitate detailed visual information. In our study,\nwe present MG-LLaVA, an innovative MLLM that enhances the model's visual\nprocessing capabilities by incorporating a multi-granularity vision flow, which\nincludes low-resolution, high-resolution, and object-centric features. We\npropose the integration of an additional high-resolution visual encoder to\ncapture fine-grained details, which are then fused with base visual features\nthrough a Conv-Gate fusion network. To further refine the model's object\nrecognition abilities, we incorporate object-level features derived from\nbounding boxes identified by offline detectors. Being trained solely on\npublicly available multimodal data through instruction tuning, MG-LLaVA\ndemonstrates exceptional perception skills. We instantiate MG-LLaVA with a wide\nvariety of language encoders, ranging from 3.8B to 34B, to evaluate the model's\nperformance comprehensively. Extensive evaluations across multiple benchmarks\ndemonstrate that MG-LLaVA outperforms existing MLLMs of comparable parameter\nsizes, showcasing its remarkable efficacy. The code will be available at\nhttps://github.com/PhoenixZ810/MG-LLaVA.\n","authors":["Xiangyu Zhao","Xiangtai Li","Haodong Duan","Haian Huang","Yining Li","Kai Chen","Hua Yang"],"pdf_url":"https://arxiv.org/pdf/2406.17770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18360v2","updated":"2024-06-27T02:11:44Z","published":"2024-06-26T14:00:21Z","title":"XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis","summary":"  Thoroughly testing autonomy systems is crucial in the pursuit of safe\nautonomous driving vehicles. It necessitates creating safety-critical scenarios\nthat go beyond what can be safely collected from real-world data, as many of\nthese scenarios occur infrequently on public roads. However, the evaluation of\nmost existing NVS methods relies on sporadic sampling of image frames from the\ntraining data, comparing the rendered images with ground truth images using\nmetrics. Unfortunately, this evaluation protocol falls short of meeting the\nactual requirements in closed-loop simulations. Specifically, the true\napplication demands the capability to render novel views that extend beyond the\noriginal trajectory (such as cross-lane views), which are challenging to\ncapture in the real world. To address this, this paper presents a novel driving\nview synthesis dataset and benchmark specifically designed for autonomous\ndriving simulations. This dataset is unique as it includes testing images\ncaptured by deviating from the training trajectory by 1-4 meters. It comprises\nsix sequences encompassing various time and weather conditions. Each sequence\ncontains 450 training images, 150 testing images, and their corresponding\ncamera poses and intrinsic parameters. Leveraging this novel dataset, we\nestablish the first realistic benchmark for evaluating existing NVS approaches\nunder front-only and multi-camera settings. The experimental findings\nunderscore the significant gap that exists in current approaches, revealing\ntheir inadequate ability to fulfill the demanding prerequisites of cross-lane\nor closed-loop simulation. Our dataset is released publicly at the project\npage: https://3d-aigc.github.io/XLD/.\n","authors":["Hao Li","Ming Yuan","Yan Zhang","Chenming Wu","Chen Zhao","Chunyu Song","Haocheng Feng","Errui Ding","Dingwen Zhang","Jingdong Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18360v2.pdf","comment":"project page: https://3d-aigc.github.io/XLD/"},{"id":"http://arxiv.org/abs/2406.18837v1","updated":"2024-06-27T02:11:33Z","published":"2024-06-27T02:11:33Z","title":"Dense Monocular Motion Segmentation Using Optical Flow and Pseudo Depth\n  Map: A Zero-Shot Approach","summary":"  Motion segmentation from a single moving camera presents a significant\nchallenge in the field of computer vision. This challenge is compounded by the\nunknown camera movements and the lack of depth information of the scene. While\ndeep learning has shown impressive capabilities in addressing these issues,\nsupervised models require extensive training on massive annotated datasets, and\nunsupervised models also require training on large volumes of unannotated data,\npresenting significant barriers for both. In contrast, traditional methods\nbased on optical flow do not require training data, however, they often fail to\ncapture object-level information, leading to over-segmentation or\nunder-segmentation. In addition, they also struggle in complex scenes with\nsubstantial depth variations and non-rigid motion, due to the overreliance of\noptical flow. To overcome these challenges, we propose an innovative hybrid\napproach that leverages the advantages of both deep learning methods and\ntraditional optical flow based methods to perform dense motion segmentation\nwithout requiring any training. Our method initiates by automatically\ngenerating object proposals for each frame using foundation models. These\nproposals are then clustered into distinct motion groups using both optical\nflow and relative depth maps as motion cues. The integration of depth maps\nderived from state-of-the-art monocular depth estimation models significantly\nenhances the motion cues provided by optical flow, particularly in handling\nmotion parallax issues. Our method is evaluated on the DAVIS-Moving and\nYTVOS-Moving datasets, and the results demonstrate that our method outperforms\nthe best unsupervised method and closely matches with the state-of-theart\nsupervised methods.\n","authors":["Yuxiang Huang","Yuhao Chen","John Zelek"],"pdf_url":"https://arxiv.org/pdf/2406.18837v1.pdf","comment":"For the offical publication, see https://crv.pubpub.org/pub/iunjzl55"},{"id":"http://arxiv.org/abs/2406.18836v1","updated":"2024-06-27T02:10:30Z","published":"2024-06-27T02:10:30Z","title":"Zero-shot Composed Image Retrieval Considering Query-target Relationship\n  Leveraging Masked Image-text Pairs","summary":"  This paper proposes a novel zero-shot composed image retrieval (CIR) method\nconsidering the query-target relationship by masked image-text pairs. The\nobjective of CIR is to retrieve the target image using a query image and a\nquery text. Existing methods use a textual inversion network to convert the\nquery image into a pseudo word to compose the image and text and use a\npre-trained visual-language model to realize the retrieval. However, they do\nnot consider the query-target relationship to train the textual inversion\nnetwork to acquire information for retrieval. In this paper, we propose a novel\nzero-shot CIR method that is trained end-to-end using masked image-text pairs.\nBy exploiting the abundant image-text pairs that are convenient to obtain with\na masking strategy for learning the query-target relationship, it is expected\nthat accurate zero-shot CIR using a retrieval-focused textual inversion network\ncan be realized. Experimental results show the effectiveness of the proposed\nmethod.\n","authors":["Huaying Zhang","Rintaro Yanagi","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2406.18836v1.pdf","comment":"Accepted as a conference paper in IEEE ICIP 2024"},{"id":"http://arxiv.org/abs/2406.18817v1","updated":"2024-06-27T01:16:44Z","published":"2024-06-27T01:16:44Z","title":"Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised\n  Clustering Analysis","summary":"  This paper presents a novel non-rigid point set registration method that is\ninspired by unsupervised clustering analysis. Unlike previous approaches that\ntreat the source and target point sets as separate entities, we develop a\nholistic framework where they are formulated as clustering centroids and\nclustering members, separately. We then adopt Tikhonov regularization with an\n$\\ell_1$-induced Laplacian kernel instead of the commonly used Gaussian kernel\nto ensure smooth and more robust displacement fields. Our formulation delivers\nclosed-form solutions, theoretical guarantees, independence from dimensions,\nand the ability to handle large deformations. Subsequently, we introduce a\nclustering-improved Nystr\\\"om method to effectively reduce the computational\ncomplexity and storage of the Gram matrix to linear, while providing a rigorous\nbound for the low-rank approximation. Our method achieves high accuracy results\nacross various scenarios and surpasses competitors by a significant margin,\nparticularly on shapes with substantial deformations. Additionally, we\ndemonstrate the versatility of our method in challenging tasks such as shape\ntransfer and medical registration.\n","authors":["Mingyang Zhao","Jingen Jiang","Lei Ma","Shiqing Xin","Gaofeng Meng","Dong-Ming Yan"],"pdf_url":"https://arxiv.org/pdf/2406.18817v1.pdf","comment":"[CVPR 2024 Highlight] Project and code at:\n  https://github.com/zikai1/CVPR24_PointSetReg"},{"id":"http://arxiv.org/abs/2406.18809v1","updated":"2024-06-27T00:54:11Z","published":"2024-06-27T00:54:11Z","title":"Divide, Ensemble and Conquer: The Last Mile on Unsupervised Domain\n  Adaptation for On-Board Semantic Segmentation","summary":"  The last mile of unsupervised domain adaptation (UDA) for semantic\nsegmentation is the challenge of solving the syn-to-real domain gap. Recent UDA\nmethods have progressed significantly, yet they often rely on strategies\ncustomized for synthetic single-source datasets (e.g., GTA5), which limits\ntheir generalisation to multi-source datasets. Conversely, synthetic\nmulti-source datasets hold promise for advancing the last mile of UDA but\nremain underutilized in current research. Thus, we propose DEC, a flexible UDA\nframework for multi-source datasets. Following a divide-and-conquer strategy,\nDEC simplifies the task by categorizing semantic classes, training models for\neach category, and fusing their outputs by an ensemble model trained\nexclusively on synthetic datasets to obtain the final segmentation mask. DEC\ncan integrate with existing UDA methods, achieving state-of-the-art performance\non Cityscapes, BDD100K, and Mapillary Vistas, significantly narrowing the\nsyn-to-real domain gap.\n","authors":["Tao Lian","Jose L. Gómez","Antonio M. López"],"pdf_url":"https://arxiv.org/pdf/2406.18809v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12070v2","updated":"2024-06-27T00:45:18Z","published":"2023-11-19T19:44:44Z","title":"FDDM: Unsupervised Medical Image Translation with a Frequency-Decoupled\n  Diffusion Model","summary":"  Diffusion models have demonstrated significant potential in producing\nhigh-quality images in medical image translation to aid disease diagnosis,\nlocalization, and treatment. Nevertheless, current diffusion models have\nlimited success in achieving faithful image translations that can accurately\npreserve the anatomical structures of medical images, especially for unpaired\ndatasets. The preservation of structural and anatomical details is essential to\nreliable medical diagnosis and treatment planning, as structural mismatches can\nlead to disease misidentification and treatment errors. In this study, we\nintroduce the Frequency Decoupled Diffusion Model (FDDM) for MR-to-CT\nconversion. FDDM first obtains the anatomical information of the CT image from\nthe MR image through an initial conversion module. This anatomical information\nthen guides a subsequent diffusion model to generate high-quality CT images.\nOur diffusion model uses a dual-path reverse diffusion process for\nlow-frequency and high-frequency information, achieving a better balance\nbetween image quality and anatomical accuracy. We extensively evaluated FDDM\nusing public datasets for brain MR-to-CT and pelvis MR-to-CT translations,\ndemonstrating its superior performance to other GAN-based, VAE-based, and\ndiffusion-based models. The evaluation metrics included Frechet Inception\nDistance (FID), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity\nIndex Measure (SSIM). FDDM achieved the best scores on all metrics for both\ndatasets, particularly excelling in FID, with scores of 25.9 for brain data and\n29.2 for pelvis data, significantly outperforming other methods. These results\ndemonstrate that FDDM can generate high-quality target domain images while\nmaintaining the accuracy of translated anatomical structures.\n","authors":["Yunxiang Li","Hua-Chieh Shao","Xiaoxue Qian","You Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19578v1","updated":"2024-06-27T23:43:36Z","published":"2024-06-27T23:43:36Z","title":"PathAlign: A vision-language model for whole slide images in\n  histopathology","summary":"  Microscopic interpretation of histopathology images underlies many important\ndiagnostic and treatment decisions. While advances in vision-language modeling\nraise new opportunities for analysis of such images, the gigapixel-scale size\nof whole slide images (WSIs) introduces unique challenges. Additionally,\npathology reports simultaneously highlight key findings from small regions\nwhile also aggregating interpretation across multiple slides, often making it\ndifficult to create robust image-text pairs. As such, pathology reports remain\na largely untapped source of supervision in computational pathology, with most\nefforts relying on region-of-interest annotations or self-supervision at the\npatch-level. In this work, we develop a vision-language model based on the\nBLIP-2 framework using WSIs paired with curated text from pathology reports.\nThis enables applications utilizing a shared image-text embedding space, such\nas text or image retrieval for finding cases of interest, as well as\nintegration of the WSI encoder with a frozen large language model (LLM) for\nWSI-based generative text capabilities such as report generation or\nAI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000\nWSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure\ntypes, and tissue types. We present pathologist evaluation of text generation\nand text retrieval using WSI embeddings, as well as results for WSI\nclassification and workflow prioritization (slide-level triaging).\nModel-generated text for WSIs was rated by pathologists as accurate, without\nclinically significant error or omission, for 78% of WSIs on average. This work\ndemonstrates exciting potential capabilities for language-aligned WSI\nembeddings.\n","authors":["Faruk Ahmed","Andrew Sellergren","Lin Yang","Shawn Xu","Boris Babenko","Abbi Ward","Niels Olson","Arash Mohtashamian","Yossi Matias","Greg S. Corrado","Quang Duong","Dale R. Webster","Shravya Shetty","Daniel Golden","Yun Liu","David F. Steiner","Ellery Wulczyn"],"pdf_url":"https://arxiv.org/pdf/2406.19578v1.pdf","comment":"9 main pages and 19 pages of supplemental material; 3 main tables, 3\n  main figures and 11 supplemental tables, 7 supplemental figures"},{"id":"http://arxiv.org/abs/2404.11819v2","updated":"2024-06-27T23:16:58Z","published":"2024-04-18T00:41:32Z","title":"Utilizing Adversarial Examples for Bias Mitigation and Accuracy\n  Enhancement","summary":"  We propose a novel approach to mitigate biases in computer vision models by\nutilizing counterfactual generation and fine-tuning. While counterfactuals have\nbeen used to analyze and address biases in DNN models, the counterfactuals\nthemselves are often generated from biased generative models, which can\nintroduce additional biases or spurious correlations. To address this issue, we\npropose using adversarial images, that is images that deceive a deep neural\nnetwork but not humans, as counterfactuals for fair model training. Our\napproach leverages a curriculum learning framework combined with a fine-grained\nadversarial loss to fine-tune the model using adversarial examples. By\nincorporating adversarial images into the training data, we aim to prevent\nbiases from propagating through the pipeline. We validate our approach through\nboth qualitative and quantitative assessments, demonstrating improved bias\nmitigation and accuracy compared to existing methods. Qualitatively, our\nresults indicate that post-training, the decisions made by the model are less\ndependent on the sensitive attribute and our model better disentangles the\nrelationship between sensitive attributes and classification variables.\n","authors":["Pushkar Shukla","Dhruv Srikanth","Lee Cohen","Matthew Turk"],"pdf_url":"https://arxiv.org/pdf/2404.11819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19568v1","updated":"2024-06-27T23:03:58Z","published":"2024-06-27T23:03:58Z","title":"What Matters in Detecting AI-Generated Videos like Sora?","summary":"  Recent advancements in diffusion-based video generation have showcased\nremarkable results, yet the gap between synthetic and real-world videos remains\nunder-explored. In this study, we examine this gap from three fundamental\nperspectives: appearance, motion, and geometry, comparing real-world videos\nwith those generated by a state-of-the-art AI model, Stable Video Diffusion. To\nachieve this, we train three classifiers using 3D convolutional networks, each\ntargeting distinct aspects: vision foundation model features for appearance,\noptical flow for motion, and monocular depth for geometry. Each classifier\nexhibits strong performance in fake video detection, both qualitatively and\nquantitatively. This indicates that AI-generated videos are still easily\ndetectable, and a significant gap between real and fake videos persists.\nFurthermore, utilizing the Grad-CAM, we pinpoint systematic failures of\nAI-generated videos in appearance, motion, and geometry. Finally, we propose an\nEnsemble-of-Experts model that integrates appearance, optical flow, and depth\ninformation for fake video detection, resulting in enhanced robustness and\ngeneralization ability. Our model is capable of detecting videos generated by\nSora with high accuracy, even without exposure to any Sora videos during\ntraining. This suggests that the gap between real and fake videos can be\ngeneralized across various video generative models. Project page:\nhttps://justin-crchang.github.io/3DCNNDetection.github.io/\n","authors":["Chirui Chang","Zhengzhe Liu","Xiaoyang Lyu","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2406.19568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19560v1","updated":"2024-06-27T22:19:19Z","published":"2024-06-27T22:19:19Z","title":"Cost-efficient Active Illumination Camera For Hyper-spectral\n  Reconstruction","summary":"  Hyper-spectral imaging has recently gained increasing attention for use in\ndifferent applications, including agricultural investigation, ground tracking,\nremote sensing and many other. However, the high cost, large physical size and\ncomplicated operation process stop hyperspectral cameras from being employed\nfor various applications and research fields. In this paper, we introduce a\ncost-efficient, compact and easy to use active illumination camera that may\nbenefit many applications. We developed a fully functional prototype of such\ncamera. With the hope of helping with agricultural research, we tested our\ncamera for plant root imaging. In addition, a U-Net model for spectral\nreconstruction was trained by using a reference hyperspectral camera's data as\nground truth and our camera's data as input. We demonstrated our camera's\nability to obtain additional information over a typical RGB camera. In\naddition, the ability to reconstruct hyperspectral data from multi-spectral\ninput makes our device compatible to models and algorithms developed for\nhyperspectral applications with no modifications required.\n","authors":["Yuxuan Zhang","T. M. Sazzad","Yangyang Song","Spencer J. Chang","Ritesh Chowdhry","Tomas Mejia","Anna Hampton","Shelby Kucharski","Stefan Gerber","Barry Tillman","Marcio F. R. Resende","William M. Hammond","Chris H. Wilson","Alina Zare","Sanjeev J. Koppal"],"pdf_url":"https://arxiv.org/pdf/2406.19560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19557v1","updated":"2024-06-27T22:17:49Z","published":"2024-06-27T22:17:49Z","title":"Robustness Testing of Black-Box Models Against CT Degradation Through\n  Test-Time Augmentation","summary":"  Deep learning models for medical image segmentation and object detection are\nbecoming increasingly available as clinical products. However, as details are\nrarely provided about the training data, models may unexpectedly fail when\ncases differ from those in the training distribution. An approach allowing\npotential users to independently test the robustness of a model, treating it as\na black box and using only a few cases from their own site, is key for\nadoption. To address this, a method to test the robustness of these models\nagainst CT image quality variation is presented. In this work we present this\nframework by demonstrating that given the same training data, the model\narchitecture and data pre processing greatly affect the robustness of several\nfrequently used segmentation and object detection methods to simulated CT\nimaging artifacts and degradation. Our framework also addresses the concern\nabout the sustainability of deep learning models in clinical use, by\nconsidering future shifts in image quality due to scanner deterioration or\nimaging protocol changes which are not reflected in a limited local test\ndataset.\n","authors":["Jack Highton","Quok Zong Chong","Samuel Finestone","Arian Beqiri","Julia A. Schnabel","Kanwal K. Bhatia"],"pdf_url":"https://arxiv.org/pdf/2406.19557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19556v1","updated":"2024-06-27T22:16:53Z","published":"2024-06-27T22:16:53Z","title":"BOrg: A Brain Organoid-Based Mitosis Dataset for Automatic Analysis of\n  Brain Diseases","summary":"  Recent advances have enabled the study of human brain development using brain\norganoids derived from stem cells. Quantifying cellular processes like mitosis\nin these organoids offers insights into neurodevelopmental disorders, but the\nmanual analysis is time-consuming, and existing datasets lack specific details\nfor brain organoid studies. We introduce BOrg, a dataset designed to study\nmitotic events in the embryonic development of the brain using confocal\nmicroscopy images of brain organoids. BOrg utilizes an efficient annotation\npipeline with sparse point annotations and techniques that minimize expert\neffort, overcoming limitations of standard deep learning approaches on sparse\ndata. We adapt and benchmark state-of-the-art object detection and cell\ncounting models on BOrg for detecting and analyzing mitotic cells across\nprophase, metaphase, anaphase, and telophase stages. Our results demonstrate\nthese adapted models significantly improve mitosis analysis efficiency and\naccuracy for brain organoid research compared to existing methods. BOrg\nfacilitates the development of automated tools to quantify statistics like\nmitosis rates, aiding mechanistic studies of neurodevelopmental processes and\ndisorders. Data and code are available at https://github.com/awaisrauf/borg.\n","authors":["Muhammad Awais","Mehaboobathunnisa Sahul Hameed","Bidisha Bhattacharya","Orly Reiner","Rao Muhammad Anwer"],"pdf_url":"https://arxiv.org/pdf/2406.19556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19540v1","updated":"2024-06-27T21:34:51Z","published":"2024-06-27T21:34:51Z","title":"Weighted Circle Fusion: Ensembling Circle Representation from Different\n  Object Detection Results","summary":"  Recently, the use of circle representation has emerged as a method to improve\nthe identification of spherical objects (such as glomeruli, cells, and nuclei)\nin medical imaging studies. In traditional bounding box-based object detection,\ncombining results from multiple models improves accuracy, especially when\nreal-time processing isn't crucial. Unfortunately, this widely adopted strategy\nis not readily available for combining circle representations. In this paper,\nwe propose Weighted Circle Fusion (WCF), a simple approach for merging\npredictions from various circle detection models. Our method leverages\nconfidence scores associated with each proposed bounding circle to generate\naveraged circles. Our method undergoes thorough evaluation on a proprietary\ndataset for glomerular detection in object detection within whole slide imaging\n(WSI). The findings reveal a performance gain of 5 %, respectively, compared to\nexisting ensemble methods. Furthermore, the Weighted Circle Fusion technique\nnot only improves the precision of object detection in medical images but also\nnotably decreases false detections, presenting a promising direction for future\nresearch and application in pathological image analysis.\n","authors":["Jialin Yue","Tianyuan Yao","Ruining Deng","Quan Liu","Juming Xiong","Haichun Yang","Yuankai Huo"],"pdf_url":"https://arxiv.org/pdf/2406.19540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19520v1","updated":"2024-06-27T20:41:49Z","published":"2024-06-27T20:41:49Z","title":"Comparative Analysis Of Color Models For Human Perception And Visual\n  Color Difference","summary":"  Color is integral to human experience, influencing emotions, decisions, and\nperceptions. This paper presents a comparative analysis of various color\nmodels' alignment with human visual perception. The study evaluates color\nmodels such as RGB, HSV, HSL, XYZ, CIELAB, and CIELUV to assess their\neffectiveness in accurately representing how humans perceive color. We evaluate\neach model based on its ability to accurately reflect visual color differences\nand dominant palette extraction compatible with the human eye. In image\nprocessing, accurate assessment of color difference is essential for\napplications ranging from digital design to quality control. Current color\ndifference metrics do not always match how people see colors, causing issues in\naccurately judging subtle differences. Understanding how different color models\nalign with human visual perception is crucial for various applications in image\nprocessing, digital media, and design.\n","authors":["Aruzhan Burambekova","Pakizar Shamoi"],"pdf_url":"https://arxiv.org/pdf/2406.19520v1.pdf","comment":"The paper has been submitted to EJMCA journal for consideration.\n  Current version is a preprint"},{"id":"http://arxiv.org/abs/2406.15727v2","updated":"2024-06-27T20:13:34Z","published":"2024-06-22T04:32:50Z","title":"Semi-supervised variational autoencoder for cell feature extraction in\n  multiplexed immunofluorescence images","summary":"  Advancements in digital imaging technologies have sparked increased interest\nin using multiplexed immunofluorescence (mIF) images to visualise and identify\nthe interactions between specific immunophenotypes with the tumour\nmicroenvironment at the cellular level. Current state-of-the-art multiplexed\nimmunofluorescence image analysis pipelines depend on cell feature\nrepresentations characterised by morphological and stain intensity-based\nmetrics generated using simple statistical and machine learning-based tools.\nHowever, these methods are not capable of generating complex representations of\ncells. We propose a deep learning-based cell feature extraction model using a\nvariational autoencoder with supervision using a latent subspace to extract\ncell features in mIF images. We perform cell phenotype classification using a\ncohort of more than 44,000 multiplexed immunofluorescence cell image patches\nextracted across 1,093 tissue microarray cores of breast cancer patients, to\ndemonstrate the success of our model against current and alternative methods.\n","authors":["Piumi Sandarenu","Julia Chen","Iveta Slapetova","Lois Browne","Peter H. Graham","Alexander Swarbrick","Ewan K. A. Millar","Yang Song","Erik Meijering"],"pdf_url":"https://arxiv.org/pdf/2406.15727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10916v2","updated":"2024-06-27T19:43:52Z","published":"2024-03-16T12:44:08Z","title":"FishNet: Deep Neural Networks for Low-Cost Fish Stock Estimation","summary":"  Fish stock assessment often involves manual fish counting by taxonomy\nspecialists, which is both time-consuming and costly. We propose FishNet, an\nautomated computer vision system for both taxonomic classification and fish\nsize estimation from images captured with a low-cost digital camera. The system\nfirst performs object detection and segmentation using a Mask R-CNN to identify\nindividual fish from images containing multiple fish, possibly consisting of\ndifferent species. Then each fish species is classified and the length is\npredicted using separate machine learning models. To develop the model, we use\na dataset of 300,000 hand-labeled images containing 1.2M fish of 163 different\nspecies and ranging in length from 10cm to 250cm, with additional annotations\nand quality control methods used to curate high-quality training data. On\nheld-out test data sets, our system achieves a 92% intersection over union on\nthe fish segmentation task, a 89% top-1 classification accuracy on single fish\nspecies classification, and a 2.3cm mean absolute error on the fish length\nestimation task.\n","authors":["Moseli Mots'oehli","Anton Nikolaev","Wawan B. IGede","John Lynham","Peter J. Mous","Peter Sadowski"],"pdf_url":"https://arxiv.org/pdf/2403.10916v2.pdf","comment":"IEEE COINS 2024"},{"id":"http://arxiv.org/abs/2406.19498v1","updated":"2024-06-27T19:27:37Z","published":"2024-06-27T19:27:37Z","title":"Stereo Vision Based Robot for Remote Monitoring with VR Support","summary":"  The machine vision systems have been playing a significant role in visual\nmonitoring systems. With the help of stereovision and machine learning, it will\nbe able to mimic human-like visual system and behaviour towards the\nenvironment. In this paper, we present a stereo vision based 3-DOF robot which\nwill be used to monitor places from remote using cloud server and internet\ndevices. The 3-DOF robot will transmit human-like head movements, i.e., yaw,\npitch, roll and produce 3D stereoscopic video and stream it in Real-time. This\nvideo stream is sent to the user through any generic internet devices with VR\nbox support, i.e., smartphones giving the user a First-person real-time 3D\nexperience and transfers the head motion of the user to the robot also in\nReal-time. The robot will also be able to track moving objects and faces as a\ntarget using deep neural networks which enables it to be a standalone\nmonitoring robot. The user will be able to choose specific subjects to monitor\nin a space. The stereovision enables us to track the depth information of\ndifferent objects detected and will be used to track human interest objects\nwith its distances and sent to the cloud. A full working prototype is developed\nwhich showcases the capabilities of a monitoring system based on stereo vision,\nrobotics, and machine learning.\n","authors":["Mohamed Fazil M. S.","Arockia Selvakumar A.","Daniel Schilberg"],"pdf_url":"https://arxiv.org/pdf/2406.19498v1.pdf","comment":"6 Pages, 10 Figures"},{"id":"http://arxiv.org/abs/2406.19492v1","updated":"2024-06-27T19:16:57Z","published":"2024-06-27T19:16:57Z","title":"High-resolution segmentations of the hypothalamus and its subregions for\n  training of segmentation models","summary":"  Segmentation of brain structures on magnetic resonance imaging (MRI) is a\nhighly relevant neuroimaging topic, as it is a prerequisite for different\nanalyses such as volumetry or shape analysis. Automated segmentation\nfacilitates the study of brain structures in larger cohorts when compared with\nmanual segmentation, which is time-consuming. However, the development of most\nautomated methods relies on large and manually annotated datasets, which limits\nthe generalizability of these methods. Recently, new techniques using synthetic\nimages have emerged, reducing the need for manual annotation. Here we provide\nHELM, Hypothalamic ex vivo Label Maps, a dataset composed of label maps built\nfrom publicly available ultra-high resolution ex vivo MRI from 10 whole\nhemispheres, which can be used to develop segmentation methods using synthetic\ndata. The label maps are obtained with a combination of manual labels for the\nhypothalamic regions and automated segmentations for the rest of the brain, and\nmirrored to simulate entire brains. We also provide the pre-processed ex vivo\nscans, as this dataset can support future projects to include other structures\nafter these are manually segmented.\n","authors":["Livia Rodrigues","Martina Bocchetta","Oula Puonti","Douglas Greve","Ana Carolina Londe","Marcondes França","Simone Appenzeller","Leticia Rittner","Juan Eugenio Iglesias"],"pdf_url":"https://arxiv.org/pdf/2406.19492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16222v2","updated":"2024-06-27T19:02:24Z","published":"2024-04-24T21:49:59Z","title":"Step Differences in Instructional Video","summary":"  Comparing a user video to a reference how-to video is a key requirement for\nAR/VR technology delivering personalized assistance tailored to the user's\nprogress. However, current approaches for language-based assistance can only\nanswer questions about a single video. We propose an approach that first\nautomatically generates large amounts of visual instruction tuning data\ninvolving pairs of videos from HowTo100M by leveraging existing step\nannotations and accompanying narrations, and then trains a video-conditioned\nlanguage model to jointly reason across multiple raw videos. Our model achieves\nstate-of-the-art performance at identifying differences between video pairs and\nranking videos based on the severity of these differences, and shows promising\nability to perform general reasoning over multiple videos. Project page:\nhttps://github.com/facebookresearch/stepdiff\n","authors":["Tushar Nagarajan","Lorenzo Torresani"],"pdf_url":"https://arxiv.org/pdf/2404.16222v2.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2406.19485v1","updated":"2024-06-27T18:58:41Z","published":"2024-06-27T18:58:41Z","title":"GAPNet: Granularity Attention Network with Anatomy-Prior-Constraint for\n  Carotid Artery Segmentation","summary":"  Atherosclerosis is a chronic, progressive disease that primarily affects the\narterial walls. It is one of the major causes of cardiovascular disease.\nMagnetic Resonance (MR) black-blood vessel wall imaging (BB-VWI) offers crucial\ninsights into vascular disease diagnosis by clearly visualizing vascular\nstructures. However, the complex anatomy of the neck poses challenges in\ndistinguishing the carotid artery (CA) from surrounding structures, especially\nwith changes like atherosclerosis. In order to address these issues, we propose\nGAPNet, which is a consisting of a novel geometric prior deduced from.\n","authors":["Lin Zhang","Chenggang Lu","Xin-yang Shi","Caifeng Shan","Jiong Zhang","Da Chen","Laurent D. Cohen"],"pdf_url":"https://arxiv.org/pdf/2406.19485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19464v1","updated":"2024-06-27T18:06:38Z","published":"2024-06-27T18:06:38Z","title":"ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data","summary":"  Audio signals provide rich information for the robot interaction and object\nproperties through contact. These information can surprisingly ease the\nlearning of contact-rich robot manipulation skills, especially when the visual\ninformation alone is ambiguous or incomplete. However, the usage of audio data\nin robot manipulation has been constrained to teleoperated demonstrations\ncollected by either attaching a microphone to the robot or object, which\nsignificantly limits its usage in robot learning pipelines. In this work, we\nintroduce ManiWAV: an 'ear-in-hand' data collection device to collect\nin-the-wild human demonstrations with synchronous audio and visual feedback,\nand a corresponding policy interface to learn robot manipulation policy\ndirectly from the demonstrations. We demonstrate the capabilities of our system\nthrough four contact-rich manipulation tasks that require either passively\nsensing the contact events and modes, or actively sensing the object surface\nmaterials and states. In addition, we show that our system can generalize to\nunseen in-the-wild environments, by learning from diverse in-the-wild human\ndemonstrations. Project website: https://mani-wav.github.io/\n","authors":["Zeyi Liu","Cheng Chi","Eric Cousineau","Naveen Kuppuswamy","Benjamin Burchfiel","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2406.19464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19461v1","updated":"2024-06-27T18:03:06Z","published":"2024-06-27T18:03:06Z","title":"Efficient and Distributed Large-Scale 3D Map Registration using\n  Tomographic Features","summary":"  A robust, resource-efficient, distributed, and minimally parameterized 3D map\nmatching and merging algorithm is proposed. The suggested algorithm utilizes\ntomographic features from 2D projections of horizontal cross-sections of\ngravity-aligned local maps, and matches these projection slices at all possible\nheight differences, enabling the estimation of four degrees of freedom in an\nefficient and parallelizable manner. The advocated algorithm improves\nstate-of-the-art feature extraction and registration pipelines by an order of\nmagnitude in memory use and execution time. Experimental studies are offered to\ninvestigate the efficiency of this 3D map merging scheme.\n","authors":["Halil Utku Unlu","Anthony Tzes","Prashanth Krishnamurthy","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2406.19461v1.pdf","comment":"Submitted to Elsevier Journal: Robotics and Autonomous Systems (RAS)"},{"id":"http://arxiv.org/abs/2310.06389v3","updated":"2024-06-27T18:02:06Z","published":"2023-10-10T07:52:30Z","title":"Learning Stackable and Skippable LEGO Bricks for Efficient,\n  Reconfigurable, and Variable-Resolution Diffusion Modeling","summary":"  Diffusion models excel at generating photo-realistic images but come with\nsignificant computational costs in both training and sampling. While various\ntechniques address these computational challenges, a less-explored issue is\ndesigning an efficient and adaptable network backbone for iterative refinement.\nCurrent options like U-Net and Vision Transformer often rely on\nresource-intensive deep networks and lack the flexibility needed for generating\nimages at variable resolutions or with a smaller network than used in training.\nThis study introduces LEGO bricks, which seamlessly integrate Local-feature\nEnrichment and Global-content Orchestration. These bricks can be stacked to\ncreate a test-time reconfigurable diffusion backbone, allowing selective\nskipping of bricks to reduce sampling costs and generate higher-resolution\nimages than the training data. LEGO bricks enrich local regions with an MLP and\ntransform them using a Transformer block while maintaining a consistent\nfull-resolution image across all bricks. Experimental results demonstrate that\nLEGO bricks enhance training efficiency, expedite convergence, and facilitate\nvariable-resolution image generation while maintaining strong generative\nperformance. Moreover, LEGO significantly reduces sampling time compared to\nother methods, establishing it as a valuable enhancement for diffusion models.\nOur code and project page are available at\nhttps://jegzheng.github.io/LEGODiffusion.\n","authors":["Huangjie Zheng","Zhendong Wang","Jianbo Yuan","Guanghan Ning","Pengcheng He","Quanzeng You","Hongxia Yang","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.06389v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19435v1","updated":"2024-06-27T17:59:49Z","published":"2024-06-27T17:59:49Z","title":"A Sanity Check for AI-generated Image Detection","summary":"  With the rapid development of generative models, discerning AI-generated\ncontent has evoked increasing attention from both industry and academia. In\nthis paper, we conduct a sanity check on \"whether the task of AI-generated\nimage detection has been solved\". To start with, we present Chameleon dataset,\nconsisting AIgenerated images that are genuinely challenging for human\nperception. To quantify the generalization of existing methods, we evaluate 9\noff-the-shelf AI-generated image detectors on Chameleon dataset. Upon analysis,\nalmost all models classify AI-generated images as real ones. Later, we propose\nAIDE (AI-generated Image DEtector with Hybrid Features), which leverages\nmultiple experts to simultaneously extract visual artifacts and noise patterns.\nSpecifically, to capture the high-level semantics, we utilize CLIP to compute\nthe visual embedding. This effectively enables the model to discern\nAI-generated images based on semantics or contextual information; Secondly, we\nselect the highest frequency patches and the lowest frequency patches in the\nimage, and compute the low-level patchwise features, aiming to detect\nAI-generated images by low-level artifacts, for example, noise pattern,\nanti-aliasing, etc. While evaluating on existing benchmarks, for example,\nAIGCDetectBenchmark and GenImage, AIDE achieves +3.5% and +4.6% improvements to\nstate-of-the-art methods, and on our proposed challenging Chameleon benchmarks,\nit also achieves the promising results, despite this problem for detecting\nAI-generated images is far from being solved. The dataset, codes, and pre-train\nmodels will be published at https://github.com/shilinyan99/AIDE.\n","authors":["Shilin Yan","Ouxiang Li","Jiayin Cai","Yanbin Hao","Xiaolong Jiang","Yao Hu","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2406.19435v1.pdf","comment":"Project page: https://shilinyan99.github.io/AIDE Code:\n  https://github.com/shilinyan99/AIDE"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2406.19384v1","updated":"2024-06-27T17:57:03Z","published":"2024-06-27T17:57:03Z","title":"The Remarkable Robustness of LLMs: Stages of Inference?","summary":"  We demonstrate and investigate the remarkable robustness of Large Language\nModels by deleting and swapping adjacent layers. We find that deleting and\nswapping interventions retain 72-95\\% of the original model's prediction\naccuracy without fine-tuning, whereas models with more layers exhibit more\nrobustness. Based on the results of the layer-wise intervention and further\nexperiments, we hypothesize the existence of four universal stages of inference\nacross eight different models: detokenization, feature engineering, prediction\nensembling, and residual sharpening. The first stage integrates local\ninformation, lifting raw token representations into higher-level contextual\nrepresentations. Next is the iterative refinement of task and entity-specific\nfeatures. Then, the second half of the model begins with a phase transition,\nwhere hidden representations align more with the vocabulary space due to\nspecialized model components. Finally, the last layer sharpens the following\ntoken distribution by eliminating obsolete features that add noise to the\nprediction.\n","authors":["Vedang Lad","Wes Gurnee","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2406.19384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19380v1","updated":"2024-06-27T17:55:31Z","published":"2024-06-27T17:55:31Z","title":"TabReD: A Benchmark of Tabular Machine Learning in-the-Wild","summary":"  Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.\n","authors":["Ivan Rubachev","Nikolay Kartashev","Yury Gorishniy","Artem Babenko"],"pdf_url":"https://arxiv.org/pdf/2406.19380v1.pdf","comment":"Code: https://github.com/puhsu/tabred"},{"id":"http://arxiv.org/abs/2406.19370v1","updated":"2024-06-27T17:50:05Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2406.19370v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2405.10930v2","updated":"2024-06-27T17:38:20Z","published":"2024-05-17T17:31:02Z","title":"Submodular Information Selection for Hypothesis Testing with\n  Misclassification Penalties","summary":"  We consider the problem of selecting an optimal subset of information sources\nfor a hypothesis testing/classification task where the goal is to identify the\ntrue state of the world from a finite set of hypotheses, based on finite\nobservation samples from the sources. In order to characterize the learning\nperformance, we propose a misclassification penalty framework, which enables\nnon-uniform treatment of different misclassification errors. In a centralized\nBayesian learning setting, we study two variants of the subset selection\nproblem: (i) selecting a minimum cost information set to ensure that the\nmaximum penalty of misclassifying the true hypothesis remains bounded and (ii)\nselecting an optimal information set under a limited budget to minimize the\nmaximum penalty of misclassifying the true hypothesis. Under certain\nassumptions, we prove that the objective (or constraints) of these\ncombinatorial optimization problems are weak (or approximate) submodular, and\nestablish high-probability performance guarantees for greedy algorithms.\nFurther, we propose an alternate metric for information set selection which is\nbased on the total penalty of misclassification. We prove that this metric is\nsubmodular and establish near-optimal guarantees for the greedy algorithms for\nboth the information set selection problems. Finally, we present numerical\nsimulations to validate our theoretical results over several randomly generated\ninstances.\n","authors":["Jayanth Bhargav","Mahsa Ghasemi","Shreyas Sundaram"],"pdf_url":"https://arxiv.org/pdf/2405.10930v2.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.19356v1","updated":"2024-06-27T17:37:31Z","published":"2024-06-27T17:37:31Z","title":"DiVERT: Distractor Generation with Variational Errors Represented as\n  Text for Math Multiple-choice Questions","summary":"  High-quality distractors are crucial to both the assessment and pedagogical\nvalue of multiple-choice questions (MCQs), where manually crafting ones that\nanticipate knowledge deficiencies or misconceptions among real students is\ndifficult. Meanwhile, automated distractor generation, even with the help of\nlarge language models (LLMs), remains challenging for subjects like math. It is\ncrucial to not only identify plausible distractors but also understand the\nerror behind them. In this paper, we introduce DiVERT (Distractor Generation\nwith Variational Errors Represented as Text), a novel variational approach that\nlearns an interpretable representation of errors behind distractors in math\nMCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions\nused by hundreds of thousands of students, we show that DiVERT, despite using a\nbase open-source LLM with 7B parameters, outperforms state-of-the-art\napproaches using GPT-4o on downstream distractor generation. We also conduct a\nhuman evaluation with math educators and find that DiVERT leads to error labels\nthat are of comparable quality to human-authored ones.\n","authors":["Nigel Fernandez","Alexander Scarlatos","Simon Woodhead","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2406.19356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13040v2","updated":"2024-06-27T17:27:13Z","published":"2024-03-19T17:35:17Z","title":"Physics-Guided Neural Networks for Intraventricular Vector Flow Mapping","summary":"  Intraventricular vector flow mapping (iVFM) seeks to enhance and quantify\ncolor Doppler in cardiac imaging. In this study, we propose novel alternatives\nto the traditional iVFM optimization scheme by utilizing physics-informed\nneural networks (PINNs) and a physics-guided nnU-Net-based supervised approach.\nWhen evaluated on simulated color Doppler images derived from a\npatient-specific computational fluid dynamics model and in vivo Doppler\nacquisitions, both approaches demonstrate comparable reconstruction performance\nto the original iVFM algorithm. The efficiency of PINNs is boosted through\ndual-stage optimization and pre-optimized weights. On the other hand, the\nnnU-Net method excels in generalizability and real-time capabilities. Notably,\nnnU-Net shows superior robustness on sparse and truncated Doppler data while\nmaintaining independence from explicit boundary conditions. Overall, our\nresults highlight the effectiveness of these methods in reconstructing\nintraventricular vector blood flow. The study also suggests potential\napplications of PINNs in ultrafast color Doppler imaging and the incorporation\nof fluid dynamics equations to derive biomarkers for cardiovascular diseases\nbased on blood flow.\n","authors":["Hang Jung Ling","Salomé Bru","Julia Puig","Florian Vixège","Simon Mendez","Franck Nicoud","Pierre-Yves Courand","Olivier Bernard","Damien Garcia"],"pdf_url":"https://arxiv.org/pdf/2403.13040v2.pdf","comment":"12 pages, accepted for publication in IEEE TUFFC; camera ready\n  corrections, corrected acknowledgments"},{"id":"http://arxiv.org/abs/2402.05162v2","updated":"2024-06-27T17:23:58Z","published":"2024-02-07T18:34:38Z","title":"Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank\n  Modifications","summary":"  Large language models (LLMs) show inherent brittleness in their safety\nmechanisms, as evidenced by their susceptibility to jailbreaking and even\nnon-malicious fine-tuning. This study explores this brittleness of safety\nalignment by leveraging pruning and low-rank modifications. We develop methods\nto identify critical regions that are vital for safety guardrails, and that are\ndisentangled from utility-relevant regions at both the neuron and rank levels.\nSurprisingly, the isolated regions we find are sparse, comprising about $3\\%$\nat the parameter level and $2.5\\%$ at the rank level. Removing these regions\ncompromises safety without significantly impacting utility, corroborating the\ninherent brittleness of the model's safety mechanisms. Moreover, we show that\nLLMs remain vulnerable to low-cost fine-tuning attacks even when modifications\nto the safety-critical regions are restricted. These findings underscore the\nurgent need for more robust safety strategies in LLMs.\n","authors":["Boyi Wei","Kaixuan Huang","Yangsibo Huang","Tinghao Xie","Xiangyu Qi","Mengzhou Xia","Prateek Mittal","Mengdi Wang","Peter Henderson"],"pdf_url":"https://arxiv.org/pdf/2402.05162v2.pdf","comment":"22 pages, 9 figures. Project page is available at\n  https://boyiwei.com/alignment-attribution/"},{"id":"http://arxiv.org/abs/2405.16755v2","updated":"2024-06-27T17:13:32Z","published":"2024-05-27T01:54:16Z","title":"CHESS: Contextual Harnessing for Efficient SQL Synthesis","summary":"  Utilizing large language models (LLMs) for transforming natural language\nquestions into SQL queries (text-to-SQL) is a promising yet challenging\napproach, particularly when applied to real-world databases with complex and\nextensive schemas. In particular, effectively incorporating data catalogs and\ndatabase values for SQL generation remains an obstacle, leading to suboptimal\nsolutions. We address this problem by proposing a new pipeline that effectively\nretrieves relevant data and context, selects an efficient schema, and\nsynthesizes correct and efficient SQL queries. To increase retrieval precision,\nour pipeline introduces a hierarchical retrieval method leveraging\nmodel-generated keywords, locality-sensitive hashing indexing, and vector\ndatabases. Additionally, we have developed an adaptive schema pruning technique\nthat adjusts based on the complexity of the problem and the model's context\nsize. Our approach generalizes to both frontier proprietary models like GPT-4\nand open-source models such as Llama-3-70B. Through a series of ablation\nstudies, we demonstrate the effectiveness of each component of our pipeline and\nits impact on the end-to-end performance. Our method achieves new\nstate-of-the-art performance on the cross-domain challenging BIRD dataset.\n","authors":["Shayan Talaei","Mohammadreza Pourreza","Yu-Chen Chang","Azalia Mirhoseini","Amin Saberi"],"pdf_url":"https://arxiv.org/pdf/2405.16755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19328v1","updated":"2024-06-27T16:59:14Z","published":"2024-06-27T16:59:14Z","title":"Subtractive Training for Music Stem Insertion using Latent Diffusion\n  Models","summary":"  We present Subtractive Training, a simple and novel method for synthesizing\nindividual musical instrument stems given other instruments as context. This\nmethod pairs a dataset of complete music mixes with 1) a variant of the dataset\nlacking a specific stem, and 2) LLM-generated instructions describing how the\nmissing stem should be reintroduced. We then fine-tune a pretrained\ntext-to-audio diffusion model to generate the missing instrument stem, guided\nby both the existing stems and the text instruction. Our results demonstrate\nSubtractive Training's efficacy in creating authentic drum stems that\nseamlessly blend with the existing tracks. We also show that we can use the\ntext instruction to control the generation of the inserted stem in terms of\nrhythm, dynamics, and genre, allowing us to modify the style of a single\ninstrument in a full song while keeping the remaining instruments the same.\nLastly, we extend this technique to MIDI formats, successfully generating\ncompatible bass, drum, and guitar parts for incomplete arrangements.\n","authors":["Ivan Villa-Renteria","Mason L. Wang","Zachary Shah","Zhe Li","Soohyun Kim","Neelesh Ramachandran","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2406.19328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12373v2","updated":"2024-06-27T16:56:13Z","published":"2024-06-18T07:58:33Z","title":"WebCanvas: Benchmarking Web Agents in Online Environments","summary":"  For web agents to be practically useful, they must adapt to the continuously\nevolving web environment characterized by frequent updates to user interfaces\nand content. However, most existing benchmarks only capture the static aspects\nof the web. To bridge this gap, we introduce WebCanvas, an innovative online\nevaluation framework for web agents that effectively addresses the dynamic\nnature of web interactions. WebCanvas contains three main components to\nfacilitate realistic assessments: (1) A novel evaluation metric which reliably\ncapture critical intermediate actions or states necessary for task completions\nwhile disregarding noise caused by insignificant events or changed\nweb-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version\nof original Mind2Web static dataset containing 542 tasks with 2439 intermediate\nevaluation states; (3) Lightweight and generalizable annotation tools and\ntesting pipelines that enables the community to collect and maintain the\nhigh-quality, up-to-date dataset. Building on WebCanvas, we open-source an\nagent framework with extensible modules for reasoning, providing a foundation\nfor the community to conduct online inference and evaluations. Our\nbest-performing agent achieves a task success rate of 23.1% and a task\ncompletion rate of 48.8% on the Mind2Web-Live test set. Additionally, we\nanalyze the performance discrepancies across various websites, domains, and\nexperimental environments. We encourage the community to contribute further\ninsights on online agent evaluation, thereby advancing this field of research.\n","authors":["Yichen Pan","Dehan Kong","Sida Zhou","Cheng Cui","Yifei Leng","Bing Jiang","Hangyu Liu","Yanyi Shang","Shuyan Zhou","Tongshuang Wu","Zhengyang Wu"],"pdf_url":"https://arxiv.org/pdf/2406.12373v2.pdf","comment":"Our platform, tool and dataset are publically available at\n  https://www.imean.ai/web-canvas/ and\n  https://huggingface.co/datasets/iMeanAI/Mind2Web-Live/"},{"id":"http://arxiv.org/abs/2406.19320v1","updated":"2024-06-27T16:54:12Z","published":"2024-06-27T16:54:12Z","title":"Efficient World Models with Context-Aware Tokenization","summary":"  Scaling up deep Reinforcement Learning (RL) methods presents a significant\nchallenge. Following developments in generative modelling, model-based RL\npositions itself as a strong contender. Recent advances in sequence modelling\nhave led to effective transformer-based world models, albeit at the price of\nheavy computations due to the long sequences of tokens required to accurately\nsimulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with\na world model architecture composed of a discrete autoencoder that encodes\nstochastic deltas between time steps and an autoregressive transformer that\npredicts future deltas by summarizing the current state of the world with\ncontinuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of\nthe art at multiple frame budgets, while being an order of magnitude faster to\ntrain than previous attention-based approaches. We release our code and models\nat https://github.com/vmicheli/delta-iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2406.19320v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2406.19317v1","updated":"2024-06-27T16:52:19Z","published":"2024-06-27T16:52:19Z","title":"Jump Starting Bandits with LLM-Generated Prior Knowledge","summary":"  We present substantial evidence demonstrating the benefits of integrating\nLarge Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.\nContextual bandits have been widely used in recommendation systems to generate\npersonalized suggestions based on user-specific contexts. We show that LLMs,\npre-trained on extensive corpora rich in human knowledge and preferences, can\nsimulate human behaviours well enough to jump-start contextual multi-armed\nbandits to reduce online learning regret. We propose an initialization\nalgorithm for contextual bandits by prompting LLMs to produce a pre-training\ndataset of approximate human preferences for the bandit. This significantly\nreduces online learning regret and data-gathering costs for training such\nmodels. Our approach is validated empirically through two sets of experiments\nwith different bandit setups: one which utilizes LLMs to serve as an oracle and\na real-world experiment utilizing data from a conjoint survey experiment.\n","authors":["Parand A. Alamdari","Yanshuai Cao","Kevin H. Wilson"],"pdf_url":"https://arxiv.org/pdf/2406.19317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.13775v2","updated":"2024-06-27T16:51:27Z","published":"2023-03-24T03:28:05Z","title":"GSplit: Scaling Graph Neural Network Training on Large Graphs via\n  Split-Parallelism","summary":"  Graph neural networks (GNNs), an emerging class of machine learning models\nfor graphs, have gained popularity for their superior performance in various\ngraph analytical tasks. Mini-batch training is commonly used to train GNNs on\nlarge graphs, and data parallelism is the standard approach to scale mini-batch\ntraining across multiple GPUs. One of the major performance costs in GNN\ntraining is the loading of input features, which prevents GPUs from being fully\nutilized. In this paper, we argue that this problem is exacerbated by\nredundancies that are inherent to the data parallel approach. To address this\nissue, we introduce a hybrid parallel mini-batch training paradigm called split\nparallelism. Split parallelism avoids redundant data loads and splits the\nsampling and training of each mini-batch across multiple GPUs online, at each\niteration, using a lightweight splitting algorithm. We implement split\nparallelism in GSplit and show that it outperforms state-of-the-art mini-batch\ntraining systems like DGL, Quiver, and $P^3$.\n","authors":["Sandeep Polisetty","Juelin Liu","Kobi Falus","Yi Ren Fung","Seung-Hwan Lim","Hui Guan","Marco Serafini"],"pdf_url":"https://arxiv.org/pdf/2303.13775v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19314v1","updated":"2024-06-27T16:47:42Z","published":"2024-06-27T16:47:42Z","title":"LiveBench: A Challenging, Contamination-Free LLM Benchmark","summary":"  Test set contamination, wherein test data from a benchmark ends up in a newer\nmodel's training set, is a well-documented obstacle for fair LLM evaluation and\ncan quickly render benchmarks obsolete. To mitigate this, many recent\nbenchmarks crowdsource new prompts and evaluations from human or LLM judges;\nhowever, these can introduce significant biases, and break down when scoring\nhard questions. In this work, we introduce a new benchmark for LLMs designed to\nbe immune to both test set contamination and the pitfalls of LLM judging and\nhuman crowdsourcing. We release LiveBench, the first benchmark that (1)\ncontains frequently-updated questions from recent information sources, (2)\nscores answers automatically according to objective ground-truth values, and\n(3) contains a wide variety of challenging tasks, spanning math, coding,\nreasoning, language, instruction following, and data analysis. To achieve this,\nLiveBench contains questions that are based on recently-released math\ncompetitions, arXiv papers, news articles, and datasets, and it contains\nharder, contamination-free versions of tasks from previous benchmarks such as\nBig-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source\nmodels, as well as dozens of open-source models ranging from 0.5B to 110B in\nsize. LiveBench is difficult, with top models achieving below 65% accuracy. We\nrelease all questions, code, and model answers. Questions will be added and\nupdated on a monthly basis, and we will release new tasks and harder versions\nof tasks over time so that LiveBench can distinguish between the capabilities\nof LLMs as they improve in the future. We welcome community engagement and\ncollaboration for expanding the benchmark tasks and models.\n","authors":["Colin White","Samuel Dooley","Manley Roberts","Arka Pal","Ben Feuer","Siddhartha Jain","Ravid Shwartz-Ziv","Neel Jain","Khalid Saifullah","Siddartha Naidu","Chinmay Hegde","Yann LeCun","Tom Goldstein","Willie Neiswanger","Micah Goldblum"],"pdf_url":"https://arxiv.org/pdf/2406.19314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.17293v3","updated":"2024-06-27T16:38:18Z","published":"2023-12-28T13:59:43Z","title":"$μ$GUIDE: a framework for quantitative imaging via generalized\n  uncertainty-driven inference using deep learning","summary":"  This work proposes $\\mu$GUIDE: a general Bayesian framework to estimate\nposterior distributions of tissue microstructure parameters from any given\nbiophysical model or MRI signal representation, with exemplar demonstration in\ndiffusion-weighted MRI. Harnessing a new deep learning architecture for\nautomatic signal feature selection combined with simulation-based inference and\nefficient sampling of the posterior distributions, $\\mu$GUIDE bypasses the high\ncomputational and time cost of conventional Bayesian approaches and does not\nrely on acquisition constraints to define model-specific summary statistics.\nThe obtained posterior distributions allow to highlight degeneracies present in\nthe model definition and quantify the uncertainty and ambiguity of the\nestimated parameters.\n","authors":["Maëliss Jallais","Marco Palombo"],"pdf_url":"https://arxiv.org/pdf/2312.17293v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08819v2","updated":"2024-06-27T16:30:32Z","published":"2024-02-20T04:13:48Z","title":"Thermometer: Towards Universal Calibration for Large Language Models","summary":"  We consider the issue of calibration in large language models (LLM). Recent\nstudies have found that common interventions such as instruction tuning often\nresult in poorly calibrated LLMs. Although calibration is well-explored in\ntraditional applications, calibrating LLMs is uniquely challenging. These\nchallenges stem as much from the severe computational requirements of LLMs as\nfrom their versatility, which allows them to be applied to diverse tasks.\nAddressing these challenges, we propose THERMOMETER, a calibration approach\ntailored to LLMs. THERMOMETER learns an auxiliary model, given data from\nmultiple tasks, for calibrating a LLM. It is computationally efficient,\npreserves the accuracy of the LLM, and produces better-calibrated responses for\nnew tasks. Extensive empirical evaluations across various benchmarks\ndemonstrate the effectiveness of the proposed method.\n","authors":["Maohao Shen","Subhro Das","Kristjan Greenewald","Prasanna Sattigeri","Gregory Wornell","Soumya Ghosh"],"pdf_url":"https://arxiv.org/pdf/2403.08819v2.pdf","comment":"Camera ready version for ICML 2024"},{"id":"http://arxiv.org/abs/2406.19302v1","updated":"2024-06-27T16:17:33Z","published":"2024-06-27T16:17:33Z","title":"Mapping Land Naturalness from Sentinel-2 using Deep Contextual and\n  Geographical Priors","summary":"  In recent decades, the causes and consequences of climate change have\naccelerated, affecting our planet on an unprecedented scale. This change is\nclosely tied to the ways in which humans alter their surroundings. As our\nactions continue to impact natural areas, using satellite images to observe and\nmeasure these effects has become crucial for understanding and combating\nclimate change. Aiming to map land naturalness on the continuum of modern human\npressure, we have developed a multi-modal supervised deep learning framework\nthat addresses the unique challenges of satellite data and the task at hand. We\nincorporate contextual and geographical priors, represented by corresponding\ncoordinate information and broader contextual information, including and\nsurrounding the immediate patch to be predicted. Our framework improves the\nmodel's predictive performance in mapping land naturalness from Sentinel-2\ndata, a type of multi-spectral optical satellite imagery. Recognizing that our\nprotective measures are only as effective as our understanding of the\necosystem, quantifying naturalness serves as a crucial step toward enhancing\nour environmental stewardship.\n","authors":["Burak Ekim","Michael Schmitt"],"pdf_url":"https://arxiv.org/pdf/2406.19302v1.pdf","comment":"6 pages, 3 figures, ICLR 2024 Tackling Climate Change with Machine\n  Learning Workshop"},{"id":"http://arxiv.org/abs/2406.19301v1","updated":"2024-06-27T16:17:26Z","published":"2024-06-27T16:17:26Z","title":"MCNC: Manifold Constrained Network Compression","summary":"  The outstanding performance of large foundational models across diverse\ntasks-from computer vision to speech and natural language processing-has\nsignificantly increased their demand. However, storing and transmitting these\nmodels pose significant challenges due to their massive size (e.g., 350GB for\nGPT-3). Recent literature has focused on compressing the original weights or\nreducing the number of parameters required for fine-tuning these models. These\ncompression methods typically involve constraining the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA) or quantization (e.g.,\nQLoRA) during model training. In this paper, we present MCNC as a novel model\ncompression method that constrains the parameter space to low-dimensional\npre-defined and frozen nonlinear manifolds, which effectively cover this space.\nGiven the prevalence of good solutions in over-parameterized deep neural\nnetworks, we show that by constraining the parameter space to our proposed\nmanifold, we can identify high-quality solutions while achieving unprecedented\ncompression rates across a wide variety of tasks. Through extensive experiments\nin computer vision and natural language processing tasks, we demonstrate that\nour method, MCNC, significantly outperforms state-of-the-art baselines in terms\nof compression, accuracy, and/or model reconstruction time.\n","authors":["Chayne Thrash","Ali Abbasi","Parsa Nooralinejad","Soroush Abbasi Koohpayegani","Reed Andreas","Hamed Pirsiavash","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2406.19301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19300v1","updated":"2024-06-27T16:16:55Z","published":"2024-06-27T16:16:55Z","title":"scTree: Discovering Cellular Hierarchies in the Presence of Batch\n  Effects in scRNA-seq Data","summary":"  We propose a novel method, scTree, for single-cell Tree Variational\nAutoencoders, extending a hierarchical clustering approach to single-cell RNA\nsequencing data. scTree corrects for batch effects while simultaneously\nlearning a tree-structured data representation. This VAE-based method allows\nfor a more in-depth understanding of complex cellular landscapes independently\nof the biasing effects of batches. We show empirically on seven datasets that\nscTree discovers the underlying clusters of the data and the hierarchical\nrelations between them, as well as outperforms established baseline methods\nacross these datasets. Additionally, we analyze the learned hierarchy to\nunderstand its biological relevance, thus underpinning the importance of\nintegrating batch correction directly into the clustering procedure.\n","authors":["Moritz Vandenhirtz","Florian Barkmann","Laura Manduchi","Julia E. Vogt","Valentina Boeva"],"pdf_url":"https://arxiv.org/pdf/2406.19300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15411v2","updated":"2024-06-27T16:15:39Z","published":"2024-02-23T16:19:32Z","title":"Optimistic Information Directed Sampling","summary":"  We study the problem of online learning in contextual bandit problems where\nthe loss function is assumed to belong to a known parametric function class. We\npropose a new analytic framework for this setting that bridges the Bayesian\ntheory of information-directed sampling due to Russo and Van Roy (2018) and the\nworst-case theory of Foster, Kakade, Qian, and Rakhlin (2021) based on the\ndecision-estimation coefficient. Drawing from both lines of work, we propose a\nalgorithmic template called Optimistic Information-Directed Sampling and show\nthat it can achieve instance-dependent regret guarantees similar to the ones\nachievable by the classic Bayesian IDS method, but with the major advantage of\nnot requiring any Bayesian assumptions. The key technical innovation of our\nanalysis is introducing an optimistic surrogate model for the regret and using\nit to define a frequentist version of the Information Ratio of Russo and Van\nRoy (2018), and a less conservative version of the Decision Estimation\nCoefficient of Foster et al. (2021). Keywords: Contextual bandits,\ninformation-directed sampling, decision estimation coefficient, first-order\nregret bounds.\n","authors":["Gergely Neu","Matteo Papini","Ludovic Schwartz"],"pdf_url":"https://arxiv.org/pdf/2402.15411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19298v1","updated":"2024-06-27T16:13:34Z","published":"2024-06-27T16:13:34Z","title":"Compositional Image Decomposition with Diffusion Models","summary":"  Given an image of a natural scene, we are able to quickly decompose it into a\nset of components such as objects, lighting, shadows, and foreground. We can\nthen envision a scene where we combine certain components with those from other\nimages, for instance a set of objects from our bedroom and animals from a zoo\nunder the lighting conditions of a forest, even if we have never encountered\nsuch a scene before. In this paper, we present a method to decompose an image\ninto such compositional components. Our approach, Decomp Diffusion, is an\nunsupervised method which, when given a single image, infers a set of different\ncomponents in the image, each represented by a diffusion model. We demonstrate\nhow components can capture different factors of the scene, ranging from global\nscene descriptors like shadows or facial expression to local scene descriptors\nlike constituent objects. We further illustrate how inferred factors can be\nflexibly composed, even with factors inferred from other models, to generate a\nvariety of scenes sharply different than those seen in training time. Website\nand code at https://energy-based-model.github.io/decomp-diffusion.\n","authors":["Jocelin Su","Nan Liu","Yanbo Wang","Joshua B. Tenenbaum","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2406.19298v1.pdf","comment":"ICML 2024, Webpage:\n  https://energy-based-model.github.io/decomp-diffusion"},{"id":"http://arxiv.org/abs/2406.19292v1","updated":"2024-06-27T16:05:13Z","published":"2024-06-27T16:05:13Z","title":"From Artificial Needles to Real Haystacks: Improving Retrieval\n  Capabilities in LLMs by Finetuning on Synthetic Data","summary":"  Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.\n","authors":["Zheyang Xiong","Vasilis Papageorgiou","Kangwook Lee","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.19292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.14938v3","updated":"2024-06-27T16:00:16Z","published":"2023-07-27T15:30:22Z","title":"Efficient Interaction-Aware Interval Analysis of Neural Network Feedback\n  Loops","summary":"  In this paper, we propose a computationally efficient framework for interval\nreachability of systems with neural network controllers. Our approach leverages\ninclusion functions for the open-loop system and the neural network controller\nto embed the closed-loop system into a larger-dimensional embedding system,\nwhere a single trajectory over-approximates the original system's behavior\nunder uncertainty. We propose two methods for constructing closed-loop\nembedding systems, which account for the interactions between the system and\nthe controller in different ways. The interconnection-based approach considers\nthe worst-case evolution of each coordinate separately by substituting the\nneural network inclusion function into the open-loop inclusion function. The\ninteraction-based approach uses novel Jacobian-based inclusion functions to\ncapture the first-order interactions between the open-loop system and the\ncontroller by leveraging state-of-the-art neural network verifiers. Finally, we\nimplement our approach in a Python framework called ReachMM to demonstrate its\nefficiency and scalability on benchmarks and examples ranging to $200$ state\ndimensions.\n","authors":["Saber Jafarpour","Akash Harapanahalli","Samuel Coogan"],"pdf_url":"https://arxiv.org/pdf/2307.14938v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02116v2","updated":"2024-06-27T15:53:56Z","published":"2023-10-03T14:57:31Z","title":"Coarse-to-Fine Concept Bottleneck Models","summary":"  Deep learning algorithms have recently gained significant attention due to\ntheir impressive performance. However, their high complexity and\nun-interpretable mode of operation hinders their confident deployment in\nreal-world safety-critical tasks. This work targets ante hoc interpretability,\nand specifically Concept Bottleneck Models (CBMs). Our goal is to design a\nframework that admits a highly interpretable decision making process with\nrespect to human understandable concepts, on two levels of granularity. To this\nend, we propose a novel two-level concept discovery formulation leveraging: (i)\nrecent advances in vision-language models, and (ii) an innovative formulation\nfor coarse-to-fine concept selection via data-driven and sparsity-inducing\nBayesian arguments. Within this framework, concept information does not solely\nrely on the similarity between the whole image and general unstructured\nconcepts; instead, we introduce the notion of concept hierarchy to uncover and\nexploit more granular concept information residing in patch-specific regions of\nthe image scene. As we experimentally show, the proposed construction not only\noutperforms recent CBM approaches, but also yields a principled framework\ntowards interpetability.\n","authors":["Konstantinos P. Panousis","Dino Ienco","Diego Marcos"],"pdf_url":"https://arxiv.org/pdf/2310.02116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19280v1","updated":"2024-06-27T15:50:41Z","published":"2024-06-27T15:50:41Z","title":"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into\n  Multimodal LLMs at Scale","summary":"  The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.\n","authors":["Junying Chen","Ruyi Ouyang","Anningzhe Gao","Shunian Chen","Guiming Hardy Chen","Xidong Wang","Ruifei Zhang","Zhenyang Cai","Ke Ji","Guangjun Yu","Xiang Wan","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06530v3","updated":"2024-06-27T15:39:12Z","published":"2024-02-09T16:41:50Z","title":"Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite\n  Kernel Strategy in One-Class Classification","summary":"  Early detection of myocardial infarction (MI), a critical condition arising\nfrom coronary artery disease (CAD), is vital to prevent further myocardial\ndamage. This study introduces a novel method for early MI detection using a\none-class classification (OCC) algorithm in echocardiography. Our study\novercomes the challenge of limited echocardiography data availability by\nadopting a novel approach based on Multi-modal Subspace Support Vector Data\nDescription. The proposed technique involves a specialized MI detection\nframework employing multi-view echocardiography incorporating a composite\nkernel in the non-linear projection trick, fusing Gaussian and Laplacian\nsigmoid functions. Additionally, we enhance the update strategy of the\nprojection matrices by adapting maximization for both or one of the modalities\nin the optimization process. Our method boosts MI detection capability by\nefficiently transforming features extracted from echocardiography data into an\noptimized lower-dimensional subspace. The OCC model trained specifically on\ntarget class instances from the comprehensive HMC-QU dataset that includes\nmultiple echocardiography views indicates a marked improvement in MI detection\naccuracy. Our findings reveal that our proposed multi-view approach achieves a\ngeometric mean of 71.24%, signifying a substantial advancement in\nechocardiography-based MI diagnosis and offering more precise and efficient\ndiagnostic tools.\n","authors":["Muhammad Uzair Zahid","Aysen Degerli","Fahad Sohrab","Serkan Kiranyaz","Tahir Hamid","Rashid Mazhar","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2402.06530v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19272v1","updated":"2024-06-27T15:38:37Z","published":"2024-06-27T15:38:37Z","title":"Stochastic Concept Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.\n","authors":["Moritz Vandenhirtz","Sonia Laguna","Ričards Marcinkevičs","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2406.19272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19258v1","updated":"2024-06-27T15:29:47Z","published":"2024-06-27T15:29:47Z","title":"Leveraging Contrastive Learning for Enhanced Node Representations in\n  Tokenized Graph Transformers","summary":"  While tokenized graph Transformers have demonstrated strong performance in\nnode classification tasks, their reliance on a limited subset of nodes with\nhigh similarity scores for constructing token sequences overlooks valuable\ninformation from other nodes, hindering their ability to fully harness graph\ninformation for learning optimal node representations. To address this\nlimitation, we propose a novel graph Transformer called GCFormer. Unlike\nprevious approaches, GCFormer develops a hybrid token generator to create two\ntypes of token sequences, positive and negative, to capture diverse graph\ninformation. And a tailored Transformer-based backbone is adopted to learn\nmeaningful node representations from these generated token sequences.\nAdditionally, GCFormer introduces contrastive learning to extract valuable\ninformation from both positive and negative token sequences, enhancing the\nquality of learned node representations. Extensive experimental results across\nvarious datasets, including homophily and heterophily graphs, demonstrate the\nsuperiority of GCFormer in node classification, when compared to representative\ngraph neural networks (GNNs) and graph Transformers.\n","authors":["Jinsong Chen","Hanpeng Liu","John E. Hopcroft","Kun He"],"pdf_url":"https://arxiv.org/pdf/2406.19258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06748v2","updated":"2024-06-27T15:24:23Z","published":"2024-03-11T14:14:52Z","title":"Shortcut Learning in Medical Image Segmentation","summary":"  Shortcut learning is a phenomenon where machine learning models prioritize\nlearning simple, potentially misleading cues from data that do not generalize\nwell beyond the training set. While existing research primarily investigates\nthis in the realm of image classification, this study extends the exploration\nof shortcut learning into medical image segmentation. We demonstrate that\nclinical annotations such as calipers, and the combination of zero-padded\nconvolutions and center-cropped training sets in the dataset can inadvertently\nserve as shortcuts, impacting segmentation accuracy. We identify and evaluate\nthe shortcut learning on two different but common medical image segmentation\ntasks. In addition, we suggest strategies to mitigate the influence of shortcut\nlearning and improve the generalizability of the segmentation models. By\nuncovering the presence and implications of shortcuts in medical image\nsegmentation, we provide insights and methodologies for evaluating and\novercoming this pervasive challenge and call for attention in the community for\nshortcuts in segmentation. Our code is public at\nhttps://github.com/nina-weng/shortcut_skinseg .\n","authors":["Manxi Lin","Nina Weng","Kamil Mikolaj","Zahra Bashir","Morten Bo Søndergaard Svendsen","Martin Tolsgaard","Anders Nymark Christensen","Aasa Feragen"],"pdf_url":"https://arxiv.org/pdf/2403.06748v2.pdf","comment":"11 pages, 6 figures, accepted at MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.19253v1","updated":"2024-06-27T15:22:21Z","published":"2024-06-27T15:22:21Z","title":"Advection Augmented Convolutional Neural Networks","summary":"  Many problems in physical sciences are characterized by the prediction of\nspace-time sequences. Such problems range from weather prediction to the\nanalysis of disease propagation and video prediction. Modern techniques for the\nsolution of these problems typically combine Convolution Neural Networks (CNN)\narchitecture with a time prediction mechanism. However, oftentimes, such\napproaches underperform in the long-range propagation of information and lack\nexplainability. In this work, we introduce a physically inspired architecture\nfor the solution of such problems. Namely, we propose to augment CNNs with\nadvection by designing a novel semi-Lagrangian push operator. We show that the\nproposed operator allows for the non-local transformation of information\ncompared with standard convolutional kernels. We then complement it with\nReaction and Diffusion neural components to form a network that mimics the\nReaction-Advection-Diffusion equation, in high dimensions. We demonstrate the\neffectiveness of our network on a number of spatio-temporal datasets that show\ntheir merit.\n","authors":["Niloufar Zakariaei","Siddharth Rout","Eldad Haber","Moshe Eliasof"],"pdf_url":"https://arxiv.org/pdf/2406.19253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19249v1","updated":"2024-06-27T15:16:00Z","published":"2024-06-27T15:16:00Z","title":"NTFormer: A Composite Node Tokenized Graph Transformer for Node\n  Classification","summary":"  Recently, the emerging graph Transformers have made significant advancements\nfor node classification on graphs. In most graph Transformers, a crucial step\ninvolves transforming the input graph into token sequences as the model input,\nenabling Transformer to effectively learn the node representations. However, we\nobserve that existing methods only express partial graph information of nodes\nthrough single-type token generation. Consequently, they require tailored\nstrategies to encode additional graph-specific features into the Transformer to\nensure the quality of node representation learning, limiting the model\nflexibility to handle diverse graphs. To this end, we propose a new graph\nTransformer called NTFormer to address this issue. NTFormer introduces a novel\ntoken generator called Node2Par, which constructs various token sequences using\ndifferent token elements for each node. This flexibility allows Node2Par to\ngenerate valuable token sequences from different perspectives, ensuring\ncomprehensive expression of rich graph features. Benefiting from the merits of\nNode2Par, NTFormer only leverages a Transformer-based backbone without\ngraph-specific modifications to learn node representations, eliminating the\nneed for graph-specific modifications. Extensive experiments conducted on\nvarious benchmark datasets containing homophily and heterophily graphs with\ndifferent scales demonstrate the superiority of NTFormer over representative\ngraph Transformers and graph neural networks for node classification.\n","authors":["Jinsong Chen","Siyu Jiang","Kun He"],"pdf_url":"https://arxiv.org/pdf/2406.19249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10263v2","updated":"2024-06-27T15:11:45Z","published":"2023-11-17T01:14:24Z","title":"Stable Differentiable Causal Discovery","summary":"  Inferring causal relationships as directed acyclic graphs (DAGs) is an\nimportant but challenging problem. Differentiable Causal Discovery (DCD) is a\npromising approach to this problem, framing the search as a continuous\noptimization. But existing DCD methods are numerically unstable, with poor\nperformance beyond tens of variables. In this paper, we propose Stable\nDifferentiable Causal Discovery (SDCD), a new method that improves previous DCD\nmethods in two ways: (1) It employs an alternative constraint for acyclicity;\nthis constraint is more stable, both theoretically and empirically, and fast to\ncompute. (2) It uses a training procedure tailored for sparse causal graphs,\nwhich are common in real-world scenarios. We first derive SDCD and prove its\nstability and correctness. We then evaluate it with both observational and\ninterventional data and on both small-scale and large-scale settings. We find\nthat SDCD outperforms existing methods in both convergence speed and accuracy\nand can scale to thousands of variables. We provide code at\nhttps://github.com/azizilab/sdcd.\n","authors":["Achille Nazaret","Justin Hong","Elham Azizi","David Blei"],"pdf_url":"https://arxiv.org/pdf/2311.10263v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19244v1","updated":"2024-06-27T15:10:56Z","published":"2024-06-27T15:10:56Z","title":"Improving the Expressiveness of $K$-hop Message-Passing GNNs by\n  Injecting Contextualized Substructure Information","summary":"  Graph neural networks (GNNs) have become the \\textit{de facto} standard for\nrepresentational learning in graphs, and have achieved state-of-the-art\nperformance in many graph-related tasks; however, it has been shown that the\nexpressive power of standard GNNs are equivalent maximally to 1-dimensional\nWeisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to\nenhance the expressive power of graph neural networks. One line of such works\naim at developing $K$-hop message-passing GNNs where node representation is\nupdated by aggregating information from not only direct neighbors but all\nneighbors within $K$-hop of the node. Another line of works leverages subgraph\ninformation to enhance the expressive power which is proven to be strictly more\npowerful than 1-WL test. In this work, we discuss the limitation of $K$-hop\nmessage-passing GNNs and propose \\textit{substructure encoding function} to\nuplift the expressive power of any $K$-hop message-passing GNN. We further\ninject contextualized substructure information to enhance the expressiveness of\n$K$-hop message-passing GNNs. Our method is provably more powerful than\nprevious works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which\nis a specific type of subgraph based GNN models, and not less powerful than\n3-WL. Empirically, our proposed method set new state-of-the-art performance or\nachieves comparable performance for a variety of datasets. Our code is\navailable at \\url{https://github.com/tianyao-aka/Expresive_K_hop_GNNs}.\n","authors":["Tianjun Yao","Yiongxu Wang","Kun Zhang","Shangsong Liang"],"pdf_url":"https://arxiv.org/pdf/2406.19244v1.pdf","comment":"13 pages, published in Research track of KDD2023"},{"id":"http://arxiv.org/abs/2405.01656v2","updated":"2024-06-27T15:07:39Z","published":"2024-05-02T18:26:15Z","title":"S4: Self-Supervised Sensing Across the Spectrum","summary":"  Satellite image time series (SITS) segmentation is crucial for many\napplications like environmental monitoring, land cover mapping and agricultural\ncrop type classification. However, training models for SITS segmentation\nremains a challenging task due to the lack of abundant training data, which\nrequires fine grained annotation. We propose S4 a new self-supervised\npre-training approach that significantly reduces the requirement for labeled\ntraining data by utilizing two new insights: (a) Satellites capture images in\ndifferent parts of the spectrum such as radio frequencies, and visible\nfrequencies. (b) Satellite imagery is geo-registered allowing for fine-grained\nspatial alignment. We use these insights to formulate pre-training tasks in S4.\nWe also curate m2s2-SITS, a large-scale dataset of unlabeled,\nspatially-aligned, multi-modal and geographic specific SITS that serves as\nrepresentative pre-training data for S4. Finally, we evaluate S4 on multiple\nSITS segmentation datasets and demonstrate its efficacy against competing\nbaselines while using limited labeled data.\n","authors":["Jayanth Shenoy","Xingjian Davis Zhang","Shlok Mehrotra","Bill Tao","Rem Yang","Han Zhao","Deepak Vasisht"],"pdf_url":"https://arxiv.org/pdf/2405.01656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03072v2","updated":"2024-06-27T15:05:17Z","published":"2024-06-05T08:57:41Z","title":"Local to Global: Learning Dynamics and Effect of Initialization for\n  Transformers","summary":"  In recent years, transformer-based models have revolutionized deep learning,\nparticularly in sequence modeling. To better understand this phenomenon, there\nis a growing interest in using Markov input processes to study transformers.\nHowever, our current understanding in this regard remains limited with many\nfundamental questions about how transformers learn Markov chains still\nunanswered. In this paper, we address this by focusing on first-order Markov\nchains and single-layer transformers, providing a comprehensive\ncharacterization of the learning dynamics in this context. Specifically, we\nprove that transformer parameters trained on next-token prediction loss can\neither converge to global or local minima, contingent on the initialization and\nthe Markovian data properties, and we characterize the precise conditions under\nwhich this occurs. To the best of our knowledge, this is the first result of\nits kind highlighting the role of initialization. We further demonstrate that\nour theoretical findings are corroborated by empirical evidence. Based on these\ninsights, we provide guidelines for the initialization of transformer\nparameters and demonstrate their effectiveness. Finally, we outline several\nopen problems in this arena. Code is available at:\nhttps://github.com/Bond1995/Markov.\n","authors":["Ashok Vardhan Makkuva","Marco Bondaschi","Chanakya Ekbote","Adway Girish","Alliot Nagle","Hyeji Kim","Michael Gastpar"],"pdf_url":"https://arxiv.org/pdf/2406.03072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19238v1","updated":"2024-06-27T15:01:53Z","published":"2024-06-27T15:01:53Z","title":"Revealing Fine-Grained Values and Opinions in Large Language Models","summary":"  Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.\n","authors":["Dustin Wright","Arnav Arora","Nadav Borenstein","Srishti Yadav","Serge Belongie","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2406.19238v1.pdf","comment":"28 pages, 20 figures, 7 tables"},{"id":"http://arxiv.org/abs/2406.19237v1","updated":"2024-06-27T15:01:48Z","published":"2024-06-27T15:01:48Z","title":"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with\n  Flowcharts","summary":"  Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.\n","authors":["Shubhankar Singh","Purvi Chaurasia","Yerram Varun","Pranshu Pandya","Vatsal Gupta","Vivek Gupta","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2406.19237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19228v1","updated":"2024-06-27T14:52:34Z","published":"2024-06-27T14:52:34Z","title":"Tools Fail: Detecting Silent Errors in Faulty Tools","summary":"  Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not\nin their weights, to perform tasks on the web, and even to control robots.\nHowever, most ontologies and surveys of tool-use have assumed the core\nchallenge for LLMs is choosing the tool. Instead, we introduce a framework for\ntools more broadly which guides us to explore a model's ability to detect\n\"silent\" tool errors, and reflect on how to plan. This more directly aligns\nwith the increasingly popular use of models as tools. We provide an initial\napproach to failure recovery with promising results both on a controlled\ncalculator setting and embodied agent planning.\n","authors":["Jimin Sun","So Yeon Min","Yingshan Chang","Yonatan Bisk"],"pdf_url":"https://arxiv.org/pdf/2406.19228v1.pdf","comment":"18 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19223v1","updated":"2024-06-27T14:49:08Z","published":"2024-06-27T14:49:08Z","title":"T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for\n  Memory-Efficient Embeddings","summary":"  Tokenizers are crucial for encoding information in Large Language Models, but\ntheir development has recently stagnated, and they contain inherent weaknesses.\nMajor limitations include computational overhead, ineffective vocabulary use,\nand unnecessarily large embedding and head layers. Additionally, their\nperformance is biased towards a reference corpus, leading to reduced\neffectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words\nthrough sparse activation patterns over character triplets, and does not\nrequire a reference corpus. T-FREE inherently exploits morphological\nsimilarities and allows for strong compression of embedding layers. In our\nexhaustive experimental evaluation, we achieve competitive downstream\nperformance with a parameter reduction of more than 85% on these layers.\nFurther, T-FREE shows significant improvements in cross-lingual transfer\nlearning.\n","authors":["Björn Deiseroth","Manuel Brack","Patrick Schramowski","Kristian Kersting","Samuel Weinbach"],"pdf_url":"https://arxiv.org/pdf/2406.19223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03228v2","updated":"2024-06-27T14:30:18Z","published":"2023-02-07T03:21:55Z","title":"Heterophily-Aware Graph Attention Network","summary":"  Graph Neural Networks (GNNs) have shown remarkable success in graph\nrepresentation learning. Unfortunately, current weight assignment schemes in\nstandard GNNs, such as the calculation based on node degrees or pair-wise\nrepresentations, can hardly be effective in processing the networks with\nheterophily, in which the connected nodes usually possess different labels or\nfeatures. Existing heterophilic GNNs tend to ignore the modeling of heterophily\nof each edge, which is also a vital part in tackling the heterophily problem.\nIn this paper, we firstly propose a heterophily-aware attention scheme and\nreveal the benefits of modeling the edge heterophily, i.e., if a GNN assigns\ndifferent weights to edges according to different heterophilic types, it can\nlearn effective local attention patterns, which enable nodes to acquire\nappropriate information from distinct neighbors. Then, we propose a novel\nHeterophily-Aware Graph Attention Network (HA-GAT) by fully exploring and\nutilizing the local distribution as the underlying heterophily, to handle the\nnetworks with different homophily ratios. To demonstrate the effectiveness of\nthe proposed HA-GAT, we analyze the proposed heterophily-aware attention scheme\nand local distribution exploration, by seeking for an interpretation from their\nmechanism. Extensive results demonstrate that our HA-GAT achieves\nstate-of-the-art performances on eight datasets with different homophily ratios\nin both the supervised and semi-supervised node classification tasks.\n","authors":["Junfu Wang","Yuanfang Guo","Liang Yang","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06196v2","updated":"2024-06-27T14:19:56Z","published":"2024-05-10T02:23:56Z","title":"VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with\n  Lightweight Blocks","summary":"  Foundation Vision-Language Models (VLMs) trained using large-scale\nopen-domain images and text pairs have recently been adapted to develop\nVision-Language Segmentation Models (VLSMs) that allow providing text prompts\nduring inference to guide image segmentation. If robust and powerful VLSMs can\nbe built for medical images, it could aid medical professionals in many\nclinical tasks where they must spend substantial time delineating the target\nstructure of interest. VLSMs for medical images resort to fine-tuning base VLM\nor VLSM pretrained on open-domain natural image datasets due to fewer annotated\nmedical image datasets; this fine-tuning is resource-consuming and expensive as\nit usually requires updating all or a significant fraction of the pretrained\nparameters. Recently, lightweight blocks called adapters have been proposed in\nVLMs that keep the pretrained model frozen and only train adapters during\nfine-tuning, substantially reducing the computing resources required. We\nintroduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained\nvision-language segmentation models using transformer encoders. Our experiments\nin widely used CLIP-based segmentation models show that with only 3 million\ntrainable parameters, the VLSM-Adapter outperforms state-of-the-art and is\ncomparable to the upper bound end-to-end fine-tuning. The source code is\navailable at: https://github.com/naamiinepal/vlsm-adapter.\n","authors":["Manish Dhakal","Rabin Adhikari","Safal Thapaliya","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2405.06196v2.pdf","comment":"Accepted at MICCAI 2024, the 27th International Conference on Medical\n  Image Computing and Computer Assisted Intervention"},{"id":"http://arxiv.org/abs/2406.19195v1","updated":"2024-06-27T14:13:46Z","published":"2024-06-27T14:13:46Z","title":"Estimating Long-term Heterogeneous Dose-response Curve: Generalization\n  Bound Leveraging Optimal Transport Weights","summary":"  Long-term causal effect estimation is a significant but challenging problem\nin many applications. Existing methods rely on ideal assumptions to estimate\nlong-term average effects, e.g., no unobserved confounders or a binary\ntreatment,while in numerous real-world applications, these assumptions could be\nviolated and average effects are unable to provide individual-level\nsuggestions.In this paper,we address a more general problem of estimating the\nlong-term heterogeneous dose-response curve (HDRC) while accounting for\nunobserved confounders. Specifically, to remove unobserved confounding in\nobservational data, we introduce an optimal transport weighting framework to\nalign the observational data to the experimental data with theoretical\nguarantees. Furthermore,to accurately predict the heterogeneous effects of\ncontinuous treatment, we establish a generalization bound on counterfactual\nprediction error by leveraging the reweighted distribution induced by optimal\ntransport. Finally, we develop an HDRC estimator building upon the above\ntheoretical foundations. Extensive experimental studies conducted on multiple\nsynthetic and semi-synthetic datasets demonstrate the effectiveness of our\nproposed method.\n","authors":["Zeqin Yang","Weilin Chen","Ruichu Cai","Yuguang Yan","Zhifeng Hao","Zhipeng Yu","Zhichao Zou","Zhen Peng","Jiecheng Guo"],"pdf_url":"https://arxiv.org/pdf/2406.19195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19189v1","updated":"2024-06-27T14:09:10Z","published":"2024-06-27T14:09:10Z","title":"BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy\n  Monitoring","summary":"  This study presents a novel approach for EEG-based seizure detection\nleveraging a BERT-based model. The model, BENDR, undergoes a two-phase training\nprocess. Initially, it is pre-trained on the extensive Temple University\nHospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,\nto extract common EEG data patterns. Subsequently, the model is fine-tuned on\nthe CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24\npediatric patients, of which 198 contain seizure events. Key contributions\ninclude optimizing fine-tuning on the CHB-MIT dataset, where the impact of\nmodel architecture, pre-processing, and post-processing techniques are\nthoroughly examined to enhance sensitivity and reduce false positives per hour\n(FP/h). We also explored custom training strategies to ascertain the most\neffective setup. The model undergoes a novel second pre-training phase before\nsubject-specific fine-tuning, enhancing its generalization capabilities. The\noptimized model demonstrates substantial performance enhancements, achieving as\nlow as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but\nstill acceptable sensitivity rate, showcasing the effectiveness of applying a\nBERT-based approach on EEG-based seizure detection.\n","authors":["Luca Benfenati","Thorir Mar Ingolfsson","Andrea Cossettini","Daniele Jahier Pagliari","Alessio Burrello","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2406.19189v1.pdf","comment":"4 pages, 2 tables, 2 figures"},{"id":"http://arxiv.org/abs/2406.19188v1","updated":"2024-06-27T14:07:38Z","published":"2024-06-27T14:07:38Z","title":"Averaging log-likelihoods in direct alignment","summary":"  To better align Large Language Models (LLMs) with human judgment,\nReinforcement Learning from Human Feedback (RLHF) learns a reward model and\nthen optimizes it using regularized RL. Recently, direct alignment methods were\nintroduced to learn such a fine-tuned model directly from a preference dataset\nwithout computing a proxy reward function. These methods are built upon\ncontrastive losses involving the log-likelihood of (dis)preferred completions\naccording to the trained model. However, completions have various lengths, and\nthe log-likelihood is not length-invariant. On the other side, the\ncross-entropy loss used in supervised training is length-invariant, as batches\nare typically averaged token-wise. To reconcile these approaches, we introduce\na principled approach for making direct alignment length-invariant. Formally,\nwe introduce a new averaging operator, to be composed with the optimality\noperator giving the best policy for the underlying RL problem. It translates\ninto averaging the log-likelihood within the loss. We empirically study the\neffect of such averaging, observing a trade-off between the length of\ngenerations and their scores.\n","authors":["Nathan Grinsztajn","Yannis Flet-Berliac","Mohammad Gheshlaghi Azar","Florian Strub","Bill Wu","Eugene Choi","Chris Cremer","Arash Ahmadian","Yash Chandak","Olivier Pietquin","Matthieu Geist"],"pdf_url":"https://arxiv.org/pdf/2406.19188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10898v3","updated":"2024-06-27T14:04:51Z","published":"2024-02-16T18:56:41Z","title":"The Price of Adaptivity in Stochastic Convex Optimization","summary":"  We prove impossibility results for adaptivity in non-smooth stochastic convex\noptimization. Given a set of problem parameters we wish to adapt to, we define\na \"price of adaptivity\" (PoA) that, roughly speaking, measures the\nmultiplicative increase in suboptimality due to uncertainty in these\nparameters. When the initial distance to the optimum is unknown but a gradient\nnorm bound is known, we show that the PoA is at least logarithmic for expected\nsuboptimality, and double-logarithmic for median suboptimality. When there is\nuncertainty in both distance and gradient norm, we show that the PoA must be\npolynomial in the level of uncertainty. Our lower bounds nearly match existing\nupper bounds, and establish that there is no parameter-free lunch.\n  En route, we also establish tight upper and lower bounds for\n(known-parameter) high-probability stochastic convex optimization with\nheavy-tailed and bounded noise, respectively.\n","authors":["Yair Carmon","Oliver Hinder"],"pdf_url":"https://arxiv.org/pdf/2402.10898v3.pdf","comment":"Accepted for presentation at the Conference on Learning Theory (COLT)\n  2024; to appear in proceedings as an extended abstract"},{"id":"http://arxiv.org/abs/2406.19185v1","updated":"2024-06-27T14:03:49Z","published":"2024-06-27T14:03:49Z","title":"Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a\n  supervised-friendly fashion","summary":"  Reinforcement Learning (RL) has been used to finetune Large Language Models\n(LLMs) using a reward model trained from preference data, to better align with\nhuman judgment. The recently introduced direct alignment methods, which are\noften simpler, more stable, and computationally lighter, can more directly\nachieve this. However, these approaches cannot optimize arbitrary rewards, and\nthe preference-based ones are not the only rewards of interest for LLMs (eg.,\nunit tests for code generation or textual entailment for summarization, among\nothers). RL-finetuning is usually done with a variation of policy gradient,\nwhich calls for on-policy or near-on-policy samples, requiring costly\ngenerations. We introduce Contrastive Policy Gradient, or CoPG, a simple and\nmathematically principled new RL algorithm that can estimate the optimal policy\neven from off-policy data. It can be seen as an off-policy policy gradient\napproach that does not rely on important sampling techniques and highlights the\nimportance of using (the right) state baseline. We show this approach to\ngeneralize the direct alignment method IPO (identity preference optimization)\nand classic policy gradient. We experiment with the proposed CoPG on a toy\nbandit problem to illustrate its properties, as well as for finetuning LLMs on\na summarization task, using a learned reward function considered as ground\ntruth for the purpose of the experiments.\n","authors":["Yannis Flet-Berliac","Nathan Grinsztajn","Florian Strub","Eugene Choi","Chris Cremer","Arash Ahmadian","Yash Chandak","Mohammad Gheshlaghi Azar","Olivier Pietquin","Matthieu Geist"],"pdf_url":"https://arxiv.org/pdf/2406.19185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19175v1","updated":"2024-06-27T13:51:53Z","published":"2024-06-27T13:51:53Z","title":"Towards Reducing Data Acquisition and Labeling for Defect Detection\n  using Simulated Data","summary":"  In many manufacturing settings, annotating data for machine learning and\ncomputer vision is costly, but synthetic data can be generated at significantly\nlower cost. Substituting the real-world data with synthetic data is therefore\nappealing for many machine learning applications that require large amounts of\ntraining data. However, relying solely on synthetic data is frequently\ninadequate for effectively training models that perform well on real-world\ndata, primarily due to domain shifts between the synthetic and real-world data.\nWe discuss approaches for dealing with such a domain shift when detecting\ndefects in X-ray scans of aluminium wheels. Using both simulated and real-world\nX-ray images, we train an object detection model with different strategies to\nidentify the training approach that generates the best detection results while\nminimising the demand for annotated real-world training samples. Our\npreliminary findings suggest that the sim-2-real domain adaptation approach is\nmore cost-efficient than a fully supervised oracle - if the total number of\navailable annotated samples is fixed. Given a certain number of labeled\nreal-world samples, training on a mix of synthetic and unlabeled real-world\ndata achieved comparable or even better detection results at significantly\nlower cost. We argue that future research into the cost-efficiency of different\ntraining strategies is important for a better understanding of how to allocate\nbudget in applied machine learning projects.\n","authors":["Lukas Malte Kemeter","Rasmus Hvingelby","Paulina Sierak","Tobias Schön","Bishwajit Gosswam"],"pdf_url":"https://arxiv.org/pdf/2406.19175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14574v2","updated":"2024-06-27T13:29:07Z","published":"2023-12-22T10:10:50Z","title":"MMGPL: Multimodal Medical Data Analysis with Graph Prompt Learning","summary":"  Prompt learning has demonstrated impressive efficacy in the fine-tuning of\nmultimodal large models to a wide range of downstream tasks. Nonetheless,\napplying existing prompt learning methods for the diagnosis of neurological\ndisorder still suffers from two issues: (i) existing methods typically treat\nall patches equally, despite the fact that only a small number of patches in\nneuroimaging are relevant to the disease, and (ii) they ignore the structural\ninformation inherent in the brain connection network which is crucial for\nunderstanding and diagnosing neurological disorders. To tackle these issues, we\nintroduce a novel prompt learning model by learning graph prompts during the\nfine-tuning process of multimodal large models for diagnosing neurological\ndisorders. Specifically, we first leverage GPT-4 to obtain relevant disease\nconcepts and compute semantic similarity between these concepts and all\npatches. Secondly, we reduce the weight of irrelevant patches according to the\nsemantic similarity between each patch and disease-related concepts. Moreover,\nwe construct a graph among tokens based on these concepts and employ a graph\nconvolutional network layer to extract the structural information of the graph,\nwhich is used to prompt the pre-trained multimodal large models for diagnosing\nneurological disorders. Extensive experiments demonstrate that our method\nachieves superior performance for neurological disorder diagnosis compared with\nstate-of-the-art methods and validated by clinicians.\n","authors":["Liang Peng","Songyue Cai","Zongqian Wu","Huifang Shang","Xiaofeng Zhu","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2312.14574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19156v1","updated":"2024-06-27T13:17:33Z","published":"2024-06-27T13:17:33Z","title":"Heterogeneous Causal Metapath Graph Neural Network for\n  Gene-Microbe-Disease Association Prediction","summary":"  The recent focus on microbes in human medicine highlights their potential\nrole in the genetic framework of diseases. To decode the complex interactions\namong genes, microbes, and diseases, computational predictions of\ngene-microbe-disease (GMD) associations are crucial. Existing methods primarily\naddress gene-disease and microbe-disease associations, but the more intricate\ntriple-wise GMD associations remain less explored. In this paper, we propose a\nHeterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD\nassociations. HCMGNN constructs a heterogeneous graph linking genes, microbes,\nand diseases through their pairwise associations, and utilizes six predefined\ncausal metapaths to extract directed causal subgraphs, which facilitate the\nmulti-view analysis of causal relations among three entity types. Within each\nsubgraph, we employ a causal semantic sharing message passing network for node\nrepresentation learning, coupled with an attentive fusion method to integrate\nthese representations for predicting GMD associations. Our extensive\nexperiments show that HCMGNN effectively predicts GMD associations and\naddresses association sparsity issue by enhancing the graph's semantics and\nstructure.\n","authors":["Kexin Zhang","Feng Huang","Luotao Liu","Zhankun Xiong","Hongyu Zhang","Yuan Quan","Wen Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19154v1","updated":"2024-06-27T13:14:20Z","published":"2024-06-27T13:14:20Z","title":"Advancing operational PM2.5 forecasting with dual deep neural networks\n  (D-DNet)","summary":"  PM2.5 forecasting is crucial for public health, air quality management, and\npolicy development. Traditional physics-based models are computationally\ndemanding and slow to adapt to real-time conditions. Deep learning models show\npotential in efficiency but still suffer from accuracy loss over time due to\nerror accumulation. To address these challenges, we propose a dual deep neural\nnetwork (D-DNet) prediction and data assimilation system that efficiently\nintegrates real-time observations, ensuring reliable operational forecasting.\nD-DNet excels in global operational forecasting for PM2.5 and AOD550,\nmaintaining consistent accuracy throughout the entire year of 2019. It\ndemonstrates notably higher efficiency than the Copernicus Atmosphere\nMonitoring Service (CAMS) 4D-Var operational forecasting system while\nmaintaining comparable accuracy. This efficiency benefits ensemble forecasting,\nuncertainty analysis, and large-scale tasks.\n","authors":["Shengjuan Cai","Fangxin Fang","Vincent-Henri Peuch","Mihai Alexe","Ionel Michael Navon","Yanghua Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12223v3","updated":"2024-06-27T13:13:11Z","published":"2023-12-19T15:11:46Z","title":"Self-Supervised Detection of Perfect and Partial Input-Dependent\n  Symmetries","summary":"  Group equivariance can overly constrain models if the symmetries in the group\ndiffer from those observed in data. While common methods address this by\ndetermining the appropriate level of symmetry at the dataset level, they are\nlimited to supervised settings and ignore scenarios in which multiple levels of\nsymmetry co-exist in the same dataset. In this paper, we propose a method able\nto detect the level of symmetry of each input without the need for labels. Our\nframework is general enough to accommodate different families of both\ncontinuous and discrete symmetry distributions, such as arbitrary unimodal,\nsymmetric distributions and discrete groups. We validate the effectiveness of\nour approach on synthetic datasets with different per-class levels of\nsymmetries, and demonstrate practical applications such as the detection of\nout-of-distribution symmetries. Our code is publicly available at\nhttps://github.com/aurban0/ssl-sym.\n","authors":["Alonso Urbano","David W. Romero"],"pdf_url":"https://arxiv.org/pdf/2312.12223v3.pdf","comment":"19 pages, 8 figures, corrected typos, revised argument in Appendix\n  B.1, results unchanged"},{"id":"http://arxiv.org/abs/2406.19146v1","updated":"2024-06-27T13:02:43Z","published":"2024-06-27T13:02:43Z","title":"Resolving Discrepancies in Compute-Optimal Scaling of Language Models","summary":"  Kaplan et al. and Hoffmann et al. developed influential scaling laws for the\noptimal model size as a function of the compute budget, but these laws yield\nsubstantially different predictions. We explain the discrepancy by reproducing\nthe Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and\nidentifying three factors causing the difference: last layer computational\ncost, warmup duration, and scale-dependent optimizer tuning. With these factors\ncorrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,\n\"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find\nthat careful learning rate decay is not essential for the validity of their\nscaling law. As a secondary result, we derive scaling laws for the optimal\nlearning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter\nis essential at lower batch sizes.\n","authors":["Tomer Porian","Mitchell Wortsman","Jenia Jitsev","Ludwig Schmidt","Yair Carmon"],"pdf_url":"https://arxiv.org/pdf/2406.19146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07100v2","updated":"2024-06-27T13:00:34Z","published":"2024-06-11T09:42:03Z","title":"D-GRIL: End-to-End Topological Learning with 2-parameter Persistence","summary":"  End-to-end topological learning using 1-parameter persistence is well-known.\nWe show that the framework can be enhanced using 2-parameter persistence by\nadopting a recently introduced 2-parameter persistence based vectorization\ntechnique called GRIL. We establish a theoretical foundation of differentiating\nGRIL producing D-GRIL. We show that D-GRIL can be used to learn a bifiltration\nfunction on standard benchmark graph datasets. Further, we exhibit that this\nframework can be applied in the context of bio-activity prediction in drug\ndiscovery.\n","authors":["Soham Mukherjee","Shreyas N. Samaga","Cheng Xin","Steve Oudot","Tamal K. Dey"],"pdf_url":"https://arxiv.org/pdf/2406.07100v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03069v2","updated":"2024-06-27T12:51:41Z","published":"2024-03-05T15:57:52Z","title":"Improving Variational Autoencoder Estimation from Incomplete Data with\n  Mixture Variational Families","summary":"  We consider the task of estimating variational autoencoders (VAEs) when the\ntraining data is incomplete. We show that missing data increases the complexity\nof the model's posterior distribution over the latent variables compared to the\nfully-observed case. The increased complexity may adversely affect the fit of\nthe model due to a mismatch between the variational and model posterior\ndistributions. We introduce two strategies based on (i) finite\nvariational-mixture and (ii) imputation-based variational-mixture distributions\nto address the increased posterior complexity. Through a comprehensive\nevaluation of the proposed approaches, we show that variational mixtures are\neffective at improving the accuracy of VAE estimation from incomplete data.\n","authors":["Vaidotas Simkus","Michael U. Gutmann"],"pdf_url":"https://arxiv.org/pdf/2403.03069v2.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR), 2024"},{"id":"http://arxiv.org/abs/2406.08756v2","updated":"2024-06-27T12:45:38Z","published":"2024-06-13T02:31:36Z","title":"Optimizing Large Model Training through Overlapped Activation\n  Recomputation","summary":"  Large model training has been using recomputation to alleviate the memory\npressure and pipelining to exploit the parallelism of data, tensor, and\ndevices. The existing recomputation approaches may incur up to 40% overhead\nwhen training real-world models, e.g., the GPT model with 22B parameters. This\nis because they are executed on demand in the critical training path. In this\npaper, we design a new recomputation framework, Lynx, to reduce the overhead by\noverlapping the recomputation with communication occurring in training\npipelines. It consists of an optimal scheduling algorithm (OPT) and a\nheuristic-based scheduling algorithm (HEU). OPT achieves a global optimum but\nsuffers from a long search time. HEU was designed based on our observation that\nthere are identical structures in large DNN models so that we can apply the\nsame scheduling policy to all identical structures. HEU achieves a local\noptimum but reduces the search time by 99% compared to OPT. Our comprehensive\nevaluation using GPT models with 1.3B-20B parameters shows that both OPT and\nHEU outperform the state-of-the-art recomputation approaches (e.g., Megatron-LM\nand Checkmake) by 1.02-1.53x. HEU achieves a similar performance as OPT with a\nsearch time of 0.16s on average.\n","authors":["Ping Chen","Wenjie Zhang","Shuibing He","Yingjie Gu","Zhuwei Peng","Kexin Huang","Xuan Zhan","Weijian Chen","Yi Zheng","Zhefeng Wang","Yanlong Yin","Gang Chen"],"pdf_url":"https://arxiv.org/pdf/2406.08756v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2406.19136v1","updated":"2024-06-27T12:40:29Z","published":"2024-06-27T12:40:29Z","title":"YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph\n  Convolutional Networks and Transformer-Attention","summary":"  The accurate prediction of drug molecule solubility is essential for\ndetermining their therapeutic effectiveness and safety, influencing the drug's\nADME processes. Traditional solubility prediction techniques often fail to\ncapture the complex nature of molecular tructures, leading to notable\ndeviations between predictions and actual results. For example, the Discussion\non Advanced Drug-Like Compound Structures. Lusci highlighted issues in\ncapturing crucial cyclic structural information in molecules with ring\nstructures. To overcome this issue, our research introduces a novel deep\nlearning framework combining attention-based transformers, Long Short-Term\nMemory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at\nenhancing the precision of solubility predictions. Utilizing a training set of\n9,943 compounds and testing on an anticancer compound dataset, our method\nachieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error\n(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)\nand 0.61 (RMSE). Importantly, in an additional independent test, our model\nsignificantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,\na relative accuracy improvement of 45.9%. This research not only demonstrates\nthe vast potential of deep learning for improving solubility prediction\naccuracy but also offers novel insights for drug design and selection in the\nfuture. Continued efforts will be directed towards optimizing the model\narchitecture and extending its application to better support the drug\ndevelopment process, underscoring the pivotal role of deep learning in drug\ndiscovery.\n","authors":["Chenxu Wang","Haowei Ming","Jian He","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2406.19136v1.pdf","comment":"18 pages, 12 figures, 6 tables"},{"id":"http://arxiv.org/abs/2309.06212v4","updated":"2024-06-27T12:40:01Z","published":"2023-09-12T13:28:06Z","title":"Long-term drought prediction using deep neural networks based on\n  geospatial weather data","summary":"  The problem of high-quality drought forecasting up to a year in advance is\ncritical for agriculture planning and insurance. Yet, it is still unsolved with\nreasonable accuracy due to data complexity and aridity stochasticity. We tackle\ndrought data by introducing an end-to-end approach that adopts a\nspatio-temporal neural network model with accessible open monthly climate data\nas the input.\n  Our systematic research employs diverse proposed models and five distinct\nenvironmental regions as a testbed to evaluate the efficacy of the Palmer\nDrought Severity Index (PDSI) prediction. Key aggregated findings are the\nexceptional performance of a Transformer model, EarthFormer, in making accurate\nshort-term (up to six months) forecasts. At the same time, the Convolutional\nLSTM excels in longer-term forecasting. Both models achieved high ROC AUC\nscores: 0.948 for one month ahead and 0.617 for twelve months ahead forecasts,\nbecoming closer to perfect ROC-AUC by $54\\%$ and $16\\%$, respectively, c.t.\nclassic approaches.\n","authors":["Vsevolod Grabar","Alexander Marusov","Yury Maximov","Nazar Sotiriadi","Alexander Bulkin","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2309.06212v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19121v1","updated":"2024-06-27T12:05:55Z","published":"2024-06-27T12:05:55Z","title":"Towards Learning Abductive Reasoning using VSA Distributed\n  Representations","summary":"  We introduce the Abductive Rule Learner with Context-awareness (ARLC), a\nmodel that solves abstract reasoning tasks based on Learn-VRF. ARLC features a\nnovel and more broadly applicable training objective for abductive reasoning,\nresulting in better interpretability and higher accuracy when solving Raven's\nprogressive matrices (RPM). ARLC allows both programming domain knowledge and\nlearning the rules underlying a data distribution. We evaluate ARLC on the\nI-RAVEN dataset, showcasing state-of-the-art accuracy across both\nin-distribution and out-of-distribution (unseen attribute-rule pairs) tests.\nARLC surpasses neuro-symbolic and connectionist baselines, including large\nlanguage models, despite having orders of magnitude fewer parameters. We show\nARLC's robustness to post-programming training by incrementally learning from\nexamples on top of programmed knowledge, which only improves its performance\nand does not result in catastrophic forgetting of the programmed solution. We\nvalidate ARLC's seamless transfer learning from a 2x2 RPM constellation to\nunseen constellations. Our code is available at\nhttps://github.com/IBM/abductive-rule-learner-with-context-awareness.\n","authors":["Giacomo Camposampiero","Michael Hersche","Aleksandar Terzić","Roger Wattenhofer","Abu Sebastian","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2406.19121v1.pdf","comment":"Accepted at the 18th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2024"},{"id":"http://arxiv.org/abs/2406.19116v1","updated":"2024-06-27T11:53:15Z","published":"2024-06-27T11:53:15Z","title":"CHEW: A Dataset of CHanging Events in Wikipedia","summary":"  We introduce CHEW, a novel dataset of changing events in Wikipedia expressed\nin naturally occurring text. We use CHEW for probing LLMs for their timeline\nunderstanding of Wikipedia entities and events in generative and classification\nexperiments. Our results suggest that LLMs, despite having temporal information\navailable, struggle to construct accurate timelines. We further show the\nusefulness of CHEW-derived embeddings for identifying meaning shift.\n","authors":["Hsuvas Borkakoty","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2406.19116v1.pdf","comment":"Short Paper"},{"id":"http://arxiv.org/abs/2406.19112v1","updated":"2024-06-27T11:48:25Z","published":"2024-06-27T11:48:25Z","title":"A Teacher Is Worth A Million Instructions","summary":"  Large Language Models(LLMs) have shown exceptional abilities, yet training\nthese models can be quite challenging. There is a strong dependence on the\nquality of data and finding the best instruction tuning set. Further, the\ninherent limitations in training methods create substantial difficulties to\ntrain relatively smaller models with 7B and 13B parameters. In our research, we\nsuggest an improved training method for these models by utilising knowledge\nfrom larger models, such as a mixture of experts (8x7B) architectures. The\nscale of these larger models allows them to capture a wide range of variations\nfrom data alone, making them effective teachers for smaller models. Moreover,\nwe implement a novel post-training domain alignment phase that employs\ndomain-specific expert models to boost domain-specific knowledge during\ntraining while preserving the model's ability to generalise. Fine-tuning\nMistral 7B and 2x7B with our method surpasses the performance of\nstate-of-the-art language models with more than 7B and 13B parameters:\nachieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.\n","authors":["Nikhil Kothari","Ravindra Nayak","Shreyas Shetty","Amey Patil","Nikesh Garera"],"pdf_url":"https://arxiv.org/pdf/2406.19112v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.18736v4","updated":"2024-06-27T11:43:10Z","published":"2024-04-29T14:34:43Z","title":"Mapping the Potential of Explainable AI for Fairness Along the AI\n  Lifecycle","summary":"  The widespread use of artificial intelligence (AI) systems across various\ndomains is increasingly surfacing issues related to algorithmic fairness,\nespecially in high-stakes scenarios. Thus, critical considerations of how\nfairness in AI systems might be improved -- and what measures are available to\naid this process -- are overdue. Many researchers and policymakers see\nexplainable AI (XAI) as a promising way to increase fairness in AI systems.\nHowever, there is a wide variety of XAI methods and fairness conceptions\nexpressing different desiderata, and the precise connections between XAI and\nfairness remain largely nebulous. Besides, different measures to increase\nalgorithmic fairness might be applicable at different points throughout an AI\nsystem's lifecycle. Yet, there currently is no coherent mapping of fairness\ndesiderata along the AI lifecycle. In this paper, we we distill eight fairness\ndesiderata, map them along the AI lifecycle, and discuss how XAI could help\naddress each of them. We hope to provide orientation for practical applications\nand to inspire XAI research specifically focused on these fairness desiderata.\n","authors":["Luca Deck","Astrid Schomäcker","Timo Speith","Jakob Schöffer","Lena Kästner","Niklas Kühl"],"pdf_url":"https://arxiv.org/pdf/2404.18736v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15415v2","updated":"2024-06-27T11:35:11Z","published":"2024-03-07T16:17:33Z","title":"Physics-informed and Unsupervised Riemannian Domain Adaptation for\n  Machine Learning on Heterogeneous EEG Datasets","summary":"  Combining electroencephalogram (EEG) datasets for supervised machine learning\n(ML) is challenging due to session, subject, and device variability. ML\nalgorithms typically require identical features at train and test time,\ncomplicating analysis due to varying sensor numbers and positions across\ndatasets. Simple channel selection discards valuable data, leading to poorer\nperformance, especially with datasets sharing few channels. To address this, we\npropose an unsupervised approach leveraging EEG signal physics. We map EEG\nchannels to fixed positions using field interpolation, facilitating source-free\ndomain adaptation. Leveraging Riemannian geometry classification pipelines and\ntransfer learning steps, our method demonstrates robust performance in\nbrain-computer interface (BCI) tasks and potential biomarker applications.\nComparative analysis against a statistical-based approach known as\nDimensionality Transcending, a signal-based imputation called ComImp,\nsource-dependent methods, as well as common channel selection and spherical\nspline interpolation, was conducted with leave-one-dataset-out validation on\nsix public BCI datasets for a right-hand/left-hand classification task.\nNumerical experiments show that in the presence of few shared channels in train\nand test, the field interpolation consistently outperforms other methods,\ndemonstrating enhanced classification performance across all datasets. When\nmore channels are shared, field interpolation was found to be competitive with\nother methods and faster to compute than source-dependent methods.\n","authors":["Apolline Mellot","Antoine Collas","Sylvain Chevallier","Denis Engemann","Alexandre Gramfort"],"pdf_url":"https://arxiv.org/pdf/2403.15415v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19092v1","updated":"2024-06-27T11:17:13Z","published":"2024-06-27T11:17:13Z","title":"Adaptive Stochastic Weight Averaging","summary":"  Ensemble models often improve generalization performances in challenging\ntasks. Yet, traditional techniques based on prediction averaging incur three\nwell-known disadvantages: the computational overhead of training multiple\nmodels, increased latency, and memory requirements at test time. To address\nthese issues, the Stochastic Weight Averaging (SWA) technique maintains a\nrunning average of model parameters from a specific epoch onward. Despite its\npotential benefits, maintaining a running average of parameters can hinder\ngeneralization, as an underlying running model begins to overfit. Conversely,\nan inadequately chosen starting point can render SWA more susceptible to\nunderfitting compared to an underlying running model. In this work, we propose\nAdaptive Stochastic Weight Averaging (ASWA) technique that updates a running\naverage of model parameters, only when generalization performance is improved\non the validation dataset. Hence, ASWA can be seen as a combination of SWA with\nthe early stopping technique, where the former accepts all updates on a\nparameter ensemble model and the latter rejects any update on an underlying\nrunning model. We conducted extensive experiments ranging from image\nclassification to multi-hop reasoning over knowledge graphs. Our experiments\nover 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a\nstatistically better generalization across models and datasets\n","authors":["Caglar Demir","Arnab Sharma","Axel-Cyrille Ngonga Ngomo"],"pdf_url":"https://arxiv.org/pdf/2406.19092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19087v1","updated":"2024-06-27T11:14:14Z","published":"2024-06-27T11:14:14Z","title":"Dimensions underlying the representational alignment of deep neural\n  networks with humans","summary":"  Determining the similarities and differences between humans and artificial\nintelligence is an important goal both in machine learning and cognitive\nneuroscience. However, similarities in representations only inform us about the\ndegree of alignment, not the factors that determine it. Drawing upon recent\ndevelopments in cognitive science, we propose a generic framework for yielding\ncomparable representations in humans and deep neural networks (DNN). Applying\nthis framework to humans and a DNN model of natural images revealed a\nlow-dimensional DNN embedding of both visual and semantic dimensions. In\ncontrast to humans, DNNs exhibited a clear dominance of visual over semantic\nfeatures, indicating divergent strategies for representing images. While\nin-silico experiments showed seemingly-consistent interpretability of DNN\ndimensions, a direct comparison between human and DNN representations revealed\nsubstantial differences in how they process images. By making representations\ndirectly comparable, our results reveal important challenges for\nrepresentational alignment, offering a means for improving their comparability.\n","authors":["Florian P. Mahner","Lukas Muttenthaler","Umut Güçlü","Martin N. Hebart"],"pdf_url":"https://arxiv.org/pdf/2406.19087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07218v2","updated":"2024-06-27T10:49:08Z","published":"2024-03-12T00:25:14Z","title":"SoK: Can Trajectory Generation Combine Privacy and Utility?","summary":"  While location trajectories represent a valuable data source for analyses and\nlocation-based services, they can reveal sensitive information, such as\npolitical and religious preferences. Differentially private publication\nmechanisms have been proposed to allow for analyses under rigorous privacy\nguarantees. However, the traditional protection schemes suffer from a limiting\nprivacy-utility trade-off and are vulnerable to correlation and reconstruction\nattacks. Synthetic trajectory data generation and release represent a promising\nalternative to protection algorithms. While initial proposals achieve\nremarkable utility, they fail to provide rigorous privacy guarantees. This\npaper proposes a framework for designing a privacy-preserving trajectory\npublication approach by defining five design goals, particularly stressing the\nimportance of choosing an appropriate Unit of Privacy. Based on this framework,\nwe briefly discuss the existing trajectory protection approaches, emphasising\ntheir shortcomings. This work focuses on the systematisation of the\nstate-of-the-art generative models for trajectories in the context of the\nproposed framework. We find that no existing solution satisfies all\nrequirements. Thus, we perform an experimental study evaluating the\napplicability of six sequential generative models to the trajectory domain.\nFinally, we conclude that a generative trajectory model providing semantic\nguarantees remains an open research question and propose concrete next steps\nfor future research.\n","authors":["Erik Buchholz","Alsharif Abuadbba","Shuo Wang","Surya Nepal","Salil S. Kanhere"],"pdf_url":"https://arxiv.org/pdf/2403.07218v2.pdf","comment":"Added DOI: 10.56553/popets-2024-0068"},{"id":"http://arxiv.org/abs/2406.19066v1","updated":"2024-06-27T10:34:50Z","published":"2024-06-27T10:34:50Z","title":"Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers","summary":"  This paper introduces a novel approach to bolster algorithmic fairness in\nscenarios where sensitive information is only partially known. In particular,\nwe propose to leverage instances with uncertain identity with regards to the\nsensitive attribute to train a conventional machine learning classifier. The\nenhanced fairness observed in the final predictions of this classifier\nhighlights the promising potential of prioritizing ambiguity (i.e.,\nnon-normativity) as a means to improve fairness guarantees in real-world\nclassification tasks.\n","authors":["Ainhize Barrainkua","Paula Gordaliza","Jose A. Lozano","Novi Quadrianto"],"pdf_url":"https://arxiv.org/pdf/2406.19066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04698v4","updated":"2024-06-27T10:34:28Z","published":"2023-11-08T14:10:19Z","title":"Examining Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we investigate paradigms in MTL in\nthe context of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Overall,\nwe find surprising similarities between STL and MTL suggesting to consider\nmethods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v4.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2406.19057v1","updated":"2024-06-27T10:08:29Z","published":"2024-06-27T10:08:29Z","title":"Segment Anything Model for automated image data annotation: empirical\n  studies using text prompts from Grounding DINO","summary":"  Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2406.19057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11565v2","updated":"2024-06-27T10:07:10Z","published":"2024-03-18T08:35:17Z","title":"Decentralized Stochastic Subgradient Methods for Nonsmooth Nonconvex\n  Optimization","summary":"  In this paper, we concentrate on decentralized optimization problems with\nnonconvex and nonsmooth objective functions, especially on the decentralized\ntraining of nonsmooth neural networks. We introduce a unified framework to\nanalyze the global convergence of decentralized stochastic subgradient-based\nmethods. We prove the global convergence of our proposed framework under mild\nconditions, by establishing that the generated sequence asymptotically\napproximates the trajectories of its associated differential inclusion.\nFurthermore, we establish that our proposed framework covers a wide range of\nexisting efficient decentralized subgradient-based methods, including\ndecentralized stochastic subgradient descent (DSGD), DSGD with\ngradient-tracking technique (DSGD-T), and DSGD with momentum (DSGD-M). In\naddition, we introduce the sign map to regularize the update directions in\nDSGD-M, and show it is enclosed in our proposed framework. Consequently, our\nconvergence results establish, for the first time, global convergence of these\nmethods when applied to nonsmooth nonconvex objectives. Preliminary numerical\nexperiments demonstrate that our proposed framework yields highly efficient\ndecentralized subgradient-based methods with convergence guarantees in the\ntraining of nonsmooth neural networks.\n","authors":["Siyuan Zhang","Nachuan Xiao","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.11565v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2406.19054v1","updated":"2024-06-27T10:01:56Z","published":"2024-06-27T10:01:56Z","title":"A look under the hood of the Interactive Deep Learning Enterprise\n  (No-IDLE)","summary":"  This DFKI technical report presents the anatomy of the No-IDLE prototype\nsystem (funded by the German Federal Ministry of Education and Research) that\nprovides not only basic and fundamental research in interactive machine\nlearning, but also reveals deeper insights into users' behaviours, needs, and\ngoals. Machine learning and deep learning should become accessible to millions\nof end users. No-IDLE's goals and scienfific challenges centre around the\ndesire to increase the reach of interactive deep learning solutions for\nnon-experts in machine learning. One of the key innovations described in this\ntechnical report is a methodology for interactive machine learning combined\nwith multimodal interaction which will become central when we start interacting\nwith semi-intelligent machines in the upcoming area of neural networks and\nlarge language models.\n","authors":["Daniel Sonntag","Michael Barz","Thiago Gouvêa"],"pdf_url":"https://arxiv.org/pdf/2406.19054v1.pdf","comment":"DFKI Technical Report"},{"id":"http://arxiv.org/abs/2406.19051v1","updated":"2024-06-27T09:59:28Z","published":"2024-06-27T09:59:28Z","title":"Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers","summary":"  Recent work has suggested using Monte Carlo methods based on piecewise\ndeterministic Markov processes (PDMPs) to sample from target distributions of\ninterest. PDMPs are non-reversible continuous-time processes endowed with\nmomentum, and hence can mix better than standard reversible MCMC samplers.\nFurthermore, they can incorporate exact sub-sampling schemes which only require\naccess to a single (randomly selected) data point at each iteration, yet\nwithout introducing bias to the algorithm's stationary distribution. However,\nthe range of models for which PDMPs can be used, particularly with\nsub-sampling, is limited. We propose approximate simulation of PDMPs with\nsub-sampling for scalable sampling from posterior distributions. The\napproximation takes the form of an Euler approximation to the true PDMP\ndynamics, and involves using an estimate of the gradient of the log-posterior\nbased on a data sub-sample. We thus call this class of algorithms\nstochastic-gradient PDMPs. Importantly, the trajectories of stochastic-gradient\nPDMPs are continuous and can leverage recent ideas for sampling from measures\nwith continuous and atomic components. We show these methods are easy to\nimplement, present results on their approximation error and demonstrate\nnumerically that this class of algorithms has similar efficiency to, but is\nmore robust than, stochastic gradient Langevin dynamics.\n","authors":["Paul Fearnhead","Sebastiano Grazzi","Chris Nemeth","Gareth O. Roberts"],"pdf_url":"https://arxiv.org/pdf/2406.19051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19050v1","updated":"2024-06-27T09:58:43Z","published":"2024-06-27T09:58:43Z","title":"FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient\n  Federated Learning","summary":"  Federated Learning (FL) is a distributed machine learning approach that\nenables training on decentralized data while preserving privacy. However, FL\nsystems often involve resource-constrained client devices with limited\ncomputational power, memory, storage, and bandwidth. This paper introduces\nFedMap, a novel method that aims to enhance the communication efficiency of FL\ndeployments by collaboratively learning an increasingly sparse global model\nthrough iterative, unstructured pruning. Importantly, FedMap trains a global\nmodel from scratch, unlike other methods reported in the literature, making it\nideal for privacy-critical use cases such as in the medical and finance\ndomains, where suitable pre-training data is often limited. FedMap adapts\niterative magnitude-based pruning to the FL setting, ensuring all clients prune\nand refine the same subset of the global model parameters, therefore gradually\nreducing the global model size and communication overhead. The iterative nature\nof FedMap, forming subsequent models as subsets of predecessors, avoids\nparameter reactivation issues seen in prior work, resulting in stable\nperformance. In this paper we provide an extensive evaluation of FedMap across\ndiverse settings, datasets, model architectures, and hyperparameters, assessing\nperformance in both IID and non-IID environments. Comparative analysis against\nthe baseline approach demonstrates FedMap's ability to achieve more stable\nclient model performance. For IID scenarios, FedMap achieves over $90$\\%\npruning without significant performance degradation. In non-IID settings, it\nachieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a\npromising solution to alleviate communication bottlenecks in FL systems while\nretaining model accuracy.\n","authors":["Alexander Herzog","Robbie Southam","Ioannis Mavromatis","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2406.19050v1.pdf","comment":"Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2406.19049v1","updated":"2024-06-27T09:57:31Z","published":"2024-06-27T09:57:31Z","title":"Accuracy on the wrong line: On the pitfalls of noisy data for\n  out-of-distribution generalisation","summary":"  \"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning,\nwhere a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)\ndata is positively correlated across different hyperparameters and data\nconfigurations. But when does this useful relationship break down? In this\nwork, we explore its robustness. The key observation is that noisy data and the\npresence of nuisance features can be sufficient to shatter the\nAccuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become\nnegatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon\ncan also occur in the presence of spurious (shortcut) features, which tend to\novershadow the more complex signal (core, non-spurious) features, resulting in\na large nuisance feature space. Moreover, scaling to larger datasets does not\nmitigate this undesirable behavior and may even exacerbate it. We formally\nprove a lower bound on Out-of-distribution (OOD) error in a linear\nclassification model, characterizing the conditions on the noise and nuisance\nfeatures for a large OOD error. We finally demonstrate this phenomenon across\nboth synthetic and real datasets with noisy data and nuisance features.\n","authors":["Amartya Sanyal","Yaxi Hu","Yaodong Yu","Yian Ma","Yixin Wang","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2406.19049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19040v1","updated":"2024-06-27T09:45:52Z","published":"2024-06-27T09:45:52Z","title":"On Convex Optimization with Semi-Sensitive Features","summary":"  We study the differentially private (DP) empirical risk minimization (ERM)\nproblem under the semi-sensitive DP setting where only some features are\nsensitive. This generalizes the Label DP setting where only the label is\nsensitive. We give improved upper and lower bounds on the excess risk for\nDP-ERM. In particular, we show that the error only scales polylogarithmically\nin terms of the sensitive domain size, improving upon previous results that\nscale polynomially in the sensitive domain size (Ghazi et al., 2021).\n","authors":["Badih Ghazi","Pritish Kamath","Ravi Kumar","Pasin Manurangsi","Raghu Meka","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19040v1.pdf","comment":"To appear in COLT 2024"},{"id":"http://arxiv.org/abs/2405.13300v2","updated":"2024-06-27T09:07:38Z","published":"2024-05-22T02:37:02Z","title":"FAITH: Frequency-domain Attention In Two Horizons for Time Series\n  Forecasting","summary":"  Time Series Forecasting plays a crucial role in various fields such as\nindustrial equipment maintenance, meteorology, energy consumption, traffic flow\nand financial investment. However, despite their considerable advantages over\ntraditional statistical approaches, current deep learning-based predictive\nmodels often exhibit a significant deviation between their forecasting outcomes\nand the ground truth. This discrepancy is largely due to an insufficient\nemphasis on extracting the sequence's latent information, particularly its\nglobal information within the frequency domain and the relationship between\ndifferent variables. To address this issue, we propose a novel model\nFrequency-domain Attention In Two Horizons, which decomposes time series into\ntrend and seasonal components using a multi-scale sequence adaptive\ndecomposition and fusion architecture, and processes them separately. FAITH\nutilizes Frequency Channel feature Extraction Module and Frequency Temporal\nfeature Extraction Module to capture inter-channel relationships and temporal\nglobal information in the sequence, significantly improving its ability to\nhandle long-term dependencies and complex patterns. Furthermore, FAITH achieves\ntheoretically linear complexity by modifying the time-frequency domain\ntransformation method, effectively reducing computational costs. Extensive\nexperiments on 6 benchmarks for long-term forecasting and 3 benchmarks for\nshort-term forecasting demonstrate that FAITH outperforms existing models in\nmany fields, such as electricity, weather and traffic, proving its\neffectiveness and superiority both in long-term and short-term time series\nforecasting tasks. Our codes and data are available at\nhttps://github.com/LRQ577/FAITH.\n","authors":["Ruiqi Li","Maowei Jiang","Kai Wang","Kaiduo Feng","Quangao Liu","Yue Sun","Xiufang Zhou"],"pdf_url":"https://arxiv.org/pdf/2405.13300v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19015v1","updated":"2024-06-27T09:00:05Z","published":"2024-06-27T09:00:05Z","title":"Lithium-Ion Battery System Health Monitoring and Fault Analysis from\n  Field Data Using Gaussian Processes","summary":"  Health monitoring, fault analysis, and detection are critical for the safe\nand sustainable operation of battery systems. We apply Gaussian process\nresistance models on lithium iron phosphate battery field data to effectively\nseparate the time-dependent and operating point-dependent resistance. The data\nset contains 29 battery systems returned to the manufacturer for warranty, each\nwith eight cells in series, totaling 232 cells and 131 million data rows. We\ndevelop probabilistic fault detection rules using recursive spatiotemporal\nGaussian processes. These processes allow the quick processing of over a\nmillion data points, enabling advanced online monitoring and furthering the\nunderstanding of battery pack failure in the field. The analysis underlines\nthat often, only a single cell shows abnormal behavior or a knee point,\nconsistent with weakest-link failure for cells connected in series, amplified\nby local resistive heating. The results further the understanding of how\nbatteries degrade and fail in the field and demonstrate the potential of\nefficient online monitoring based on data. We open-source the code and publish\nthe large data set upon completion of the review of this article.\n","authors":["Joachim Schaeffer","Eric Lenz","Duncan Gulla","Martin Z. Bazant","Richard D. Braatz","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2406.19015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02739v2","updated":"2024-06-27T08:48:53Z","published":"2023-12-05T13:06:25Z","title":"LExCI: A Framework for Reinforcement Learning with Embedded Systems","summary":"  Advances in artificial intelligence (AI) have led to its application in many\nareas of everyday life. In the context of control engineering, reinforcement\nlearning (RL) represents a particularly promising approach as it is centred\naround the idea of allowing an agent to freely interact with its environment to\nfind an optimal strategy. One of the challenges professionals face when\ntraining and deploying RL agents is that the latter often have to run on\ndedicated embedded devices. This could be to integrate them into an existing\ntoolchain or to satisfy certain performance criteria like real-time\nconstraints. Conventional RL libraries, however, cannot be easily utilised in\nconjunction with that kind of hardware. In this paper, we present a framework\nnamed LExCI, the Learning and Experiencing Cycle Interface, which bridges this\ngap and provides end-users with a free and open-source tool for training agents\non embedded systems using the open-source library RLlib. Its operability is\ndemonstrated with two state-of-the-art RL-algorithms and a rapid control\nprototyping system.\n","authors":["Kevin Badalian","Lucas Koch","Tobias Brinkmann","Mario Picerno","Marius Wegener","Sung-Yong Lee","Jakob Andert"],"pdf_url":"https://arxiv.org/pdf/2312.02739v2.pdf","comment":"The code, models, and data used for this work are available in a\n  separate branch of LExCI's GitHub repository\n  (https://github.com/mechatronics-RWTH/lexci-2/tree/lexci_paper). This paper\n  has been submitted to Applied Intelligence\n  (https://link.springer.com/journal/10489). 2024-06-27: Updated the footnote\n  on the title page so that it provides information about the paper's Version\n  of Record"},{"id":"http://arxiv.org/abs/2406.05504v3","updated":"2024-06-27T08:42:11Z","published":"2024-06-08T16:04:33Z","title":"G-Transformer: Counterfactual Outcome Prediction under Dynamic and\n  Time-varying Treatment Regimes","summary":"  In the context of medical decision making, counterfactual prediction enables\nclinicians to predict treatment outcomes of interest under alternative courses\nof therapeutic actions given observed patient history. Prior machine learning\napproaches for counterfactual predictions under time-varying treatments focus\non static time-varying treatment regimes where treatments do not depend on\nprevious covariate history. In this work, we present G-Transformer, a\nTransformer-based framework supporting g-computation for counterfactual\nprediction under dynamic and time-varying treatment strategies. G-Transfomer\ncaptures complex, long-range dependencies in time-varying covariates using a\nTransformer architecture. G-Transformer estimates the conditional distribution\nof relevant covariates given covariate and treatment history at each time point\nusing an encoder architecture, then produces Monte Carlo estimates of\ncounterfactual outcomes by simulating forward patient trajectories under\ntreatment strategies of interest. We evaluate G-Transformer extensively using\ntwo simulated longitudinal datasets from mechanistic models, and a real-world\nsepsis ICU dataset from MIMIC-IV. G-Transformer outperforms both classical and\nstate-of-the-art counterfactual prediction models in these settings. To the\nbest of our knowledge, this is the first Transformer-based architecture for\ncounterfactual outcome prediction under dynamic and time-varying treatment\nstrategies.\n","authors":["Hong Xiong","Feng Wu","Leon Deng","Megan Su","Li-wei H Lehman"],"pdf_url":"https://arxiv.org/pdf/2406.05504v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18996v1","updated":"2024-06-27T08:37:26Z","published":"2024-06-27T08:37:26Z","title":"Zero-shot domain adaptation based on dual-level mix and contrast","summary":"  Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the\nsituation that labeled samples for a target task (task of interest) are only\navailable from the source domain at training time, but for a task different\nfrom the task of interest (irrelevant task), labeled samples are available from\nboth source and target domains. In this situation, classical domain adaptation\ntechniques can only learn domain-invariant features in the irrelevant task.\nHowever, due to the difference in sample distribution between the two tasks,\ndomain-invariant features learned in the irrelevant task are biased and not\nnecessarily domain-invariant in the task of interest. To solve this problem,\nthis paper proposes a new ZSDA method to learn domain-invariant features with\nlow task bias. To this end, we propose (1) data augmentation with dual-level\nmixups in both task and domain to fill the absence of target task-of-interest\ndata, (2) an extension of domain adversarial learning to learn domain-invariant\nfeatures with less task bias, and (3) a new dual-level contrastive learning\nmethod that enhances domain-invariance and less task biasedness of features.\nExperimental results show that our proposal achieves good performance on\nseveral benchmarks.\n","authors":["Yu Zhe","Jun Sakuma"],"pdf_url":"https://arxiv.org/pdf/2406.18996v1.pdf","comment":"Accepted by IEEE conference on Artificial intelligence 2024"},{"id":"http://arxiv.org/abs/2406.18995v1","updated":"2024-06-27T08:36:43Z","published":"2024-06-27T08:36:43Z","title":"FedMLP: Federated Multi-Label Medical Image Classification under Task\n  Heterogeneity","summary":"  Cross-silo federated learning (FL) enables decentralized organizations to\ncollaboratively train models while preserving data privacy and has made\nsignificant progress in medical image classification. One common assumption is\ntask homogeneity where each client has access to all classes during training.\nHowever, in clinical practice, given a multi-label classification task,\nconstrained by the level of medical knowledge and the prevalence of diseases,\neach institution may diagnose only partial categories, resulting in task\nheterogeneity. How to pursue effective multi-label medical image classification\nunder task heterogeneity is under-explored. In this paper, we first formulate\nsuch a realistic label missing setting in the multi-label FL domain and propose\na two-stage method FedMLP to combat class missing from two aspects: pseudo\nlabel tagging and global knowledge learning. The former utilizes a warmed-up\nmodel to generate class prototypes and select samples with high confidence to\nsupplement missing labels, while the latter uses a global model as a teacher\nfor consistency regularization to prevent forgetting missing class knowledge.\nExperiments on two publicly-available medical datasets validate the superiority\nof FedMLP against the state-of-the-art both federated semi-supervised and noisy\nlabel learning approaches under task heterogeneity. Code is available at\nhttps://github.com/szbonaldo/FedMLP.\n","authors":["Zhaobin Sun","Nannan Wu","Junjie Shi","Li Yu","Xin Yang","Kwang-Ting Cheng","Zengqiang Yan"],"pdf_url":"https://arxiv.org/pdf/2406.18995v1.pdf","comment":"Early accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2311.01200v4","updated":"2024-06-27T08:35:53Z","published":"2023-11-02T12:54:50Z","title":"Continual Learning Under Language Shift","summary":"  The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. We study the pros and cons of updating a language\nmodel when new data comes from new languages -- the case of continual learning\nunder language shift. Starting from a monolingual English language model, we\nincrementally add data from Danish, Icelandic, and Norwegian to investigate how\nforward and backward transfer effects depend on pre-training order and\ncharacteristics of languages, for three different model sizes. Our results show\nthat, while forward transfer is largely positive and independent of language\norder, backward transfer can be positive or negative depending on the order and\ncharacteristics of new languages. We explore a number of potentially\nexplanatory factors and find that a combination of language contamination and\nsyntactic similarity best fits our results.\n","authors":["Evangelia Gogoulou","Timothée Lesort","Magnus Boman","Joakim Nivre"],"pdf_url":"https://arxiv.org/pdf/2311.01200v4.pdf","comment":"Accepted to TSD 2024"},{"id":"http://arxiv.org/abs/2406.18992v1","updated":"2024-06-27T08:33:35Z","published":"2024-06-27T08:33:35Z","title":"Semi-supervised Concept Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) have garnered increasing attention due to\ntheir ability to provide concept-based explanations for black-box deep learning\nmodels while achieving high final prediction accuracy using human-like\nconcepts. However, the training of current CBMs heavily relies on the accuracy\nand richness of annotated concepts in the dataset. These concept labels are\ntypically provided by experts, which can be costly and require significant\nresources and effort. Additionally, concept saliency maps frequently misalign\nwith input saliency maps, causing concept predictions to correspond to\nirrelevant input features - an issue related to annotation alignment. To\naddress these limitations, we propose a new framework called SSCBM\n(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical\nsituations where annotated data is scarce. By leveraging joint training on both\nlabeled and unlabeled data and aligning the unlabeled data at the concept\nlevel, we effectively solve these issues. We proposed a strategy to generate\npseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is\nboth effective and efficient. With only 20% labeled data, we achieved 93.19%\n(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a\nfully supervised setting) prediction accuracy.\n","authors":["Lijie Hu","Tianhao Huang","Huanyi Xie","Chenyang Ren","Zhengyu Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18992v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2406.18990v1","updated":"2024-06-27T08:29:04Z","published":"2024-06-27T08:29:04Z","title":"A Fast Learning-Based Surrogate of Electrical Machines using a Reduced\n  Basis","summary":"  A surrogate model approximates the outputs of a solver of Partial\nDifferential Equations (PDEs) with a low computational cost. In this article,\nwe propose a method to build learning-based surrogates in the context of\nparameterized PDEs, which are PDEs that depend on a set of parameters but are\nalso temporal and spatial processes. Our contribution is a method hybridizing\nthe Proper Orthogonal Decomposition and several Support Vector Regression\nmachines. This method is conceived to work in real-time, thus aimed for being\nused in the context of digital twins, where a user can perform an interactive\nanalysis of results based on the proposed surrogate. We present promising\nresults on two use cases concerning electrical machines. These use cases are\nnot toy examples but are produced an industrial computational code, they use\nmeshes representing non-trivial geometries and contain non-linearities.\n","authors":["Alejandro Ribés","Nawfal Benchekroun","Théo Delagnes"],"pdf_url":"https://arxiv.org/pdf/2406.18990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07940v2","updated":"2024-06-27T08:06:15Z","published":"2024-03-11T02:06:30Z","title":"InfiBench: Evaluating the Question-Answering Capabilities of Code Large\n  Language Models","summary":"  Large Language Models for code (code LLMs) have witnessed tremendous progress\nin recent years. With the rapid development of code LLMs, many popular\nevaluation benchmarks, such as HumanEval, DS-1000, and MBPP, have emerged to\nmeasure the performance of code LLMs with a particular focus on code generation\ntasks. However, they are insufficient to cover the full range of expected\ncapabilities of code LLMs, which span beyond code generation to answering\ndiverse coding-related questions. To fill this gap, we propose InfiBench, the\nfirst large-scale freeform question-answering (QA) benchmark for code to our\nknowledge, comprising 234 carefully selected high-quality Stack Overflow\nquestions that span across 15 programming languages. InfiBench uses four types\nof model-free automatic metrics to evaluate response correctness where domain\nexperts carefully concretize the criterion for each question. We conduct a\nsystematic evaluation for over 100 latest code LLMs on InfiBench, leading to a\nseries of novel and insightful findings. Our detailed analyses showcase\npotential directions for further advancement of code LLMs. InfiBench is fully\nopen source and continuously expanding to foster more scientific and systematic\npractices for code LLM evaluation.\n","authors":["Linyi Li","Shijie Geng","Zhenwen Li","Yibo He","Hao Yu","Ziyue Hua","Guanghan Ning","Siwei Wang","Tao Xie","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2404.07940v2.pdf","comment":"30 pages, 10 pages for main content, work in progress"},{"id":"http://arxiv.org/abs/2405.09541v2","updated":"2024-06-27T07:46:23Z","published":"2024-05-15T17:55:05Z","title":"Spectral complexity of deep neural networks","summary":"  It is well-known that randomly initialized, push-forward, fully-connected\nneural networks weakly converge to isotropic Gaussian processes, in the limit\nwhere the width of all layers goes to infinity. In this paper, we propose to\nuse the angular power spectrum of the limiting field to characterize the\ncomplexity of the network architecture. In particular, we define sequences of\nrandom variables associated with the angular power spectrum, and provide a full\ncharacterization of the network complexity in terms of the asymptotic\ndistribution of these sequences as the depth diverges. On this basis, we\nclassify neural networks as low-disorder, sparse, or high-disorder; we show how\nthis classification highlights a number of distinct features for standard\nactivation functions, and in particular, sparsity properties of ReLU networks.\nOur theoretical results are also validated by numerical simulations.\n","authors":["Simmaco Di Lillo","Domenico Marinucci","Michele Salvi","Stefano Vigogna"],"pdf_url":"https://arxiv.org/pdf/2405.09541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08847v2","updated":"2024-06-27T07:45:28Z","published":"2024-03-13T16:50:04Z","title":"JAXbind: Bind any function to JAX","summary":"  JAX is widely used in machine learning and scientific computing, the latter\nof which often relies on existing high-performance code that we would ideally\nlike to incorporate into JAX. Reimplementing the existing code in JAX is often\nimpractical and the existing interface in JAX for binding custom code either\nlimits the user to a single Jacobian product or requires deep knowledge of JAX\nand its C++ backend for general Jacobian products. With JAXbind we drastically\nreduce the effort required to bind custom functions implemented in other\nprogramming languages with full support for Jacobian-vector products and\nvector-Jacobian products to JAX. Specifically, JAXbind provides an easy-to-use\nPython interface for defining custom, so-called JAX primitives. Via JAXbind,\nany function callable from Python can be exposed as a JAX primitive. JAXbind\nallows a user to interface the JAX function transformation engine with custom\nderivatives and batching rules, enabling all JAX transformations for the custom\nprimitive.\n","authors":["Jakob Roth","Martin Reinecke","Gordian Edenhofer"],"pdf_url":"https://arxiv.org/pdf/2403.08847v2.pdf","comment":"4 pages, Github: https://github.com/NIFTy-PPL/JAXbind"},{"id":"http://arxiv.org/abs/2406.18954v1","updated":"2024-06-27T07:36:25Z","published":"2024-06-27T07:36:25Z","title":"Alignment For Performance Improvement in Conversation Bots","summary":"  This paper shows that alignment methods can achieve superior adherence to\nguardrails compared to instruction fine-tuning alone in conversational agents,\nalso known as bots, within predefined guidelines or 'guardrails'. It examines\ntraditional training approaches such as instruction fine-tuning and the recent\nadvancements in direct alignment methods like Identity Preference Optimization\n(IPO), and Kahneman-Tversky Optimization (KTO). The effectiveness of alignment\ntechniques both pre and post-instruction tuning is highlighted, illustrating\ntheir potential to optimize conversational bots in domains that require strict\nadherence to specified rules, such as customer care.\n","authors":["Raghav Garg","Kapil Sharma","Shrey Singla"],"pdf_url":"https://arxiv.org/pdf/2406.18954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18939v1","updated":"2024-06-27T07:11:48Z","published":"2024-06-27T07:11:48Z","title":"Evaluating AI Group Fairness: a Fuzzy Logic Perspective","summary":"  Artificial intelligence systems often address fairness concerns by evaluating\nand mitigating measures of group discrimination, for example that indicate\nbiases against certain genders or races. However, what constitutes group\nfairness depends on who is asked and the social context, whereas definitions\nare often relaxed to accept small deviations from the statistical constraints\nthey set out to impose. Here we decouple definitions of group fairness both\nfrom the context and from relaxation-related uncertainty by expressing them in\nthe axiomatic system of Basic fuzzy Logic (BL) with loosely understood\npredicates, like encountering group members. We then evaluate the definitions\nin subclasses of BL, such as Product or Lukasiewicz logics. Evaluation produces\ncontinuous instead of binary truth values by choosing the logic subclass and\ntruth values for predicates that reflect uncertain context-specific beliefs,\nsuch as stakeholder opinions gathered through questionnaires. Internally, it\nfollows logic-specific rules to compute the truth values of definitions. We\nshow that commonly held propositions standardize the resulting mathematical\nformulas and we transcribe logic and truth value choices to layperson terms, so\nthat anyone can answer them. We also use our framework to study several\nliterature definitions of algorithmic fairness, for which we rationalize\nprevious expedient practices that are non-probabilistic and show how to\nre-interpret their formulas and parameters in new contexts.\n","authors":["Emmanouil Krasanakis","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2406.18939v1.pdf","comment":"preprint, 32 pages, 7 figures, 2 theorems, 6 appendices"},{"id":"http://arxiv.org/abs/2406.18937v1","updated":"2024-06-27T07:08:28Z","published":"2024-06-27T07:08:28Z","title":"Federated Graph Semantic and Structural Learning","summary":"  Federated graph learning collaboratively learns a global graph neural network\nwith distributed graphs, where the non-independent and identically distributed\nproperty is one of the major challenges. Most relative arts focus on\ntraditional distributed tasks like images and voices, incapable of graph\nstructures. This paper firstly reveals that local client distortion is brought\nby both node-level semantics and graph-level structure. First, for node-level\nsemantics, we find that contrasting nodes from distinct classes is beneficial\nto provide a well-performing discrimination. We pull the local node towards the\nglobal node of the same class and push it away from the global node of\ndifferent classes. Second, we postulate that a well-structural graph neural\nnetwork possesses similarity for neighbors due to the inherent adjacency\nrelationships. However, aligning each node with adjacent nodes hinders\ndiscrimination due to the potential class inconsistency. We transform the\nadjacency relationships into the similarity distribution and leverage the\nglobal model to distill the relation knowledge into the local model, which\npreserves the structural information and discriminability of the local model.\nEmpirical results on three graph datasets manifest the superiority of the\nproposed method over its counterparts.\n","authors":["Wenke Huang","Guancheng Wan","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2406.18937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14207v3","updated":"2024-06-27T07:01:27Z","published":"2024-06-20T11:25:50Z","title":"LayerMatch: Do Pseudo-labels Benefit All Layers?","summary":"  Deep neural networks have achieved remarkable performance across various\ntasks when supplied with large-scale labeled data. However, the collection of\nlabeled data can be time-consuming and labor-intensive. Semi-supervised\nlearning (SSL), particularly through pseudo-labeling algorithms that\niteratively assign pseudo-labels for self-training, offers a promising solution\nto mitigate the dependency of labeled data. Previous research generally applies\na uniform pseudo-labeling strategy across all model layers, assuming that\npseudo-labels exert uniform influence throughout. Contrasting this, our\ntheoretical analysis and empirical experiment demonstrate feature extraction\nlayer and linear classification layer have distinct learning behaviors in\nresponse to pseudo-labels. Based on these insights, we develop two\nlayer-specific pseudo-label strategies, termed Grad-ReLU and Avg-Clustering.\nGrad-ReLU mitigates the impact of noisy pseudo-labels by removing the gradient\ndetrimental effects of pseudo-labels in the linear classification layer.\nAvg-Clustering accelerates the convergence of feature extraction layer towards\nstable clustering centers by integrating consistent outputs. Our approach,\nLayerMatch, which integrates these two strategies, can avoid the severe\ninterference of noisy pseudo-labels in the linear classification layer while\naccelerating the clustering capability of the feature extraction layer. Through\nextensive experimentation, our approach consistently demonstrates exceptional\nperformance on standard semi-supervised learning benchmarks, achieving a\nsignificant improvement of 10.38% over baseline method and a 2.44% increase\ncompared to state-of-the-art methods.\n","authors":["Chaoqi Liang","Guanglei Yang","Lifeng Qiao","Zitong Huang","Hongliang Yan","Yunchao Wei","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2406.14207v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18931v1","updated":"2024-06-27T06:56:46Z","published":"2024-06-27T06:56:46Z","title":"Semi-adaptive Synergetic Two-way Pseudoinverse Learning System","summary":"  Deep learning has become a crucial technology for making breakthroughs in\nmany fields. Nevertheless, it still faces two important challenges in\ntheoretical and applied aspects. The first lies in the shortcomings of gradient\ndescent based learning schemes which are time-consuming and difficult to\ndetermine the learning control hyperparameters. Next, the architectural design\nof the model is usually tricky. In this paper, we propose a semi-adaptive\nsynergetic two-way pseudoinverse learning system, wherein each subsystem\nencompasses forward learning, backward learning, and feature concatenation\nmodules. The whole system is trained using a non-gradient descent learning\nalgorithm. It simplifies the hyperparameter tuning while improving the training\nefficiency. The architecture of the subsystems is designed using a data-driven\napproach that enables automated determination of the depth of the subsystems.\nWe compare our method with the baselines of mainstream non-gradient descent\nbased methods and the results demonstrate the effectiveness of our proposed\nmethod. The source code for this paper is available at\nhttp://github.com/B-berrypie/Semi-adaptive-Synergetic-Two-way-Pseudoinverse-Learning-System}{http://github.com/B-berrypie/Semi-adaptive-Synergetic-Two-way-Pseudoinverse-Learning-System.\n","authors":["Binghong Liu","Ziqi Zhao","Shupan Li","Ke Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01843v5","updated":"2024-06-27T06:51:18Z","published":"2023-06-02T18:03:03Z","title":"Lifting Architectural Constraints of Injective Flows","summary":"  Normalizing Flows explicitly maximize a full-dimensional likelihood on the\ntraining data. However, real data is typically only supported on a\nlower-dimensional manifold leading the model to expend significant compute on\nmodeling noise. Injective Flows fix this by jointly learning a manifold and the\ndistribution on it. So far, they have been limited by restrictive architectures\nand/or high computational cost. We lift both constraints by a new efficient\nestimator for the maximum likelihood loss, compatible with free-form bottleneck\narchitectures. We further show that naively learning both the data manifold and\nthe distribution on it can lead to divergent solutions, and use this insight to\nmotivate a stable maximum likelihood training objective. We perform extensive\nexperiments on toy, tabular and image data, demonstrating the competitive\nperformance of the resulting model.\n","authors":["Peter Sorrenson","Felix Draxler","Armand Rousselot","Sander Hummerich","Lea Zimmermann","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2306.01843v5.pdf","comment":"Camera-ready version: accepted to ICLR 2024"},{"id":"http://arxiv.org/abs/2406.18928v1","updated":"2024-06-27T06:40:01Z","published":"2024-06-27T06:40:01Z","title":"Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation\n  Network","summary":"  In the realm of automatic speech recognition (ASR), robustness in noisy\nenvironments remains a significant challenge. Recent ASR models, such as\nWhisper, have shown promise, but their efficacy in noisy conditions can be\nfurther enhanced. This study is focused on recovering from packet loss to\nimprove the word error rate (WER) of ASR models. We propose using a front-end\nadaptation network connected to a frozen ASR model. The adaptation network is\ntrained to modify the corrupted input spectrum by minimizing the criteria of\nthe ASR model in addition to an enhancement loss function. Our experiments\ndemonstrate that the adaptation network, trained on Whisper's criteria, notably\nreduces word error rates across domains and languages in packet-loss scenarios.\nThis improvement is achieved with minimal affect to Whisper model's\nfoundational performance, underscoring our method's practicality and potential\nin enhancing ASR models in challenging acoustic environments.\n","authors":["Yehoshua Dissen","Shiry Yonash","Israel Cohen","Joseph Keshet"],"pdf_url":"https://arxiv.org/pdf/2406.18928v1.pdf","comment":"Accepted for publication at INTERSPEECH 2024"},{"id":"http://arxiv.org/abs/2406.13808v3","updated":"2024-06-27T06:37:21Z","published":"2024-06-19T20:14:39Z","title":"Can Low-Rank Knowledge Distillation in LLMs be Useful for\n  Microelectronic Reasoning?","summary":"  In this work, we present empirical results regarding the feasibility of using\noffline large language models (LLMs) in the context of electronic design\nautomation (EDA). The goal is to investigate and evaluate a contemporary\nlanguage model's (Llama-2-7B) ability to function as a microelectronic Q & A\nexpert as well as its reasoning, and generation capabilities in solving\nmicroelectronic-related problems. Llama-2-7B was tested across a variety of\nadaptation methods, including introducing a novel low-rank knowledge\ndistillation (LoRA-KD) scheme. Our experiments produce both qualitative and\nquantitative results.\n","authors":["Nirjhor Rouf","Fin Amin","Paul D. Franzon"],"pdf_url":"https://arxiv.org/pdf/2406.13808v3.pdf","comment":"4 pages, 2 figures, 2 tables, The First IEEE International Workshop\n  on LLM-Aided Design (LAD'24)"},{"id":"http://arxiv.org/abs/2406.18926v1","updated":"2024-06-27T06:33:41Z","published":"2024-06-27T06:33:41Z","title":"Fine-tuned network relies on generic representation to solve unseen\n  cognitive task","summary":"  Fine-tuning pretrained language models has shown promising results on a wide\nrange of tasks, but when encountering a novel task, do they rely more on\ngeneric pretrained representation, or develop brand new task-specific\nsolutions? Here, we fine-tuned GPT-2 on a context-dependent decision-making\ntask, novel to the model but adapted from neuroscience literature. We compared\nits performance and internal mechanisms to a version of GPT-2 trained from\nscratch on the same task. Our results show that fine-tuned models depend\nheavily on pretrained representations, particularly in later layers, while\nmodels trained from scratch develop different, more task-specific mechanisms.\nThese findings highlight the advantages and limitations of pretraining for task\ngeneralization and underscore the need for further investigation into the\nmechanisms underpinning task-specific fine-tuning in LLMs.\n","authors":["Dongyan Lin"],"pdf_url":"https://arxiv.org/pdf/2406.18926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18924v1","updated":"2024-06-27T06:31:51Z","published":"2024-06-27T06:31:51Z","title":"Learning Pareto Set for Multi-Objective Continuous Robot Control","summary":"  For a control problem with multiple conflicting objectives, there exists a\nset of Pareto-optimal policies called the Pareto set instead of a single\noptimal policy. When a multi-objective control problem is continuous and\ncomplex, traditional multi-objective reinforcement learning (MORL) algorithms\nsearch for many Pareto-optimal deep policies to approximate the Pareto set,\nwhich is quite resource-consuming. In this paper, we propose a simple and\nresource-efficient MORL algorithm that learns a continuous representation of\nthe Pareto set in a high-dimensional policy parameter space using a single\nhypernet. The learned hypernet can directly generate various well-trained\npolicy networks for different user preferences. We compare our method with two\nstate-of-the-art MORL algorithms on seven multi-objective continuous robot\ncontrol problems. Experimental results show that our method achieves the best\noverall performance with the least training parameters. An interesting\nobservation is that the Pareto set is well approximated by a curved line or\nsurface in a high-dimensional parameter space. This observation will provide\ninsight for researchers to design new MORL algorithms.\n","authors":["Tianye Shu","Ke Shang","Cheng Gong","Yang Nan","Hisao Ishibuchi"],"pdf_url":"https://arxiv.org/pdf/2406.18924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02956v3","updated":"2024-06-27T06:30:01Z","published":"2024-02-05T12:34:03Z","title":"AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a\n  Single High-Resolution Image","summary":"  The process of estimating and counting tree density using only a single\naerial or satellite image is a difficult task in the fields of photogrammetry\nand remote sensing. However, it plays a crucial role in the management of\nforests. The huge variety of trees in varied topography severely hinders tree\ncounting models to perform well. The purpose of this paper is to propose a\nframework that is learnt from the source domain with sufficient labeled trees\nand is adapted to the target domain with only a limited number of labeled\ntrees. Our method, termed as AdaTreeFormer, contains one shared encoder with a\nhierarchical feature extraction scheme to extract robust features from the\nsource and target domains. It also consists of three subnets: two for\nextracting self-domain attention maps from source and target domains\nrespectively and one for extracting cross-domain attention maps. For the\nlatter, an attention-to-adapt mechanism is introduced to distill relevant\ninformation from different domains while generating tree density maps; a\nhierarchical cross-domain feature alignment scheme is proposed that\nprogressively aligns the features from the source and target domains. We also\nadopt adversarial learning into the framework to further reduce the gap between\nsource and target domains. Our AdaTreeFormer is evaluated on six designed\ndomain adaptation tasks using three tree counting datasets, \\ie Jiangsu,\nYosemite, and London. Experimental results show that AdaTreeFormer\nsignificantly surpasses the state of the art, \\eg in the cross domain from the\nYosemite to Jiangsu dataset, it achieves a reduction of 15.9 points in terms of\nthe absolute counting errors and an increase of 10.8\\% in the accuracy of the\ndetected trees' locations. The codes and datasets are available at\nhttps://github.com/HAAClassic/AdaTreeFormer.\n","authors":["Hamed Amini Amirkolaee","Miaojing Shi","Lianghua He","Mark Mulligan"],"pdf_url":"https://arxiv.org/pdf/2402.02956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18922v1","updated":"2024-06-27T06:26:22Z","published":"2024-06-27T06:26:22Z","title":"Time Matters: Scaling Laws for Any Budget","summary":"  A primary cost driver for training large models is wall-clock training time.\nWe show that popular time estimates based on FLOPs are poor estimates, and\nconstruct a more accurate proxy based on memory copies. We show that with some\nsimple accounting, we can estimate the training speed of a transformer model\nfrom its hyperparameters. Combined with a scaling law curve like Chinchilla,\nthis lets us estimate the final loss of the model. We fit our estimate to real\ndata with a linear regression, and apply the result to rewrite Chinchilla in\nterms of a model's estimated training time as opposed to the amount of training\ndata. This gives an expression for the loss in terms of the model's\nhyperparameters alone. We show that this expression is accurate across a wide\nrange of model hyperparameter values, enabling us to analytically make\narchitectural decisions and train models more efficiently.\n","authors":["Itay Inbar","Luke Sernau"],"pdf_url":"https://arxiv.org/pdf/2406.18922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17329v2","updated":"2024-06-27T06:19:01Z","published":"2024-03-26T02:24:32Z","title":"Deep Support Vectors","summary":"  Deep learning has achieved tremendous success. \\nj{However,} unlike SVMs,\nwhich provide direct decision criteria and can be trained with a small dataset,\nit still has significant weaknesses due to its requirement for massive datasets\nduring training and the black-box characteristics on decision criteria.\n\\nj{This paper addresses} these issues by identifying support vectors in deep\nlearning models. To this end, we propose the DeepKKT condition, an adaptation\nof the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models,\nand confirm that generated Deep Support Vectors (DSVs) using this condition\nexhibit properties similar to traditional support vectors. This allows us to\napply our method to few-shot dataset distillation problems and alleviate the\nblack-box characteristics of deep learning models. Additionally, we demonstrate\nthat the DeepKKT condition can transform conventional classification models\ninto generative models with high fidelity, particularly as latent\n\\jh{generative} models using class labels as latent variables. We validate the\neffectiveness of DSVs \\nj{using common datasets (ImageNet, CIFAR10 \\nj{and}\nCIFAR100) on the general architectures (ResNet and ConvNet)}, proving their\npractical applicability. (See Fig.~\\ref{fig:generated})\n","authors":["Junhoo Lee","Hyunho Lee","Kyomin Hwang","Nojun Kwak"],"pdf_url":"https://arxiv.org/pdf/2403.17329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11009v4","updated":"2024-06-27T06:09:58Z","published":"2023-10-17T05:36:46Z","title":"LPFormer: An Adaptive Graph Transformer for Link Prediction","summary":"  Link prediction is a common task on graph-structured data that has seen\napplications in a variety of domains. Classically, hand-crafted heuristics were\nused for this task. Heuristic measures are chosen such that they correlate well\nwith the underlying factors related to link formation. In recent years, a new\nclass of methods has emerged that combines the advantages of message-passing\nneural networks (MPNN) and heuristics methods. These methods perform\npredictions by using the output of an MPNN in conjunction with a \"pairwise\nencoding\" that captures the relationship between nodes in the candidate link.\nThey have been shown to achieve strong performance on numerous datasets.\nHowever, current pairwise encodings often contain a strong inductive bias,\nusing the same underlying factors to classify all links. This limits the\nability of existing methods to learn how to properly classify a variety of\ndifferent links that may form from different factors. To address this\nlimitation, we propose a new method, LPFormer, which attempts to adaptively\nlearn the pairwise encodings for each link. LPFormer models the link factors\nvia an attention module that learns the pairwise encoding that exists between\nnodes by modeling multiple factors integral to link prediction. Extensive\nexperiments demonstrate that LPFormer can achieve SOTA performance on numerous\ndatasets while maintaining efficiency. The code is available at The code is\navailable at https://github.com/HarryShomer/LPFormer.\n","authors":["Harry Shomer","Yao Ma","Haitao Mao","Juanhui Li","Bo Wu","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2310.11009v4.pdf","comment":"KDD'24"},{"id":"http://arxiv.org/abs/2406.02027v2","updated":"2024-06-27T05:47:55Z","published":"2024-06-04T07:06:06Z","title":"Inference Attacks: A Taxonomy, Survey, and Promising Directions","summary":"  The prosperity of machine learning has also brought people's concerns about\ndata privacy. Among them, inference attacks can implement privacy breaches in\nvarious MLaaS scenarios and model training/prediction phases. Specifically,\ninference attacks can perform privacy inference on undisclosed target training\nsets based on outputs of the target model, including but not limited to\nstatistics, membership, semantics, data representation, etc. For instance,\ninfer whether the target data has the characteristics of AIDS. In addition, the\nrapid development of the machine learning community in recent years, especially\nthe surge of model types and application scenarios, has further stimulated the\ninference attacks' research. Thus, studying inference attacks and analyzing\nthem in depth is urgent and significant. However, there is still a gap in the\nsystematic discussion of inference attacks from taxonomy, global perspective,\nattack, and defense perspectives. This survey provides an in-depth and\ncomprehensive inference of attacks and corresponding countermeasures in\nML-as-a-service based on taxonomy and the latest researches. Without\ncompromising researchers' intuition, we first propose the 3MP taxonomy based on\nthe community research status, trying to normalize the confusing naming system\nof inference attacks. Also, we analyze the pros and cons of each type of\ninference attack, their workflow, countermeasure, and how they interact with\nother attacks. In the end, we point out several promising directions for\nresearchers from a more comprehensive and novel perspective.\n","authors":["Feng Wu","Lei Cui","Shaowen Yao","Shui Yu"],"pdf_url":"https://arxiv.org/pdf/2406.02027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18902v1","updated":"2024-06-27T05:30:08Z","published":"2024-06-27T05:30:08Z","title":"Statistical Test for Data Analysis Pipeline by Selective Inference","summary":"  A data analysis pipeline is a structured sequence of processing steps that\ntransforms raw data into meaningful insights by effectively integrating various\nanalysis algorithms. In this paper, we propose a novel statistical test\ndesigned to assess the statistical significance of data analysis pipelines. Our\napproach allows for the systematic development of valid statistical tests\napplicable to any data analysis pipeline configuration composed of a set of\ndata analysis components. We have developed this framework by adapting\nselective inference, which has gained recent attention as a new statistical\ninference technique for data-driven hypotheses. The proposed statistical test\nis theoretically designed to control the type I error at the desired\nsignificance level in finite samples. As examples, we consider a class of\npipelines composed of three missing value imputation algorithms, three outlier\ndetection algorithms, and three feature selection algorithms. We confirm the\nvalidity of our statistical test through experiments with both synthetic and\nreal data for this class of data analysis pipelines. Additionally, we present\nan implementation framework that facilitates testing across any configuration\nof data analysis pipelines in this class without extra implementation costs.\n","authors":["Tomohiro Shiraishi","Tatsuya Matsukawa","Shuichi Nishino","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2406.18902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12199v2","updated":"2024-06-27T05:18:57Z","published":"2024-06-18T01:55:37Z","title":"Time Series Modeling for Heart Rate Prediction: From ARIMA to\n  Transformers","summary":"  Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.\n","authors":["Haowei Ni","Shuchen Meng","Xieming Geng","Panfeng Li","Zhuoying Li","Xupeng Chen","Xiaotong Wang","Shiyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12199v2.pdf","comment":"Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics"},{"id":"http://arxiv.org/abs/2405.17035v2","updated":"2024-06-27T05:09:57Z","published":"2024-05-27T10:42:13Z","title":"Glauber Generative Model: Discrete Diffusion Models via Binary\n  Classification","summary":"  We introduce the Glauber Generative Model (GGM), a new class of discrete\ndiffusion models, to obtain new samples from a distribution given samples from\na discrete space. GGM deploys a discrete Markov chain called the heat bath\ndynamics (or the Glauber dynamics) to denoise a sequence of noisy tokens to a\nsample from a joint distribution of discrete tokens. Our novel conceptual\nframework provides an exact reduction of the task of learning the denoising\nMarkov chain to solving a class of binary classification tasks. More\nspecifically, the model learns to classify a given token in a noisy sequence as\nsignal or noise. In contrast, prior works on discrete diffusion models either\nsolve regression problems to learn importance ratios, or minimize loss\nfunctions given by variational approximations. We apply GGM to language\nmodeling and image generation, where images are discretized using image\ntokenizers like VQGANs. We show that it outperforms existing discrete diffusion\nmodels in language generation, and demonstrates strong performance for image\ngeneration without using dataset-specific image tokenizers. We also show that\nour model is capable of performing well in zero-shot control settings like text\nand image infilling.\n","authors":["Harshit Varma","Dheeraj Nagaraj","Karthikeyan Shanmugam"],"pdf_url":"https://arxiv.org/pdf/2405.17035v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18892v1","updated":"2024-06-27T05:08:09Z","published":"2024-06-27T05:08:09Z","title":"LearnedKV: Integrating LSM and Learned Index for Superior Performance on\n  SSD","summary":"  In this paper, we introduce LearnedKV, a novel tiered key-value (KV) store\nthat seamlessly integrates a Log-Structured Merge (LSM) tree with a Learned\nIndex. This integration yields superior read and write performance compared to\nstandalone indexing structures on SSDs. Our design capitalizes on the LSM\ntree's high write/update throughput and the Learned Index's fast read\ncapabilities, enabling each component to leverage its strengths. We analyze the\nimpact of size on LSM tree performance and demonstrate how the tiered Learned\nIndex significantly mitigates the LSM tree's size-related performance\ndegradation, particularly by reducing the intensive I/O operations resulting\nfrom re-insertions after Garbage Collection (GC). To maintain rapid read\nperformance for newly inserted keys, we introduce a non-blocking conversion\nmechanism that efficiently transforms the existing LSM tree into a new Learned\nIndex with minimal overhead during GC. Our experimental results, conducted\nacross diverse workloads, show that LearnedKV outperforms state-of-the-art\nsolutions by up to 1.32x in read requests and 1.31x in write performance.\n","authors":["Wenlong Wang","David Hung-Chang Du"],"pdf_url":"https://arxiv.org/pdf/2406.18892v1.pdf","comment":"17 pages, 13 figures"},{"id":"http://arxiv.org/abs/2307.14839v4","updated":"2024-06-27T04:58:29Z","published":"2023-07-27T13:18:52Z","title":"Kernelised Normalising Flows","summary":"  Normalising Flows are non-parametric statistical models characterised by\ntheir dual capabilities of density estimation and generation. This duality\nrequires an inherently invertible architecture. However, the requirement of\ninvertibility imposes constraints on their expressiveness, necessitating a\nlarge number of parameters and innovative architectural designs to achieve good\nresults. Whilst flow-based models predominantly rely on neural-network-based\ntransformations for expressive designs, alternative transformation methods have\nreceived limited attention. In this work, we present Ferumal flow, a novel\nkernelised normalising flow paradigm that integrates kernels into the\nframework. Our results demonstrate that a kernelised flow can yield competitive\nor superior results compared to neural network-based flows whilst maintaining\nparameter efficiency. Kernelised flows excel especially in the low-data regime,\nenabling flexible non-parametric density estimation in applications with sparse\ndata availability.\n","authors":["Eshant English","Matthias Kirchler","Christoph Lippert"],"pdf_url":"https://arxiv.org/pdf/2307.14839v4.pdf","comment":"Alternate title: Kernelized Normalizing Flows; Accepted at ICLR 2024"},{"id":"http://arxiv.org/abs/2406.04567v2","updated":"2024-06-27T04:47:43Z","published":"2024-06-07T01:07:35Z","title":"Error Bounds of Supervised Classification from Information-Theoretic\n  Perspective","summary":"  There remains a list of unanswered research questions on deep learning (DL),\nincluding the remarkable generalization power of overparametrized neural\nnetworks, the efficient optimization performance despite the non-convexity, and\nthe mechanisms behind flat minima in generalization. In this paper, we adopt an\ninformation-theoretic perspective to explore the theoretical foundations of\nsupervised classification using deep neural networks (DNNs). Our analysis\nintroduces the concepts of fitting error and model risk, which, together with\ngeneralization error, constitute an upper bound on the expected risk. We\ndemonstrate that the generalization errors are bounded by the complexity,\ninfluenced by both the smoothness of distribution and the sample size.\nConsequently, task complexity serves as a reliable indicator of the dataset's\nquality, guiding the setting of regularization hyperparameters. Furthermore,\nthe derived upper bound fitting error links the back-propagated gradient,\nNeural Tangent Kernel (NTK), and the model's parameter count with the fitting\nerror. Utilizing the triangle inequality, we establish an upper bound on the\nexpected risk. This bound offers valuable insights into the effects of\noverparameterization, non-convex optimization, and the flat minima in\nDNNs.Finally, empirical verification confirms a significant positive\ncorrelation between the derived theoretical bounds and the practical expected\nrisk, confirming the practical relevance of the theoretical findings.\n","authors":["Binchuan Qi","Wei Gong","Li Li"],"pdf_url":"https://arxiv.org/pdf/2406.04567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09478v2","updated":"2024-06-27T04:45:00Z","published":"2024-02-13T05:06:34Z","title":"Data Reconstruction Attacks and Defenses: A Systematic Evaluation","summary":"  Reconstruction attacks and defenses are essential in understanding the data\nleakage problem in machine learning. However, prior work has centered around\nempirical observations of gradient inversion attacks, lacks theoretical\njustifications, and cannot disentangle the usefulness of defending methods from\nthe computational limitation of attacking methods. In this work, we propose to\nview the problem as an inverse problem, enabling us to theoretically,\nquantitatively, and systematically evaluate the data reconstruction problem. On\nvarious defense methods, we derived the algorithmic upper bound and the\nmatching (in feature dimension and model width) information-theoretical lower\nbound on the reconstruction error for two-layer neural networks. To complement\nthe theoretical results and investigate the utility-privacy trade-off, we\ndefined a natural evaluation metric of the defense methods with similar utility\nloss among the strongest attacks. We further propose a strong reconstruction\nattack that helps update some previous understanding of the strength of defense\nmethods under our proposed evaluation metric.\n","authors":["Sheng Liu","Zihan Wang","Yuxiao Chen","Qi Lei"],"pdf_url":"https://arxiv.org/pdf/2402.09478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16777v2","updated":"2024-06-27T04:23:30Z","published":"2023-10-25T17:10:37Z","title":"MixerFlow: MLP-Mixer meets Normalising Flows","summary":"  Normalising flows are generative models that transform a complex density into\na simpler density through the use of bijective transformations enabling both\ndensity estimation and data generation from a single model. %However, the\nrequirement for bijectivity imposes the use of specialised architectures. In\nthe context of image modelling, the predominant choice has been the Glow-based\narchitecture, whereas alternative architectures remain largely unexplored in\nthe research community. In this work, we propose a novel architecture called\nMixerFlow, based on the MLP-Mixer architecture, further unifying the generative\nand discriminative modelling architectures. MixerFlow offers an efficient\nmechanism for weight sharing for flow-based models. Our results demonstrate\ncomparative or superior density estimation on image datasets and good scaling\nas the image resolution increases, making MixerFlow a simple yet powerful\nalternative to the Glow-based architectures. We also show that MixerFlow\nprovides more informative embeddings than Glow-based architectures and can\nintegrate many structured transformations such as splines or Kolmogorov-Arnold\nNetworks.\n","authors":["Eshant English","Matthias Kirchler","Christoph Lippert"],"pdf_url":"https://arxiv.org/pdf/2310.16777v2.pdf","comment":"Alternative title: MixerFlow for Image Modelling; Accepted at\n  ECML-PKDD 2024"},{"id":"http://arxiv.org/abs/2312.09193v2","updated":"2024-06-27T04:01:05Z","published":"2023-12-14T18:14:11Z","title":"Fast Sampling via Discrete Non-Markov Diffusion Models","summary":"  Discrete diffusion models have emerged as powerful tools for high-quality\ndata generation. Despite their success in discrete spaces, such as text\ngeneration tasks, the acceleration of discrete diffusion models remains under\nexplored. In this paper, we propose a discrete non-Markov diffusion model,\nwhich admits an accelerated reverse sampling for discrete data generation. Our\nmethod significantly reduces the number of function evaluations (i.e., calls to\nthe neural network), making the sampling process much faster. Furthermore, we\nstudy the transition from finite to infinite step sampling, offering new\ninsights into bridging the gap between discrete and continuous-time processes\nfor discrete diffusion models. Extensive experiments on natural language\ngeneration and machine translation tasks demonstrate the superior performance\nof our method in terms of both generation speed and sample quality compared to\nexisting methods for discrete diffusion models.\n","authors":["Zixiang Chen","Huizhuo Yuan","Yongqian Li","Yiwen Kou","Junkai Zhang","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2312.09193v2.pdf","comment":"33 pages, 5 figures, 12 tables"},{"id":"http://arxiv.org/abs/2402.14905v2","updated":"2024-06-27T03:53:46Z","published":"2024-02-22T18:58:55Z","title":"MobileLLM: Optimizing Sub-billion Parameter Language Models for\n  On-Device Use Cases","summary":"  This paper addresses the growing need for efficient large language models\n(LLMs) on mobile devices, driven by increasing cloud costs and latency\nconcerns. We focus on designing top-quality LLMs with fewer than a billion\nparameters, a practical choice for mobile deployment. Contrary to prevailing\nbelief emphasizing the pivotal role of data and parameter quantity in\ndetermining model quality, our investigation underscores the significance of\nmodel architecture for sub-billion scale LLMs. Leveraging deep and thin\narchitectures, coupled with embedding sharing and grouped-query attention\nmechanisms, we establish a strong baseline network denoted as MobileLLM, which\nattains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M\nstate-of-the-art models. Additionally, we propose an immediate block-wise\nweight-sharing approach with no increase in model size and only marginal\nlatency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a\nfurther accuracy enhancement of 0.7%/0.8% than MobileLLM 125M/350M. Moreover,\nMobileLLM model family shows significant improvements compared to previous\nsub-billion models on chat benchmarks, and demonstrates close correctness to\nLLaMA-v2 7B in API calling tasks, highlighting the capability of small models\nfor common on-device use cases.\n","authors":["Zechun Liu","Changsheng Zhao","Forrest Iandola","Chen Lai","Yuandong Tian","Igor Fedorov","Yunyang Xiong","Ernie Chang","Yangyang Shi","Raghuraman Krishnamoorthi","Liangzhen Lai","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2402.14905v2.pdf","comment":"ICML 2024. Code is available at\n  https://github.com/facebookresearch/MobileLLM"},{"id":"http://arxiv.org/abs/2402.02021v2","updated":"2024-06-27T03:46:35Z","published":"2024-02-03T04:27:26Z","title":"Transfer Learning in ECG Diagnosis: Is It Effective?","summary":"  The adoption of deep learning in ECG diagnosis is often hindered by the\nscarcity of large, well-labeled datasets in real-world scenarios, leading to\nthe use of transfer learning to leverage features learned from larger datasets.\nYet the prevailing assumption that transfer learning consistently outperforms\ntraining from scratch has never been systematically validated. In this study,\nwe conduct the first extensive empirical study on the effectiveness of transfer\nlearning in multi-label ECG classification, by investigating comparing the\nfine-tuning performance with that of training from scratch, covering a variety\nof ECG datasets and deep neural networks. We confirm that fine-tuning is the\npreferable choice for small downstream datasets; however, when the dataset is\nsufficiently large, training from scratch can achieve comparable performance,\nalbeit requiring a longer training time to catch up. Furthermore, we find that\ntransfer learning exhibits better compatibility with convolutional neural\nnetworks than with recurrent neural networks, which are the two most prevalent\narchitectures for time-series ECG applications. Our results underscore the\nimportance of transfer learning in ECG diagnosis, yet depending on the amount\nof available data, researchers may opt not to use it, considering the\nnon-negligible cost associated with pre-training.\n","authors":["Cuong V. Nguyen","Cuong D. Do"],"pdf_url":"https://arxiv.org/pdf/2402.02021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18865v1","updated":"2024-06-27T03:33:38Z","published":"2024-06-27T03:33:38Z","title":"From Biased Selective Labels to Pseudo-Labels: An\n  Expectation-Maximization Framework for Learning from Biased Decisions","summary":"  Selective labels occur when label observations are subject to a\ndecision-making process; e.g., diagnoses that depend on the administration of\nlaboratory tests. We study a clinically-inspired selective label problem called\ndisparate censorship, where labeling biases vary across subgroups and unlabeled\nindividuals are imputed as \"negative\" (i.e., no diagnostic test = no illness).\nMachine learning models naively trained on such labels could amplify labeling\nbias. Inspired by causal models of selective labels, we propose Disparate\nCensorship Expectation-Maximization (DCEM), an algorithm for learning in the\npresence of disparate censorship. We theoretically analyze how DCEM mitigates\nthe effects of disparate censorship on model performance. We validate DCEM on\nsynthetic data, showing that it improves bias mitigation (area between ROC\ncurves) without sacrificing discriminative performance (AUC) compared to\nbaselines. We achieve similar results in a sepsis classification task using\nclinical data.\n","authors":["Trenton Chang","Jenna Wiens"],"pdf_url":"https://arxiv.org/pdf/2406.18865v1.pdf","comment":"39 pages, 33 figures. ICML 2024 conference paper"},{"id":"http://arxiv.org/abs/2311.07202v5","updated":"2024-06-27T03:33:24Z","published":"2023-11-13T09:41:32Z","title":"Real-Time Machine-Learning-Based Optimization Using Input Convex LSTM","summary":"  Neural network-based optimization and control have gradually supplanted\nfirst-principles model-based approaches in energy and manufacturing systems due\nto their efficient, data-driven process modeling that requires fewer resources.\nHowever, their non-convex nature significantly slows down the optimization and\ncontrol processes, limiting their application in real-time decision-making\nprocesses. To address this challenge, we propose a novel Input Convex Long\nShort-Term Memory (ICLSTM) network to enhance the computational efficiency of\nneural network-based optimization. Through two case studies employing real-time\nneural network-based optimization for optimizing energy and chemical systems,\nwe demonstrate the superior performance of ICLSTM-based optimization in terms\nof runtime. Specifically, in a real-time optimization problem of a real-world\nsolar photovoltaic (PV) energy system at LHT Holdings in Singapore,\nICLSTM-based optimization achieved an 8-fold speedup compared to conventional\nLSTM-based optimization. These results highlight the potential of ICLSTM\nnetworks to significantly enhance the efficiency of neural network-based\noptimization and control in practical applications. Source code is available at\nhttps://github.com/killingbear999/ICLSTM.\n","authors":["Zihao Wang","Donghan Yu","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2311.07202v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15772v3","updated":"2024-06-27T03:31:25Z","published":"2024-04-24T09:45:48Z","title":"Bi-Mamba+: Bidirectional Mamba for Time Series Forecasting","summary":"  Long-term time series forecasting (LTSF) provides longer insights into future\ntrends and patterns. Over the past few years, deep learning models especially\nTransformers have achieved advanced performance in LTSF tasks. However, LTSF\nfaces inherent challenges such as long-term dependencies capturing and sparse\nsemantic characteristics. Recently, a new state space model (SSM) named Mamba\nis proposed. With the selective capability on input data and the hardware-aware\nparallel computing algorithm, Mamba has shown great potential in balancing\npredicting performance and computational efficiency compared to Transformers.\nTo enhance Mamba's ability to preserve historical information in a longer\nrange, we design a novel Mamba+ block by adding a forget gate inside Mamba to\nselectively combine the new features with the historical features in a\ncomplementary manner. Furthermore, we apply Mamba+ both forward and backward\nand propose Bi-Mamba+, aiming to promote the model's ability to capture\ninteractions among time series elements. Additionally, multivariate time series\ndata in different scenarios may exhibit varying emphasis on intra- or\ninter-series dependencies. Therefore, we propose a series-relation-aware\ndecider that controls the utilization of channel-independent or channel-mixing\ntokenization strategy for specific datasets. Extensive experiments on 8\nreal-world datasets show that our model achieves more accurate predictions\ncompared with state-of-the-art methods.\n","authors":["Aobo Liang","Xingguo Jiang","Yan Sun","Xiaohou Shi","Ke Li"],"pdf_url":"https://arxiv.org/pdf/2404.15772v3.pdf","comment":"New Mamba-based architecture. All experiments rerun"},{"id":"http://arxiv.org/abs/2403.12946v2","updated":"2024-06-27T03:16:30Z","published":"2024-03-19T17:48:42Z","title":"Sample Complexity of Offline Distributionally Robust Linear Markov\n  Decision Processes","summary":"  In offline reinforcement learning (RL), the absence of active exploration\ncalls for attention on the model robustness to tackle the sim-to-real gap,\nwhere the discrepancy between the simulated and deployed environments can\nsignificantly undermine the performance of the learned policy. To endow the\nlearned policy with robustness in a sample-efficient manner in the presence of\nhigh-dimensional state-action space, this paper considers the sample complexity\nof distributionally robust linear Markov decision processes (MDPs) with an\nuncertainty set characterized by the total variation distance using offline\ndata. We develop a pessimistic model-based algorithm and establish its sample\ncomplexity bound under minimal data coverage assumptions, which outperforms\nprior art by at least $\\widetilde{O}(d)$, where $d$ is the feature dimension.\nWe further improve the performance guarantee of the proposed algorithm by\nincorporating a carefully-designed variance estimator.\n","authors":["He Wang","Laixi Shi","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2403.12946v2.pdf","comment":"accepted by Reinforcement Learning Conference (RLC)"},{"id":"http://arxiv.org/abs/2406.18861v1","updated":"2024-06-27T03:16:09Z","published":"2024-06-27T03:16:09Z","title":"Predicting the duration of traffic incidents for Sydney greater\n  metropolitan area using machine learning methods","summary":"  This research presents a comprehensive approach to predicting the duration of\ntraffic incidents and classifying them as short-term or long-term across the\nSydney Metropolitan Area. Leveraging a dataset that encompasses detailed\nrecords of traffic incidents, road network characteristics, and socio-economic\nindicators, we train and evaluate a variety of advanced machine learning models\nincluding Gradient Boosted Decision Trees (GBDT), Random Forest, LightGBM, and\nXGBoost. The models are assessed using Root Mean Square Error (RMSE) for\nregression tasks and F1 score for classification tasks.\n  Our experimental results demonstrate that XGBoost and LightGBM outperform\nconventional models with XGBoost achieving the lowest RMSE of 33.7 for\npredicting incident duration and highest classification F1 score of 0.62 for a\n30-minute duration threshold. For classification, the 30-minute threshold\nbalances performance with 70.84\\% short-term duration classification accuracy\nand 62.72\\% long-term duration classification accuracy. Feature importance\nanalysis, employing both tree split counts and SHAP values, identifies the\nnumber of affected lanes, traffic volume, and types of primary and secondary\nvehicles as the most influential features.\n  The proposed methodology not only achieves high predictive accuracy but also\nprovides stakeholders with vital insights into factors contributing to incident\ndurations. These insights enable more informed decision-making for traffic\nmanagement and response strategies. The code is available by the link:\nhttps://github.com/Future-Mobility-Lab/SydneyIncidents\n","authors":["Artur Grigorev","Sajjad Shafiei","Hanna Grzybowska","Adriana-Simona Mihaita"],"pdf_url":"https://arxiv.org/pdf/2406.18861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17931v2","updated":"2024-06-27T03:01:29Z","published":"2024-06-25T20:43:15Z","title":"CAT: Interpretable Concept-based Taylor Additive Models","summary":"  As an emerging interpretable technique, Generalized Additive Models (GAMs)\nadopt neural networks to individually learn non-linear functions for each\nfeature, which are then combined through a linear model for final predictions.\nAlthough GAMs can explain deep neural networks (DNNs) at the feature level,\nthey require large numbers of model parameters and are prone to overfitting,\nmaking them hard to train and scale. Additionally, in real-world datasets with\nmany features, the interpretability of feature-based explanations diminishes\nfor humans. To tackle these issues, recent research has shifted towards\nconcept-based interpretable methods. These approaches try to integrate concept\nlearning as an intermediate step before making predictions, explaining the\npredictions in terms of human-understandable concepts. However, these methods\nrequire domain experts to extensively label concepts with relevant names and\ntheir ground-truth values. In response, we propose CAT, a novel interpretable\nConcept-bAsed Taylor additive model to simply this process. CAT does not have\nto require domain experts to annotate concepts and their ground-truth values.\nInstead, it only requires users to simply categorize input features into broad\ngroups, which can be easily accomplished through a quick metadata review.\nSpecifically, CAT first embeds each group of input features into\none-dimensional high-level concept representation, and then feeds the concept\nrepresentations into a new white-box Taylor Neural Network (TaylorNet). The\nTaylorNet aims to learn the non-linear relationship between the inputs and\noutputs using polynomials. Evaluation results across multiple benchmarks\ndemonstrate that CAT can outperform or compete with the baselines while\nreducing the need of extensive model parameters. Importantly, it can explain\nmodel predictions through high-level concepts that human can understand.\n","authors":["Viet Duong","Qiong Wu","Zhengyi Zhou","Hongjue Zhao","Chenxiang Luo","Eric Zavesky","Huaxiu Yao","Huajie Shao"],"pdf_url":"https://arxiv.org/pdf/2406.17931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17323v4","updated":"2024-06-27T02:53:30Z","published":"2023-05-27T01:56:09Z","title":"Some Primal-Dual Theory for Subgradient Methods for Strongly Convex\n  Optimization","summary":"  We consider (stochastic) subgradient methods for strongly convex but\npotentially nonsmooth non-Lipschitz optimization. We provide new equivalent\ndual descriptions (in the style of dual averaging) for the classic subgradient\nmethod, the proximal subgradient method, and the switching subgradient method.\nThese equivalences enable $O(1/T)$ convergence guarantees in terms of both\ntheir classic primal gap and a not previously analyzed dual gap for strongly\nconvex optimization. Consequently, our theory provides these classic methods\nwith simple, optimal stopping criteria and optimality certificates at no added\ncomputational cost. Our results apply to a wide range of stepsize selections\nand of non-Lipschitz ill-conditioned problems where the early iterations of the\nsubgradient method may diverge exponentially quickly (a phenomenon which, to\nthe best of our knowledge, no prior works address). Even in the presence of\nsuch undesirable behaviors, our theory still ensures and bounds eventual\nconvergence.\n","authors":["Benjamin Grimmer","Danlin Li"],"pdf_url":"https://arxiv.org/pdf/2305.17323v4.pdf","comment":"24 pages, major revision shortened the write-up and unified the\n  analysis to be done just once in a single \"super\" setting"},{"id":"http://arxiv.org/abs/2406.18854v1","updated":"2024-06-27T02:48:33Z","published":"2024-06-27T02:48:33Z","title":"What Is Missing In Homophily? Disentangling Graph Homophily For Graph\n  Neural Networks","summary":"  Graph homophily refers to the phenomenon that connected nodes tend to share\nsimilar characteristics. Understanding this concept and its related metrics is\ncrucial for designing effective Graph Neural Networks (GNNs). The most widely\nused homophily metrics, such as edge or node homophily, quantify such\n\"similarity\" as label consistency across the graph topology. These metrics are\nbelieved to be able to reflect the performance of GNNs, especially on\nnode-level tasks. However, many recent studies have empirically demonstrated\nthat the performance of GNNs does not always align with homophily metrics, and\nhow homophily influences GNNs still remains unclear and controversial. Then, a\ncrucial question arises: What is missing in our current understanding of\nhomophily? To figure out the missing part, in this paper, we disentangle the\ngraph homophily into $3$ aspects: label, structural, and feature homophily,\nproviding a more comprehensive understanding of GNN performance. To investigate\ntheir synergy, we propose a Contextual Stochastic Block Model with $3$ types of\nHomophily (CSBM-3H), where the topology and feature generation are controlled\nby the $3$ metrics. Based on the theoretical analysis of CSBM-3H, we derive a\nnew composite metric, named Tri-Hom, that considers all $3$ aspects and\novercomes the limitations of conventional homophily metrics. The theoretical\nconclusions and the effectiveness of Tri-Hom have been verified through\nsynthetic experiments on CSBM-3H. In addition, we conduct experiments on $31$\nreal-world benchmark datasets and calculate the correlations between homophily\nmetrics and model performance. Tri-Hom has significantly higher correlation\nvalues than $17$ existing metrics that only focus on a single homophily aspect,\ndemonstrating its superiority and the importance of homophily synergy. Our code\nis available at \\url{https://github.com/zylMozart/Disentangle_GraphHom}.\n","authors":["Yilun Zheng","Sitao Luan","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18853v1","updated":"2024-06-27T02:46:30Z","published":"2024-06-27T02:46:30Z","title":"Decoding-Time Language Model Alignment with Multiple Objectives","summary":"  Aligning language models (LMs) to human preferences has emerged as a critical\npursuit, enabling these models to better serve diverse user needs. Existing\nmethods primarily focus on optimizing LMs for a single reward function,\nlimiting their adaptability to varied objectives. Here, we propose\n$\\textbf{multi-objective decoding (MOD)}$, a decoding-time algorithm that\noutputs the next token from a linear combination of predictions of all base\nmodels, for any given weightings over different objectives. We exploit a common\nform among a family of $f$-divergence regularized alignment approaches (such as\nPPO, DPO, and their variants) to identify a closed-form solution by Legendre\ntransform, and derive an efficient decoding strategy. Theoretically, we show\nwhy existing approaches can be sub-optimal even in natural settings and obtain\noptimality guarantees for our method. Empirical results demonstrate the\neffectiveness of the algorithm. For example, compared to a parameter-merging\nbaseline, MOD achieves 12.8% overall reward improvement when equally optimizing\ntowards $3$ objectives. Moreover, we experiment with MOD on combining three\nfully-finetuned LLMs of different model sizes, each aimed at different\nobjectives such as safety, coding, and general user preference. Unlike\ntraditional methods that require careful curation of a mixture of datasets to\nachieve comprehensive improvement, we can quickly experiment with preference\nweightings using MOD to find the best combination of models. Our best\ncombination reduces toxicity on Toxigen to nearly 0% and achieves 7.9--33.3%\nimprovement across other three metrics ($\\textit{i.e.}$, Codex@1, GSM-COT,\nBBH-COT).\n","authors":["Ruizhe Shi","Yifang Chen","Yushi Hu","ALisa Liu","Noah Smith","Hannaneh Hajishirzi","Simon Du"],"pdf_url":"https://arxiv.org/pdf/2406.18853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09181v3","updated":"2024-06-27T02:45:41Z","published":"2024-01-17T12:44:17Z","title":"Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with\n  Positive Forward Transfer","summary":"  Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large\nLanguage Models (MLLMs) to meet continuously emerging requirements without\nexpensive retraining. MCIT faces two major obstacles: catastrophic forgetting\n(where old knowledge is forgotten) and negative forward transfer (where the\nperformance of future tasks is degraded). Although existing methods have\ngreatly alleviated catastrophic forgetting, they still suffer from negative\nforward transfer. We discover a large discrepancy in different input embeddings\nby performing singular value decomposition (SVD) on input embeddings. This\ndiscrepancy results in the model learning irrelevant information for old and\npre-trained tasks, leading to catastrophic forgetting and negative forward\ntransfer. To address these issues, we propose Prompt Tuning with Positive\nForward Transfer (Fwd-Prompt), a prompt-based method that projects the prompt\ngradient to the residual space to minimize interference between tasks and to\nthe pre-trained subspace for reusing pre-trained knowledge. Our experiments\ndemonstrate that Fwd-Prompt achieves state-of-the-art performance while\nupdating fewer parameters and requiring no old samples. Our research\nilluminates the potential of continuously adapting MLLMs to new tasks under the\ninstruction tuning paradigm and encourages future studies to explore MCIT.\n","authors":["Junhao Zheng","Qianli Ma","Zhen Liu","Binquan Wu","Huawen Feng"],"pdf_url":"https://arxiv.org/pdf/2401.09181v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18851v1","updated":"2024-06-27T02:43:18Z","published":"2024-06-27T02:43:18Z","title":"LICO: Large Language Models for In-Context Molecular Optimization","summary":"  Optimizing black-box functions is a fundamental problem in science and\nengineering. To solve this problem, many approaches learn a surrogate function\nthat estimates the underlying objective from limited historical evaluations.\nLarge Language Models (LLMs), with their strong pattern-matching capabilities\nvia pretraining on vast amounts of data, stand out as a potential candidate for\nsurrogate modeling. However, directly prompting a pretrained language model to\nproduce predictions is not feasible in many scientific domains due to the\nscarcity of domain-specific data in the pretraining corpora and the challenges\nof articulating complex problems in natural language. In this work, we\nintroduce LICO, a general-purpose model that extends arbitrary base LLMs for\nblack-box optimization, with a particular application to the molecular domain.\nTo achieve this, we equip the language model with a separate embedding layer\nand prediction layer, and train the model to perform in-context predictions on\na diverse set of functions defined over the domain. Once trained, LICO can\ngeneralize to unseen molecule properties simply via in-context prompting. LICO\nachieves state-of-the-art performance on PMO, a challenging molecular\noptimization benchmark comprising over 20 objective functions.\n","authors":["Tung Nguyen","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2406.18851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18848v1","updated":"2024-06-27T02:38:25Z","published":"2024-06-27T02:38:25Z","title":"Temporally Multi-Scale Sparse Self-Attention for Physical Activity Data\n  Imputation","summary":"  Wearable sensors enable health researchers to continuously collect data\npertaining to the physiological state of individuals in real-world settings.\nHowever, such data can be subject to extensive missingness due to a complex\ncombination of factors. In this work, we study the problem of imputation of\nmissing step count data, one of the most ubiquitous forms of wearable sensor\ndata. We construct a novel and large scale data set consisting of a training\nset with over 3 million hourly step count observations and a test set with over\n2.5 million hourly step count observations. We propose a domain\nknowledge-informed sparse self-attention model for this task that captures the\ntemporal multi-scale nature of step-count data. We assess the performance of\nthe model relative to baselines and conduct ablation studies to verify our\nspecific model designs.\n","authors":["Hui Wei","Maxwell A. Xu","Colin Samplawski","James M. Rehg","Santosh Kumar","Benjamin M. Marlin"],"pdf_url":"https://arxiv.org/pdf/2406.18848v1.pdf","comment":"Accepted by Conference on Health, Inference, and Learning (CHIL) 2024"},{"id":"http://arxiv.org/abs/2406.18847v1","updated":"2024-06-27T02:38:13Z","published":"2024-06-27T02:38:13Z","title":"Learning Retrieval Augmentation for Personalized Dialogue Generation","summary":"  Personalized dialogue generation, focusing on generating highly tailored\nresponses by leveraging persona profiles and dialogue context, has gained\nsignificant attention in conversational AI applications. However, persona\nprofiles, a prevalent setting in current personalized dialogue datasets,\ntypically composed of merely four to five sentences, may not offer\ncomprehensive descriptions of the persona about the agent, posing a challenge\nto generate truly personalized dialogues. To handle this problem, we propose\n$\\textbf{L}$earning Retrieval $\\textbf{A}$ugmentation for\n$\\textbf{P}$ersonalized $\\textbf{D}$ial$\\textbf{O}$gue $\\textbf{G}$eneration\n($\\textbf{LAPDOG}$), which studies the potential of leveraging external\nknowledge for persona dialogue generation. Specifically, the proposed LAPDOG\nmodel consists of a story retriever and a dialogue generator. The story\nretriever uses a given persona profile as queries to retrieve relevant\ninformation from the story document, which serves as a supplementary context to\naugment the persona profile. The dialogue generator utilizes both the dialogue\nhistory and the augmented persona profile to generate personalized responses.\nFor optimization, we adopt a joint training framework that collaboratively\nlearns the story retriever and dialogue generator, where the story retriever is\noptimized towards desired ultimate metrics (e.g., BLEU) to retrieve content for\nthe dialogue generator to generate personalized responses. Experiments\nconducted on the CONVAI2 dataset with ROCStory as a supplementary data source\nshow that the proposed LAPDOG method substantially outperforms the baselines,\nindicating the effectiveness of the proposed method. The LAPDOG model code is\npublicly available for further exploration.\nhttps://github.com/hqsiswiliam/LAPDOG\n","authors":["Qiushi Huang","Shuai Fu","Xubo Liu","Wenwu Wang","Tom Ko","Yu Zhang","Lilian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.18847v1.pdf","comment":"Accepted to EMNLP-2023"},{"id":"http://arxiv.org/abs/2212.07632v2","updated":"2024-06-27T02:32:42Z","published":"2022-12-15T06:36:14Z","title":"Reinforcement Learning in Credit Scoring and Underwriting","summary":"  This paper proposes a novel reinforcement learning (RL) framework for credit\nunderwriting that tackles ungeneralizable contextual challenges. We adapt RL\nprinciples for credit scoring, incorporating action space renewal and\nmulti-choice actions. Our work demonstrates that the traditional underwriting\napproach aligns with the RL greedy strategy. We introduce two new RL-based\ncredit underwriting algorithms to enable more informed decision-making.\nSimulations show these new approaches outperform the traditional method in\nscenarios where the data aligns with the model. However, complex situations\nhighlight model limitations, emphasizing the importance of powerful machine\nlearning models for optimal performance. Future research directions include\nexploring more sophisticated models alongside efficient exploration mechanisms.\n","authors":["Seksan Kiatsupaibul","Pakawan Chansiripas","Pojtanut Manopanjasiri","Kantapong Visantavarakul","Zheng Wen"],"pdf_url":"https://arxiv.org/pdf/2212.07632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12754v2","updated":"2024-06-27T02:03:21Z","published":"2024-05-21T13:04:53Z","title":"Neural Operator for Accelerating Coronal Magnetic Field Model","summary":"  Studying the sun's outer atmosphere is challenging due to its complex\nmagnetic fields impacting solar activities. Magnetohydrodynamics (MHD)\nsimulations help model these interactions but are extremely time-consuming\n(usually on a scale of days). Our research applies the Fourier Neural Operator\n(FNO) to accelerate the coronal magnetic field modeling, specifically, the\nBifrost MHD model. We apply Tensorized FNO (TFNO) to generate solutions from\npartial differential equations (PDEs) over a 3D domain efficiently. TFNO's\nperformance is compared with other deep learning methods, highlighting its\naccuracy and scalability. Physics analysis confirms that TFNO is reliable and\ncapable of accelerating MHD simulations with high precision. This advancement\nimproves efficiency in data handling, enhances predictive capabilities, and\nprovides a better understanding of magnetic topologies.\n","authors":["Yutao Du","Qin Li","Raghav Gnanasambandam","Mengnan Du","Haimin Wang","Bo Shen"],"pdf_url":"https://arxiv.org/pdf/2405.12754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11740v3","updated":"2024-06-27T01:49:19Z","published":"2024-02-18T23:54:35Z","title":"Extraction of nonlinearity in neural networks with Koopman operator","summary":"  Nonlinearity plays a crucial role in deep neural networks. In this paper, we\ninvestigate the degree to which the nonlinearity of the neural network is\nessential. For this purpose, we employ the Koopman operator, extended dynamic\nmode decomposition, and the tensor-train format. The Koopman operator approach\nhas been recently developed in physics and nonlinear sciences; the Koopman\noperator deals with the time evolution in the observable space instead of the\nstate space. Since we can replace the nonlinearity in the state space with the\nlinearity in the observable space, it is a hopeful candidate for understanding\ncomplex behavior in nonlinear systems. Here, we analyze learned neural networks\nfor the classification problems. As a result, the replacement of the nonlinear\nmiddle layers with the Koopman matrix yields enough accuracy in numerical\nexperiments. In addition, we confirm that the pruning of the Koopman matrix\ngives sufficient accuracy even at high compression ratios. These results\nindicate the possibility of extracting some features in the neural networks\nwith the Koopman operator approach.\n","authors":["Naoki Sugishita","Kayo Kinjo","Jun Ohkubo"],"pdf_url":"https://arxiv.org/pdf/2402.11740v3.pdf","comment":"22 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.18820v1","updated":"2024-06-27T01:28:30Z","published":"2024-06-27T01:28:30Z","title":"Universal Checkpointing: Efficient and Flexible Checkpointing for Large\n  Scale Distributed Training","summary":"  Existing checkpointing approaches seem ill-suited for distributed training\neven though hardware limitations make model parallelism, i.e., sharding model\nstate across multiple accelerators, a requirement for model scaling.\nConsolidating distributed model state into a single checkpoint unacceptably\nslows down training, and is impractical at extreme scales. Distributed\ncheckpoints, in contrast, are tightly coupled to the model parallelism and\nhardware configurations of the training run, and thus unusable on different\nconfigurations. To address this problem, we propose Universal Checkpointing, a\ntechnique that enables efficient checkpoint creation while providing the\nflexibility of resuming on arbitrary parallelism strategy and hardware\nconfigurations. Universal Checkpointing unlocks unprecedented capabilities for\nlarge-scale training such as improved resilience to hardware failures through\ncontinued training on remaining healthy hardware, and reduced training time\nthrough opportunistic exploitation of elastic capacity.\n  The key insight of Universal Checkpointing is the selection of the optimal\nrepresentation in each phase of the checkpointing life cycle: distributed\nrepresentation for saving, and consolidated representation for loading. This is\nachieved using two key mechanisms. First, the universal checkpoint format,\nwhich consists of a consolidated representation of each model parameter and\nmetadata for mapping parameter fragments into training ranks of arbitrary\nmodel-parallelism configuration. Second, the universal checkpoint language, a\nsimple but powerful specification language for converting distributed\ncheckpoints into the universal checkpoint format. Our evaluation demonstrates\nthe effectiveness and generality of Universal Checkpointing on state-of-the-art\nmodel architectures and a wide range of parallelism techniques.\n","authors":["Xinyu Lian","Sam Ade Jacobs","Lev Kurilenko","Masahiro Tanaka","Stas Bekman","Olatunji Ruwase","Minjia Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12308v2","updated":"2024-06-27T01:22:30Z","published":"2024-04-18T16:35:38Z","title":"ASID: Active Exploration for System Identification in Robotic\n  Manipulation","summary":"  Model-free control strategies such as reinforcement learning have shown the\nability to learn control strategies without requiring an accurate model or\nsimulator of the world. While this is appealing due to the lack of modeling\nrequirements, such methods can be sample inefficient, making them impractical\nin many real-world domains. On the other hand, model-based control techniques\nleveraging accurate simulators can circumvent these challenges and use a large\namount of cheap simulation data to learn controllers that can effectively\ntransfer to the real world. The challenge with such model-based techniques is\nthe requirement for an extremely accurate simulation, requiring both the\nspecification of appropriate simulation assets and physical parameters. This\nrequires considerable human effort to design for every environment being\nconsidered. In this work, we propose a learning system that can leverage a\nsmall amount of real-world data to autonomously refine a simulation model and\nthen plan an accurate control strategy that can be deployed in the real world.\nOur approach critically relies on utilizing an initial (possibly inaccurate)\nsimulator to design effective exploration policies that, when deployed in the\nreal world, collect high-quality data. We demonstrate the efficacy of this\nparadigm in identifying articulation, mass, and other physical parameters in\nseveral challenging robotic manipulation tasks, and illustrate that only a\nsmall amount of real-world data can allow for effective sim-to-real transfer.\nProject website at https://weirdlabuw.github.io/asid\n","authors":["Marius Memmel","Andrew Wagenmaker","Chuning Zhu","Patrick Yin","Dieter Fox","Abhishek Gupta"],"pdf_url":"https://arxiv.org/pdf/2404.12308v2.pdf","comment":"Project website at https://weirdlabuw.github.io/asid"},{"id":"http://arxiv.org/abs/2308.11933v3","updated":"2024-06-27T01:09:29Z","published":"2023-08-23T05:53:13Z","title":"System Identification for Continuous-time Linear Dynamical Systems","summary":"  The problem of system identification for the Kalman filter, relying on the\nexpectation-maximization (EM) procedure to learn the underlying parameters of a\ndynamical system, has largely been studied assuming that observations are\nsampled at equally-spaced time points. However, in many applications this is a\nrestrictive and unrealistic assumption. This paper addresses system\nidentification for the continuous-discrete filter, with the aim of generalizing\nlearning for the Kalman filter by relying on a solution to a continuous-time\nIt\\^o stochastic differential equation (SDE) for the latent state and\ncovariance dynamics. We introduce a novel two-filter, analytical form for the\nposterior with a Bayesian derivation, which yields analytical updates which do\nnot require the forward-pass to be pre-computed. Using this analytical and\nefficient computation of the posterior, we provide an EM procedure which\nestimates the parameters of the SDE, naturally incorporating irregularly\nsampled measurements. Generalizing the learning of latent linear dynamical\nsystems (LDS) to continuous-time may extend the use of the hybrid Kalman filter\nto data which is not regularly sampled or has intermittent missing values, and\ncan extend the power of non-linear system identification methods such as\nswitching LDS (SLDS), which rely on EM for the linear discrete-time Kalman\nfilter as a sub-unit for learning locally linearized behavior of a non-linear\nsystem. We apply the method by learning the parameters of a latent,\nmultivariate Fokker-Planck SDE representing a toggle-switch genetic circuit\nusing biologically realistic parameters, and compare the efficacy of learning\nrelative to the discrete-time Kalman filter as the step-size irregularity and\nspectral-radius of the dynamics-matrix increases.\n","authors":["Peter Halmos","Jonathan Pillow","David A. Knowles"],"pdf_url":"https://arxiv.org/pdf/2308.11933v3.pdf","comment":"31 pages, 3 figures. Only light changes and restructuring to previous\n  version made"},{"id":"http://arxiv.org/abs/2406.18815v1","updated":"2024-06-27T01:09:07Z","published":"2024-06-27T01:09:07Z","title":"MissionGNN: Hierarchical Multimodal GNN-based Weakly Supervised Video\n  Anomaly Recognition with Mission-Specific Knowledge Graph Generation","summary":"  In the context of escalating safety concerns across various domains, the\ntasks of Video Anomaly Detection (VAD) and Video Anomaly Recognition (VAR) have\nemerged as critically important for applications in intelligent surveillance,\nevidence investigation, violence alerting, etc. These tasks, aimed at\nidentifying and classifying deviations from normal behavior in video data, face\nsignificant challenges due to the rarity of anomalies which leads to extremely\nimbalanced data and the impracticality of extensive frame-level data annotation\nfor supervised learning. This paper introduces a novel hierarchical graph\nneural network (GNN) based model MissionGNN that addresses these challenges by\nleveraging a state-of-the-art large language model and a comprehensive\nknowledge graph for efficient weakly supervised learning in VAR. Our approach\ncircumvents the limitations of previous methods by avoiding heavy gradient\ncomputations on large multimodal models and enabling fully frame-level training\nwithout fixed video segmentation. Utilizing automated, mission-specific\nknowledge graph generation, our model provides a practical and efficient\nsolution for real-time video analysis without the constraints of previous\nsegmentation-based or multimodal approaches. Experimental validation on\nbenchmark datasets demonstrates our model's performance in VAD and VAR,\nhighlighting its potential to redefine the landscape of anomaly detection and\nrecognition in video surveillance systems.\n","authors":["Sanggeon Yun","Ryozo Masukawa","Minhyoung Na","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2406.18815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18814v1","updated":"2024-06-27T01:08:04Z","published":"2024-06-27T01:08:04Z","title":"Length Optimization in Conformal Prediction","summary":"  Conditional validity and length efficiency are two crucial aspects of\nconformal prediction (CP). Achieving conditional validity ensures accurate\nuncertainty quantification for data subpopulations, while proper length\nefficiency ensures that the prediction sets remain informative and non-trivial.\nDespite significant efforts to address each of these issues individually, a\nprincipled framework that reconciles these two objectives has been missing in\nthe CP literature. In this paper, we develop Conformal Prediction with\nLength-Optimization (CPL) - a novel framework that constructs prediction sets\nwith (near-) optimal length while ensuring conditional validity under various\nclasses of covariate shifts, including the key cases of marginal and\ngroup-conditional coverage. In the infinite sample regime, we provide strong\nduality results which indicate that CPL achieves conditional validity and\nlength optimality. In the finite sample regime, we show that CPL constructs\nconditionally valid prediction sets. Our extensive empirical evaluations\ndemonstrate the superior prediction set size performance of CPL compared to\nstate-of-the-art methods across diverse real-world and synthetic datasets in\nclassification, regression, and text-related settings.\n","authors":["Shayan Kiyani","George Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2406.18814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18806v1","updated":"2024-06-27T00:44:46Z","published":"2024-06-27T00:44:46Z","title":"Density Ratio Estimation via Sampling along Generalized Geodesics on\n  Statistical Manifolds","summary":"  The density ratio of two probability distributions is one of the fundamental\ntools in mathematical and computational statistics and machine learning, and it\nhas a variety of known applications. Therefore, density ratio estimation from\nfinite samples is a very important task, but it is known to be unstable when\nthe distributions are distant from each other. One approach to address this\nproblem is density ratio estimation using incremental mixtures of the two\ndistributions. We geometrically reinterpret existing methods for density ratio\nestimation based on incremental mixtures. We show that these methods can be\nregarded as iterating on the Riemannian manifold along a particular curve\nbetween the two probability distributions. Making use of the geometry of the\nmanifold, we propose to consider incremental density ratio estimation along\ngeneralized geodesics on this manifold. To achieve such a method requires Monte\nCarlo sampling along geodesics via transformations of the two distributions. We\nshow how to implement an iterative algorithm to sample along these geodesics\nand show how changing the distances along the geodesic affect the variance and\naccuracy of the estimation of the density ratio. Our experiments demonstrate\nthat the proposed approach outperforms the existing approaches using\nincremental mixtures that do not take the geometry of the\n","authors":["Masanari Kimura","Howard Bondell"],"pdf_url":"https://arxiv.org/pdf/2406.18806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18805v1","updated":"2024-06-27T00:42:33Z","published":"2024-06-27T00:42:33Z","title":"Online Stackelberg Optimization via Nonlinear Control","summary":"  In repeated interaction problems with adaptive agents, our objective often\nrequires anticipating and optimizing over the space of possible agent\nresponses. We show that many problems of this form can be cast as instances of\nonline (nonlinear) control which satisfy \\textit{local controllability}, with\nconvex losses over a bounded state space which encodes agent behavior, and we\nintroduce a unified algorithmic framework for tractable regret minimization in\nsuch cases. When the instance dynamics are known but otherwise arbitrary, we\nobtain oracle-efficient $O(\\sqrt{T})$ regret by reduction to online convex\noptimization, which can be made computationally efficient if dynamics are\nlocally \\textit{action-linear}. In the presence of adversarial disturbances to\nthe state, we give tight bounds in terms of either the cumulative or per-round\ndisturbance magnitude (for \\textit{strongly} or \\textit{weakly} locally\ncontrollable dynamics, respectively). Additionally, we give sublinear regret\nresults for the cases of unknown locally action-linear dynamics as well as for\nthe bandit feedback setting. Finally, we demonstrate applications of our\nframework to well-studied problems including performative prediction,\nrecommendations for adaptive agents, adaptive pricing of real-valued goods, and\nrepeated gameplay against no-regret learners, directly yielding extensions\nbeyond prior results in each case.\n","authors":["William Brown","Christos Papadimitriou","Tim Roughgarden"],"pdf_url":"https://arxiv.org/pdf/2406.18805v1.pdf","comment":"COLT 2024"},{"id":"http://arxiv.org/abs/2406.18802v1","updated":"2024-06-27T00:21:10Z","published":"2024-06-27T00:21:10Z","title":"All Random Features Representations are Equivalent","summary":"  Random features are an important technique that make it possible to rewrite\npositive-definite kernels as infinite-dimensional dot products. Over time,\nincreasingly elaborate random feature representations have been developed in\npursuit of finite approximations with ever lower error. We resolve this arms\nrace by deriving an optimal sampling policy, and show that under this policy\nall random features representations have the same approximation error. This\nestablishes a lower bound that holds across all random feature representations,\nand shows that we are free to choose whatever representation we please,\nprovided we sample optimally.\n","authors":["Luke Sernau","Silvano Bonacina","Rif A. Saurous"],"pdf_url":"https://arxiv.org/pdf/2406.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18800v1","updated":"2024-06-27T00:15:54Z","published":"2024-06-27T00:15:54Z","title":"Infinite Width Models That Work: Why Feature Learning Doesn't Matter as\n  Much as You Think","summary":"  Common infinite-width architectures such as Neural Tangent Kernels (NTKs)\nhave historically shown weak performance compared to finite models. This has\nbeen attributed to the absence of feature learning. We show that this is not\nthe case. In fact, we show that infinite width NTK models are able to access\nricher features than finite models by selecting relevant subfeatures from their\n(infinite) feature vector. In fact, we show experimentally that NTKs\nunder-perform traditional finite models even when feature learning is\nartificially disabled. Instead, weak performance is due to the fact that\nexisting constructions depend on weak optimizers like SGD. We provide an\ninfinite width limit based on ADAM-like learning dynamics and demonstrate\nempirically that the resulting models erase this performance gap.\n","authors":["Luke Sernau"],"pdf_url":"https://arxiv.org/pdf/2406.18800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.05989v2","updated":"2024-06-27T11:02:53Z","published":"2020-01-16T18:41:17Z","title":"Cross-conformal e-prediction","summary":"  This note discusses a simple modification of cross-conformal prediction\ninspired by recent work on e-values. The precursor of conformal prediction\ndeveloped in the 1990s by Gammerman, Vapnik, and Vovk was also based on\ne-values and is called conformal e-prediction in this note. Replacing e-values\nby p-values led to conformal prediction, which has important advantages over\nconformal e-prediction without obvious disadvantages. The situation with\ncross-conformal prediction is, however, different: whereas for cross-conformal\nprediction validity is only an empirical fact (and can be broken with excessive\nrandomization), this note draws the reader's attention to the obvious fact that\ncross-conformal e-prediction enjoys a guaranteed property of validity.\n","authors":["Vladimir Vovk"],"pdf_url":"https://arxiv.org/pdf/2001.05989v2.pdf","comment":"8 pages. This version: exposition improved; proof of Proposition 4\n  added"},{"id":"http://arxiv.org/abs/1911.02142v3","updated":"2024-06-27T08:24:52Z","published":"2019-11-05T23:39:55Z","title":"Intriguing Properties of Adversarial ML Attacks in the Problem Space\n  [Extended Version]","summary":"  Recent research efforts on adversarial machine learning (ML) have\ninvestigated problem-space attacks, focusing on the generation of real evasive\nobjects in domains where, unlike images, there is no clear inverse mapping to\nthe feature space (e.g., software). However, the design, comparison, and\nreal-world implications of problem-space attacks remain underexplored. This\narticle makes three major contributions. Firstly, we propose a general\nformalization for adversarial ML evasion attacks in the problem-space, which\nincludes the definition of a comprehensive set of constraints on available\ntransformations, preserved semantics, absent artifacts, and plausibility. We\nshed light on the relationship between feature space and problem space, and we\nintroduce the concept of side-effect features as the by-product of the inverse\nfeature-mapping problem. This enables us to define and prove necessary and\nsufficient conditions for the existence of problem-space attacks. Secondly,\nbuilding on our general formalization, we propose a novel problem-space attack\non Android malware that overcomes past limitations in terms of semantics and\nartifacts. We have tested our approach on a dataset with 150K Android apps from\n2016 and 2018 which show the practical feasibility of evading a\nstate-of-the-art malware classifier along with its hardened version. Thirdly,\nwe explore the effectiveness of adversarial training as a possible approach to\nenforce robustness against adversarial samples, evaluating its effectiveness on\nthe considered machine learning models under different scenarios. Our results\ndemonstrate that \"adversarial-malware as a service\" is a realistic threat, as\nwe automatically generate thousands of realistic and inconspicuous adversarial\napplications at scale, where on average it takes only a few minutes to generate\nan adversarial instance.\n","authors":["Jacopo Cortellazzi","Feargus Pendlebury","Daniel Arp","Erwin Quiring","Fabio Pierazzi","Lorenzo Cavallaro"],"pdf_url":"https://arxiv.org/pdf/1911.02142v3.pdf","comment":"This arXiv version (v3) corresponds to an extended version"},{"id":"http://arxiv.org/abs/2406.19579v1","updated":"2024-06-27T23:57:01Z","published":"2024-06-27T23:57:01Z","title":"Private Zeroth-Order Nonsmooth Nonconvex Optimization","summary":"  We introduce a new zeroth-order algorithm for private stochastic optimization\non nonconvex and nonsmooth objectives. Given a dataset of size $M$, our\nalgorithm ensures $(\\alpha,\\alpha\\rho^2/2)$-R\\'enyi differential privacy and\nfinds a $(\\delta,\\epsilon)$-stationary point so long as\n$M=\\tilde\\Omega\\left(\\frac{d}{\\delta\\epsilon^3} +\n\\frac{d^{3/2}}{\\rho\\delta\\epsilon^2}\\right)$. This matches the optimal\ncomplexity of its non-private zeroth-order analog. Notably, although the\nobjective is not smooth, we have privacy ``for free'' whenever $\\rho \\ge\n\\sqrt{d}\\epsilon$.\n","authors":["Qinzi Zhang","Hoang Tran","Ashok Cutkosky"],"pdf_url":"https://arxiv.org/pdf/2406.19579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19578v1","updated":"2024-06-27T23:43:36Z","published":"2024-06-27T23:43:36Z","title":"PathAlign: A vision-language model for whole slide images in\n  histopathology","summary":"  Microscopic interpretation of histopathology images underlies many important\ndiagnostic and treatment decisions. While advances in vision-language modeling\nraise new opportunities for analysis of such images, the gigapixel-scale size\nof whole slide images (WSIs) introduces unique challenges. Additionally,\npathology reports simultaneously highlight key findings from small regions\nwhile also aggregating interpretation across multiple slides, often making it\ndifficult to create robust image-text pairs. As such, pathology reports remain\na largely untapped source of supervision in computational pathology, with most\nefforts relying on region-of-interest annotations or self-supervision at the\npatch-level. In this work, we develop a vision-language model based on the\nBLIP-2 framework using WSIs paired with curated text from pathology reports.\nThis enables applications utilizing a shared image-text embedding space, such\nas text or image retrieval for finding cases of interest, as well as\nintegration of the WSI encoder with a frozen large language model (LLM) for\nWSI-based generative text capabilities such as report generation or\nAI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000\nWSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure\ntypes, and tissue types. We present pathologist evaluation of text generation\nand text retrieval using WSI embeddings, as well as results for WSI\nclassification and workflow prioritization (slide-level triaging).\nModel-generated text for WSIs was rated by pathologists as accurate, without\nclinically significant error or omission, for 78% of WSIs on average. This work\ndemonstrates exciting potential capabilities for language-aligned WSI\nembeddings.\n","authors":["Faruk Ahmed","Andrew Sellergren","Lin Yang","Shawn Xu","Boris Babenko","Abbi Ward","Niels Olson","Arash Mohtashamian","Yossi Matias","Greg S. Corrado","Quang Duong","Dale R. Webster","Shravya Shetty","Daniel Golden","Yun Liu","David F. Steiner","Ellery Wulczyn"],"pdf_url":"https://arxiv.org/pdf/2406.19578v1.pdf","comment":"9 main pages and 19 pages of supplemental material; 3 main tables, 3\n  main figures and 11 supplemental tables, 7 supplemental figures"},{"id":"http://arxiv.org/abs/2406.19574v1","updated":"2024-06-27T23:26:57Z","published":"2024-06-27T23:26:57Z","title":"Deep Temporal Sequence Classification and Mathematical Modeling for Cell\n  Tracking in Dense 3D Microscopy Videos of Bacterial Biofilms","summary":"  Automatic cell tracking in dense environments is plagued by inaccurate\ncorrespondences and misidentification of parent-offspring relationships. In\nthis paper, we introduce a novel cell tracking algorithm named DenseTrack,\nwhich integrates deep learning with mathematical model-based strategies to\neffectively establish correspondences between consecutive frames and detect\ncell division events in crowded scenarios. We formulate the cell tracking\nproblem as a deep learning-based temporal sequence classification task followed\nby solving a constrained one-to-one matching optimization problem exploiting\nthe classifier's confidence scores. Additionally, we present an\neigendecomposition-based cell division detection strategy that leverages\nknowledge of cellular geometry. The performance of the proposed approach has\nbeen evaluated by tracking densely packed cells in 3D time-lapse image\nsequences of bacterial biofilm development. The experimental results on\nsimulated as well as experimental fluorescence image sequences suggest that the\nproposed tracking method achieves superior performance in terms of both\nqualitative and quantitative evaluation measures compared to recent\nstate-of-the-art cell tracking approaches.\n","authors":["Tanjin Taher Toma","Yibo Wang","Andreas Gahlmann","Scott T. Acton"],"pdf_url":"https://arxiv.org/pdf/2406.19574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19573v1","updated":"2024-06-27T23:25:57Z","published":"2024-06-27T23:25:57Z","title":"On Counterfactual Interventions in Vector Autoregressive Models","summary":"  Counterfactual reasoning allows us to explore hypothetical scenarios in order\nto explain the impacts of our decisions. However, addressing such inquires is\nimpossible without establishing the appropriate mathematical framework. In this\nwork, we introduce the problem of counterfactual reasoning in the context of\nvector autoregressive (VAR) processes. We also formulate the inference of a\ncausal model as a joint regression task where for inference we use both data\nwith and without interventions. After learning the model, we exploit linearity\nof the VAR model to make exact predictions about the effects of counterfactual\ninterventions. Furthermore, we quantify the total causal effects of past\ncounterfactual interventions. The source code for this project is freely\navailable at https://github.com/KurtButler/counterfactual_interventions.\n","authors":["Kurt Butler","Marija Iloska","Petar M. Djuric"],"pdf_url":"https://arxiv.org/pdf/2406.19573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02319v2","updated":"2024-06-27T23:22:14Z","published":"2024-04-02T21:35:54Z","title":"Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient\n  Compile-Time Prompt Optimization","summary":"  In many modern LLM applications, such as retrieval augmented generation,\nprompts have become programs themselves. In these settings, prompt programs are\nrepeatedly called with different user queries or data instances. A big\npractical challenge is optimizing such prompt programs. Recent work has mostly\nfocused on either simple prompt programs or assumed that the general structure\nof a prompt program is fixed.\n  We introduce SAMMO, a framework to perform symbolic prompt program search for\ncompile-time optimizations of prompt programs. SAMMO represents prompt programs\non a symbolic level which allows for a rich set of transformations that can be\nsearched over during optimization. We show that SAMMO generalizes previous\nmethods and improves the performance of complex prompts on (1) instruction\ntuning, (2) RAG pipeline tuning, and (3) prompt compression, across several\ndifferent LLMs. We make all code available open-source at\nhttps://github.com/microsoft/sammo .\n","authors":["Tobias Schnabel","Jennifer Neville"],"pdf_url":"https://arxiv.org/pdf/2404.02319v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19566v1","updated":"2024-06-27T22:51:06Z","published":"2024-06-27T22:51:06Z","title":"Instance-Optimal Private Density Estimation in the Wasserstein Distance","summary":"  Estimating the density of a distribution from samples is a fundamental\nproblem in statistics. In many practical settings, the Wasserstein distance is\nan appropriate error metric for density estimation. For example, when\nestimating population densities in a geographic region, a small Wasserstein\ndistance means that the estimate is able to capture roughly where the\npopulation mass is. In this work we study differentially private density\nestimation in the Wasserstein distance. We design and analyze instance-optimal\nalgorithms for this problem that can adapt to easy instances.\n  For distributions $P$ over $\\mathbb{R}$, we consider a strong notion of\ninstance-optimality: an algorithm that uniformly achieves the instance-optimal\nestimation rate is competitive with an algorithm that is told that the\ndistribution is either $P$ or $Q_P$ for some distribution $Q_P$ whose\nprobability density function (pdf) is within a factor of 2 of the pdf of $P$.\nFor distributions over $\\mathbb{R}^2$, we use a different notion of instance\noptimality. We say that an algorithm is instance-optimal if it is competitive\nwith an algorithm that is given a constant-factor multiplicative approximation\nof the density of the distribution. We characterize the instance-optimal\nestimation rates in both these settings and show that they are uniformly\nachievable (up to polylogarithmic factors). Our approach for $\\mathbb{R}^2$\nextends to arbitrary metric spaces as it goes via hierarchically separated\ntrees. As a special case our results lead to instance-optimal private learning\nin TV distance for discrete distributions.\n","authors":["Vitaly Feldman","Audra McMillan","Satchit Sivakumar","Kunal Talwar"],"pdf_url":"https://arxiv.org/pdf/2406.19566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.10563v3","updated":"2024-06-27T22:40:45Z","published":"2023-09-19T12:18:28Z","title":"A Hierarchical Neural Framework for Classification and its Explanation\n  in Large Unstructured Legal Documents","summary":"  Automatic legal judgment prediction and its explanation suffer from the\nproblem of long case documents exceeding tens of thousands of words, in\ngeneral, and having a non-uniform structure. Predicting judgments from such\ndocuments and extracting their explanation becomes a challenging task, more so\non documents with no structural annotation. We define this problem as \"scarce\nannotated legal documents\" and explore their lack of structural information and\ntheir long lengths with a deep-learning-based classification framework which we\ncall MESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment\nprediction. We explore the adaptability of LLMs with multi-billion parameters\n(GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer\nlearning capacity. Alongside this, we compare their performance and\nadaptability with MESc and the impact of combining embeddings from their last\nlayers. For such hierarchical models, we also propose an explanation extraction\nalgorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor;\nbased on the input-occlusion sensitivity of the model, to explain the\npredictions with the most relevant sentences from the document. We explore\nthese methods and test their effectiveness with extensive experiments and\nablation studies on legal documents from India, the European Union, and the\nUnited States with the ILDC dataset and a subset of the LexGLUE dataset. MESc\nachieves a minimum total performance gain of approximately 2 points over\nprevious state-of-the-art proposed methods, while ORSE applied on MESc achieves\na total average gain of 50% over the baseline explainability scores.\n","authors":["Nishchal Prasad","Mohand Boughanem","Taoufik Dkaki"],"pdf_url":"https://arxiv.org/pdf/2309.10563v3.pdf","comment":"Published as non archival paper in the The 3rd International Workshop\n  on Mining and Learning in the Legal Domain (MLLD-2023) at CIKM 2023,\n  Birmingham, United Kingdom. (https://sites.google.com/view/mlld2023/)"},{"id":"http://arxiv.org/abs/2406.19561v1","updated":"2024-06-27T22:24:46Z","published":"2024-06-27T22:24:46Z","title":"Meta-Gradient Search Control: A Method for Improving the Efficiency of\n  Dyna-style Planning","summary":"  We study how a Reinforcement Learning (RL) system can remain sample-efficient\nwhen learning from an imperfect model of the environment. This is particularly\nchallenging when the learning system is resource-constrained and in continual\nsettings, where the environment dynamics change. To address these challenges,\nour paper introduces an online, meta-gradient algorithm that tunes a\nprobability with which states are queried during Dyna-style planning. Our study\ncompares the aggregate, empirical performance of this meta-gradient method to\nbaselines that employ conventional sampling strategies. Results indicate that\nour method improves efficiency of the planning process, which, as a\nconsequence, improves the sample-efficiency of the overall learning process. On\nthe whole, we observe that our meta-learned solutions avoid several pathologies\nof conventional planning approaches, such as sampling inaccurate transitions\nand those that stall credit assignment. We believe these findings could prove\nuseful, in future work, for designing model-based RL systems at scale.\n","authors":["Bradley Burega","John D. Martin","Luke Kapeluck","Michael Bowling"],"pdf_url":"https://arxiv.org/pdf/2406.19561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19560v1","updated":"2024-06-27T22:19:19Z","published":"2024-06-27T22:19:19Z","title":"Cost-efficient Active Illumination Camera For Hyper-spectral\n  Reconstruction","summary":"  Hyper-spectral imaging has recently gained increasing attention for use in\ndifferent applications, including agricultural investigation, ground tracking,\nremote sensing and many other. However, the high cost, large physical size and\ncomplicated operation process stop hyperspectral cameras from being employed\nfor various applications and research fields. In this paper, we introduce a\ncost-efficient, compact and easy to use active illumination camera that may\nbenefit many applications. We developed a fully functional prototype of such\ncamera. With the hope of helping with agricultural research, we tested our\ncamera for plant root imaging. In addition, a U-Net model for spectral\nreconstruction was trained by using a reference hyperspectral camera's data as\nground truth and our camera's data as input. We demonstrated our camera's\nability to obtain additional information over a typical RGB camera. In\naddition, the ability to reconstruct hyperspectral data from multi-spectral\ninput makes our device compatible to models and algorithms developed for\nhyperspectral applications with no modifications required.\n","authors":["Yuxuan Zhang","T. M. Sazzad","Yangyang Song","Spencer J. Chang","Ritesh Chowdhry","Tomas Mejia","Anna Hampton","Shelby Kucharski","Stefan Gerber","Barry Tillman","Marcio F. R. Resende","William M. Hammond","Chris H. Wilson","Alina Zare","Sanjeev J. Koppal"],"pdf_url":"https://arxiv.org/pdf/2406.19560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19556v1","updated":"2024-06-27T22:16:53Z","published":"2024-06-27T22:16:53Z","title":"BOrg: A Brain Organoid-Based Mitosis Dataset for Automatic Analysis of\n  Brain Diseases","summary":"  Recent advances have enabled the study of human brain development using brain\norganoids derived from stem cells. Quantifying cellular processes like mitosis\nin these organoids offers insights into neurodevelopmental disorders, but the\nmanual analysis is time-consuming, and existing datasets lack specific details\nfor brain organoid studies. We introduce BOrg, a dataset designed to study\nmitotic events in the embryonic development of the brain using confocal\nmicroscopy images of brain organoids. BOrg utilizes an efficient annotation\npipeline with sparse point annotations and techniques that minimize expert\neffort, overcoming limitations of standard deep learning approaches on sparse\ndata. We adapt and benchmark state-of-the-art object detection and cell\ncounting models on BOrg for detecting and analyzing mitotic cells across\nprophase, metaphase, anaphase, and telophase stages. Our results demonstrate\nthese adapted models significantly improve mitosis analysis efficiency and\naccuracy for brain organoid research compared to existing methods. BOrg\nfacilitates the development of automated tools to quantify statistics like\nmitosis rates, aiding mechanistic studies of neurodevelopmental processes and\ndisorders. Data and code are available at https://github.com/awaisrauf/borg.\n","authors":["Muhammad Awais","Mehaboobathunnisa Sahul Hameed","Bidisha Bhattacharya","Orly Reiner","Rao Muhammad Anwer"],"pdf_url":"https://arxiv.org/pdf/2406.19556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19552v1","updated":"2024-06-27T22:08:22Z","published":"2024-06-27T22:08:22Z","title":"Rethinking harmless refusals when fine-tuning foundation models","summary":"  In this paper, we investigate the degree to which fine-tuning in Large\nLanguage Models (LLMs) effectively mitigates versus merely conceals undesirable\nbehavior. Through the lens of semi-realistic role-playing exercises designed to\nelicit such behaviors, we explore the response dynamics of LLMs post\nfine-tuning interventions. Our methodology involves prompting models for\nChain-of-Thought (CoT) reasoning and analyzing the coherence between the\nreasoning traces and the resultant outputs. Notably, we identify a pervasive\nphenomenon we term \\emph{reason-based deception}, where models either stop\nproducing reasoning traces or produce seemingly ethical reasoning traces that\nbelie the unethical nature of their final outputs. We further examine the\nefficacy of response strategies (polite refusal versus explicit rebuttal) in\ncurbing the occurrence of undesired behavior in subsequent outputs of\nmulti-turn interactions. Our findings reveal that explicit rebuttals\nsignificantly outperform polite refusals in preventing the continuation of\nundesired outputs and nearly eliminate reason-based deception, challenging\ncurrent practices in model fine-tuning. Accordingly, the two key contributions\nof this paper are (1) defining and studying reason-based deception, a new type\nof hidden behavior, and (2) demonstrating that rebuttals provide a more robust\nresponse model to harmful requests than refusals, thereby highlighting the need\nto reconsider the response strategies in fine-tuning approaches.\n","authors":["Florin Pop","Judd Rosenblatt","Diogo Schwerz de Lucena","Michael Vaiana"],"pdf_url":"https://arxiv.org/pdf/2406.19552v1.pdf","comment":"ICLR 2024 AGI Workshop Poster"},{"id":"http://arxiv.org/abs/2406.09606v2","updated":"2024-06-27T22:06:19Z","published":"2024-06-13T22:34:58Z","title":"Cross-Modality Program Representation Learning for Electronic Design\n  Automation with High-Level Synthesis","summary":"  In recent years, domain-specific accelerators (DSAs) have gained popularity\nfor applications such as deep learning and autonomous driving. To facilitate\nDSA designs, programmers use high-level synthesis (HLS) to compile a high-level\ndescription written in C/C++ into a design with low-level hardware description\nlanguages that eventually synthesize DSAs on circuits. However, creating a\nhigh-quality HLS design still demands significant domain knowledge,\nparticularly in microarchitecture decisions expressed as \\textit{pragmas}.\nThus, it is desirable to automate such decisions with the help of machine\nlearning for predicting the quality of HLS designs, requiring a deeper\nunderstanding of the program that consists of original code and pragmas.\nNaturally, these programs can be considered as sequence data. In addition,\nthese programs can be compiled and converted into a control data flow graph\n(CDFG). But existing works either fail to leverage both modalities or combine\nthe two in shallow or coarse ways. We propose ProgSG, a model that allows\ninteraction between the source code sequence modality and the graph modality in\na deep and fine-grained way. To alleviate the scarcity of labeled designs, a\npre-training method is proposed based on a suite of compiler's data flow\nanalysis tasks. Experimental results show that ProgSG reduces the RMSE of\ndesign performance predictions by up to $22\\%$, and identifies designs with an\naverage of $1.10\\times$ and $1.26\\times$ (up to $8.17\\times$ and $13.31\\times$)\nperformance improvement in design space exploration (DSE) task compared to HARP\nand AutoDSE, respectively.\n","authors":["Zongyue Qin","Yunsheng Bai","Atefeh Sohrabizadeh","Zijian Ding","Ziniu Hu","Yizhou Sun","Jason Cong"],"pdf_url":"https://arxiv.org/pdf/2406.09606v2.pdf","comment":"14 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2305.10838"},{"id":"http://arxiv.org/abs/2406.19549v1","updated":"2024-06-27T22:01:00Z","published":"2024-06-27T22:01:00Z","title":"ASCENT: Amplifying Power Side-Channel Resilience via Learning &\n  Monte-Carlo Tree Search","summary":"  Power side-channel (PSC) analysis is pivotal for securing cryptographic\nhardware. Prior art focused on securing gate-level netlists obtained as-is from\nchip design automation, neglecting all the complexities and potential\nside-effects for security arising from the design automation process. That is,\nautomation traditionally prioritizes power, performance, and area (PPA),\nsidelining security. We propose a \"security-first\" approach, refining the logic\nsynthesis stage to enhance the overall resilience of PSC countermeasures. We\nintroduce ASCENT, a learning-and-search-based framework that (i) drastically\nreduces the time for post-design PSC evaluation and (ii) explores the\nsecurity-vs-PPA design space. Thus, ASCENT enables an efficient exploration of\na large number of candidate netlists, leading to an improvement in PSC\nresilience compared to regular PPA-optimized netlists. ASCENT is up to 120x\nfaster than traditional PSC analysis and yields a 3.11x improvement for PSC\nresilience of state-of-the-art PSC countermeasures\n","authors":["Jitendra Bhandari","Animesh Basak Chowdhury","Ozgur Sinanoglu","Siddharth Garg","Ramesh Karri","Johann Knechtel"],"pdf_url":"https://arxiv.org/pdf/2406.19549v1.pdf","comment":"Accepted at 2024 ACM/IEEE International Conference on Computer-Aided\n  Design"},{"id":"http://arxiv.org/abs/2404.05891v2","updated":"2024-06-27T21:54:40Z","published":"2024-04-08T22:20:23Z","title":"Condition Monitoring with Incomplete Data: An Integrated Variational\n  Autoencoder and Distance Metric Framework","summary":"  Condition monitoring of industrial systems is crucial for ensuring safety and\nmaintenance planning, yet notable challenges arise in real-world settings due\nto the limited or non-existent availability of fault samples. This paper\nintroduces an innovative solution to this problem by proposing a new method for\nfault detection and condition monitoring for unseen data. Adopting an approach\ninspired by zero-shot learning, our method can identify faults and assign a\nrelative health index to various operational conditions. Typically, we have\nplenty of data on normal operations, some data on compromised conditions, and\nvery few (if any) samples of severe faults. We use a variational autoencoder to\ncapture the probabilistic distribution of previously seen and new unseen\nconditions. The health status is determined by comparing each sample's\ndeviation from a normal operation reference distribution in the latent space.\nFaults are detected by establishing a threshold for the health indexes,\nallowing the model to identify severe, unseen faults with high accuracy, even\namidst noise. We validate our approach using the run-to-failure IMS-bearing\ndataset and compare it with other methods. The health indexes generated by our\nmodel closely match the established descriptive model of bearing wear,\nattesting to the robustness and reliability of our method. These findings\nhighlight the potential of our methodology in augmenting fault detection\ncapabilities within industrial domains, thereby contributing to heightened\nsafety protocols and optimized maintenance practices.\n","authors":["Maryam Ahang","Mostafa Abbasi","Todd Charter","Homayoun Najjaran"],"pdf_url":"https://arxiv.org/pdf/2404.05891v2.pdf","comment":"Accepted in the 2024 IEEE 20th International Conference on Automation\n  Science and Engineering (CASE 2024)"},{"id":"http://arxiv.org/abs/2406.19532v1","updated":"2024-06-27T21:12:48Z","published":"2024-06-27T21:12:48Z","title":"Dataless Quadratic Neural Networks for the Maximum Independent Set\n  Problem","summary":"  Combinatorial Optimization (CO) plays a crucial role in addressing various\nsignificant problems, among them the challenging Maximum Independent Set (MIS)\nproblem. In light of recent advancements in deep learning methods, efforts have\nbeen directed towards leveraging data-driven learning approaches, typically\nrooted in supervised learning and reinforcement learning, to tackle the NP-hard\nMIS problem. However, these approaches rely on labeled datasets, exhibit weak\ngeneralization, and often depend on problem-specific heuristics. Recently,\nReLU-based dataless neural networks were introduced to address combinatorial\noptimization problems. This paper introduces a novel dataless quadratic neural\nnetwork formulation, featuring a continuous quadratic relaxation for the MIS\nproblem. Notably, our method eliminates the need for training data by treating\nthe given MIS instance as a trainable entity. More specifically, the graph\nstructure and constraints of the MIS instance are used to define the structure\nand parameters of the neural network such that training it on a fixed input\nprovides a solution to the problem, thereby setting it apart from traditional\nsupervised or reinforcement learning approaches. By employing a gradient-based\noptimization algorithm like ADAM and leveraging an efficient off-the-shelf GPU\nparallel implementation, our straightforward yet effective approach\ndemonstrates competitive or superior performance compared to state-of-the-art\nlearning-based methods. Another significant advantage of our approach is that,\nunlike exact and heuristic solvers, the running time of our method scales only\nwith the number of nodes in the graph, not the number of edges.\n","authors":["Ismail Alkhouri","Cedric Le Denmat","Yingjie Li","Cunxi Yu","Jia Liu","Rongrong Wang","Alvaro Velasquez"],"pdf_url":"https://arxiv.org/pdf/2406.19532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19531v1","updated":"2024-06-27T21:12:26Z","published":"2024-06-27T21:12:26Z","title":"Forward and Backward State Abstractions for Off-policy Evaluation","summary":"  Off-policy evaluation (OPE) is crucial for evaluating a target policy's\nimpact offline before its deployment. However, achieving accurate OPE in large\nstate spaces remains challenging.This paper studies state\nabstractions-originally designed for policy learning-in the context of OPE. Our\ncontributions are three-fold: (i) We define a set of irrelevance conditions\ncentral to learning state abstractions for OPE. (ii) We derive sufficient\nconditions for achieving irrelevance in Q-functions and marginalized importance\nsampling ratios, the latter obtained by constructing a time-reversed Markov\ndecision process (MDP) based on the observed MDP. (iii) We propose a novel\ntwo-step procedure that sequentially projects the original state space into a\nsmaller space, which substantially simplify the sample complexity of OPE\narising from high cardinality.\n","authors":["Meiling Hao","Pingfan Su","Liyuan Hu","Zoltan Szabo","Qingyuan Zhao","Chengchun Shi"],"pdf_url":"https://arxiv.org/pdf/2406.19531v1.pdf","comment":"42 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.19526v1","updated":"2024-06-27T20:56:57Z","published":"2024-06-27T20:56:57Z","title":"TocBERT: Medical Document Structure Extraction Using Bidirectional\n  Transformers","summary":"  Text segmentation holds paramount importance in the field of Natural Language\nProcessing (NLP). It plays an important role in several NLP downstream tasks\nlike information retrieval and document summarization. In this work, we propose\na new solution, namely TocBERT, for segmenting texts using bidirectional\ntransformers. TocBERT represents a supervised solution trained on the detection\nof titles and sub-titles from their semantic representations. This task was\nformulated as a named entity recognition (NER) problem. The solution has been\napplied on a medical text segmentation use-case where the Bio-ClinicalBERT\nmodel is fine-tuned to segment discharge summaries of the MIMIC-III dataset.\nThe performance of TocBERT has been evaluated on a human-labeled ground truth\ncorpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a\nlinear text segmentation problem and 72.8% on a hierarchical text segmentation\nproblem. It outperformed a carefully designed rule-based solution, particularly\nin distinguishing titles from subtitles.\n","authors":["Majd Saleh","Sarra Baghdadi","Stéphane Paquelet"],"pdf_url":"https://arxiv.org/pdf/2406.19526v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2312.00246v3","updated":"2024-06-27T20:51:56Z","published":"2023-11-30T23:24:45Z","title":"Directions of Curvature as an Explanation for Loss of Plasticity","summary":"  Loss of plasticity is a phenomenon in which neural networks lose their\nability to learn from new experience. Despite being empirically observed in\nseveral problem settings, little is understood about the mechanisms that lead\nto loss of plasticity. In this paper, we offer a consistent explanation for\nloss of plasticity: Neural networks lose directions of curvature during\ntraining and that loss of plasticity can be attributed to this reduction in\ncurvature. To support such a claim, we provide a systematic investigation of\nloss of plasticity across continual learning tasks using MNIST, CIFAR-10 and\nImageNet. Our findings illustrate that loss of curvature directions coincides\nwith loss of plasticity, while also showing that previous explanations are\ninsufficient to explain loss of plasticity in all settings. Lastly, we show\nthat regularizers which mitigate loss of plasticity also preserve curvature,\nmotivating a simple distributional regularizer that proves to be effective\nacross the problem settings we considered.\n","authors":["Alex Lewandowski","Haruto Tanaka","Dale Schuurmans","Marlos C. Machado"],"pdf_url":"https://arxiv.org/pdf/2312.00246v3.pdf","comment":null}],"Robotics":[{"id":"http://arxiv.org/abs/2404.02795v2","updated":"2024-06-27T17:52:25Z","published":"2024-04-03T15:02:03Z","title":"Robust Pushing: Exploiting Quasi-static Belief Dynamics and\n  Contact-informed Optimization","summary":"  Non-prehensile manipulation such as pushing is typically subject to\nuncertain, non-smooth dynamics. However, modeling the uncertainty of the\ndynamics typically results in intractable belief dynamics, making\ndata-efficient planning under uncertainty difficult. This article focuses on\nthe problem of efficiently generating robust open-loop pushing plans. First, we\ninvestigate how the belief over object configurations propagates through\nquasi-static contact dynamics. We exploit the simplified dynamics to predict\nthe variance of the object configuration without sampling from a perturbation\ndistribution. In a sampling-based trajectory optimization algorithm, the gain\nof the variance is constrained in order to enforce robustness of the plan.\nSecond, we propose an informed trajectory sampling mechanism for drawing robot\ntrajectories that are likely to make contact with the object. This sampling\nmechanism is shown to significantly improve chances of finding robust\nsolutions, especially when making-and-breaking contacts is required. We\ndemonstrate that the proposed approach is able to synthesize bi-manual pushing\ntrajectories, resulting in successful long-horizon pushing maneuvers without\nexteroceptive feedback such as vision or tactile feedback. We furthermore\ndeploy the proposed approach in a model-predictive control scheme,\ndemonstrating additional robustness against unmodeled perturbations.\n","authors":["Julius Jankowski","Lara Brudermüller","Nick Hawes","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2404.02795v2.pdf","comment":"submitted to the International Journal of Robotics Research (IJRR)"},{"id":"http://arxiv.org/abs/2405.04188v2","updated":"2024-06-27T17:44:36Z","published":"2024-05-07T10:48:37Z","title":"Systematically Exploring the Landscape of Grasp Affordances via\n  Behavioral Manifolds","summary":"  The use of machine learning to investigate grasp affordances has received\nextensive attention over the past several decades. The existing literature\nprovides a robust basis to build upon, though a number of aspects may be\nimproved. Results commonly work in terms of grasp configuration, with little\nconsideration for the manner in which the grasp may be (re-)produced from a\nreachability and trajectory planning perspective. In addition, the majority of\nexisting learning approaches focus of producing a single viable grasp, offering\nlittle transparency on how the result was reached, or insights on its\nrobustness. We propose a different perspective on grasp affordance learning,\nexplicitly accounting for grasp synthesis; that is, the manner in which\nmanipulator kinematics are used to allow materialization of grasps. The\napproach allows to explicitly map the grasp policy space in terms of generated\ngrasp types and associated grasp quality. Results of numerical simulations\nillustrate merit of the method and highlight the manner in which it may promote\na greater degree of explainability for otherwise intransparent reinforcement\nprocesses.\n","authors":["Michael Zechmair","Yannick Morel"],"pdf_url":"https://arxiv.org/pdf/2405.04188v2.pdf","comment":"12pages"},{"id":"http://arxiv.org/abs/2406.19323v1","updated":"2024-06-27T16:54:56Z","published":"2024-06-27T16:54:56Z","title":"Multimodal Visual-haptic pose estimation in the presence of transient\n  occlusion","summary":"  Human-robot collaboration requires the establishment of methods to guarantee\nthe safety of participating operators. A necessary part of this process is\nensuring reliable human pose estimation. Established vision-based modalities\nencounter problems when under conditions of occlusion. This article describes\nthe combination of two perception modalities for pose estimation in\nenvironments containing such transient occlusion. We first introduce a\nvision-based pose estimation method, based on a deep Predictive Coding (PC)\nmodel featuring robustness to partial occlusion. Next, capacitive sensing\nhardware capable of detecting various objects is introduced. The sensor is\ncompact enough to be mounted on the exterior of any given robotic system. The\ntechnology is particularly well-suited to detection of capacitive material,\nsuch as living tissue. Pose estimation from the two individual sensing\nmodalities is combined using a modified Luenberger observer model. We\ndemonstrate that the results offer better performance than either sensor alone.\nThe efficacy of the system is demonstrated on an environment containing a robot\narm and a human, showing the ability to estimate the pose of a human forearm\nunder varying levels of occlusion.\n","authors":["Michael Zechmair","Yannick Morel"],"pdf_url":"https://arxiv.org/pdf/2406.19323v1.pdf","comment":"12 pages. arXiv admin note: text overlap with arXiv:2310.18009"},{"id":"http://arxiv.org/abs/2402.12315v2","updated":"2024-06-27T15:13:09Z","published":"2024-02-19T17:37:11Z","title":"Cosserat Rod Modeling and Validation for a Soft Continuum Robot with\n  Self-Controllable Variable Curvature","summary":"  This paper introduces a Cosserat rod based mathematical model for modeling a\nself-controllable variable curvature soft continuum robot. This soft continuum\nrobot has a hollow inner channel and was developed with the ability to perform\nvariable curvature utilizing a growing spine. The growing spine is able to grow\nand retract while modifies its stiffness through milli-size particle (glass\nbubble) granular jamming. This soft continuum robot can then perform continuous\ncurvature variation, unlike previous approaches whose curvature variation is\ndiscrete and depends on the number of locking mechanisms or manual\nconfigurations. The robot poses an emergent modeling problem due to the\nvariable stiffness growing spine which is addressed in this paper. We\ninvestigate the property of growing spine stiffness and incorporate it into the\nCosserat rod model by implementing a combined stiffness approach. We conduct\nexperiments with the soft continuum robot in various configurations and\ncompared the results with our developed mathematical model. The results show\nthat the mathematical model based on the adapted Cosserat rod matches the\nexperimental results with only a 3.3\\% error with respect to the length of the\nsoft continuum robot.\n","authors":["Xinran Wang","Nicolas Rojas"],"pdf_url":"https://arxiv.org/pdf/2402.12315v2.pdf","comment":"Accepted for IEEE RoboSoft Conference 2024, April 14-17"},{"id":"http://arxiv.org/abs/2406.19236v1","updated":"2024-06-27T15:01:42Z","published":"2024-06-27T15:01:42Z","title":"Human-Aware Vision-and-Language Navigation: Bridging Simulation to\n  Reality with Dynamic Human Interactions","summary":"  Vision-and-Language Navigation (VLN) aims to develop embodied agents that\nnavigate based on human instructions. However, current VLN frameworks often\nrely on static environments and optimal expert supervision, limiting their\nreal-world applicability. To address this, we introduce Human-Aware\nVision-and-Language Navigation (HA-VLN), extending traditional VLN by\nincorporating dynamic human activities and relaxing key assumptions. We propose\nthe Human-Aware 3D (HA3D) simulator, which combines dynamic human activities\nwith the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)\ndataset, extending R2R with human activity descriptions. To tackle HA-VLN\nchallenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and\nNon-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing\ncross-modal fusion and diverse training strategies for effective navigation in\ndynamic human environments. A comprehensive evaluation, including metrics\nconsidering human activities, and systematic analysis of HA-VLN's unique\nchallenges, underscores the need for further research to enhance HA-VLN agents'\nreal-world robustness and adaptability. Ultimately, this work provides\nbenchmarks and insights for future research on embodied AI and Sim2Real\ntransfer, paving the way for more realistic and applicable VLN systems in\nhuman-populated environments.\n","authors":["Minghan Li","Heng Li","Zhi-Qi Cheng","Yifei Dong","Yuxuan Zhou","Jun-Yan He","Qi Dai","Teruko Mitamura","Alexander G. Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2406.19236v1.pdf","comment":"30 pages, 18 figures, Project Page:\n  https://lpercc.github.io/HA3D_simulator/"},{"id":"http://arxiv.org/abs/2308.00911v3","updated":"2024-06-27T14:47:37Z","published":"2023-08-02T02:37:24Z","title":"Optimal Sensor Deception to Deviate from an Allowed Itinerary","summary":"  In this work, we study a class of deception planning problems in which an\nagent aims to alter a security monitoring system's sensor readings so as to\ndisguise its adversarial itinerary as an allowed itinerary in the environment.\nThe adversarial itinerary set and allowed itinerary set are captured by regular\nlanguages. To deviate without being detected, we investigate whether there\nexists a strategy for the agent to alter the sensor readings, with a minimal\ncost, such that for any of those paths it takes, the system thinks the agent\ntook a path within the allowed itinerary. Our formulation assumes an offline\nsensor alteration where the agent determines the sensor alteration strategy and\nimplement it, and then carry out any path in its deviation itinerary. We prove\nthat the problem of solving the optimal sensor alteration is NP-hard, by a\nreduction from the directed multi-cut problem. Further, we present an exact\nalgorithm based on integer linear programming and demonstrate the correctness\nand the efficacy of the algorithm in case studies.\n","authors":["Hazhar Rahmani","Arash Ahadi","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2308.00911v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19217v1","updated":"2024-06-27T14:43:50Z","published":"2024-06-27T14:43:50Z","title":"Think Step by Step: Chain-of-Gesture Prompting for Error Detection in\n  Robotic Surgical Videos","summary":"  Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable.\n","authors":["Zhimin Shao","Jialang Xu","Danail Stoyanov","Evangelos B. Mazomenos","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2406.19217v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.07474v2","updated":"2024-06-27T13:17:58Z","published":"2024-05-13T05:23:48Z","title":"Integrating Intent Understanding and Optimal Behavior Planning for\n  Behavior Tree Generation from Human Instructions","summary":"  Robots executing tasks following human instructions in domestic or industrial\nenvironments essentially require both adaptability and reliability. Behavior\nTree (BT) emerges as an appropriate control architecture for these scenarios\ndue to its modularity and reactivity. Existing BT generation methods, however,\neither do not involve interpreting natural language or cannot theoretically\nguarantee the BTs' success. This paper proposes a two-stage framework for BT\ngeneration, which first employs large language models (LLMs) to interpret goals\nfrom high-level instructions, then constructs an efficient goal-specific BT\nthrough the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent\ngoals as well-formed formulas in first-order logic, effectively bridging intent\nunderstanding and optimal behavior planning. Experiments in the service robot\nvalidate the proficiency of LLMs in producing grammatically correct and\naccurately interpreted goals, demonstrate OBTEA's superiority over the baseline\nBT Expansion algorithm in various metrics, and finally confirm the practical\ndeployability of our framework. The project website is\nhttps://dids-ei.github.io/Project/LLM-OBTEA/.\n","authors":["Xinglin Chen","Yishuai Cai","Yunxin Mao","Minglong Li","Wenjing Yang","Weixia Xu","Ji Wang"],"pdf_url":"https://arxiv.org/pdf/2405.07474v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18388v2","updated":"2024-06-27T13:13:12Z","published":"2024-06-26T14:30:51Z","title":"SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and\n  Real-time Hysteresis Compensation Control Algorithm","summary":"  Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via\nnatural orifices and improve target lesion accessibility through curved paths.\nHowever, CDCMs face limitations in workspace and control accuracy due to\nnon-linear cable effects causing hysteresis. This paper introduces an\nextensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via\ntranslational motion without additional mechanical elements or actuation. We\ncollect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Based\non this dataset, we develop a real-time hysteresis compensation control\nalgorithm using the trained Temporal Convolutional Network (TCN) with a 1ms\ntime latency, effectively estimating the manipulator's hysteresis behavior.\nPerformance validation through random trajectory tracking tests and box\npointing tasks shows the proposed controller significantly reduces hysteresis\nby up to 69.5% in joint space and approximately 26% in the box pointing task.\n","authors":["Junhyun Park","Seonghyeok Jang","Myeongbo Park","Hyojae Park","Jeonghyeon Yoon","Minho Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.18388v2.pdf","comment":"12 pages, 14 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.19057v1","updated":"2024-06-27T10:08:29Z","published":"2024-06-27T10:08:29Z","title":"Segment Anything Model for automated image data annotation: empirical\n  studies using text prompts from Grounding DINO","summary":"  Grounding DINO and the Segment Anything Model (SAM) have achieved impressive\nperformance in zero-shot object detection and image segmentation, respectively.\nTogether, they have a great potential in revolutionizing zero-shot semantic\nsegmentation or data annotation. Yet, in specialized domains like medical image\nsegmentation, objects of interest (e.g., organs, tissues, and tumors) may not\nfall in existing class names. To address this problem, the referring expression\ncomprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary\ntargets by their language descriptions. However, recent studies have\nhighlighted severe limitation of the REC framework in this application setting\nowing to its tendency to make false positive predictions when the target is\nabsent in the given image. And, while this bottleneck is central to the\nprospect of open-set semantic segmentation, it is still largely unknown how\nmuch improvement can be achieved by studying the prediction errors. To this\nend, we perform empirical studies on eight publicly available datasets and\nreveal that these errors consistently follow a predictable pattern and can,\nthus, be mitigated by a simple strategy. Specifically, we show that these false\npositive detections with appreciable confidence scores generally occupy large\nimage areas and can usually be filtered by their relative sizes. More\nimportantly, we expect these observations to inspire future research in\nimproving REC-based detection and automated segmentation. Using this technique,\nwe evaluate the performance of SAM on multiple datasets from various\nspecialized domains and report significant improvement in segmentation\nperformance and annotation time savings over manual approaches.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2406.19057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19016v1","updated":"2024-06-27T09:02:02Z","published":"2024-06-27T09:02:02Z","title":"Robust Multi-Robot Global Localization with Unknown Initial Pose based\n  on Neighbor Constraints","summary":"  Multi-robot global localization (MR-GL) with unknown initial positions in a\nlarge scale environment is a challenging task. The key point is the data\nassociation between different robots' viewpoints. It also makes traditional\nAppearance-based localization methods unusable. Recently, researchers have\nutilized the object's semantic invariance to generate a semantic graph to\naddress this issue. However, previous works lack robustness and are sensitive\nto overlap rate of maps, resulting in unpredictable performance in real-world\nenvironments. In this paper, we propose a data association algorithm based on\nneighbor constraints to improve the robustness of the system. We demonstrate\nthe effectiveness of our method on three different datasets, indicating a\nsignificant improvement in robustness compared to previous works.\n","authors":["Yaojie Zhang","Haowen Luo","Weijun Wang","Wei Feng"],"pdf_url":"https://arxiv.org/pdf/2406.19016v1.pdf","comment":"7 pages (6+1), accepted by ICRA 2024"},{"id":"http://arxiv.org/abs/2406.18977v1","updated":"2024-06-27T08:13:33Z","published":"2024-06-27T08:13:33Z","title":"RoboUniView: Visual-Language Model with Unified View Representation for\n  Robotic Manipulaiton","summary":"  Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a\nnovel paradigm, aiming to enhance the model's ability to generalize to new\nobjects and instructions. However, due to variations in camera specifications\nand mounting positions, existing methods exhibit significant performance\ndisparities across different robotic platforms. To address this challenge, we\npropose RoboUniView in this paper, an innovative approach that decouples visual\nfeature extraction from action learning. We first learn a unified view\nrepresentation from multi-perspective views by pre-training on readily\naccessible data, and then derive actions from this unified view representation\nto control robotic manipulation. This unified view representation more\naccurately mirrors the physical world and is not constrained by the robotic\nplatform's camera parameters. Thanks to this methodology, we achieve\nstate-of-the-art performance on the demanding CALVIN benchmark, enhancing the\nsuccess rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to\nD$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding\nadaptability and flexibility: it maintains high performance under unseen camera\nparameters, can utilize multiple datasets with varying camera parameters, and\nis capable of joint cross-task learning across datasets. Code is provided for\nre-implementation. https://github.com/liufanfanlff/RoboUniview\n","authors":["Fanfan Liu","Feng Yan","Liming Zheng","Chengjian Feng","Yiyang Huang","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2406.18977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18924v1","updated":"2024-06-27T06:31:51Z","published":"2024-06-27T06:31:51Z","title":"Learning Pareto Set for Multi-Objective Continuous Robot Control","summary":"  For a control problem with multiple conflicting objectives, there exists a\nset of Pareto-optimal policies called the Pareto set instead of a single\noptimal policy. When a multi-objective control problem is continuous and\ncomplex, traditional multi-objective reinforcement learning (MORL) algorithms\nsearch for many Pareto-optimal deep policies to approximate the Pareto set,\nwhich is quite resource-consuming. In this paper, we propose a simple and\nresource-efficient MORL algorithm that learns a continuous representation of\nthe Pareto set in a high-dimensional policy parameter space using a single\nhypernet. The learned hypernet can directly generate various well-trained\npolicy networks for different user preferences. We compare our method with two\nstate-of-the-art MORL algorithms on seven multi-objective continuous robot\ncontrol problems. Experimental results show that our method achieves the best\noverall performance with the least training parameters. An interesting\nobservation is that the Pareto set is well approximated by a curved line or\nsurface in a high-dimensional parameter space. This observation will provide\ninsight for researchers to design new MORL algorithms.\n","authors":["Tianye Shu","Ke Shang","Cheng Gong","Yang Nan","Hisao Ishibuchi"],"pdf_url":"https://arxiv.org/pdf/2406.18924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18915v1","updated":"2024-06-27T06:12:01Z","published":"2024-06-27T06:12:01Z","title":"Manipulate-Anything: Automating Real-World Robots using Vision-Language\n  Models","summary":"  Large-scale endeavors like RT-1 and widespread community efforts such as\nOpen-X-Embodiment have contributed to growing the scale of robot demonstration\ndata. However, there is still an opportunity to improve the quality, quantity,\nand diversity of robot demonstration data. Although vision-language models have\nbeen shown to automatically generate demonstration data, their utility has been\nlimited to environments with privileged state information, they require\nhand-designed skills, and are limited to interactions with few object\ninstances. We propose Manipulate-Anything, a scalable automated generation\nmethod for real-world robotic manipulation. Unlike prior work, our method can\noperate in real-world environments without any privileged state information,\nhand-designed skills, and can manipulate any static object. We evaluate our\nmethod using two setups. First, Manipulate-Anything successfully generates\ntrajectories for all 5 real-world and 12 simulation tasks, significantly\noutperforming existing methods like VoxPoser. Second, Manipulate-Anything's\ndemonstrations can train more robust behavior cloning policies than training\nwith human demonstrations, or from data generated by VoxPoser and\nCode-As-Policies. We believe \\methodLong\\ can be the scalable method for both\ngenerating data for robotics and solving novel tasks in a zero-shot setting.\n","authors":["Jiafei Duan","Wentao Yuan","Wilbert Pumacay","Yi Ru Wang","Kiana Ehsani","Dieter Fox","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.18915v1.pdf","comment":"Project page: https://robo-point.github.io/"},{"id":"http://arxiv.org/abs/2406.18914v1","updated":"2024-06-27T06:06:37Z","published":"2024-06-27T06:06:37Z","title":"Verification and Synthesis of Compatible Control Lyapunov and Control\n  Barrier Functions","summary":"  Safety and stability are essential properties of control systems. Control\nBarrier Functions (CBFs) and Control Lyapunov Functions (CLFs) have been\nproposed to ensure safety and stability respectively. However, previous\napproaches typically verify and synthesize the CBFs and CLFs separately,\nsatisfying their respective constraints, without proving that the CBFs and CLFs\nare compatible with each other, namely at every state, there exists control\nactions that satisfy both the CBF and CLF constraints simultaneously. There\nexists some recent works that synthesized compatible CLF and CBF, but relying\non nominal polynomial or rational controllers, which is just a sufficient but\nnot necessary condition for compatibility. In this work, we investigate\nverification and synthesis of compatible CBF and CLF independent from any\nnominal controllers. We derive exact necessary and sufficient conditions for\ncompatibility, and further formulate Sum-Of-Squares program for the\ncompatibility verification. Based on our verification framework, we also design\nan alternating nominal-controller-free synthesis method. We evaluate our method\nin a linear toy, a non-linear toy, and a power converter example.\n","authors":["Hongkai Dai","Chuanrui Jiang","Hongchao Zhang","Andrew Clark"],"pdf_url":"https://arxiv.org/pdf/2406.18914v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18899v1","updated":"2024-06-27T05:27:39Z","published":"2024-06-27T05:27:39Z","title":"Autonomous Control of a Novel Closed Chain Five Bar Active Suspension\n  via Deep Reinforcement Learning","summary":"  Planetary exploration requires traversal in environments with rugged\nterrains. In addition, Mars rovers and other planetary exploration robots often\ncarry sensitive scientific experiments and components onboard, which must be\nprotected from mechanical harm. This paper deals with an active suspension\nsystem focused on chassis stabilisation and an efficient traversal method while\nencountering unavoidable obstacles. Soft Actor-Critic (SAC) was applied along\nwith Proportional Integral Derivative (PID) control to stabilise the chassis\nand traverse large obstacles at low speeds. The model uses the rover's distance\nfrom surrounding obstacles, the height of the obstacle, and the chassis'\norientation to actuate the control links of the suspension accurately.\nSimulations carried out in the Gazebo environment are used to validate the\nproposed active system.\n","authors":["Nishesh Singh","Sidharth Ramesh","Abhishek Shankar","Jyotishka Duttagupta","Leander Stephen D'Souza","Sanjay Singh"],"pdf_url":"https://arxiv.org/pdf/2406.18899v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.18850v1","updated":"2024-06-27T02:41:17Z","published":"2024-06-27T02:41:17Z","title":"RAVE: A Framework for Radar Ego-Velocity Estimation","summary":"  State estimation is an essential component of autonomous systems, usually\nrelying on sensor fusion that integrates data from cameras, LiDARs and IMUs.\nRecently, radars have shown the potential to improve the accuracy and\nrobustness of state estimation and perception, especially in challenging\nenvironmental conditions such as adverse weather and low-light scenarios. In\nthis paper, we present a framework for ego-velocity estimation, which we call\nRAVE, that relies on 3D automotive radar data and encompasses zero velocity\ndetection, outlier rejection, and velocity estimation. In addition, we propose\na simple filtering method to discard infeasible ego-velocity estimates. We also\nconduct a systematic analysis of how different existing outlier rejection\ntechniques and optimization loss functions impact estimation accuracy. Our\nevaluation on three open-source datasets demonstrates the effectiveness of the\nproposed filter and a significant positive impact of RAVE on the odometry\naccuracy. Furthermore, we release an open-source implementation of the proposed\nframework for radar ego-velocity estimation accompanied with a ROS interface.\n","authors":["Vlaho-Josip Štironja","Luka Petrović","Juraj Peršić","Ivan Marković","Ivan Petrović"],"pdf_url":"https://arxiv.org/pdf/2406.18850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20248v2","updated":"2024-06-27T02:26:39Z","published":"2024-05-30T16:59:43Z","title":"Image-to-Joint Inverse Kinematic of a Supportive Continuum Arm Using\n  Deep Learning","summary":"  In this work, a deep learning-based technique is used to study the\nimage-to-joint inverse kinematics of a tendon-driven supportive continuum arm.\nAn eye-off-hand configuration is considered by mounting a camera at a fixed\npose with respect to the inertial frame attached at the arm base. This camera\ncaptures an image for each distinct joint variable at each sampling time to\nconstruct the training dataset. This dataset is then employed to adapt a\nfeed-forward deep convolutional neural network, namely the modified VGG-16\nmodel, to estimate the joint variable. One thousand images are recorded to\ntrain the deep network, and transfer learning and fine-tuning techniques are\napplied to the modified VGG-16 to further improve the training. Finally,\ntraining is also completed with a larger dataset of images that are affected by\nvarious types of noises, changes in illumination, and partial occlusion. The\nmain contribution of this research is the development of an image-to-joint\nnetwork that can estimate the joint variable given an image of the arm, even if\nthe image is not captured in an ideal condition. The key benefits of this\nresearch are twofold: 1) image-to-joint mapping can offer a real-time\nalternative to computationally complex inverse kinematic mapping through\nanalytical models; and 2) the proposed technique can provide robustness against\nnoise, occlusion, and changes in illumination. The dataset is publicly\navailable on Kaggle.\n","authors":["Shayan Sepahvand","Guanghui Wang","Farrokh Janabi-Sharifi"],"pdf_url":"https://arxiv.org/pdf/2405.20248v2.pdf","comment":"Presented at the Candian Conference on Robots and Vision (CRV)"},{"id":"http://arxiv.org/abs/2406.18837v1","updated":"2024-06-27T02:11:33Z","published":"2024-06-27T02:11:33Z","title":"Dense Monocular Motion Segmentation Using Optical Flow and Pseudo Depth\n  Map: A Zero-Shot Approach","summary":"  Motion segmentation from a single moving camera presents a significant\nchallenge in the field of computer vision. This challenge is compounded by the\nunknown camera movements and the lack of depth information of the scene. While\ndeep learning has shown impressive capabilities in addressing these issues,\nsupervised models require extensive training on massive annotated datasets, and\nunsupervised models also require training on large volumes of unannotated data,\npresenting significant barriers for both. In contrast, traditional methods\nbased on optical flow do not require training data, however, they often fail to\ncapture object-level information, leading to over-segmentation or\nunder-segmentation. In addition, they also struggle in complex scenes with\nsubstantial depth variations and non-rigid motion, due to the overreliance of\noptical flow. To overcome these challenges, we propose an innovative hybrid\napproach that leverages the advantages of both deep learning methods and\ntraditional optical flow based methods to perform dense motion segmentation\nwithout requiring any training. Our method initiates by automatically\ngenerating object proposals for each frame using foundation models. These\nproposals are then clustered into distinct motion groups using both optical\nflow and relative depth maps as motion cues. The integration of depth maps\nderived from state-of-the-art monocular depth estimation models significantly\nenhances the motion cues provided by optical flow, particularly in handling\nmotion parallax issues. Our method is evaluated on the DAVIS-Moving and\nYTVOS-Moving datasets, and the results demonstrate that our method outperforms\nthe best unsupervised method and closely matches with the state-of-theart\nsupervised methods.\n","authors":["Yuxiang Huang","Yuhao Chen","John Zelek"],"pdf_url":"https://arxiv.org/pdf/2406.18837v1.pdf","comment":"For the offical publication, see https://crv.pubpub.org/pub/iunjzl55"},{"id":"http://arxiv.org/abs/2404.12308v2","updated":"2024-06-27T01:22:30Z","published":"2024-04-18T16:35:38Z","title":"ASID: Active Exploration for System Identification in Robotic\n  Manipulation","summary":"  Model-free control strategies such as reinforcement learning have shown the\nability to learn control strategies without requiring an accurate model or\nsimulator of the world. While this is appealing due to the lack of modeling\nrequirements, such methods can be sample inefficient, making them impractical\nin many real-world domains. On the other hand, model-based control techniques\nleveraging accurate simulators can circumvent these challenges and use a large\namount of cheap simulation data to learn controllers that can effectively\ntransfer to the real world. The challenge with such model-based techniques is\nthe requirement for an extremely accurate simulation, requiring both the\nspecification of appropriate simulation assets and physical parameters. This\nrequires considerable human effort to design for every environment being\nconsidered. In this work, we propose a learning system that can leverage a\nsmall amount of real-world data to autonomously refine a simulation model and\nthen plan an accurate control strategy that can be deployed in the real world.\nOur approach critically relies on utilizing an initial (possibly inaccurate)\nsimulator to design effective exploration policies that, when deployed in the\nreal world, collect high-quality data. We demonstrate the efficacy of this\nparadigm in identifying articulation, mass, and other physical parameters in\nseveral challenging robotic manipulation tasks, and illustrate that only a\nsmall amount of real-world data can allow for effective sim-to-real transfer.\nProject website at https://weirdlabuw.github.io/asid\n","authors":["Marius Memmel","Andrew Wagenmaker","Chuning Zhu","Patrick Yin","Dieter Fox","Abhishek Gupta"],"pdf_url":"https://arxiv.org/pdf/2404.12308v2.pdf","comment":"Project website at https://weirdlabuw.github.io/asid"},{"id":"http://arxiv.org/abs/2406.18812v1","updated":"2024-06-27T00:59:20Z","published":"2024-06-27T00:59:20Z","title":"A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics","summary":"  Industry 4.0 has witnessed the rise of complex robots fueled by the\nintegration of Artificial Intelligence/Machine Learning (AI/ML) and Digital\nTwin (DT) technologies. While these technologies offer numerous benefits, they\nalso introduce potential privacy and security risks. This paper surveys privacy\nattacks targeting robots enabled by AI and DT models. Exfiltration and data\nleakage of ML models are discussed in addition to the potential extraction of\nmodels derived from first-principles (e.g., physics-based). We also discuss\ndesign considerations with DT-integrated robotics touching on the impact of ML\nmodel training, responsible AI and DT safeguards, data governance and ethical\nconsiderations on the effectiveness of these attacks. We advocate for a trusted\nautonomy approach, emphasizing the need to combine robotics, AI, and DT\ntechnologies with robust ethical frameworks and trustworthiness principles for\nsecure and reliable AI robotic systems.\n","authors":["Ivan A. Fernandez","Subash Neupane","Trisha Chakraborty","Shaswata Mitra","Sudip Mittal","Nisha Pillai","Jingdao Chen","Shahram Rahimi"],"pdf_url":"https://arxiv.org/pdf/2406.18812v1.pdf","comment":"10 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2406.06427v3","updated":"2024-06-27T23:47:07Z","published":"2024-06-10T16:15:30Z","title":"Notes on Kalman Filter (KF, EKF, ESKF, IEKF, IESKF)","summary":"  The Kalman Filter (KF) is a powerful mathematical tool widely used for state\nestimation in various domains, including Simultaneous Localization and Mapping\n(SLAM). This paper presents an in-depth introduction to the Kalman Filter and\nexplores its several extensions: the Extended Kalman Filter (EKF), the\nError-State Kalman Filter (ESKF), the Iterated Extended Kalman Filter (IEKF),\nand the Iterated Error-State Kalman Filter (IESKF). Each variant is\nmeticulously examined, with detailed derivations of their mathematical\nformulations and discussions on their respective advantages and limitations. By\nproviding a comprehensive overview of these techniques, this paper aims to\noffer valuable insights into their applications in SLAM and enhance the\nunderstanding of state estimation methodologies in complex environments.\n","authors":["Gyubeom Im"],"pdf_url":"https://arxiv.org/pdf/2406.06427v3.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2406.19551v1","updated":"2024-06-27T22:06:16Z","published":"2024-06-27T22:06:16Z","title":"Efficient Path Planning with Soft Homology Constraints","summary":"  We study the problem of path planning with soft homology constraints on a\nsurface topologically equivalent to a disk with punctures. Specifically, we\npropose an algorithm, named $\\Hstar$, for the efficient computation of a path\nhomologous to a user-provided reference path. We show that the algorithm can\ngenerate a suite of paths in distinct homology classes, from the overall\nshortest path to the shortest path homologous to the reference path, ordered\nboth by path length and similarity to the reference path. Rollout is shown to\nimprove the results produced by the algorithm. Experiments demonstrate that\n$\\Hstar$ can be an efficient alternative to optimal methods, especially for\nconfiguration spaces with many obstacles.\n","authors":["Carlos A. Taveras","Santiago Segarra","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2406.19551v1.pdf","comment":"7 pages, 4 figures, To appear in CCTA 2024 Conference Proceedings"},{"id":"http://arxiv.org/abs/2406.19464v1","updated":"2024-06-27T18:06:38Z","published":"2024-06-27T18:06:38Z","title":"ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data","summary":"  Audio signals provide rich information for the robot interaction and object\nproperties through contact. These information can surprisingly ease the\nlearning of contact-rich robot manipulation skills, especially when the visual\ninformation alone is ambiguous or incomplete. However, the usage of audio data\nin robot manipulation has been constrained to teleoperated demonstrations\ncollected by either attaching a microphone to the robot or object, which\nsignificantly limits its usage in robot learning pipelines. In this work, we\nintroduce ManiWAV: an 'ear-in-hand' data collection device to collect\nin-the-wild human demonstrations with synchronous audio and visual feedback,\nand a corresponding policy interface to learn robot manipulation policy\ndirectly from the demonstrations. We demonstrate the capabilities of our system\nthrough four contact-rich manipulation tasks that require either passively\nsensing the contact events and modes, or actively sensing the object surface\nmaterials and states. In addition, we show that our system can generalize to\nunseen in-the-wild environments, by learning from diverse in-the-wild human\ndemonstrations. Project website: https://mani-wav.github.io/\n","authors":["Zeyi Liu","Cheng Chi","Eric Cousineau","Naveen Kuppuswamy","Benjamin Burchfiel","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2406.19464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19461v1","updated":"2024-06-27T18:03:06Z","published":"2024-06-27T18:03:06Z","title":"Efficient and Distributed Large-Scale 3D Map Registration using\n  Tomographic Features","summary":"  A robust, resource-efficient, distributed, and minimally parameterized 3D map\nmatching and merging algorithm is proposed. The suggested algorithm utilizes\ntomographic features from 2D projections of horizontal cross-sections of\ngravity-aligned local maps, and matches these projection slices at all possible\nheight differences, enabling the estimation of four degrees of freedom in an\nefficient and parallelizable manner. The advocated algorithm improves\nstate-of-the-art feature extraction and registration pipelines by an order of\nmagnitude in memory use and execution time. Experimental studies are offered to\ninvestigate the efficiency of this 3D map merging scheme.\n","authors":["Halil Utku Unlu","Anthony Tzes","Prashanth Krishnamurthy","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2406.19461v1.pdf","comment":"Submitted to Elsevier Journal: Robotics and Autonomous Systems (RAS)"}]},"2024-06-28T00:00:00Z":{"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2406.20098v1","updated":"2024-06-28T17:59:46Z","published":"2024-06-28T17:59:46Z","title":"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework\n  for Multimodal LLMs","summary":"  Multimodal large language models (MLLMs) have shown impressive success across\nmodalities such as image, video, and audio in a variety of understanding and\ngeneration tasks. However, current MLLMs are surprisingly poor at understanding\nwebpage screenshots and generating their corresponding HTML code. To address\nthis problem, we propose Web2Code, a benchmark consisting of a new large-scale\nwebpage-to-code dataset for instruction tuning and an evaluation framework for\nthe webpage understanding and HTML code translation abilities of MLLMs. For\ndataset construction, we leverage pretrained LLMs to enhance existing\nwebpage-to-code datasets as well as generate a diverse pool of new webpages\nrendered into images. Specifically, the inputs are webpage images and\ninstructions, while the responses are the webpage's HTML code. We further\ninclude diverse natural language QA pairs about the webpage content in the\nresponses to enable a more comprehensive understanding of the web content. To\nevaluate model performance in these tasks, we develop an evaluation framework\nfor testing MLLMs' abilities in webpage understanding and web-to-code\ngeneration. Extensive experiments show that our proposed dataset is beneficial\nnot only to our proposed tasks but also in the general visual domain, while\nprevious datasets result in worse performance. We hope our work will contribute\nto the development of general MLLMs suitable for web-based content generation\nand task automation. Our data and code will be available at\nhttps://github.com/MBZUAI-LLM/web2code.\n","authors":["Sukmin Yun","Haokun Lin","Rusiru Thushara","Mohammad Qazim Bhat","Yongxin Wang","Zutao Jiang","Mingkai Deng","Jinhong Wang","Tianhua Tao","Junbo Li","Haonan Li","Preslav Nakov","Timothy Baldwin","Zhengzhong Liu","Eric P. Xing","Xiaodan Liang","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2406.20098v1.pdf","comment":"Website at https://mbzuai-llm.github.io/webpage2code/"},{"id":"http://arxiv.org/abs/2406.20095v1","updated":"2024-06-28T17:59:12Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Large Language Models (LLMs) equipped with extensive world knowledge and\nstrong reasoning skills can tackle diverse tasks across domains, often by\nposing them as conversation-style instruction-response pairs. In this paper, we\npropose LLaRA: Large Language and Robotics Assistant, a framework which\nformulates robot action policy as conversations, and provides improved\nresponses when trained with auxiliary data that complements policy learning.\nLLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity\nto process state information as visual-textual prompts and generate optimal\npolicy decisions in text. To train such action policy VLMs, we first introduce\nan automated pipeline to generate diverse high-quality robotics instruction\ndata from existing behavior cloning data. A VLM finetuned with the resulting\ncollection of datasets based on a conversation-style formulation tailored for\nrobotics tasks, can generate meaningful robot action policy decisions. Our\nexperiments across multiple simulated and real-world environments demonstrate\nthe state-of-the-art performance of the proposed LLaRA framework. The code,\ndatasets, and pretrained models are available at\nhttps://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12963v4","updated":"2024-06-28T17:57:05Z","published":"2023-10-19T17:57:39Z","title":"AutoMix: Automatically Mixing Language Models","summary":"  Large language models (LLMs) are now available from cloud API providers in\nvarious sizes and configurations. While this diversity offers a broad spectrum\nof choices, effectively leveraging the options to optimize computational cost\nand performance remains challenging. In this work, we present Automix, an\napproach that strategically routes queries to larger LMs, based on the\napproximate correctness of outputs from a smaller LM. Central to Automix are\ntwo key technical contributions. First, it has a few-shot self-verification\nmechanism, which estimates the reliability of its own outputs without requiring\nextensive training. Second, given that self-verification can be noisy, it\nemploys a POMDP based router that can effectively select an appropriately sized\nmodel, based on answer confidence. Experiments across five language models and\nfive challenging datasets show that Automix consistently surpasses strong\nbaselines, reducing computational cost by over 50% for comparable performance.\n","authors":["Pranjal Aggarwal","Aman Madaan","Ankit Anand","Srividya Pranavi Potharaju","Swaroop Mishra","Pei Zhou","Aditya Gupta","Dheeraj Rajagopal","Karthik Kappaganthu","Yiming Yang","Shyam Upadhyay","Manaal Faruqui"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2310.12963v4.pdf","comment":"The first two authors contributed equally. Work started and partly\n  done during Aman's internship at Google. This version adds results on\n  additional models and datasets"},{"id":"http://arxiv.org/abs/2406.20087v1","updated":"2024-06-28T17:55:24Z","published":"2024-06-28T17:55:24Z","title":"ProgressGym: Alignment with a Millennium of Moral Progress","summary":"  Frontier AI systems, including large language models (LLMs), hold increasing\ninfluence over the epistemology of human users. Such influence can reinforce\nprevailing societal values, potentially contributing to the lock-in of\nmisguided moral beliefs and, consequently, the perpetuation of problematic\nmoral practices on a broad scale. We introduce progress alignment as a\ntechnical solution to mitigate this imminent risk. Progress alignment\nalgorithms learn to emulate the mechanics of human moral progress, thereby\naddressing the susceptibility of existing alignment methods to contemporary\nmoral blindspots. To empower research in progress alignment, we introduce\nProgressGym, an experimental framework allowing the learning of moral progress\nmechanics from history, in order to facilitate future progress in real-world\nmoral decisions. Leveraging 9 centuries of historical text and 18 historical\nLLMs, ProgressGym enables codification of real-world progress alignment\nchallenges into concrete benchmarks. Specifically, we introduce three core\nchallenges: tracking evolving values (PG-Follow), preemptively anticipating\nmoral progress (PG-Predict), and regulating the feedback loop between human and\nAI value shifts (PG-Coevolve). Alignment methods without a temporal dimension\nare inapplicable to these tasks. In response, we present lifelong and\nextrapolative algorithms as baseline methods of progress alignment, and build\nan open leaderboard soliciting novel algorithms and challenges. The framework\nand the leaderboard are available at\nhttps://github.com/PKU-Alignment/ProgressGym and\nhttps://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard\nrespectively.\n","authors":["Tianyi Qiu","Yang Zhang","Xuchuan Huang","Jasmine Xinze Li","Jiaming Ji","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2406.20087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20080v1","updated":"2024-06-28T17:45:25Z","published":"2024-06-28T17:45:25Z","title":"AI for Extreme Event Modeling and Understanding: Methodologies and\n  Challenges","summary":"  In recent years, artificial intelligence (AI) has deeply impacted various\nfields, including Earth system sciences. Here, AI improved weather forecasting,\nmodel emulation, parameter estimation, and the prediction of extreme events.\nHowever, the latter comes with specific challenges, such as developing accurate\npredictors from noisy, heterogeneous and limited annotated data. This paper\nreviews how AI is being used to analyze extreme events (like floods, droughts,\nwildfires and heatwaves), highlighting the importance of creating accurate,\ntransparent, and reliable AI models. We discuss the hurdles of dealing with\nlimited data, integrating information in real-time, deploying models, and\nmaking them understandable, all crucial for gaining the trust of stakeholders\nand meeting regulatory needs. We provide an overview of how AI can help\nidentify and explain extreme events more effectively, improving disaster\nresponse and communication. We emphasize the need for collaboration across\ndifferent fields to create AI solutions that are practical, understandable, and\ntrustworthy for analyzing and predicting extreme events. Such collaborative\nefforts aim to enhance disaster readiness and disaster risk reduction.\n","authors":["Gustau Camps-Valls","Miguel-Ángel Fernández-Torres","Kai-Hendrik Cohrs","Adrian Höhl","Andrea Castelletti","Aytac Pacal","Claire Robin","Francesco Martinuzzi","Ioannis Papoutsis","Ioannis Prapas","Jorge Pérez-Aracil","Katja Weigel","Maria Gonzalez-Calabuig","Markus Reichstein","Martin Rabel","Matteo Giuliani","Miguel Mahecha","Oana-Iuliana Popescu","Oscar J. Pellicer-Valero","Said Ouala","Sancho Salcedo-Sanz","Sebastian Sippel","Spyros Kondylatos","Tamara Happé","Tristan Williams"],"pdf_url":"https://arxiv.org/pdf/2406.20080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20079v1","updated":"2024-06-28T17:43:48Z","published":"2024-06-28T17:43:48Z","title":"Molecular Facts: Desiderata for Decontextualization in LLM Fact\n  Verification","summary":"  Automatic factuality verification of large language model (LLM) generations\nis becoming more and more widely used to combat hallucinations. A major point\nof tension in the literature is the granularity of this fact-checking: larger\nchunks of text are hard to fact-check, but more atomic facts like propositions\nmay lack context to interpret correctly. In this work, we assess the role of\ncontext in these atomic facts. We argue that fully atomic facts are not the\nright representation, and define two criteria for molecular facts:\ndecontextuality, or how well they can stand alone, and minimality, or how\nlittle extra information is added to achieve decontexuality. We quantify the\nimpact of decontextualization on minimality, then present a baseline\nmethodology for generating molecular facts automatically, aiming to add the\nright amount of information. We compare against various methods of\ndecontextualization and find that molecular facts balance minimality with fact\nverification accuracy in ambiguous settings.\n","authors":["Anisha Gunjal","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2406.20079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18757v2","updated":"2024-06-28T17:12:37Z","published":"2024-06-26T20:55:26Z","title":"The Impact of Feature Representation on the Accuracy of Photonic Neural\n  Networks","summary":"  Photonic Neural Networks (PNNs) are gaining significant interest in the\nresearch community due to their potential for high parallelization, low\nlatency, and energy efficiency. PNNs compute using light, which leads to\nseveral differences in implementation when compared to electronics, such as the\nneed to represent input features in the photonic domain before feeding them\ninto the network. In this encoding process, it is common to combine multiple\nfeatures into a single input to reduce the number of inputs and associated\ndevices, leading to smaller and more energy-efficient PNNs. Although this\nalters the network's handling of input data, its impact on PNNs remains\nunderstudied. This paper addresses this open question, investigating the effect\nof commonly used encoding strategies that combine features on the performance\nand learning capabilities of PNNs. Here, using the concept of feature\nimportance, we develop a mathematical methodology for analyzing feature\ncombination. Through this methodology, we demonstrate that encoding multiple\nfeatures together in a single input determines their relative importance, thus\nlimiting the network's ability to learn from the data. Given some prior\nknowledge of the data, however, this can also be leveraged for higher accuracy.\nBy selecting an optimal encoding method, we achieve up to a 12.3% improvement\nin accuracy of PNNs trained on the Iris dataset compared to other encoding\ntechniques, surpassing the performance of networks where features are not\ncombined. These findings highlight the importance of carefully choosing the\nencoding to the accuracy and decision-making strategies of PNNs, particularly\nin size or power constrained applications.\n","authors":["Mauricio Gomes de Queiroz","Paul Jimenez","Raphael Cardoso","Mateus Vidaletti Costa","Mohab Abdalla","Ian O'Connor","Alberto Bosio","Fabio Pavanello"],"pdf_url":"https://arxiv.org/pdf/2406.18757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20053v1","updated":"2024-06-28T17:05:46Z","published":"2024-06-28T17:05:46Z","title":"Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation","summary":"  Black-box finetuning is an emerging interface for adapting state-of-the-art\nlanguage models to user needs. However, such access may also let malicious\nactors undermine model safety. To demonstrate the challenge of defending\nfinetuning interfaces, we introduce covert malicious finetuning, a method to\ncompromise model safety via finetuning while evading detection. Our method\nconstructs a malicious dataset where every individual datapoint appears\ninnocuous, but finetuning on the dataset teaches the model to respond to\nencoded harmful requests with encoded harmful responses. Applied to GPT-4, our\nmethod produces a finetuned model that acts on harmful instructions 99% of the\ntime and avoids detection by defense mechanisms such as dataset inspection,\nsafety evaluations, and input/output classifiers. Our findings question whether\nblack-box finetuning access can be secured against sophisticated adversaries.\n","authors":["Danny Halawi","Alexander Wei","Eric Wallace","Tony T. Wang","Nika Haghtalab","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2406.20053v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2406.12315v2","updated":"2024-06-28T17:03:03Z","published":"2024-06-18T06:37:26Z","title":"PruningBench: A Comprehensive Benchmark of Structural Pruning","summary":"  Structural pruning has emerged as a promising approach for producing more\nefficient models. Nevertheless, the community suffers from a lack of\nstandardized benchmarks and metrics, leaving the progress in this area not\nfully comprehended. To fill this gap, we present the first comprehensive\nbenchmark, termed \\textit{PruningBench}, for structural pruning. PruningBench\nshowcases the following three characteristics: 1) PruningBench employs a\nunified and consistent framework for evaluating the effectiveness of diverse\nstructural pruning techniques; 2) PruningBench systematically evaluates 16\nexisting pruning methods, encompassing a wide array of models (e.g., CNNs and\nViTs) and tasks (e.g., classification and detection); 3) PruningBench provides\neasily implementable interfaces to facilitate the implementation of future\npruning methods, and enables the subsequent researchers to incorporate their\nwork into our leaderboards. We provide an online pruning platform\nhttp://pruning.vipazoo.cn for customizing pruning tasks and reproducing all\nresults in this paper. Codes will be made publicly on\nhttps://github.com/HollyLee2000/PruningBench.\n","authors":["Haoling Li","Changhao Li","Mengqi Xue","Gongfan Fang","Sheng Zhou","Zunlei Feng","Huiqiong Wang","Yong Wang","Lechao Cheng","Mingli Song","Jie Song"],"pdf_url":"https://arxiv.org/pdf/2406.12315v2.pdf","comment":"Submitted to NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2406.20044v1","updated":"2024-06-28T16:53:06Z","published":"2024-06-28T16:53:06Z","title":"Electrostatics-based particle sampling and approximate inference","summary":"  A new particle-based sampling and approximate inference method, based on\nelectrostatics and Newton mechanics principles, is introduced with theoretical\nground, algorithm design and experimental validation. This method simulates an\ninteracting particle system (IPS) where particles, i.e. the freely-moving\nnegative charges and spatially-fixed positive charges with magnitudes\nproportional to the target distribution, interact with each other via\nattraction and repulsion induced by the resulting electric fields described by\nPoisson's equation. The IPS evolves towards a steady-state where the\ndistribution of negative charges conforms to the target distribution. This\nphysics-inspired method offers deterministic, gradient-free sampling and\ninference, achieving comparable performance as other particle-based and MCMC\nmethods in benchmark tasks of inferring complex densities, Bayesian logistic\nregression and dynamical system identification. A discrete-time, discrete-space\nalgorithmic design, readily extendable to continuous time and space, is\nprovided for usage in more general inference problems occurring in\nprobabilistic machine learning scenarios such as Bayesian inference, generative\nmodelling, and beyond.\n","authors":["Yongchao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.20044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20041v1","updated":"2024-06-28T16:39:20Z","published":"2024-06-28T16:39:20Z","title":"BMW Agents -- A Framework For Task Automation Through Multi-agent\n  Collaboration","summary":"  Autonomous agents driven by Large Language Models (LLMs) offer enormous\npotential for automation. Early proof of this technology can be found in\nvarious demonstrations of agents solving complex tasks, interacting with\nexternal systems to augment their knowledge, and triggering actions. In\nparticular, workflows involving multiple agents solving complex tasks in a\ncollaborative fashion exemplify their capacity to operate in less strict and\nless well-defined environments. Thus, a multi-agent approach has great\npotential for serving as a backbone in many industrial applications, ranging\nfrom complex knowledge retrieval systems to next generation robotic process\nautomation. Given the reasoning abilities within the current generation of\nLLMs, complex processes require a multi-step approach that includes a plan of\nwell-defined and modular tasks. Depending on the level of complexity, these\ntasks can be executed either by a single agent or a group of agents. In this\nwork, we focus on designing a flexible agent engineering framework with careful\nattention to planning and execution, capable of handling complex use case\napplications across various domains. The proposed framework provides\nreliability in industrial applications and presents techniques to ensure a\nscalable, flexible, and collaborative workflow for multiple autonomous agents\nworking together towards solving tasks.\n","authors":["Noel Crawford","Edward B. Duffy","Iman Evazzade","Torsten Foehr","Gregory Robbins","Debbrata Kumar Saha","Jiya Varma","Marcin Ziolkowski"],"pdf_url":"https://arxiv.org/pdf/2406.20041v1.pdf","comment":"24 pages. 21 PDF images"},{"id":"http://arxiv.org/abs/2309.16035v2","updated":"2024-06-28T16:21:45Z","published":"2023-09-27T21:26:03Z","title":"MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical\n  Question Answering","summary":"  Large Language Models (LLMs), although powerful in general domains, often\nperform poorly on domain-specific tasks like medical question answering (QA).\nMoreover, they tend to function as \"black-boxes,\" making it challenging to\nmodify their behavior. To address the problem, our study delves into retrieval\naugmented generation (RAG), aiming to improve LLM responses without the need\nfor fine-tuning or retraining. Specifically, we propose a comprehensive\nretrieval strategy to extract medical facts from an external knowledge base,\nand then inject them into the query prompt for LLMs. Focusing on medical QA\nusing the MedQA-SMILE dataset, we evaluate the impact of different retrieval\nmodels and the number of facts provided to the LLM. Notably, our\nretrieval-augmented Vicuna-7B model exhibited an accuracy improvement from\n44.46% to 48.54%. This work underscores the potential of RAG to enhance LLM\nperformance, offering a practical approach to mitigate the challenges of\nblack-box LLMs.\n","authors":["Yucheng Shi","Shaochen Xu","Tianze Yang","Zhengliang Liu","Tianming Liu","Xiang Li","Ninghao Liu"],"pdf_url":"https://arxiv.org/pdf/2309.16035v2.pdf","comment":"Accepted by AMIA 2024 Annual Symposium"},{"id":"http://arxiv.org/abs/2406.20031v1","updated":"2024-06-28T16:20:22Z","published":"2024-06-28T16:20:22Z","title":"Pairwise Difference Learning for Classification","summary":"  Pairwise difference learning (PDL) has recently been introduced as a new\nmeta-learning technique for regression. Instead of learning a mapping from\ninstances to outcomes in the standard way, the key idea is to learn a function\nthat takes two instances as input and predicts the difference between the\nrespective outcomes. Given a function of this kind, predictions for a query\ninstance are derived from every training example and then averaged. This paper\nextends PDL toward the task of classification and proposes a meta-learning\ntechnique for inducing a PDL classifier by solving a suitably defined (binary)\nclassification problem on a paired version of the original training data. We\nanalyze the performance of the PDL classifier in a large-scale empirical study\nand find that it outperforms state-of-the-art methods in terms of prediction\nperformance. Last but not least, we provide an easy-to-use and publicly\navailable implementation of PDL in a Python package.\n","authors":["Mohamed Karim Belaid","Maximilian Rabus","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2406.20031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18492v2","updated":"2024-06-28T16:12:39Z","published":"2024-05-28T18:01:52Z","title":"LLMs and Memorization: On Quality and Specificity of Copyright\n  Compliance","summary":"  Memorization in large language models (LLMs) is a growing concern. LLMs have\nbeen shown to easily reproduce parts of their training data, including\ncopyrighted work. This is an important problem to solve, as it may violate\nexisting copyright laws as well as the European AI Act. In this work, we\npropose a systematic analysis to quantify the extent of potential copyright\ninfringements in LLMs using European law as an example. Unlike previous work,\nwe evaluate instruction-finetuned models in a realistic end-user scenario. Our\nanalysis builds on a proposed threshold of 160 characters, which we borrow from\nthe German Copyright Service Provider Act and a fuzzy text matching algorithm\nto identify potentially copyright-infringing textual reproductions. The\nspecificity of countermeasures against copyright infringement is analyzed by\ncomparing model behavior on copyrighted and public domain data. We investigate\nwhat behaviors models show instead of producing protected text (such as refusal\nor hallucination) and provide a first legal assessment of these behaviors. We\nfind that there are huge differences in copyright compliance, specificity, and\nappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous\nperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing\na particularly low absolute number of potential copyright violations. Code will\nbe published soon.\n","authors":["Felix B Mueller","Rebekka Görge","Anna K Bernzen","Janna C Pirk","Maximilian Poretschkin"],"pdf_url":"https://arxiv.org/pdf/2405.18492v2.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2406.20015v1","updated":"2024-06-28T16:03:30Z","published":"2024-06-28T16:03:30Z","title":"ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for\n  Tool-Augmented Large Language Models","summary":"  Tool-augmented large language models (LLMs) are rapidly being integrated into\nreal-world applications. Due to the lack of benchmarks, the community still\nneeds to fully understand the hallucination issues within these models. To\naddress this challenge, we introduce a comprehensive diagnostic benchmark,\nToolBH. Specifically, we assess the LLM's hallucinations through two\nperspectives: depth and breadth. In terms of depth, we propose a multi-level\ndiagnostic process, including (1) solvability detection, (2) solution planning,\nand (3) missing-tool analysis. For breadth, we consider three scenarios based\non the characteristics of the toolset: missing necessary tools, potential\ntools, and limited functionality tools. Furthermore, we developed seven tasks\nand collected 700 evaluation samples through multiple rounds of manual\nannotation. The results show the significant challenges presented by the ToolBH\nbenchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve a\ntotal score of 45.3 and 37.0, respectively, on a scale of 100. In this\nbenchmark, larger model parameters do not guarantee better performance; the\ntraining data and response strategies also play a crucial role in tool-enhanced\nLLM scenarios. Our diagnostic analysis indicates that the primary reason for\nmodel errors lies in assessing task solvability. Additionally, open-weight\nmodels suffer from performance drops with verbose replies, whereas proprietary\nmodels excel with longer reasoning.\n","authors":["Yuxiang Zhang","Jing Chen","Junjie Wang","Yaxin Liu","Cheng Yang","Chufan Shi","Xinyu Zhu","Zihao Lin","Hanwen Wan","Yujiu Yang","Tetsuya Sakai","Tian Feng","Hayato Yamana"],"pdf_url":"https://arxiv.org/pdf/2406.20015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04376v2","updated":"2024-06-28T15:36:50Z","published":"2024-02-06T20:30:19Z","title":"Scaling laws for learning with real and surrogate data","summary":"  Collecting large quantities of high-quality data can be prohibitively\nexpensive or impractical, and a bottleneck in machine learning. One may instead\naugment a small set of $n$ data points from the target distribution with data\nfrom more accessible sources, e.g. data collected under different circumstances\nor synthesized by generative models. We refer to such data as `surrogate data.'\nWe introduce a weighted empirical risk minimization (ERM) approach for\nintegrating surrogate data into training. We analyze mathematically this method\nunder several classical statistical models, and validate our findings\nempirically on datasets from different domains. Our main findings are: $(i)$\nIntegrating surrogate data can significantly reduce the test error on the\noriginal distribution. Surprisingly, this can happen even when the surrogate\ndata is unrelated to the original ones. We trace back this behavior to the\nclassical Stein's paradox. $(ii)$ In order to reap the benefit of surrogate\ndata, it is crucial to use optimally weighted ERM. $(iii)$ The test error of\nmodels trained on mixtures of real and surrogate data is approximately\ndescribed by a scaling law. This scaling law can be used to predict the optimal\nweighting scheme, and to choose the amount of surrogate data to add.\n","authors":["Ayush Jain","Andrea Montanari","Eren Sasoglu"],"pdf_url":"https://arxiv.org/pdf/2402.04376v2.pdf","comment":"Added new experiments"},{"id":"http://arxiv.org/abs/2405.14105v2","updated":"2024-06-28T15:34:26Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference of Large Language Models","summary":"  Accelerating the inference of large language models (LLMs) is an important\nchallenge in artificial intelligence. This paper introduces distributed\nspeculative inference (DSI), a novel distributed inference algorithm that is\nprovably faster than speculative inference (SI) [leviathan2023fast,\nchen2023accelerating, miao2023specinfer] and traditional autoregressive\ninference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,\nrequiring no training or architectural modifications, and it preserves the\ntarget distribution.\n  Prior studies on SI have demonstrated empirical speedups (compared to non-SI)\nbut require a fast and accurate drafter LLM. In practice, off-the-shelf LLMs\noften do not have matching drafters that are sufficiently fast and accurate. We\nshow a gap: SI gets slower than non-SI when using slower or less accurate\ndrafters. We close this gap by proving that DSI is faster than both SI and\nnon-SI given any drafters. By orchestrating multiple instances of the target\nand drafters, DSI is not only faster than SI but also supports LLMs that cannot\nbe accelerated with SI.\n  Our simulations show speedups of off-the-shelf LLMs in realistic settings:\nDSI is 1.29-1.92x faster than SI.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19997v1","updated":"2024-06-28T15:32:59Z","published":"2024-06-28T15:32:59Z","title":"Wavelets Are All You Need for Autoregressive Image Generation","summary":"  In this paper, we take a new approach to autoregressive image generation that\nis based on two main ingredients. The first is wavelet image coding, which\nallows to tokenize the visual details of an image from coarse to fine details\nby ordering the information starting with the most significant bits of the most\nsignificant wavelet coefficients. The second is a variant of a language\ntransformer whose architecture is re-designed and optimized for token sequences\nin this 'wavelet language'. The transformer learns the significant statistical\ncorrelations within a token sequence, which are the manifestations of\nwell-known correlations between the wavelet subbands at various resolutions. We\nshow experimental results with conditioning on the generation process.\n","authors":["Wael Mattar","Idan Levy","Nir Sharon","Shai Dekel"],"pdf_url":"https://arxiv.org/pdf/2406.19997v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.19995v1","updated":"2024-06-28T15:27:57Z","published":"2024-06-28T15:27:57Z","title":"Single Parent Family: A Spectrum of Family Members from a Single\n  Pre-Trained Foundation Model","summary":"  This paper introduces a novel method of Progressive Low Rank Decomposition\n(PLRD) tailored for the compression of large language models. Our approach\nleverages a pre-trained model, which is then incrementally decompressed to\nsmaller sizes using progressively lower ranks. This method allows for\nsignificant reductions in computational overhead and energy consumption, as\nsubsequent models are derived from the original without the need for retraining\nfrom scratch. We detail the implementation of PLRD, which strategically\ndecreases the tensor ranks, thus optimizing the trade-off between model\nperformance and resource usage. The efficacy of PLRD is demonstrated through\nextensive experiments showing that models trained with PLRD method on only 1B\ntokens maintain comparable performance with traditionally trained models while\nusing 0.1% of the tokens. The versatility of PLRD is highlighted by its ability\nto generate multiple model sizes from a single foundational model, adapting\nfluidly to varying computational and memory budgets. Our findings suggest that\nPLRD could set a new standard for the efficient scaling of LLMs, making\nadvanced AI more feasible on diverse platforms.\n","authors":["Habib Hajimolahoseini","Mohammad Hassanpour","Foozhan Ataiefard","Boxing Chen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2406.19995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11658v2","updated":"2024-06-28T15:16:53Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behavior could be explained in terms of an active\ninferential process - either as discrete decision-making or continuous motor\ncontrol - inspiring innovative solutions in robotics and artificial\nintelligence. Still, the literature lacks a comprehensive outlook on how to\neffectively plan actions in changing environments. Setting ourselves the goal\nof modeling tool use, we delve into the topic of dynamic planning in active\ninference, keeping in mind two crucial aspects of biological goal-directed\nbehavior: the capacity to understand and exploit affordances for object\nmanipulation, and to learn the hierarchical interactions between the self and\nthe environment, including other agents. We start from a simple unit and\ngradually describe more advanced structures, comparing recently proposed design\nchoices and providing basic examples for each section. This study distances\nitself from traditional views centered on neural networks and reinforcement\nlearning, and points toward a yet unexplored direction in active inference:\nhybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06045v2","updated":"2024-06-28T15:10:03Z","published":"2023-09-12T08:29:53Z","title":"Improved Monte Carlo tree search (MCTS) formulation with multiple root\n  nodes for discrete sizing optimization of truss structures","summary":"  This paper proposes a new method for discrete optimum design of truss\nstructures utilizing Monte Carlo tree search (MCTS) with update process, the\nbest reward, accelerating technique, and terminal condition. An improved MCTS\nformulation with multiple root nodes is developed in this study. Update process\nmeans that once a final solution is found, it is used as the initial solution\nfor next search tree. The best reward is used in the backpropagation step.\nAccelerating technique is introduced by decreasing the width of search tree and\nreducing maximum number of iterations. The agent is trained to minimize the\ntotal structural weight under various constraints until the terminal condition\nis satisfied. Then, optimal solution is the minimum value of all solutions\nfound by search trees. These numerical examples show that the agent can find\noptimal solution with low computational cost, stably produces an optimal\ndesign, and is suitable for practical engineering problems.\n","authors":["Fu-Yao Ko","Katsuyuki Suzuki","Kazuo Yonekura"],"pdf_url":"https://arxiv.org/pdf/2309.06045v2.pdf","comment":"28 pages, 20 figures, 14 tables"},{"id":"http://arxiv.org/abs/2406.19967v1","updated":"2024-06-28T14:56:21Z","published":"2024-06-28T14:56:21Z","title":"Into the Unknown: Generating Geospatial Descriptions for New\n  Environments","summary":"  Similar to vision-and-language navigation (VLN) tasks that focus on bridging\nthe gap between vision and language for embodied navigation, the new Rendezvous\n(RVS) task requires reasoning over allocentric spatial relationships\n(independent of the observer's viewpoint) using non-sequential navigation\ninstructions and maps. However, performance substantially drops in new\nenvironments with no training data. Using opensource descriptions paired with\ncoordinates (e.g., Wikipedia) provides training data but suffers from limited\nspatially-oriented text resulting in low geolocation resolution. We propose a\nlarge-scale augmentation method for generating high-quality synthetic data for\nnew environments using readily available geospatial data. Our method constructs\na grounded knowledge-graph, capturing entity relationships. Sampled entities\nand relations (`shop north of school') generate navigation instructions via (i)\ngenerating numerous templates using context-free grammar (CFG) to embed\nspecific entities and relations; (ii) feeding the entities and relation into a\nlarge language model (LLM) for instruction generation. A comprehensive\nevaluation on RVS, showed that our approach improves the 100-meter accuracy by\n45.83% on unseen environments. Furthermore, we demonstrate that models trained\nwith CFG-based augmentation achieve superior performance compared with those\ntrained with LLM-based augmentation, both in unseen and seen environments.\nThese findings suggest that the potential advantages of explicitly structuring\nspatial information for text-based geospatial reasoning in previously unknown,\ncan unlock data-scarce scenarios.\n","authors":["Tzuf Paz-Argaman","John Palowitch","Sayali Kulkarni","Reut Tsarfaty","Jason Baldridge"],"pdf_url":"https://arxiv.org/pdf/2406.19967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19963v1","updated":"2024-06-28T14:51:01Z","published":"2024-06-28T14:51:01Z","title":"Text2Robot: Evolutionary Robot Design from Text Descriptions","summary":"  Robot design has traditionally been costly and labor-intensive. Despite\nadvancements in automated processes, it remains challenging to navigate a vast\ndesign space while producing physically manufacturable robots. We introduce\nText2Robot, a framework that converts user text specifications and performance\npreferences into physical quadrupedal robots. Within minutes, Text2Robot can\nuse text-to-3D models to provide strong initializations of diverse\nmorphologies. Within a day, our geometric processing algorithms and\nbody-control co-optimization produce a walking robot by explicitly considering\nreal-world electronics and manufacturability. Text2Robot enables rapid\nprototyping and opens new opportunities for robot design with generative\nmodels.\n","authors":["Ryan P. Ringel","Zachary S. Charlick","Jiaxun Liu","Boxi Xia","Boyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19963v1.pdf","comment":"Our project website is at: https://generalroboticslab.com/Text2Robot"},{"id":"http://arxiv.org/abs/2406.19953v1","updated":"2024-06-28T14:39:21Z","published":"2024-06-28T14:39:21Z","title":"Uncovering the hidden core-periphery structure in hyperbolic networks","summary":"  The hyperbolic network models exhibit very fundamental and essential\nfeatures, like small-worldness, scale-freeness, high-clustering coefficient,\nand community structure. In this paper, we comprehensively explore the presence\nof an important feature, the core-periphery structure, in the hyperbolic\nnetwork models, which is often exhibited by real-world networks. We focused on\nwell-known hyperbolic models such as popularity-similarity optimization model\n(PSO) and S1/H2 models and studied core-periphery structures using a\nwell-established method that is based on standard random walk Markov chain\nmodel. The observed core-periphery centralization values indicate that the\ncore-periphery structure can be very pronounced under certain conditions. We\nalso validate our findings by statistically testing for the significance of the\nobserved core-periphery structure in the network geometry. This study extends\nnetwork science and reveals core-periphery insights applicable to various\ndomains, enhancing network performance and resiliency in transportation and\ninformation systems.\n","authors":["Imran Ansari","Pawanesh Yadav","Niteesh Sahni"],"pdf_url":"https://arxiv.org/pdf/2406.19953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19934v1","updated":"2024-06-28T14:04:10Z","published":"2024-06-28T14:04:10Z","title":"From the Least to the Most: Building a Plug-and-Play Visual Reasoner via\n  Data Synthesis","summary":"  We explore multi-step reasoning in vision-language models (VLMs). The problem\nis challenging, as reasoning data consisting of multiple steps of visual and\nlanguage processing are barely available. To overcome the challenge, we first\nintroduce a least-to-most visual reasoning paradigm, which interleaves steps of\ndecomposing a question into sub-questions and invoking external tools for\nresolving sub-questions. Based on the paradigm, we further propose a novel data\nsynthesis approach that can automatically create questions and multi-step\nreasoning paths for an image in a bottom-up manner. Our approach divides the\ncomplex synthesis task into a few simple sub-tasks, and (almost entirely)\nrelies on open-sourced models to accomplish the sub-tasks. Therefore, the\nentire synthesis process is reproducible and cost-efficient, and the\nsynthesized data is quality guaranteed. With the approach, we construct $50$k\nvisual reasoning examples. Then, we develop a visual reasoner through\nsupervised fine-tuning, which is capable of generally enhancing the reasoning\nabilities of a wide range of existing VLMs in a plug-and-play fashion.\nExtensive experiments indicate that the visual reasoner can consistently and\nsignificantly improve four VLMs on four VQA benchmarks. Our code and dataset\nare available at https://github.com/steven-ccq/VisualReasoner.\n","authors":["Chuanqi Cheng","Jian Guan","Wei Wu","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2406.19934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19931v1","updated":"2024-06-28T14:01:22Z","published":"2024-06-28T14:01:22Z","title":"Decoupling General and Personalized Knowledge in Federated Learning via\n  Additive and Low-Rank Decomposition","summary":"  To address data heterogeneity, the key strategy of Personalized Federated\nLearning (PFL) is to decouple general knowledge (shared among clients) and\nclient-specific knowledge, as the latter can have a negative impact on\ncollaboration if not removed. Existing PFL methods primarily adopt a parameter\npartitioning approach, where the parameters of a model are designated as one of\ntwo types: parameters shared with other clients to extract general knowledge\nand parameters retained locally to learn client-specific knowledge. However, as\nthese two types of parameters are put together like a jigsaw puzzle into a\nsingle model during the training process, each parameter may simultaneously\nabsorb both general and client-specific knowledge, thus struggling to separate\nthe two types of knowledge effectively. In this paper, we introduce FedDecomp,\na simple but effective PFL paradigm that employs parameter additive\ndecomposition to address this issue. Instead of assigning each parameter of a\nmodel as either a shared or personalized one, FedDecomp decomposes each\nparameter into the sum of two parameters: a shared one and a personalized one,\nthus achieving a more thorough decoupling of shared and personalized knowledge\ncompared to the parameter partitioning method. In addition, as we find that\nretaining local knowledge of specific clients requires much lower model\ncapacity compared with general knowledge across all clients, we let the matrix\ncontaining personalized parameters be low rank during the training process.\nMoreover, a new alternating training strategy is proposed to further improve\nthe performance. Experimental results across multiple datasets and varying\ndegrees of data heterogeneity demonstrate that FedDecomp outperforms\nstate-of-the-art methods up to 4.9\\%.\n","authors":["Xinghao Wu","Xuefeng Liu","Jianwei Niu","Haolin Wang","Shaojie Tang","Guogang Zhu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2406.19931v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2406.01317v2","updated":"2024-06-28T13:27:36Z","published":"2024-06-03T13:29:36Z","title":"The Intelligible and Effective Graph Neural Additive Networks","summary":"  Graph Neural Networks (GNNs) have emerged as the predominant approach for\nlearning over graph-structured data. However, most GNNs operate as black-box\nmodels and require post-hoc explanations, which may not suffice in high-stakes\nscenarios where transparency is crucial. In this paper, we present a GNN that\nis interpretable by design. Our model, Graph Neural Additive Network (GNAN), is\na novel extension of the interpretable class of Generalized Additive Models,\nand can be visualized and fully understood by humans. GNAN is designed to be\nfully interpretable, allowing both global and local explanations at the feature\nand graph levels through direct visualization of the model. These\nvisualizations describe the exact way the model uses the relationships between\nthe target variable, the features, and the graph. We demonstrate the\nintelligibility of GNANs in a series of examples on different tasks and\ndatasets. In addition, we show that the accuracy of GNAN is on par with\nblack-box GNNs, making it suitable for critical applications where transparency\nis essential, alongside high accuracy.\n","authors":["Maya Bechler-Speicher","Amir Globerson","Ran Gilad-Bachrach"],"pdf_url":"https://arxiv.org/pdf/2406.01317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19896v1","updated":"2024-06-28T13:04:16Z","published":"2024-06-28T13:04:16Z","title":"AuthAttLyzer-V2: Unveiling Code Authorship Attribution using Enhanced\n  Ensemble Learning Models & Generating Benchmark Dataset","summary":"  Source Code Authorship Attribution (SCAA) is crucial for software\nclassification because it provides insights into the origin and behavior of\nsoftware. By accurately identifying the author or group behind a piece of code,\nexperts can better understand the motivations and techniques of developers. In\nthe cybersecurity era, this attribution helps trace the source of malicious\nsoftware, identify patterns in the code that may indicate specific threat\nactors or groups, and ultimately enhance threat intelligence and mitigation\nstrategies. This paper presents AuthAttLyzer-V2, a new source code feature\nextractor for SCAA, focusing on lexical, semantic, syntactic, and N-gram\nfeatures. Our research explores author identification in C++ by examining\n24,000 source code samples from 3,000 authors. Our methodology integrates\nRandom Forest, Gradient Boosting, and XGBoost models, enhanced with SHAP for\ninterpretability. The study demonstrates how ensemble models can effectively\ndiscern individual coding styles, offering insights into the unique attributes\nof code authorship. This approach is pivotal in understanding and interpreting\ncomplex patterns in authorship attribution, especially for malware\nclassification.\n","authors":["Bhaskar Joshi","Sepideh HajiHossein Khani","Arash HabibiLashkari"],"pdf_url":"https://arxiv.org/pdf/2406.19896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19888v1","updated":"2024-06-28T12:54:10Z","published":"2024-06-28T12:54:10Z","title":"Fine-tuning of Geospatial Foundation Models for Aboveground Biomass\n  Estimation","summary":"  Global vegetation structure mapping is critical for understanding the global\ncarbon cycle and maximizing the efficacy of nature-based carbon sequestration\ninitiatives. Moreover, vegetation structure mapping can help reduce the impacts\nof climate change by, for example, guiding actions to improve water security,\nincrease biodiversity and reduce flood risk. Global satellite measurements\nprovide an important set of observations for monitoring and managing\ndeforestation and degradation of existing forests, natural forest regeneration,\nreforestation, biodiversity restoration, and the implementation of sustainable\nagricultural practices. In this paper, we explore the effectiveness of\nfine-tuning of a geospatial foundation model to estimate above-ground biomass\n(AGB) using space-borne data collected across different eco-regions in Brazil.\nThe fine-tuned model architecture consisted of a Swin-B transformer as the\nencoder (i.e., backbone) and a single convolutional layer for the decoder head.\nAll results were compared to a U-Net which was trained as the baseline model\nExperimental results of this sparse-label prediction task demonstrate that the\nfine-tuned geospatial foundation model with a frozen encoder has comparable\nperformance to a U-Net trained from scratch. This is despite the fine-tuned\nmodel having 13 times less parameters requiring optimization, which saves both\ntime and compute resources. Further, we explore the transfer-learning\ncapabilities of the geospatial foundation models by fine-tuning on satellite\nimagery with sparse labels from different eco-regions in Brazil.\n","authors":["Michal Muszynski","Levente Klein","Ademir Ferreira da Silva","Anjani Prasad Atluri","Carlos Gomes","Daniela Szwarcman","Gurkanwar Singh","Kewen Gu","Maciel Zortea","Naomi Simumba","Paolo Fraccaro","Shraddha Singh","Steve Meliksetian","Campbell Watson","Daiki Kimura","Harini Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.19888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19874v1","updated":"2024-06-28T12:28:52Z","published":"2024-06-28T12:28:52Z","title":"Detecting Subtle Differences between Human and Model Languages Using\n  Spectrum of Relative Likelihood","summary":"  Human and model-generated texts can be distinguished by examining the\nmagnitude of likelihood in language. However, it is becoming increasingly\ndifficult as language model's capabilities of generating human-like texts keep\nevolving. This study provides a new perspective by using the relative\nlikelihood values instead of absolute ones, and extracting useful features from\nthe spectrum-view of likelihood for the human-model text detection task. We\npropose a detection procedure with two classification methods, supervised and\nheuristic-based, respectively, which results in competitive performances with\nprevious zero-shot detection methods and a new state-of-the-art on short-text\ndetection. Our method can also reveal subtle differences between human and\nmodel languages, which find theoretical roots in psycholinguistics studies. Our\ncode is available at https://github.com/CLCS-SUSTech/FourierGPT\n","authors":["Yang Xu","Yu Wang","Hao An","Zhichen Liu","Yongyuan Li"],"pdf_url":"https://arxiv.org/pdf/2406.19874v1.pdf","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19859v1","updated":"2024-06-28T11:58:26Z","published":"2024-06-28T11:58:26Z","title":"MetaDesigner: Advancing Artistic Typography through AI-Driven,\n  User-Centric, and Multilingual WordArt Synthesis","summary":"  MetaDesigner revolutionizes artistic typography synthesis by leveraging the\nstrengths of Large Language Models (LLMs) to drive a design paradigm centered\naround user engagement. At the core of this framework lies a multi-agent system\ncomprising the Pipeline, Glyph, and Texture agents, which collectively enable\nthe creation of customized WordArt, ranging from semantic enhancements to the\nimposition of complex textures. MetaDesigner incorporates a comprehensive\nfeedback mechanism that harnesses insights from multimodal models and user\nevaluations to refine and enhance the design process iteratively. Through this\nfeedback loop, the system adeptly tunes hyperparameters to align with\nuser-defined stylistic and thematic preferences, generating WordArt that not\nonly meets but exceeds user expectations of visual appeal and contextual\nrelevance. Empirical validations highlight MetaDesigner's capability to\neffectively serve diverse WordArt applications, consistently producing\naesthetically appealing and context-sensitive results.\n","authors":["Jun-Yan He","Zhi-Qi Cheng","Chenyang Li","Jingdong Sun","Qi He","Wangmeng Xiang","Hanyuan Chen","Jin-Peng Lan","Xianhui Lin","Kang Zhu","Bin Luo","Yifeng Geng","Xuansong Xie","Alexander G. Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2406.19859v1.pdf","comment":"18 pages, 16 figures, Project:\n  https://modelscope.cn/studios/WordArt/WordArt"},{"id":"http://arxiv.org/abs/2406.19853v1","updated":"2024-06-28T11:52:53Z","published":"2024-06-28T11:52:53Z","title":"YuLan: An Open-source Large Language Model","summary":"  Large language models (LLMs) have become the foundation of many applications,\nleveraging their extensive capabilities in processing and understanding natural\nlanguage. While many open-source LLMs have been released with technical\nreports, the lack of training details hinders further research and development.\nThis paper presents the development of YuLan, a series of open-source LLMs with\n$12$ billion parameters. The base model of YuLan is pre-trained on\napproximately $1.7$T tokens derived from a diverse corpus, including massive\nEnglish, Chinese, and multilingual texts. We design a three-stage pre-training\nmethod to enhance YuLan's overall capabilities. Subsequent phases of training\nincorporate instruction-tuning and human alignment, employing a substantial\nvolume of high-quality synthesized data. To facilitate the learning of complex\nand long-tail knowledge, we devise a curriculum-learning framework throughout\nacross these stages, which helps LLMs learn knowledge in an easy-to-hard\nmanner. YuLan's training is finished on Jan, 2024 and has achieved performance\non par with state-of-the-art LLMs across various English and Chinese\nbenchmarks. This paper outlines a comprehensive technical roadmap for\ndeveloping LLMs from scratch. Our model and codes are available at\nhttps://github.com/RUC-GSAI/YuLan-Chat.\n","authors":["Yutao Zhu","Kun Zhou","Kelong Mao","Wentong Chen","Yiding Sun","Zhipeng Chen","Qian Cao","Yihan Wu","Yushuo Chen","Feng Wang","Lei Zhang","Junyi Li","Xiaolei Wang","Lei Wang","Beichen Zhang","Zican Dong","Xiaoxue Cheng","Yuhan Chen","Xinyu Tang","Yupeng Hou","Qiangqiang Ren","Xincheng Pang","Shufang Xie","Wayne Xin Zhao","Zhicheng Dou","Jiaxin Mao","Yankai Lin","Ruihua Song","Jun Xu","Xu Chen","Rui Yan","Zhewei Wei","Di Hu","Wenbing Huang","Ze-Feng Gao","Yueguo Chen","Weizheng Lu","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2406.19853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13699v2","updated":"2024-06-28T11:49:52Z","published":"2024-01-22T03:17:41Z","title":"Generative AI-Driven Human Digital Twin in IoT-Healthcare: A\n  Comprehensive Survey","summary":"  The Internet of things (IoT) can significantly enhance the quality of human\nlife, specifically in healthcare, attracting extensive attentions to\nIoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as\nan innovative paradigm that can comprehensively characterize the replication of\nthe individual human body in the digital world and reflect its physical status\nin real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the\napplication of healthcare monitoring by acting as a versatile and vivid human\ndigital testbed, simulating the outcomes and guiding the practical treatments.\nHowever, successfully establishing HDT requires high-fidelity virtual modeling\nand strong information interactions but possibly with scarce, biased and noisy\ndata. Fortunately, a recent popular technology called generative artificial\nintelligence (GAI) may be a promising solution because it can leverage advanced\nAI algorithms to automatically create, manipulate, and modify valuable while\ndiverse data. This survey particularly focuses on the implementation of\nGAI-driven HDT in IoT-healthcare. We start by introducing the background of\nIoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the\nfundamental techniques and present the overall framework of GAI-driven HDT.\nAfter that, we explore the realization of GAI-driven HDT in detail, including\nGAI-enabled data acquisition, communication, data management, digital modeling,\nand data analysis. Besides, we discuss typical IoT-healthcare applications that\ncan be revolutionized by GAI-driven HDT, namely personalized health monitoring\nand diagnosis, personalized prescription, and personalized rehabilitation.\nFinally, we conclude this survey by highlighting some future research\ndirections.\n","authors":["Jiayuan Chen","You Shi","Changyan Yi","Hongyang Du","Jiawen Kang","Dusit Niyato"],"pdf_url":"https://arxiv.org/pdf/2401.13699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15114v3","updated":"2024-06-28T11:49:51Z","published":"2024-03-22T11:16:11Z","title":"Solving a Real-World Package Delivery Routing Problem Using Quantum\n  Annealers","summary":"  Research focused on the conjunction between quantum computing and routing\nproblems has been very prolific in recent years. Most of the works revolve\naround classical problems such as the Traveling Salesman Problem or the Vehicle\nRouting Problem. The real-world applicability of these problems is dependent on\nthe objectives and constraints considered. Anyway, it is undeniable that it is\noften difficult to translate complex requirements into these classical\nformulations.The main objective of this research is to present a solving scheme\nfor dealing with realistic instances while maintaining all the characteristics\nand restrictions of the original real-world problem. Thus, a quantum-classical\nstrategy has been developed, coined Q4RPD, that considers a set of real\nconstraints such as a heterogeneous fleet of vehicles, priority deliveries, and\ncapacities characterized by two values: weight and dimensions of the packages.\nQ4RPD resorts to the Leap Constrained Quadratic Model Hybrid Solver of D-Wave.\nTo demonstrate the application of Q4RPD, an experimentation composed of six\ndifferent instances has been conducted, aiming to serve as illustrative\nexamples.\n","authors":["Eneko Osaba","Esther Villar-Rodriguez","Antón Asla"],"pdf_url":"https://arxiv.org/pdf/2403.15114v3.pdf","comment":"16 pages, 11 figures and 4 tables. Paper submitted for review in\n  Scientific Reports"},{"id":"http://arxiv.org/abs/2306.02766v3","updated":"2024-06-28T11:39:10Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"  We introduce networked communication to the mean-field game framework, in\nparticular to oracle-free settings where $N$ decentralised agents learn along a\nsingle, non-episodic run of the empirical system. We prove that our\narchitecture, with only a few reasonable assumptions about network structure,\nhas sample guarantees bounded between those of the centralised- and\nindependent-learning cases. We discuss how the sample guarantees of the three\ntheoretical algorithms do not actually result in practical convergence. We\ntherefore show that in practical settings where the theoretical parameters are\nnot observed (leading to poor estimation of the Q-function), our communication\nscheme significantly accelerates convergence over the independent case (and\noften even the centralised case), without relying on the assumption of a\ncentralised learner. We contribute further practical enhancements to all three\ntheoretical algorithms, allowing us to present their first empirical\ndemonstrations. Our experiments confirm that we can remove several of the\ntheoretical assumptions of the algorithms, and display the empirical\nconvergence benefits brought by our new networked communication. We\nadditionally show that the networked approach has significant advantages, over\nboth the centralised and independent alternatives, in terms of robustness to\nunexpected learning failures and to changes in population size.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2306.02766v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02772v6","updated":"2024-06-28T11:33:07Z","published":"2023-10-04T12:42:21Z","title":"Spike Accumulation Forwarding for Effective Training of Spiking Neural\n  Networks","summary":"  In this article, we propose a new paradigm for training spiking neural\nnetworks (SNNs), spike accumulation forwarding (SAF). It is known that SNNs are\nenergy-efficient but difficult to train. Consequently, many researchers have\nproposed various methods to solve this problem, among which online training\nthrough time (OTTT) is a method that allows inferring at each time step while\nsuppressing the memory cost. However, to compute efficiently on GPUs, OTTT\nrequires operations with spike trains and weighted summation of spike trains\nduring forwarding. In addition, OTTT has shown a relationship with the Spike\nRepresentation, an alternative training method, though theoretical agreement\nwith Spike Representation has yet to be proven. Our proposed method can solve\nthese problems; namely, SAF can halve the number of operations during the\nforward process, and it can be theoretically proven that SAF is consistent with\nthe Spike Representation and OTTT, respectively. Furthermore, we confirmed the\nabove contents through experiments and showed that it is possible to reduce\nmemory and training time while maintaining accuracy.\n","authors":["Ryuji Saiin","Tomoya Shirakawa","Sota Yoshihara","Yoshihide Sawada","Hiroyuki Kusumoto"],"pdf_url":"https://arxiv.org/pdf/2310.02772v6.pdf","comment":"14 pages, 5 figures, Appendix:10 pages, 2 figures, v6:Published in\n  Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2406.19840v1","updated":"2024-06-28T11:28:44Z","published":"2024-06-28T11:28:44Z","title":"AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through\n  low-confidence single-token predictions","summary":"  This paper introduces AnomaLLMy, a novel technique for the automatic\ndetection of anomalous tokens in black-box Large Language Models (LLMs) with\nAPI-only access. Utilizing low-confidence single-token predictions as a\ncost-effective indicator, AnomaLLMy identifies irregularities in model\nbehavior, addressing the issue of anomalous tokens degrading the quality and\nreliability of models. Validated on the cl100k_base dataset, the token set of\nGPT-4, AnomaLLMy detected 413 major and 65 minor anomalies, demonstrating the\nmethod's efficiency with just \\$24.39 spent in API credits. The insights from\nthis research are expected to be beneficial for enhancing the robustness of and\naccuracy of LLMs, particularly in the development and assessment of tokenizers.\n","authors":["Waligóra Witold"],"pdf_url":"https://arxiv.org/pdf/2406.19840v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2312.10170v4","updated":"2024-06-28T11:25:41Z","published":"2023-12-15T19:37:39Z","title":"UINav: A Practical Approach to Train On-Device Automation Agents","summary":"  Automation systems that can autonomously drive application user interfaces to\ncomplete user tasks are of great benefit, especially when users are\nsituationally or permanently impaired. Prior automation systems do not produce\ngeneralizable models while AI-based automation agents work reliably only in\nsimple, hand-crafted applications or incur high computation costs. We propose\nUINav, a demonstration-based approach to train automation agents that fit\nmobile devices, yet achieving high success rates with modest numbers of\ndemonstrations. To reduce the demonstration overhead, UINav uses a referee\nmodel that provides users with immediate feedback on tasks where the agent\nfails, and automatically augments human demonstrations to increase diversity in\ntraining data. Our evaluation shows that with only 10 demonstrations UINav can\nachieve 70% accuracy, and that with enough demonstrations it can surpass 90%\naccuracy.\n","authors":["Wei Li","Fu-Lin Hsu","Will Bishop","Folawiyo Campbell-Ajala","Max Lin","Oriana Riva"],"pdf_url":"https://arxiv.org/pdf/2312.10170v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19820v1","updated":"2024-06-28T10:53:48Z","published":"2024-06-28T10:53:48Z","title":"BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for\n  Multi-hop Question Answering","summary":"  Large language models (LLMs) have demonstrated strong reasoning capabilities.\nNevertheless, they still suffer from factual errors when tackling\nknowledge-intensive tasks. Retrieval-augmented reasoning represents a promising\napproach. However, significant challenges still persist, including inaccurate\nand insufficient retrieval for complex questions, as well as difficulty in\nintegrating multi-source knowledge. To address this, we propose Beam\nAggregation Reasoning, BeamAggR, a reasoning framework for knowledge-intensive\nmulti-hop QA. BeamAggR explores and prioritizes promising answers at each hop\nof question. Concretely, we parse the complex questions into trees, which\ninclude atom and composite questions, followed by bottom-up reasoning. For\natomic questions, the LLM conducts reasoning on multi-source knowledge to get\nanswer candidates. For composite questions, the LLM combines beam candidates,\nexplores multiple reasoning paths through probabilistic aggregation, and\nprioritizes the most promising trajectory. Extensive experiments on four\nopen-domain multi-hop reasoning datasets show that our method significantly\noutperforms SOTA methods by 8.5%. Furthermore, our analysis reveals that\nBeamAggR elicits better knowledge collaboration and answer aggregation.\n","authors":["Zheng Chu","Jingchang Chen","Qianglong Chen","Haotian Wang","Kun Zhu","Xiyuan Du","Weijiang Yu","Ming Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2406.19820v1.pdf","comment":"Accepted to ACL 2024"},{"id":"http://arxiv.org/abs/2406.19815v1","updated":"2024-06-28T10:45:37Z","published":"2024-06-28T10:45:37Z","title":"Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based\n  on Multi-dimensional Features","summary":"  Adversarial attack on skeletal motion is a hot topic. However, existing\nresearches only consider part of dynamic features when measuring distance\nbetween skeleton graph sequences, which results in poor imperceptibility. To\nthis end, we propose a novel adversarial attack method to attack action\nrecognizers for skeletal motions. Firstly, our method systematically proposes a\ndynamic distance function to measure the difference between skeletal motions.\nMeanwhile, we innovatively introduce emotional features for complementary\ninformation. In addition, we use Alternating Direction Method of\nMultipliers(ADMM) to solve the constrained optimization problem, which\ngenerates adversarial samples with better imperceptibility to deceive the\nclassifiers. Experiments show that our method is effective on multiple action\nclassifiers and datasets. When the perturbation magnitude measured by l norms\nis the same, the dynamic perturbations generated by our method are much lower\nthan that of other methods. What's more, we are the first to prove the\neffectiveness of emotional features, and provide a new idea for measuring the\ndistance between skeletal motions.\n","authors":["Feng Liu","Qing Xu","Qijian Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.19815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19812v1","updated":"2024-06-28T10:41:17Z","published":"2024-06-28T10:41:17Z","title":"Fuzzy Logic Guided Reward Function Variation: An Oracle for Testing\n  Reinforcement Learning Programs","summary":"  Reinforcement Learning (RL) has gained significant attention across various\ndomains. However, the increasing complexity of RL programs presents testing\nchallenges, particularly the oracle problem: defining the correctness of the RL\nprogram. Conventional human oracles struggle to cope with the complexity,\nleading to inefficiencies and potential unreliability in RL testing. To\nalleviate this problem, we propose an automated oracle approach that leverages\nRL properties using fuzzy logic. Our oracle quantifies an agent's behavioral\ncompliance with reward policies and analyzes its trend over training episodes.\nIt labels an RL program as \"Buggy\" if the compliance trend violates\nexpectations derived from RL characteristics. We evaluate our oracle on RL\nprograms with varying complexities and compare it with human oracles. Results\nshow that while human oracles perform well in simpler testing scenarios, our\nfuzzy oracle demonstrates superior performance in complex environments. The\nproposed approach shows promise in addressing the oracle problem for RL\ntesting, particularly in complex cases where manual testing falls short. It\noffers a potential solution to improve the efficiency, reliability, and\nscalability of RL program testing. This research takes a step towards automated\ntesting of RL programs and highlights the potential of fuzzy logic-based\noracles in tackling the oracle problem.\n","authors":["Shiyu Zhang","Haoyang Song","Qixin Wang","Yu Pei"],"pdf_url":"https://arxiv.org/pdf/2406.19812v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.10133v2","updated":"2024-06-28T10:41:02Z","published":"2024-02-15T17:37:25Z","title":"Zero-Shot Reasoning: Personalized Content Generation Without the Cold\n  Start Problem","summary":"  Procedural content generation uses algorithmic techniques to create large\namounts of new content for games at much lower production costs. In newer\napproaches, procedural content generation utilizes machine learning. However,\nthese methods usually require expensive collection of large amounts of data, as\nwell as the development and training of fairly complex learning models, which\ncan be both extremely time-consuming and expensive. The core of our research is\nto explore whether we can lower the barrier to the use of personalized\nprocedural content generation through a more practical and generalizable\napproach with large language models. Matching game content with player\npreferences benefits both players, who enjoy the game more, and developers, who\nincreasingly depend on players enjoying the game before being able to monetize\nit. Therefore, this paper presents a novel approach to achieving\npersonalization by using large language models to propose levels based on the\ngameplay data continuously collected from individual players. We compared the\nlevels generated using our approach with levels generated with more traditional\nprocedural generation techniques. Our easily reproducible method has proven\nviable in a production setting and outperformed levels generated by traditional\nmethods in the probability that a player will not quit the game mid-level.\n","authors":["Davor Hafnar","Jure Demšar"],"pdf_url":"https://arxiv.org/pdf/2402.10133v2.pdf","comment":"9 pages, 6 figures. Paper accepted to IEEE Transactions on Games"},{"id":"http://arxiv.org/abs/2311.17667v2","updated":"2024-06-28T10:40:26Z","published":"2023-11-29T14:30:16Z","title":"TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in\n  Large Language Models","summary":"  Grasping the concept of time is a fundamental facet of human cognition,\nindispensable for truly comprehending the intricacies of the world. Previous\nstudies typically focus on specific aspects of time, lacking a comprehensive\ntemporal reasoning benchmark. To address this, we propose TimeBench, a\ncomprehensive hierarchical temporal reasoning benchmark that covers a broad\nspectrum of temporal reasoning phenomena. TimeBench provides a thorough\nevaluation for investigating the temporal reasoning capabilities of large\nlanguage models. We conduct extensive experiments on GPT-4, LLaMA2, and other\npopular LLMs under various settings. Our experimental results indicate a\nsignificant performance gap between the state-of-the-art LLMs and humans,\nhighlighting that there is still a considerable distance to cover in temporal\nreasoning. Besides, LLMs exhibit capability discrepancies across different\nreasoning categories. Furthermore, we thoroughly analyze the impact of multiple\naspects on temporal reasoning and emphasize the associated challenges. We\naspire for TimeBench to serve as a comprehensive benchmark, fostering research\nin temporal reasoning. Resources are available at:\nhttps://github.com/zchuz/TimeBench\n","authors":["Zheng Chu","Jingchang Chen","Qianglong Chen","Weijiang Yu","Haotian Wang","Ming Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2311.17667v2.pdf","comment":"Accepted to ACL 2024"},{"id":"http://arxiv.org/abs/2402.18485v3","updated":"2024-06-28T10:35:56Z","published":"2024-02-28T17:06:54Z","title":"A Multimodal Foundation Agent for Financial Trading: Tool-Augmented,\n  Diversified, and Generalist","summary":"  Financial trading is a crucial component of the markets, informed by a\nmultimodal information landscape encompassing news, prices, and Kline charts,\nand encompasses diverse tasks such as quantitative trading and high-frequency\ntrading with various assets. While advanced AI techniques like deep learning\nand reinforcement learning are extensively utilized in finance, their\napplication in financial trading tasks often faces challenges due to inadequate\nhandling of multimodal data and limited generalizability across various tasks.\nTo address these challenges, we present FinAgent, a multimodal foundational\nagent with tool augmentation for financial trading. FinAgent's market\nintelligence module processes a diverse range of data-numerical, textual, and\nvisual-to accurately analyze the financial market. Its unique dual-level\nreflection module not only enables rapid adaptation to market dynamics but also\nincorporates a diversified memory retrieval system, enhancing the agent's\nability to learn from historical data and improve decision-making processes.\nThe agent's emphasis on reasoning for actions fosters trust in its financial\ndecisions. Moreover, FinAgent integrates established trading strategies and\nexpert insights, ensuring that its trading approaches are both data-driven and\nrooted in sound financial principles. With comprehensive experiments on 6\nfinancial datasets, including stocks and Crypto, FinAgent significantly\noutperforms 9 state-of-the-art baselines in terms of 6 financial metrics with\nover 36% average improvement on profit. Specifically, a 92.27% return (a 84.39%\nrelative improvement) is achieved on one dataset. Notably, FinAgent is the\nfirst advanced multimodal foundation agent designed for financial trading\ntasks.\n","authors":["Wentao Zhang","Lingxuan Zhao","Haochong Xia","Shuo Sun","Jiaze Sun","Molei Qin","Xinyi Li","Yuqing Zhao","Yilei Zhao","Xinyu Cai","Longtao Zheng","Xinrun Wang","Bo An"],"pdf_url":"https://arxiv.org/pdf/2402.18485v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19807v1","updated":"2024-06-28T10:30:46Z","published":"2024-06-28T10:30:46Z","title":"Deceptive Diffusion: Generating Synthetic Adversarial Examples","summary":"  We introduce the concept of deceptive diffusion -- training a generative AI\nmodel to produce adversarial images. Whereas a traditional adversarial attack\nalgorithm aims to perturb an existing image to induce a misclassificaton, the\ndeceptive diffusion model can create an arbitrary number of new, misclassified\nimages that are not directly associated with training or test images. Deceptive\ndiffusion offers the possibility of strengthening defence algorithms by\nproviding adversarial training data at scale, including types of\nmisclassification that are otherwise difficult to find. In our experiments, we\nalso investigate the effect of training on a partially attacked data set. This\nhighlights a new type of vulnerability for generative diffusion models: if an\nattacker is able to stealthily poison a portion of the training data, then the\nresulting diffusion model will generate a similar proportion of misleading\noutputs.\n","authors":["Lucas Beerens","Catherine F. Higham","Desmond J. Higham"],"pdf_url":"https://arxiv.org/pdf/2406.19807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16783v2","updated":"2024-06-28T10:14:53Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2402.03216v4","updated":"2024-06-28T09:55:49Z","published":"2024-02-05T17:26:49Z","title":"BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity\n  Text Embeddings Through Self-Knowledge Distillation","summary":"  In this paper, we present a new embedding model, called M3-Embedding, which\nis distinguished for its versatility in Multi-Linguality, Multi-Functionality,\nand Multi-Granularity. It can support more than 100 working languages, leading\nto new state-of-the-art performances on multi-lingual and cross-lingual\nretrieval tasks. It can simultaneously perform the three common retrieval\nfunctionalities of embedding model: dense retrieval, multi-vector retrieval,\nand sparse retrieval, which provides a unified model foundation for real-world\nIR applications. It is able to process inputs of different granularities,\nspanning from short sentences to long documents of up to 8192 tokens. The\neffective training of M3-Embedding involves the following technical\ncontributions. We propose a novel self-knowledge distillation approach, where\nthe relevance scores from different retrieval functionalities can be integrated\nas the teacher signal to enhance the training quality. We also optimize the\nbatching strategy, enabling a large batch size and high training throughput to\nensure the discriminativeness of embeddings. To the best of our knowledge,\nM3-Embedding is the first embedding model which realizes such a strong\nversatility. The model and code will be publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Jianlv Chen","Shitao Xiao","Peitian Zhang","Kun Luo","Defu Lian","Zheng Liu"],"pdf_url":"https://arxiv.org/pdf/2402.03216v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15613v2","updated":"2024-06-28T09:22:38Z","published":"2024-05-24T14:58:51Z","title":"Automatic Data Curation for Self-Supervised Learning: A Clustering-Based\n  Approach","summary":"  Self-supervised features are the cornerstone of modern machine learning\nsystems. They are typically pre-trained on data collections whose construction\nand curation typically require extensive human effort. This manual process has\nsome limitations similar to those encountered in supervised learning, e.g., the\ncrowd-sourced selection of data is costly and time-consuming, preventing\nscaling the dataset size. In this work, we consider the problem of automatic\ncuration of high-quality datasets for self-supervised pre-training. We posit\nthat such datasets should be large, diverse and balanced, and propose a\nclustering-based approach for building ones satisfying all these criteria. Our\nmethod involves successive and hierarchical applications of $k$-means on a\nlarge and diverse data repository to obtain clusters that distribute uniformly\namong data concepts, followed by a hierarchical, balanced sampling step from\nthese clusters. Extensive experiments on three different data domains including\nweb-based images, satellite images and text show that features trained on our\nautomatically curated datasets outperform those trained on uncurated data while\nbeing on par or better than ones trained on manually curated data. Code is\navailable at https://github.com/facebookresearch/ssl-data-curation.\n","authors":["Huy V. Vo","Vasil Khalidov","Timothée Darcet","Théo Moutakanni","Nikita Smetanin","Marc Szafraniec","Hugo Touvron","Camille Couprie","Maxime Oquab","Armand Joulin","Hervé Jégou","Patrick Labatut","Piotr Bojanowski"],"pdf_url":"https://arxiv.org/pdf/2405.15613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19770v1","updated":"2024-06-28T09:17:58Z","published":"2024-06-28T09:17:58Z","title":"Self-Supervised Spatial-Temporal Normality Learning for Time Series\n  Anomaly Detection","summary":"  Time Series Anomaly Detection (TSAD) finds widespread applications across\nvarious domains such as financial markets, industrial production, and\nhealthcare. Its primary objective is to learn the normal patterns of time\nseries data, thereby identifying deviations in test samples. Most existing TSAD\nmethods focus on modeling data from the temporal dimension, while ignoring the\nsemantic information in the spatial dimension. To address this issue, we\nintroduce a novel approach, called Spatial-Temporal Normality learning (STEN).\nSTEN is composed of a sequence Order prediction-based Temporal Normality\nlearning (OTN) module that captures the temporal correlations within sequences,\nand a Distance prediction-based Spatial Normality learning (DSN) module that\nlearns the relative spatial relations between sequences in a feature space. By\nsynthesizing these two modules, STEN learns expressive spatial-temporal\nrepresentations for the normal patterns hidden in the time series data.\nExtensive experiments on five popular TSAD benchmarks show that STEN\nsubstantially outperforms state-of-the-art competing methods. Our code is\navailable at https://github.com/mala-lab/STEN.\n","authors":["Yutong Chen","Hongzuo Xu","Guansong Pang","Hezhe Qiao","Yuan Zhou","Mingsheng Shang"],"pdf_url":"https://arxiv.org/pdf/2406.19770v1.pdf","comment":"18 pages, 4 figures, accepted in ECML PKDD2024"},{"id":"http://arxiv.org/abs/2304.01468v2","updated":"2024-06-28T09:17:31Z","published":"2023-04-04T02:13:46Z","title":"DLRover-RM: Resource Optimization for Deep Recommendation Models\n  Training in the Cloud","summary":"  Deep learning recommendation models (DLRM) rely on large embedding tables to\nmanage categorical sparse features. Expanding such embedding tables can\nsignificantly enhance model performance, but at the cost of increased\nGPU/CPU/memory usage. Meanwhile, tech companies have built extensive\ncloud-based services to accelerate training DLRM models at scale. In this\npaper, we conduct a deep investigation of the DLRM training platforms at\nAntGroup and reveal two critical challenges: low resource utilization due to\nsuboptimal configurations by users and the tendency to encounter abnormalities\ndue to an unstable cloud environment. To overcome them, we introduce\nDLRover-RM, an elastic training framework for DLRMs designed to increase\nresource utilization and handle the instability of a cloud environment.\nDLRover-RM develops a resource-performance model by considering the unique\ncharacteristics of DLRMs and a three-stage heuristic strategy to automatically\nallocate and dynamically adjust resources for DLRM training jobs for higher\nresource utilization. Further, DLRover-RM develops multiple mechanisms to\nensure efficient and reliable execution of DLRM training jobs. Our extensive\nevaluation shows that DLRover-RM reduces job completion times by 31%, increases\nthe job completion rate by 6%, enhances CPU usage by 15%, and improves memory\nutilization by 20%, compared to state-of-the-art resource scheduling\nframeworks. DLRover-RM has been widely deployed at AntGroup and processes\nthousands of DLRM training jobs on a daily basis. DLRover-RM is open-sourced\nand has been adopted by 10+ companies.\n","authors":["Qinlong Wang","Tingfeng Lan","Yinghao Tang","Ziling Huang","Yiheng Du","Haitao Zhang","Jian Sha","Hui Lu","Yuanchun Zhou","Ke Zhang","Mingjie Tang"],"pdf_url":"https://arxiv.org/pdf/2304.01468v2.pdf","comment":"Accepted in VLDB'24"},{"id":"http://arxiv.org/abs/2406.10552v3","updated":"2024-06-28T09:16:28Z","published":"2024-06-15T08:13:47Z","title":"Large Language Model Enhanced Clustering for News Event Detection","summary":"  The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labelling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes multiple feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that the use of LLM embedding in the event detection framework has\nsignificantly improved the results, demonstrating greater robustness in terms\nof CSAI scores. Moreover, post-event detection tasks generate meaningful\ninsights, facilitating effective interpretation of event clustering results.\nOverall, our experimental results indicate that the proposed framework offers\nvaluable insights and could enhance the accuracy in news analysis and\nreporting.\n","authors":["Adane Nega Tarekegn"],"pdf_url":"https://arxiv.org/pdf/2406.10552v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19763v1","updated":"2024-06-28T09:06:52Z","published":"2024-06-28T09:06:52Z","title":"xSemAD: Explainable Semantic Anomaly Detection in Event Logs Using\n  Sequence-to-Sequence Models","summary":"  The identification of undesirable behavior in event logs is an important\naspect of process mining that is often addressed by anomaly detection methods.\nTraditional anomaly detection methods tend to focus on statistically rare\nbehavior and neglect the subtle difference between rarity and undesirability.\nThe introduction of semantic anomaly detection has opened a promising avenue by\nidentifying semantically deviant behavior. This work addresses a gap in\nsemantic anomaly detection, which typically indicates the occurrence of an\nanomaly without explaining the nature of the anomaly. We propose xSemAD, an\napproach that uses a sequence-to-sequence model to go beyond pure\nidentification and provides extended explanations. In essence, our approach\nlearns constraints from a given process model repository and then checks\nwhether these constraints hold in the considered event log. This approach not\nonly helps understand the specifics of the undesired behavior, but also\nfacilitates targeted corrective actions. Our experiments demonstrate that our\napproach outperforms existing state-of-the-art semantic anomaly detection\nmethods.\n","authors":["Kiran Busch","Timotheus Kampik","Henrik Leopold"],"pdf_url":"https://arxiv.org/pdf/2406.19763v1.pdf","comment":"Accepted at BPM 2024"},{"id":"http://arxiv.org/abs/2406.15486v2","updated":"2024-06-28T08:55:17Z","published":"2024-06-17T11:05:15Z","title":"SampleAttention: Near-Lossless Acceleration of Long Context LLM\n  Inference with Adaptive Structured Sparse Attention","summary":"  Large language models (LLMs) now support extremely long context windows, but\nthe quadratic complexity of vanilla attention results in significantly long\nTime-to-First-Token (TTFT) latency. Existing approaches to address this\ncomplexity require additional pretraining or finetuning, and often sacrifice\nmodel accuracy. In this paper, we first provide both theoretical and empirical\nfoundations for near-lossless sparse attention. We find dynamically capturing\nhead-specific sparse patterns at runtime with low overhead is crucial. To\naddress this, we propose SampleAttention, an adaptive structured and\nnear-lossless sparse attention. Leveraging observed significant sparse\npatterns, SampleAttention attends to a fixed percentage of adjacent tokens to\ncapture local window patterns, and employs a two-stage query-guided key-value\nfiltering approach, which adaptively select a minimum set of key-values with\nlow overhead, to capture column stripe patterns. Comprehensive evaluations show\nthat SampleAttention can seamlessly replace vanilla attention in off-the-shelf\nLLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\\times$\ncompared with FlashAttention.\n","authors":["Qianchao Zhu","Jiangfei Duan","Chang Chen","Siran Liu","Xiuhong Li","Guanyu Feng","Xin Lv","Huanqi Cao","Xiao Chuanfu","Xingcheng Zhang","Dahua Lin","Chao Yang"],"pdf_url":"https://arxiv.org/pdf/2406.15486v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19756v1","updated":"2024-06-28T08:54:44Z","published":"2024-06-28T08:54:44Z","title":"Structure-aware World Model for Probe Guidance via Large-scale\n  Self-supervised Pre-train","summary":"  The complex structure of the heart leads to significant challenges in\nechocardiography, especially in acquisition cardiac ultrasound images.\nSuccessful echocardiography requires a thorough understanding of the structures\non the two-dimensional plane and the spatial relationships between planes in\nthree-dimensional space. In this paper, we innovatively propose a large-scale\nself-supervised pre-training method to acquire a cardiac structure-aware world\nmodel. The core innovation lies in constructing a self-supervised task that\nrequires structural inference by predicting masked structures on a 2D plane and\nimagining another plane based on pose transformation in 3D space. To support\nlarge-scale pre-training, we collected over 1.36 million echocardiograms from\nten standard views, along with their 3D spatial poses. In the downstream probe\nguidance task, we demonstrate that our pre-trained model consistently reduces\nguidance errors across the ten most common standard views on the test set with\n0.29 million samples from 74 routine clinical scans, indicating that\nstructure-aware pre-training benefits the scanning.\n","authors":["Haojun Jiang","Meng Li","Zhenguo Sun","Ning Jia","Yu Sun","Shaqi Luo","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.19756v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.19755v1","updated":"2024-06-28T08:54:37Z","published":"2024-06-28T08:54:37Z","title":"Protein Representation Learning with Sequence Information Embedding:\n  Does it Always Lead to a Better Performance?","summary":"  Deep learning has become a crucial tool in studying proteins. While the\nsignificance of modeling protein structure has been discussed extensively in\nthe literature, amino acid types are typically included in the input as a\ndefault operation for many inference tasks. This study demonstrates with\nstructure alignment task that embedding amino acid types in some cases may not\nhelp a deep learning model learn better representation. To this end, we propose\nProtLOCA, a local geometry alignment method based solely on amino acid\nstructure representation. The effectiveness of ProtLOCA is examined by a global\nstructure-matching task on protein pairs with an independent test dataset based\non CATH labels. Our method outperforms existing sequence- and structure-based\nrepresentation learning methods by more quickly and accurately matching\nstructurally consistent protein domains. Furthermore, in local structure\npairing tasks, ProtLOCA for the first time provides a valid solution to\nhighlight common local structures among proteins with different overall\nstructures but the same function. This suggests a new possibility for using\ndeep learning methods to analyze protein structure to infer function.\n","authors":["Yang Tan","Lirong Zheng","Bozitao Zhong","Liang Hong","Bingxin Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.19755v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.00532v2","updated":"2024-06-28T08:48:06Z","published":"2024-05-01T14:05:52Z","title":"ULLER: A Unified Language for Learning and Reasoning","summary":"  The field of neuro-symbolic artificial intelligence (NeSy), which combines\nlearning and reasoning, has recently experienced significant growth. There now\nare a wide variety of NeSy frameworks, each with its own specific language for\nexpressing background knowledge and how to relate it to neural networks. This\nheterogeneity hinders accessibility for newcomers and makes comparing different\nNeSy frameworks challenging. We propose a language for NeSy, which we call\nULLER, a Unfied Language for LEarning and Reasoning. ULLER encompasses a wide\nvariety of settings, while ensuring that knowledge described in it can be used\nin existing NeSy systems. ULLER has a first-order logic syntax specialised for\nNeSy for which we provide example semantics including classical FOL, fuzzy\nlogic, and probabilistic logic. We believe ULLER is a first step towards making\nNeSy research more accessible and comparable, paving the way for libraries that\nstreamline training and evaluation across a multitude of semantics, knowledge\nbases, and NeSy systems.\n","authors":["Emile van Krieken","Samy Badreddine","Robin Manhaeve","Eleonora Giunchiglia"],"pdf_url":"https://arxiv.org/pdf/2405.00532v2.pdf","comment":"Accepted at NeSy 2024"},{"id":"http://arxiv.org/abs/2402.13914v2","updated":"2024-06-28T08:37:28Z","published":"2024-02-21T16:30:24Z","title":"Position: Explain to Question not to Justify","summary":"  Explainable Artificial Intelligence (XAI) is a young but very promising field\nof research. Unfortunately, the progress in this field is currently slowed down\nby divergent and incompatible goals. We separate various threads tangled within\nthe area of XAI into two complementary cultures of human/value-oriented\nexplanations (BLUE XAI) and model/validation-oriented explanations (RED XAI).\nThis position paper argues that the area of RED XAI is currently\nunder-explored, i.e., more methods for explainability are desperately needed to\nquestion models (e.g., extract knowledge from well-performing models as well as\nspotting and fixing bugs in faulty models), and the area of RED XAI hides great\nopportunities and potential for important research necessary to ensure the\nsafety of AI systems. We conclude this paper by presenting promising challenges\nin this area.\n","authors":["Przemyslaw Biecek","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2402.13914v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19741v1","updated":"2024-06-28T08:28:38Z","published":"2024-06-28T08:28:38Z","title":"ROS-LLM: A ROS framework for embodied AI with task feedback and\n  structured reasoning","summary":"  We present a framework for intuitive robot programming by non-experts,\nleveraging natural language prompts and contextual information from the Robot\nOperating System (ROS). Our system integrates large language models (LLMs),\nenabling non-experts to articulate task requirements to the system through a\nchat interface. Key features of the framework include: integration of ROS with\nan AI agent connected to a plethora of open-source and commercial LLMs,\nautomatic extraction of a behavior from the LLM output and execution of ROS\nactions/services, support for three behavior modes (sequence, behavior tree,\nstate machine), imitation learning for adding new robot actions to the library\nof possible actions, and LLM reflection via human and environment feedback.\nExtensive experiments validate the framework, showcasing robustness,\nscalability, and versatility in diverse scenarios, including long-horizon\ntasks, tabletop rearrangements, and remote supervisory control. To facilitate\nthe adoption of our framework and support the reproduction of our results, we\nhave made our code open-source. You can access it at:\nhttps://github.com/huawei-noah/HEBO/tree/master/ROSLLM.\n","authors":["Christopher E. Mower","Yuhui Wan","Hongzhan Yu","Antoine Grosnit","Jonas Gonzalez-Billandon","Matthieu Zimmer","Jinlong Wang","Xinyu Zhang","Yao Zhao","Anbang Zhai","Puze Liu","Davide Tateo","Cesar Cadena","Marco Hutter","Jan Peters","Guangjian Tian","Yuzheng Zhuang","Kun Shao","Xingyue Quan","Jianye Hao","Jun Wang","Haitham Bou-Ammar"],"pdf_url":"https://arxiv.org/pdf/2406.19741v1.pdf","comment":"This document contains 26 pages and 13 figures"},{"id":"http://arxiv.org/abs/2406.19738v1","updated":"2024-06-28T08:26:47Z","published":"2024-06-28T08:26:47Z","title":"Classical Bandit Algorithms for Entanglement Detection in Parameterized\n  Qubit States","summary":"  Entanglement is a key resource for a wide range of tasks in quantum\ninformation and computing. Thus, verifying availability of this quantum\nresource is essential. Extensive research on entanglement detection has led to\nno-go theorems (Lu et al. [Phys. Rev. Lett., 116, 230501 (2016)]) that\nhighlight the need for full state tomography (FST) in the absence of adaptive\nor joint measurements. Recent advancements, as proposed by Zhu, Teo, and\nEnglert [Phys. Rev. A, 81, 052339, 2010], introduce a single-parameter family\nof entanglement witness measurements which are capable of conclusively\ndetecting certain entangled states and only resort to FST when all witness\nmeasurements are inconclusive. We find a variety of realistic noisy two-qubit\nquantum states $\\mathcal{F}$ that yield conclusive results under this witness\nfamily. We solve the problem of detecting entanglement among $K$ quantum states\nin $\\mathcal{F}$, of which $m$ states are entangled, with $m$ potentially\nunknown. We recognize a structural connection of this problem to the Bad Arm\nIdentification problem in stochastic Multi-Armed Bandits (MAB). In contrast to\nexisting quantum bandit frameworks, we establish a new correspondence tailored\nfor entanglement detection and term it the $(m,K)$-quantum Multi-Armed Bandit.\nWe implement two well-known MAB policies for arbitrary states derived from\n$\\mathcal{F}$, present theoretical guarantees on the measurement/sample\ncomplexity and demonstrate the practicality of the policies through numerical\nsimulations. More broadly, this paper highlights the potential for employing\nclassical machine learning techniques for quantum entanglement detection.\n","authors":["Bharati. K","Vikesh Siddhu","Krishna Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2406.19738v1.pdf","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.19736v1","updated":"2024-06-28T08:25:27Z","published":"2024-06-28T08:25:27Z","title":"MM-Instruct: Generated Visual Instructions for Large Multimodal Model\n  Alignment","summary":"  This paper introduces MM-Instruct, a large-scale dataset of diverse and\nhigh-quality visual instruction data designed to enhance the\ninstruction-following capabilities of large multimodal models (LMMs). While\nexisting visual instruction datasets often focus on question-answering, they\nstruggle to generalize to broader application scenarios such as creative\nwriting, summarization, or image analysis. To address these limitations, we\npropose a novel approach to constructing MM-Instruct that leverages the strong\ninstruction-following capabilities of existing LLMs to generate novel visual\ninstruction data from large-scale but conventional image captioning datasets.\nMM-Instruct first leverages ChatGPT to automatically generate diverse\ninstructions from a small set of seed instructions through augmenting and\nsummarization. It then matches these instructions with images and uses an\nopen-sourced large language model (LLM) to generate coherent answers to the\ninstruction-image pairs. The LLM is grounded by the detailed text descriptions\nof images in the whole answer generation process to guarantee the alignment of\nthe instruction data. Moreover, we introduce a benchmark based on the generated\ninstruction data to evaluate the instruction-following capabilities of existing\nLMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5\nmodel on the generated data, denoted as LLaVA-Instruct, which exhibits\nsignificant improvements in instruction-following capabilities compared to\nLLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models\nare available at https://github.com/jihaonew/MM-Instruct.\n","authors":["Jihao Liu","Xin Huang","Jinliang Zheng","Boxiao Liu","Jia Wang","Osamu Yoshie","Yu Liu","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.19736v1.pdf","comment":"Dataset and models are available at\n  https://github.com/jihaonew/MM-Instruct"},{"id":"http://arxiv.org/abs/2307.10635v3","updated":"2024-06-28T08:24:13Z","published":"2023-07-20T07:01:57Z","title":"SciBench: Evaluating College-Level Scientific Problem-Solving Abilities\n  of Large Language Models","summary":"  Most of the existing Large Language Model (LLM) benchmarks on scientific\nproblem reasoning focus on problems grounded in high-school subjects and are\nconfined to elementary algebraic operations. To systematically examine the\nreasoning capabilities required for solving complex scientific problems, we\nintroduce an expansive benchmark suite SciBench for LLMs. SciBench contains a\ncarefully curated dataset featuring a range of collegiate-level scientific\nproblems from mathematics, chemistry, and physics domains. Based on the\ndataset, we conduct an in-depth benchmarking study of representative\nopen-source and proprietary LLMs with various prompting strategies. The results\nreveal that the current LLMs fall short of delivering satisfactory performance,\nwith the best overall score of merely 43.22%. Furthermore, through a detailed\nuser study, we categorize the errors made by LLMs into ten problem-solving\nabilities. Our analysis indicates that no single prompting strategy\nsignificantly outperforms the others and some strategies that demonstrate\nimprovements in certain problem-solving skills could result in declines in\nother skills. We envision that SciBench will catalyze further developments in\nthe reasoning abilities of LLMs, thereby ultimately contributing to scientific\nresearch and discovery.\n","authors":["Xiaoxuan Wang","Ziniu Hu","Pan Lu","Yanqiao Zhu","Jieyu Zhang","Satyen Subramaniam","Arjun R. Loomba","Shichang Zhang","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2307.10635v3.pdf","comment":"To appear at ICML 2024"},{"id":"http://arxiv.org/abs/2402.08114v2","updated":"2024-06-28T08:22:01Z","published":"2024-02-12T23:09:00Z","title":"Active Preference Learning for Large Language Models","summary":"  As large language models (LLMs) become more capable, fine-tuning techniques\nfor aligning with human intent are increasingly important. A key consideration\nfor aligning these models is how to most effectively use human resources, or\nmodel resources in the case where LLMs themselves are used as oracles.\nReinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most\nprominent example of such a technique, but is complex and often unstable.\nDirect Preference Optimization (DPO) has recently been proposed as a simpler\nand more stable alternative. In this work, we develop an active learning\nstrategy for DPO to make better use of preference labels. We propose a\npractical acquisition function for prompt/completion pairs based on the\npredictive entropy of the language model and a measure of certainty of the\nimplicit preference model optimized by DPO. We demonstrate how our approach\nimproves both the rate of learning and final performance of fine-tuning on\npairwise preference data.\n","authors":["William Muldrew","Peter Hayes","Mingtian Zhang","David Barber"],"pdf_url":"https://arxiv.org/pdf/2402.08114v2.pdf","comment":"13 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.19720v1","updated":"2024-06-28T08:09:55Z","published":"2024-06-28T08:09:55Z","title":"CUPID: Improving Battle Fairness and Position Satisfaction in Online\n  MOBA Games with a Re-matchmaking System","summary":"  The multiplayer online battle arena (MOBA) genre has gained significant\npopularity and economic success, attracting considerable research interest\nwithin the Human-Computer Interaction community. Enhancing the gaming\nexperience requires a deep understanding of player behavior, and a crucial\naspect of MOBA games is matchmaking, which aims to assemble teams of comparable\nskill levels. However, existing matchmaking systems often neglect important\nfactors such as players' position preferences and team assignment, resulting in\nimbalanced matches and reduced player satisfaction. To address these\nlimitations, this paper proposes a novel framework called CUPID, which\nintroduces a novel process called ``re-matchmaking'' to optimize team and\nposition assignments to improve both fairness and player satisfaction. CUPID\nincorporates a pre-filtering step to ensure a minimum level of matchmaking\nquality, followed by a pre-match win-rate prediction model that evaluates the\nfairness of potential assignments. By simultaneously considering players'\nposition satisfaction and game fairness, CUPID aims to provide an enhanced\nmatchmaking experience. Extensive experiments were conducted on two\nlarge-scale, real-world MOBA datasets to validate the effectiveness of CUPID.\nThe results surpass all existing state-of-the-art baselines, with an average\nrelative improvement of 7.18% in terms of win prediction accuracy. Furthermore,\nCUPID has been successfully deployed in a popular online mobile MOBA game. The\ndeployment resulted in significant improvements in match fairness and player\nsatisfaction, as evidenced by critical Human-Computer Interaction (HCI) metrics\ncovering usability, accessibility, and engagement, observed through A/B\ntesting. To the best of our knowledge, CUPID is the first re-matchmaking system\ndesigned specifically for large-scale MOBA games.\n","authors":["Ge Fan","Chaoyun Zhang","Kai Wang","Yingjie Li","Junyang Chen","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2406.19720v1.pdf","comment":"38 pages, accepted by CSCW 24"},{"id":"http://arxiv.org/abs/2403.09703v2","updated":"2024-06-28T08:03:19Z","published":"2024-03-08T19:07:47Z","title":"Concept-aware Data Construction Improves In-context Learning of Language\n  Models","summary":"  Many recent language models (LMs) are capable of in-context learning (ICL),\nmanifested in the LMs' ability to perform a new task solely from\nnatural-language instruction. Previous work curating in-context learners\nassumes that ICL emerges from a vast over-parametrization or the scale of\nmulti-task training. However, recent theoretical work attributes the ICL\nability to concept-dependent training data and creates functional in-context\nlearners even in small-scale, synthetic settings.\n  In this work, we practically explore this newly identified axis of ICL\nquality. We propose Concept-aware Training (CoAT), a framework for constructing\ntraining scenarios that make it beneficial for the LM to learn to utilize the\nanalogical reasoning concepts from demonstrations. We find that by using CoAT,\npre-trained transformers can learn to better utilise new latent concepts from\ndemonstrations and that such ability makes ICL more robust to the functional\ndeficiencies of the previous models. Finally, we show that concept-aware\nin-context learning is more effective for a majority of new tasks when compared\nto traditional instruction tuning, resulting in a performance comparable to the\nprevious in-context learners using magnitudes of more training data.\n","authors":["Michal Štefánik","Marek Kadlčík","Petr Sojka"],"pdf_url":"https://arxiv.org/pdf/2403.09703v2.pdf","comment":"Long paper to appear in Findings of ACL 2024"},{"id":"http://arxiv.org/abs/2406.19712v1","updated":"2024-06-28T07:47:34Z","published":"2024-06-28T07:47:34Z","title":"Uncertainty Quantification in Large Language Models Through Convex Hull\n  Analysis","summary":"  Uncertainty quantification approaches have been more critical in large\nlanguage models (LLMs), particularly high-risk applications requiring reliable\noutputs. However, traditional methods for uncertainty quantification, such as\nprobabilistic models and ensemble techniques, face challenges when applied to\nthe complex and high-dimensional nature of LLM-generated outputs. This study\nproposes a novel geometric approach to uncertainty quantification using convex\nhull analysis. The proposed method leverages the spatial properties of response\nembeddings to measure the dispersion and variability of model outputs. The\nprompts are categorized into three types, i.e., `easy', `moderate', and\n`confusing', to generate multiple responses using different LLMs at varying\ntemperature settings. The responses are transformed into high-dimensional\nembeddings via a BERT model and subsequently projected into a two-dimensional\nspace using Principal Component Analysis (PCA). The Density-Based Spatial\nClustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster\nthe embeddings and compute the convex hull for each selected cluster. The\nexperimental results indicate that the uncertainty of the model for LLMs\ndepends on the prompt complexity, the model, and the temperature setting.\n","authors":["Ferhat Ozgur Catak","Murat Kuzlu"],"pdf_url":"https://arxiv.org/pdf/2406.19712v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2406.19708v1","updated":"2024-06-28T07:41:31Z","published":"2024-06-28T07:41:31Z","title":"A Differentiable Approach to Multi-scale Brain Modeling","summary":"  We present a multi-scale differentiable brain modeling workflow utilizing\nBrainPy, a unique differentiable brain simulator that combines accurate brain\nsimulation with powerful gradient-based optimization. We leverage this\ncapability of BrainPy across different brain scales. At the single-neuron\nlevel, we implement differentiable neuron models and employ gradient methods to\noptimize their fit to electrophysiological data. On the network level, we\nincorporate connectomic data to construct biologically constrained network\nmodels. Finally, to replicate animal behavior, we train these models on\ncognitive tasks using gradient-based learning rules. Experiments demonstrate\nthat our approach achieves superior performance and speed in fitting\ngeneralized leaky integrate-and-fire and Hodgkin-Huxley single neuron models.\nAdditionally, training a biologically-informed network of excitatory and\ninhibitory spiking neurons on working memory tasks successfully replicates\nobserved neural activity and synaptic weight distributions. Overall, our\ndifferentiable multi-scale simulation approach offers a promising tool to\nbridge neuroscience data across electrophysiological, anatomical, and\nbehavioral scales.\n","authors":["Chaoming Wang","Muyang Lyu","Tianqiu Zhang","Sichao He","Si Wu"],"pdf_url":"https://arxiv.org/pdf/2406.19708v1.pdf","comment":"2nd Differentiable Almost Everything Workshop at ICML 2024"},{"id":"http://arxiv.org/abs/2406.19705v1","updated":"2024-06-28T07:36:31Z","published":"2024-06-28T07:36:31Z","title":"DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial\n  Optimization Problems","summary":"  Combinatorial Optimization (CO) problems are fundamentally crucial in\nnumerous practical applications across diverse industries, characterized by\nentailing enormous solution space and demanding time-sensitive response.\nDespite significant advancements made by recent neural solvers, their limited\nexpressiveness does not conform well to the multi-modal nature of CO\nlandscapes. While some research has pivoted towards diffusion models, they\nrequire simulating a Markov chain with many steps to produce a sample, which is\ntime-consuming and does not meet the efficiency requirement of real\napplications, especially at scale. We propose DISCO, an efficient DIffusion\nSolver for Combinatorial Optimization problems that excels in both solution\nquality and inference speed. DISCO's efficacy is two-pronged: Firstly, it\nachieves rapid denoising of solutions through an analytically solvable form,\nallowing for direct sampling from the solution space with very few reverse-time\nsteps, thereby drastically reducing inference time. Secondly, DISCO enhances\nsolution quality by restricting the sampling space to a more constrained,\nmeaningful domain guided by solution residues, while still preserving the\ninherent multi-modality of the output probabilistic distributions. DISCO\nachieves state-of-the-art results on very large Traveling Salesman Problems\nwith 10000 nodes and challenging Maximal Independent Set benchmarks, with its\nper-instance denoising time up to 44.8 times faster. Through further combining\na divide-and-conquer strategy, DISCO can be generalized to solve\narbitrary-scale problem instances off the shelf, even outperforming models\ntrained specifically on corresponding scales.\n","authors":["Kexiong Yu","Hang Zhao","Yuhang Huang","Renjiao Yi","Kai Xu","Chenyang Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.19705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18584v2","updated":"2024-06-28T07:34:25Z","published":"2024-06-06T06:22:06Z","title":"Assessment of Sentinel-2 spatial and temporal coverage based on the\n  scene classification layer","summary":"  Since the launch of the Sentinel-2 (S2) satellites, many ML models have used\nthe data for diverse applications. The scene classification layer (SCL) inside\nthe S2 product provides rich information for training, such as filtering images\nwith high cloud coverage. However, there is more potential in this. We propose\na technique to assess the clean optical coverage of a region, expressed by a\nSITS and calculated with the S2-based SCL data. With a manual threshold and\nspecific labels in the SCL, the proposed technique assigns a percentage of\nspatial and temporal coverage across the time series and a high/low assessment.\nBy evaluating the AI4EO challenge for Enhanced Agriculture, we show that the\nassessment is correlated to the predictive results of ML models. The\nclassification results in a region with low spatial and temporal coverage is\nworse than in a region with high coverage. Finally, we applied the technique\nacross all continents of the global dataset LandCoverNet.\n","authors":["Cristhian Sanchez","Francisco Mena","Marcela Charfuelan","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2406.18584v2.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2024"},{"id":"http://arxiv.org/abs/2402.11622v2","updated":"2024-06-28T07:20:22Z","published":"2024-02-18T15:28:39Z","title":"Logical Closed Loop: Uncovering Object Hallucinations in Large\n  Vision-Language Models","summary":"  Object hallucination has been an Achilles' heel which hinders the broader\napplications of large vision-language models (LVLMs). Object hallucination\nrefers to the phenomenon that the LVLMs claim non-existent objects in the\nimage. To mitigate the object hallucinations, instruction tuning and external\nmodel-based detection methods have been proposed, which either require\nlarge-scare computational resources or depend on the detection result of\nexternal models. However, there remains an under-explored field to utilize the\nLVLM itself to alleviate object hallucinations. In this work, we adopt the\nintuition that the LVLM tends to respond logically consistently for existent\nobjects but inconsistently for hallucinated objects. Therefore, we propose a\nLogical Closed Loop-based framework for Object Hallucination Detection and\nMitigation, namely LogicCheckGPT. In specific, we devise logical consistency\nprobing to raise questions with logical correlations, inquiring about\nattributes from objects and vice versa. Whether their responses can form a\nlogical closed loop serves as an indicator of object hallucination. As a\nplug-and-play method, it can be seamlessly applied to all existing LVLMs.\nComprehensive experiments conducted on three benchmarks across four LVLMs have\ndemonstrated significant improvements brought by our method, indicating its\neffectiveness and generality.\n","authors":["Junfei Wu","Qiang Liu","Ding Wang","Jinghao Zhang","Shu Wu","Liang Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2402.11622v2.pdf","comment":"Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2406.19690v1","updated":"2024-06-28T07:06:02Z","published":"2024-06-28T07:06:02Z","title":"Deep Fusion Model for Brain Tumor Classification Using Fine-Grained\n  Gradient Preservation","summary":"  Brain tumors are one of the most common diseases that lead to early death if\nnot diagnosed at an early stage. Traditional diagnostic approaches are\nextremely time-consuming and prone to errors. In this context, computer\nvision-based approaches have emerged as an effective tool for accurate brain\ntumor classification. While some of the existing solutions demonstrate\nnoteworthy accuracy, the models become infeasible to deploy in areas where\ncomputational resources are limited. This research addresses the need for\naccurate and fast classification of brain tumors with a priority of deploying\nthe model in technologically underdeveloped regions. The research presents a\nnovel architecture for precise brain tumor classification fusing pretrained\nResNet152V2 and modified VGG16 models. The proposed architecture undergoes a\ndiligent fine-tuning process that ensures fine gradients are preserved in deep\nneural networks, which are essential for effective brain tumor classification.\nThe proposed solution incorporates various image processing techniques to\nimprove image quality and achieves an astounding accuracy of 98.36% and 98.04%\nin Figshare and Kaggle datasets respectively. This architecture stands out for\nhaving a streamlined profile, with only 2.8 million trainable parameters. We\nhave leveraged 8-bit quantization to produce a model of size 73.881 MB,\nsignificantly reducing it from the previous size of 289.45 MB, ensuring smooth\ndeployment in edge devices even in resource-constrained areas. Additionally,\nthe use of Grad-CAM improves the interpretability of the model, offering\ninsightful information regarding its decision-making process. Owing to its high\ndiscriminative ability, this model can be a reliable option for accurate brain\ntumor classification.\n","authors":["Niful Islam","Mohaiminul Islam Bhuiyan","Jarin Tasnim Raya","Nur Shazwani Kamarudin","Khan Md Hasib","M. F. Mridha","Dewan Md. Farid"],"pdf_url":"https://arxiv.org/pdf/2406.19690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19686v1","updated":"2024-06-28T06:51:38Z","published":"2024-06-28T06:51:38Z","title":"Enhancing Radiological Diagnosis: A Collaborative Approach Integrating\n  AI and Human Expertise for Visual Miss Correction","summary":"  Human-AI collaboration to identify and correct perceptual errors in chest\nradiographs has not been previously explored. This study aimed to develop a\ncollaborative AI system, CoRaX, which integrates eye gaze data and radiology\nreports to enhance diagnostic accuracy in chest radiology by pinpointing\nperceptual errors and refining the decision-making process. Using public\ndatasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX,\nemploying a large multimodal model to analyze image embeddings, eye gaze data,\nand radiology reports. The system's effectiveness was evaluated based on its\nreferral-making process, the quality of referrals, and performance in\ncollaborative diagnostic settings. CoRaX was tested on a simulated error\ndataset of 271 samples with 28% (93 of 332) missed abnormalities. The system\ncorrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved.\nThe Referral-Usefulness score, indicating the accuracy of predicted regions for\nall true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score,\nreflecting the diagnostic accuracy of CoRaX's interactions with radiologists,\nshowed that 84% (237 of 280) of these interactions had a score above 0.40. In\nconclusion, CoRaX efficiently collaborates with radiologists to address\nperceptual errors across various abnormalities, with potential applications in\nthe education and training of novice radiologists.\n","authors":["Akash Awasthi","Ngan Le","Zhigang Deng","Carol C. Wu","Hien Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2406.19686v1.pdf","comment":"Under Review in Journal"},{"id":"http://arxiv.org/abs/2402.03848v6","updated":"2024-06-28T06:49:39Z","published":"2024-02-06T09:50:08Z","title":"ANLS* -- A Universal Document Processing Metric for Generative Large\n  Language Models","summary":"  Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, and more than 10 different GLLMs\ntogether with 3 different prompting methods using the ANLS* metric is also\nprovided, demonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In 6 out of 7 cases, SFT\noutperforms other techniques and improves the state-of-the-art, sometimes by as\nmuch as $10$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric\n","authors":["David Peer","Philemon Schöpf","Volckmar Nebendahl","Alexander Rietzler","Sebastian Stabinger"],"pdf_url":"https://arxiv.org/pdf/2402.03848v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19680v1","updated":"2024-06-28T06:40:53Z","published":"2024-06-28T06:40:53Z","title":"MimicMotion: High-Quality Human Motion Video Generation with\n  Confidence-aware Pose Guidance","summary":"  In recent years, generative artificial intelligence has achieved significant\nadvancements in the field of image generation, spawning a variety of\napplications. However, video generation still faces considerable challenges in\nvarious aspects, such as controllability, video length, and richness of\ndetails, which hinder the application and popularization of this technology. In\nthis work, we propose a controllable video generation framework, dubbed\nMimicMotion, which can generate high-quality videos of arbitrary length\nmimicking specific motion guidance. Compared with previous methods, our\napproach has several highlights. Firstly, we introduce confidence-aware pose\nguidance that ensures high frame quality and temporal smoothness. Secondly, we\nintroduce regional loss amplification based on pose confidence, which\nsignificantly reduces image distortion. Lastly, for generating long and smooth\nvideos, we propose a progressive latent fusion strategy. By this means, we can\nproduce videos of arbitrary length with acceptable resource consumption. With\nextensive experiments and user studies, MimicMotion demonstrates significant\nimprovements over previous approaches in various aspects. Detailed results and\ncomparisons are available on our project page:\nhttps://tencent.github.io/MimicMotion .\n","authors":["Yuang Zhang","Jiaxi Gu","Li-Wen Wang","Han Wang","Junqi Cheng","Yuefeng Zhu","Fangyuan Zou"],"pdf_url":"https://arxiv.org/pdf/2406.19680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03640v3","updated":"2024-06-28T06:16:24Z","published":"2024-03-06T11:56:02Z","title":"Apollo: A Lightweight Multilingual Medical LLM towards Democratizing\n  Medical AI to 6B People","summary":"  Despite the vast repository of global medical knowledge predominantly being\nin English, local languages are crucial for delivering tailored healthcare\nservices, particularly in areas with limited medical resources. To extend the\nreach of medical AI advancements to a broader population, we aim to develop\nmedical LLMs across the six most widely spoken languages, encompassing a global\npopulation of 6.1 billion. This effort culminates in the creation of the\nApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the\nmultilingual medical benchmark, the released Apollo models, at various\nrelatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best\nperformance among models of equivalent size. Especially, Apollo-7B is the\nstate-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite\nmodels could be used to improve the multi-lingual medical capabilities of\nlarger models without fine-tuning in a proxy-tuning fashion. We will\nopen-source training corpora, code, model weights and evaluation benchmark.\n","authors":["Xidong Wang","Nuo Chen","Junyin Chen","Yan Hu","Yidong Wang","Xiangbo Wu","Anningzhe Gao","Xiang Wan","Haizhou Li","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2403.03640v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.19670v1","updated":"2024-06-28T05:44:47Z","published":"2024-06-28T05:44:47Z","title":"Function+Data Flow: A Framework to Specify Machine Learning Pipelines\n  for Digital Twinning","summary":"  The development of digital twins (DTs) for physical systems increasingly\nleverages artificial intelligence (AI), particularly for combining data from\ndifferent sources or for creating computationally efficient, reduced-dimension\nmodels. Indeed, even in very different application domains, twinning employs\ncommon techniques such as model order reduction and modelization with hybrid\ndata (that is, data sourced from both physics-based models and sensors).\nDespite this apparent generality, current development practices are ad-hoc,\nmaking the design of AI pipelines for digital twinning complex and\ntime-consuming. Here we propose Function+Data Flow (FDF), a domain-specific\nlanguage (DSL) to describe AI pipelines within DTs. FDF aims to facilitate the\ndesign and validation of digital twins. Specifically, FDF treats functions as\nfirst-class citizens, enabling effective manipulation of models learned with\nAI. We illustrate the benefits of FDF on two concrete use cases from different\ndomains: predicting the plastic strain of a structure and modeling the\nelectromagnetic behavior of a bearing.\n","authors":["Eduardo de Conto","Blaise Genest","Arvind Easwaran"],"pdf_url":"https://arxiv.org/pdf/2406.19670v1.pdf","comment":"10 pages, 5 figures, to be published in AIware'24"},{"id":"http://arxiv.org/abs/2406.11741v3","updated":"2024-06-28T05:28:27Z","published":"2024-06-17T17:00:52Z","title":"Transcendence: Generative Models Can Outperform The Experts That Train\n  Them","summary":"  Generative models are trained with the simple objective of imitating the\nconditional probability distribution induced by the data they are trained on.\nTherefore, when trained on data generated by humans, we may not expect the\nartificial model to outperform the humans on their original objectives. In this\nwork, we study the phenomenon of transcendence: when a generative model\nachieves capabilities that surpass the abilities of the experts generating its\ndata. We demonstrate transcendence by training an autoregressive transformer to\nplay chess from game transcripts, and show that the trained model can sometimes\nachieve better performance than all players in the dataset. We theoretically\nprove that transcendence can be enabled by low-temperature sampling, and\nrigorously assess this claim experimentally. Finally, we discuss other sources\nof transcendence, laying the groundwork for future investigation of this\nphenomenon in a broader setting.\n","authors":["Edwin Zhang","Vincent Zhu","Naomi Saphra","Anat Kleiman","Benjamin L. Edelman","Milind Tambe","Sham M. Kakade","Eran Malach"],"pdf_url":"https://arxiv.org/pdf/2406.11741v3.pdf","comment":"Code, models, and data at https://transcendence.eddie.win"},{"id":"http://arxiv.org/abs/2406.19653v1","updated":"2024-06-28T04:48:05Z","published":"2024-06-28T04:48:05Z","title":"ACES: Automatic Cohort Extraction System for Event-Stream Datasets","summary":"  Reproducibility remains a significant challenge in machine learning (ML) for\nhealthcare. In this field, datasets, model pipelines, and even task/cohort\ndefinitions are often private, leading to a significant barrier in sharing,\niterating, and understanding ML results on electronic health record (EHR)\ndatasets. In this paper, we address a significant part of this problem by\nintroducing the Automatic Cohort Extraction System for Event-Stream Datasets\n(ACES). This tool is designed to simultaneously simplify the development of\ntask/cohorts for ML in healthcare and enable the reproduction of these cohorts,\nboth at an exact level for single datasets and at a conceptual level across\ndatasets. To accomplish this, ACES provides (1) a highly intuitive and\nexpressive configuration language for defining both dataset-specific concepts\nand dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to\nautomatically extract patient records that meet these defined criteria from\nreal-world data. ACES can be automatically applied to any dataset in either the\nMedical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to\n*any* dataset for which the necessary task-specific predicates can be extracted\nin an event-stream form. ACES has the potential to significantly lower the\nbarrier to entry for defining ML tasks, redefine the way researchers interact\nwith EHR datasets, and significantly improve the state of reproducibility for\nML studies in this modality. ACES is available at\nhttps://github.com/justin13601/aces.\n","authors":["Justin Xu","Jack Gallifant","Alistair E. W. Johnson","Matthew B. A. McDermott"],"pdf_url":"https://arxiv.org/pdf/2406.19653v1.pdf","comment":"For ACES Online Documentation, see\n  https://eventstreamaces.readthedocs.io/en/latest/"},{"id":"http://arxiv.org/abs/2406.19651v1","updated":"2024-06-28T04:46:11Z","published":"2024-06-28T04:46:11Z","title":"CANDY: A Benchmark for Continuous Approximate Nearest Neighbor Search\n  with Dynamic Data Ingestion","summary":"  Approximate K Nearest Neighbor (AKNN) algorithms play a pivotal role in\nvarious AI applications, including information retrieval, computer vision, and\nnatural language processing. Although numerous AKNN algorithms and benchmarks\nhave been developed recently to evaluate their effectiveness, the dynamic\nnature of real-world data presents significant challenges that existing\nbenchmarks fail to address. Traditional benchmarks primarily assess retrieval\neffectiveness in static contexts and often overlook update efficiency, which is\ncrucial for handling continuous data ingestion. This limitation results in an\nincomplete assessment of an AKNN algorithms ability to adapt to changing data\npatterns, thereby restricting insights into their performance in dynamic\nenvironments. To address these gaps, we introduce CANDY, a benchmark tailored\nfor Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion.\nCANDY comprehensively assesses a wide range of AKNN algorithms, integrating\nadvanced optimizations such as machine learning-driven inference to supplant\ntraditional heuristic scans, and improved distance computation methods to\nreduce computational overhead. Our extensive evaluations across diverse\ndatasets demonstrate that simpler AKNN baselines often surpass more complex\nalternatives in terms of recall and latency. These findings challenge\nestablished beliefs about the necessity of algorithmic complexity for high\nperformance. Furthermore, our results underscore existing challenges and\nilluminate future research opportunities. We have made the datasets and\nimplementation methods available at: https://github.com/intellistream/candy.\n","authors":["Xianzhi Zeng","Zhuoyan Wu","Xinjing Hu","Xuanhua Shi","Shixuan Sun","Shuhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19648v1","updated":"2024-06-28T04:33:41Z","published":"2024-06-28T04:33:41Z","title":"Designing and Evaluating Multi-Chatbot Interface for Human-AI\n  Communication: Preliminary Findings from a Persuasion Task","summary":"  The dynamics of human-AI communication have been reshaped by language models\nsuch as ChatGPT. However, extant research has primarily focused on dyadic\ncommunication, leaving much to be explored regarding the dynamics of human-AI\ncommunication in group settings. The availability of multiple language model\nchatbots presents a unique opportunity for scholars to better understand the\ninteraction between humans and multiple chatbots. This study examines the\nimpact of multi-chatbot communication in a specific persuasion setting:\npromoting charitable donations. We developed an online environment that enables\nmulti-chatbot communication and conducted a pilot experiment utilizing two\nGPT-based chatbots, Save the Children and UNICEF chatbots, to promote\ncharitable donations. In this study, we present our development process of the\nmulti-chatbot interface and present preliminary findings from a pilot\nexperiment. Analysis of qualitative and quantitative feedback are presented,\nand limitations are addressed.\n","authors":["Sion Yoon","Tae Eun Kim","Yoo Jung Oh"],"pdf_url":"https://arxiv.org/pdf/2406.19648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19644v1","updated":"2024-06-28T04:21:24Z","published":"2024-06-28T04:21:24Z","title":"Beyond Human Preferences: Exploring Reinforcement Learning Trajectory\n  Evaluation and Improvement through LLMs","summary":"  Reinforcement learning (RL) faces challenges in evaluating policy\ntrajectories within intricate game tasks due to the difficulty in designing\ncomprehensive and precise reward functions. This inherent difficulty curtails\nthe broader application of RL within game environments characterized by diverse\nconstraints. Preference-based reinforcement learning (PbRL) presents a\npioneering framework that capitalizes on human preferences as pivotal reward\nsignals, thereby circumventing the need for meticulous reward engineering.\nHowever, obtaining preference data from human experts is costly and\ninefficient, especially under conditions marked by complex constraints. To\ntackle this challenge, we propose a LLM-enabled automatic preference generation\nframework named LLM4PG , which harnesses the capabilities of large language\nmodels (LLMs) to abstract trajectories, rank preferences, and reconstruct\nreward functions to optimize conditioned policies. Experiments on tasks with\ncomplex language constraints demonstrated the effectiveness of our LLM-enabled\nreward functions, accelerating RL convergence and overcoming stagnation caused\nby slow or absent progress under original reward structures. This approach\nmitigates the reliance on specialized human knowledge and demonstrates the\npotential of LLMs to enhance RL's effectiveness in complex environments in the\nwild.\n","authors":["Zichao Shen","Tianchen Zhu","Qingyun Sun","Shiqi Gao","Jianxin Li"],"pdf_url":"https://arxiv.org/pdf/2406.19644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19643v1","updated":"2024-06-28T04:21:20Z","published":"2024-06-28T04:21:20Z","title":"Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework\n  with Debate-Driven Text Planning for Argument Generation","summary":"  Writing persuasive arguments is a challenging task for both humans and\nmachines. It entails incorporating high-level beliefs from various perspectives\non the topic, along with deliberate reasoning and planning to construct a\ncoherent narrative. Current language models often generate surface tokens\nautoregressively, lacking explicit integration of these underlying controls,\nresulting in limited output diversity and coherence. In this work, we propose a\npersona-based multi-agent framework for argument writing. Inspired by the human\ndebate, we first assign each agent a persona representing its high-level\nbeliefs from a unique perspective, and then design an agent interaction process\nso that the agents can collaboratively debate and discuss the idea to form an\noverall plan for argument writing. Such debate process enables fluid and\nnonlinear development of ideas. We evaluate our framework on argumentative\nessay writing. The results show that our framework can generate more diverse\nand persuasive arguments through both automatic and human evaluations.\n","authors":["Zhe Hu","Hou Pong Chan","Jing Li","Yu Yin"],"pdf_url":"https://arxiv.org/pdf/2406.19643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03181v2","updated":"2024-06-28T04:15:33Z","published":"2024-03-05T18:19:29Z","title":"Behavior Generation with Latent Actions","summary":"  Generative modeling of complex behaviors from labeled datasets has been a\nlongstanding problem in decision making. Unlike language or image generation,\ndecision making requires modeling actions - continuous-valued vectors that are\nmultimodal in their distribution, potentially drawn from uncurated sources,\nwhere generation errors can compound in sequential prediction. A recent class\nof models called Behavior Transformers (BeT) addresses this by discretizing\nactions using k-means clustering to capture different modes. However, k-means\nstruggles to scale for high-dimensional action spaces or long sequences, and\nlacks gradient information, and thus BeT suffers in modeling long-range\nactions. In this work, we present Vector-Quantized Behavior Transformer\n(VQ-BeT), a versatile model for behavior generation that handles multimodal\naction prediction, conditional generation, and partial observations. VQ-BeT\naugments BeT by tokenizing continuous actions with a hierarchical vector\nquantization module. Across seven environments including simulated\nmanipulation, autonomous driving, and robotics, VQ-BeT improves on\nstate-of-the-art models such as BeT and Diffusion Policies. Importantly, we\ndemonstrate VQ-BeT's improved ability to capture behavior modes while\naccelerating inference speed 5x over Diffusion Policies. Videos and code can be\nfound https://sjlee.cc/vq-bet\n","authors":["Seungjae Lee","Yibin Wang","Haritheja Etukuru","H. Jin Kim","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2403.03181v2.pdf","comment":"Github repo: https://github.com/jayLEE0301/vq_bet_official"},{"id":"http://arxiv.org/abs/2406.12058v3","updated":"2024-06-28T04:08:12Z","published":"2024-06-17T19:50:40Z","title":"WellDunn: On the Robustness and Explainability of Language Models and\n  Large Language Models in Identifying Wellness Dimensions","summary":"  Language Models (LMs) are being proposed for mental health applications where\nthe heightened risk of adverse outcomes means predictive performance may not be\na sufficient litmus test of a model's utility in clinical practice. A model\nthat can be trusted for practice should have a correspondence between\nexplanation and clinical determination, yet no prior research has examined the\nattention fidelity of these models and their effect on ground truth\nexplanations. We introduce an evaluation design that focuses on the robustness\nand explainability of LMs in identifying Wellness Dimensions (WD). We focus on\ntwo mental health and well-being datasets: (a) Multi-label Classification-based\nMultiWD, and (b) WellXplain for evaluating attention mechanism veracity against\nexpert-labeled explanations. The labels are based on Halbert Dunn's theory of\nwellness, which gives grounding to our evaluation. We reveal four surprising\nresults about LMs/LLMs: (1) Despite their human-like capabilities, GPT-3.5/4\nlag behind RoBERTa, and MedAlpaca, a fine-tuned LLM fails to deliver any\nremarkable improvements in performance or explanations. (2) Re-examining LMs'\npredictions based on a confidence-oriented loss function reveals a significant\nperformance drop. (3) Across all LMs/LLMs, the alignment between attention and\nexplanations remains low, with LLMs scoring a dismal 0.0. (4) Most mental\nhealth-specific LMs/LLMs overlook domain-specific knowledge and undervalue\nexplanations, causing these discrepancies. This study highlights the need for\nfurther research into their consistency and explanations in mental health and\nwell-being.\n","authors":["Seyedali Mohammadi","Edward Raff","Jinendra Malekar","Vedant Palit","Francis Ferraro","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2406.12058v3.pdf","comment":"26 pages, including reference and appendix sections, 8 figures, and\n  16 tables"},{"id":"http://arxiv.org/abs/2406.02105v2","updated":"2024-06-28T04:05:53Z","published":"2024-06-04T08:33:56Z","title":"Kernel vs. Kernel: Exploring How the Data Structure Affects Neural\n  Collapse","summary":"  Recently, a vast amount of literature has focused on the \"Neural Collapse\"\n(NC) phenomenon, which emerges when training neural network (NN) classifiers\nbeyond the zero training error point. The core component of NC is the decrease\nin the within class variability of the network's deepest features, dubbed as\nNC1. The theoretical works that study NC are typically based on simplified\nunconstrained features models (UFMs) that mask any effect of the data on the\nextent of collapse. In this paper, we provide a kernel-based analysis that does\nnot suffer from this limitation. First, given a kernel function, we establish\nexpressions for the traces of the within- and between-class covariance matrices\nof the samples' features (and consequently an NC1 metric). Then, we turn to\nfocus on kernels associated with shallow NNs. First, we consider the NN\nGaussian Process kernel (NNGP), associated with the network at initialization,\nand the complement Neural Tangent Kernel (NTK), associated with its training in\nthe \"lazy regime\". Interestingly, we show that the NTK does not represent more\ncollapsed features than the NNGP for prototypical data models. As NC emerges\nfrom training, we then consider an alternative to NTK: the recently proposed\nadaptive kernel, which generalizes NNGP to model the feature mapping learned\nfrom the training data. Contrasting our NC1 analysis for these two kernels\nenables gaining insights into the effect of data distribution on the extent of\ncollapse, which are empirically aligned with the behavior observed with\npractical training of NNs.\n","authors":["Vignesh Kothapalli","Tom Tirer"],"pdf_url":"https://arxiv.org/pdf/2406.02105v2.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2405.16141v3","updated":"2024-06-28T03:59:15Z","published":"2024-05-25T09:21:43Z","title":"AIGB: Generative Auto-bidding via Diffusion Modeling","summary":"  Auto-bidding plays a crucial role in facilitating online advertising by\nautomatically providing bids for advertisers. Reinforcement learning (RL) has\ngained popularity for auto-bidding. However, most current RL auto-bidding\nmethods are modeled through the Markovian Decision Process (MDP), which assumes\nthe Markovian state transition. This assumption restricts the ability to\nperform in long horizon scenarios and makes the model unstable when dealing\nwith highly random online advertising environments. To tackle this issue, this\npaper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding\nthrough generative modeling. In this paradigm, we propose DiffBid, a\nconditional diffusion modeling approach for bid generation. DiffBid directly\nmodels the correlation between the return and the entire trajectory,\neffectively avoiding error propagation across time steps in long horizons.\nAdditionally, DiffBid offers a versatile approach for generating trajectories\nthat maximize given targets while adhering to specific constraints. Extensive\nexperiments conducted on the real-world dataset and online A/B test on Alibaba\nadvertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%\nincrease in GMV and 3.36% increase in ROI.\n","authors":["Jiayan Guo","Yusen Huo","Zhilin Zhang","Tianyu Wang","Chuan Yu","Jian Xu","Yan Zhang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2405.16141v3.pdf","comment":"Accepted by KDD 2024"},{"id":"http://arxiv.org/abs/2406.19638v1","updated":"2024-06-28T03:58:02Z","published":"2024-06-28T03:58:02Z","title":"Precision matters: Precision-aware ensemble for weakly supervised\n  semantic segmentation","summary":"  Weakly Supervised Semantic Segmentation (WSSS) employs weak supervision, such\nas image-level labels, to train the segmentation model. Despite the impressive\nachievement in recent WSSS methods, we identify that introducing weak labels\nwith high mean Intersection of Union (mIoU) does not guarantee high\nsegmentation performance. Existing studies have emphasized the importance of\nprioritizing precision and reducing noise to improve overall performance. In\nthe same vein, we propose ORANDNet, an advanced ensemble approach tailored for\nWSSS. ORANDNet combines Class Activation Maps (CAMs) from two different\nclassifiers to increase the precision of pseudo-masks (PMs). To further\nmitigate small noise in the PMs, we incorporate curriculum learning. This\ninvolves training the segmentation model initially with pairs of smaller-sized\nimages and corresponding PMs, gradually transitioning to the original-sized\npairs. By combining the original CAMs of ResNet-50 and ViT, we significantly\nimprove the segmentation performance over the single-best model and the naive\nensemble model, respectively. We further extend our ensemble method to CAMs\nfrom AMN (ResNet-like) and MCTformer (ViT-like) models, achieving performance\nbenefits in advanced WSSS models. It highlights the potential of our ORANDNet\nas a final add-on module for WSSS models.\n","authors":["Junsung Park","Hyunjung Shim"],"pdf_url":"https://arxiv.org/pdf/2406.19638v1.pdf","comment":"5 pages, 5 figures, accepted in AAAI 2024 Edge Intelligence Workshop"},{"id":"http://arxiv.org/abs/2405.12807v7","updated":"2024-06-28T03:55:48Z","published":"2024-05-21T13:58:17Z","title":"FAdam: Adam is a natural gradient optimizer using diagonal empirical\n  Fisher information","summary":"  This paper establishes a mathematical foundation for the Adam optimizer,\nelucidating its connection to natural gradient descent through Riemannian and\ninformation geometry. We rigorously analyze the diagonal empirical Fisher\ninformation matrix (FIM) in Adam, clarifying all detailed approximations and\nadvocating for the use of log probability functions as loss, which should be\nbased on discrete distributions, due to the limitations of empirical FIM. Our\nanalysis uncovers flaws in the original Adam algorithm, leading to proposed\ncorrections such as enhanced momentum calculations, adjusted bias corrections,\nadaptive epsilon, and gradient clipping. We refine the weight decay term based\non our theoretical framework. Our modified algorithm, Fisher Adam (FAdam),\ndemonstrates superior performance across diverse domains including LLM, ASR,\nand VQ-VAE, achieving state-of-the-art results in ASR.\n","authors":["Dongseong Hwang"],"pdf_url":"https://arxiv.org/pdf/2405.12807v7.pdf","comment":"21 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.04607v4","updated":"2024-06-28T03:53:21Z","published":"2024-06-07T03:31:58Z","title":"MeGA: Merging Multiple Independently Trained Neural Networks Based on\n  Genetic Algorithm","summary":"  In this paper, we introduce a novel method for merging the weights of\nmultiple pre-trained neural networks using a genetic algorithm called MeGA.\nTraditional techniques, such as weight averaging and ensemble methods, often\nfail to fully harness the capabilities of pre-trained networks. Our approach\nleverages a genetic algorithm with tournament selection, crossover, and\nmutation to optimize weight combinations, creating a more effective fusion.\nThis technique allows the merged model to inherit advantageous features from\nboth parent models, resulting in enhanced accuracy and robustness. Through\nexperiments on the CIFAR-10 dataset, we demonstrate that our genetic\nalgorithm-based weight merging method improves test accuracy compared to\nindividual models and conventional methods. This approach provides a scalable\nsolution for integrating multiple pre-trained networks across various deep\nlearning applications. Github is available at:\nhttps://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm\n","authors":["Daniel Yun"],"pdf_url":"https://arxiv.org/pdf/2406.04607v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19630v1","updated":"2024-06-28T03:36:38Z","published":"2024-06-28T03:36:38Z","title":"Optimal Video Compression using Pixel Shift Tracking","summary":"  The Video comprises approximately ~85\\% of all internet traffic, but video\nencoding/compression is being historically done with hard coded rules, which\nhas worked well but only to a certain limit. We have seen a surge in video\ncompression algorithms using ML-based models in the last few years and many of\nthem have outperformed several legacy codecs. The models range from encoding\nvideo end to end using an ML approach or replacing some intermediate steps in\nlegacy codecs using ML models to increase the efficiency of those steps.\n  Optimizing video storage is an essential aspect of video processing, so we\nare proposing one of the possible approaches to achieve it is by avoiding\nredundant data at each frame. In this paper, we want to introduce the approach\nof redundancies removal in subsequent frames for a given video as a main\napproach for video compression. We call this method Redundancy Removal using\nShift (R\\textsuperscript2S). This method can be utilized across various Machine\nLearning model algorithms, and make the compression more accessible and\nadaptable. In this study, we have utilized a computer vision-based pixel point\ntracking method to identify redundant pixels to encode video for optimal\nstorage.\n","authors":["Hitesh Saai Mananchery Panneerselvam","Smit Anand"],"pdf_url":"https://arxiv.org/pdf/2406.19630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13650v3","updated":"2024-06-28T03:33:28Z","published":"2023-05-23T03:47:32Z","title":"Robust Model-Based Optimization for Challenging Fitness Landscapes","summary":"  Protein design, a grand challenge of the day, involves optimization on a\nfitness landscape, and leading methods adopt a model-based approach where a\nmodel is trained on a training set (protein sequences and fitness) and proposes\ncandidates to explore next. These methods are challenged by sparsity of\nhigh-fitness samples in the training set, a problem that has been in the\nliterature. A less recognized but equally important problem stems from the\ndistribution of training samples in the design space: leading methods are not\ndesigned for scenarios where the desired optimum is in a region that is not\nonly poorly represented in training data, but also relatively far from the\nhighly represented low-fitness regions. We show that this problem of\n\"separation\" in the design space is a significant bottleneck in existing\nmodel-based optimization tools and propose a new approach that uses a novel VAE\nas its search model to overcome the problem. We demonstrate its advantage over\nprior methods in robustly finding improved samples, regardless of the imbalance\nand separation between low- and high-fitness samples. Our comprehensive\nbenchmark on real and semi-synthetic protein datasets as well as solution\ndesign for physics-informed neural networks, showcases the generality of our\napproach in discrete and continuous design spaces. Our implementation is\navailable at https://github.com/sabagh1994/PGVAE.\n","authors":["Saba Ghaffari","Ehsan Saleh","Alexander G. Schwing","Yu-Xiong Wang","Martin D. Burke","Saurabh Sinha"],"pdf_url":"https://arxiv.org/pdf/2305.13650v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19626v1","updated":"2024-06-28T03:29:33Z","published":"2024-06-28T03:29:33Z","title":"Safety through feedback in Constrained RL","summary":"  In safety-critical RL settings, the inclusion of an additional cost function\nis often favoured over the arduous task of modifying the reward function to\nensure the agent's safe behaviour. However, designing or evaluating such a cost\nfunction can be prohibitively expensive. For instance, in the domain of\nself-driving, designing a cost function that encompasses all unsafe behaviours\n(e.g. aggressive lane changes) is inherently complex. In such scenarios, the\ncost function can be learned from feedback collected offline in between\ntraining rounds. This feedback can be system generated or elicited from a human\nobserving the training process. Previous approaches have not been able to scale\nto complex environments and are constrained to receiving feedback at the state\nlevel which can be expensive to collect. To this end, we introduce an approach\nthat scales to more complex domains and extends to beyond state-level feedback,\nthus, reducing the burden on the evaluator. Inferring the cost function in such\nsettings poses challenges, particularly in assigning credit to individual\nstates based on trajectory-level feedback. To address this, we propose a\nsurrogate objective that transforms the problem into a state-level supervised\nclassification task with noisy labels, which can be solved efficiently.\nAdditionally, it is often infeasible to collect feedback on every trajectory\ngenerated by the agent, hence, two fundamental questions arise: (1) Which\ntrajectories should be presented to the human? and (2) How many trajectories\nare necessary for effective learning? To address these questions, we introduce\n\\textit{novelty-based sampling} that selectively involves the evaluator only\nwhen the the agent encounters a \\textit{novel} trajectory. We showcase the\nefficiency of our method through experimentation on several benchmark Safety\nGymnasium environments and realistic self-driving scenarios.\n","authors":["Shashank Reddy Chirra","Pradeep Varakantham","Praveen Paruchuri"],"pdf_url":"https://arxiv.org/pdf/2406.19626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16537v2","updated":"2024-06-28T03:21:15Z","published":"2024-06-24T11:16:37Z","title":"Character-Adapter: Prompt-Guided Region Control for High-Fidelity\n  Character Customization","summary":"  Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods. Our code will be\nreleased at https://github.com/Character-Adapter/Character-Adapte\n","authors":["Yuhang Ma","Wenting Xu","Jiji Tang","Qinfeng Jin","Rongsheng Zhang","Zeng Zhao","Changjie Fan","Zhipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2406.16537v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11160v3","updated":"2024-06-28T03:20:22Z","published":"2024-06-17T02:59:19Z","title":"Context Graph","summary":"  Knowledge Graphs (KGs) are foundational structures in many AI applications,\nrepresenting entities and their interrelations through triples. However,\ntriple-based KGs lack the contextual information of relational knowledge, like\ntemporal dynamics and provenance details, which are crucial for comprehensive\nknowledge representation and effective reasoning. Instead, \\textbf{Context\nGraphs} (CGs) expand upon the conventional structure by incorporating\nadditional information such as time validity, geographic location, and source\nprovenance. This integration provides a more nuanced and accurate understanding\nof knowledge, enabling KGs to offer richer insights and support more\nsophisticated reasoning processes. In this work, we first discuss the inherent\nlimitations of triple-based KGs and introduce the concept of CGs, highlighting\ntheir advantages in knowledge representation and reasoning. We then present a\ncontext graph reasoning \\textbf{CGR$^3$} paradigm that leverages large language\nmodels (LLMs) to retrieve candidate entities and related contexts, rank them\nbased on the retrieved information, and reason whether sufficient information\nhas been obtained to answer a query. Our experimental results demonstrate that\nCGR$^3$ significantly improves performance on KG completion (KGC) and KG\nquestion answering (KGQA) tasks, validating the effectiveness of incorporating\ncontextual information on KG representation and reasoning.\n","authors":["Chengjin Xu","Muzhi Li","Cehao Yang","Xuhui Jiang","Lumingyuan Tang","Yiyan Qi","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2406.11160v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19622v1","updated":"2024-06-28T03:10:36Z","published":"2024-06-28T03:10:36Z","title":"Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve\n  Adversarial Robustness","summary":"  The security and robustness of deep neural networks (DNNs) have become\nincreasingly concerning. This paper aims to provide both a theoretical\nfoundation and a practical solution to ensure the reliability of DNNs. We\nexplore the concept of Lipschitz continuity to certify the robustness of DNNs\nagainst adversarial attacks, which aim to mislead the network with adding\nimperceptible perturbations into inputs. We propose a novel algorithm that\nremaps the input domain into a constrained range, reducing the Lipschitz\nconstant and potentially enhancing robustness. Unlike existing adversarially\ntrained models, where robustness is enhanced by introducing additional examples\nfrom other datasets or generative models, our method is almost cost-free as it\ncan be integrated with existing models without requiring re-training.\nExperimental results demonstrate the generalizability of our method, as it can\nbe combined with various models and achieve enhancements in robustness.\nFurthermore, our method achieves the best robust accuracy for CIFAR10,\nCIFAR100, and ImageNet datasets on the RobustBench leaderboard.\n","authors":["Erh-Chung Chen","Pin-Yu Chen","I-Hsin Chung","Che-Rung Lee"],"pdf_url":"https://arxiv.org/pdf/2406.19622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06777v3","updated":"2024-06-28T03:07:29Z","published":"2024-06-10T20:25:18Z","title":"MolX: Enhancing Large Language Models for Molecular Learning with A\n  Multi-Modal Extension","summary":"  Recently, Large Language Models (LLMs) with their strong task-handling\ncapabilities have shown remarkable advancements across a spectrum of fields,\nmoving beyond natural language understanding. However, their proficiency within\nthe chemistry domain remains restricted, especially in solving professional\nmolecule-related tasks. This challenge is attributed to their inherent\nlimitations in comprehending molecules using only common textual\nrepresentations, i.e., SMILES strings. In this study, we seek to enhance the\nability of LLMs to comprehend molecules by designing and equipping them with a\nmulti-modal external module, namely MolX. In particular, instead of directly\nusing a SMILES string to represent a molecule, we utilize specific encoders to\nextract fine-grained features from both SMILES string and 2D molecular graph\nrepresentations for feeding into an LLM. Moreover, a human-defined molecular\nfingerprint is incorporated to leverage its embedded domain knowledge. Then, to\nestablish an alignment between MolX and the LLM's textual input space, the\nwhole model in which the LLM is frozen, is pre-trained with a versatile\nstrategy including a diverse set of tasks. Extensive experimental evaluations\ndemonstrate that our proposed method only introduces a small number of\ntrainable parameters while outperforming baselines on various downstream\nmolecule-related tasks ranging from molecule-to-text translation to\nretrosynthesis, with and without fine-tuning the LLM.\n","authors":["Khiem Le","Zhichun Guo","Kaiwen Dong","Xiaobao Huang","Bozhao Nan","Roshni Iyer","Xiangliang Zhang","Olaf Wiest","Wei Wang","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2406.06777v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18841v2","updated":"2024-06-28T02:56:09Z","published":"2024-05-14T15:03:05Z","title":"Navigating LLM Ethics: Advancements, Challenges, and Future Directions","summary":"  This study addresses ethical issues surrounding Large Language Models (LLMs)\nwithin the field of artificial intelligence. It explores the common ethical\nchallenges posed by both LLMs and other AI systems, such as privacy and\nfairness, as well as ethical challenges uniquely arising from LLMs. It\nhighlights challenges such as hallucination, verifiable accountability, and\ndecoding censorship complexity, which are unique to LLMs and distinct from\nthose encountered in traditional AI systems. The study underscores the need to\ntackle these complexities to ensure accountability, reduce biases, and enhance\ntransparency in the influential role that LLMs play in shaping information\ndissemination. It proposes mitigation strategies and future directions for LLM\nethics, advocating for interdisciplinary collaboration. It recommends ethical\nframeworks tailored to specific domains and dynamic auditing systems adapted to\ndiverse contexts. This roadmap aims to guide responsible development and\nintegration of LLMs, envisioning a future where ethical considerations govern\nAI advancements in society.\n","authors":["Junfeng Jiao","Saleh Afroogh","Yiming Xu","Connor Phillips"],"pdf_url":"https://arxiv.org/pdf/2406.18841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18842v2","updated":"2024-06-28T02:54:06Z","published":"2024-05-26T15:28:24Z","title":"The global landscape of academic guidelines for generative AI and Large\n  Language Models","summary":"  The integration of Generative Artificial Intelligence (GAI) and Large\nLanguage Models (LLMs) in academia has spurred a global discourse on their\npotential pedagogical benefits and ethical considerations. Positive reactions\nhighlight some potential, such as collaborative creativity, increased access to\neducation, and empowerment of trainers and trainees. However, negative\nreactions raise concerns about ethical complexities, balancing innovation and\nacademic integrity, unequal access, and misinformation risks. Through a\nsystematic survey and text-mining-based analysis of global and national\ndirectives, insights from independent research, and eighty university-level\nguidelines, this study provides a nuanced understanding of the opportunities\nand challenges posed by GAI and LLMs in education. It emphasizes the importance\nof balanced approaches that harness the benefits of these technologies while\naddressing ethical considerations and ensuring equitable access and educational\noutcomes. The paper concludes with recommendations for fostering responsible\ninnovation and ethical practices to guide the integration of GAI and LLMs in\nacademia.\n","authors":["Junfeng Jiao","Saleh Afroogh","Kevin Chen","David Atkinson","Amit Dhurandhar"],"pdf_url":"https://arxiv.org/pdf/2406.18842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19614v1","updated":"2024-06-28T02:41:33Z","published":"2024-06-28T02:41:33Z","title":"A Survey on Data Quality Dimensions and Tools for Machine Learning","summary":"  Machine learning (ML) technologies have become substantial in practically all\naspects of our society, and data quality (DQ) is critical for the performance,\nfairness, robustness, safety, and scalability of ML models. With the large and\ncomplex data in data-centric AI, traditional methods like exploratory data\nanalysis (EDA) and cross-validation (CV) face challenges, highlighting the\nimportance of mastering DQ tools. In this survey, we review 17 DQ evaluation\nand improvement tools in the last 5 years. By introducing the DQ dimensions,\nmetrics, and main functions embedded in these tools, we compare their strengths\nand limitations and propose a roadmap for developing open-source DQ tools for\nML. Based on the discussions on the challenges and emerging trends, we further\nhighlight the potential applications of large language models (LLMs) and\ngenerative AI in DQ evaluation and improvement for ML. We believe this\ncomprehensive survey can enhance understanding of DQ in ML and could drive\nprogress in data-centric AI. A complete list of the literature investigated in\nthis survey is available on GitHub at:\nhttps://github.com/haihua0913/awesome-dq4ml.\n","authors":["Yuhan Zhou","Fengjiao Tu","Kewei Sha","Junhua Ding","Haihua Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19614v1.pdf","comment":"This paper has been accepted by The 6th IEEE International Conference\n  on Artificial Intelligence Testing (IEEE AITest 2024) as an invited paper"},{"id":"http://arxiv.org/abs/2403.02990v3","updated":"2024-06-28T02:35:38Z","published":"2024-03-05T14:11:54Z","title":"Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and\n  Challenges","summary":"  In the rapidly evolving field of large language models (LLMs), data\naugmentation (DA) has emerged as a pivotal technique for enhancing model\nperformance by diversifying training examples without the need for additional\ndata collection. This survey explores the transformative impact of LLMs on DA,\nparticularly addressing the unique challenges and opportunities they present in\nthe context of natural language processing (NLP) and beyond. From both data and\nlearning perspectives, we examine various strategies that utilize LLMs for data\naugmentation, including a novel exploration of learning paradigms where\nLLM-generated data is used for diverse forms of further training. Additionally,\nthis paper highlights the primary open challenges faced in this domain, ranging\nfrom controllable data augmentation to multi-modal data augmentation. This\nsurvey highlights a paradigm shift introduced by LLMs in DA, and aims to serve\nas a comprehensive guide for researchers and practitioners.\n","authors":["Bosheng Ding","Chengwei Qin","Ruochen Zhao","Tianze Luo","Xinze Li","Guizhen Chen","Wenhan Xia","Junjie Hu","Anh Tuan Luu","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2403.02990v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19611v1","updated":"2024-06-28T02:35:05Z","published":"2024-06-28T02:35:05Z","title":"Multimodal Data Integration for Precision Oncology: Challenges and\n  Future Directions","summary":"  The essence of precision oncology lies in its commitment to tailor targeted\ntreatments and care measures to each patient based on the individual\ncharacteristics of the tumor. The inherent heterogeneity of tumors necessitates\ngathering information from diverse data sources to provide valuable insights\nfrom various perspectives, fostering a holistic comprehension of the tumor.\nOver the past decade, multimodal data integration technology for precision\noncology has made significant strides, showcasing remarkable progress in\nunderstanding the intricate details within heterogeneous data modalities. These\nstrides have exhibited tremendous potential for improving clinical\ndecision-making and model interpretation, contributing to the advancement of\ncancer care and treatment. Given the rapid progress that has been achieved, we\nprovide a comprehensive overview of about 300 papers detailing cutting-edge\nmultimodal data integration techniques in precision oncology. In addition, we\nconclude the primary clinical applications that have reaped significant\nbenefits, including early assessment, diagnosis, prognosis, and biomarker\ndiscovery. Finally, derived from the findings of this survey, we present an\nin-depth analysis that explores the pivotal challenges and reveals essential\npathways for future research in the field of multimodal data integration for\nprecision oncology.\n","authors":["Huajun Zhou","Fengtao Zhou","Chenyu Zhao","Yingxue Xu","Luyang Luo","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19611v1.pdf","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2402.00808v2","updated":"2024-06-28T02:16:13Z","published":"2024-02-01T17:44:46Z","title":"Exploring the Dynamics between Cobot's Production Rhythm, Locus of\n  Control and Emotional State in a Collaborative Assembly Scenario","summary":"  In industrial scenarios, there is widespread use of collaborative robots\n(cobots), and growing interest is directed at evaluating and measuring the\nimpact of some characteristics of the cobot on the human factor. In the present\npilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 -\nAdapted to the participant's pace) of a cobot has on the Experiential Locus of\nControl (ELoC) and the emotional state of 31 participants has been examined.\nThe operators' performance, the degree of basic internal Locus of Control, and\nthe attitude towards the robots were also considered. No difference was found\nregarding the emotional state and the ELoC in the three conditions, but\nconsidering the other psychological variables, a more complex situation\nemerges. Overall, results seem to indicate a need to consider the person's\npsychological characteristics to offer a differentiated and optimal interaction\nexperience.\n","authors":["Marta Mondellini","Matteo Lavit Nicora","Pooja Prajod","Elisabeth André","Rocco Vertechy","Alessandro Antonietti","Matteo Malosio"],"pdf_url":"https://arxiv.org/pdf/2402.00808v2.pdf","comment":"Accepted to 4th IEEE International Conference on Human-Machine\n  Systems"},{"id":"http://arxiv.org/abs/2406.19596v1","updated":"2024-06-28T01:37:46Z","published":"2024-06-28T01:37:46Z","title":"Optimizing Cyber Defense in Dynamic Active Directories through\n  Reinforcement Learning","summary":"  This paper addresses a significant gap in Autonomous Cyber Operations (ACO)\nliterature: the absence of effective edge-blocking ACO strategies in dynamic,\nreal-world networks. It specifically targets the cybersecurity vulnerabilities\nof organizational Active Directory (AD) systems. Unlike the existing literature\non edge-blocking defenses which considers AD systems as static entities, our\nstudy counters this by recognizing their dynamic nature and developing advanced\nedge-blocking defenses through a Stackelberg game model between attacker and\ndefender. We devise a Reinforcement Learning (RL)-based attack strategy and an\nRL-assisted Evolutionary Diversity Optimization-based defense strategy, where\nthe attacker and defender improve each other strategy via parallel gameplay. To\naddress the computational challenges of training attacker-defender strategies\non numerous dynamic AD graphs, we propose an RL Training Facilitator that\nprunes environments and neural networks to eliminate irrelevant elements,\nenabling efficient and scalable training for large graphs. We extensively train\nthe attacker strategy, as a sophisticated attacker model is essential for a\nrobust defense. Our empirical results successfully demonstrate that our\nproposed approach enhances defender's proficiency in hardening dynamic AD\ngraphs while ensuring scalability for large-scale AD.\n","authors":["Diksha Goel","Kristen Moore","Mingyu Guo","Derui Wang","Minjune Kim","Seyit Camtepe"],"pdf_url":"https://arxiv.org/pdf/2406.19596v1.pdf","comment":"The manuscript has been accepted as full paper at European Symposium\n  on Research in Computer Security (ESORICS) 2024"},{"id":"http://arxiv.org/abs/2405.05480v2","updated":"2024-06-28T00:05:14Z","published":"2024-05-09T00:37:56Z","title":"FloorSet -- a VLSI Floorplanning Dataset with Design Constraints of\n  Real-World SoCs","summary":"  Floorplanning for systems-on-a-chip (SoCs) and its sub-systems is a crucial\nand non-trivial step of the physical design flow. It represents a difficult\ncombinatorial optimization problem. A typical large scale SoC with 120\npartitions generates a search-space of nearly 10E250. As novel machine learning\n(ML) approaches emerge to tackle such problems, there is a growing need for a\nmodern benchmark that comprises a large training dataset and performance\nmetrics that better reflect real-world constraints and objectives compared to\nexisting benchmarks. To address this need, we present FloorSet -- two\ncomprehensive datasets of synthetic fixed-outline floorplan layouts that\nreflect the distribution of real SoCs. Each dataset has 1M training samples and\n100 test samples where each sample is a synthetic floor-plan. FloorSet-Prime\ncomprises fully-abutted rectilinear partitions and near-optimal wire-length. A\nsimplified dataset that reflects early design phases, FloorSet-Lite comprises\nrectangular partitions, with under 5 percent white-space and near-optimal\nwire-length. Both datasets define hard constraints seen in modern design flows\nsuch as shape constraints, edge-affinity, grouping constraints, and\npre-placement constraints. FloorSet is intended to spur fundamental research on\nlarge-scale constrained optimization problems. Crucially, FloorSet alleviates\nthe core issue of reproducibility in modern ML driven solutions to such\nproblems. FloorSet is available as an open-source repository for the research\ncommunity.\n","authors":["Uday Mallappa","Hesham Mostafa","Mikhail Galkin","Mariano Phielipp","Somdeb Majumdar"],"pdf_url":"https://arxiv.org/pdf/2405.05480v2.pdf","comment":"10 pages, 11 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.20099v1","updated":"2024-06-28T17:59:51Z","published":"2024-06-28T17:59:51Z","title":"Odd-One-Out: Anomaly Detection by Comparing with Neighbors","summary":"  This paper introduces a novel anomaly detection (AD) problem that focuses on\nidentifying `odd-looking' objects relative to the other instances within a\nscene. Unlike the traditional AD benchmarks, in our setting, anomalies in this\ncontext are scene-specific, defined by the regular instances that make up the\nmajority. Since object instances are often partly visible from a single\nviewpoint, our setting provides multiple views of each scene as input. To\nprovide a testbed for future research in this task, we introduce two\nbenchmarks, ToysAD-8K and PartsAD-15K. We propose a novel method that generates\n3D object-centric representations for each instance and detects the anomalous\nones through a cross-examination between the instances. We rigorously analyze\nour method quantitatively and qualitatively in the presented benchmarks.\n","authors":["Ankan Bhunia","Changjian Li","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2406.20099v1.pdf","comment":"Codes & Dataset at https://github.com/VICO-UoE/OddOneOutAD"},{"id":"http://arxiv.org/abs/2406.20098v1","updated":"2024-06-28T17:59:46Z","published":"2024-06-28T17:59:46Z","title":"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework\n  for Multimodal LLMs","summary":"  Multimodal large language models (MLLMs) have shown impressive success across\nmodalities such as image, video, and audio in a variety of understanding and\ngeneration tasks. However, current MLLMs are surprisingly poor at understanding\nwebpage screenshots and generating their corresponding HTML code. To address\nthis problem, we propose Web2Code, a benchmark consisting of a new large-scale\nwebpage-to-code dataset for instruction tuning and an evaluation framework for\nthe webpage understanding and HTML code translation abilities of MLLMs. For\ndataset construction, we leverage pretrained LLMs to enhance existing\nwebpage-to-code datasets as well as generate a diverse pool of new webpages\nrendered into images. Specifically, the inputs are webpage images and\ninstructions, while the responses are the webpage's HTML code. We further\ninclude diverse natural language QA pairs about the webpage content in the\nresponses to enable a more comprehensive understanding of the web content. To\nevaluate model performance in these tasks, we develop an evaluation framework\nfor testing MLLMs' abilities in webpage understanding and web-to-code\ngeneration. Extensive experiments show that our proposed dataset is beneficial\nnot only to our proposed tasks but also in the general visual domain, while\nprevious datasets result in worse performance. We hope our work will contribute\nto the development of general MLLMs suitable for web-based content generation\nand task automation. Our data and code will be available at\nhttps://github.com/MBZUAI-LLM/web2code.\n","authors":["Sukmin Yun","Haokun Lin","Rusiru Thushara","Mohammad Qazim Bhat","Yongxin Wang","Zutao Jiang","Mingkai Deng","Jinhong Wang","Tianhua Tao","Junbo Li","Haonan Li","Preslav Nakov","Timothy Baldwin","Zhengzhong Liu","Eric P. Xing","Xiaodan Liang","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2406.20098v1.pdf","comment":"Website at https://mbzuai-llm.github.io/webpage2code/"},{"id":"http://arxiv.org/abs/2406.20095v1","updated":"2024-06-28T17:59:12Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Large Language Models (LLMs) equipped with extensive world knowledge and\nstrong reasoning skills can tackle diverse tasks across domains, often by\nposing them as conversation-style instruction-response pairs. In this paper, we\npropose LLaRA: Large Language and Robotics Assistant, a framework which\nformulates robot action policy as conversations, and provides improved\nresponses when trained with auxiliary data that complements policy learning.\nLLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity\nto process state information as visual-textual prompts and generate optimal\npolicy decisions in text. To train such action policy VLMs, we first introduce\nan automated pipeline to generate diverse high-quality robotics instruction\ndata from existing behavior cloning data. A VLM finetuned with the resulting\ncollection of datasets based on a conversation-style formulation tailored for\nrobotics tasks, can generate meaningful robot action policy decisions. Our\nexperiments across multiple simulated and real-world environments demonstrate\nthe state-of-the-art performance of the proposed LLaRA framework. The code,\ndatasets, and pretrained models are available at\nhttps://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20092v1","updated":"2024-06-28T17:57:14Z","published":"2024-06-28T17:57:14Z","title":"LLaVolta: Efficient Multi-modal Models via Stage-wise Visual Context\n  Compression","summary":"  While significant advancements have been made in compressed representations\nfor text embeddings in large language models (LLMs), the compression of visual\ntokens in large multi-modal models (LMMs) has remained a largely overlooked\narea. In this work, we present the study on the analysis of redundancy\nconcerning visual tokens and efficient training within these models. Our\ninitial experiments show that eliminating up to 70% of visual tokens at the\ntesting stage by simply average pooling only leads to a minimal 3% reduction in\nvisual question answering accuracy on the GQA benchmark, indicating significant\nredundancy in visual context. Addressing this, we introduce Visual Context\nCompressor, which reduces the number of visual tokens during training to\nenhance training efficiency without sacrificing performance. To minimize\ninformation loss caused by the compression on visual tokens while maintaining\ntraining efficiency, we develop LLaVolta as a lite training scheme. LLaVolta\nincorporates stage-wise visual context compression to progressively compress\nthe visual tokens from heavily to lightly, and finally no compression at the\nend of training, yielding no loss of information when testing. Extensive\nexperiments demonstrate that our approach enhances the performance of MLLMs in\nboth image-language and video-language understanding, while also significantly\ncutting training costs. Code is available at\nhttps://github.com/Beckschen/LLaVolta\n","authors":["Jieneng Chen","Luoxin Ye","Ju He","Zhao-Yang Wang","Daniel Khashabi","Alan Yuille"],"pdf_url":"https://arxiv.org/pdf/2406.20092v1.pdf","comment":"Code is available at https://github.com/Beckschen/LLaVolta"},{"id":"http://arxiv.org/abs/2406.20085v1","updated":"2024-06-28T17:53:18Z","published":"2024-06-28T17:53:18Z","title":"Auto Cherry-Picker: Learning from High-quality Generative Data Driven by\n  Language","summary":"  Diffusion-based models have shown great potential in generating high-quality\nimages with various layouts, which can benefit downstream perception tasks.\nHowever, a fully automatic layout generation driven only by language and a\nsuitable metric for measuring multiple generated instances has not been well\nexplored. In this work, we present Auto Cherry-Picker (ACP), a novel framework\nthat generates high-quality multi-modal training examples to augment perception\nand multi-modal training. Starting with a simple list of natural language\nconcepts, we prompt large language models (LLMs) to generate a detailed\ndescription and design reasonable layouts. Next, we use an off-the-shelf\ntext-to-image model to generate multiple images. Then, the generated data are\nrefined using a comprehensively designed metric to ensure quality. In\nparticular, we present a new metric, Composite Layout and Image Score (CLIS),\nto evaluate the generated images fairly. Our synthetic high-quality examples\nboost performance in various scenarios by customizing the initial concept list,\nespecially in addressing challenges associated with long-tailed distribution\nand imbalanced datasets. Experiment results on downstream tasks demonstrate\nthat Auto Cherry-Picker can significantly improve the performance of existing\nmodels. In addition, we have thoroughly investigated the correlation between\nCLIS and performance gains in downstream tasks, and we find that a better CLIS\nscore results in better performance. This finding shows the potential for\nevaluation metrics as the role for various visual perception and MLLM tasks.\nCode will be available.\n","authors":["Yicheng Chen","Xiangtai Li","Yining Li","Yanhong Zeng","Jianzong Wu","Xiangyu Zhao","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2406.20085v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.20083v1","updated":"2024-06-28T17:51:10Z","published":"2024-06-28T17:51:10Z","title":"PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful\n  Navigators","summary":"  We present PoliFormer (Policy Transformer), an RGB-only indoor navigation\nagent trained end-to-end with reinforcement learning at scale that generalizes\nto the real-world without adaptation despite being trained purely in\nsimulation. PoliFormer uses a foundational vision transformer encoder with a\ncausal transformer decoder enabling long-term memory and reasoning. It is\ntrained for hundreds of millions of interactions across diverse environments,\nleveraging parallelized, multi-machine rollouts for efficient training with\nhigh throughput. PoliFormer is a masterful navigator, producing\nstate-of-the-art results across two distinct embodiments, the LoCoBot and\nStretch RE-1 robots, and four navigation benchmarks. It breaks through the\nplateaus of previous work, achieving an unprecedented 85.5% success rate in\nobject goal navigation on the CHORES-S benchmark, a 28.5% absolute improvement.\nPoliFormer can also be trivially extended to a variety of downstream\napplications such as object tracking, multi-object navigation, and\nopen-vocabulary navigation with no finetuning.\n","authors":["Kuo-Hao Zeng","Zichen Zhang","Kiana Ehsani","Rose Hendrix","Jordi Salvador","Alvaro Herrasti","Ross Girshick","Aniruddha Kembhavi","Luca Weihs"],"pdf_url":"https://arxiv.org/pdf/2406.20083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20081v1","updated":"2024-06-28T17:47:32Z","published":"2024-06-28T17:47:32Z","title":"Segment Anything without Supervision","summary":"  The Segmentation Anything Model (SAM) requires labor-intensive data labeling.\nWe present Unsupervised SAM (UnSAM) for promptable and automatic whole-image\nsegmentation that does not require human annotations. UnSAM utilizes a\ndivide-and-conquer strategy to \"discover\" the hierarchical structure of visual\nscenes. We first leverage top-down clustering methods to partition an unlabeled\nimage into instance/semantic level segments. For all pixels within a segment, a\nbottom-up clustering method is employed to iteratively merge them into larger\ngroups, thereby forming a hierarchical structure. These unsupervised\nmulti-granular masks are then utilized to supervise model training. Evaluated\nacross seven popular datasets, UnSAM achieves competitive results with the\nsupervised counterpart SAM, and surpasses the previous state-of-the-art in\nunsupervised segmentation by 11% in terms of AR. Moreover, we show that\nsupervised SAM can also benefit from our self-supervised labels. By integrating\nour unsupervised pseudo masks into SA-1B's ground-truth masks and training\nUnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segment\nentities overlooked by supervised SAM, exceeding SAM's AR by over 6.7% and AP\nby 3.9% on SA-1B.\n","authors":["XuDong Wang","Jingfeng Yang","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2406.20081v1.pdf","comment":"Code: https://github.com/frank-xwang/UnSAM"},{"id":"http://arxiv.org/abs/2406.20078v1","updated":"2024-06-28T17:42:08Z","published":"2024-06-28T17:42:08Z","title":"GM-DF: Generalized Multi-Scenario Deepfake Detection","summary":"  Existing face forgery detection usually follows the paradigm of training\nmodels in a single domain, which leads to limited generalization capacity when\nunseen scenarios and unknown attacks occur. In this paper, we elaborately\ninvestigate the generalization capacity of deepfake detection models when\njointly trained on multiple face forgery detection datasets. We first find a\nrapid degradation of detection accuracy when models are directly trained on\ncombined datasets due to the discrepancy across collection scenarios and\ngeneration methods. To address the above issue, a Generalized Multi-Scenario\nDeepfake Detection framework (GM-DF) is proposed to serve multiple real-world\nscenarios by a unified model. First, we propose a hybrid expert modeling\napproach for domain-specific real/forgery feature extraction. Besides, as for\nthe commonality representation, we use CLIP to extract the common features for\nbetter aligning visual and textual features across domains. Meanwhile, we\nintroduce a masked image reconstruction mechanism to force models to capture\nrich forged details. Finally, we supervise the models via a domain-aware\nmeta-learning strategy to further enhance their generalization capacities.\nSpecifically, we design a novel domain alignment loss to strongly align the\ndistributions of the meta-test domains and meta-train domains. Thus, the\nupdated models are able to represent both specific and common real/forgery\nfeatures across multiple datasets. In consideration of the lack of study of\nmulti-dataset training, we establish a new benchmark leveraging multi-source\ndata to fairly evaluate the models' generalization capacity on unseen\nscenarios. Both qualitative and quantitative experiments on five datasets\nconducted on traditional protocols as well as the proposed benchmark\ndemonstrate the effectiveness of our approach.\n","authors":["Yingxin Lai","Zitong Yu","Jing Yang","Bin Li","Xiangui Kang","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2406.20078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20077v1","updated":"2024-06-28T17:39:38Z","published":"2024-06-28T17:39:38Z","title":"HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model","summary":"  We introduce HouseCrafter, a novel approach that can lift a floorplan into a\ncomplete large 3D indoor scene (e.g., a house). Our key insight is to adapt a\n2D diffusion model, which is trained on web-scale images, to generate\nconsistent multi-view color (RGB) and depth (D) images across different\nlocations of the scene. Specifically, the RGB-D images are generated\nautoregressively in a batch-wise manner along sampled locations based on the\nfloorplan, where previously generated images are used as condition to the\ndiffusion model to produce images at nearby locations. The global floorplan and\nattention design in the diffusion model ensures the consistency of the\ngenerated images, from which a 3D scene can be reconstructed. Through extensive\nevaluation on the 3D-Front dataset, we demonstrate that HouseCraft can generate\nhigh-quality house-scale 3D scenes. Ablation studies also validate the\neffectiveness of different design choices. We will release our code and model\nweights. Project page: https://neu-vi.github.io/houseCrafter/\n","authors":["Hieu T. Nguyen","Yiwen Chen","Vikram Voleti","Varun Jampani","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.20077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20076v1","updated":"2024-06-28T17:38:18Z","published":"2024-06-28T17:38:18Z","title":"EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything\n  Model","summary":"  Segment Anything Model (SAM) has attracted widespread attention for its\nsuperior interactive segmentation capabilities with visual prompts while\nlacking further exploration of text prompts. In this paper, we empirically\ninvestigate what text prompt encoders (e.g., CLIP or LLM) are good for adapting\nSAM for referring expression segmentation and introduce the Early\nVision-language Fusion-based SAM (EVF-SAM). EVF-SAM is a simple yet effective\nreferring segmentation method which exploits multimodal prompts (i.e., image\nand text) and comprises a pre-trained vision-language model to generate\nreferring prompts and a SAM model for segmentation. Surprisingly, we observe\nthat: (1) multimodal prompts and (2) vision-language models with early fusion\n(e.g., BEIT-3) are beneficial for prompting SAM for accurate referring\nsegmentation. Our experiments show that the proposed EVF-SAM based on BEIT-3\ncan obtain state-of-the-art performance on RefCOCO/+/g for referring expression\nsegmentation and demonstrate the superiority of prompting SAM with early\nvision-language fusion. In addition, the proposed EVF-SAM with 1.32B parameters\nachieves remarkably higher performance while reducing nearly 82% of parameters\ncompared to previous SAM methods based on large multimodal models.\n","authors":["Yuxuan Zhang","Tianheng Cheng","Rui Hu","ei Liu","Heng Liu","Longjin Ran","Xiaoxin Chen","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2406.20076v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.20066v1","updated":"2024-06-28T17:22:33Z","published":"2024-06-28T17:22:33Z","title":"ASSR-NeRF: Arbitrary-Scale Super-Resolution on Voxel Grid for\n  High-Quality Radiance Fields Reconstruction","summary":"  NeRF-based methods reconstruct 3D scenes by building a radiance field with\nimplicit or explicit representations. While NeRF-based methods can perform\nnovel view synthesis (NVS) at arbitrary scale, the performance in\nhigh-resolution novel view synthesis (HRNVS) with low-resolution (LR)\noptimization often results in oversmoothing. On the other hand, single-image\nsuper-resolution (SR) aims to enhance LR images to HR counterparts but lacks\nmulti-view consistency. To address these challenges, we propose Arbitrary-Scale\nSuper-Resolution NeRF (ASSR-NeRF), a novel framework for super-resolution novel\nview synthesis (SRNVS). We propose an attention-based VoxelGridSR model to\ndirectly perform 3D super-resolution (SR) on the optimized volume. Our model is\ntrained on diverse scenes to ensure generalizability. For unseen scenes trained\nwith LR views, we then can directly apply our VoxelGridSR to further refine the\nvolume and achieve multi-view consistent SR. We demonstrate quantitative and\nqualitatively that the proposed method achieves significant performance in\nSRNVS.\n","authors":["Ding-Jiun Huang","Zi-Ting Chou","Yu-Chiang Frank Wang","Cheng Sun"],"pdf_url":"https://arxiv.org/pdf/2406.20066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07015v4","updated":"2024-06-28T17:14:13Z","published":"2023-05-11T17:55:25Z","title":"Exploiting Diffusion Prior for Real-World Image Super-Resolution","summary":"  We present a novel approach to leverage prior knowledge encapsulated in\npre-trained text-to-image diffusion models for blind super-resolution (SR).\nSpecifically, by employing our time-aware encoder, we can achieve promising\nrestoration results without altering the pre-trained synthesis model, thereby\npreserving the generative prior and minimizing training cost. To remedy the\nloss of fidelity caused by the inherent stochasticity of diffusion models, we\nemploy a controllable feature wrapping module that allows users to balance\nquality and fidelity by simply adjusting a scalar value during the inference\nprocess. Moreover, we develop a progressive aggregation sampling strategy to\novercome the fixed-size constraints of pre-trained diffusion models, enabling\nadaptation to resolutions of any size. A comprehensive evaluation of our method\nusing both synthetic and real-world benchmarks demonstrates its superiority\nover current state-of-the-art approaches. Code and models are available at\nhttps://github.com/IceClear/StableSR.\n","authors":["Jianyi Wang","Zongsheng Yue","Shangchen Zhou","Kelvin C. K. Chan","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2305.07015v4.pdf","comment":"Accepted by IJCV'2024. Some Figs are compressed due to size limits.\n  Uncompressed ver.:\n  https://github.com/IceClear/StableSR/releases/download/UncompressedPDF/StableSR_IJCV_Uncompressed.pdf.\n  Project page: https://iceclear.github.io/projects/stablesr/"},{"id":"http://arxiv.org/abs/2406.20055v1","updated":"2024-06-28T17:07:11Z","published":"2024-06-28T17:07:11Z","title":"SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) is a promising technique for 3D reconstruction,\noffering efficient training and rendering speeds, making it suitable for\nreal-time applications.However, current methods require highly controlled\nenvironments (no moving people or wind-blown elements, and consistent lighting)\nto meet the inter-view consistency assumption of 3DGS. This makes\nreconstruction of real-world captures problematic. We present SpotlessSplats,\nan approach that leverages pre-trained and general-purpose features coupled\nwith robust optimization to effectively ignore transient distractors. Our\nmethod achieves state-of-the-art reconstruction quality both visually and\nquantitatively, on casual captures.\n","authors":["Sara Sabour","Lily Goli","George Kopanas","Mark Matthews","Dmitry Lagun","Leonidas Guibas","Alec Jacobson","David J. Fleet","Andrea Tagliasacchi"],"pdf_url":"https://arxiv.org/pdf/2406.20055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20042v1","updated":"2024-06-28T16:40:57Z","published":"2024-06-28T16:40:57Z","title":"HAITCH: A Framework for Distortion and Motion Correction in Fetal\n  Multi-Shell Diffusion-Weighted MRI","summary":"  Diffusion magnetic resonance imaging (dMRI) is pivotal for probing the\nmicrostructure of the rapidly-developing fetal brain. However, fetal motion\nduring scans and its interaction with magnetic field inhomogeneities result in\nartifacts and data scattering across spatial and angular domains. The effects\nof those artifacts are more pronounced in high-angular resolution fetal dMRI,\nwhere signal-to-noise ratio is very low. Those effects lead to biased estimates\nand compromise the consistency and reliability of dMRI analysis. This work\npresents HAITCH, the first and the only publicly available tool to correct and\nreconstruct multi-shell high-angular resolution fetal dMRI data. HAITCH offers\nseveral technical advances that include a blip-reversed dual-echo acquisition\nfor dynamic distortion correction, advanced motion correction for model-free\nand robust reconstruction, optimized multi-shell design for enhanced\ninformation capture and increased tolerance to motion, and outlier detection\nfor improved reconstruction fidelity. The framework is open-source, flexible,\nand can be used to process any type of fetal dMRI data including single-echo or\nsingle-shell acquisitions, but is most effective when used with multi-shell\nmulti-echo fetal dMRI data that cannot be processed with any of the existing\ntools. Validation experiments on real fetal dMRI scans demonstrate significant\nimprovements and accurate correction across diverse fetal ages and motion\nlevels. HAITCH successfully removes artifacts and reconstructs high-fidelity\nfetal dMRI data suitable for advanced diffusion modeling, including fiber\norientation distribution function estimation. These advancements pave the way\nfor more reliable analysis of the fetal brain microstructure and tractography\nunder challenging imaging conditions.\n","authors":["Haykel Snoussi","Davood Karimi","Onur Afacan","Mustafa Utkur","Ali Gholipour"],"pdf_url":"https://arxiv.org/pdf/2406.20042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.15180v2","updated":"2024-06-28T16:40:39Z","published":"2023-07-27T20:19:11Z","title":"EnSolver: Uncertainty-Aware Ensemble CAPTCHA Solvers with Theoretical\n  Guarantees","summary":"  The popularity of text-based CAPTCHA as a security mechanism to protect\nwebsites from automated bots has prompted researches in CAPTCHA solvers, with\nthe aim of understanding its failure cases and subsequently making CAPTCHAs\nmore secure. Recently proposed solvers, built on advances in deep learning, are\nable to crack even the very challenging CAPTCHAs with high accuracy. However,\nthese solvers often perform poorly on out-of-distribution samples that contain\nvisual features different from those in the training set. Furthermore, they\nlack the ability to detect and avoid such samples, making them susceptible to\nbeing locked out by defense systems after a certain number of failed attempts.\nIn this paper, we propose EnSolver, a family of CAPTCHA solvers that use deep\nensemble uncertainty to detect and skip out-of-distribution CAPTCHAs, making it\nharder to be detected. We prove novel theoretical bounds on the effectiveness\nof our solvers and demonstrate their use with state-of-the-art CAPTCHA solvers.\nOur experiments show that the proposed approaches perform well when cracking\nCAPTCHA datasets that contain both in-distribution and out-of-distribution\nsamples.\n","authors":["Duc C. Hoang","Behzad Ousat","Amin Kharraz","Cuong V. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2307.15180v2.pdf","comment":"A previous version of this paper was presented at the Epistemic\n  Uncertainty - E-pi UAI 2023 Workshop"},{"id":"http://arxiv.org/abs/2406.20024v1","updated":"2024-06-28T16:13:55Z","published":"2024-06-28T16:13:55Z","title":"eMoE-Tracker: Environmental MoE-based Transformer for Robust\n  Event-guided Object Tracking","summary":"  The unique complementarity of frame-based and event cameras for high frame\nrate object tracking has recently inspired some research attempts to develop\nmulti-modal fusion approaches. However, these methods directly fuse both\nmodalities and thus ignore the environmental attributes, e.g., motion blur,\nillumination variance, occlusion, scale variation, etc. Meanwhile, no\ninteraction between search and template features makes distinguishing target\nobjects and backgrounds difficult. As a result, performance degradation is\ninduced especially in challenging conditions. This paper proposes a novel and\neffective Transformer-based event-guided tracking framework, called\neMoE-Tracker, which achieves new SOTA performance under various conditions. Our\nkey idea is to disentangle the environment into several learnable attributes to\ndynamically learn the attribute-specific features for better interaction and\ndiscriminability between the target information and background. To achieve the\ngoal, we first propose an environmental Mix-of-Experts (eMoE) module that is\nbuilt upon the environmental Attributes Disentanglement to learn\nattribute-specific features and environmental Attributes Gating to assemble the\nattribute-specific features by the learnable attribute scores dynamically. The\neMoE module is a subtle router that fine-tunes the transformer backbone more\nefficiently. We then introduce a contrastive relation modeling (CRM) module to\nimprove interaction and discriminability between the target information and\nbackground. Extensive experiments on diverse event-based benchmark datasets\nshowcase the superior performance of our eMoE-Tracker compared to the prior\narts.\n","authors":["Yucheng Chen","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.20024v1.pdf","comment":"RGB-event single object tracking"},{"id":"http://arxiv.org/abs/2406.20005v1","updated":"2024-06-28T15:44:55Z","published":"2024-06-28T15:44:55Z","title":"Malaria Cell Detection Using Deep Neural Networks","summary":"  Malaria remains one of the most pressing public health concerns globally,\ncausing significant morbidity and mortality, especially in sub-Saharan Africa.\nRapid and accurate diagnosis is crucial for effective treatment and disease\nmanagement. Traditional diagnostic methods, such as microscopic examination of\nblood smears, are labor-intensive and require significant expertise, which may\nnot be readily available in resource-limited settings. This project aims to\nautomate the detection of malaria-infected cells using a deep learning\napproach. We employed a convolutional neural network (CNN) based on the\nResNet50 architecture, leveraging transfer learning to enhance performance. The\nMalaria Cell Images Dataset from Kaggle, containing 27,558 images categorized\ninto infected and uninfected cells, was used for training and evaluation. Our\nmodel demonstrated high accuracy, precision, and recall, indicating its\npotential as a reliable tool for assisting in malaria diagnosis. Additionally,\na web application was developed using Streamlit to allow users to upload cell\nimages and receive predictions about malaria infection, making the technology\naccessible and user-friendly. This paper provides a comprehensive overview of\nthe methodology, experiments, and results, highlighting the effectiveness of\ndeep learning in medical image analysis.\n","authors":["Saurabh Sawant","Anurag Singh"],"pdf_url":"https://arxiv.org/pdf/2406.20005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00035v3","updated":"2024-06-28T15:42:12Z","published":"2024-01-08T12:19:46Z","title":"Robustness Assessment of a Runway Object Classifier for Safe Aircraft\n  Taxiing","summary":"  As deep neural networks (DNNs) are becoming the prominent solution for many\ncomputational problems, the aviation industry seeks to explore their potential\nin alleviating pilot workload and in improving operational safety. However, the\nuse of DNNs in this type of safety-critical applications requires a thorough\ncertification process. This need can be addressed through formal verification,\nwhich provides rigorous assurances -- e.g.,~by proving the absence of certain\nmispredictions. In this case-study paper, we demonstrate this process using an\nimage-classifier DNN currently under development at Airbus and intended for use\nduring the aircraft taxiing phase. We use formal methods to assess this DNN's\nrobustness to three common image perturbation types: noise, brightness and\ncontrast, and some of their combinations. This process entails multiple\ninvocations of the underlying verifier, which might be computationally\nexpensive; and we therefore propose a method that leverages the monotonicity of\nthese robustness properties, as well as the results of past verification\nqueries, in order to reduce the overall number of verification queries required\nby nearly 60%. Our results provide an indication of the level of robustness\nachieved by the DNN classifier under study, and indicate that it is\nconsiderably more vulnerable to noise than to brightness or contrast\nperturbations.\n","authors":["Yizhak Elboher","Raya Elsaleh","Omri Isac","Mélanie Ducoffe","Audrey Galametz","Guillaume Povéda","Ryma Boumazouza","Noémie Cohen","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2402.00035v3.pdf","comment":"This is a preprint version of the paper in the proceedings of 43rd\n  Digital Avionics Systems Conference (DASC)"},{"id":"http://arxiv.org/abs/2406.19997v1","updated":"2024-06-28T15:32:59Z","published":"2024-06-28T15:32:59Z","title":"Wavelets Are All You Need for Autoregressive Image Generation","summary":"  In this paper, we take a new approach to autoregressive image generation that\nis based on two main ingredients. The first is wavelet image coding, which\nallows to tokenize the visual details of an image from coarse to fine details\nby ordering the information starting with the most significant bits of the most\nsignificant wavelet coefficients. The second is a variant of a language\ntransformer whose architecture is re-designed and optimized for token sequences\nin this 'wavelet language'. The transformer learns the significant statistical\ncorrelations within a token sequence, which are the manifestations of\nwell-known correlations between the wavelet subbands at various resolutions. We\nshow experimental results with conditioning on the generation process.\n","authors":["Wael Mattar","Idan Levy","Nir Sharon","Shai Dekel"],"pdf_url":"https://arxiv.org/pdf/2406.19997v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.19973v1","updated":"2024-06-28T15:01:23Z","published":"2024-06-28T15:01:23Z","title":"STLLaVA-Med: Self-Training Large Language and Vision Assistant for\n  Medical","summary":"  Large Vision-Language Models (LVLMs) have shown significant potential in\nassisting medical diagnosis by leveraging extensive biomedical datasets.\nHowever, the advancement of medical image understanding and reasoning\ncritically depends on building high-quality visual instruction data, which is\ncostly and labor-intensive to obtain, particularly in the medical domain. To\nmitigate this data-starving issue, we introduce Self-Training Large Language\nand Vision Assistant for Medical (STLLaVA-Med). The proposed method is designed\nto train a policy model (an LVLM) capable of auto-generating medical visual\ninstruction data to improve data efficiency, guided through Direct Preference\nOptimization (DPO). Specifically, a more powerful and larger LVLM (e.g.,\nGPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuning\nprocess on the auto-generated data, encouraging the policy model to align\nefficiently with human preferences. We validate the efficacy and data\nefficiency of STLLaVA-Med across three major medical Visual Question Answering\n(VQA) benchmarks, demonstrating competitive zero-shot performance with the\nutilization of only 9% of the medical data.\n","authors":["Guohao Sun","Can Qin","Huazhu Fu","Linwei Wang","Zhiqiang Tao"],"pdf_url":"https://arxiv.org/pdf/2406.19973v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.05779v3","updated":"2024-06-28T14:53:06Z","published":"2024-06-09T13:25:02Z","title":"Learning to utilize image second-order derivative information for crisp\n  edge detection","summary":"  Edge detection is a fundamental task in computer vision. It has made great\nprogress under the development of deep convolutional neural networks (DCNNs),\nsome of which have achieved a beyond human-level performance. However, recent\ntop-performing edge detection methods tend to generate thick and noisy edge\nlines. In this work, we solve this problem from two aspects: (1) the lack of\nprior knowledge regarding image edges, and (2) the issue of imbalanced pixel\ndistribution. We propose a second-order derivative-based multi-scale contextual\nenhancement module (SDMCM) to help the model locate true edge pixels accurately\nby introducing the edge prior knowledge. We also construct a hybrid focal loss\nfunction (HFL) to alleviate the imbalanced distribution issue. In addition, we\nemploy the conditionally parameterized convolution (CondConv) to develop a\nnovel boundary refinement module (BRM), which can further refine the final\noutput edge maps. In the end, we propose a U-shape network named LUS-Net which\nis based on the SDMCM and BRM for crisp edge detection. We perform extensive\nexperiments on three standard benchmarks, and the experiment results illustrate\nthat our method can predict crisp and clean edge maps and achieves\nstate-of-the-art performance on the BSDS500 dataset (ODS=0.829), NYUD-V2\ndataset (ODS=0.768), and BIPED dataset (ODS=0.903).\n","authors":["Changsong Liu","Wei Zhang","Yanyan Liu","Yimeng Fan","Mingyang Li","Wenlin Li"],"pdf_url":"https://arxiv.org/pdf/2406.05779v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17032v2","updated":"2024-06-28T14:34:00Z","published":"2024-06-24T18:00:11Z","title":"DWARF: Disease-weighted network for attention map refinement","summary":"  The interpretability of deep learning is crucial for evaluating the\nreliability of medical imaging models and reducing the risks of inaccurate\npatient recommendations. This study addresses the \"human out of the loop\" and\n\"trustworthiness\" issues in medical image analysis by integrating medical\nprofessionals into the interpretability process. We propose a disease-weighted\nattention map refinement network (DWARF) that leverages expert feedback to\nenhance model relevance and accuracy. Our method employs cyclic training to\niteratively improve diagnostic performance, generating precise and\ninterpretable feature maps. Experimental results demonstrate significant\nimprovements in interpretability and diagnostic accuracy across multiple\nmedical imaging datasets. This approach fosters effective collaboration between\nAI systems and healthcare professionals, ultimately aiming to improve patient\noutcomes\n","authors":["Haozhe Luo","Aurélie Pahud de Mortanges","Oana Inel","Abraham Bernstein","Mauricio Reyes"],"pdf_url":"https://arxiv.org/pdf/2406.17032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19943v1","updated":"2024-06-28T14:22:30Z","published":"2024-06-28T14:22:30Z","title":"Impact of Initialization on Intra-subject Pediatric Brain MR Image\n  Registration: A Comparative Analysis between SyN ANTs and Deep Learning-Based\n  Approaches","summary":"  This study evaluates the performance of conventional SyN ANTs and\nlearning-based registration methods in the context of pediatric neuroimaging,\nspecifically focusing on intrasubject deformable registration. The comparison\ninvolves three approaches: without (NR), with rigid (RR), and with rigid and\naffine (RAR) initializations. In addition to initialization, performances are\nevaluated in terms of accuracy, speed, and the impact of age intervals and sex\nper pair. Data consists of the publicly available MRI scans from the Calgary\nPreschool dataset, which includes 63 children aged 2-7 years, allowing for 431\nregistration pairs. We implemented the unsupervised DL framework with a U-Net\narchitecture using DeepReg and it was 5-fold cross-validated. Evaluation\nincludes Dice scores for tissue segmentation from 18 smaller regions obtained\nby SynthSeg, analysis of log Jacobian determinants, and registration pro-rated\ntraining and inference times. Learning-based approaches, with or without linear\ninitializations, exhibit slight superiority over SyN ANTs in terms of Dice\nscores. Indeed, DL-based implementations with RR and RAR initializations\nsignificantly outperform SyN ANTs. Both SyN ANTs and DL-based registration\ninvolve parameter optimization, but the choice between these methods depends on\nthe scale of registration: network-based for broader coverage or SyN ANTs for\nspecific structures. Both methods face challenges with larger age intervals due\nto greater growth changes. The main takeaway is that while DL-based methods\nshow promise with faster and more accurate registrations, SyN ANTs remains\nrobust and generalizable without the need for extensive training, highlighting\nthe importance of method selection based on specific registration needs in the\npediatric context. Our code is available at\nhttps://github.com/neuropoly/pediatric-DL-registration\n","authors":["Andjela Dimitrijevic","Vincent Noblet","Benjamin De Leener"],"pdf_url":"https://arxiv.org/pdf/2406.19943v1.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:013"},{"id":"http://arxiv.org/abs/2406.19941v1","updated":"2024-06-28T14:17:16Z","published":"2024-06-28T14:17:16Z","title":"GRACE: Graph-Regularized Attentive Convolutional Entanglement with\n  Laplacian Smoothing for Robust DeepFake Video Detection","summary":"  As DeepFake video manipulation techniques escalate, posing profound threats,\nthe urgent need to develop efficient detection strategies is underscored.\nHowever, one particular issue lies with facial images being mis-detected, often\noriginating from degraded videos or adversarial attacks, leading to unexpected\ntemporal artifacts that can undermine the efficacy of DeepFake video detection\ntechniques. This paper introduces a novel method for robust DeepFake video\ndetection, harnessing the power of the proposed Graph-Regularized Attentive\nConvolutional Entanglement (GRACE) based on the graph convolutional network\nwith graph Laplacian to address the aforementioned challenges. First,\nconventional Convolution Neural Networks are deployed to perform spatiotemporal\nfeatures for the entire video. Then, the spatial and temporal features are\nmutually entangled by constructing a graph with sparse constraint, enforcing\nessential features of valid face images in the noisy face sequences remaining,\nthus augmenting stability and performance for DeepFake video detection.\nFurthermore, the Graph Laplacian prior is proposed in the graph convolutional\nnetwork to remove the noise pattern in the feature space to further improve the\nperformance. Comprehensive experiments are conducted to illustrate that our\nproposed method delivers state-of-the-art performance in DeepFake video\ndetection under noisy face sequences. The source code is available at\nhttps://github.com/ming053l/GRACE.\n","authors":["Chih-Chung Hsu","Shao-Ning Chen","Mei-Hsuan Wu","Yi-Fang Wang","Chia-Ming Lee","Yi-Shiuan Chou"],"pdf_url":"https://arxiv.org/pdf/2406.19941v1.pdf","comment":"Submitted to TPAMI 2024"},{"id":"http://arxiv.org/abs/2404.00548v2","updated":"2024-06-28T14:13:18Z","published":"2024-03-31T03:30:37Z","title":"Modeling State Shifting via Local-Global Distillation for Event-Frame\n  Gaze Tracking","summary":"  This paper tackles the problem of passive gaze estimation using both event\nand frame data. Considering the inherently different physiological structures,\nit is intractable to accurately estimate gaze purely based on a given state.\nThus, we reformulate gaze estimation as the quantification of the state\nshifting from the current state to several prior registered anchor states.\nSpecifically, we propose a two-stage learning-based gaze estimation framework\nthat divides the whole gaze estimation process into a coarse-to-fine approach\ninvolving anchor state selection and final gaze location. Moreover, to improve\nthe generalization ability, instead of learning a large gaze estimation network\ndirectly, we align a group of local experts with a student network, where a\nnovel denoising distillation algorithm is introduced to utilize denoising\ndiffusion techniques to iteratively remove inherent noise in event data.\nExtensive experiments demonstrate the effectiveness of the proposed method,\nwhich surpasses state-of-the-art methods by a large margin of 15$\\%$. The code\nwill be publicly available at\nhttps://github.com/jdjdli/Denoise_distill_EF_gazetracker.\n","authors":["Jiading Li","Zhiyu Zhu","Jinhui Hou","Junhui Hou","Jinjian Wu"],"pdf_url":"https://arxiv.org/pdf/2404.00548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00592v2","updated":"2024-06-28T14:02:06Z","published":"2023-12-01T13:56:28Z","title":"Tracking Object Positions in Reinforcement Learning: A Metric for\n  Keypoint Detection (extended version)","summary":"  Reinforcement learning (RL) for robot control typically requires a detailed\nrepresentation of the environment state, including information about\ntask-relevant objects not directly measurable. Keypoint detectors, such as\nspatial autoencoders (SAEs), are a common approach to extracting a\nlow-dimensional representation from high-dimensional image data. SAEs aim at\nspatial features such as object positions, which are often useful\nrepresentations in robotic RL. However, whether an SAE is actually able to\ntrack objects in the scene and thus yields a spatial state representation well\nsuited for RL tasks has rarely been examined due to a lack of established\nmetrics. In this paper, we propose to assess the performance of an SAE instance\nby measuring how well keypoints track ground truth objects in images. We\npresent a computationally lightweight metric and use it to evaluate common\nbaseline SAE architectures on image data from a simulated robot task. We find\nthat common SAEs differ substantially in their spatial extraction capability.\nFurthermore, we validate that SAEs that perform well in our metric achieve\nsuperior performance when used in downstream RL. Thus, our metric is an\neffective and lightweight indicator of RL performance before executing\nexpensive RL training. Building on these insights, we identify three key\nmodifications of SAE architectures to improve tracking performance. We make our\ncode available at anonymous.4open.science/r/sae-rl.\n","authors":["Emma Cramer","Jonas Reiher","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2312.00592v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19922v1","updated":"2024-06-28T13:51:59Z","published":"2024-06-28T13:51:59Z","title":"Parallax-tolerant Image Stitching via Segmentation-guided\n  Multi-homography Warping","summary":"  Large parallax between images is an intractable issue in image stitching.\nVarious warping-based methods are proposed to address it, yet the results are\nunsatisfactory. In this paper, we propose a novel image stitching method using\nmulti-homography warping guided by image segmentation. Specifically, we\nleverage the Segment Anything Model to segment the target image into numerous\ncontents and partition the feature points into multiple subsets via the\nenergy-based multi-homography fitting algorithm. The multiple subsets of\nfeature points are used to calculate the corresponding multiple homographies.\nFor each segmented content in the overlapping region, we select its\nbest-fitting homography with the lowest photometric error. For each segmented\ncontent in the non-overlapping region, we calculate a weighted combination of\nthe linearized homographies. Finally, the target image is warped via the\nbest-fitting homographies to align with the reference image, and the final\npanorama is generated via linear blending. Comprehensive experimental results\non the public datasets demonstrate that our method provides the best alignment\naccuracy by a large margin, compared with the state-of-the-art methods. The\nsource code is available at https://github.com/tlliao/multi-homo-warp.\n","authors":["Tianli Liao","Ce Wang","Lei Li","Guangen Liu","Nan Li"],"pdf_url":"https://arxiv.org/pdf/2406.19922v1.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.19905v1","updated":"2024-06-28T13:20:17Z","published":"2024-06-28T13:20:17Z","title":"Solving Token Gradient Conflict in Mixture-of-Experts for Large\n  Vision-Language Model","summary":"  The Mixture-of-Experts (MoE) has gained increasing attention in the study of\nLarge Vision-Language Models (LVLMs). It uses a sparse model to replace the\ndense model, achieving comparable performance while activating fewer parameters\nduring inference, thus significantly reducing the inference cost. Existing MoE\nmethods in LVLMs encourage different experts to handle different tokens, and\nthus they employ a router to predict the routing for each token. However, the\npredictions are based solely on sample features and do not truly reveal the\noptimization direction of tokens. This can lead to severe optimization\nconflicts between different tokens within an expert. To address this problem,\nthis paper proposes a novel method based on token-level gradient analysis.\nSpecifically, we first use token-level gradients to identify conflicting tokens\nin experts. Then, we add a specialized loss tailored to eliminate conflicts\namong tokens within each expert. Our method can serve as a plug-in for diverse\nLarge Vision-Language Models, and extensive experimental results demonstrate\nthe effectiveness of our method. The code will be publicly available at\nhttps://github.com/longrongyang/STGC.\n","authors":["Longrong Yang","Dong Sheng","Chaoxiang Cai","Fan Yang","Size Li","Di Zhang","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2406.19905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14862v3","updated":"2024-06-28T13:19:37Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\nLatentExplainer, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\nLatentExplainer tackles three main challenges: inferring the meaning of latent\nvariables, aligning explanations with inductive biases, and handling varying\ndegrees of explainability. By perturbing latent variables and interpreting\nchanges in generated data, the framework provides a systematic approach to\nunderstanding and controlling the data generation process, enhancing the\ntransparency and interpretability of deep generative models. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations of\nlatent variables.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19899v1","updated":"2024-06-28T13:07:43Z","published":"2024-06-28T13:07:43Z","title":"On the Value of PHH3 for Mitotic Figure Detection on H&E-stained Images","summary":"  The count of mitotic figures (MFs) observed in hematoxylin and eosin\n(H&E)-stained slides is an important prognostic marker as it is a measure for\ntumor cell proliferation. However, the identification of MFs has a known low\ninter-rater agreement. Deep learning algorithms can standardize this task, but\nthey require large amounts of annotated data for training and validation.\nFurthermore, label noise introduced during the annotation process may impede\nthe algorithm's performance. Unlike H&E, the mitosis-specific antibody\nphospho-histone H3 (PHH3) specifically highlights MFs. Counting MFs on slides\nstained against PHH3 leads to higher agreement among raters and has therefore\nrecently been used as a ground truth for the annotation of MFs in H&E. However,\nas PHH3 facilitates the recognition of cells indistinguishable from H&E stain\nalone, the use of this ground truth could potentially introduce noise into the\nH&E-related dataset, impacting model performance. This study analyzes the\nimpact of PHH3-assisted MF annotation on inter-rater reliability and object\nlevel agreement through an extensive multi-rater experiment. We found that the\nannotators' object-level agreement increased when using PHH3-assisted labeling.\nSubsequently, MF detectors were evaluated on the resulting datasets to\ninvestigate the influence of PHH3-assisted labeling on the models' performance.\nAdditionally, a novel dual-stain MF detector was developed to investigate the\ninterpretation-shift of PHH3-assisted labels used in H&E, which clearly\noutperformed single-stain detectors. However, the PHH3-assisted labels did not\nhave a positive effect on solely H&E-based models. The high performance of our\ndual-input detector reveals an information mismatch between the H&E and\nPHH3-stained images as the cause of this effect.\n","authors":["Jonathan Ganz","Christian Marzahl","Jonas Ammeling","Barbara Richter","Chloé Puget","Daniela Denk","Elena A. Demeter","Flaviu A. Tabaran","Gabriel Wasinger","Karoline Lipnik","Marco Tecilla","Matthew J. Valentine","Michael J. Dark","Niklas Abele","Pompei Bolfa","Ramona Erber","Robert Klopfleisch","Sophie Merz","Taryn A. Donovan","Samir Jabari","Christof A. Bertram","Katharina Breininger","Marc Aubreville"],"pdf_url":"https://arxiv.org/pdf/2406.19899v1.pdf","comment":"10 pages, 5 figures, 1 Table"},{"id":"http://arxiv.org/abs/2406.19875v1","updated":"2024-06-28T12:35:01Z","published":"2024-06-28T12:35:01Z","title":"InfiniBench: A Comprehensive Benchmark for Large Multimodal Models in\n  Very Long Video Understanding","summary":"  Understanding long videos, ranging from tens of minutes to several hours,\npresents unique challenges in video comprehension. Despite the increasing\nimportance of long-form video content, existing benchmarks primarily focus on\nshorter clips. To address this gap, we introduce InfiniBench a comprehensive\nbenchmark for very long video understanding which presents 1)The longest video\nduration, averaging 76.34 minutes; 2) The largest number of question-answer\npairs, 108.2K; 3) Diversity in questions that examine nine different skills and\ninclude both multiple-choice questions and open-ended questions; 4)\nHumancentric, as the video sources come from movies and daily TV shows, with\nspecific human-level question designs such as Movie Spoiler Questions that\nrequire critical thinking and comprehensive understanding. Using InfiniBench,\nwe comprehensively evaluate existing Large MultiModality Models (LMMs) on each\nskill, including the commercial model Gemini 1.5 Flash and the open-source\nmodels. The evaluation shows significant challenges in our benchmark.Our\nresults show that the best AI models such Gemini struggles to perform well with\n42.72% average accuracy and 2.71 out of 5 average score. We hope this benchmark\nwill stimulate the LMMs community towards long video and human-level\nunderstanding. Our benchmark can be accessed at\nhttps://vision-cair.github.io/InfiniBench/\n","authors":["Kirolos Ataallah","Chenhui Gou","Eslam Abdelrahman","Khushbu Pahwa","Jian Ding","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2406.19875v1.pdf","comment":"16 page ,17 figures"},{"id":"http://arxiv.org/abs/2406.11252v2","updated":"2024-06-28T11:59:01Z","published":"2024-06-17T06:28:58Z","title":"Mining Open Semantics from CLIP: A Relation Transition Perspective for\n  Few-Shot Learning","summary":"  Contrastive Vision-Language Pre-training(CLIP) demonstrates impressive\nzero-shot capability. The key to improve the adaptation of CLIP to downstream\ntask with few exemplars lies in how to effectively model and transfer the\nuseful knowledge embedded in CLIP. Previous work mines the knowledge typically\nbased on the limited visual samples and close-set semantics (i.e., within\ntarget category set of downstream task). However, the aligned CLIP image/text\nencoders contain abundant relationships between visual features and almost\ninfinite open semantics, which may benefit the few-shot learning but remains\nunexplored. In this paper, we propose to mine open semantics as anchors to\nperform a relation transition from image-anchor relationship to image-target\nrelationship to make predictions. Specifically, we adopt a transformer module\nwhich takes the visual feature as \"Query\", the text features of the anchors as\n\"Key\" and the similarity matrix between the text features of anchor and target\nclasses as \"Value\". In this way, the output of such a transformer module\nrepresents the relationship between the image and target categories, i.e., the\nclassification predictions. To avoid manually selecting the open semantics, we\nmake the [CLASS] token of input text embedding learnable. We conduct extensive\nexperiments on eleven representative classification datasets. The results show\nthat our method performs favorably against previous state-of-the-arts\nconsidering few-shot classification settings.\n","authors":["Cilin Yan","Haochen Wang","Xiaolong Jiang","Yao Hu","Xu Tang","Guoliang Kang","Efstratios Gavves"],"pdf_url":"https://arxiv.org/pdf/2406.11252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19852v1","updated":"2024-06-28T11:49:59Z","published":"2024-06-28T11:49:59Z","title":"FootBots: A Transformer-based Architecture for Motion Prediction in\n  Soccer","summary":"  Motion prediction in soccer involves capturing complex dynamics from player\nand ball interactions. We present FootBots, an encoder-decoder\ntransformer-based architecture addressing motion prediction and conditioned\nmotion prediction through equivariance properties. FootBots captures temporal\nand social dynamics using set attention blocks and multi-attention block\ndecoder. Our evaluation utilizes two datasets: a real soccer dataset and a\ntailored synthetic one. Insights from the synthetic dataset highlight the\neffectiveness of FootBots' social attention mechanism and the significance of\nconditioned motion prediction. Empirical results on real soccer data\ndemonstrate that FootBots outperforms baselines in motion prediction and excels\nin conditioned tasks, such as predicting the players based on the ball\nposition, predicting the offensive (defensive) team based on the ball and the\ndefensive (offensive) team, and predicting the ball position based on all\nplayers. Our evaluation connects quantitative and qualitative findings.\nhttps://youtu.be/9kaEkfzG3L8\n","authors":["Guillem Capellera","Luis Ferraz","Antonio Rubio","Antonio Agudo","Francesc Moreno-Noguer"],"pdf_url":"https://arxiv.org/pdf/2406.19852v1.pdf","comment":"Published as a conference paper at IEEE ICIP 2024"},{"id":"http://arxiv.org/abs/2406.19844v1","updated":"2024-06-28T11:35:35Z","published":"2024-06-28T11:35:35Z","title":"StreamMOTP: Streaming and Unified Framework for Joint 3D Multi-Object\n  Tracking and Trajectory Prediction","summary":"  3D multi-object tracking and trajectory prediction are two crucial modules in\nautonomous driving systems. Generally, the two tasks are handled separately in\ntraditional paradigms and a few methods have started to explore modeling these\ntwo tasks in a joint manner recently. However, these approaches suffer from the\nlimitations of single-frame training and inconsistent coordinate\nrepresentations between tracking and prediction tasks. In this paper, we\npropose a streaming and unified framework for joint 3D Multi-Object Tracking\nand trajectory Prediction (StreamMOTP) to address the above challenges.\nFirstly, we construct the model in a streaming manner and exploit a memory bank\nto preserve and leverage the long-term latent features for tracked objects more\neffectively. Secondly, a relative spatio-temporal positional encoding strategy\nis introduced to bridge the gap of coordinate representations between the two\ntasks and maintain the pose-invariance for trajectory prediction. Thirdly, we\nfurther improve the quality and consistency of predicted trajectories with a\ndual-stream predictor. We conduct extensive experiments on popular nuSences\ndataset and the experimental results demonstrate the effectiveness and\nsuperiority of StreamMOTP, which outperforms previous methods significantly on\nboth tasks. Furthermore, we also prove that the proposed framework has great\npotential and advantages in actual applications of autonomous driving.\n","authors":["Jiaheng Zhuang","Guoan Wang","Siyu Zhang","Xiyang Wang","Hangning Zhou","Ziyao Xu","Chi Zhang","Zhiheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.19844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03511v3","updated":"2024-06-28T11:23:11Z","published":"2023-12-06T14:13:38Z","title":"Kandinsky 3.0 Technical Report","summary":"  We present Kandinsky 3.0, a large-scale text-to-image generation model based\non latent diffusion, continuing the series of text-to-image Kandinsky models\nand reflecting our progress to achieve higher quality and realism of image\ngeneration. In this report we describe the architecture of the model, the data\ncollection procedure, the training technique, and the production system for\nuser interaction. We focus on the key components that, as we have identified as\na result of a large number of experiments, had the most significant impact on\nimproving the quality of our model compared to the others. We also describe\nextensions and applications of our model, including super resolution,\ninpainting, image editing, image-to-video generation, and a distilled version\nof Kandinsky 3.0 - Kandinsky 3.1, which does inference in 4 steps of the\nreverse process and 20 times faster without visual quality decrease. By\nside-by-side human preferences comparison, Kandinsky becomes better in text\nunderstanding and works better on specific domains. The code is available at\nhttps://github.com/ai-forever/Kandinsky-3\n","authors":["Vladimir Arkhipkin","Andrei Filatov","Viacheslav Vasilev","Anastasia Maltseva","Said Azizov","Igor Pavlov","Julia Agafonova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2312.03511v3.pdf","comment":"Project page: https://ai-forever.github.io/Kandinsky-3"},{"id":"http://arxiv.org/abs/2406.19833v1","updated":"2024-06-28T11:11:24Z","published":"2024-06-28T11:11:24Z","title":"LightStereo: Channel Boost Is All Your Need for Efficient 2D Cost\n  Aggregation","summary":"  We present LightStereo, a cutting-edge stereo-matching network crafted to\naccelerate the matching process. Departing from conventional methodologies that\nrely on aggregating computationally intensive 4D costs, LightStereo adopts the\n3D cost volume as a lightweight alternative. While similar approaches have been\nexplored previously, our breakthrough lies in enhancing performance through a\ndedicated focus on the channel dimension of the 3D cost volume, where the\ndistribution of matching costs is encapsulated. Our exhaustive exploration has\nyielded plenty of strategies to amplify the capacity of the pivotal dimension,\nensuring both precision and efficiency. We compare the proposed LightStereo\nwith existing state-of-the-art methods across various benchmarks, which\ndemonstrate its superior performance in speed, accuracy, and resource\nutilization. LightStereo achieves a competitive EPE metric in the SceneFlow\ndatasets while demanding a minimum of only 22 GFLOPs, with an inference time of\njust 17 ms. Our comprehensive analysis reveals the effect of 2D cost\naggregation for stereo matching, paving the way for real-world applications of\nefficient stereo systems. Code will be available at\n\\url{https://github.com/XiandaGuo/OpenStereo}.\n","authors":["Xianda Guo","Chenming Zhang","Dujun Nie","Wenzhao Zheng","Youmin Zhang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19833v1.pdf","comment":"Code will be available at\n  \\url{https://github.com/XiandaGuo/OpenStereo}"},{"id":"http://arxiv.org/abs/2406.19815v1","updated":"2024-06-28T10:45:37Z","published":"2024-06-28T10:45:37Z","title":"Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based\n  on Multi-dimensional Features","summary":"  Adversarial attack on skeletal motion is a hot topic. However, existing\nresearches only consider part of dynamic features when measuring distance\nbetween skeleton graph sequences, which results in poor imperceptibility. To\nthis end, we propose a novel adversarial attack method to attack action\nrecognizers for skeletal motions. Firstly, our method systematically proposes a\ndynamic distance function to measure the difference between skeletal motions.\nMeanwhile, we innovatively introduce emotional features for complementary\ninformation. In addition, we use Alternating Direction Method of\nMultipliers(ADMM) to solve the constrained optimization problem, which\ngenerates adversarial samples with better imperceptibility to deceive the\nclassifiers. Experiments show that our method is effective on multiple action\nclassifiers and datasets. When the perturbation magnitude measured by l norms\nis the same, the dynamic perturbations generated by our method are much lower\nthan that of other methods. What's more, we are the first to prove the\neffectiveness of emotional features, and provide a new idea for measuring the\ndistance between skeletal motions.\n","authors":["Feng Liu","Qing Xu","Qijian Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.19815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19814v1","updated":"2024-06-28T10:45:25Z","published":"2024-06-28T10:45:25Z","title":"Extract More from Less: Efficient Fine-Grained Visual Recognition in\n  Low-Data Regimes","summary":"  The emerging task of fine-grained image classification in low-data regimes\nassumes the presence of low inter-class variance and large intra-class\nvariation along with a highly limited amount of training samples per class.\nHowever, traditional ways of separately dealing with fine-grained\ncategorisation and extremely scarce data may be inefficient under both these\nharsh conditions presented together. In this paper, we present a novel\nframework, called AD-Net, aiming to enhance deep neural network performance on\nthis challenge by leveraging the power of Augmentation and Distillation\ntechniques. Specifically, our approach is designed to refine learned features\nthrough self-distillation on augmented samples, mitigating harmful overfitting.\nWe conduct comprehensive experiments on popular fine-grained image\nclassification benchmarks where our AD-Net demonstrates consistent improvement\nover traditional fine-tuning and state-of-the-art low-data techniques.\nRemarkably, with the smallest data available, our framework shows an\noutstanding relative accuracy increase of up to 45 % compared to standard\nResNet-50 and up to 27 % compared to the closest SOTA runner-up. We emphasise\nthat our approach is practically architecture-independent and adds zero extra\ncost at inference time. Additionally, we provide an extensive study on the\nimpact of every framework's component, highlighting the importance of each in\nachieving optimal performance. Source code and trained models are publicly\navailable at github.com/demidovd98/fgic_lowd.\n","authors":["Dmitry Demidov","Abduragim Shtanchaev","Mihail Mihaylov","Mohammad Almansoori"],"pdf_url":"https://arxiv.org/pdf/2406.19814v1.pdf","comment":"Main paper and Appendices"},{"id":"http://arxiv.org/abs/2406.19811v1","updated":"2024-06-28T10:39:36Z","published":"2024-06-28T10:39:36Z","title":"EgoGaussian: Dynamic Scene Understanding from Egocentric Video with 3D\n  Gaussian Splatting","summary":"  Human activities are inherently complex, and even simple household tasks\ninvolve numerous object interactions. To better understand these activities and\nbehaviors, it is crucial to model their dynamic interactions with the\nenvironment. The recent availability of affordable head-mounted cameras and\negocentric data offers a more accessible and efficient means to understand\ndynamic human-object interactions in 3D environments. However, most existing\nmethods for human activity modeling either focus on reconstructing 3D models of\nhand-object or human-scene interactions or on mapping 3D scenes, neglecting\ndynamic interactions with objects. The few existing solutions often require\ninputs from multiple sources, including multi-camera setups, depth-sensing\ncameras, or kinesthetic sensors. To this end, we introduce EgoGaussian, the\nfirst method capable of simultaneously reconstructing 3D scenes and dynamically\ntracking 3D object motion from RGB egocentric input alone. We leverage the\nuniquely discrete nature of Gaussian Splatting and segment dynamic interactions\nfrom the background. Our approach employs a clip-level online learning pipeline\nthat leverages the dynamic nature of human activities, allowing us to\nreconstruct the temporal evolution of the scene in chronological order and\ntrack rigid object motion. Additionally, our method automatically segments\nobject and background Gaussians, providing 3D representations for both static\nscenes and dynamic objects. EgoGaussian outperforms previous NeRF and Dynamic\nGaussian methods in challenging in-the-wild videos and we also qualitatively\ndemonstrate the high quality of the reconstructed models.\n","authors":["Daiwei Zhang","Gengyan Li","Jiajie Li","Mickaël Bressieux","Otmar Hilliges","Marc Pollefeys","Luc Van Gool","Xi Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19796v1","updated":"2024-06-28T10:05:58Z","published":"2024-06-28T10:05:58Z","title":"Comprehensive Generative Replay for Task-Incremental Segmentation with\n  Concurrent Appearance and Semantic Forgetting","summary":"  Generalist segmentation models are increasingly favored for diverse tasks\ninvolving various objects from different image sources. Task-Incremental\nLearning (TIL) offers a privacy-preserving training paradigm using tasks\narriving sequentially, instead of gathering them due to strict data sharing\npolicies. However, the task evolution can span a wide scope that involves\nshifts in both image appearance and segmentation semantics with intricate\ncorrelation, causing concurrent appearance and semantic forgetting. To solve\nthis issue, we propose a Comprehensive Generative Replay (CGR) framework that\nrestores appearance and semantic knowledge by synthesizing image-mask pairs to\nmimic past task data, which focuses on two aspects: modeling image-mask\ncorrespondence and promoting scalability for diverse tasks. Specifically, we\nintroduce a novel Bayesian Joint Diffusion (BJD) model for high-quality\nsynthesis of image-mask pairs with their correspondence explicitly preserved by\nconditional denoising. Furthermore, we develop a Task-Oriented Adapter (TOA)\nthat recalibrates prompt embeddings to modulate the diffusion model, making the\ndata synthesis compatible with different tasks. Experiments on incremental\ntasks (cardiac, fundus and prostate segmentation) show its clear advantage for\nalleviating concurrent appearance and semantic forgetting. Code is available at\nhttps://github.com/jingyzhang/CGR.\n","authors":["Wei Li","Jingyang Zhang","Pheng-Ann Heng","Lixu Gu"],"pdf_url":"https://arxiv.org/pdf/2406.19796v1.pdf","comment":"Accepted by MICCAI24"},{"id":"http://arxiv.org/abs/2404.09666v2","updated":"2024-06-28T09:25:25Z","published":"2024-04-15T10:57:16Z","title":"Deformable MRI Sequence Registration for AI-based Prostate Cancer\n  Diagnosis","summary":"  The PI-CAI (Prostate Imaging: Cancer AI) challenge led to expert-level\ndiagnostic algorithms for clinically significant prostate cancer detection. The\nalgorithms receive biparametric MRI scans as input, which consist of\nT2-weighted and diffusion-weighted scans. These scans can be misaligned due to\nmultiple factors in the scanning process. Image registration can alleviate this\nissue by predicting the deformation between the sequences. We investigate the\neffect of image registration on the diagnostic performance of AI-based prostate\ncancer diagnosis. First, the image registration algorithm, developed in\nMeVisLab, is analyzed using a dataset with paired lesion annotations. Second,\nthe effect on diagnosis is evaluated by comparing case-level cancer diagnosis\nperformance between using the original dataset, rigidly aligned\ndiffusion-weighted scans, or deformably aligned diffusion-weighted scans. Rigid\nregistration showed no improvement. Deformable registration demonstrated a\nsubstantial improvement in lesion overlap (+10% median Dice score) and a\npositive yet non-significant improvement in diagnostic performance (+0.3%\nAUROC, p=0.18). Our investigation shows that a substantial improvement in\nlesion alignment does not directly lead to a significant improvement in\ndiagnostic performance. Qualitative analysis indicated that jointly developing\nimage registration methods and diagnostic AI algorithms could enhance\ndiagnostic accuracy and patient outcomes.\n","authors":["Alessa Hering","Sarah de Boer","Anindo Saha","Jasper J. Twilt","Mattias P. Heinrich","Derya Yakar","Maarten de Rooij","Henkjan Huisman","Joeran S. Bosma"],"pdf_url":"https://arxiv.org/pdf/2404.09666v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15613v2","updated":"2024-06-28T09:22:38Z","published":"2024-05-24T14:58:51Z","title":"Automatic Data Curation for Self-Supervised Learning: A Clustering-Based\n  Approach","summary":"  Self-supervised features are the cornerstone of modern machine learning\nsystems. They are typically pre-trained on data collections whose construction\nand curation typically require extensive human effort. This manual process has\nsome limitations similar to those encountered in supervised learning, e.g., the\ncrowd-sourced selection of data is costly and time-consuming, preventing\nscaling the dataset size. In this work, we consider the problem of automatic\ncuration of high-quality datasets for self-supervised pre-training. We posit\nthat such datasets should be large, diverse and balanced, and propose a\nclustering-based approach for building ones satisfying all these criteria. Our\nmethod involves successive and hierarchical applications of $k$-means on a\nlarge and diverse data repository to obtain clusters that distribute uniformly\namong data concepts, followed by a hierarchical, balanced sampling step from\nthese clusters. Extensive experiments on three different data domains including\nweb-based images, satellite images and text show that features trained on our\nautomatically curated datasets outperform those trained on uncurated data while\nbeing on par or better than ones trained on manually curated data. Code is\navailable at https://github.com/facebookresearch/ssl-data-curation.\n","authors":["Huy V. Vo","Vasil Khalidov","Timothée Darcet","Théo Moutakanni","Nikita Smetanin","Marc Szafraniec","Hugo Touvron","Camille Couprie","Maxime Oquab","Armand Joulin","Hervé Jégou","Patrick Labatut","Piotr Bojanowski"],"pdf_url":"https://arxiv.org/pdf/2405.15613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19336v2","updated":"2024-06-28T09:20:01Z","published":"2024-06-27T17:10:10Z","title":"LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver\n  with a Few Partial Ultrasound Scans","summary":"  3D reconstruction of the liver for volumetry is important for qualitative\nanalysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,\nalthough advantageous due to less acquisition time and safety, is challenging\ndue to the inherent noisiness in US scans, blurry boundaries, and partial liver\nvisibility. We address these challenges by using the segmentation masks of a\nfew incomplete sagittal-plane US scans of the liver in conjunction with a\nstatistical shape model (SSM) built using a set of CT scans of the liver. We\ncompute the shape parameters needed to warp this canonical SSM to fit the US\nscans through a parametric regression network. The resulting 3D liver\nreconstruction is accurate and leads to automatic liver volume calculation. We\nevaluate the accuracy of the estimated liver volumes with respect to CT\nsegmentation volumes using RMSE. Our volume computation is statistically much\ncloser to the volume estimated using CT scans than the volume computed using\nChilds' method by radiologists: p-value of 0.094 (>0.05) says that there is no\nsignificant difference between CT segmentation volumes and ours in contrast to\nChilds' method. We validate our method using investigations (ablation studies)\non the US image resolution, the number of CT scans used for SSM, the number of\nprincipal components, and the number of input US scans. To the best of our\nknowledge, this is the first automatic liver volumetry system using a few\nincomplete US scans given a set of CT scans of livers for SSM.\n","authors":["Kaushalya Sivayogaraj","Sahan T. Guruge","Udari Liyanage","Jeevani Udupihille","Saroj Jayasinghe","Gerard Fernando","Ranga Rodrigo","M. Rukshani Liyanaarachchi"],"pdf_url":"https://arxiv.org/pdf/2406.19336v2.pdf","comment":"10 pages, Accepted to MICCAI 2024"},{"id":"http://arxiv.org/abs/2304.10839v4","updated":"2024-06-28T09:01:03Z","published":"2023-04-21T09:30:22Z","title":"Cross-domain Denoising for Low-dose Multi-frame Spiral Computed\n  Tomography","summary":"  Computed tomography (CT) has been used worldwide as a non-invasive test to\nassist in diagnosis. However, the ionizing nature of X-ray exposure raises\nconcerns about potential health risks such as cancer. The desire for lower\nradiation doses has driven researchers to improve reconstruction quality.\nAlthough previous studies on low-dose computed tomography (LDCT) denoising have\ndemonstrated the effectiveness of learning-based methods, most were developed\non the simulated data. However, the real-world scenario differs significantly\nfrom the simulation domain, especially when using the multi-slice spiral\nscanner geometry. This paper proposes a two-stage method for the commercially\navailable multi-slice spiral CT scanners that better exploits the complete\nreconstruction pipeline for LDCT denoising across different domains. Our\napproach makes good use of the high redundancy of multi-slice projections and\nthe volumetric reconstructions while leveraging the over-smoothing problem in\nconventional cascaded frameworks caused by aggressive denoising. The dedicated\ndesign also provides a more explicit interpretation of the data flow. Extensive\nexperiments on various datasets showed that the proposed method could remove up\nto 70\\% of noise without compromised spatial resolution, and subjective\nevaluations by two experienced radiologists further supported its superior\nperformance against state-of-the-art methods in clinical practice.\n","authors":["Yucheng Lu","Zhixin Xu","Moon Hyung Choi","Jimin Kim","Seung-Won Jung"],"pdf_url":"https://arxiv.org/pdf/2304.10839v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19756v1","updated":"2024-06-28T08:54:44Z","published":"2024-06-28T08:54:44Z","title":"Structure-aware World Model for Probe Guidance via Large-scale\n  Self-supervised Pre-train","summary":"  The complex structure of the heart leads to significant challenges in\nechocardiography, especially in acquisition cardiac ultrasound images.\nSuccessful echocardiography requires a thorough understanding of the structures\non the two-dimensional plane and the spatial relationships between planes in\nthree-dimensional space. In this paper, we innovatively propose a large-scale\nself-supervised pre-training method to acquire a cardiac structure-aware world\nmodel. The core innovation lies in constructing a self-supervised task that\nrequires structural inference by predicting masked structures on a 2D plane and\nimagining another plane based on pose transformation in 3D space. To support\nlarge-scale pre-training, we collected over 1.36 million echocardiograms from\nten standard views, along with their 3D spatial poses. In the downstream probe\nguidance task, we demonstrate that our pre-trained model consistently reduces\nguidance errors across the ten most common standard views on the test set with\n0.29 million samples from 74 routine clinical scans, indicating that\nstructure-aware pre-training benefits the scanning.\n","authors":["Haojun Jiang","Meng Li","Zhenguo Sun","Ning Jia","Yu Sun","Shaqi Luo","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.19756v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.19749v1","updated":"2024-06-28T08:48:14Z","published":"2024-06-28T08:48:14Z","title":"SPIRONet: Spatial-Frequency Learning and Topological Channel Interaction\n  Network for Vessel Segmentation","summary":"  Automatic vessel segmentation is paramount for developing next-generation\ninterventional navigation systems. However, current approaches suffer from\nsuboptimal segmentation performances due to significant challenges in\nintraoperative images (i.e., low signal-to-noise ratio, small or slender\nvessels, and strong interference). In this paper, a novel spatial-frequency\nlearning and topological channel interaction network (SPIRONet) is proposed to\naddress the above issues. Specifically, dual encoders are utilized to\ncomprehensively capture local spatial and global frequency vessel features.\nThen, a cross-attention fusion module is introduced to effectively fuse spatial\nand frequency features, thereby enhancing feature discriminability.\nFurthermore, a topological channel interaction module is designed to filter out\ntask-irrelevant responses based on graph neural networks. Extensive\nexperimental results on several challenging datasets (CADSA, CAXF, DCA1, and\nXCAD) demonstrate state-of-the-art performances of our method. Moreover, the\ninference speed of SPIRONet is 21 FPS with a 512x512 input size, surpassing\nclinical real-time requirements (6~12FPS). These promising outcomes indicate\nSPIRONet's potential for integration into vascular interventional navigation\nsystems. Code is available at https://github.com/Dxhuang-CASIA/SPIRONet.\n","authors":["De-Xing Huang","Xiao-Hu Zhou","Xiao-Liang Xie","Shi-Qi Liu","Shuang-Yi Wang","Zhen-Qiu Feng","Mei-Jiang Gui","Hao Li","Tian-Yu Xiang","Bo-Xian Yao","Zeng-Guang Hou"],"pdf_url":"https://arxiv.org/pdf/2406.19749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19736v1","updated":"2024-06-28T08:25:27Z","published":"2024-06-28T08:25:27Z","title":"MM-Instruct: Generated Visual Instructions for Large Multimodal Model\n  Alignment","summary":"  This paper introduces MM-Instruct, a large-scale dataset of diverse and\nhigh-quality visual instruction data designed to enhance the\ninstruction-following capabilities of large multimodal models (LMMs). While\nexisting visual instruction datasets often focus on question-answering, they\nstruggle to generalize to broader application scenarios such as creative\nwriting, summarization, or image analysis. To address these limitations, we\npropose a novel approach to constructing MM-Instruct that leverages the strong\ninstruction-following capabilities of existing LLMs to generate novel visual\ninstruction data from large-scale but conventional image captioning datasets.\nMM-Instruct first leverages ChatGPT to automatically generate diverse\ninstructions from a small set of seed instructions through augmenting and\nsummarization. It then matches these instructions with images and uses an\nopen-sourced large language model (LLM) to generate coherent answers to the\ninstruction-image pairs. The LLM is grounded by the detailed text descriptions\nof images in the whole answer generation process to guarantee the alignment of\nthe instruction data. Moreover, we introduce a benchmark based on the generated\ninstruction data to evaluate the instruction-following capabilities of existing\nLMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5\nmodel on the generated data, denoted as LLaVA-Instruct, which exhibits\nsignificant improvements in instruction-following capabilities compared to\nLLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models\nare available at https://github.com/jihaonew/MM-Instruct.\n","authors":["Jihao Liu","Xin Huang","Jinliang Zheng","Boxiao Liu","Jia Wang","Osamu Yoshie","Yu Liu","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.19736v1.pdf","comment":"Dataset and models are available at\n  https://github.com/jihaonew/MM-Instruct"},{"id":"http://arxiv.org/abs/2406.19726v1","updated":"2024-06-28T08:16:54Z","published":"2024-06-28T08:16:54Z","title":"EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans","summary":"  Monocular Human Pose Estimation (HPE) aims at determining the 3D positions of\nhuman joints from a single 2D image captured by a camera. However, a single 2D\npoint in the image may correspond to multiple points in 3D space. Typically,\nthe uniqueness of the 2D-3D relationship is approximated using an orthographic\nor weak-perspective camera model. In this study, instead of relying on\napproximations, we advocate for utilizing the full perspective camera model.\nThis involves estimating camera parameters and establishing a precise,\nunambiguous 2D-3D relationship. To do so, we introduce the EPOCH framework,\ncomprising two main components: the pose lifter network (LiftNet) and the pose\nregressor network (RegNet). LiftNet utilizes the full perspective camera model\nto precisely estimate the 3D pose in an unsupervised manner. It takes a 2D pose\nand camera parameters as inputs and produces the corresponding 3D pose\nestimation. These inputs are obtained from RegNet, which starts from a single\nimage and provides estimates for the 2D pose and camera parameters. RegNet\nutilizes only 2D pose data as weak supervision. Internally, RegNet predicts a\n3D pose, which is then projected to 2D using the estimated camera parameters.\nThis process enables RegNet to establish the unambiguous 2D-3D relationship.\nOur experiments show that modeling the lifting as an unsupervised task with a\ncamera in-the-loop results in better generalization to unseen data. We obtain\nstate-of-the-art results for the 3D HPE on the Human3.6M and MPI-INF-3DHP\ndatasets. Our code is available at: [Github link upon acceptance, see\nsupplementary materials].\n","authors":["Nicola Garau","Giulia Martinelli","Niccolò Bisagno","Denis Tomè","Carsten Stoll"],"pdf_url":"https://arxiv.org/pdf/2406.19726v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2309.01469v2","updated":"2024-06-28T08:13:48Z","published":"2023-09-04T09:26:04Z","title":"Defect Detection in Synthetic Fibre Ropes using Detectron2 Framework","summary":"  Fibre ropes with the latest technology have emerged as an appealing\nalternative to steel ropes for offshore industries due to their lightweight and\nhigh tensile strength. At the same time, frequent inspection of these ropes is\nessential to ensure the proper functioning and safety of the entire system. The\ndevelopment of deep learning (DL) models in condition monitoring (CM)\napplications offers a simpler and more effective approach for defect detection\nin synthetic fibre ropes (SFRs). The present paper investigates the performance\nof Detectron2, a state-of-the-art library for defect detection and instance\nsegmentation. Detectron2 with Mask R-CNN architecture is used for segmenting\ndefects in SFRs. Mask R-CNN with various backbone configurations has been\ntrained and tested on an experimentally obtained dataset comprising 1,803\nhigh-dimensional images containing seven damage classes (placking high,\nplacking medium, placking low, compression, core out, chafing, and normal\nrespectively) for SFRs. By leveraging the capabilities of Detectron2, this\nstudy aims to develop an automated and efficient method for detecting defects\nin SFRs, enhancing the inspection process, and ensuring the safety of the fibre\nropes.\n","authors":["Anju Rani","Daniel O. Arroyo","Petar Durdevic"],"pdf_url":"https://arxiv.org/pdf/2309.01469v2.pdf","comment":"12 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.18584v2","updated":"2024-06-28T07:34:25Z","published":"2024-06-06T06:22:06Z","title":"Assessment of Sentinel-2 spatial and temporal coverage based on the\n  scene classification layer","summary":"  Since the launch of the Sentinel-2 (S2) satellites, many ML models have used\nthe data for diverse applications. The scene classification layer (SCL) inside\nthe S2 product provides rich information for training, such as filtering images\nwith high cloud coverage. However, there is more potential in this. We propose\na technique to assess the clean optical coverage of a region, expressed by a\nSITS and calculated with the S2-based SCL data. With a manual threshold and\nspecific labels in the SCL, the proposed technique assigns a percentage of\nspatial and temporal coverage across the time series and a high/low assessment.\nBy evaluating the AI4EO challenge for Enhanced Agriculture, we show that the\nassessment is correlated to the predictive results of ML models. The\nclassification results in a region with low spatial and temporal coverage is\nworse than in a region with high coverage. Finally, we applied the technique\nacross all continents of the global dataset LandCoverNet.\n","authors":["Cristhian Sanchez","Francisco Mena","Marcela Charfuelan","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2406.18584v2.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2024"},{"id":"http://arxiv.org/abs/2406.19703v1","updated":"2024-06-28T07:28:50Z","published":"2024-06-28T07:28:50Z","title":"Vision Transformer with Key-select Routing Attention for Single Image\n  Dehazing","summary":"  We present Ksformer, utilizing Multi-scale Key-select Routing Attention\n(MKRA) for intelligent selection of key areas through multi-channel,\nmulti-scale windows with a top-k operator, and Lightweight Frequency Processing\nModule (LFPM) to enhance high-frequency features, outperforming other dehazing\nmethods in tests.\n","authors":["Lihan Tong","Weijia Li","Qingxia Yang","Liyuan Chen","Peng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19703v1.pdf","comment":"5 pages,4 figures,IEICE Trans. Information and Systems"},{"id":"http://arxiv.org/abs/2402.11622v2","updated":"2024-06-28T07:20:22Z","published":"2024-02-18T15:28:39Z","title":"Logical Closed Loop: Uncovering Object Hallucinations in Large\n  Vision-Language Models","summary":"  Object hallucination has been an Achilles' heel which hinders the broader\napplications of large vision-language models (LVLMs). Object hallucination\nrefers to the phenomenon that the LVLMs claim non-existent objects in the\nimage. To mitigate the object hallucinations, instruction tuning and external\nmodel-based detection methods have been proposed, which either require\nlarge-scare computational resources or depend on the detection result of\nexternal models. However, there remains an under-explored field to utilize the\nLVLM itself to alleviate object hallucinations. In this work, we adopt the\nintuition that the LVLM tends to respond logically consistently for existent\nobjects but inconsistently for hallucinated objects. Therefore, we propose a\nLogical Closed Loop-based framework for Object Hallucination Detection and\nMitigation, namely LogicCheckGPT. In specific, we devise logical consistency\nprobing to raise questions with logical correlations, inquiring about\nattributes from objects and vice versa. Whether their responses can form a\nlogical closed loop serves as an indicator of object hallucination. As a\nplug-and-play method, it can be seamlessly applied to all existing LVLMs.\nComprehensive experiments conducted on three benchmarks across four LVLMs have\ndemonstrated significant improvements brought by our method, indicating its\neffectiveness and generality.\n","authors":["Junfei Wu","Qiang Liu","Ding Wang","Jinghao Zhang","Shu Wu","Liang Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2402.11622v2.pdf","comment":"Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2406.19693v1","updated":"2024-06-28T07:09:06Z","published":"2024-06-28T07:09:06Z","title":"MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?","summary":"  It is fundamentally challenging for robots to serve as useful assistants in\nhuman environments because this requires addressing a spectrum of sub-problems\nacross robotics, including perception, language understanding, reasoning, and\nplanning. The recent advancements in Multimodal Large Language Models (MLLMs)\nhave demonstrated their exceptional abilities in solving complex mathematical\nproblems, mastering commonsense and abstract reasoning. This has led to the\nrecent utilization of MLLMs as the brain in robotic systems, enabling these\nmodels to conduct high-level planning prior to triggering low-level control\nactions for task execution. However, it remains uncertain whether existing\nMLLMs are reliable in serving the brain role of robots. In this study, we\nintroduce the first benchmark for evaluating Multimodal LLM for Robotic (MMRo)\nbenchmark, which tests the capability of MLLMs for robot applications.\nSpecifically, we identify four essential capabilities perception, task\nplanning, visual reasoning, and safety measurement that MLLMs must possess to\nqualify as the robot's central processing unit. We have developed several\nscenarios for each capability, resulting in a total of 14 metrics for\nevaluation. We present experimental results for various MLLMs, including both\ncommercial and open-source models, to assess the performance of existing\nsystems. Our findings indicate that no single model excels in all areas,\nsuggesting that current MLLMs are not yet trustworthy enough to serve as the\ncognitive core for robots. Our data can be found in\nhttps://mm-robobench.github.io/.\n","authors":["Jinming Li","Yichen Zhu","Zhiyuan Xu","Jindong Gu","Minjie Zhu","Xin Liu","Ning Liu","Yaxin Peng","Feifei Feng","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.19693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19690v1","updated":"2024-06-28T07:06:02Z","published":"2024-06-28T07:06:02Z","title":"Deep Fusion Model for Brain Tumor Classification Using Fine-Grained\n  Gradient Preservation","summary":"  Brain tumors are one of the most common diseases that lead to early death if\nnot diagnosed at an early stage. Traditional diagnostic approaches are\nextremely time-consuming and prone to errors. In this context, computer\nvision-based approaches have emerged as an effective tool for accurate brain\ntumor classification. While some of the existing solutions demonstrate\nnoteworthy accuracy, the models become infeasible to deploy in areas where\ncomputational resources are limited. This research addresses the need for\naccurate and fast classification of brain tumors with a priority of deploying\nthe model in technologically underdeveloped regions. The research presents a\nnovel architecture for precise brain tumor classification fusing pretrained\nResNet152V2 and modified VGG16 models. The proposed architecture undergoes a\ndiligent fine-tuning process that ensures fine gradients are preserved in deep\nneural networks, which are essential for effective brain tumor classification.\nThe proposed solution incorporates various image processing techniques to\nimprove image quality and achieves an astounding accuracy of 98.36% and 98.04%\nin Figshare and Kaggle datasets respectively. This architecture stands out for\nhaving a streamlined profile, with only 2.8 million trainable parameters. We\nhave leveraged 8-bit quantization to produce a model of size 73.881 MB,\nsignificantly reducing it from the previous size of 289.45 MB, ensuring smooth\ndeployment in edge devices even in resource-constrained areas. Additionally,\nthe use of Grad-CAM improves the interpretability of the model, offering\ninsightful information regarding its decision-making process. Owing to its high\ndiscriminative ability, this model can be a reliable option for accurate brain\ntumor classification.\n","authors":["Niful Islam","Mohaiminul Islam Bhuiyan","Jarin Tasnim Raya","Nur Shazwani Kamarudin","Khan Md Hasib","M. F. Mridha","Dewan Md. Farid"],"pdf_url":"https://arxiv.org/pdf/2406.19690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16462v2","updated":"2024-06-28T07:04:21Z","published":"2023-11-28T03:45:29Z","title":"Viewport Prediction for Volumetric Video Streaming by Exploring Video\n  Saliency and Trajectory Information","summary":"  Volumetric video, also known as hologram video, is a novel medium that\nportrays natural content in Virtual Reality (VR), Augmented Reality (AR), and\nMixed Reality (MR). It is expected to be the next-gen video technology and a\nprevalent use case for 5G and beyond wireless communication. Considering that\neach user typically only watches a section of the volumetric video, known as\nthe viewport, it is essential to have precise viewport prediction for optimal\nperformance. However, research on this topic is still in its infancy. In the\nend, this paper presents and proposes a novel approach, named Saliency and\nTrajectory Viewport Prediction (STVP), which aims to improve the precision of\nviewport prediction in volumetric video streaming. The STVP extensively\nutilizes video saliency information and viewport trajectory. To our knowledge,\nthis is the first comprehensive study of viewport prediction in volumetric\nvideo streaming. In particular, we introduce a novel sampling method, Uniform\nRandom Sampling (URS), to reduce computational complexity while still\npreserving video features in an efficient manner. Then we present a saliency\ndetection technique that incorporates both spatial and temporal information for\ndetecting static, dynamic geometric, and color salient regions. Finally, we\nintelligently fuse saliency and trajectory information to achieve more accurate\nviewport prediction. We conduct extensive simulations to evaluate the\neffectiveness of our proposed viewport prediction methods using\nstate-of-the-art volumetric video sequences. The experimental results show the\nsuperiority of the proposed method over existing schemes. The dataset and\nsource code will be publicly accessible after acceptance.\n","authors":["Jie Li","Zhixin Li","Zhi Liu","Pengyuan Zhou","Richang Hong","Qiyue Li","Han Hu"],"pdf_url":"https://arxiv.org/pdf/2311.16462v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19686v1","updated":"2024-06-28T06:51:38Z","published":"2024-06-28T06:51:38Z","title":"Enhancing Radiological Diagnosis: A Collaborative Approach Integrating\n  AI and Human Expertise for Visual Miss Correction","summary":"  Human-AI collaboration to identify and correct perceptual errors in chest\nradiographs has not been previously explored. This study aimed to develop a\ncollaborative AI system, CoRaX, which integrates eye gaze data and radiology\nreports to enhance diagnostic accuracy in chest radiology by pinpointing\nperceptual errors and refining the decision-making process. Using public\ndatasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX,\nemploying a large multimodal model to analyze image embeddings, eye gaze data,\nand radiology reports. The system's effectiveness was evaluated based on its\nreferral-making process, the quality of referrals, and performance in\ncollaborative diagnostic settings. CoRaX was tested on a simulated error\ndataset of 271 samples with 28% (93 of 332) missed abnormalities. The system\ncorrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved.\nThe Referral-Usefulness score, indicating the accuracy of predicted regions for\nall true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score,\nreflecting the diagnostic accuracy of CoRaX's interactions with radiologists,\nshowed that 84% (237 of 280) of these interactions had a score above 0.40. In\nconclusion, CoRaX efficiently collaborates with radiologists to address\nperceptual errors across various abnormalities, with potential applications in\nthe education and training of novice radiologists.\n","authors":["Akash Awasthi","Ngan Le","Zhigang Deng","Carol C. Wu","Hien Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2406.19686v1.pdf","comment":"Under Review in Journal"},{"id":"http://arxiv.org/abs/2406.19070v2","updated":"2024-06-28T06:47:10Z","published":"2024-06-27T10:40:35Z","title":"FAGhead: Fully Animate Gaussian Head from Monocular Videos","summary":"  High-fidelity reconstruction of 3D human avatars has a wild application in\nvisual reality. In this paper, we introduce FAGhead, a method that enables\nfully controllable human portraits from monocular videos. We explicit the\ntraditional 3D morphable meshes (3DMM) and optimize the neutral 3D Gaussians to\nreconstruct with complex expressions. Furthermore, we employ a novel\nPoint-based Learnable Representation Field (PLRF) with learnable Gaussian point\npositions to enhance reconstruction performance. Meanwhile, to effectively\nmanage the edges of avatars, we introduced the alpha rendering to supervise the\nalpha value of each pixel. Extensive experimental results on the open-source\ndatasets and our capturing datasets demonstrate that our approach is able to\ngenerate high-fidelity 3D head avatars and fully control the expression and\npose of the virtual avatars, which is outperforming than existing works.\n","authors":["Yixin Xuan","Xinyang Li","Gongxin Yao","Shiwei Zhou","Donghui Sun","Xiaoxin Chen","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2406.19070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18146v2","updated":"2024-06-28T06:43:39Z","published":"2024-06-26T07:56:17Z","title":"A Refer-and-Ground Multimodal Large Language Model for Biomedicine","summary":"  With the rapid development of multimodal large language models (MLLMs),\nespecially their capabilities in visual chat through refer and ground\nfunctionalities, their significance is increasingly recognized. However, the\nbiomedical field currently exhibits a substantial gap in this area, primarily\ndue to the absence of a dedicated refer and ground dataset for biomedical\nimages. To address this challenge, we devised the Med-GRIT-270k dataset. It\ncomprises 270k question-and-answer pairs and spans eight distinct medical\nimaging modalities. Most importantly, it is the first dedicated to the\nbiomedical domain and integrating refer and ground conversations. The key idea\nis to sample large-scale biomedical image-mask pairs from medical segmentation\ndatasets and generate instruction datasets from text using chatGPT.\nAdditionally, we introduce a Refer-and-Ground Multimodal Large Language Model\nfor Biomedicine (BiRD) by using this dataset and multi-task instruction\nlearning. Extensive experiments have corroborated the efficacy of the\nMed-GRIT-270k dataset and the multi-modal, fine-grained interactive\ncapabilities of the BiRD model. This holds significant reference value for the\nexploration and development of intelligent biomedical assistants.\n","authors":["Xiaoshuang Huang","Haifeng Huang","Lingdong Shen","Yehui Yang","Fangxin Shang","Junwei Liu","Jia Liu"],"pdf_url":"https://arxiv.org/pdf/2406.18146v2.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2406.19680v1","updated":"2024-06-28T06:40:53Z","published":"2024-06-28T06:40:53Z","title":"MimicMotion: High-Quality Human Motion Video Generation with\n  Confidence-aware Pose Guidance","summary":"  In recent years, generative artificial intelligence has achieved significant\nadvancements in the field of image generation, spawning a variety of\napplications. However, video generation still faces considerable challenges in\nvarious aspects, such as controllability, video length, and richness of\ndetails, which hinder the application and popularization of this technology. In\nthis work, we propose a controllable video generation framework, dubbed\nMimicMotion, which can generate high-quality videos of arbitrary length\nmimicking specific motion guidance. Compared with previous methods, our\napproach has several highlights. Firstly, we introduce confidence-aware pose\nguidance that ensures high frame quality and temporal smoothness. Secondly, we\nintroduce regional loss amplification based on pose confidence, which\nsignificantly reduces image distortion. Lastly, for generating long and smooth\nvideos, we propose a progressive latent fusion strategy. By this means, we can\nproduce videos of arbitrary length with acceptable resource consumption. With\nextensive experiments and user studies, MimicMotion demonstrates significant\nimprovements over previous approaches in various aspects. Detailed results and\ncomparisons are available on our project page:\nhttps://tencent.github.io/MimicMotion .\n","authors":["Yuang Zhang","Jiaxi Gu","Li-Wen Wang","Han Wang","Junqi Cheng","Yuefeng Zhu","Fangyuan Zou"],"pdf_url":"https://arxiv.org/pdf/2406.19680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19675v1","updated":"2024-06-28T06:25:21Z","published":"2024-06-28T06:25:21Z","title":"Deep Learning-based Depth Estimation Methods from Monocular Image and\n  Videos: A Comprehensive Survey","summary":"  Estimating depth from single RGB images and videos is of widespread interest\ndue to its applications in many areas, including autonomous driving, 3D\nreconstruction, digital entertainment, and robotics. More than 500 deep\nlearning-based papers have been published in the past 10 years, which indicates\nthe growing interest in the task. This paper presents a comprehensive survey of\nthe existing deep learning-based methods, the challenges they address, and how\nthey have evolved in their architecture and supervision methods. It provides a\ntaxonomy for classifying the current work based on their input and output\nmodalities, network architectures, and learning methods. It also discusses the\nmajor milestones in the history of monocular depth estimation, and different\npipelines, datasets, and evaluation metrics used in existing methods.\n","authors":["Uchitha Rajapaksha","Ferdous Sohel","Hamid Laga","Dean Diepeveen","Mohammed Bennamoun"],"pdf_url":"https://arxiv.org/pdf/2406.19675v1.pdf","comment":"46 pages, 10 figures, The paper has been accepted for publication in\n  ACM Computing Surveys 2024"},{"id":"http://arxiv.org/abs/2405.05164v2","updated":"2024-06-28T06:11:11Z","published":"2024-05-08T15:54:57Z","title":"ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with\n  Probability Map Guided Multi-Format Feature Fusion","summary":"  Millimeter wave (mmWave) radar is a non-intrusive privacy and relatively\nconvenient and inexpensive device, which has been demonstrated to be applicable\nin place of RGB cameras in human indoor pose estimation tasks. However, mmWave\nradar relies on the collection of reflected signals from the target, and the\nradar signals containing information is difficult to be fully applied. This has\nbeen a long-standing hindrance to the improvement of pose estimation accuracy.\nTo address this major challenge, this paper introduces a probability map guided\nmulti-format feature fusion model, ProbRadarM3F. This is a novel radar feature\nextraction framework using a traditional FFT method in parallel with a\nprobability map based positional encoding method. ProbRadarM3F fuses the\ntraditional heatmap features and the positional features, then effectively\nachieves the estimation of 14 keypoints of the human body. Experimental\nevaluation on the HuPR dataset proves the effectiveness of the model proposed\nin this paper, outperforming other methods experimented on this dataset with an\nAP of 69.9 %. The emphasis of our study is focusing on the position information\nthat is not exploited before in radar singal. This provides direction to\ninvestigate other potential non-redundant information from mmWave rader.\n","authors":["Bing Zhu","Zixin He","Weiyi Xiong","Guanhua Ding","Jianan Liu","Tao Huang","Wei Chen","Wei Xiang"],"pdf_url":"https://arxiv.org/pdf/2405.05164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19672v1","updated":"2024-06-28T06:06:01Z","published":"2024-06-28T06:06:01Z","title":"Beyond First-Order: A Multi-Scale Approach to Finger Knuckle Print\n  Biometrics","summary":"  Recently, finger knuckle prints (FKPs) have gained attention due to their\nrich textural patterns, positioning them as a promising biometric for identity\nrecognition. Prior FKP recognition methods predominantly leverage first-order\nfeature descriptors, which capture intricate texture details but fail to\naccount for structural information. Emerging research, however, indicates that\nsecond-order textures, which describe the curves and arcs of the textures,\nencompass this overlooked structural information. This paper introduces a novel\nFKP recognition approach, the Dual-Order Texture Competition Network (DOTCNet),\ndesigned to capture texture information in FKP images comprehensively. DOTCNet\nincorporates three dual-order texture competitive modules (DTCMs), each\ntargeting textures at different scales. Each DTCM employs a learnable texture\ndescriptor, specifically a learnable Gabor filter (LGF), to extract texture\nfeatures. By leveraging LGFs, the network extracts first and second order\ntextures to describe fine textures and structural features thoroughly.\nFurthermore, an attention mechanism enhances relevant features in the\nfirst-order features, thereby highlighting significant texture details. For\nsecond-order features, a competitive mechanism emphasizes structural\ninformation while reducing noise from higher-order features. Extensive\nexperimental results reveal that DOTCNet significantly outperforms several\nstandard algorithms on the publicly available PolyU-FKP dataset.\n","authors":["Chengrui Gao","Ziyuan Yang","Andrew Beng Jin Teoh","Min Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.19672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19364v2","updated":"2024-06-28T05:56:08Z","published":"2024-06-27T17:46:13Z","title":"SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text\n  Cues","summary":"  Weakly-supervised medical image segmentation is a challenging task that aims\nto reduce the annotation cost while keep the segmentation performance. In this\npaper, we present a novel framework, SimTxtSeg, that leverages simple text cues\nto generate high-quality pseudo-labels and study the cross-modal fusion in\ntraining segmentation models, simultaneously. Our contribution consists of two\nkey components: an effective Textual-to-Visual Cue Converter that produces\nvisual prompts from text prompts on medical images, and a text-guided\nsegmentation model with Text-Vision Hybrid Attention that fuses text and image\nfeatures. We evaluate our framework on two medical image segmentation tasks:\ncolonic polyp segmentation and MRI brain tumor segmentation, and achieve\nconsistent state-of-the-art performance.\n","authors":["Yuxin Xie","Tao Zhou","Yi Zhou","Geng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19364v2.pdf","comment":"accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.17051v2","updated":"2024-06-28T05:50:11Z","published":"2024-06-24T18:13:09Z","title":"Leveraging Knowledge Distillation for Lightweight Skin Cancer\n  Classification: Balancing Accuracy and Computational Efficiency","summary":"  Skin cancer is a major concern to public health, accounting for one-third of\nthe reported cancers. If not detected early, the cancer has the potential for\nsevere consequences. Recognizing the critical need for effective skin cancer\nclassification, we address the limitations of existing models, which are often\ntoo large to deploy in areas with limited computational resources. In response,\nwe present a knowledge distillation based approach for creating a lightweight\nyet high-performing classifier. The proposed solution involves fusing three\nmodels, namely ResNet152V2, ConvNeXtBase, and ViT Base, to create an effective\nteacher model. The teacher model is then employed to guide a lightweight\nstudent model of size 2.03 MB. This student model is further compressed to\n469.77 KB using 16-bit quantization, enabling smooth incorporation into edge\ndevices. With six-stage image preprocessing, data augmentation, and a rigorous\nablation study, the model achieves an impressive accuracy of 98.75% on the\nHAM10000 dataset and 98.94% on the Kaggle dataset in classifying benign and\nmalignant skin cancers. With its high accuracy and compact size, our model\nappears to be a potential choice for accurate skin cancer classification,\nparticularly in resource-constrained settings.\n","authors":["Niful Islam","Khan Md Hasib","Fahmida Akter Joti","Asif Karim","Sami Azam"],"pdf_url":"https://arxiv.org/pdf/2406.17051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19237v2","updated":"2024-06-28T05:43:46Z","published":"2024-06-27T15:01:48Z","title":"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with\n  Flowcharts","summary":"  Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.\n","authors":["Shubhankar Singh","Purvi Chaurasia","Yerram Varun","Pranshu Pandya","Vatsal Gupta","Vivek Gupta","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2406.19237v2.pdf","comment":"Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables"},{"id":"http://arxiv.org/abs/2406.18684v2","updated":"2024-06-28T05:43:41Z","published":"2024-06-26T18:42:22Z","title":"CSI4Free: GAN-Augmented mmWave CSI for Improved Pose Classification","summary":"  In recent years, Joint Communication and Sensing (JC&S), has demonstrated\nsignificant success, particularly in utilizing sub-6 GHz frequencies with\ncommercial-off-the-shelf (COTS) Wi-Fi devices for applications such as\nlocalization, gesture recognition, and pose classification. Deep learning and\nthe existence of large public datasets has been pivotal in achieving such\nresults. However, at mmWave frequencies (30-300 GHz), which has shown potential\nfor more accurate sensing performance, there is a noticeable lack of research\nin the domain of COTS Wi-Fi sensing. Challenges such as limited research\nhardware, the absence of large datasets, limited functionality in COTS\nhardware, and the complexities of data collection present obstacles to a\ncomprehensive exploration of this field. In this work, we aim to address these\nchallenges by developing a method that can generate synthetic mmWave channel\nstate information (CSI) samples. In particular, we use a generative adversarial\nnetwork (GAN) on an existing dataset, to generate 30,000 additional CSI\nsamples. The augmented samples exhibit a remarkable degree of consistency with\nthe original data, as indicated by the notably high GAN-train and GAN-test\nscores. Furthermore, we integrate the augmented samples in training a pose\nclassification model. We observe that the augmented samples complement the real\ndata and improve the generalization of the classification model.\n","authors":["Nabeel Nisar Bhat","Rafael Berkvens","Jeroen Famaey"],"pdf_url":"https://arxiv.org/pdf/2406.18684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19668v1","updated":"2024-06-28T05:38:32Z","published":"2024-06-28T05:38:32Z","title":"PopAlign: Population-Level Alignment for Fair Text-to-Image Generation","summary":"  Text-to-image (T2I) models achieve high-fidelity generation through extensive\ntraining on large datasets. However, these models may unintentionally pick up\nundesirable biases of their training data, such as over-representation of\nparticular identities in gender or ethnicity neutral prompts. Existing\nalignment methods such as Reinforcement Learning from Human Feedback (RLHF) and\nDirect Preference Optimization (DPO) fail to address this problem effectively\nbecause they operate on pairwise preferences consisting of individual samples,\nwhile the aforementioned biases can only be measured at a population level. For\nexample, a single sample for the prompt \"doctor\" could be male or female, but a\nmodel generating predominantly male doctors even with repeated sampling\nreflects a gender bias. To address this limitation, we introduce PopAlign, a\nnovel approach for population-level preference optimization, while standard\noptimization would prefer entire sets of samples over others. We further derive\na stochastic lower bound that directly optimizes for individual samples from\npreferred populations over others for scalable training. Using human evaluation\nand standard image quality and bias metrics, we show that PopAlign\nsignificantly mitigates the bias of pretrained T2I models while largely\npreserving the generation quality. Code is available at\nhttps://github.com/jacklishufan/PopAlignSDXL.\n","authors":["Shufan Li","Harkanwar Singh","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2406.19668v1.pdf","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.19666v1","updated":"2024-06-28T05:25:57Z","published":"2024-06-28T05:25:57Z","title":"CSAKD: Knowledge Distillation with Cross Self-Attention for\n  Hyperspectral and Multispectral Image Fusion","summary":"  Hyperspectral imaging, capturing detailed spectral information for each\npixel, is pivotal in diverse scientific and industrial applications. Yet, the\nacquisition of high-resolution (HR) hyperspectral images (HSIs) often needs to\nbe addressed due to the hardware limitations of existing imaging systems. A\nprevalent workaround involves capturing both a high-resolution multispectral\nimage (HR-MSI) and a low-resolution (LR) HSI, subsequently fusing them to yield\nthe desired HR-HSI. Although deep learning-based methods have shown promising\nin HR-MSI/LR-HSI fusion and LR-HSI super-resolution (SR), their substantial\nmodel complexities hinder deployment on resource-constrained imaging devices.\nThis paper introduces a novel knowledge distillation (KD) framework for\nHR-MSI/LR-HSI fusion to achieve SR of LR-HSI. Our KD framework integrates the\nproposed Cross-Layer Residual Aggregation (CLRA) block to enhance efficiency\nfor constructing Dual Two-Streamed (DTS) network structure, designed to extract\njoint and distinct features from LR-HSI and HR-MSI simultaneously. To fully\nexploit the spatial and spectral feature representations of LR-HSI and HR-MSI,\nwe propose a novel Cross Self-Attention (CSA) fusion module to adaptively fuse\nthose features to improve the spatial and spectral quality of the reconstructed\nHR-HSI. Finally, the proposed KD-based joint loss function is employed to\nco-train the teacher and student networks. Our experimental results demonstrate\nthat the student model not only achieves comparable or superior LR-HSI SR\nperformance but also significantly reduces the model-size and computational\nrequirements. This marks a substantial advancement over existing\nstate-of-the-art methods. The source code is available at\nhttps://github.com/ming053l/CSAKD.\n","authors":["Chih-Chung Hsu","Chih-Chien Ni","Chia-Ming Lee","Li-Wei Kang"],"pdf_url":"https://arxiv.org/pdf/2406.19666v1.pdf","comment":"Submitted to TIP 2024"},{"id":"http://arxiv.org/abs/2405.19769v2","updated":"2024-06-28T05:25:19Z","published":"2024-05-30T07:34:05Z","title":"All-In-One Medical Image Restoration via Task-Adaptive Routing","summary":"  Although single-task medical image restoration (MedIR) has witnessed\nremarkable success, the limited generalizability of these methods poses a\nsubstantial obstacle to wider application. In this paper, we focus on the task\nof all-in-one medical image restoration, aiming to address multiple distinct\nMedIR tasks with a single universal model. Nonetheless, due to significant\ndifferences between different MedIR tasks, training a universal model often\nencounters task interference issues, where different tasks with shared\nparameters may conflict with each other in the gradient update direction. This\ntask interference leads to deviation of the model update direction from the\noptimal path, thereby affecting the model's performance. To tackle this issue,\nwe propose a task-adaptive routing strategy, allowing conflicting tasks to\nselect different network paths in spatial and channel dimensions, thereby\nmitigating task interference. Experimental results demonstrate that our\nproposed \\textbf{A}ll-in-one \\textbf{M}edical \\textbf{I}mage\n\\textbf{R}estoration (\\textbf{AMIR}) network achieves state-of-the-art\nperformance in three MedIR tasks: MRI super-resolution, CT denoising, and PET\nsynthesis, both in single-task and all-in-one settings. The code and data will\nbe available at\n\\href{https://github.com/Yaziwel/All-In-One-Medical-Image-Restoration-via-Task-Adaptive-Routing.git}{https://github.com/Yaziwel/AMIR}.\n","authors":["Zhiwen Yang","Haowei Chen","Ziniu Qian","Yang Yi","Hui Zhang","Dan Zhao","Bingzheng Wei","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2405.19769v2.pdf","comment":"This article has been early accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.19665v1","updated":"2024-06-28T05:22:39Z","published":"2024-06-28T05:22:39Z","title":"PM-VIS+: High-Performance Video Instance Segmentation without Video\n  Annotation","summary":"  Video instance segmentation requires detecting, segmenting, and tracking\nobjects in videos, typically relying on costly video annotations. This paper\nintroduces a method that eliminates video annotations by utilizing image\ndatasets. The PM-VIS algorithm is adapted to handle both bounding box and\ninstance-level pixel annotations dynamically. We introduce ImageNet-bbox to\nsupplement missing categories in video datasets and propose the PM-VIS+\nalgorithm to adjust supervision based on annotation types. To enhance accuracy,\nwe use pseudo masks and semi-supervised optimization techniques on unannotated\nvideo data. This method achieves high video instance segmentation performance\nwithout manual video annotations, offering a cost-effective solution and new\nperspectives for video instance segmentation applications. The code will be\navailable in https://github.com/ldknight/PM-VIS-plus\n","authors":["Zhangjing Yang","Dun Liu","Xin Wang","Zhe Li","Barathwaj Anandan","Yi Wu"],"pdf_url":"https://arxiv.org/pdf/2406.19665v1.pdf","comment":"MIPR 2024"},{"id":"http://arxiv.org/abs/2406.18844v2","updated":"2024-06-28T05:21:13Z","published":"2024-06-27T02:31:03Z","title":"Revisiting Backdoor Attacks against Large Vision-Language Models","summary":"  Instruction tuning enhances large vision-language models (LVLMs) but raises\nsecurity risks through potential backdoor attacks due to their openness.\nPrevious backdoor studies focus on enclosed scenarios with consistent training\nand testing instructions, neglecting the practical domain gaps that could\naffect attack effectiveness. This paper empirically examines the\ngeneralizability of backdoor attacks during the instruction tuning of LVLMs for\nthe first time, revealing certain limitations of most backdoor strategies in\npractical scenarios. We quantitatively evaluate the generalizability of six\ntypical backdoor attacks on image caption benchmarks across multiple LVLMs,\nconsidering both visual and textual domain offsets. Our findings indicate that\nattack generalizability is positively correlated with the backdoor trigger's\nirrelevance to specific images/models and the preferential correlation of the\ntrigger pattern. Additionally, we modify existing backdoor attacks based on the\nabove key observations, demonstrating significant improvements in cross-domain\nscenario generalizability (+86% attack success rate). Notably, even without\naccess to the instruction datasets, a multimodal instruction set can be\nsuccessfully poisoned with a very low poisoning rate (0.2%), achieving an\nattack success rate of over 97%. This paper underscores that even simple\ntraditional backdoor strategies pose a serious threat to LVLMs, necessitating\nmore attention and in-depth research.\n","authors":["Siyuan Liang","Jiawei Liang","Tianyu Pang","Chao Du","Aishan Liu","Ee-Chien Chang","Xiaochun Cao"],"pdf_url":"https://arxiv.org/pdf/2406.18844v2.pdf","comment":"23 pages, 8 figures"},{"id":"http://arxiv.org/abs/2406.19655v1","updated":"2024-06-28T04:49:57Z","published":"2024-06-28T04:49:57Z","title":"Basketball-SORT: An Association Method for Complex Multi-object\n  Occlusion Problems in Basketball Multi-object Tracking","summary":"  Recent deep learning-based object detection approaches have led to\nsignificant progress in multi-object tracking (MOT) algorithms. The current MOT\nmethods mainly focus on pedestrian or vehicle scenes, but basketball sports\nscenes are usually accompanied by three or more object occlusion problems with\nsimilar appearances and high-intensity complex motions, which we call complex\nmulti-object occlusion (CMOO). Here, we propose an online and robust MOT\napproach, named Basketball-SORT, which focuses on the CMOO problems in\nbasketball videos. To overcome the CMOO problem, instead of using the\nintersection-over-union-based (IoU-based) approach, we use the trajectories of\nneighboring frames based on the projected positions of the players. Our method\ndesigns the basketball game restriction (BGR) and reacquiring Long-Lost IDs\n(RLLI) based on the characteristics of basketball scenes, and we also solve the\nocclusion problem based on the player trajectories and appearance features.\nExperimental results show that our method achieves a Higher Order Tracking\nAccuracy (HOTA) score of 63.48$\\%$ on the basketball fixed video dataset and\noutperforms other recent popular approaches. Overall, our approach solved the\nCMOO problem more effectively than recent MOT algorithms.\n","authors":["Qingrui Hu","Atom Scott","Calvin Yeung","Keisuke Fujii"],"pdf_url":"https://arxiv.org/pdf/2406.19655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19649v1","updated":"2024-06-28T04:38:12Z","published":"2024-06-28T04:38:12Z","title":"AstMatch: Adversarial Self-training Consistency Framework for\n  Semi-Supervised Medical Image Segmentation","summary":"  Semi-supervised learning (SSL) has shown considerable potential in medical\nimage segmentation, primarily leveraging consistency regularization and\npseudo-labeling. However, many SSL approaches only pay attention to low-level\nconsistency and overlook the significance of pseudo-label reliability.\nTherefore, in this work, we propose an adversarial self-training consistency\nframework (AstMatch). Firstly, we design an adversarial consistency\nregularization (ACR) approach to enhance knowledge transfer and strengthen\nprediction consistency under varying perturbation intensities. Second, we apply\na feature matching loss for adversarial training to incorporate high-level\nconsistency regularization. Additionally, we present the pyramid channel\nattention (PCA) and efficient channel and spatial attention (ECSA) modules to\nimprove the discriminator's performance. Finally, we propose an adaptive\nself-training (AST) approach to ensure the pseudo-labels' quality. The proposed\nAstMatch has been extensively evaluated with cutting-edge SSL methods on three\npublic-available datasets. The experimental results under different labeled\nratios indicate that AstMatch outperforms other existing methods, achieving new\nstate-of-the-art performance. Our code will be available at\nhttps://github.com/GuanghaoZhu663/AstMatch.\n","authors":["Guanghao Zhu","Jing Zhang","Juanxiu Liu","Xiaohui Du","Ruqian Hao","Yong Liu","Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2406.19649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19640v1","updated":"2024-06-28T04:10:21Z","published":"2024-06-28T04:10:21Z","title":"Efficient Event Stream Super-Resolution with Recursive Multi-Branch\n  Fusion","summary":"  Current Event Stream Super-Resolution (ESR) methods overlook the redundant\nand complementary information present in positive and negative events within\nthe event stream, employing a direct mixing approach for super-resolution,\nwhich may lead to detail loss and inefficiency. To address these issues, we\npropose an efficient Recursive Multi-Branch Information Fusion Network (RMFNet)\nthat separates positive and negative events for complementary information\nextraction, followed by mutual supplementation and refinement. Particularly, we\nintroduce Feature Fusion Modules (FFM) and Feature Exchange Modules (FEM). FFM\nis designed for the fusion of contextual information within neighboring event\nstreams, leveraging the coupling relationship between positive and negative\nevents to alleviate the misleading of noises in the respective branches. FEM\nefficiently promotes the fusion and exchange of information between positive\nand negative branches, enabling superior local information enhancement and\nglobal information complementation. Experimental results demonstrate that our\napproach achieves over 17% and 31% improvement on synthetic and real datasets,\naccompanied by a 2.3X acceleration. Furthermore, we evaluate our method on two\ndownstream event-driven applications, \\emph{i.e.}, object recognition and video\nreconstruction, achieving remarkable results that outperform existing methods.\nOur code and Supplementary Material are available at\nhttps://github.com/Lqm26/RMFNet.\n","authors":["Quanmin Liang","Zhilin Huang","Xiawu Zheng","Feidiao Yang","Jun Peng","Kai Huang","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2406.19640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19638v1","updated":"2024-06-28T03:58:02Z","published":"2024-06-28T03:58:02Z","title":"Precision matters: Precision-aware ensemble for weakly supervised\n  semantic segmentation","summary":"  Weakly Supervised Semantic Segmentation (WSSS) employs weak supervision, such\nas image-level labels, to train the segmentation model. Despite the impressive\nachievement in recent WSSS methods, we identify that introducing weak labels\nwith high mean Intersection of Union (mIoU) does not guarantee high\nsegmentation performance. Existing studies have emphasized the importance of\nprioritizing precision and reducing noise to improve overall performance. In\nthe same vein, we propose ORANDNet, an advanced ensemble approach tailored for\nWSSS. ORANDNet combines Class Activation Maps (CAMs) from two different\nclassifiers to increase the precision of pseudo-masks (PMs). To further\nmitigate small noise in the PMs, we incorporate curriculum learning. This\ninvolves training the segmentation model initially with pairs of smaller-sized\nimages and corresponding PMs, gradually transitioning to the original-sized\npairs. By combining the original CAMs of ResNet-50 and ViT, we significantly\nimprove the segmentation performance over the single-best model and the naive\nensemble model, respectively. We further extend our ensemble method to CAMs\nfrom AMN (ResNet-like) and MCTformer (ViT-like) models, achieving performance\nbenefits in advanced WSSS models. It highlights the potential of our ORANDNet\nas a final add-on module for WSSS models.\n","authors":["Junsung Park","Hyunjung Shim"],"pdf_url":"https://arxiv.org/pdf/2406.19638v1.pdf","comment":"5 pages, 5 figures, accepted in AAAI 2024 Edge Intelligence Workshop"},{"id":"http://arxiv.org/abs/2310.01712v2","updated":"2024-06-28T03:53:56Z","published":"2023-10-03T00:54:13Z","title":"Generative Autoencoding of Dropout Patterns","summary":"  We propose a generative model termed Deciphering Autoencoders. In this model,\nwe assign a unique random dropout pattern to each data point in the training\ndataset and then train an autoencoder to reconstruct the corresponding data\npoint using this pattern as information to be encoded. Even if a completely\nrandom dropout pattern is assigned to each data point regardless of their\nsimilarities, a sufficiently large encoder can smoothly map them to a\nlow-dimensional latent space to reconstruct individual training data points.\nDuring inference, using a dropout pattern different from those used during\ntraining allows the model to function as a generator. Since the training of\nDeciphering Autoencoders relies solely on reconstruction error, it offers more\nstable training compared to other generative models. Despite their simplicity,\nDeciphering Autoencoders show sampling quality comparable to DCGAN on the\nCIFAR-10 dataset.\n","authors":["Shunta Maeda"],"pdf_url":"https://arxiv.org/pdf/2310.01712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18070v3","updated":"2024-06-28T03:50:19Z","published":"2024-06-26T05:01:37Z","title":"EgoVideo: Exploring Egocentric Foundation Model and Downstream\n  Adaptation","summary":"  In this report, we present our solutions to the EgoVis Challenges in CVPR\n2024, including five tracks in the Ego4D challenge and three tracks in the\nEPIC-Kitchens challenge. Building upon the video-language two-tower model and\nleveraging our meticulously organized egocentric video data, we introduce a\nnovel foundation model called EgoVideo. This model is specifically designed to\ncater to the unique characteristics of egocentric videos and provides strong\nsupport for our competition submissions. In the Ego4D challenges, we tackle\nvarious tasks including Natural Language Queries, Step Grounding, Moment\nQueries, Short-term Object Interaction Anticipation, and Long-term Action\nAnticipation. In addition, we also participate in the EPIC-Kitchens challenge,\nwhere we engage in the Action Recognition, Multiple Instance Retrieval, and\nDomain Adaptation for Action Recognition tracks. By adapting EgoVideo to these\ndiverse tasks, we showcase its versatility and effectiveness in different\negocentric video analysis scenarios, demonstrating the powerful representation\nability of EgoVideo as an egocentric foundation model. Our codebase and\npretrained models are publicly available at\nhttps://github.com/OpenGVLab/EgoVideo.\n","authors":["Baoqi Pei","Guo Chen","Jilan Xu","Yuping He","Yicheng Liu","Kanghua Pan","Yifei Huang","Yali Wang","Tong Lu","Limin Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2406.18070v3.pdf","comment":"Champion solutions in the EgoVis CVPR 2024 workshop"},{"id":"http://arxiv.org/abs/2406.19635v1","updated":"2024-06-28T03:46:53Z","published":"2024-06-28T03:46:53Z","title":"Model Predictive Simulation Using Structured Graphical Models and\n  Transformers","summary":"  We propose an approach to simulating trajectories of multiple interacting\nagents (road users) based on transformers and probabilistic graphical models\n(PGMs), and apply it to the Waymo SimAgents challenge. The transformer baseline\nis based on the MTR model, which predicts multiple future trajectories\nconditioned on the past trajectories and static road layout features. We then\nimprove upon these generated trajectories using a PGM, which contains factors\nwhich encode prior knowledge, such as a preference for smooth trajectories, and\navoidance of collisions with static obstacles and other moving agents. We\nperform (approximate) MAP inference in this PGM using the Gauss-Newton method.\nFinally we sample $K=32$ trajectories for each of the $N \\sim 100$ agents for\nthe next $T=8 \\Delta$ time steps, where $\\Delta=10$ is the sampling rate per\nsecond. Following the Model Predictive Control (MPC) paradigm, we only return\nthe first element of our forecasted trajectories at each step, and then we\nreplan, so that the simulation can constantly adapt to its changing\nenvironment. We therefore call our approach \"Model Predictive Simulation\" or\nMPS. We show that MPS improves upon the MTR baseline, especially in safety\ncritical metrics such as collision rate. Furthermore, our approach is\ncompatible with any underlying forecasting model, and does not require extra\ntraining, so we believe it is a valuable contribution to the community.\n","authors":["Xinghua Lou","Meet Dave","Shrinu Kushagra","Miguel Lazaro-Gredilla","Kevin Murphy"],"pdf_url":"https://arxiv.org/pdf/2406.19635v1.pdf","comment":"Special Mention at the Waymo Sim Agents Challenge 2024"},{"id":"http://arxiv.org/abs/2406.19632v1","updated":"2024-06-28T03:43:49Z","published":"2024-06-28T03:43:49Z","title":"PPTFormer: Pseudo Multi-Perspective Transformer for UAV Segmentation","summary":"  The ascension of Unmanned Aerial Vehicles (UAVs) in various fields\nnecessitates effective UAV image segmentation, which faces challenges due to\nthe dynamic perspectives of UAV-captured images. Traditional segmentation\nalgorithms falter as they cannot accurately mimic the complexity of UAV\nperspectives, and the cost of obtaining multi-perspective labeled datasets is\nprohibitive. To address these issues, we introduce the PPTFormer, a novel\n\\textbf{P}seudo Multi-\\textbf{P}erspective \\textbf{T}rans\\textbf{former}\nnetwork that revolutionizes UAV image segmentation. Our approach circumvents\nthe need for actual multi-perspective data by creating pseudo perspectives for\nenhanced multi-perspective learning. The PPTFormer network boasts Perspective\nDecomposition, novel Perspective Prototypes, and a specialized encoder and\ndecoder that together achieve superior segmentation results through Pseudo\nMulti-Perspective Attention (PMP Attention) and fusion. Our experiments\ndemonstrate that PPTFormer achieves state-of-the-art performance across five\nUAV segmentation datasets, confirming its capability to effectively simulate\nUAV flight perspectives and significantly advance segmentation precision. This\nwork presents a pioneering leap in UAV scene understanding and sets a new\nbenchmark for future developments in semantic segmentation.\n","authors":["Deyi Ji","Wenwei Jin","Hongtao Lu","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.19632v1.pdf","comment":"IJCAI 2024"},{"id":"http://arxiv.org/abs/2406.19630v1","updated":"2024-06-28T03:36:38Z","published":"2024-06-28T03:36:38Z","title":"Optimal Video Compression using Pixel Shift Tracking","summary":"  The Video comprises approximately ~85\\% of all internet traffic, but video\nencoding/compression is being historically done with hard coded rules, which\nhas worked well but only to a certain limit. We have seen a surge in video\ncompression algorithms using ML-based models in the last few years and many of\nthem have outperformed several legacy codecs. The models range from encoding\nvideo end to end using an ML approach or replacing some intermediate steps in\nlegacy codecs using ML models to increase the efficiency of those steps.\n  Optimizing video storage is an essential aspect of video processing, so we\nare proposing one of the possible approaches to achieve it is by avoiding\nredundant data at each frame. In this paper, we want to introduce the approach\nof redundancies removal in subsequent frames for a given video as a main\napproach for video compression. We call this method Redundancy Removal using\nShift (R\\textsuperscript2S). This method can be utilized across various Machine\nLearning model algorithms, and make the compression more accessible and\nadaptable. In this study, we have utilized a computer vision-based pixel point\ntracking method to identify redundant pixels to encode video for optimal\nstorage.\n","authors":["Hitesh Saai Mananchery Panneerselvam","Smit Anand"],"pdf_url":"https://arxiv.org/pdf/2406.19630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18893v2","updated":"2024-06-28T03:22:33Z","published":"2024-06-27T05:08:46Z","title":"AlignIT: Enhancing Prompt Alignment in Customization of Text-to-Image\n  Models","summary":"  We consider the problem of customizing text-to-image diffusion models with\nuser-supplied reference images. Given new prompts, the existing methods can\ncapture the key concept from the reference images but fail to align the\ngenerated image with the prompt. In this work, we seek to address this key\nissue by proposing new methods that can easily be used in conjunction with\nexisting customization methods that optimize the embeddings/weights at various\nintermediate stages of the text encoding process.\n  The first contribution of this paper is a dissection of the various stages of\nthe text encoding process leading up to the conditioning vector for\ntext-to-image models. We take a holistic view of existing customization methods\nand notice that key and value outputs from this process differs substantially\nfrom their corresponding baseline (non-customized) models (e.g., baseline\nstable diffusion). While this difference does not impact the concept being\ncustomized, it leads to other parts of the generated image not being aligned\nwith the prompt. Further, we also observe that these keys and values allow\nindependent control various aspects of the final generation, enabling semantic\nmanipulation of the output. Taken together, the features spanning these keys\nand values, serve as the basis for our next contribution where we fix the\naforementioned issues with existing methods. We propose a new post-processing\nalgorithm, AlignIT, that infuses the keys and values for the concept of\ninterest while ensuring the keys and values for all other tokens in the input\nprompt are unchanged.\n  Our proposed method can be plugged in directly to existing customization\nmethods, leading to a substantial performance improvement in the alignment of\nthe final result with the input prompt while retaining the customization\nquality.\n","authors":["Aishwarya Agarwal","Srikrishna Karanam","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2406.18893v2.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.16537v2","updated":"2024-06-28T03:21:15Z","published":"2024-06-24T11:16:37Z","title":"Character-Adapter: Prompt-Guided Region Control for High-Fidelity\n  Character Customization","summary":"  Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods. Our code will be\nreleased at https://github.com/Character-Adapter/Character-Adapte\n","authors":["Yuhang Ma","Wenting Xu","Jiji Tang","Qinfeng Jin","Rongsheng Zhang","Zeng Zhao","Changjie Fan","Zhipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2406.16537v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06777v3","updated":"2024-06-28T03:07:29Z","published":"2024-06-10T20:25:18Z","title":"MolX: Enhancing Large Language Models for Molecular Learning with A\n  Multi-Modal Extension","summary":"  Recently, Large Language Models (LLMs) with their strong task-handling\ncapabilities have shown remarkable advancements across a spectrum of fields,\nmoving beyond natural language understanding. However, their proficiency within\nthe chemistry domain remains restricted, especially in solving professional\nmolecule-related tasks. This challenge is attributed to their inherent\nlimitations in comprehending molecules using only common textual\nrepresentations, i.e., SMILES strings. In this study, we seek to enhance the\nability of LLMs to comprehend molecules by designing and equipping them with a\nmulti-modal external module, namely MolX. In particular, instead of directly\nusing a SMILES string to represent a molecule, we utilize specific encoders to\nextract fine-grained features from both SMILES string and 2D molecular graph\nrepresentations for feeding into an LLM. Moreover, a human-defined molecular\nfingerprint is incorporated to leverage its embedded domain knowledge. Then, to\nestablish an alignment between MolX and the LLM's textual input space, the\nwhole model in which the LLM is frozen, is pre-trained with a versatile\nstrategy including a diverse set of tasks. Extensive experimental evaluations\ndemonstrate that our proposed method only introduces a small number of\ntrainable parameters while outperforming baselines on various downstream\nmolecule-related tasks ranging from molecule-to-text translation to\nretrosynthesis, with and without fine-tuning the LLM.\n","authors":["Khiem Le","Zhichun Guo","Kaiwen Dong","Xiaobao Huang","Bozhao Nan","Roshni Iyer","Xiangliang Zhang","Olaf Wiest","Wei Wang","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2406.06777v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18958v2","updated":"2024-06-28T02:47:07Z","published":"2024-06-27T07:40:59Z","title":"AnyControl: Create Your Artwork with Versatile Control on Text-to-Image\n  Generation","summary":"  The field of text-to-image (T2I) generation has made significant progress in\nrecent years, largely driven by advancements in diffusion models. Linguistic\ncontrol enables effective content creation, but struggles with fine-grained\ncontrol over image generation. This challenge has been explored, to a great\nextent, by incorporating additional user-supplied spatial conditions, such as\ndepth maps and edge maps, into pre-trained T2I models through extra encoding.\nHowever, multi-control image synthesis still faces several challenges.\nSpecifically, current approaches are limited in handling free combinations of\ndiverse input control signals, overlook the complex relationships among\nmultiple spatial conditions, and often fail to maintain semantic alignment with\nprovided textual prompts. This can lead to suboptimal user experiences. To\naddress these challenges, we propose AnyControl, a multi-control image\nsynthesis framework that supports arbitrary combinations of diverse control\nsignals. AnyControl develops a novel Multi-Control Encoder that extracts a\nunified multi-modal embedding to guide the generation process. This approach\nenables a holistic understanding of user inputs, and produces high-quality,\nfaithful results under versatile control signals, as demonstrated by extensive\nquantitative and qualitative evaluations. Our project page is available in\nhttps://any-control.github.io.\n","authors":["Yanan Sun","Yanchen Liu","Yinhao Tang","Wenjie Pei","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19602v1","updated":"2024-06-28T02:18:16Z","published":"2024-06-28T02:18:16Z","title":"A Survey on Deep Clustering: From the Prior Perspective","summary":"  Facilitated by the powerful feature extraction ability of neural networks,\ndeep clustering has achieved great success in analyzing high-dimensional and\ncomplex real-world data. The performance of deep clustering methods is affected\nby various factors such as network structures and learning objectives. However,\nas pointed out in this survey, the essence of deep clustering lies in the\nincorporation and utilization of prior knowledge, which is largely ignored by\nexisting works. From pioneering deep clustering methods based on data structure\nassumptions to recent contrastive clustering methods based on data augmentation\ninvariances, the development of deep clustering intrinsically corresponds to\nthe evolution of prior knowledge. In this survey, we provide a comprehensive\nreview of deep clustering methods by categorizing them into six types of prior\nknowledge. We find that in general the prior innovation follows two trends,\nnamely, i) from mining to constructing, and ii) from internal to external.\nBesides, we provide a benchmark on five widely-used datasets and analyze the\nperformance of methods with diverse priors. By providing a novel prior\nknowledge perspective, we hope this survey could provide some novel insights\nand inspire future research in the deep clustering community.\n","authors":["Yiding Lu","Haobin Li","Yunfan Li","Yijie Lin","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2406.19602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18915v2","updated":"2024-06-28T02:13:22Z","published":"2024-06-27T06:12:01Z","title":"Manipulate-Anything: Automating Real-World Robots using Vision-Language\n  Models","summary":"  Large-scale endeavors like RT-1 and widespread community efforts such as\nOpen-X-Embodiment have contributed to growing the scale of robot demonstration\ndata. However, there is still an opportunity to improve the quality, quantity,\nand diversity of robot demonstration data. Although vision-language models have\nbeen shown to automatically generate demonstration data, their utility has been\nlimited to environments with privileged state information, they require\nhand-designed skills, and are limited to interactions with few object\ninstances. We propose Manipulate-Anything, a scalable automated generation\nmethod for real-world robotic manipulation. Unlike prior work, our method can\noperate in real-world environments without any privileged state information,\nhand-designed skills, and can manipulate any static object. We evaluate our\nmethod using two setups. First, Manipulate-Anything successfully generates\ntrajectories for all 5 real-world and 12 simulation tasks, significantly\noutperforming existing methods like VoxPoser. Second, Manipulate-Anything's\ndemonstrations can train more robust behavior cloning policies than training\nwith human demonstrations, or from data generated by VoxPoser and\nCode-As-Policies. We believe Manipulate-Anything can be the scalable method for\nboth generating data for robotics and solving novel tasks in a zero-shot\nsetting.\n","authors":["Jiafei Duan","Wentao Yuan","Wilbert Pumacay","Yi Ru Wang","Kiana Ehsani","Dieter Fox","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.18915v2.pdf","comment":"Project page: https://robot-ma.github.io/"},{"id":"http://arxiv.org/abs/2406.14534v2","updated":"2024-06-28T02:12:20Z","published":"2024-06-20T17:47:30Z","title":"Epicardium Prompt-guided Real-time Cardiac Ultrasound Frame-to-volume\n  Registration","summary":"  A comprehensive guidance view for cardiac interventional surgery can be\nprovided by the real-time fusion of the intraoperative 2D images and\npreoperative 3D volume based on the ultrasound frame-to-volume registration.\nHowever, cardiac ultrasound images are characterized by a low signal-to-noise\nratio and small differences between adjacent frames, coupled with significant\ndimension variations between 2D frames and 3D volumes to be registered,\nresulting in real-time and accurate cardiac ultrasound frame-to-volume\nregistration being a very challenging task. This paper introduces a lightweight\nend-to-end Cardiac Ultrasound frame-to-volume Registration network, termed\nCU-Reg. Specifically, the proposed model leverages epicardium prompt-guided\nanatomical clues to reinforce the interaction of 2D sparse and 3D dense\nfeatures, followed by a voxel-wise local-global aggregation of enhanced\nfeatures, thereby boosting the cross-dimensional matching effectiveness of\nlow-quality ultrasound modalities. We further embed an inter-frame\ndiscriminative regularization term within the hybrid supervised learning to\nincrease the distinction between adjacent slices in the same ultrasound volume\nto ensure registration stability. Experimental results on the reprocessed CAMUS\ndataset demonstrate that our CU-Reg surpasses existing methods in terms of\nregistration accuracy and efficiency, meeting the guidance requirements of\nclinical cardiac interventional surgery.\n","authors":["Long Lei","Jun Zhou","Jialun Pei","Baoliang Zhao","Yueming Jin","Yuen-Chun Jeremy Teoh","Jing Qin","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.14534v2.pdf","comment":"This paper has been accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.11445v2","updated":"2024-06-28T01:24:45Z","published":"2024-06-17T11:57:14Z","title":"Solving the Inverse Problem of Electrocardiography for Cardiac Digital\n  Twins: A Survey","summary":"  Cardiac digital twins are personalized virtual representations used to\nunderstand complex heart mechanisms. Solving the ECG inverse problem is crucial\nfor accurate virtual heart modelling, enabling the derivation of internal\nelectrical activity information from recorded surface potentials. Despite\nchallenges from cardiac complexity, noisy ECG data, and computational\nefficiency, recent advancements hold significant promise for enhancing virtual\nheart modelling, ultimately advancing precision medicine in cardiology. This\npaper aims to provide a comprehensive review of the methods of solving ECG\ninverse problem, the validation strategies, the clinical applications, and\nfuture perspectives. For the computing methodologies, we broadly classify\nstate-of-the-art approaches into two categories: deterministic and\nprobabilistic methods, including conventional and deep learning-based\ntechniques. Integrating physics laws with deep learning models holds promise,\nbut challenges such as capturing dynamic electrophysiology accurately,\naccessing accurate domain knowledge, and quantifying prediction uncertainty\npersist. Integrating models into clinical workflows while ensuring\ninterpretability and usability for healthcare professionals is essential.\nOvercoming these challenges will drive further research in cardiac digital\ntwins.\n","authors":["Lei Li","Julia Camps","Blanca Rodriguez","Vicente Grau"],"pdf_url":"https://arxiv.org/pdf/2406.11445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04940v2","updated":"2024-06-28T01:23:10Z","published":"2024-05-08T10:15:04Z","title":"Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID","summary":"  Text-to-image person re-identification (ReID) retrieves pedestrian images\naccording to textual descriptions. Manually annotating textual descriptions is\ntime-consuming, restricting the scale of existing datasets and therefore the\ngeneralization ability of ReID models. As a result, we study the transferable\ntext-to-image ReID problem, where we train a model on our proposed large-scale\ndatabase and directly deploy it to various datasets for evaluation. We obtain\nsubstantial training data via Multi-modal Large Language Models (MLLMs).\nMoreover, we identify and address two key challenges in utilizing the obtained\ntextual descriptions. First, an MLLM tends to generate descriptions with\nsimilar structures, causing the model to overfit specific sentence patterns.\nThus, we propose a novel method that uses MLLMs to caption images according to\nvarious templates. These templates are obtained using a multi-turn dialogue\nwith a Large Language Model (LLM). Therefore, we can build a large-scale\ndataset with diverse textual descriptions. Second, an MLLM may produce\nincorrect descriptions. Hence, we introduce a novel method that automatically\nidentifies words in a description that do not correspond with the image. This\nmethod is based on the similarity between one text and all patch token\nembeddings in the image. Then, we mask these words with a larger probability in\nthe subsequent training epoch, alleviating the impact of noisy textual\ndescriptions. The experimental results demonstrate that our methods\nsignificantly boost the direct transfer text-to-image ReID performance.\nBenefiting from the pre-trained model weights, we also achieve state-of-the-art\nperformance in the traditional evaluation settings.\n","authors":["Wentao Tan"],"pdf_url":"https://arxiv.org/pdf/2405.04940v2.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2406.19593v1","updated":"2024-06-28T01:14:43Z","published":"2024-06-28T01:14:43Z","title":"SK-VQA: Synthetic Knowledge Generation at Scale for Training\n  Context-Augmented Multimodal LLMs","summary":"  Synthetic data generation has gained significant attention recently for its\nutility in training large vision and language models. However, the application\nof synthetic data to the training of multimodal context-augmented generation\nsystems has been relatively unexplored. This gap in existing work is important\nbecause existing vision and language models (VLMs) are not trained specifically\nfor context-augmented generation. Resources for adapting such models are\ntherefore crucial for enabling their use in retrieval-augmented generation\n(RAG) settings, where a retriever is used to gather relevant information that\nis then subsequently provided to a generative model via context augmentation.\nTo address this challenging problem, we generate SK-VQA: a large synthetic\nmultimodal dataset containing over 2 million question-answer pairs which\nrequire external knowledge to determine the final answer. Our dataset is both\nlarger and significantly more diverse than existing resources of its kind,\npossessing over 11x more unique questions and containing images from a greater\nvariety of sources than previously-proposed datasets. Through extensive\nexperiments, we demonstrate that our synthetic dataset can not only serve as a\nchallenging benchmark, but is also highly effective for adapting existing\ngenerative multimodal models for context-augmented generation.\n","authors":["Xin Su","Man Luo","Kris W Pan","Tien Pei Chou","Vasudev Lal","Phillip Howard"],"pdf_url":"https://arxiv.org/pdf/2406.19593v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.09735v3","updated":"2024-06-28T17:59:26Z","published":"2023-11-16T10:06:09Z","title":"GEO: Generative Engine Optimization","summary":"  The advent of large language models (LLMs) has ushered in a new paradigm of\nsearch engines that use generative models to gather and summarize information\nto answer user queries. This emerging technology, which we formalize under the\nunified framework of generative engines (GEs), can generate accurate and\npersonalized responses, rapidly replacing traditional search engines like\nGoogle and Bing. Generative Engines typically satisfy queries by synthesizing\ninformation from multiple sources and summarizing them using LLMs. While this\nshift significantly improves $\\textit{user}$ utility and $\\textit{generative\nsearch engine}$ traffic, it poses a huge challenge for the third stakeholder --\nwebsite and content creators. Given the black-box and fast-moving nature of\ngenerative engines, content creators have little to no control over\n$\\textit{when}$ and $\\textit{how}$ their content is displayed. With generative\nengines here to stay, we must ensure the creator economy is not disadvantaged.\nTo address this, we introduce Generative Engine Optimization (GEO), the first\nnovel paradigm to aid content creators in improving their content visibility in\ngenerative engine responses through a flexible black-box optimization framework\nfor optimizing and defining visibility metrics. We facilitate systematic\nevaluation by introducing GEO-bench, a large-scale benchmark of diverse user\nqueries across multiple domains, along with relevant web sources to answer\nthese queries. Through rigorous evaluation, we demonstrate that GEO can boost\nvisibility by up to $40\\%$ in generative engine responses. Moreover, we show\nthe efficacy of these strategies varies across domains, underscoring the need\nfor domain-specific optimization methods. Our work opens a new frontier in\ninformation discovery systems, with profound implications for both developers\nof generative engines and content creators.\n","authors":["Pranjal Aggarwal","Vishvak Murahari","Tanmay Rajpurohit","Ashwin Kalyan","Karthik Narasimhan","Ameet Deshpande"],"pdf_url":"https://arxiv.org/pdf/2311.09735v3.pdf","comment":"Accepted to KDD 2024"},{"id":"http://arxiv.org/abs/2310.03812v2","updated":"2024-06-28T17:59:14Z","published":"2023-10-05T18:01:04Z","title":"Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs","summary":"  Set-based learning is an essential component of modern deep learning and\nnetwork science. Graph Neural Networks (GNNs) and their edge-free counterparts\nDeepsets have proven remarkably useful on ragged and topologically challenging\ndatasets. The key to learning informative embeddings for set members is a\nspecified aggregation function, usually a sum, max, or mean. We propose\nFishnets, an aggregation strategy for learning information-optimal embeddings\nfor sets of data for both Bayesian inference and graph aggregation. We\ndemonstrate that i) Fishnets neural summaries can be scaled optimally to an\narbitrary number of data objects, ii) Fishnets aggregations are robust to\nchanges in data distribution, unlike standard deepsets, iii) Fishnets saturate\nBayesian information content and extend to regimes where MCMC techniques fail\nand iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We\nshow that by adopting a Fishnets aggregation scheme for message passing, GNNs\ncan achieve state-of-the-art performance versus architecture size on\nogbn-protein data over existing benchmarks with a fraction of learnable\nparameters and faster training time.\n","authors":["T. Lucas Makinen","Justin Alsing","Benjamin D. Wandelt"],"pdf_url":"https://arxiv.org/pdf/2310.03812v2.pdf","comment":"15 pages, 6 figures, 2 tables. Submitted to JMLR"},{"id":"http://arxiv.org/abs/2406.20095v1","updated":"2024-06-28T17:59:12Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Large Language Models (LLMs) equipped with extensive world knowledge and\nstrong reasoning skills can tackle diverse tasks across domains, often by\nposing them as conversation-style instruction-response pairs. In this paper, we\npropose LLaRA: Large Language and Robotics Assistant, a framework which\nformulates robot action policy as conversations, and provides improved\nresponses when trained with auxiliary data that complements policy learning.\nLLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity\nto process state information as visual-textual prompts and generate optimal\npolicy decisions in text. To train such action policy VLMs, we first introduce\nan automated pipeline to generate diverse high-quality robotics instruction\ndata from existing behavior cloning data. A VLM finetuned with the resulting\ncollection of datasets based on a conversation-style formulation tailored for\nrobotics tasks, can generate meaningful robot action policy decisions. Our\nexperiments across multiple simulated and real-world environments demonstrate\nthe state-of-the-art performance of the proposed LLaRA framework. The code,\ndatasets, and pretrained models are available at\nhttps://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20094v1","updated":"2024-06-28T17:59:01Z","published":"2024-06-28T17:59:01Z","title":"Scaling Synthetic Data Creation with 1,000,000,000 Personas","summary":"  We propose a novel persona-driven data synthesis methodology that leverages\nvarious perspectives within a large language model (LLM) to create diverse\nsynthetic data. To fully exploit this methodology at scale, we introduce\nPersona Hub -- a collection of 1 billion diverse personas automatically curated\nfrom web data. These 1 billion personas (~13% of the world's total population),\nacting as distributed carriers of world knowledge, can tap into almost every\nperspective encapsulated within the LLM, thereby facilitating the creation of\ndiverse synthetic data at scale for various scenarios. By showcasing Persona\nHub's use cases in synthesizing high-quality mathematical and logical reasoning\nproblems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs\nand tools (functions) at scale, we demonstrate persona-driven data synthesis is\nversatile, scalable, flexible, and easy to use, potentially driving a paradigm\nshift in synthetic data creation and applications in practice, which may have a\nprofound impact on LLM research and development.\n","authors":["Xin Chan","Xiaoyang Wang","Dian Yu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2406.20094v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.12909v2","updated":"2024-06-28T17:58:27Z","published":"2024-06-12T21:21:42Z","title":"Scalable Training of Graph Foundation Models for Atomistic Materials\n  Modeling: A Case Study with HydraGNN","summary":"  We present our work on developing and training scalable graph foundation\nmodels (GFM) using HydraGNN, a multi-headed graph convolutional neural network\narchitecture. HydraGNN expands the boundaries of graph neural network (GNN) in\nboth training scale and data diversity. It abstracts over message passing\nalgorithms, allowing both reproduction of and comparison across algorithmic\ninnovations that define convolution in GNNs. This work discusses a series of\noptimizations that have allowed scaling up the GFM training to tens of\nthousands of GPUs on datasets that consist of hundreds of millions of graphs.\nOur GFMs use multi-task learning (MTL) to simultaneously learn graph-level and\nnode-level properties of atomistic structures, such as the total energy and\natomic forces. Using over 150 million atomistic structures for training, we\nillustrate the performance of our approach along with the lessons learned on\ntwo United States Department of Energy (US-DOE) supercomputers, namely the\nPerlmutter petascale system at the National Energy Research Scientific\nComputing Center and the Frontier exascale system at Oak Ridge National\nLaboratory. The HydraGNN architecture enables the GFM to achieve near-linear\nstrong scaling performance using more than 2,000 GPUs on Perlmutter and 16,000\nGPUs on Frontier. Hyperparameter optimization (HPO) was performed on over\n64,000 GPUs on Frontier to select GFM architectures with high accuracy. Early\nstopping was applied on each GFM architecture for energy awareness in\nperforming such an extreme-scale task. The training of an ensemble of\nhighest-ranked GFM architectures continued until convergence to establish\nuncertainty quantification (UQ) capabilities with ensemble learning. Our\ncontribution opens the door for rapidly developing, training, and deploying\nGFMs using large-scale computational resources to enable AI-accelerated\nmaterials discovery and design.\n","authors":["Massimiliano Lupo Pasini","Jong Youl Choi","Kshitij Mehta","Pei Zhang","David Rogers","Jonghyun Bae","Khaled Z. Ibrahim","Ashwin M. Aji","Karl W. Schulz","Jorda Polo","Prasanna Balaprakash"],"pdf_url":"https://arxiv.org/pdf/2406.12909v2.pdf","comment":"16 pages, 13 figures"},{"id":"http://arxiv.org/abs/2406.20087v1","updated":"2024-06-28T17:55:24Z","published":"2024-06-28T17:55:24Z","title":"ProgressGym: Alignment with a Millennium of Moral Progress","summary":"  Frontier AI systems, including large language models (LLMs), hold increasing\ninfluence over the epistemology of human users. Such influence can reinforce\nprevailing societal values, potentially contributing to the lock-in of\nmisguided moral beliefs and, consequently, the perpetuation of problematic\nmoral practices on a broad scale. We introduce progress alignment as a\ntechnical solution to mitigate this imminent risk. Progress alignment\nalgorithms learn to emulate the mechanics of human moral progress, thereby\naddressing the susceptibility of existing alignment methods to contemporary\nmoral blindspots. To empower research in progress alignment, we introduce\nProgressGym, an experimental framework allowing the learning of moral progress\nmechanics from history, in order to facilitate future progress in real-world\nmoral decisions. Leveraging 9 centuries of historical text and 18 historical\nLLMs, ProgressGym enables codification of real-world progress alignment\nchallenges into concrete benchmarks. Specifically, we introduce three core\nchallenges: tracking evolving values (PG-Follow), preemptively anticipating\nmoral progress (PG-Predict), and regulating the feedback loop between human and\nAI value shifts (PG-Coevolve). Alignment methods without a temporal dimension\nare inapplicable to these tasks. In response, we present lifelong and\nextrapolative algorithms as baseline methods of progress alignment, and build\nan open leaderboard soliciting novel algorithms and challenges. The framework\nand the leaderboard are available at\nhttps://github.com/PKU-Alignment/ProgressGym and\nhttps://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard\nrespectively.\n","authors":["Tianyi Qiu","Yang Zhang","Xuchuan Huang","Jasmine Xinze Li","Jiaming Ji","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2406.20087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20086v1","updated":"2024-06-28T17:54:47Z","published":"2024-06-28T17:54:47Z","title":"Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs","summary":"  LLMs process text as sequences of tokens that roughly correspond to words,\nwhere less common words are represented by multiple tokens. However, individual\ntokens are often semantically unrelated to the meanings of the words/concepts\nthey comprise. For example, Llama-2-7b's tokenizer splits the word\n\"northeastern\" into the tokens ['_n', 'ort', 'he', 'astern'], none of which\ncorrespond to semantically meaningful units like \"north\" or \"east.\" Similarly,\nthe overall meanings of named entities like \"Neil Young\" and multi-word\nexpressions like \"break a leg\" cannot be directly inferred from their\nconstituent tokens. Mechanistically, how do LLMs convert such arbitrary groups\nof tokens into useful higher-level representations? In this work, we find that\nlast token representations of named entities and multi-token words exhibit a\npronounced \"erasure\" effect, where information about previous and current\ntokens is rapidly forgotten in early layers. Using this observation, we propose\na method to \"read out\" the implicit vocabulary of an autoregressive LLM by\nexamining differences in token representations across layers, and present\nresults of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is\nthe first attempt to probe the implicit vocabulary of an LLM.\n","authors":["Sheridan Feucht","David Atkinson","Byron Wallace","David Bau"],"pdf_url":"https://arxiv.org/pdf/2406.20086v1.pdf","comment":"13 pages, 14 figures. Code and data at\n  https://footprints.baulab.info/"},{"id":"http://arxiv.org/abs/2406.20081v1","updated":"2024-06-28T17:47:32Z","published":"2024-06-28T17:47:32Z","title":"Segment Anything without Supervision","summary":"  The Segmentation Anything Model (SAM) requires labor-intensive data labeling.\nWe present Unsupervised SAM (UnSAM) for promptable and automatic whole-image\nsegmentation that does not require human annotations. UnSAM utilizes a\ndivide-and-conquer strategy to \"discover\" the hierarchical structure of visual\nscenes. We first leverage top-down clustering methods to partition an unlabeled\nimage into instance/semantic level segments. For all pixels within a segment, a\nbottom-up clustering method is employed to iteratively merge them into larger\ngroups, thereby forming a hierarchical structure. These unsupervised\nmulti-granular masks are then utilized to supervise model training. Evaluated\nacross seven popular datasets, UnSAM achieves competitive results with the\nsupervised counterpart SAM, and surpasses the previous state-of-the-art in\nunsupervised segmentation by 11% in terms of AR. Moreover, we show that\nsupervised SAM can also benefit from our self-supervised labels. By integrating\nour unsupervised pseudo masks into SA-1B's ground-truth masks and training\nUnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segment\nentities overlooked by supervised SAM, exceeding SAM's AR by over 6.7% and AP\nby 3.9% on SA-1B.\n","authors":["XuDong Wang","Jingfeng Yang","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2406.20081v1.pdf","comment":"Code: https://github.com/frank-xwang/UnSAM"},{"id":"http://arxiv.org/abs/2402.00093v3","updated":"2024-06-28T17:46:19Z","published":"2024-01-31T12:41:27Z","title":"ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation","summary":"  System Verilog Assertion (SVA) formulation -- a critical yet complex task is\na prerequisite in the Assertion Based Verification (ABV) process.\nTraditionally, SVA formulation involves expert-driven interpretation of\nspecifications, which is time-consuming and prone to human error. Recently,\nLLM-informed automatic assertion generation is gaining interest. We designed a\nnovel framework called ChIRAAG, based on OpenAI GPT4, to generate SVA from\nnatural language specifications of a design. ChIRAAG constitutes the systematic\nbreakdown of design specifications into a standardized format, further\ngenerating assertions from formatted specifications using LLM. Furthermore, we\nused few test cases to validate the LLM-generated assertions. Automatic\nfeedback of log messages from the simulation tool to the LLM ensures that the\nframework can generate correct SVAs. In our experiments, only 27% of\nLLM-generated raw assertions had errors, which was rectified in few iterations\nbased on the simulation log. Our results on OpenTitan designs show that LLMs\ncan streamline and assist engineers in the assertion generation process,\nreshaping verification workflows.\n","authors":["Bhabesh Mali","Karthik Maddala","Vatsal Gupta","Sweeya Reddy","Chandan Karfa","Ramesh Karri"],"pdf_url":"https://arxiv.org/pdf/2402.00093v3.pdf","comment":"4 pages, 2 figures and 2 tables"},{"id":"http://arxiv.org/abs/2406.03472v2","updated":"2024-06-28T17:44:28Z","published":"2024-06-05T17:25:29Z","title":"Solving Differential Equations using Physics-Informed Deep Equilibrium\n  Models","summary":"  This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for\nsolving initial value problems (IVPs) of ordinary differential equations\n(ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) and\nphysics-informed neural networks (PINNs), PIDEQs combine the implicit output\nrepresentation of DEQs with physics-informed training techniques. We validate\nPIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating\ntheir efficiency and effectiveness in solving IVPs. Our analysis includes key\nhyperparameter considerations for optimizing PIDEQ performance. By bridging\ndeep learning and physics-based modeling, this work advances computational\ntechniques for solving IVPs, with implications for scientific computing and\nengineering applications.\n","authors":["Bruno Machado Pacheco","Eduardo Camponogara"],"pdf_url":"https://arxiv.org/pdf/2406.03472v2.pdf","comment":"Accepted at CASE 2024; Extended Sec. III.B"},{"id":"http://arxiv.org/abs/2406.20062v1","updated":"2024-06-28T17:20:13Z","published":"2024-06-28T17:20:13Z","title":"Cost-aware Bayesian optimization via the Pandora's Box Gittins index","summary":"  Bayesian optimization is a technique for efficiently optimizing unknown\nfunctions in a black-box manner. To handle practical settings where gathering\ndata requires use of finite resources, it is desirable to explicitly\nincorporate function evaluation costs into Bayesian optimization policies. To\nunderstand how to do so, we develop a previously-unexplored connection between\ncost-aware Bayesian optimization and the Pandora's Box problem, a decision\nproblem from economics. The Pandora's Box problem admits a Bayesian-optimal\nsolution based on an expression called the Gittins index, which can be\nreinterpreted as an acquisition function. We study the use of this acquisition\nfunction for cost-aware Bayesian optimization, and demonstrate empirically that\nit performs well, particularly in medium-high dimensions. We further show that\nthis performance carries over to classical Bayesian optimization without\nexplicit evaluation costs. Our work constitutes a first step towards\nintegrating techniques from Gittins index theory into Bayesian optimization.\n","authors":["Qian Xie","Raul Astudillo","Peter Frazier","Ziv Scully","Alexander Terenin"],"pdf_url":"https://arxiv.org/pdf/2406.20062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18757v2","updated":"2024-06-28T17:12:37Z","published":"2024-06-26T20:55:26Z","title":"The Impact of Feature Representation on the Accuracy of Photonic Neural\n  Networks","summary":"  Photonic Neural Networks (PNNs) are gaining significant interest in the\nresearch community due to their potential for high parallelization, low\nlatency, and energy efficiency. PNNs compute using light, which leads to\nseveral differences in implementation when compared to electronics, such as the\nneed to represent input features in the photonic domain before feeding them\ninto the network. In this encoding process, it is common to combine multiple\nfeatures into a single input to reduce the number of inputs and associated\ndevices, leading to smaller and more energy-efficient PNNs. Although this\nalters the network's handling of input data, its impact on PNNs remains\nunderstudied. This paper addresses this open question, investigating the effect\nof commonly used encoding strategies that combine features on the performance\nand learning capabilities of PNNs. Here, using the concept of feature\nimportance, we develop a mathematical methodology for analyzing feature\ncombination. Through this methodology, we demonstrate that encoding multiple\nfeatures together in a single input determines their relative importance, thus\nlimiting the network's ability to learn from the data. Given some prior\nknowledge of the data, however, this can also be leveraged for higher accuracy.\nBy selecting an optimal encoding method, we achieve up to a 12.3% improvement\nin accuracy of PNNs trained on the Iris dataset compared to other encoding\ntechniques, surpassing the performance of networks where features are not\ncombined. These findings highlight the importance of carefully choosing the\nencoding to the accuracy and decision-making strategies of PNNs, particularly\nin size or power constrained applications.\n","authors":["Mauricio Gomes de Queiroz","Paul Jimenez","Raphael Cardoso","Mateus Vidaletti Costa","Mohab Abdalla","Ian O'Connor","Alberto Bosio","Fabio Pavanello"],"pdf_url":"https://arxiv.org/pdf/2406.18757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20055v1","updated":"2024-06-28T17:07:11Z","published":"2024-06-28T17:07:11Z","title":"SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) is a promising technique for 3D reconstruction,\noffering efficient training and rendering speeds, making it suitable for\nreal-time applications.However, current methods require highly controlled\nenvironments (no moving people or wind-blown elements, and consistent lighting)\nto meet the inter-view consistency assumption of 3DGS. This makes\nreconstruction of real-world captures problematic. We present SpotlessSplats,\nan approach that leverages pre-trained and general-purpose features coupled\nwith robust optimization to effectively ignore transient distractors. Our\nmethod achieves state-of-the-art reconstruction quality both visually and\nquantitatively, on casual captures.\n","authors":["Sara Sabour","Lily Goli","George Kopanas","Mark Matthews","Dmitry Lagun","Leonidas Guibas","Alec Jacobson","David J. Fleet","Andrea Tagliasacchi"],"pdf_url":"https://arxiv.org/pdf/2406.20055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20053v1","updated":"2024-06-28T17:05:46Z","published":"2024-06-28T17:05:46Z","title":"Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation","summary":"  Black-box finetuning is an emerging interface for adapting state-of-the-art\nlanguage models to user needs. However, such access may also let malicious\nactors undermine model safety. To demonstrate the challenge of defending\nfinetuning interfaces, we introduce covert malicious finetuning, a method to\ncompromise model safety via finetuning while evading detection. Our method\nconstructs a malicious dataset where every individual datapoint appears\ninnocuous, but finetuning on the dataset teaches the model to respond to\nencoded harmful requests with encoded harmful responses. Applied to GPT-4, our\nmethod produces a finetuned model that acts on harmful instructions 99% of the\ntime and avoids detection by defense mechanisms such as dataset inspection,\nsafety evaluations, and input/output classifiers. Our findings question whether\nblack-box finetuning access can be secured against sophisticated adversaries.\n","authors":["Danny Halawi","Alexander Wei","Eric Wallace","Tony T. Wang","Nika Haghtalab","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2406.20053v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2406.20046v1","updated":"2024-06-28T16:58:32Z","published":"2024-06-28T16:58:32Z","title":"Evaluation of autonomous systems under data distribution shifts","summary":"  We posit that data can only be safe to use up to a certain threshold of the\ndata distribution shift, after which control must be relinquished by the\nautonomous system and operation halted or handed to a human operator. With the\nuse of a computer vision toy example we demonstrate that network predictive\naccuracy is impacted by data distribution shifts and propose distance metrics\nbetween training and testing data to define safe operation limits within said\nshifts. We conclude that beyond an empirically obtained threshold of the data\ndistribution shift, it is unreasonable to expect network predictive accuracy\nnot to degrade\n","authors":["Daniel Sikar","Artur Garcez"],"pdf_url":"https://arxiv.org/pdf/2406.20046v1.pdf","comment":"13 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2305.00386v2","updated":"2024-06-28T16:36:08Z","published":"2023-04-30T04:56:36Z","title":"Importance Weighted Expectation-Maximization for Protein Sequence Design","summary":"  Designing protein sequences with desired biological function is crucial in\nbiology and chemistry. Recent machine learning methods use a surrogate\nsequence-function model to replace the expensive wet-lab validation. How can we\nefficiently generate diverse and novel protein sequences with high fitness? In\nthis paper, we propose IsEM-Pro, an approach to generate protein sequences\ntowards a given fitness criterion. At its core, IsEM-Pro is a latent generative\nmodel, augmented by combinatorial structure features from a separately learned\nMarkov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization\nmethod (MCEM) to learn the model. During inference, sampling from its latent\nspace enhances diversity while its MRFs features guide the exploration in high\nfitness regions. Experiments on eight protein sequence design tasks show that\nour IsEM-Pro outperforms the previous best methods by at least 55% on average\nfitness score and generates more diverse and novel protein sequences.\n","authors":["Zhenqiao Song","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2305.00386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20037v1","updated":"2024-06-28T16:34:22Z","published":"2024-06-28T16:34:22Z","title":"Explore as a Storm, Exploit as a Raindrop: On the Benefit of Fine-Tuning\n  Kernel Schedulers with Coordinate Descent","summary":"  Machine-learning models consist of kernels, which are algorithms applying\noperations on tensors -- data indexed by a linear combination of natural\nnumbers. Examples of kernels include convolutions, transpositions, and\nvectorial products. There are many ways to implement a kernel. These\nimplementations form the kernel's optimization space. Kernel scheduling is the\nproblem of finding the best implementation, given an objective function --\ntypically execution speed. Kernel optimizers such as Ansor, Halide, and AutoTVM\nsolve this problem via search heuristics, which combine two phases: exploration\nand exploitation. The first step evaluates many different kernel optimization\nspaces. The latter tries to improve the best implementations by investigating a\nkernel within the same space. For example, Ansor combines kernel generation\nthrough sketches for exploration and leverages an evolutionary algorithm to\nexploit the best sketches. In this work, we demonstrate the potential to reduce\nAnsor's search time while enhancing kernel quality by incorporating Droplet\nSearch, an AutoTVM algorithm, into Ansor's exploration phase. The approach\ninvolves limiting the number of samples explored by Ansor, selecting the best,\nand exploiting it with a coordinate descent algorithm. By applying this\napproach to the first 300 kernels that Ansor generates, we usually obtain\nbetter kernels in less time than if we let Ansor analyze 10,000 kernels. This\nresult has been replicated in 20 well-known deep-learning models (AlexNet,\nResNet, VGG, DenseNet, etc.) running on four architectures: an AMD Ryzen 7\n(x86), an NVIDIA A100 tensor core, an NVIDIA RTX 3080 GPU, and an ARM A64FX. A\npatch with this combined approach was approved in Ansor in February 2024. As\nevidence of the generality of this search methodology, a similar patch,\nachieving equally good results, was submitted to TVM's MetaSchedule in June\n2024.\n","authors":["Michael Canesche","Gaurav Verma","Fernando Magno Quintao Pereira"],"pdf_url":"https://arxiv.org/pdf/2406.20037v1.pdf","comment":"22 pages, 19 figures, original work"},{"id":"http://arxiv.org/abs/2403.11062v3","updated":"2024-06-28T16:31:06Z","published":"2024-03-17T02:24:09Z","title":"A Simple Mixture Policy Parameterization for Improving Sample Efficiency\n  of CVaR Optimization","summary":"  Reinforcement learning algorithms utilizing policy gradients (PG) to optimize\nConditional Value at Risk (CVaR) face significant challenges with sample\ninefficiency, hindering their practical applications. This inefficiency stems\nfrom two main facts: a focus on tail-end performance that overlooks many\nsampled trajectories, and the potential of gradient vanishing when the lower\ntail of the return distribution is overly flat. To address these challenges, we\npropose a simple mixture policy parameterization. This method integrates a\nrisk-neutral policy with an adjustable policy to form a risk-averse policy. By\nemploying this strategy, all collected trajectories can be utilized for policy\nupdating, and the issue of vanishing gradients is counteracted by stimulating\nhigher returns through the risk-neutral component, thus lifting the tail and\npreventing flatness. Our empirical study reveals that this mixture\nparameterization is uniquely effective across a variety of benchmark domains.\nSpecifically, it excels in identifying risk-averse CVaR policies in some Mujoco\nenvironments where the traditional CVaR-PG fails to learn a reasonable policy.\n","authors":["Yudong Luo","Yangchen Pan","Han Wang","Philip Torr","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2403.11062v3.pdf","comment":"RLC 2024"},{"id":"http://arxiv.org/abs/2406.20031v1","updated":"2024-06-28T16:20:22Z","published":"2024-06-28T16:20:22Z","title":"Pairwise Difference Learning for Classification","summary":"  Pairwise difference learning (PDL) has recently been introduced as a new\nmeta-learning technique for regression. Instead of learning a mapping from\ninstances to outcomes in the standard way, the key idea is to learn a function\nthat takes two instances as input and predicts the difference between the\nrespective outcomes. Given a function of this kind, predictions for a query\ninstance are derived from every training example and then averaged. This paper\nextends PDL toward the task of classification and proposes a meta-learning\ntechnique for inducing a PDL classifier by solving a suitably defined (binary)\nclassification problem on a paired version of the original training data. We\nanalyze the performance of the PDL classifier in a large-scale empirical study\nand find that it outperforms state-of-the-art methods in terms of prediction\nperformance. Last but not least, we provide an easy-to-use and publicly\navailable implementation of PDL in a Python package.\n","authors":["Mohamed Karim Belaid","Maximilian Rabus","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2406.20031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20006v1","updated":"2024-06-28T15:46:08Z","published":"2024-06-28T15:46:08Z","title":"On the Trade-off between Flatness and Optimization in Distributed\n  Learning","summary":"  This paper proposes a theoretical framework to evaluate and compare the\nperformance of gradient-descent algorithms for distributed learning in relation\nto their behavior around local minima in nonconvex environments. Previous works\nhave noticed that convergence toward flat local minima tend to enhance the\ngeneralization ability of learning algorithms. This work discovers two\ninteresting results. First, it shows that decentralized learning strategies are\nable to escape faster away from local minimizers and favor convergence toward\nflatter minima relative to the centralized solution in the large-batch training\nregime. Second, and importantly, the ultimate classification accuracy is not\nsolely dependent on the flatness of the local minimizer but also on how well a\nlearning algorithm can approach that minimum. In other words, the\nclassification accuracy is a function of both flatness and optimization\nperformance. The paper examines the interplay between the two measures of\nflatness and optimization error closely. One important conclusion is that\ndecentralized strategies of the diffusion type deliver enhanced classification\naccuracy because it strikes a more favorable balance between flatness and\noptimization performance.\n","authors":["Ying Cao","Zhaoxian Wu","Kun Yuan","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2406.20006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00035v3","updated":"2024-06-28T15:42:12Z","published":"2024-01-08T12:19:46Z","title":"Robustness Assessment of a Runway Object Classifier for Safe Aircraft\n  Taxiing","summary":"  As deep neural networks (DNNs) are becoming the prominent solution for many\ncomputational problems, the aviation industry seeks to explore their potential\nin alleviating pilot workload and in improving operational safety. However, the\nuse of DNNs in this type of safety-critical applications requires a thorough\ncertification process. This need can be addressed through formal verification,\nwhich provides rigorous assurances -- e.g.,~by proving the absence of certain\nmispredictions. In this case-study paper, we demonstrate this process using an\nimage-classifier DNN currently under development at Airbus and intended for use\nduring the aircraft taxiing phase. We use formal methods to assess this DNN's\nrobustness to three common image perturbation types: noise, brightness and\ncontrast, and some of their combinations. This process entails multiple\ninvocations of the underlying verifier, which might be computationally\nexpensive; and we therefore propose a method that leverages the monotonicity of\nthese robustness properties, as well as the results of past verification\nqueries, in order to reduce the overall number of verification queries required\nby nearly 60%. Our results provide an indication of the level of robustness\nachieved by the DNN classifier under study, and indicate that it is\nconsiderably more vulnerable to noise than to brightness or contrast\nperturbations.\n","authors":["Yizhak Elboher","Raya Elsaleh","Omri Isac","Mélanie Ducoffe","Audrey Galametz","Guillaume Povéda","Ryma Boumazouza","Noémie Cohen","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2402.00035v3.pdf","comment":"This is a preprint version of the paper in the proceedings of 43rd\n  Digital Avionics Systems Conference (DASC)"},{"id":"http://arxiv.org/abs/2402.04376v2","updated":"2024-06-28T15:36:50Z","published":"2024-02-06T20:30:19Z","title":"Scaling laws for learning with real and surrogate data","summary":"  Collecting large quantities of high-quality data can be prohibitively\nexpensive or impractical, and a bottleneck in machine learning. One may instead\naugment a small set of $n$ data points from the target distribution with data\nfrom more accessible sources, e.g. data collected under different circumstances\nor synthesized by generative models. We refer to such data as `surrogate data.'\nWe introduce a weighted empirical risk minimization (ERM) approach for\nintegrating surrogate data into training. We analyze mathematically this method\nunder several classical statistical models, and validate our findings\nempirically on datasets from different domains. Our main findings are: $(i)$\nIntegrating surrogate data can significantly reduce the test error on the\noriginal distribution. Surprisingly, this can happen even when the surrogate\ndata is unrelated to the original ones. We trace back this behavior to the\nclassical Stein's paradox. $(ii)$ In order to reap the benefit of surrogate\ndata, it is crucial to use optimally weighted ERM. $(iii)$ The test error of\nmodels trained on mixtures of real and surrogate data is approximately\ndescribed by a scaling law. This scaling law can be used to predict the optimal\nweighting scheme, and to choose the amount of surrogate data to add.\n","authors":["Ayush Jain","Andrea Montanari","Eren Sasoglu"],"pdf_url":"https://arxiv.org/pdf/2402.04376v2.pdf","comment":"Added new experiments"},{"id":"http://arxiv.org/abs/2405.14105v2","updated":"2024-06-28T15:34:26Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference of Large Language Models","summary":"  Accelerating the inference of large language models (LLMs) is an important\nchallenge in artificial intelligence. This paper introduces distributed\nspeculative inference (DSI), a novel distributed inference algorithm that is\nprovably faster than speculative inference (SI) [leviathan2023fast,\nchen2023accelerating, miao2023specinfer] and traditional autoregressive\ninference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,\nrequiring no training or architectural modifications, and it preserves the\ntarget distribution.\n  Prior studies on SI have demonstrated empirical speedups (compared to non-SI)\nbut require a fast and accurate drafter LLM. In practice, off-the-shelf LLMs\noften do not have matching drafters that are sufficiently fast and accurate. We\nshow a gap: SI gets slower than non-SI when using slower or less accurate\ndrafters. We close this gap by proving that DSI is faster than both SI and\nnon-SI given any drafters. By orchestrating multiple instances of the target\nand drafters, DSI is not only faster than SI but also supports LLMs that cannot\nbe accelerated with SI.\n  Our simulations show speedups of off-the-shelf LLMs in realistic settings:\nDSI is 1.29-1.92x faster than SI.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19997v1","updated":"2024-06-28T15:32:59Z","published":"2024-06-28T15:32:59Z","title":"Wavelets Are All You Need for Autoregressive Image Generation","summary":"  In this paper, we take a new approach to autoregressive image generation that\nis based on two main ingredients. The first is wavelet image coding, which\nallows to tokenize the visual details of an image from coarse to fine details\nby ordering the information starting with the most significant bits of the most\nsignificant wavelet coefficients. The second is a variant of a language\ntransformer whose architecture is re-designed and optimized for token sequences\nin this 'wavelet language'. The transformer learns the significant statistical\ncorrelations within a token sequence, which are the manifestations of\nwell-known correlations between the wavelet subbands at various resolutions. We\nshow experimental results with conditioning on the generation process.\n","authors":["Wael Mattar","Idan Levy","Nir Sharon","Shai Dekel"],"pdf_url":"https://arxiv.org/pdf/2406.19997v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2406.19995v1","updated":"2024-06-28T15:27:57Z","published":"2024-06-28T15:27:57Z","title":"Single Parent Family: A Spectrum of Family Members from a Single\n  Pre-Trained Foundation Model","summary":"  This paper introduces a novel method of Progressive Low Rank Decomposition\n(PLRD) tailored for the compression of large language models. Our approach\nleverages a pre-trained model, which is then incrementally decompressed to\nsmaller sizes using progressively lower ranks. This method allows for\nsignificant reductions in computational overhead and energy consumption, as\nsubsequent models are derived from the original without the need for retraining\nfrom scratch. We detail the implementation of PLRD, which strategically\ndecreases the tensor ranks, thus optimizing the trade-off between model\nperformance and resource usage. The efficacy of PLRD is demonstrated through\nextensive experiments showing that models trained with PLRD method on only 1B\ntokens maintain comparable performance with traditionally trained models while\nusing 0.1% of the tokens. The versatility of PLRD is highlighted by its ability\nto generate multiple model sizes from a single foundational model, adapting\nfluidly to varying computational and memory budgets. Our findings suggest that\nPLRD could set a new standard for the efficient scaling of LLMs, making\nadvanced AI more feasible on diverse platforms.\n","authors":["Habib Hajimolahoseini","Mohammad Hassanpour","Foozhan Ataiefard","Boxing Chen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2406.19995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00125v2","updated":"2024-06-28T15:17:05Z","published":"2023-11-30T19:00:02Z","title":"Scalable Bayesian uncertainty quantification with data-driven priors for\n  radio interferometric imaging","summary":"  Next-generation radio interferometers like the Square Kilometer Array have\nthe potential to unlock scientific discoveries thanks to their unprecedented\nangular resolution and sensitivity. One key to unlocking their potential\nresides in handling the deluge and complexity of incoming data. This challenge\nrequires building radio interferometric imaging methods that can cope with the\nmassive data sizes and provide high-quality image reconstructions with\nuncertainty quantification (UQ). This work proposes a method coined QuantifAI\nto address UQ in radio-interferometric imaging with data-driven (learned)\npriors for high-dimensional settings. Our model, rooted in the Bayesian\nframework, uses a physically motivated model for the likelihood. The model\nexploits a data-driven convex prior, which can encode complex information\nlearned implicitly from simulations and guarantee the log-concavity of the\nposterior. We leverage probability concentration phenomena of high-dimensional\nlog-concave posteriors that let us obtain information about the posterior,\navoiding MCMC sampling techniques. We rely on convex optimisation methods to\ncompute the MAP estimation, which is known to be faster and better scale with\ndimension than MCMC sampling strategies. Our method allows us to compute local\ncredible intervals, i.e., Bayesian error bars, and perform hypothesis testing\nof structure on the reconstructed image. In addition, we propose a novel\nblazing-fast method to compute pixel-wise uncertainties at different scales. We\ndemonstrate our method by reconstructing radio-interferometric images in a\nsimulated setting and carrying out fast and scalable UQ, which we validate with\nMCMC sampling. Our method shows an improved image quality and more meaningful\nuncertainties than the benchmark method based on a sparsity-promoting prior.\nQuantifAI's source code: https://github.com/astro-informatics/QuantifAI.\n","authors":["Tobías I. Liaudat","Matthijs Mars","Matthew A. Price","Marcelo Pereyra","Marta M. Betcke","Jason D. McEwen"],"pdf_url":"https://arxiv.org/pdf/2312.00125v2.pdf","comment":"30 pages, 14 figures, 10 tables, code available at\n  https://github.com/astro-informatics/QuantifAI"},{"id":"http://arxiv.org/abs/2402.11658v2","updated":"2024-06-28T15:16:53Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behavior could be explained in terms of an active\ninferential process - either as discrete decision-making or continuous motor\ncontrol - inspiring innovative solutions in robotics and artificial\nintelligence. Still, the literature lacks a comprehensive outlook on how to\neffectively plan actions in changing environments. Setting ourselves the goal\nof modeling tool use, we delve into the topic of dynamic planning in active\ninference, keeping in mind two crucial aspects of biological goal-directed\nbehavior: the capacity to understand and exploit affordances for object\nmanipulation, and to learn the hierarchical interactions between the self and\nthe environment, including other agents. We start from a simple unit and\ngradually describe more advanced structures, comparing recently proposed design\nchoices and providing basic examples for each section. This study distances\nitself from traditional views centered on neural networks and reinforcement\nlearning, and points toward a yet unexplored direction in active inference:\nhybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19983v1","updated":"2024-06-28T15:15:01Z","published":"2024-06-28T15:15:01Z","title":"Machine Learning Predictors for Min-Entropy Estimation","summary":"  This study investigates the application of machine learning predictors for\nmin-entropy estimation in Random Number Generators (RNGs), a key component in\ncryptographic applications where accurate entropy assessment is essential for\ncybersecurity. Our research indicates that these predictors, and indeed any\npredictor that leverages sequence correlations, primarily estimate average\nmin-entropy, a metric not extensively studied in this context. We explore the\nrelationship between average min-entropy and the traditional min-entropy,\nfocusing on their dependence on the number of target bits being predicted.\nUtilizing data from Generalized Binary Autoregressive Models, a subset of\nMarkov processes, we demonstrate that machine learning models (including a\nhybrid of convolutional and recurrent Long Short-Term Memory layers and the\ntransformer-based GPT-2 model) outperform traditional NIST SP 800-90B\npredictors in certain scenarios. Our findings underscore the importance of\nconsidering the number of target bits in min-entropy assessment for RNGs and\nhighlight the potential of machine learning approaches in enhancing entropy\nestimation techniques for improved cryptographic security.\n","authors":["Javier Blanco-Romero","Vicente Lorenzo","Florina Almenares Mendoza","Daniel Díaz-Sánchez"],"pdf_url":"https://arxiv.org/pdf/2406.19983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03913v2","updated":"2024-06-28T15:13:15Z","published":"2024-05-07T00:22:13Z","title":"Digital Twin Calibration for Biological System-of-Systems: Cell Culture\n  Manufacturing Process","summary":"  Biomanufacturing innovation relies on an efficient Design of Experiments\n(DoEs) to optimize processes and product quality. Traditional DoE methods,\nignoring the underlying bioprocessing mechanisms, often suffer from a lack of\ninterpretability and sample efficiency. This limitation motivates us to create\na new optimal learning approach for digital twin model calibration. In this\nstudy, we consider the cell culture process multi-scale mechanistic model, also\nknown as Biological System-of-Systems (Bio-SoS). This model with a modular\ndesign, composed of sub-models, allows us to integrate data across various\nproduction processes. To calibrate the Bio-SoS digital twin, we evaluate the\nmean squared error of model prediction and develop a computational approach to\nquantify the impact of parameter estimation error of individual sub-models on\nthe prediction accuracy of digital twin, which can guide sample-efficient and\ninterpretable DoEs.\n","authors":["Fuqiang Cheng","Wei Xie","Hua Zheng"],"pdf_url":"https://arxiv.org/pdf/2405.03913v2.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2312.09969v2","updated":"2024-06-28T15:10:53Z","published":"2023-12-15T17:28:09Z","title":"Nearest Neighbor Sampling for Covariate Shift Adaptation","summary":"  Many existing covariate shift adaptation methods estimate sample weights\ngiven to loss values to mitigate the gap between the source and the target\ndistribution. However, estimating the optimal weights typically involves\ncomputationally expensive matrix inversion and hyper-parameter tuning. In this\npaper, we propose a new covariate shift adaptation method which avoids\nestimating the weights. The basic idea is to directly work on unlabeled target\ndata, labeled according to the $k$-nearest neighbors in the source dataset. Our\nanalysis reveals that setting $k = 1$ is an optimal choice. This property\nremoves the necessity of tuning the only hyper-parameter $k$ and leads to a\nrunning time quasi-linear in the sample size. Our results include sharp rates\nof convergence for our estimator, with a tight control of the mean square error\nand explicit constants. In particular, the variance of our estimators has the\nsame rate of convergence as for standard parametric estimation despite their\nnon-parametric nature. The proposed estimator shares similarities with some\nmatching-based treatment effect estimators used, e.g., in biostatistics,\neconometrics, and epidemiology. Our experiments show that it achieves drastic\nreduction in the running time with remarkable accuracy.\n","authors":["François Portier","Lionel Truquet","Ikko Yamane"],"pdf_url":"https://arxiv.org/pdf/2312.09969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19980v1","updated":"2024-06-28T15:06:22Z","published":"2024-06-28T15:06:22Z","title":"Comparative Analysis of LSTM Neural Networks and Traditional Machine\n  Learning Models for Predicting Diabetes Patient Readmission","summary":"  Diabetes mellitus is a chronic metabolic disorder that has emerged as one of\nthe major health problems worldwide due to its high prevalence and serious\ncomplications, which are pricey to manage. Effective management requires good\nglycemic control and regular follow-up in the clinic; however, non-adherence to\nscheduled follow-ups is very common. This study uses the Diabetes 130-US\nHospitals dataset for analysis and prediction of readmission patients by\nvarious traditional machine learning models, such as XGBoost, LightGBM,\nCatBoost, Decision Tree, and Random Forest, and also uses an in-house LSTM\nneural network for comparison. The quality of the data was assured by\npreprocessing it, and the performance evaluation for all these models was based\non accuracy, precision, recall, and F1-score. LightGBM turned out to be the\nbest traditional model, while XGBoost was the runner-up. The LSTM model\nsuffered from overfitting despite high training accuracy. A major strength of\nLSTM is capturing temporal dependencies among the patient data. Further, SHAP\nvalues were used, which improved model interpretability, whereby key factors\namong them number of lab procedures and discharge disposition were identified\nas critical in the prediction of readmissions. This study demonstrates that\nmodel selection, validation, and interpretability are key steps in predictive\nhealthcare modeling. This will help health providers design interventions for\nimproved follow-up adherence and better management of diabetes.\n","authors":["Abolfazl Zarghani"],"pdf_url":"https://arxiv.org/pdf/2406.19980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19976v1","updated":"2024-06-28T15:03:08Z","published":"2024-06-28T15:03:08Z","title":"ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting","summary":"  Bilevel optimization has shown its utility across various machine learning\nsettings, yet most algorithms in practice require second-order information,\nmaking it challenging to scale them up. Only recently, a paradigm of\nfirst-order algorithms emerged, capable of effectively addressing bilevel\noptimization problems. Nevertheless, the practical efficiency of this paradigm\nremains unverified, particularly in the context of large language models\n(LLMs). This paper introduces the first scalable instantiation of this paradigm\ncalled ScaleBiO, focusing on bilevel optimization for large-scale LLM data\nreweighting. By combining with a recently proposed memory-efficient training\ntechnique called LISA, our novel algorithm allows the paradigm to scale to\n34-billion-parameter LLMs on eight A40 GPUs, marking the first successful\napplication of bilevel optimization under practical scenarios for large-sized\nLLMs. Empirically, extensive experiments on data reweighting verify the\neffectiveness of ScaleBiO for different-scaled models, including GPT-2,\nLLaMA-3-8B, GPT-NeoX-20B, and Yi-34B, where bilevel optimization succeeds in\nfiltering irrelevant data samples and selecting informative samples.\nTheoretically, ScaleBiO ensures the optimality of the learned data weights,\nalong with a convergence guarantee matching the conventional first-order\nbilevel optimization paradigm on smooth and strongly convex objectives.\n","authors":["Rui Pan","Jipeng Zhang","Xingyuan Pan","Renjie Pi","Xiaoyu Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.19976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19973v1","updated":"2024-06-28T15:01:23Z","published":"2024-06-28T15:01:23Z","title":"STLLaVA-Med: Self-Training Large Language and Vision Assistant for\n  Medical","summary":"  Large Vision-Language Models (LVLMs) have shown significant potential in\nassisting medical diagnosis by leveraging extensive biomedical datasets.\nHowever, the advancement of medical image understanding and reasoning\ncritically depends on building high-quality visual instruction data, which is\ncostly and labor-intensive to obtain, particularly in the medical domain. To\nmitigate this data-starving issue, we introduce Self-Training Large Language\nand Vision Assistant for Medical (STLLaVA-Med). The proposed method is designed\nto train a policy model (an LVLM) capable of auto-generating medical visual\ninstruction data to improve data efficiency, guided through Direct Preference\nOptimization (DPO). Specifically, a more powerful and larger LVLM (e.g.,\nGPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuning\nprocess on the auto-generated data, encouraging the policy model to align\nefficiently with human preferences. We validate the efficacy and data\nefficiency of STLLaVA-Med across three major medical Visual Question Answering\n(VQA) benchmarks, demonstrating competitive zero-shot performance with the\nutilization of only 9% of the medical data.\n","authors":["Guohao Sun","Can Qin","Huazhu Fu","Linwei Wang","Zhiqiang Tao"],"pdf_url":"https://arxiv.org/pdf/2406.19973v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.19963v1","updated":"2024-06-28T14:51:01Z","published":"2024-06-28T14:51:01Z","title":"Text2Robot: Evolutionary Robot Design from Text Descriptions","summary":"  Robot design has traditionally been costly and labor-intensive. Despite\nadvancements in automated processes, it remains challenging to navigate a vast\ndesign space while producing physically manufacturable robots. We introduce\nText2Robot, a framework that converts user text specifications and performance\npreferences into physical quadrupedal robots. Within minutes, Text2Robot can\nuse text-to-3D models to provide strong initializations of diverse\nmorphologies. Within a day, our geometric processing algorithms and\nbody-control co-optimization produce a walking robot by explicitly considering\nreal-world electronics and manufacturability. Text2Robot enables rapid\nprototyping and opens new opportunities for robot design with generative\nmodels.\n","authors":["Ryan P. Ringel","Zachary S. Charlick","Jiaxun Liu","Boxi Xia","Boyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19963v1.pdf","comment":"Our project website is at: https://generalroboticslab.com/Text2Robot"},{"id":"http://arxiv.org/abs/2406.19958v1","updated":"2024-06-28T14:45:29Z","published":"2024-06-28T14:45:29Z","title":"The Computational Curse of Big Data for Bayesian Additive Regression\n  Trees: A Hitting Time Analysis","summary":"  Bayesian Additive Regression Trees (BART) is a popular Bayesian\nnon-parametric regression model that is commonly used in causal inference and\nbeyond. Its strong predictive performance is supported by theoretical\nguarantees that its posterior distribution concentrates around the true\nregression function at optimal rates under various data generative settings and\nfor appropriate prior choices. In this paper, we show that the BART sampler\noften converges slowly, confirming empirical observations by other researchers.\nAssuming discrete covariates, we show that, while the BART posterior\nconcentrates on a set comprising all optimal tree structures (smallest bias and\ncomplexity), the Markov chain's hitting time for this set increases with $n$\n(training sample size), under several common data generative settings. As $n$\nincreases, the approximate BART posterior thus becomes increasingly different\nfrom the exact posterior (for the same number of MCMC samples), contrasting\nwith earlier concentration results on the exact posterior. This contrast is\nhighlighted by our simulations showing worsening frequentist undercoverage for\napproximate posterior intervals and a growing ratio between the MSE of the\napproximate posterior and that obtainable by artificially improving convergence\nvia averaging multiple sampler chains. Finally, based on our theoretical\ninsights, possibilities are discussed to improve the BART sampler convergence\nperformance.\n","authors":["Yan Shuo Tan","Omer Ronen","Theo Saarinen","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2406.19958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19948v1","updated":"2024-06-28T14:30:14Z","published":"2024-06-28T14:30:14Z","title":"Kolmogorov-Smirnov GAN","summary":"  We propose a novel deep generative model, the Kolmogorov-Smirnov Generative\nAdversarial Network (KSGAN). Unlike existing approaches, KSGAN formulates the\nlearning process as a minimization of the Kolmogorov-Smirnov (KS) distance,\ngeneralized to handle multivariate distributions. This distance is calculated\nusing the quantile function, which acts as the critic in the adversarial\ntraining process. We formally demonstrate that minimizing the KS distance leads\nto the trained approximate distribution aligning with the target distribution.\nWe propose an efficient implementation and evaluate its effectiveness through\nexperiments. The results show that KSGAN performs on par with existing\nadversarial methods, exhibiting stability during training, resistance to mode\ndropping and collapse, and tolerance to variations in hyperparameter settings.\nAdditionally, we review the literature on the Generalized KS test and discuss\nthe connections between KSGAN and existing adversarial generative models.\n","authors":["Maciej Falkiewicz","Naoya Takeishi","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2406.19948v1.pdf","comment":"Code available at https://github.com/DMML-Geneva/ksgan"},{"id":"http://arxiv.org/abs/2402.05758v2","updated":"2024-06-28T14:27:29Z","published":"2024-02-08T15:41:48Z","title":"Latent variable model for high-dimensional point process with structured\n  missingness","summary":"  Longitudinal data are important in numerous fields, such as healthcare,\nsociology and seismology, but real-world datasets present notable challenges\nfor practitioners because they can be high-dimensional, contain structured\nmissingness patterns, and measurement time points can be governed by an unknown\nstochastic process. While various solutions have been suggested, the majority\nof them have been designed to account for only one of these challenges. In this\nwork, we propose a flexible and efficient latent-variable model that is capable\nof addressing all these limitations. Our approach utilizes Gaussian processes\nto capture temporal correlations between samples and their associated\nmissingness masks as well as to model the underlying point process. We\nconstruct our model as a variational autoencoder together with deep neural\nnetwork parameterised encoder and decoder models, and develop a scalable\namortised variational inference approach for efficient model training. We\ndemonstrate competitive performance using both simulated and real datasets.\n","authors":["Maksim Sinelnikov","Manuel Haussmann","Harri Lähdesmäki"],"pdf_url":"https://arxiv.org/pdf/2402.05758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15612v2","updated":"2024-06-28T14:23:49Z","published":"2024-06-21T19:27:46Z","title":"Catastrophic-risk-aware reinforcement learning with\n  extreme-value-theory-based policy gradients","summary":"  This paper tackles the problem of mitigating catastrophic risk (which is risk\nwith very low frequency but very high severity) in the context of a sequential\ndecision making process. This problem is particularly challenging due to the\nscarcity of observations in the far tail of the distribution of cumulative\ncosts (negative rewards). A policy gradient algorithm is developed, that we\ncall POTPG. It is based on approximations of the tail risk derived from extreme\nvalue theory. Numerical experiments highlight the out-performance of our method\nover common benchmarks, relying on the empirical distribution. An application\nto financial risk management, more precisely to the dynamic hedging of a\nfinancial option, is presented.\n","authors":["Parisa Davar","Frédéric Godin","Jose Garrido"],"pdf_url":"https://arxiv.org/pdf/2406.15612v2.pdf","comment":"The Python code to replicate the various numerical experiments of\n  this paper is available at\n  https://github.com/parisadavar/EVT-policy-gradient-RL"},{"id":"http://arxiv.org/abs/2312.00592v2","updated":"2024-06-28T14:02:06Z","published":"2023-12-01T13:56:28Z","title":"Tracking Object Positions in Reinforcement Learning: A Metric for\n  Keypoint Detection (extended version)","summary":"  Reinforcement learning (RL) for robot control typically requires a detailed\nrepresentation of the environment state, including information about\ntask-relevant objects not directly measurable. Keypoint detectors, such as\nspatial autoencoders (SAEs), are a common approach to extracting a\nlow-dimensional representation from high-dimensional image data. SAEs aim at\nspatial features such as object positions, which are often useful\nrepresentations in robotic RL. However, whether an SAE is actually able to\ntrack objects in the scene and thus yields a spatial state representation well\nsuited for RL tasks has rarely been examined due to a lack of established\nmetrics. In this paper, we propose to assess the performance of an SAE instance\nby measuring how well keypoints track ground truth objects in images. We\npresent a computationally lightweight metric and use it to evaluate common\nbaseline SAE architectures on image data from a simulated robot task. We find\nthat common SAEs differ substantially in their spatial extraction capability.\nFurthermore, we validate that SAEs that perform well in our metric achieve\nsuperior performance when used in downstream RL. Thus, our metric is an\neffective and lightweight indicator of RL performance before executing\nexpensive RL training. Building on these insights, we identify three key\nmodifications of SAE architectures to improve tracking performance. We make our\ncode available at anonymous.4open.science/r/sae-rl.\n","authors":["Emma Cramer","Jonas Reiher","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2312.00592v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19931v1","updated":"2024-06-28T14:01:22Z","published":"2024-06-28T14:01:22Z","title":"Decoupling General and Personalized Knowledge in Federated Learning via\n  Additive and Low-Rank Decomposition","summary":"  To address data heterogeneity, the key strategy of Personalized Federated\nLearning (PFL) is to decouple general knowledge (shared among clients) and\nclient-specific knowledge, as the latter can have a negative impact on\ncollaboration if not removed. Existing PFL methods primarily adopt a parameter\npartitioning approach, where the parameters of a model are designated as one of\ntwo types: parameters shared with other clients to extract general knowledge\nand parameters retained locally to learn client-specific knowledge. However, as\nthese two types of parameters are put together like a jigsaw puzzle into a\nsingle model during the training process, each parameter may simultaneously\nabsorb both general and client-specific knowledge, thus struggling to separate\nthe two types of knowledge effectively. In this paper, we introduce FedDecomp,\na simple but effective PFL paradigm that employs parameter additive\ndecomposition to address this issue. Instead of assigning each parameter of a\nmodel as either a shared or personalized one, FedDecomp decomposes each\nparameter into the sum of two parameters: a shared one and a personalized one,\nthus achieving a more thorough decoupling of shared and personalized knowledge\ncompared to the parameter partitioning method. In addition, as we find that\nretaining local knowledge of specific clients requires much lower model\ncapacity compared with general knowledge across all clients, we let the matrix\ncontaining personalized parameters be low rank during the training process.\nMoreover, a new alternating training strategy is proposed to further improve\nthe performance. Experimental results across multiple datasets and varying\ndegrees of data heterogeneity demonstrate that FedDecomp outperforms\nstate-of-the-art methods up to 4.9\\%.\n","authors":["Xinghao Wu","Xuefeng Liu","Jianwei Niu","Haolin Wang","Shaojie Tang","Guogang Zhu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2406.19931v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.17001v4","updated":"2024-06-28T13:40:00Z","published":"2023-03-29T20:07:07Z","title":"The G-invariant graph Laplacian","summary":"  Graph Laplacian based algorithms for data lying on a manifold have been\nproven effective for tasks such as dimensionality reduction, clustering, and\ndenoising. In this work, we consider data sets whose data points lie on a\nmanifold that is closed under the action of a known unitary matrix Lie group G.\nWe propose to construct the graph Laplacian by incorporating the distances\nbetween all the pairs of points generated by the action of G on the data set.\nWe deem the latter construction the ``G-invariant Graph Laplacian'' (G-GL). We\nshow that the G-GL converges to the Laplace-Beltrami operator on the data\nmanifold, while enjoying a significantly improved convergence rate compared to\nthe standard graph Laplacian which only utilizes the distances between the\npoints in the given data set. Furthermore, we show that the G-GL admits a set\nof eigenfunctions that have the form of certain products between the group\nelements and eigenvectors of certain matrices, which can be estimated from the\ndata efficiently using FFT-type algorithms. We demonstrate our construction and\nits advantages on the problem of filtering data on a noisy manifold closed\nunder the action of the special unitary group SU(2).\n","authors":["Eitan Rosen","Paulina Hoyos","Xiuyuan Cheng","Joe Kileel","Yoel Shkolnisky"],"pdf_url":"https://arxiv.org/pdf/2303.17001v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08498v3","updated":"2024-06-28T13:31:48Z","published":"2024-05-14T10:55:04Z","title":"Learning Decision Policies with Instrumental Variables through Double\n  Machine Learning","summary":"  A common issue in learning decision-making policies in data-rich settings is\nspurious correlations in the offline dataset, which can be caused by hidden\nconfounders. Instrumental variable (IV) regression, which utilises a key\nunconfounded variable known as the instrument, is a standard technique for\nlearning causal relationships between confounded action, outcome, and context\nvariables. Most recent IV regression algorithms use a two-stage approach, where\na deep neural network (DNN) estimator learnt in the first stage is directly\nplugged into the second stage, in which another DNN is used to estimate the\ncausal effect. Naively plugging the estimator can cause heavy bias in the\nsecond stage, especially when regularisation bias is present in the first stage\nestimator. We propose DML-IV, a non-linear IV regression method that reduces\nthe bias in two-stage IV regressions and effectively learns high-performing\npolicies. We derive a novel learning objective to reduce bias and design the\nDML-IV algorithm following the double/debiased machine learning (DML)\nframework. The learnt DML-IV estimator has strong convergence rate and\n$O(N^{-1/2})$ suboptimality guarantees that match those when the dataset is\nunconfounded. DML-IV outperforms state-of-the-art IV regression methods on IV\nregression benchmarks and learns high-performing policies in the presence of\ninstruments.\n","authors":["Daqian Shao","Ashkan Soleymani","Francesco Quinzan","Marta Kwiatkowska"],"pdf_url":"https://arxiv.org/pdf/2405.08498v3.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2406.17295v2","updated":"2024-06-28T13:28:04Z","published":"2024-06-25T05:45:07Z","title":"MatText: Do Language Models Need More than Text & Scale for Materials\n  Modeling?","summary":"  Effectively representing materials as text has the potential to leverage the\nvast advancements of large language models (LLMs) for discovering new\nmaterials. While LLMs have shown remarkable success in various domains, their\napplication to materials science remains underexplored. A fundamental challenge\nis the lack of understanding of how to best utilize text-based representations\nfor materials modeling. This challenge is further compounded by the absence of\na comprehensive benchmark to rigorously evaluate the capabilities and\nlimitations of these text representations in capturing the complexity of\nmaterial systems. To address this gap, we propose MatText, a suite of\nbenchmarking tools and datasets designed to systematically evaluate the\nperformance of language models in modeling materials. MatText encompasses nine\ndistinct text-based representations for material systems, including several\nnovel representations. Each representation incorporates unique inductive biases\nthat capture relevant information and integrate prior physical knowledge about\nmaterials. Additionally, MatText provides essential tools for training and\nbenchmarking the performance of language models in the context of materials\nscience. These tools include standardized dataset splits for each\nrepresentation, probes for evaluating sensitivity to geometric factors, and\ntools for seamlessly converting crystal structures into text. Using MatText, we\nconduct an extensive analysis of the capabilities of language models in\nmodeling materials. Our findings reveal that current language models\nconsistently struggle to capture the geometric information crucial for\nmaterials modeling across all representations. Instead, these models tend to\nleverage local information, which is emphasized in some of our novel\nrepresentations. Our analysis underscores MatText's ability to reveal\nshortcomings of text-based methods for materials design.\n","authors":["Nawaf Alampara","Santiago Miret","Kevin Maik Jablonka"],"pdf_url":"https://arxiv.org/pdf/2406.17295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01317v2","updated":"2024-06-28T13:27:36Z","published":"2024-06-03T13:29:36Z","title":"The Intelligible and Effective Graph Neural Additive Networks","summary":"  Graph Neural Networks (GNNs) have emerged as the predominant approach for\nlearning over graph-structured data. However, most GNNs operate as black-box\nmodels and require post-hoc explanations, which may not suffice in high-stakes\nscenarios where transparency is crucial. In this paper, we present a GNN that\nis interpretable by design. Our model, Graph Neural Additive Network (GNAN), is\na novel extension of the interpretable class of Generalized Additive Models,\nand can be visualized and fully understood by humans. GNAN is designed to be\nfully interpretable, allowing both global and local explanations at the feature\nand graph levels through direct visualization of the model. These\nvisualizations describe the exact way the model uses the relationships between\nthe target variable, the features, and the graph. We demonstrate the\nintelligibility of GNANs in a series of examples on different tasks and\ndatasets. In addition, we show that the accuracy of GNAN is on par with\nblack-box GNNs, making it suitable for critical applications where transparency\nis essential, alongside high accuracy.\n","authors":["Maya Bechler-Speicher","Amir Globerson","Ran Gilad-Bachrach"],"pdf_url":"https://arxiv.org/pdf/2406.01317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14862v3","updated":"2024-06-28T13:19:37Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\nLatentExplainer, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\nLatentExplainer tackles three main challenges: inferring the meaning of latent\nvariables, aligning explanations with inductive biases, and handling varying\ndegrees of explainability. By perturbing latent variables and interpreting\nchanges in generated data, the framework provides a systematic approach to\nunderstanding and controlling the data generation process, enhancing the\ntransparency and interpretability of deep generative models. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations of\nlatent variables.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07049v2","updated":"2024-06-28T13:14:13Z","published":"2024-04-10T14:38:58Z","title":"Towards Learning Stochastic Population Models by Gradient Descent","summary":"  Increasing effort is put into the development of methods for learning\nmechanistic models from data. This task entails not only the accurate\nestimation of parameters but also a suitable model structure. Recent work on\nthe discovery of dynamical systems formulates this problem as a linear equation\nsystem. Here, we explore several simulation-based optimization approaches,\nwhich allow much greater freedom in the objective formulation and weaker\nconditions on the available data. We show that even for relatively small\nstochastic population models, simultaneous estimation of parameters and\nstructure poses major challenges for optimization procedures. Particularly, we\ninvestigate the application of the local stochastic gradient descent method,\ncommonly used for training machine learning models. We demonstrate accurate\nestimation of models but find that enforcing the inference of parsimonious,\ninterpretable models drastically increases the difficulty. We give an outlook\non how this challenge can be overcome.\n","authors":["Justin N. Kreikemeyer","Philipp Andelfinger","Adelinde M. Uhrmacher"],"pdf_url":"https://arxiv.org/pdf/2404.07049v2.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.19900v1","updated":"2024-06-28T13:10:13Z","published":"2024-06-28T13:10:13Z","title":"`Just One More Sensor is Enough' -- Iterative Water Leak Localization\n  with Physical Simulation and a Small Number of Pressure Sensors","summary":"  In this article, we propose an approach to leak localisation in a complex\nwater delivery grid with the use of data from physical simulation (e.g. EPANET\nsoftware). This task is usually achieved by a network of multiple water\npressure sensors and analysis of the so-called sensitivity matrix of pressure\ndifferences between the network's simulated data and actual data of the network\naffected by the leak. However, most algorithms using this approach require a\nsignificant number of pressure sensors -- a condition that is not easy to\nfulfil in the case of many less equipped networks. Therefore, we answer the\nquestion of whether leak localisation is possible by utilising very few sensors\nbut having the ability to relocate one of them. Our algorithm is based on\nphysical simulations (EPANET software) and an iterative scheme for mobile\nsensor relocation. The experiments show that the proposed system can equalise\nthe low number of sensors with adjustments made for their positioning, giving a\nvery good approximation of leak's position both in simulated cases and\nreal-life example taken from BattLeDIM competition L-Town data.\n","authors":["Michał Cholewa","Michał Romaszewski","Przemysław Głomb","Katarzyna Kołodziej","Michał Gorawski","Jakub Koral","Wojciech Koral","Andrzej Madej","Kryspin Musioł"],"pdf_url":"https://arxiv.org/pdf/2406.19900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19897v1","updated":"2024-06-28T13:05:17Z","published":"2024-06-28T13:05:17Z","title":"FI-CBL: A Probabilistic Method for Concept-Based Learning with Expert\n  Rules","summary":"  A method for solving concept-based learning (CBL) problem is proposed. The\nmain idea behind the method is to divide each concept-annotated image into\npatches, to transform the patches into embeddings by using an autoencoder, and\nto cluster the embeddings assuming that each cluster will mainly contain\nembeddings of patches with certain concepts. To find concepts of a new image,\nthe method implements the frequentist inference by computing prior and\nposterior probabilities of concepts based on rates of patches from images with\ncertain values of the concepts. Therefore, the proposed method is called the\nFrequentist Inference CBL (FI-CBL). FI-CBL allows us to incorporate the expert\nrules in the form of logic functions into the inference procedure. An idea\nbehind the incorporation is to update prior and conditional probabilities of\nconcepts to satisfy the rules. The method is transparent because it has an\nexplicit sequence of probabilistic calculations and a clear frequency\ninterpretation. Numerical experiments show that FI-CBL outperforms the concept\nbottleneck model in cases when the number of training data is small. The code\nof proposed algorithms is publicly available.\n","authors":["Lev V. Utkin","Andrei V. Konstantinov","Stanislav R. Kirpichenko"],"pdf_url":"https://arxiv.org/pdf/2406.19897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.02029v3","updated":"2024-06-28T13:02:49Z","published":"2023-08-03T20:45:11Z","title":"Deep Maxout Network-based Feature Fusion and Political Tangent Search\n  Optimizer enabled Transfer Learning for Thalassemia Detection","summary":"  Thalassemia is a heritable blood disorder which is the outcome of a genetic\ndefect causing lack of production of hemoglobin polypeptide chains. However,\nthere is less understanding of the precise frequency as well as sharing in\nthese areas. Knowing about the frequency of thalassemia occurrence and\ndependable mutations is thus a significant step in preventing, controlling, and\ntreatment planning. Here, Political Tangent Search Optimizer based Transfer\nLearning (PTSO_TL) is introduced for thalassemia detection. Initially, input\ndata obtained from a particular dataset is normalized in the data normalization\nstage. Quantile normalization is utilized in the data normalization stage, and\nthe data are then passed to the feature fusion phase, in which Weighted\nEuclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data\naugmentation is performed using the oversampling method to increase data\ndimensionality. Lastly, thalassemia detection is carried out by TL, wherein a\nconvolutional neural network (CNN) is utilized with hyperparameters from a\ntrained model such as Xception. TL is tuned by PTSO, and the training algorithm\nPTSO is presented by merging of Political Optimizer (PO) and Tangent Search\nAlgorithm (TSA). Furthermore, PTSO_TL obtained maximal precision, recall, and\nf-measure values of about 94.3%, 96.1%, and 95.2%, respectively.\n","authors":["Hemn Barzan Abdalla","Awder Ahmed","Guoquan Li","Nasser Mustafa","Abdur Rashid Sangi"],"pdf_url":"https://arxiv.org/pdf/2308.02029v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03565v3","updated":"2024-06-28T12:55:35Z","published":"2023-07-07T12:57:10Z","title":"MALIBO: Meta-learning for Likelihood-free Bayesian Optimization","summary":"  Bayesian optimization (BO) is a popular method to optimize costly black-box\nfunctions. While traditional BO optimizes each new target task from scratch,\nmeta-learning has emerged as a way to leverage knowledge from related tasks to\noptimize new tasks faster. However, existing meta-learning BO methods rely on\nsurrogate models that suffer from scalability issues and are sensitive to\nobservations with different scales and noise types across tasks. Moreover, they\noften overlook the uncertainty associated with task similarity. This leads to\nunreliable task adaptation when only limited observations are obtained or when\nthe new tasks differ significantly from the related tasks. To address these\nlimitations, we propose a novel meta-learning BO approach that bypasses the\nsurrogate model and directly learns the utility of queries across tasks. Our\nmethod explicitly models task uncertainty and includes an auxiliary model to\nenable robust adaptation to new tasks. Extensive experiments show that our\nmethod demonstrates strong anytime performance and outperforms state-of-the-art\nmeta-learning BO methods in various benchmarks.\n","authors":["Jiarong Pan","Stefan Falkner","Felix Berkenkamp","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2307.03565v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18328v2","updated":"2024-06-28T12:45:52Z","published":"2024-06-26T13:16:40Z","title":"PDFA Distillation via String Probability Queries","summary":"  Probabilistic deterministic finite automata (PDFA) are discrete event systems\nmodeling conditional probabilities over languages: Given an already seen\nsequence of tokens they return the probability of tokens of interest to appear\nnext. These types of models have gained interest in the domain of explainable\nmachine learning, where they are used as surrogate models for neural networks\ntrained as language models. In this work we present an algorithm to distill\nPDFA from neural networks. Our algorithm is a derivative of the L# algorithm\nand capable of learning PDFA from a new type of query, in which the algorithm\ninfers conditional probabilities from the probability of the queried string to\noccur. We show its effectiveness on a recent public dataset by distilling PDFA\nfrom a set of trained neural networks.\n","authors":["Robert Baumgartner","Sicco Verwer"],"pdf_url":"https://arxiv.org/pdf/2406.18328v2.pdf","comment":"LearnAUT 2024"},{"id":"http://arxiv.org/abs/2406.19881v1","updated":"2024-06-28T12:44:01Z","published":"2024-06-28T12:44:01Z","title":"Attention Meets UAVs: A Comprehensive Evaluation of DDoS Detection in\n  Low-Cost UAVs","summary":"  This paper explores the critical issue of enhancing cybersecurity measures\nfor low-cost, Wi-Fi-based Unmanned Aerial Vehicles (UAVs) against Distributed\nDenial of Service (DDoS) attacks. In the current work, we have explored three\nvariants of DDoS attacks, namely Transmission Control Protocol (TCP), Internet\nControl Message Protocol (ICMP), and TCP + ICMP flooding attacks, and developed\na detection mechanism that runs on the companion computer of the UAV system. As\na part of the detection mechanism, we have evaluated various machine learning,\nand deep learning algorithms, such as XGBoost, Isolation Forest, Long\nShort-Term Memory (LSTM), Bidirectional-LSTM (Bi-LSTM), LSTM with attention,\nBi-LSTM with attention, and Time Series Transformer (TST) in terms of various\nclassification metrics. Our evaluation reveals that algorithms with attention\nmechanisms outperform their counterparts in general, and TST stands out as the\nmost efficient model with a run time of 0.1 seconds. TST has demonstrated an F1\nscore of 0.999, 0.997, and 0.943 for TCP, ICMP, and TCP + ICMP flooding attacks\nrespectively. In this work, we present the necessary steps required to build an\non-board DDoS detection mechanism. Further, we also present the ablation study\nto identify the best TST hyperparameters for DDoS detection, and we have also\nunderscored the advantage of adapting learnable positional embeddings in TST\nfor DDoS detection with an improvement in F1 score from 0.94 to 0.99.\n","authors":["Ashish Sharma","SVSLN Surya Suhas Vaddhiparthy","Sai Usha Goparaju","Deepak Gangadharan","Harikumar Kandath"],"pdf_url":"https://arxiv.org/pdf/2406.19881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19871v1","updated":"2024-06-28T12:26:28Z","published":"2024-06-28T12:26:28Z","title":"Koopman based trajectory model and computation offloading for high\n  mobility paradigm in ISAC enabled IoT system","summary":"  User experience on mobile devices is constrained by limited battery capacity\nand processing power, but 6G technology advancements are diving rapidly into\nmobile technical evolution. Mobile edge computing (MEC) offers a solution,\noffloading computationally intensive tasks to edge cloud servers, reducing\nbattery drain compared to local processing. The upcoming integrated sensing and\ncommunication in mobile communication may improve the trajectory prediction and\nprocessing delays. This study proposes a greedy resource allocation\noptimization strategy for multi-user networks to minimize aggregate energy\nusage. Numerical results show potential improvement at 33\\% for every 1000\niteration. Addressing prediction model division and velocity accuracy issues is\ncrucial for better results. A plan for further improvement and achieving\nobjectives is outlined for the upcoming work phase.\n","authors":["Minh-Tuan Tran"],"pdf_url":"https://arxiv.org/pdf/2406.19871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19861v1","updated":"2024-06-28T12:05:47Z","published":"2024-06-28T12:05:47Z","title":"Operator World Models for Reinforcement Learning","summary":"  Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology\nfor sequential decision-making. However, it is not directly applicable to\nReinforcement Learning (RL) due to the inaccessibility of explicit action-value\nfunctions. We address this challenge by introducing a novel approach based on\nlearning a world model of the environment using conditional mean embeddings. We\nthen leverage the operatorial formulation of RL to express the action-value\nfunction in terms of this quantity in closed form via matrix operations.\nCombining these estimators with PMD leads to POWR, a new RL algorithm for which\nwe prove convergence rates to the global optimum. Preliminary experiments in\nfinite and infinite state settings support the effectiveness of our method.\n","authors":["Pietro Novelli","Marco Pratticò","Massimiliano Pontil","Carlo Ciliberto"],"pdf_url":"https://arxiv.org/pdf/2406.19861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13699v2","updated":"2024-06-28T11:49:52Z","published":"2024-01-22T03:17:41Z","title":"Generative AI-Driven Human Digital Twin in IoT-Healthcare: A\n  Comprehensive Survey","summary":"  The Internet of things (IoT) can significantly enhance the quality of human\nlife, specifically in healthcare, attracting extensive attentions to\nIoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as\nan innovative paradigm that can comprehensively characterize the replication of\nthe individual human body in the digital world and reflect its physical status\nin real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the\napplication of healthcare monitoring by acting as a versatile and vivid human\ndigital testbed, simulating the outcomes and guiding the practical treatments.\nHowever, successfully establishing HDT requires high-fidelity virtual modeling\nand strong information interactions but possibly with scarce, biased and noisy\ndata. Fortunately, a recent popular technology called generative artificial\nintelligence (GAI) may be a promising solution because it can leverage advanced\nAI algorithms to automatically create, manipulate, and modify valuable while\ndiverse data. This survey particularly focuses on the implementation of\nGAI-driven HDT in IoT-healthcare. We start by introducing the background of\nIoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the\nfundamental techniques and present the overall framework of GAI-driven HDT.\nAfter that, we explore the realization of GAI-driven HDT in detail, including\nGAI-enabled data acquisition, communication, data management, digital modeling,\nand data analysis. Besides, we discuss typical IoT-healthcare applications that\ncan be revolutionized by GAI-driven HDT, namely personalized health monitoring\nand diagnosis, personalized prescription, and personalized rehabilitation.\nFinally, we conclude this survey by highlighting some future research\ndirections.\n","authors":["Jiayuan Chen","You Shi","Changyan Yi","Hongyang Du","Jiawen Kang","Dusit Niyato"],"pdf_url":"https://arxiv.org/pdf/2401.13699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02766v3","updated":"2024-06-28T11:39:10Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"  We introduce networked communication to the mean-field game framework, in\nparticular to oracle-free settings where $N$ decentralised agents learn along a\nsingle, non-episodic run of the empirical system. We prove that our\narchitecture, with only a few reasonable assumptions about network structure,\nhas sample guarantees bounded between those of the centralised- and\nindependent-learning cases. We discuss how the sample guarantees of the three\ntheoretical algorithms do not actually result in practical convergence. We\ntherefore show that in practical settings where the theoretical parameters are\nnot observed (leading to poor estimation of the Q-function), our communication\nscheme significantly accelerates convergence over the independent case (and\noften even the centralised case), without relying on the assumption of a\ncentralised learner. We contribute further practical enhancements to all three\ntheoretical algorithms, allowing us to present their first empirical\ndemonstrations. Our experiments confirm that we can remove several of the\ntheoretical assumptions of the algorithms, and display the empirical\nconvergence benefits brought by our new networked communication. We\nadditionally show that the networked approach has significant advantages, over\nboth the centralised and independent alternatives, in terms of robustness to\nunexpected learning failures and to changes in population size.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2306.02766v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03511v3","updated":"2024-06-28T11:23:11Z","published":"2023-12-06T14:13:38Z","title":"Kandinsky 3.0 Technical Report","summary":"  We present Kandinsky 3.0, a large-scale text-to-image generation model based\non latent diffusion, continuing the series of text-to-image Kandinsky models\nand reflecting our progress to achieve higher quality and realism of image\ngeneration. In this report we describe the architecture of the model, the data\ncollection procedure, the training technique, and the production system for\nuser interaction. We focus on the key components that, as we have identified as\na result of a large number of experiments, had the most significant impact on\nimproving the quality of our model compared to the others. We also describe\nextensions and applications of our model, including super resolution,\ninpainting, image editing, image-to-video generation, and a distilled version\nof Kandinsky 3.0 - Kandinsky 3.1, which does inference in 4 steps of the\nreverse process and 20 times faster without visual quality decrease. By\nside-by-side human preferences comparison, Kandinsky becomes better in text\nunderstanding and works better on specific domains. The code is available at\nhttps://github.com/ai-forever/Kandinsky-3\n","authors":["Vladimir Arkhipkin","Andrei Filatov","Viacheslav Vasilev","Anastasia Maltseva","Said Azizov","Igor Pavlov","Julia Agafonova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2312.03511v3.pdf","comment":"Project page: https://ai-forever.github.io/Kandinsky-3"},{"id":"http://arxiv.org/abs/2406.19832v1","updated":"2024-06-28T11:11:16Z","published":"2024-06-28T11:11:16Z","title":"MuGSI: Distilling GNNs with Multi-Granularity Structural Information for\n  Graph Classification","summary":"  Recent works have introduced GNN-to-MLP knowledge distillation (KD)\nframeworks to combine both GNN's superior performance and MLP's fast inference\nspeed. However, existing KD frameworks are primarily designed for node\nclassification within single graphs, leaving their applicability to graph\nclassification largely unexplored. Two main challenges arise when extending KD\nfor node classification to graph classification: (1) The inherent sparsity of\nlearning signals due to soft labels being generated at the graph level; (2) The\nlimited expressiveness of student MLPs, especially in datasets with limited\ninput feature spaces. To overcome these challenges, we introduce MuGSI, a novel\nKD framework that employs Multi-granularity Structural Information for graph\nclassification. Specifically, we propose multi-granularity distillation loss in\nMuGSI to tackle the first challenge. This loss function is composed of three\ndistinct components: graph-level distillation, subgraph-level distillation, and\nnode-level distillation. Each component targets a specific granularity of the\ngraph structure, ensuring a comprehensive transfer of structural knowledge from\nthe teacher model to the student model. To tackle the second challenge, MuGSI\nproposes to incorporate a node feature augmentation component, thereby\nenhancing the expressiveness of the student MLPs and making them more capable\nlearners. We perform extensive experiments across a variety of datasets and\ndifferent teacher/student model architectures. The experiment results\ndemonstrate the effectiveness, efficiency, and robustness of MuGSI. Codes are\npublicly available at: \\textbf{\\url{https://github.com/tianyao-aka/MuGSI}.}\n","authors":["Tianjun Yao","Jiaqi Sun","Defu Cao","Kun Zhang","Guangyi Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19832v1.pdf","comment":"12 pages, 4 figures. Accepted by TheWebConf2024"},{"id":"http://arxiv.org/abs/2406.19827v1","updated":"2024-06-28T11:06:46Z","published":"2024-06-28T11:06:46Z","title":"Towards Stable and Storage-efficient Dataset Distillation: Matching\n  Convexified Trajectory","summary":"  The rapid evolution of deep learning and large language models has led to an\nexponential growth in the demand for training data, prompting the development\nof Dataset Distillation methods to address the challenges of managing large\ndatasets. Among these, Matching Training Trajectories (MTT) has been a\nprominent approach, which replicates the training trajectory of an expert\nnetwork on real data with a synthetic dataset. However, our investigation found\nthat this method suffers from three significant limitations: 1. Instability of\nexpert trajectory generated by Stochastic Gradient Descent (SGD); 2. Low\nconvergence speed of the distillation process; 3. High storage consumption of\nthe expert trajectory. To address these issues, we offer a new perspective on\nunderstanding the essence of Dataset Distillation and MTT through a simple\ntransformation of the objective function, and introduce a novel method called\nMatching Convexified Trajectory (MCT), which aims to provide better guidance\nfor the student trajectory. MCT leverages insights from the linearized dynamics\nof Neural Tangent Kernel methods to create a convex combination of expert\ntrajectories, guiding the student network to converge rapidly and stably. This\ntrajectory is not only easier to store, but also enables a continuous sampling\nstrategy during distillation, ensuring thorough learning and fitting of the\nentire expert trajectory. Comprehensive experiments across three public\ndatasets validate the superiority of MCT over traditional MTT methods.\n","authors":["Wenliang Zhong","Haoyu Tang","Qinghai Zheng","Mingzhu Xu","Yupeng Hu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2406.19827v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2406.19825v1","updated":"2024-06-28T11:01:02Z","published":"2024-06-28T11:01:02Z","title":"Reinforcement Learning for Efficient Design and Control Co-optimisation\n  of Energy Systems","summary":"  The ongoing energy transition drives the development of decentralised\nrenewable energy sources, which are heterogeneous and weather-dependent,\ncomplicating their integration into energy systems. This study tackles this\nissue by introducing a novel reinforcement learning (RL) framework tailored for\nthe co-optimisation of design and control in energy systems. Traditionally, the\nintegration of renewable sources in the energy sector has relied on complex\nmathematical modelling and sequential processes. By leveraging RL's model-free\ncapabilities, the framework eliminates the need for explicit system modelling.\nBy optimising both control and design policies jointly, the framework enhances\nthe integration of renewable sources and improves system efficiency. This\ncontribution paves the way for advanced RL applications in energy management,\nleading to more efficient and effective use of renewable energy sources.\n","authors":["Marine Cauz","Adrien Bolland","Nicolas Wyrsch","Christophe Ballif"],"pdf_url":"https://arxiv.org/pdf/2406.19825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03080v3","updated":"2024-06-28T10:52:37Z","published":"2022-12-06T15:50:28Z","title":"Straggler-Resilient Differentially-Private Decentralized Learning","summary":"  We consider the straggler problem in decentralized learning over a logical\nring while preserving user data privacy. Especially, we extend the recently\nproposed framework of differential privacy (DP) amplification by\ndecentralization by Cyffers and Bellet to include overall training\nlatency--comprising both computation and communication latency. Analytical\nresults on both the convergence speed and the DP level are derived for both a\nskipping scheme (which ignores the stragglers after a timeout) and a baseline\nscheme that waits for each node to finish before the training continues. A\ntrade-off between overall training latency, accuracy, and privacy,\nparameterized by the timeout of the skipping scheme, is identified and\nempirically validated for logistic regression on a real-world dataset and for\nimage classification using the MNIST and CIFAR-10 datasets.\n","authors":["Yauhen Yakimenka","Chung-Wei Weng","Hsuan-Yin Lin","Eirik Rosnes","Jörg Kliewer"],"pdf_url":"https://arxiv.org/pdf/2212.03080v3.pdf","comment":"To appear in the IEEE Journal on Selected Areas in Information Theory\n  (special issue on Information-Theoretic Methods for Trustworthy and Reliable\n  Machine Learning)"},{"id":"http://arxiv.org/abs/2406.19807v1","updated":"2024-06-28T10:30:46Z","published":"2024-06-28T10:30:46Z","title":"Deceptive Diffusion: Generating Synthetic Adversarial Examples","summary":"  We introduce the concept of deceptive diffusion -- training a generative AI\nmodel to produce adversarial images. Whereas a traditional adversarial attack\nalgorithm aims to perturb an existing image to induce a misclassificaton, the\ndeceptive diffusion model can create an arbitrary number of new, misclassified\nimages that are not directly associated with training or test images. Deceptive\ndiffusion offers the possibility of strengthening defence algorithms by\nproviding adversarial training data at scale, including types of\nmisclassification that are otherwise difficult to find. In our experiments, we\nalso investigate the effect of training on a partially attacked data set. This\nhighlights a new type of vulnerability for generative diffusion models: if an\nattacker is able to stealthily poison a portion of the training data, then the\nresulting diffusion model will generate a similar proportion of misleading\noutputs.\n","authors":["Lucas Beerens","Catherine F. Higham","Desmond J. Higham"],"pdf_url":"https://arxiv.org/pdf/2406.19807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19801v1","updated":"2024-06-28T10:16:10Z","published":"2024-06-28T10:16:10Z","title":"MulTi-Wise Sampling: Trading Uniform T-Wise Feature Interaction Coverage\n  for Smaller Samples","summary":"  Ensuring the functional safety of highly configurable systems often requires\ntesting representative subsets of all possible configurations to reduce testing\neffort and save resources. The ratio of covered t-wise feature interactions\n(i.e., T-Wise Feature Interaction Coverage) is a common criterion for\ndetermining whether a subset of configurations is representative and capable of\nfinding faults. Existing t-wise sampling algorithms uniformly cover t-wise\nfeature interactions for all features, resulting in lengthy execution times and\nlarge sample sizes, particularly when large t-wise feature interactions are\nconsidered (i.e., high values of t). In this paper, we introduce a novel\napproach to t-wise feature interaction sampling, questioning the necessity of\nuniform coverage across all t-wise feature interactions, called\n\\emph{\\mulTiWise{}}. Our approach prioritizes between subsets of critical and\nnon-critical features, considering higher t-values for subsets of critical\nfeatures when generating a t-wise feature interaction sample. We evaluate our\napproach using subject systems from real-world applications, including\n\\busybox{}, \\soletta{}, \\fiasco{}, and \\uclibc{}. Our results show that\nsacrificing uniform t-wise feature interaction coverage between all features\nreduces the time needed to generate a sample and the resulting sample size.\nHence, \\mulTiWise{} Sampling offers an alternative to existing approaches if\nknowledge about feature criticality is available.\n","authors":["Tobias Pett","Sebastian Krieter","Thomas Thüm","Ina Schaefer"],"pdf_url":"https://arxiv.org/pdf/2406.19801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16783v2","updated":"2024-06-28T10:14:53Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2406.19800v1","updated":"2024-06-28T10:13:50Z","published":"2024-06-28T10:13:50Z","title":"Modeling the Real World with High-Density Visual Particle Dynamics","summary":"  We present High-Density Visual Particle Dynamics (HD-VPD), a learned world\nmodel that can emulate the physical dynamics of real scenes by processing\nmassive latent point clouds containing 100K+ particles. To enable efficiency at\nthis scale, we introduce a novel family of Point Cloud Transformers (PCTs)\ncalled Interlacers leveraging intertwined linear-attention Performer layers and\ngraph-based neighbour attention layers. We demonstrate the capabilities of\nHD-VPD by modeling the dynamics of high degree-of-freedom bi-manual robots with\ntwo RGB-D cameras. Compared to the previous graph neural network approach, our\nInterlacer dynamics is twice as fast with the same prediction quality, and can\nachieve higher quality using 4x as many particles. We illustrate how HD-VPD can\nevaluate motion plan quality with robotic box pushing and can grasping tasks.\nSee videos and particle dynamics rendered by HD-VPD at\nhttps://sites.google.com/view/hd-vpd.\n","authors":["William F. Whitney","Jacob Varley","Deepali Jain","Krzysztof Choromanski","Sumeet Singh","Vikas Sindhwani"],"pdf_url":"https://arxiv.org/pdf/2406.19800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.04268v2","updated":"2024-06-28T09:59:08Z","published":"2023-09-08T11:29:05Z","title":"Optimal Rate of Kernel Regression in Large Dimensions","summary":"  We perform a study on kernel regression for large-dimensional data (where the\nsample size $n$ is polynomially depending on the dimension $d$ of the samples,\ni.e., $n\\asymp d^{\\gamma}$ for some $\\gamma >0$ ). We first build a general\ntool to characterize the upper bound and the minimax lower bound of kernel\nregression for large dimensional data through the Mendelson complexity\n$\\varepsilon_{n}^{2}$ and the metric entropy $\\bar{\\varepsilon}_{n}^{2}$\nrespectively. When the target function falls into the RKHS associated with a\n(general) inner product model defined on $\\mathbb{S}^{d}$, we utilize the new\ntool to show that the minimax rate of the excess risk of kernel regression is\n$n^{-1/2}$ when $n\\asymp d^{\\gamma}$ for $\\gamma =2, 4, 6, 8, \\cdots$. We then\nfurther determine the optimal rate of the excess risk of kernel regression for\nall the $\\gamma>0$ and find that the curve of optimal rate varying along\n$\\gamma$ exhibits several new phenomena including the multiple descent behavior\nand the periodic plateau behavior. As an application, For the neural tangent\nkernel (NTK), we also provide a similar explicit description of the curve of\noptimal rate. As a direct corollary, we know these claims hold for wide neural\nnetworks as well.\n","authors":["Weihao Lu","Haobo Zhang","Yicheng Li","Manyun Xu","Qian Lin"],"pdf_url":"https://arxiv.org/pdf/2309.04268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03216v4","updated":"2024-06-28T09:55:49Z","published":"2024-02-05T17:26:49Z","title":"BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity\n  Text Embeddings Through Self-Knowledge Distillation","summary":"  In this paper, we present a new embedding model, called M3-Embedding, which\nis distinguished for its versatility in Multi-Linguality, Multi-Functionality,\nand Multi-Granularity. It can support more than 100 working languages, leading\nto new state-of-the-art performances on multi-lingual and cross-lingual\nretrieval tasks. It can simultaneously perform the three common retrieval\nfunctionalities of embedding model: dense retrieval, multi-vector retrieval,\nand sparse retrieval, which provides a unified model foundation for real-world\nIR applications. It is able to process inputs of different granularities,\nspanning from short sentences to long documents of up to 8192 tokens. The\neffective training of M3-Embedding involves the following technical\ncontributions. We propose a novel self-knowledge distillation approach, where\nthe relevance scores from different retrieval functionalities can be integrated\nas the teacher signal to enhance the training quality. We also optimize the\nbatching strategy, enabling a large batch size and high training throughput to\nensure the discriminativeness of embeddings. To the best of our knowledge,\nM3-Embedding is the first embedding model which realizes such a strong\nversatility. The model and code will be publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Jianlv Chen","Shitao Xiao","Peitian Zhang","Kun Luo","Defu Lian","Zheng Liu"],"pdf_url":"https://arxiv.org/pdf/2402.03216v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19792v1","updated":"2024-06-28T09:55:29Z","published":"2024-06-28T09:55:29Z","title":"Improving Performance Prediction of Electrolyte Formulations with\n  Transformer-based Molecular Representation Model","summary":"  Development of efficient and high-performing electrolytes is crucial for\nadvancing energy storage technologies, particularly in batteries. Predicting\nthe performance of battery electrolytes rely on complex interactions between\nthe individual constituents. Consequently, a strategy that adeptly captures\nthese relationships and forms a robust representation of the formulation is\nessential for integrating with machine learning models to predict properties\naccurately. In this paper, we introduce a novel approach leveraging a\ntransformer-based molecular representation model to effectively and efficiently\ncapture the representation of electrolyte formulations. The performance of the\nproposed approach is evaluated on two battery property prediction tasks and the\nresults show superior performance compared to the state-of-the-art methods.\n","authors":["Indra Priyadarsini","Vidushi Sharma","Seiji Takeda","Akihiro Kishimoto","Lisa Hamada","Hajime Shinohara"],"pdf_url":"https://arxiv.org/pdf/2406.19792v1.pdf","comment":"Accepted in ML4LMS Workshop at ICML 2024"},{"id":"http://arxiv.org/abs/2405.15613v2","updated":"2024-06-28T09:22:38Z","published":"2024-05-24T14:58:51Z","title":"Automatic Data Curation for Self-Supervised Learning: A Clustering-Based\n  Approach","summary":"  Self-supervised features are the cornerstone of modern machine learning\nsystems. They are typically pre-trained on data collections whose construction\nand curation typically require extensive human effort. This manual process has\nsome limitations similar to those encountered in supervised learning, e.g., the\ncrowd-sourced selection of data is costly and time-consuming, preventing\nscaling the dataset size. In this work, we consider the problem of automatic\ncuration of high-quality datasets for self-supervised pre-training. We posit\nthat such datasets should be large, diverse and balanced, and propose a\nclustering-based approach for building ones satisfying all these criteria. Our\nmethod involves successive and hierarchical applications of $k$-means on a\nlarge and diverse data repository to obtain clusters that distribute uniformly\namong data concepts, followed by a hierarchical, balanced sampling step from\nthese clusters. Extensive experiments on three different data domains including\nweb-based images, satellite images and text show that features trained on our\nautomatically curated datasets outperform those trained on uncurated data while\nbeing on par or better than ones trained on manually curated data. Code is\navailable at https://github.com/facebookresearch/ssl-data-curation.\n","authors":["Huy V. Vo","Vasil Khalidov","Timothée Darcet","Théo Moutakanni","Nikita Smetanin","Marc Szafraniec","Hugo Touvron","Camille Couprie","Maxime Oquab","Armand Joulin","Hervé Jégou","Patrick Labatut","Piotr Bojanowski"],"pdf_url":"https://arxiv.org/pdf/2405.15613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19770v1","updated":"2024-06-28T09:17:58Z","published":"2024-06-28T09:17:58Z","title":"Self-Supervised Spatial-Temporal Normality Learning for Time Series\n  Anomaly Detection","summary":"  Time Series Anomaly Detection (TSAD) finds widespread applications across\nvarious domains such as financial markets, industrial production, and\nhealthcare. Its primary objective is to learn the normal patterns of time\nseries data, thereby identifying deviations in test samples. Most existing TSAD\nmethods focus on modeling data from the temporal dimension, while ignoring the\nsemantic information in the spatial dimension. To address this issue, we\nintroduce a novel approach, called Spatial-Temporal Normality learning (STEN).\nSTEN is composed of a sequence Order prediction-based Temporal Normality\nlearning (OTN) module that captures the temporal correlations within sequences,\nand a Distance prediction-based Spatial Normality learning (DSN) module that\nlearns the relative spatial relations between sequences in a feature space. By\nsynthesizing these two modules, STEN learns expressive spatial-temporal\nrepresentations for the normal patterns hidden in the time series data.\nExtensive experiments on five popular TSAD benchmarks show that STEN\nsubstantially outperforms state-of-the-art competing methods. Our code is\navailable at https://github.com/mala-lab/STEN.\n","authors":["Yutong Chen","Hongzuo Xu","Guansong Pang","Hezhe Qiao","Yuan Zhou","Mingsheng Shang"],"pdf_url":"https://arxiv.org/pdf/2406.19770v1.pdf","comment":"18 pages, 4 figures, accepted in ECML PKDD2024"},{"id":"http://arxiv.org/abs/2406.19768v1","updated":"2024-06-28T09:17:51Z","published":"2024-06-28T09:17:51Z","title":"Contextualized Hybrid Ensemble Q-learning: Learning Fast with Control\n  Priors","summary":"  Combining Reinforcement Learning (RL) with a prior controller can yield the\nbest out of two worlds: RL can solve complex nonlinear problems, while the\ncontrol prior ensures safer exploration and speeds up training. Prior work\nlargely blends both components with a fixed weight, neglecting that the RL\nagent's performance varies with the training progress and across regions in the\nstate space. Therefore, we advocate for an adaptive strategy that dynamically\nadjusts the weighting based on the RL agent's current capabilities. We propose\na new adaptive hybrid RL algorithm, Contextualized Hybrid Ensemble Q-learning\n(CHEQ). CHEQ combines three key ingredients: (i) a time-invariant formulation\nof the adaptive hybrid RL problem treating the adaptive weight as a context\nvariable, (ii) a weight adaption mechanism based on the parametric uncertainty\nof a critic ensemble, and (iii) ensemble-based acceleration for data-efficient\nRL. Evaluating CHEQ on a car racing task reveals substantially stronger data\nefficiency, exploration safety, and transferability to unknown scenarios than\nstate-of-the-art adaptive hybrid RL methods.\n","authors":["Emma Cramer","Bernd Frauenknecht","Ramil Sabirov","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2406.19768v1.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.10552v3","updated":"2024-06-28T09:16:28Z","published":"2024-06-15T08:13:47Z","title":"Large Language Model Enhanced Clustering for News Event Detection","summary":"  The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labelling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes multiple feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that the use of LLM embedding in the event detection framework has\nsignificantly improved the results, demonstrating greater robustness in terms\nof CSAI scores. Moreover, post-event detection tasks generate meaningful\ninsights, facilitating effective interpretation of event clustering results.\nOverall, our experimental results indicate that the proposed framework offers\nvaluable insights and could enhance the accuracy in news analysis and\nreporting.\n","authors":["Adane Nega Tarekegn"],"pdf_url":"https://arxiv.org/pdf/2406.10552v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19765v1","updated":"2024-06-28T09:10:23Z","published":"2024-06-28T09:10:23Z","title":"Systematic Literature Review on Application of Learning-based Approaches\n  in Continuous Integration","summary":"  Context: Machine learning (ML) and deep learning (DL) analyze raw data to\nextract valuable insights in specific phases. The rise of continuous practices\nin software projects emphasizes automating Continuous Integration (CI) with\nthese learning-based methods, while the growing adoption of such approaches\nunderscores the need for systematizing knowledge. Objective: Our objective is\nto comprehensively review and analyze existing literature concerning\nlearning-based methods within the CI domain. We endeavour to identify and\nanalyse various techniques documented in the literature, emphasizing the\nfundamental attributes of training phases within learning-based solutions in\nthe context of CI. Method: We conducted a Systematic Literature Review (SLR)\ninvolving 52 primary studies. Through statistical and thematic analyses, we\nexplored the correlations between CI tasks and the training phases of\nlearning-based methodologies across the selected studies, encompassing a\nspectrum from data engineering techniques to evaluation metrics. Results: This\npaper presents an analysis of the automation of CI tasks utilizing\nlearning-based methods. We identify and analyze nine types of data sources,\nfour steps in data preparation, four feature types, nine subsets of data\nfeatures, five approaches for hyperparameter selection and tuning, and fifteen\nevaluation metrics. Furthermore, we discuss the latest techniques employed,\nexisting gaps in CI task automation, and the characteristics of the utilized\nlearning-based techniques. Conclusion: This study provides a comprehensive\noverview of learning-based methods in CI, offering valuable insights for\nresearchers and practitioners developing CI task automation. It also highlights\nthe need for further research to advance these methods in CI.\n","authors":["Ali Kazemi Arani","Triet Huynh Minh Le","Mansooreh Zahedi","M. Ali Babar"],"pdf_url":"https://arxiv.org/pdf/2406.19765v1.pdf","comment":"This paper has been accepted to be published in IEEE Access"},{"id":"http://arxiv.org/abs/2402.07158v2","updated":"2024-06-28T08:57:39Z","published":"2024-02-11T11:03:08Z","title":"Effort and Size Estimation in Software Projects with Large Language\n  Model-based Intelligent Interfaces","summary":"  The advancement of Large Language Models (LLM) has also resulted in an\nequivalent proliferation in its applications. Software design, being one, has\ngained tremendous benefits in using LLMs as an interface component that extends\nfixed user stories. However, inclusion of LLM-based AI agents in software\ndesign often poses unexpected challenges, especially in the estimation of\ndevelopment efforts. Through the example of UI-based user stories, we provide a\ncomparison against traditional methods and propose a new way to enhance\nspecifications of natural language-based questions that allows for the\nestimation of development effort by taking into account data sources,\ninterfaces and algorithms.\n","authors":["Claudionor N. Coelho Jr","Hanchen Xiong","Tushar Karayil","Sree Koratala","Rex Shang","Jacob Bollinger","Mohamed Shabar","Syam Nair"],"pdf_url":"https://arxiv.org/pdf/2402.07158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15486v2","updated":"2024-06-28T08:55:17Z","published":"2024-06-17T11:05:15Z","title":"SampleAttention: Near-Lossless Acceleration of Long Context LLM\n  Inference with Adaptive Structured Sparse Attention","summary":"  Large language models (LLMs) now support extremely long context windows, but\nthe quadratic complexity of vanilla attention results in significantly long\nTime-to-First-Token (TTFT) latency. Existing approaches to address this\ncomplexity require additional pretraining or finetuning, and often sacrifice\nmodel accuracy. In this paper, we first provide both theoretical and empirical\nfoundations for near-lossless sparse attention. We find dynamically capturing\nhead-specific sparse patterns at runtime with low overhead is crucial. To\naddress this, we propose SampleAttention, an adaptive structured and\nnear-lossless sparse attention. Leveraging observed significant sparse\npatterns, SampleAttention attends to a fixed percentage of adjacent tokens to\ncapture local window patterns, and employs a two-stage query-guided key-value\nfiltering approach, which adaptively select a minimum set of key-values with\nlow overhead, to capture column stripe patterns. Comprehensive evaluations show\nthat SampleAttention can seamlessly replace vanilla attention in off-the-shelf\nLLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\\times$\ncompared with FlashAttention.\n","authors":["Qianchao Zhu","Jiangfei Duan","Chang Chen","Siran Liu","Xiuhong Li","Guanyu Feng","Xin Lv","Huanqi Cao","Xiao Chuanfu","Xingcheng Zhang","Dahua Lin","Chao Yang"],"pdf_url":"https://arxiv.org/pdf/2406.15486v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19753v1","updated":"2024-06-28T08:53:33Z","published":"2024-06-28T08:53:33Z","title":"Backdoor Attack in Prompt-Based Continual Learning","summary":"  Prompt-based approaches offer a cutting-edge solution to data privacy issues\nin continual learning, particularly in scenarios involving multiple data\nsuppliers where long-term storage of private user data is prohibited. Despite\ndelivering state-of-the-art performance, its impressive remembering capability\ncan become a double-edged sword, raising security concerns as it might\ninadvertently retain poisoned knowledge injected during learning from private\nuser data. Following this insight, in this paper, we expose continual learning\nto a potential threat: backdoor attack, which drives the model to follow a\ndesired adversarial target whenever a specific trigger is present while still\nperforming normally on clean samples. We highlight three critical challenges in\nexecuting backdoor attacks on incremental learners and propose corresponding\nsolutions: (1) \\emph{Transferability}: We employ a surrogate dataset and\nmanipulate prompt selection to transfer backdoor knowledge to data from other\nsuppliers; (2) \\emph{Resiliency}: We simulate static and dynamic states of the\nvictim to ensure the backdoor trigger remains robust during intense incremental\nlearning processes; and (3) \\emph{Authenticity}: We apply binary cross-entropy\nloss as an anti-cheating factor to prevent the backdoor trigger from devolving\ninto adversarial noise. Extensive experiments across various benchmark datasets\nand continual learners validate our continual backdoor framework, achieving up\nto $100\\%$ attack success rate, with further ablation studies confirming our\ncontributions' effectiveness.\n","authors":["Trang Nguyen","Anh Tran","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2406.19753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00532v2","updated":"2024-06-28T08:48:06Z","published":"2024-05-01T14:05:52Z","title":"ULLER: A Unified Language for Learning and Reasoning","summary":"  The field of neuro-symbolic artificial intelligence (NeSy), which combines\nlearning and reasoning, has recently experienced significant growth. There now\nare a wide variety of NeSy frameworks, each with its own specific language for\nexpressing background knowledge and how to relate it to neural networks. This\nheterogeneity hinders accessibility for newcomers and makes comparing different\nNeSy frameworks challenging. We propose a language for NeSy, which we call\nULLER, a Unfied Language for LEarning and Reasoning. ULLER encompasses a wide\nvariety of settings, while ensuring that knowledge described in it can be used\nin existing NeSy systems. ULLER has a first-order logic syntax specialised for\nNeSy for which we provide example semantics including classical FOL, fuzzy\nlogic, and probabilistic logic. We believe ULLER is a first step towards making\nNeSy research more accessible and comparable, paving the way for libraries that\nstreamline training and evaluation across a multitude of semantics, knowledge\nbases, and NeSy systems.\n","authors":["Emile van Krieken","Samy Badreddine","Robin Manhaeve","Eleonora Giunchiglia"],"pdf_url":"https://arxiv.org/pdf/2405.00532v2.pdf","comment":"Accepted at NeSy 2024"},{"id":"http://arxiv.org/abs/2402.13914v2","updated":"2024-06-28T08:37:28Z","published":"2024-02-21T16:30:24Z","title":"Position: Explain to Question not to Justify","summary":"  Explainable Artificial Intelligence (XAI) is a young but very promising field\nof research. Unfortunately, the progress in this field is currently slowed down\nby divergent and incompatible goals. We separate various threads tangled within\nthe area of XAI into two complementary cultures of human/value-oriented\nexplanations (BLUE XAI) and model/validation-oriented explanations (RED XAI).\nThis position paper argues that the area of RED XAI is currently\nunder-explored, i.e., more methods for explainability are desperately needed to\nquestion models (e.g., extract knowledge from well-performing models as well as\nspotting and fixing bugs in faulty models), and the area of RED XAI hides great\nopportunities and potential for important research necessary to ensure the\nsafety of AI systems. We conclude this paper by presenting promising challenges\nin this area.\n","authors":["Przemyslaw Biecek","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2402.13914v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06560v2","updated":"2024-06-28T08:35:58Z","published":"2023-12-11T17:45:10Z","title":"Automatic Regularization for Linear MMSE Filters","summary":"  In this work, we consider the problem of regularization in the design of\nminimum mean square error (MMSE) linear filters. Using the relationship with\nstatistical machine learning methods, using a Bayesian approach, the\nregularization parameter is found from the observed signals in a simple and\nautomatic manner. The proposed approach is illustrated in system identification\nand beamforming examples, where the automatic regularization is shown to yield\nnear-optimal results.\n","authors":["Daniel Gomes de Pinho Zanco","Leszek Szczecinski","Jacob Benesty"],"pdf_url":"https://arxiv.org/pdf/2312.06560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19738v1","updated":"2024-06-28T08:26:47Z","published":"2024-06-28T08:26:47Z","title":"Classical Bandit Algorithms for Entanglement Detection in Parameterized\n  Qubit States","summary":"  Entanglement is a key resource for a wide range of tasks in quantum\ninformation and computing. Thus, verifying availability of this quantum\nresource is essential. Extensive research on entanglement detection has led to\nno-go theorems (Lu et al. [Phys. Rev. Lett., 116, 230501 (2016)]) that\nhighlight the need for full state tomography (FST) in the absence of adaptive\nor joint measurements. Recent advancements, as proposed by Zhu, Teo, and\nEnglert [Phys. Rev. A, 81, 052339, 2010], introduce a single-parameter family\nof entanglement witness measurements which are capable of conclusively\ndetecting certain entangled states and only resort to FST when all witness\nmeasurements are inconclusive. We find a variety of realistic noisy two-qubit\nquantum states $\\mathcal{F}$ that yield conclusive results under this witness\nfamily. We solve the problem of detecting entanglement among $K$ quantum states\nin $\\mathcal{F}$, of which $m$ states are entangled, with $m$ potentially\nunknown. We recognize a structural connection of this problem to the Bad Arm\nIdentification problem in stochastic Multi-Armed Bandits (MAB). In contrast to\nexisting quantum bandit frameworks, we establish a new correspondence tailored\nfor entanglement detection and term it the $(m,K)$-quantum Multi-Armed Bandit.\nWe implement two well-known MAB policies for arbitrary states derived from\n$\\mathcal{F}$, present theoretical guarantees on the measurement/sample\ncomplexity and demonstrate the practicality of the policies through numerical\nsimulations. More broadly, this paper highlights the potential for employing\nclassical machine learning techniques for quantum entanglement detection.\n","authors":["Bharati. K","Vikesh Siddhu","Krishna Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2406.19738v1.pdf","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.19736v1","updated":"2024-06-28T08:25:27Z","published":"2024-06-28T08:25:27Z","title":"MM-Instruct: Generated Visual Instructions for Large Multimodal Model\n  Alignment","summary":"  This paper introduces MM-Instruct, a large-scale dataset of diverse and\nhigh-quality visual instruction data designed to enhance the\ninstruction-following capabilities of large multimodal models (LMMs). While\nexisting visual instruction datasets often focus on question-answering, they\nstruggle to generalize to broader application scenarios such as creative\nwriting, summarization, or image analysis. To address these limitations, we\npropose a novel approach to constructing MM-Instruct that leverages the strong\ninstruction-following capabilities of existing LLMs to generate novel visual\ninstruction data from large-scale but conventional image captioning datasets.\nMM-Instruct first leverages ChatGPT to automatically generate diverse\ninstructions from a small set of seed instructions through augmenting and\nsummarization. It then matches these instructions with images and uses an\nopen-sourced large language model (LLM) to generate coherent answers to the\ninstruction-image pairs. The LLM is grounded by the detailed text descriptions\nof images in the whole answer generation process to guarantee the alignment of\nthe instruction data. Moreover, we introduce a benchmark based on the generated\ninstruction data to evaluate the instruction-following capabilities of existing\nLMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5\nmodel on the generated data, denoted as LLaVA-Instruct, which exhibits\nsignificant improvements in instruction-following capabilities compared to\nLLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models\nare available at https://github.com/jihaonew/MM-Instruct.\n","authors":["Jihao Liu","Xin Huang","Jinliang Zheng","Boxiao Liu","Jia Wang","Osamu Yoshie","Yu Liu","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.19736v1.pdf","comment":"Dataset and models are available at\n  https://github.com/jihaonew/MM-Instruct"},{"id":"http://arxiv.org/abs/2307.10635v3","updated":"2024-06-28T08:24:13Z","published":"2023-07-20T07:01:57Z","title":"SciBench: Evaluating College-Level Scientific Problem-Solving Abilities\n  of Large Language Models","summary":"  Most of the existing Large Language Model (LLM) benchmarks on scientific\nproblem reasoning focus on problems grounded in high-school subjects and are\nconfined to elementary algebraic operations. To systematically examine the\nreasoning capabilities required for solving complex scientific problems, we\nintroduce an expansive benchmark suite SciBench for LLMs. SciBench contains a\ncarefully curated dataset featuring a range of collegiate-level scientific\nproblems from mathematics, chemistry, and physics domains. Based on the\ndataset, we conduct an in-depth benchmarking study of representative\nopen-source and proprietary LLMs with various prompting strategies. The results\nreveal that the current LLMs fall short of delivering satisfactory performance,\nwith the best overall score of merely 43.22%. Furthermore, through a detailed\nuser study, we categorize the errors made by LLMs into ten problem-solving\nabilities. Our analysis indicates that no single prompting strategy\nsignificantly outperforms the others and some strategies that demonstrate\nimprovements in certain problem-solving skills could result in declines in\nother skills. We envision that SciBench will catalyze further developments in\nthe reasoning abilities of LLMs, thereby ultimately contributing to scientific\nresearch and discovery.\n","authors":["Xiaoxuan Wang","Ziniu Hu","Pan Lu","Yanqiao Zhu","Jieyu Zhang","Satyen Subramaniam","Arjun R. Loomba","Shichang Zhang","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2307.10635v3.pdf","comment":"To appear at ICML 2024"},{"id":"http://arxiv.org/abs/2402.08114v2","updated":"2024-06-28T08:22:01Z","published":"2024-02-12T23:09:00Z","title":"Active Preference Learning for Large Language Models","summary":"  As large language models (LLMs) become more capable, fine-tuning techniques\nfor aligning with human intent are increasingly important. A key consideration\nfor aligning these models is how to most effectively use human resources, or\nmodel resources in the case where LLMs themselves are used as oracles.\nReinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most\nprominent example of such a technique, but is complex and often unstable.\nDirect Preference Optimization (DPO) has recently been proposed as a simpler\nand more stable alternative. In this work, we develop an active learning\nstrategy for DPO to make better use of preference labels. We propose a\npractical acquisition function for prompt/completion pairs based on the\npredictive entropy of the language model and a measure of certainty of the\nimplicit preference model optimized by DPO. We demonstrate how our approach\nimproves both the rate of learning and final performance of fine-tuning on\npairwise preference data.\n","authors":["William Muldrew","Peter Hayes","Mingtian Zhang","David Barber"],"pdf_url":"https://arxiv.org/pdf/2402.08114v2.pdf","comment":"13 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.19726v1","updated":"2024-06-28T08:16:54Z","published":"2024-06-28T08:16:54Z","title":"EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans","summary":"  Monocular Human Pose Estimation (HPE) aims at determining the 3D positions of\nhuman joints from a single 2D image captured by a camera. However, a single 2D\npoint in the image may correspond to multiple points in 3D space. Typically,\nthe uniqueness of the 2D-3D relationship is approximated using an orthographic\nor weak-perspective camera model. In this study, instead of relying on\napproximations, we advocate for utilizing the full perspective camera model.\nThis involves estimating camera parameters and establishing a precise,\nunambiguous 2D-3D relationship. To do so, we introduce the EPOCH framework,\ncomprising two main components: the pose lifter network (LiftNet) and the pose\nregressor network (RegNet). LiftNet utilizes the full perspective camera model\nto precisely estimate the 3D pose in an unsupervised manner. It takes a 2D pose\nand camera parameters as inputs and produces the corresponding 3D pose\nestimation. These inputs are obtained from RegNet, which starts from a single\nimage and provides estimates for the 2D pose and camera parameters. RegNet\nutilizes only 2D pose data as weak supervision. Internally, RegNet predicts a\n3D pose, which is then projected to 2D using the estimated camera parameters.\nThis process enables RegNet to establish the unambiguous 2D-3D relationship.\nOur experiments show that modeling the lifting as an unsupervised task with a\ncamera in-the-loop results in better generalization to unseen data. We obtain\nstate-of-the-art results for the 3D HPE on the Human3.6M and MPI-INF-3DHP\ndatasets. Our code is available at: [Github link upon acceptance, see\nsupplementary materials].\n","authors":["Nicola Garau","Giulia Martinelli","Niccolò Bisagno","Denis Tomè","Carsten Stoll"],"pdf_url":"https://arxiv.org/pdf/2406.19726v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.19714v1","updated":"2024-06-28T07:56:35Z","published":"2024-06-28T07:56:35Z","title":"State Matching and Multiple References in Adaptive Active Automata\n  Learning","summary":"  Active automata learning (AAL) is a method to infer state machines by\ninteracting with black-box systems. Adaptive AAL aims to reduce the sample\ncomplexity of AAL by incorporating domain specific knowledge in the form of\n(similar) reference models. Such reference models appear naturally when\nlearning multiple versions or variants of a software system. In this paper, we\npresent state matching, which allows flexible use of the structure of these\nreference models by the learner. State matching is the main ingredient of\nadaptive L#, a novel framework for adaptive learning, built on top of L#. Our\nempirical evaluation shows that adaptive L# improves the state of the art by up\nto two orders of magnitude.\n","authors":["Loes Kruger","Sebastian Junges","Jurriaan Rot"],"pdf_url":"https://arxiv.org/pdf/2406.19714v1.pdf","comment":"Extended paper for FM 2024"},{"id":"http://arxiv.org/abs/2406.01124v3","updated":"2024-06-28T07:54:19Z","published":"2024-06-03T09:10:42Z","title":"Latent Logic Tree Extraction for Event Sequence Explanation from LLMs","summary":"  Modern high-stakes systems, such as healthcare or robotics, often generate\nvast streaming event sequences. Our goal is to design an efficient,\nplug-and-play tool to elicit logic tree-based explanations from Large Language\nModels (LLMs) to provide customized insights into each observed event sequence.\nBuilt on the temporal point process model for events, our method employs the\nlikelihood function as a score to evaluate generated logic trees. We propose an\namortized Expectation-Maximization (EM) learning framework and treat the logic\ntree as latent variables. In the E-step, we evaluate the posterior distribution\nover the latent logic trees using an LLM prior and the likelihood of the\nobserved event sequences. LLM provides a high-quality prior for the latent\nlogic trees, however, since the posterior is built over a discrete\ncombinatorial space, we cannot get the closed-form solution. We propose to\ngenerate logic tree samples from the posterior using a learnable GFlowNet,\nwhich is a diversity-seeking generator for structured discrete variables. The\nM-step employs the generated logic rules to approximate marginalization over\nthe posterior, facilitating the learning of model parameters and refining the\ntunable LLM prior parameters. In the online setting, our locally built,\nlightweight model will iteratively extract the most relevant rules from LLMs\nfor each sequence using only a few iterations. Empirical demonstrations\nshowcase the promising performance and adaptability of our framework.\n","authors":["Zitao Song","Chao Yang","Chaojie Wang","Bo An","Shuang Li"],"pdf_url":"https://arxiv.org/pdf/2406.01124v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09904v2","updated":"2024-06-28T07:53:12Z","published":"2024-06-14T10:23:45Z","title":"QQQ: Quality Quattuor-Bit Quantization for Large Language Models","summary":"  Quantization is a proven effective method for compressing large language\nmodels. Although popular techniques like W8A8 and W4A16 effectively maintain\nmodel performance, they often fail to concurrently speed up the prefill and\ndecoding stages of inference. W4A8 is a promising strategy to accelerate both\nof them while usually leads to a significant performance degradation. To\naddress these issues, we present QQQ, a Quality Quattuor-bit Quantization\nmethod with 4-bit weights and 8-bit activations. QQQ employs adaptive smoothing\nand Hessian-based compensation, significantly enhancing the performance of\nquantized models without extensive training. Furthermore, we meticulously\nengineer W4A8 GEMM kernels to increase inference speed. Our specialized\nper-channel W4A8 GEMM and per-group W4A8 GEMM achieve impressive speed\nincreases of 3.67$\\times$ and 3.29 $\\times$ over FP16 GEMM. Our extensive\nexperiments show that QQQ achieves performance on par with existing\nstate-of-the-art LLM quantization methods while significantly accelerating\ninference, achieving speed boosts up to 2.24 $\\times$, 2.10$\\times$, and\n1.25$\\times$ compared to FP16, W8A8, and W4A16, respectively.\n","authors":["Ying Zhang","Peng Zhang","Mincong Huang","Jingyang Xiang","Yujie Wang","Chao Wang","Yineng Zhang","Lei Yu","Chuan Liu","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2406.09904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19711v1","updated":"2024-06-28T07:46:51Z","published":"2024-06-28T07:46:51Z","title":"CHASE: A Causal Heterogeneous Graph based Framework for Root Cause\n  Analysis in Multimodal Microservice Systems","summary":"  In recent years, the widespread adoption of distributed microservice\narchitectures within the industry has significantly increased the demand for\nenhanced system availability and robustness. Due to the complex service\ninvocation paths and dependencies at enterprise-level microservice systems, it\nis challenging to locate the anomalies promptly during service invocations,\nthus causing intractable issues for normal system operations and maintenance.\nIn this paper, we propose a Causal Heterogeneous grAph baSed framEwork for root\ncause analysis, namely CHASE, for microservice systems with multimodal data,\nincluding traces, logs, and system monitoring metrics. Specifically, related\ninformation is encoded into representative embeddings and further modeled by a\nmultimodal invocation graph. Following that, anomaly detection is performed on\neach instance node with attentive heterogeneous message passing from its\nadjacent metric and log nodes. Finally, CHASE learns from the constructed\nhypergraph with hyperedges representing the flow of causality and performs root\ncause localization. We evaluate the proposed framework on two public\nmicroservice datasets with distinct attributes and compare with the\nstate-of-the-art methods. The results show that CHASE achieves the average\nperformance gain up to 36.2%(A@1) and 29.4%(Percentage@1), respectively to its\nbest counterpart.\n","authors":["Ziming Zhao","Tiehua Zhang","Zhishu Shen","Hai Dong","Xingjun Ma","Xianhui Liu","Yun Yang"],"pdf_url":"https://arxiv.org/pdf/2406.19711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19707v1","updated":"2024-06-28T07:41:26Z","published":"2024-06-28T07:41:26Z","title":"InfiniGen: Efficient Generative Inference of Large Language Models with\n  Dynamic KV Cache Management","summary":"  Transformer-based large language models (LLMs) demonstrate impressive\nperformance across various natural language processing tasks. Serving LLM\ninference for generating long contents, however, poses a challenge due to the\nenormous memory footprint of the transient state, known as the key-value (KV)\ncache, which scales with the sequence length and batch size. In this paper, we\npresent InfiniGen, a novel KV cache management framework tailored for long-text\ngeneration, which synergistically works with modern offloading-based inference\nsystems. InfiniGen leverages the key insight that a few important tokens that\nare essential for computing the subsequent attention layer in the Transformer\ncan be speculated by performing a minimal rehearsal with the inputs of the\ncurrent layer and part of the query weight and key cache of the subsequent\nlayer. This allows us to prefetch only the essential KV cache entries (without\nfetching them all), thereby mitigating the fetch overhead from the host memory\nin offloading-based LLM serving systems. Our evaluation on several\nrepresentative LLMs shows that InfiniGen improves the overall performance of a\nmodern offloading-based system by up to 3.00x compared to prior KV cache\nmanagement methods while offering substantially better model accuracy.\n","authors":["Wonbeom Lee","Jungi Lee","Junghwan Seo","Jaewoong Sim"],"pdf_url":"https://arxiv.org/pdf/2406.19707v1.pdf","comment":"OSDI 2024"},{"id":"http://arxiv.org/abs/2406.12569v2","updated":"2024-06-28T07:23:16Z","published":"2024-06-18T12:57:33Z","title":"MOYU: A Theoretical Study on Massive Over-activation Yielded Uplifts in\n  LLMs","summary":"  Massive Over-activation Yielded Uplifts(MOYU) is an inherent property of\nlarge language models, and dynamic activation(DA) based on the MOYU property is\na clever yet under-explored strategy designed to accelerate inference in these\nmodels. Existing methods that utilize MOYU often face a significant 'Impossible\nTrinity': struggling to simultaneously maintain model performance, enhance\ninference speed, and extend applicability across various architectures. Due to\nthe theoretical ambiguities surrounding MOYU, this paper elucidates the root\ncause of the MOYU property and outlines the mechanisms behind two primary\nlimitations encountered by current DA methods: 1) history-related activation\nuncertainty, and 2) semantic-irrelevant activation inertia. Our analysis not\nonly underscores the limitations of current dynamic activation strategies\nwithin large-scale LLaMA models but also proposes opportunities for refining\nthe design of future sparsity schemes.\n","authors":["Chi Ma","Mincong Huang","Chao Wang","Yujie Wang","Lei Yu"],"pdf_url":"https://arxiv.org/pdf/2406.12569v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11622v2","updated":"2024-06-28T07:20:22Z","published":"2024-02-18T15:28:39Z","title":"Logical Closed Loop: Uncovering Object Hallucinations in Large\n  Vision-Language Models","summary":"  Object hallucination has been an Achilles' heel which hinders the broader\napplications of large vision-language models (LVLMs). Object hallucination\nrefers to the phenomenon that the LVLMs claim non-existent objects in the\nimage. To mitigate the object hallucinations, instruction tuning and external\nmodel-based detection methods have been proposed, which either require\nlarge-scare computational resources or depend on the detection result of\nexternal models. However, there remains an under-explored field to utilize the\nLVLM itself to alleviate object hallucinations. In this work, we adopt the\nintuition that the LVLM tends to respond logically consistently for existent\nobjects but inconsistently for hallucinated objects. Therefore, we propose a\nLogical Closed Loop-based framework for Object Hallucination Detection and\nMitigation, namely LogicCheckGPT. In specific, we devise logical consistency\nprobing to raise questions with logical correlations, inquiring about\nattributes from objects and vice versa. Whether their responses can form a\nlogical closed loop serves as an indicator of object hallucination. As a\nplug-and-play method, it can be seamlessly applied to all existing LVLMs.\nComprehensive experiments conducted on three benchmarks across four LVLMs have\ndemonstrated significant improvements brought by our method, indicating its\neffectiveness and generality.\n","authors":["Junfei Wu","Qiang Liu","Ding Wang","Jinghao Zhang","Shu Wu","Liang Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2402.11622v2.pdf","comment":"Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2401.11447v4","updated":"2024-06-28T06:53:51Z","published":"2024-01-21T09:55:47Z","title":"Sequential Model for Predicting Patient Adherence in Subcutaneous\n  Immunotherapy for Allergic Rhinitis","summary":"  Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal\ntreatment of allergic rhinitis (AR). How to enhance the adherence of patients\nto maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in\nthe management of AIT. This study aims to leverage novel machine learning\nmodels to precisely predict the risk of non-adherence of AR patients and\nrelated local symptom scores in three years SCIT.\n  Methods: The research develops and analyzes two models, sequential\nlatent-variable model (SLVM) of Sequential Latent Actor-Critic (SLAC) and Long\nShort-Term Memory (LSTM) evaluating them based on scoring and adherence\nprediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive\nadherence accuracy of the SLAC models is from 60\\% to 72\\%, and for LSTM\nmodels, it is 66\\% to 84\\%, varying according to the time steps. The range of\nRoot Mean Square Error (RMSE) for SLAC models is between 0.93 and 2.22, while\nfor LSTM models it is between 1.09 and 1.77. Notably, these RMSEs are\nsignificantly lower than the random prediction error of 4.55.\n  Conclusion: We creatively apply sequential models in the long-term management\nof SCIT with promising accuracy in the prediction of SCIT nonadherence in AR\npatients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in\nscore prediction for patients undergoing SCIT for AR. The state-action-based\nSLAC adds flexibility, presenting a novel and effective approach for managing\nlong-term AIT.\n","authors":["Yin Li","Yu Xiong","Wenxin Fan","Kai Wang","Qingqing Yu","Liping Si","Patrick van der Smagt","Jun Tang","Nutan Chen"],"pdf_url":"https://arxiv.org/pdf/2401.11447v4.pdf","comment":"Frontiers in Pharmacology, research topic: Methods and Metrics to\n  Measure Medication Adherence"},{"id":"http://arxiv.org/abs/2406.17963v2","updated":"2024-06-28T06:44:45Z","published":"2024-06-25T22:44:53Z","title":"Empowering Interdisciplinary Insights with Dynamic Graph Embedding\n  Trajectories","summary":"  We developed DyGETViz, a novel framework for effectively visualizing dynamic\ngraphs (DGs) that are ubiquitous across diverse real-world systems. This\nframework leverages recent advancements in discrete-time dynamic graph (DTDG)\nmodels to adeptly handle the temporal dynamics inherent in dynamic graphs.\nDyGETViz effectively captures both micro- and macro-level structural shifts\nwithin these graphs, offering a robust method for representing complex and\nmassive dynamic graphs. The application of DyGETViz extends to a diverse array\nof domains, including ethology, epidemiology, finance, genetics, linguistics,\ncommunication studies, social studies, and international relations. Through its\nimplementation, DyGETViz has revealed or confirmed various critical insights.\nThese include the diversity of content sharing patterns and the degree of\nspecialization within online communities, the chronological evolution of\nlexicons across decades, and the distinct trajectories exhibited by\naging-related and non-related genes. Importantly, DyGETViz enhances the\naccessibility of scientific findings to non-domain experts by simplifying the\ncomplexities of dynamic graphs. Our framework is released as an open-source\nPython package for use across diverse disciplines. Our work not only addresses\nthe ongoing challenges in visualizing and analyzing DTDG models but also\nestablishes a foundational framework for future investigations into dynamic\ngraph representation and analysis across various disciplines.\n","authors":["Yiqiao Jin","Andrew Zhao","Yeon-Chang Lee","Meng Ye","Ajay Divakaran","Srijan Kumar"],"pdf_url":"https://arxiv.org/pdf/2406.17963v2.pdf","comment":"27 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.19674v1","updated":"2024-06-28T06:22:23Z","published":"2024-06-28T06:22:23Z","title":"Less is More: Accurate Speech Recognition & Translation without\n  Web-Scale Data","summary":"  Recent advances in speech recognition and translation rely on hundreds of\nthousands of hours of Internet speech data. We argue that state-of-the art\naccuracy can be reached without relying on web-scale data. Canary -\nmultilingual ASR and speech translation model, outperforms current\nstate-of-the-art models - Whisper, OWSM, and Seamless-M4T on English, French,\nSpanish, and German languages, while being trained on an order of magnitude\nless data than these models. Three key factors enables such data-efficient\nmodel: (1) a FastConformer-based attention encoder-decoder architecture (2)\ntraining on synthetic data generated with machine translation and (3) advanced\ntraining techniques: data-balancing, dynamic data blending, dynamic bucketing\nand noise-robust fine-tuning. The model, weights, and training code will be\nopen-sourced.\n","authors":["Krishna C. Puvvada","Piotr Żelasko","He Huang","Oleksii Hrinchuk","Nithin Rao Koluguri","Kunal Dhawan","Somshubra Majumdar","Elena Rastorgueva","Zhehuai Chen","Vitaly Lavrukhin","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2406.19674v1.pdf","comment":"Accepted at Interspeech-2024"},{"id":"http://arxiv.org/abs/2406.17051v2","updated":"2024-06-28T05:50:11Z","published":"2024-06-24T18:13:09Z","title":"Leveraging Knowledge Distillation for Lightweight Skin Cancer\n  Classification: Balancing Accuracy and Computational Efficiency","summary":"  Skin cancer is a major concern to public health, accounting for one-third of\nthe reported cancers. If not detected early, the cancer has the potential for\nsevere consequences. Recognizing the critical need for effective skin cancer\nclassification, we address the limitations of existing models, which are often\ntoo large to deploy in areas with limited computational resources. In response,\nwe present a knowledge distillation based approach for creating a lightweight\nyet high-performing classifier. The proposed solution involves fusing three\nmodels, namely ResNet152V2, ConvNeXtBase, and ViT Base, to create an effective\nteacher model. The teacher model is then employed to guide a lightweight\nstudent model of size 2.03 MB. This student model is further compressed to\n469.77 KB using 16-bit quantization, enabling smooth incorporation into edge\ndevices. With six-stage image preprocessing, data augmentation, and a rigorous\nablation study, the model achieves an impressive accuracy of 98.75% on the\nHAM10000 dataset and 98.94% on the Kaggle dataset in classifying benign and\nmalignant skin cancers. With its high accuracy and compact size, our model\nappears to be a potential choice for accurate skin cancer classification,\nparticularly in resource-constrained settings.\n","authors":["Niful Islam","Khan Md Hasib","Fahmida Akter Joti","Asif Karim","Sami Azam"],"pdf_url":"https://arxiv.org/pdf/2406.17051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19670v1","updated":"2024-06-28T05:44:47Z","published":"2024-06-28T05:44:47Z","title":"Function+Data Flow: A Framework to Specify Machine Learning Pipelines\n  for Digital Twinning","summary":"  The development of digital twins (DTs) for physical systems increasingly\nleverages artificial intelligence (AI), particularly for combining data from\ndifferent sources or for creating computationally efficient, reduced-dimension\nmodels. Indeed, even in very different application domains, twinning employs\ncommon techniques such as model order reduction and modelization with hybrid\ndata (that is, data sourced from both physics-based models and sensors).\nDespite this apparent generality, current development practices are ad-hoc,\nmaking the design of AI pipelines for digital twinning complex and\ntime-consuming. Here we propose Function+Data Flow (FDF), a domain-specific\nlanguage (DSL) to describe AI pipelines within DTs. FDF aims to facilitate the\ndesign and validation of digital twins. Specifically, FDF treats functions as\nfirst-class citizens, enabling effective manipulation of models learned with\nAI. We illustrate the benefits of FDF on two concrete use cases from different\ndomains: predicting the plastic strain of a structure and modeling the\nelectromagnetic behavior of a bearing.\n","authors":["Eduardo de Conto","Blaise Genest","Arvind Easwaran"],"pdf_url":"https://arxiv.org/pdf/2406.19670v1.pdf","comment":"10 pages, 5 figures, to be published in AIware'24"},{"id":"http://arxiv.org/abs/2406.19237v2","updated":"2024-06-28T05:43:46Z","published":"2024-06-27T15:01:48Z","title":"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with\n  Flowcharts","summary":"  Existing benchmarks for visual question answering lack in visual grounding\nand complexity, particularly in evaluating spatial reasoning skills. We\nintroduce FlowVQA, a novel benchmark aimed at assessing the capabilities of\nvisual question-answering multimodal language models in reasoning with\nflowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and\nhuman-verified flowchart images from three distinct content sources, along with\n22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,\nincluding information localization, decision-making, and logical progression.\nWe conduct a thorough baseline evaluation on a suite of both open-source and\nproprietary multimodal language models using various strategies, followed by an\nanalysis of directional bias. The results underscore the benchmark's potential\nas a vital tool for advancing the field of multimodal modeling, providing a\nfocused and challenging environment for enhancing model performance in visual\nand logical reasoning tasks.\n","authors":["Shubhankar Singh","Purvi Chaurasia","Yerram Varun","Pranshu Pandya","Vatsal Gupta","Vivek Gupta","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2406.19237v2.pdf","comment":"Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables"},{"id":"http://arxiv.org/abs/2406.11741v3","updated":"2024-06-28T05:28:27Z","published":"2024-06-17T17:00:52Z","title":"Transcendence: Generative Models Can Outperform The Experts That Train\n  Them","summary":"  Generative models are trained with the simple objective of imitating the\nconditional probability distribution induced by the data they are trained on.\nTherefore, when trained on data generated by humans, we may not expect the\nartificial model to outperform the humans on their original objectives. In this\nwork, we study the phenomenon of transcendence: when a generative model\nachieves capabilities that surpass the abilities of the experts generating its\ndata. We demonstrate transcendence by training an autoregressive transformer to\nplay chess from game transcripts, and show that the trained model can sometimes\nachieve better performance than all players in the dataset. We theoretically\nprove that transcendence can be enabled by low-temperature sampling, and\nrigorously assess this claim experimentally. Finally, we discuss other sources\nof transcendence, laying the groundwork for future investigation of this\nphenomenon in a broader setting.\n","authors":["Edwin Zhang","Vincent Zhu","Naomi Saphra","Anat Kleiman","Benjamin L. Edelman","Milind Tambe","Sham M. Kakade","Eran Malach"],"pdf_url":"https://arxiv.org/pdf/2406.11741v3.pdf","comment":"Code, models, and data at https://transcendence.eddie.win"},{"id":"http://arxiv.org/abs/2406.19662v1","updated":"2024-06-28T05:13:43Z","published":"2024-06-28T05:13:43Z","title":"Finite basis Kolmogorov-Arnold networks: domain decomposition for\n  data-driven and physics-informed problems","summary":"  Kolmogorov-Arnold networks (KANs) have attracted attention recently as an\nalternative to multilayer perceptrons (MLPs) for scientific machine learning.\nHowever, KANs can be expensive to train, even for relatively small networks.\nInspired by finite basis physics-informed neural networks (FBPINNs), in this\nwork, we develop a domain decomposition method for KANs that allows for several\nsmall KANs to be trained in parallel to give accurate solutions for multiscale\nproblems. We show that finite basis KANs (FBKANs) can provide accurate results\nwith noisy data and for physics-informed training.\n","authors":["Amanda A. Howard","Bruno Jacob","Sarah H. Murphy","Alexander Heinlein","Panos Stinis"],"pdf_url":"https://arxiv.org/pdf/2406.19662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19657v1","updated":"2024-06-28T04:56:53Z","published":"2024-06-28T04:56:53Z","title":"LLMEasyQuant -- An Easy to Use Toolkit for LLM Quantization","summary":"  Currently, there are many quantization methods appeared for LLM quantization,\nyet few are user-friendly and easy to be deployed locally. Packages like\nTensorRT and Quantohave many underlying structures and self-invoking internal\nfunctions, which are not conducive to developers' personalized development and\nlearning for deployment. Therefore, we develop LLMEasyQuant, it is a package\naiming to for easy quantization deployment which is user-friendly and suitable\nfor beginners' learning.\n","authors":["Dong Liu","Meng Jiang","Kaiser Pister"],"pdf_url":"https://arxiv.org/pdf/2406.19657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19653v1","updated":"2024-06-28T04:48:05Z","published":"2024-06-28T04:48:05Z","title":"ACES: Automatic Cohort Extraction System for Event-Stream Datasets","summary":"  Reproducibility remains a significant challenge in machine learning (ML) for\nhealthcare. In this field, datasets, model pipelines, and even task/cohort\ndefinitions are often private, leading to a significant barrier in sharing,\niterating, and understanding ML results on electronic health record (EHR)\ndatasets. In this paper, we address a significant part of this problem by\nintroducing the Automatic Cohort Extraction System for Event-Stream Datasets\n(ACES). This tool is designed to simultaneously simplify the development of\ntask/cohorts for ML in healthcare and enable the reproduction of these cohorts,\nboth at an exact level for single datasets and at a conceptual level across\ndatasets. To accomplish this, ACES provides (1) a highly intuitive and\nexpressive configuration language for defining both dataset-specific concepts\nand dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to\nautomatically extract patient records that meet these defined criteria from\nreal-world data. ACES can be automatically applied to any dataset in either the\nMedical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to\n*any* dataset for which the necessary task-specific predicates can be extracted\nin an event-stream form. ACES has the potential to significantly lower the\nbarrier to entry for defining ML tasks, redefine the way researchers interact\nwith EHR datasets, and significantly improve the state of reproducibility for\nML studies in this modality. ACES is available at\nhttps://github.com/justin13601/aces.\n","authors":["Justin Xu","Jack Gallifant","Alistair E. W. Johnson","Matthew B. A. McDermott"],"pdf_url":"https://arxiv.org/pdf/2406.19653v1.pdf","comment":"For ACES Online Documentation, see\n  https://eventstreamaces.readthedocs.io/en/latest/"},{"id":"http://arxiv.org/abs/2403.03181v2","updated":"2024-06-28T04:15:33Z","published":"2024-03-05T18:19:29Z","title":"Behavior Generation with Latent Actions","summary":"  Generative modeling of complex behaviors from labeled datasets has been a\nlongstanding problem in decision making. Unlike language or image generation,\ndecision making requires modeling actions - continuous-valued vectors that are\nmultimodal in their distribution, potentially drawn from uncurated sources,\nwhere generation errors can compound in sequential prediction. A recent class\nof models called Behavior Transformers (BeT) addresses this by discretizing\nactions using k-means clustering to capture different modes. However, k-means\nstruggles to scale for high-dimensional action spaces or long sequences, and\nlacks gradient information, and thus BeT suffers in modeling long-range\nactions. In this work, we present Vector-Quantized Behavior Transformer\n(VQ-BeT), a versatile model for behavior generation that handles multimodal\naction prediction, conditional generation, and partial observations. VQ-BeT\naugments BeT by tokenizing continuous actions with a hierarchical vector\nquantization module. Across seven environments including simulated\nmanipulation, autonomous driving, and robotics, VQ-BeT improves on\nstate-of-the-art models such as BeT and Diffusion Policies. Importantly, we\ndemonstrate VQ-BeT's improved ability to capture behavior modes while\naccelerating inference speed 5x over Diffusion Policies. Videos and code can be\nfound https://sjlee.cc/vq-bet\n","authors":["Seungjae Lee","Yibin Wang","Haritheja Etukuru","H. Jin Kim","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2403.03181v2.pdf","comment":"Github repo: https://github.com/jayLEE0301/vq_bet_official"},{"id":"http://arxiv.org/abs/2406.19642v1","updated":"2024-06-28T04:14:35Z","published":"2024-06-28T04:14:35Z","title":"IDT: Dual-Task Adversarial Attacks for Privacy Protection","summary":"  Natural language processing (NLP) models may leak private information in\ndifferent ways, including membership inference, reconstruction or attribute\ninference attacks. Sensitive information may not be explicit in the text, but\nhidden in underlying writing characteristics. Methods to protect privacy can\ninvolve using representations inside models that are demonstrated not to detect\nsensitive attributes or -- for instance, in cases where users might not trust a\nmodel, the sort of scenario of interest here -- changing the raw text before\nmodels can have access to it. The goal is to rewrite text to prevent someone\nfrom inferring a sensitive attribute (e.g. the gender of the author, or their\nlocation by the writing style) whilst keeping the text useful for its original\nintention (e.g. the sentiment of a product review). The few works tackling this\nhave focused on generative techniques. However, these often create extensively\ndifferent texts from the original ones or face problems such as mode collapse.\nThis paper explores a novel adaptation of adversarial attack techniques to\nmanipulate a text to deceive a classifier w.r.t one task (privacy) whilst\nkeeping the predictions of another classifier trained for another task\n(utility) unchanged. We propose IDT, a method that analyses predictions made by\nauxiliary and interpretable models to identify which tokens are important to\nchange for the privacy task, and which ones should be kept for the utility\ntask. We evaluate different datasets for NLP suitable for different tasks.\nAutomatic and human evaluations show that IDT retains the utility of text,\nwhile also outperforming existing methods when deceiving a classifier w.r.t\nprivacy task.\n","authors":["Pedro Faustini","Shakila Mahjabin Tonni","Annabelle McIver","Qiongkai Xu","Mark Dras"],"pdf_url":"https://arxiv.org/pdf/2406.19642v1.pdf","comment":"28 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.02105v2","updated":"2024-06-28T04:05:53Z","published":"2024-06-04T08:33:56Z","title":"Kernel vs. Kernel: Exploring How the Data Structure Affects Neural\n  Collapse","summary":"  Recently, a vast amount of literature has focused on the \"Neural Collapse\"\n(NC) phenomenon, which emerges when training neural network (NN) classifiers\nbeyond the zero training error point. The core component of NC is the decrease\nin the within class variability of the network's deepest features, dubbed as\nNC1. The theoretical works that study NC are typically based on simplified\nunconstrained features models (UFMs) that mask any effect of the data on the\nextent of collapse. In this paper, we provide a kernel-based analysis that does\nnot suffer from this limitation. First, given a kernel function, we establish\nexpressions for the traces of the within- and between-class covariance matrices\nof the samples' features (and consequently an NC1 metric). Then, we turn to\nfocus on kernels associated with shallow NNs. First, we consider the NN\nGaussian Process kernel (NNGP), associated with the network at initialization,\nand the complement Neural Tangent Kernel (NTK), associated with its training in\nthe \"lazy regime\". Interestingly, we show that the NTK does not represent more\ncollapsed features than the NNGP for prototypical data models. As NC emerges\nfrom training, we then consider an alternative to NTK: the recently proposed\nadaptive kernel, which generalizes NNGP to model the feature mapping learned\nfrom the training data. Contrasting our NC1 analysis for these two kernels\nenables gaining insights into the effect of data distribution on the extent of\ncollapse, which are empirically aligned with the behavior observed with\npractical training of NNs.\n","authors":["Vignesh Kothapalli","Tom Tirer"],"pdf_url":"https://arxiv.org/pdf/2406.02105v2.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2405.16141v3","updated":"2024-06-28T03:59:15Z","published":"2024-05-25T09:21:43Z","title":"AIGB: Generative Auto-bidding via Diffusion Modeling","summary":"  Auto-bidding plays a crucial role in facilitating online advertising by\nautomatically providing bids for advertisers. Reinforcement learning (RL) has\ngained popularity for auto-bidding. However, most current RL auto-bidding\nmethods are modeled through the Markovian Decision Process (MDP), which assumes\nthe Markovian state transition. This assumption restricts the ability to\nperform in long horizon scenarios and makes the model unstable when dealing\nwith highly random online advertising environments. To tackle this issue, this\npaper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding\nthrough generative modeling. In this paradigm, we propose DiffBid, a\nconditional diffusion modeling approach for bid generation. DiffBid directly\nmodels the correlation between the return and the entire trajectory,\neffectively avoiding error propagation across time steps in long horizons.\nAdditionally, DiffBid offers a versatile approach for generating trajectories\nthat maximize given targets while adhering to specific constraints. Extensive\nexperiments conducted on the real-world dataset and online A/B test on Alibaba\nadvertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%\nincrease in GMV and 3.36% increase in ROI.\n","authors":["Jiayan Guo","Yusen Huo","Zhilin Zhang","Tianyu Wang","Chuan Yu","Jian Xu","Yan Zhang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2405.16141v3.pdf","comment":"Accepted by KDD 2024"},{"id":"http://arxiv.org/abs/2301.12616v4","updated":"2024-06-28T03:57:21Z","published":"2023-01-30T02:23:49Z","title":"Active Sequential Two-Sample Testing","summary":"  A two-sample hypothesis test is a statistical procedure used to determine\nwhether the distributions generating two samples are identical. We consider the\ntwo-sample testing problem in a new scenario where the sample measurements (or\nsample features) are inexpensive to access, but their group memberships (or\nlabels) are costly. To address the problem, we devise the first \\emph{active\nsequential two-sample testing framework} that not only sequentially but also\n\\emph{actively queries}. Our test statistic is a likelihood ratio where one\nlikelihood is found by maximization over all class priors, and the other is\nprovided by a probabilistic classification model. The classification model is\nadaptively updated and used to predict where the (unlabelled) features have a\nhigh dependency on labels; labeling the ``high-dependency'' features leads to\nthe increased power of the proposed testing framework. In theory, we provide\nthe proof that our framework produces an \\emph{anytime-valid} $p$-value. In\naddition, we characterize the proposed framework's gain in testing power by\nanalyzing the mutual information between the feature and label variables in\nasymptotic and finite-sample scenarios. In practice, we introduce an\ninstantiation of our framework and evaluate it using several experiments; the\nexperiments on the synthetic, MNIST, and application-specific datasets\ndemonstrate that the testing power of the instantiated active sequential test\nsignificantly increases while the Type I error is under control.\n","authors":["Weizhi Li","Prad Kadambi","Pouria Saidi","Karthikeyan Natesan Ramamurthy","Gautam Dasarathy","Visar Berisha"],"pdf_url":"https://arxiv.org/pdf/2301.12616v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12807v7","updated":"2024-06-28T03:55:48Z","published":"2024-05-21T13:58:17Z","title":"FAdam: Adam is a natural gradient optimizer using diagonal empirical\n  Fisher information","summary":"  This paper establishes a mathematical foundation for the Adam optimizer,\nelucidating its connection to natural gradient descent through Riemannian and\ninformation geometry. We rigorously analyze the diagonal empirical Fisher\ninformation matrix (FIM) in Adam, clarifying all detailed approximations and\nadvocating for the use of log probability functions as loss, which should be\nbased on discrete distributions, due to the limitations of empirical FIM. Our\nanalysis uncovers flaws in the original Adam algorithm, leading to proposed\ncorrections such as enhanced momentum calculations, adjusted bias corrections,\nadaptive epsilon, and gradient clipping. We refine the weight decay term based\non our theoretical framework. Our modified algorithm, Fisher Adam (FAdam),\ndemonstrates superior performance across diverse domains including LLM, ASR,\nand VQ-VAE, achieving state-of-the-art results in ASR.\n","authors":["Dongseong Hwang"],"pdf_url":"https://arxiv.org/pdf/2405.12807v7.pdf","comment":"21 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2310.01712v2","updated":"2024-06-28T03:53:56Z","published":"2023-10-03T00:54:13Z","title":"Generative Autoencoding of Dropout Patterns","summary":"  We propose a generative model termed Deciphering Autoencoders. In this model,\nwe assign a unique random dropout pattern to each data point in the training\ndataset and then train an autoencoder to reconstruct the corresponding data\npoint using this pattern as information to be encoded. Even if a completely\nrandom dropout pattern is assigned to each data point regardless of their\nsimilarities, a sufficiently large encoder can smoothly map them to a\nlow-dimensional latent space to reconstruct individual training data points.\nDuring inference, using a dropout pattern different from those used during\ntraining allows the model to function as a generator. Since the training of\nDeciphering Autoencoders relies solely on reconstruction error, it offers more\nstable training compared to other generative models. Despite their simplicity,\nDeciphering Autoencoders show sampling quality comparable to DCGAN on the\nCIFAR-10 dataset.\n","authors":["Shunta Maeda"],"pdf_url":"https://arxiv.org/pdf/2310.01712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04607v4","updated":"2024-06-28T03:53:21Z","published":"2024-06-07T03:31:58Z","title":"MeGA: Merging Multiple Independently Trained Neural Networks Based on\n  Genetic Algorithm","summary":"  In this paper, we introduce a novel method for merging the weights of\nmultiple pre-trained neural networks using a genetic algorithm called MeGA.\nTraditional techniques, such as weight averaging and ensemble methods, often\nfail to fully harness the capabilities of pre-trained networks. Our approach\nleverages a genetic algorithm with tournament selection, crossover, and\nmutation to optimize weight combinations, creating a more effective fusion.\nThis technique allows the merged model to inherit advantageous features from\nboth parent models, resulting in enhanced accuracy and robustness. Through\nexperiments on the CIFAR-10 dataset, we demonstrate that our genetic\nalgorithm-based weight merging method improves test accuracy compared to\nindividual models and conventional methods. This approach provides a scalable\nsolution for integrating multiple pre-trained networks across various deep\nlearning applications. Github is available at:\nhttps://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm\n","authors":["Daniel Yun"],"pdf_url":"https://arxiv.org/pdf/2406.04607v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10930v3","updated":"2024-06-28T03:51:23Z","published":"2024-05-17T17:31:02Z","title":"Submodular Information Selection for Hypothesis Testing with\n  Misclassification Penalties","summary":"  We consider the problem of selecting an optimal subset of information sources\nfor a hypothesis testing/classification task where the goal is to identify the\ntrue state of the world from a finite set of hypotheses, based on finite\nobservation samples from the sources. In order to characterize the learning\nperformance, we propose a misclassification penalty framework, which enables\nnonuniform treatment of different misclassification errors. In a centralized\nBayesian learning setting, we study two variants of the subset selection\nproblem: (i) selecting a minimum cost information set to ensure that the\nmaximum penalty of misclassifying the true hypothesis is below a desired bound\nand (ii) selecting an optimal information set under a limited budget to\nminimize the maximum penalty of misclassifying the true hypothesis. Under\ncertain assumptions, we prove that the objective (or constraints) of these\ncombinatorial optimization problems are weak (or approximate) submodular, and\nestablish high-probability performance guarantees for greedy algorithms.\nFurther, we propose an alternate metric for information set selection which is\nbased on the total penalty of misclassification. We prove that this metric is\nsubmodular and establish near-optimal guarantees for the greedy algorithms for\nboth the information set selection problems. Finally, we present numerical\nsimulations to validate our theoretical results over several randomly generated\ninstances.\n","authors":["Jayanth Bhargav","Mahsa Ghasemi","Shreyas Sundaram"],"pdf_url":"https://arxiv.org/pdf/2405.10930v3.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.19636v1","updated":"2024-06-28T03:47:54Z","published":"2024-06-28T03:47:54Z","title":"Enforcing Equity in Neural Climate Emulators","summary":"  Neural network emulators have become an invaluable tool for a wide variety of\nclimate and weather prediction tasks. While showing incredibly promising\nresults, these networks do not have an inherent ability to produce equitable\npredictions. That is, they are not guaranteed to provide a uniform quality of\nprediction along any particular class or group of people. This potential for\ninequitable predictions motivates the need for explicit representations of\nfairness in these neural networks. To that end, we draw on methods for\nenforcing analytical physical constraints in neural networks to bias networks\ntowards more equitable predictions. We demonstrate the promise of this\nmethodology using the task of climate model emulation. Specifically, we propose\na custom loss function which punishes emulators with unequal quality of\npredictions across any prespecified regions or category, here defined using\nhuman development index (HDI). This loss function weighs a standard loss metric\nsuch as mean squared error against another metric which captures inequity along\nthe equity category (HDI), allowing us to adjust the priority of each term\nbefore training. Importantly, the loss function does not specify a particular\ndefinition of equity to bias the neural network towards, opening the door for\ncustom fairness metrics. Our results show that neural climate emulators trained\nwith our loss function provide more equitable predictions and that the equity\nmetric improves with greater weighting in the loss function. We empirically\ndemonstrate that while there is a tradeoff between accuracy and equity when\nprioritizing the latter during training, an appropriate selection of the equity\npriority hyperparameter can minimize loss of performance.\n","authors":["William Yik","Sam J. Silva"],"pdf_url":"https://arxiv.org/pdf/2406.19636v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.19635v1","updated":"2024-06-28T03:46:53Z","published":"2024-06-28T03:46:53Z","title":"Model Predictive Simulation Using Structured Graphical Models and\n  Transformers","summary":"  We propose an approach to simulating trajectories of multiple interacting\nagents (road users) based on transformers and probabilistic graphical models\n(PGMs), and apply it to the Waymo SimAgents challenge. The transformer baseline\nis based on the MTR model, which predicts multiple future trajectories\nconditioned on the past trajectories and static road layout features. We then\nimprove upon these generated trajectories using a PGM, which contains factors\nwhich encode prior knowledge, such as a preference for smooth trajectories, and\navoidance of collisions with static obstacles and other moving agents. We\nperform (approximate) MAP inference in this PGM using the Gauss-Newton method.\nFinally we sample $K=32$ trajectories for each of the $N \\sim 100$ agents for\nthe next $T=8 \\Delta$ time steps, where $\\Delta=10$ is the sampling rate per\nsecond. Following the Model Predictive Control (MPC) paradigm, we only return\nthe first element of our forecasted trajectories at each step, and then we\nreplan, so that the simulation can constantly adapt to its changing\nenvironment. We therefore call our approach \"Model Predictive Simulation\" or\nMPS. We show that MPS improves upon the MTR baseline, especially in safety\ncritical metrics such as collision rate. Furthermore, our approach is\ncompatible with any underlying forecasting model, and does not require extra\ntraining, so we believe it is a valuable contribution to the community.\n","authors":["Xinghua Lou","Meet Dave","Shrinu Kushagra","Miguel Lazaro-Gredilla","Kevin Murphy"],"pdf_url":"https://arxiv.org/pdf/2406.19635v1.pdf","comment":"Special Mention at the Waymo Sim Agents Challenge 2024"},{"id":"http://arxiv.org/abs/2406.19631v1","updated":"2024-06-28T03:39:45Z","published":"2024-06-28T03:39:45Z","title":"Personalized Interpretation on Federated Learning: A Virtual Concepts\n  approach","summary":"  Tackling non-IID data is an open challenge in federated learning research.\nExisting FL methods, including robust FL and personalized FL, are designed to\nimprove model performance without consideration of interpreting non-IID across\nclients. This paper aims to design a novel FL method to robust and interpret\nthe non-IID data across clients. Specifically, we interpret each client's\ndataset as a mixture of conceptual vectors that each one represents an\ninterpretable concept to end-users. These conceptual vectors could be\npre-defined or refined in a human-in-the-loop process or be learnt via the\noptimization procedure of the federated learning system. In addition to the\ninterpretability, the clarity of client-specific personalization could also be\napplied to enhance the robustness of the training process on FL system. The\neffectiveness of the proposed method have been validated on benchmark datasets.\n","authors":["Peng Yan","Guodong Long","Jing Jiang","Michael Blumenstein"],"pdf_url":"https://arxiv.org/pdf/2406.19631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13650v3","updated":"2024-06-28T03:33:28Z","published":"2023-05-23T03:47:32Z","title":"Robust Model-Based Optimization for Challenging Fitness Landscapes","summary":"  Protein design, a grand challenge of the day, involves optimization on a\nfitness landscape, and leading methods adopt a model-based approach where a\nmodel is trained on a training set (protein sequences and fitness) and proposes\ncandidates to explore next. These methods are challenged by sparsity of\nhigh-fitness samples in the training set, a problem that has been in the\nliterature. A less recognized but equally important problem stems from the\ndistribution of training samples in the design space: leading methods are not\ndesigned for scenarios where the desired optimum is in a region that is not\nonly poorly represented in training data, but also relatively far from the\nhighly represented low-fitness regions. We show that this problem of\n\"separation\" in the design space is a significant bottleneck in existing\nmodel-based optimization tools and propose a new approach that uses a novel VAE\nas its search model to overcome the problem. We demonstrate its advantage over\nprior methods in robustly finding improved samples, regardless of the imbalance\nand separation between low- and high-fitness samples. Our comprehensive\nbenchmark on real and semi-synthetic protein datasets as well as solution\ndesign for physics-informed neural networks, showcases the generality of our\napproach in discrete and continuous design spaces. Our implementation is\navailable at https://github.com/sabagh1994/PGVAE.\n","authors":["Saba Ghaffari","Ehsan Saleh","Alexander G. Schwing","Yu-Xiong Wang","Martin D. Burke","Saurabh Sinha"],"pdf_url":"https://arxiv.org/pdf/2305.13650v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05743v4","updated":"2024-06-28T03:17:12Z","published":"2024-03-09T00:41:30Z","title":"Forecasting Electricity Market Signals via Generative AI","summary":"  This paper presents a generative artificial intelligence approach to\nprobabilistic forecasting of electricity market signals, such as real-time\nlocational marginal prices and area control error signals. Inspired by the\nWiener-Kallianpur innovation representation of nonparametric time series, we\npropose a weak innovation autoencoder architecture and a novel deep learning\nalgorithm that extracts the canonical independent and identically distributed\ninnovation sequence of the time series, from which samples of future time\nseries are generated. The validity of the proposed approach is established by\nproving that, under ideal training conditions, the generated samples have the\nsame conditional probability distribution as that of the ground truth. Three\napplications involving highly dynamic and volatile time series in real-time\nmarket operations are considered: (i) locational marginal price forecasting for\nself-scheduled resources such as battery storage participants, (ii)\ninterregional price spread forecasting for virtual bidders in interchange\nmarkets, and (iii) area control error forecasting for frequency regulations.\nNumerical studies based on market data from multiple independent system\noperators demonstrate the superior performance of the proposed generative\nforecaster over leading classical and modern machine learning techniques under\nboth probabilistic and point forecasting metrics.\n","authors":["Xinyi Wang","Qing Zhao","Lang Tong"],"pdf_url":"https://arxiv.org/pdf/2403.05743v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19622v1","updated":"2024-06-28T03:10:36Z","published":"2024-06-28T03:10:36Z","title":"Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve\n  Adversarial Robustness","summary":"  The security and robustness of deep neural networks (DNNs) have become\nincreasingly concerning. This paper aims to provide both a theoretical\nfoundation and a practical solution to ensure the reliability of DNNs. We\nexplore the concept of Lipschitz continuity to certify the robustness of DNNs\nagainst adversarial attacks, which aim to mislead the network with adding\nimperceptible perturbations into inputs. We propose a novel algorithm that\nremaps the input domain into a constrained range, reducing the Lipschitz\nconstant and potentially enhancing robustness. Unlike existing adversarially\ntrained models, where robustness is enhanced by introducing additional examples\nfrom other datasets or generative models, our method is almost cost-free as it\ncan be integrated with existing models without requiring re-training.\nExperimental results demonstrate the generalizability of our method, as it can\nbe combined with various models and achieve enhancements in robustness.\nFurthermore, our method achieves the best robust accuracy for CIFAR10,\nCIFAR100, and ImageNet datasets on the RobustBench leaderboard.\n","authors":["Erh-Chung Chen","Pin-Yu Chen","I-Hsin Chung","Che-Rung Lee"],"pdf_url":"https://arxiv.org/pdf/2406.19622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19621v1","updated":"2024-06-28T03:07:53Z","published":"2024-06-28T03:07:53Z","title":"Machine-Learning-Driven Runtime Optimization of BLAS Level 3 on Modern\n  Multi-Core Systems","summary":"  BLAS Level 3 operations are essential for scientific computing, but finding\nthe optimal number of threads for multi-threaded implementations on modern\nmulti-core systems is challenging. We present an extension to the Architecture\nand Data-Structure Aware Linear Algebra (ADSALA) library that uses machine\nlearning to optimize the runtime of all BLAS Level 3 operations. Our method\npredicts the best number of threads for each operation based on the matrix\ndimensions and the system architecture. We test our method on two HPC platforms\nwith Intel and AMD processors, using MKL and BLIS as baseline BLAS\nimplementations. We achieve speedups of 1.5 to 3.0 for all operations, compared\nto using the maximum number of threads. We also analyze the runtime patterns of\ndifferent BLAS operations and explain the sources of speedup. Our work shows\nthe effectiveness and generality of the ADSALA approach for optimizing BLAS\nroutines on modern multi-core systems.\n","authors":["Yufan Xia","Giuseppe Maria Junior Barca"],"pdf_url":"https://arxiv.org/pdf/2406.19621v1.pdf","comment":"Multi-Thread, Matrix Multiplication, Optimization, BLAS, Machine\n  Learning"},{"id":"http://arxiv.org/abs/2406.19619v1","updated":"2024-06-28T03:02:25Z","published":"2024-06-28T03:02:25Z","title":"ScoreFusion: fusing score-based generative models via Kullback-Leibler\n  barycenters","summary":"  We study the problem of fusing pre-trained (auxiliary) generative models to\nenhance the training of a target generative model. We propose using\nKL-divergence weighted barycenters as an optimal fusion mechanism, in which the\nbarycenter weights are optimally trained to minimize a suitable loss for the\ntarget population. While computing the optimal KL-barycenter weights can be\nchallenging, we demonstrate that this process can be efficiently executed using\ndiffusion score training when the auxiliary generative models are also trained\nbased on diffusion score methods. Moreover, we show that our fusion method has\na dimension-free sample complexity in total variation distance provided that\nthe auxiliary models are well fitted for their own task and the auxiliary tasks\ncombined capture the target well. The main takeaway of our method is that if\nthe auxiliary models are well-trained and can borrow features from each other\nthat are present in the target, our fusion method significantly improves the\ntraining of generative models. We provide a concise computational\nimplementation of the fusion algorithm, and validate its efficiency in the\nlow-data regime with numerical experiments involving mixtures models and image\ndatasets.\n","authors":["Hao Liu"," Junze"," Ye","Jose Blanchet","Nian Si"],"pdf_url":"https://arxiv.org/pdf/2406.19619v1.pdf","comment":"40 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.19617v1","updated":"2024-06-28T02:56:22Z","published":"2024-06-28T02:56:22Z","title":"Stochastic Zeroth-Order Optimization under Strongly Convexity and\n  Lipschitz Hessian: Minimax Sample Complexity","summary":"  Optimization of convex functions under stochastic zeroth-order feedback has\nbeen a major and challenging question in online learning. In this work, we\nconsider the problem of optimizing second-order smooth and strongly convex\nfunctions where the algorithm is only accessible to noisy evaluations of the\nobjective function it queries. We provide the first tight characterization for\nthe rate of the minimax simple regret by developing matching upper and lower\nbounds. We propose an algorithm that features a combination of a bootstrapping\nstage and a mirror-descent stage. Our main technical innovation consists of a\nsharp characterization for the spherical-sampling gradient estimator under\nhigher-order smoothness conditions, which allows the algorithm to optimally\nbalance the bias-variance tradeoff, and a new iterative method for the\nbootstrapping stage, which maintains the performance for unbounded Hessian.\n","authors":["Qian Yu","Yining Wang","Baihe Huang","Qi Lei","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2406.19617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17366v3","updated":"2024-06-28T02:56:10Z","published":"2023-09-28T10:05:37Z","title":"3D-Mol: A Novel Contrastive Learning Framework for Molecular Property\n  Prediction with 3D Information","summary":"  Molecular property prediction, crucial for early drug candidate screening and\noptimization, has seen advancements with deep learning-based methods. While\ndeep learning-based methods have advanced considerably, they often fall short\nin fully leveraging 3D spatial information. Specifically, current molecular\nencoding techniques tend to inadequately extract spatial information, leading\nto ambiguous representations where a single one might represent multiple\ndistinct molecules. Moreover, existing molecular modeling methods focus\npredominantly on the most stable 3D conformations, neglecting other viable\nconformations present in reality. To address these issues, we propose 3D-Mol, a\nnovel approach designed for more accurate spatial structure representation. It\ndeconstructs molecules into three hierarchical graphs to better extract\ngeometric information. Additionally, 3D-Mol leverages contrastive learning for\npretraining on 20 million unlabeled data, treating their conformations with\nidentical topological structures as weighted positive pairs and contrasting\nones as negatives, based on the similarity of their 3D conformation descriptors\nand fingerprints. We compare 3D-Mol with various state-of-the-art baselines on\n7 benchmarks and demonstrate our outstanding performance.\n","authors":["Taojie Kuang","Yiming Ren","Zhixiang Ren"],"pdf_url":"https://arxiv.org/pdf/2309.17366v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19615v1","updated":"2024-06-28T02:42:30Z","published":"2024-06-28T02:42:30Z","title":"VarteX: Enhancing Weather Forecast through Distributed Variable\n  Representation","summary":"  Weather forecasting is essential for various human activities. Recent\ndata-driven models have outperformed numerical weather prediction by utilizing\ndeep learning in forecasting performance. However, challenges remain in\nefficiently handling multiple meteorological variables. This study proposes a\nnew variable aggregation scheme and an efficient learning framework for that\nchallenge. Experiments show that VarteX outperforms the conventional model in\nforecast performance, requiring significantly fewer parameters and resources.\nThe effectiveness of learning through multiple aggregations and regional split\ntraining is demonstrated, enabling more efficient and accurate deep\nlearning-based weather forecasting.\n","authors":["Ayumu Ueyama","Kazuhiko Kawamoto","Hiroshi Kera"],"pdf_url":"https://arxiv.org/pdf/2406.19615v1.pdf","comment":"ICML 2024, Workshop on Machine Learning for Earth System Modeling"},{"id":"http://arxiv.org/abs/2406.19614v1","updated":"2024-06-28T02:41:33Z","published":"2024-06-28T02:41:33Z","title":"A Survey on Data Quality Dimensions and Tools for Machine Learning","summary":"  Machine learning (ML) technologies have become substantial in practically all\naspects of our society, and data quality (DQ) is critical for the performance,\nfairness, robustness, safety, and scalability of ML models. With the large and\ncomplex data in data-centric AI, traditional methods like exploratory data\nanalysis (EDA) and cross-validation (CV) face challenges, highlighting the\nimportance of mastering DQ tools. In this survey, we review 17 DQ evaluation\nand improvement tools in the last 5 years. By introducing the DQ dimensions,\nmetrics, and main functions embedded in these tools, we compare their strengths\nand limitations and propose a roadmap for developing open-source DQ tools for\nML. Based on the discussions on the challenges and emerging trends, we further\nhighlight the potential applications of large language models (LLMs) and\ngenerative AI in DQ evaluation and improvement for ML. We believe this\ncomprehensive survey can enhance understanding of DQ in ML and could drive\nprogress in data-centric AI. A complete list of the literature investigated in\nthis survey is available on GitHub at:\nhttps://github.com/haihua0913/awesome-dq4ml.\n","authors":["Yuhan Zhou","Fengjiao Tu","Kewei Sha","Junhua Ding","Haihua Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19614v1.pdf","comment":"This paper has been accepted by The 6th IEEE International Conference\n  on Artificial Intelligence Testing (IEEE AITest 2024) as an invited paper"},{"id":"http://arxiv.org/abs/2406.18820v2","updated":"2024-06-28T02:33:11Z","published":"2024-06-27T01:28:30Z","title":"Universal Checkpointing: Efficient and Flexible Checkpointing for Large\n  Scale Distributed Training","summary":"  Existing checkpointing approaches seem ill-suited for distributed training\neven though hardware limitations make model parallelism, i.e., sharding model\nstate across multiple accelerators, a requirement for model scaling.\nConsolidating distributed model state into a single checkpoint unacceptably\nslows down training, and is impractical at extreme scales. Distributed\ncheckpoints, in contrast, are tightly coupled to the model parallelism and\nhardware configurations of the training run, and thus unusable on different\nconfigurations. To address this problem, we propose Universal Checkpointing, a\ntechnique that enables efficient checkpoint creation while providing the\nflexibility of resuming on arbitrary parallelism strategy and hardware\nconfigurations. Universal Checkpointing unlocks unprecedented capabilities for\nlarge-scale training such as improved resilience to hardware failures through\ncontinued training on remaining healthy hardware, and reduced training time\nthrough opportunistic exploitation of elastic capacity.\n  The key insight of Universal Checkpointing is the selection of the optimal\nrepresentation in each phase of the checkpointing life cycle: distributed\nrepresentation for saving, and consolidated representation for loading. This is\nachieved using two key mechanisms. First, the universal checkpoint format,\nwhich consists of a consolidated representation of each model parameter and\nmetadata for mapping parameter fragments into training ranks of arbitrary\nmodel-parallelism configuration. Second, the universal checkpoint language, a\nsimple but powerful specification language for converting distributed\ncheckpoints into the universal checkpoint format. Our evaluation demonstrates\nthe effectiveness and generality of Universal Checkpointing on state-of-the-art\nmodel architectures and a wide range of parallelism techniques.\n","authors":["Xinyu Lian","Sam Ade Jacobs","Lev Kurilenko","Masahiro Tanaka","Stas Bekman","Olatunji Ruwase","Minjia Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.18820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07249v3","updated":"2024-06-28T02:32:03Z","published":"2024-02-11T17:29:58Z","title":"Impact of Domain Knowledge and Multi-Modality on Intelligent Molecular\n  Property Prediction: A Systematic Survey","summary":"  The precise prediction of molecular properties is essential for advancements\nin drug development, particularly in virtual screening and compound\noptimization. The recent introduction of numerous deep learning-based methods\nhas shown remarkable potential in enhancing molecular property prediction\n(MPP), especially improving accuracy and insights into molecular structures.\nYet, two critical questions arise: does the integration of domain knowledge\naugment the accuracy of molecular property prediction and does employing\nmulti-modal data fusion yield more precise results than unique data source\nmethods? To explore these matters, we comprehensively review and quantitatively\nanalyze recent deep learning methods based on various benchmarks. We discover\nthat integrating molecular information significantly improves molecular\nproperty prediction (MPP) for both regression and classification tasks.\nSpecifically, regression improvements, measured by reductions in root mean\nsquare error (RMSE), are up to 4.0%, while classification enhancements,\nmeasured by the area under the receiver operating characteristic curve\n(ROC-AUC), are up to 1.7%. We also discover that enriching 2D graphs with 1D\nSMILES boosts multi-modal learning performance for regression tasks by up to\n9.1%, and augmenting 2D graphs with 3D information increases performance for\nclassification tasks by up to 13.2%, with both enhancements measured using\nROC-AUC. The two consolidated insights offer crucial guidance for future\nadvancements in drug discovery.\n","authors":["Taojie Kuang","Pengfei Liu","Zhixiang Ren"],"pdf_url":"https://arxiv.org/pdf/2402.07249v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06873v2","updated":"2024-06-28T02:25:20Z","published":"2024-03-11T16:24:26Z","title":"Last Iterate Convergence of Incremental Methods and Applications in\n  Continual Learning","summary":"  Incremental gradient and incremental proximal methods are a fundamental class\nof optimization algorithms used for solving finite sum problems, broadly\nstudied in the literature. Yet, without strong convexity, their convergence\nguarantees have primarily been established for the ergodic (average) iterate.\nMotivated by applications in continual learning, we obtain the first\nconvergence guarantees for the last iterate of both incremental gradient and\nincremental proximal methods, in general convex smooth (for both) and convex\nLipschitz (for the proximal variants) settings. Our oracle complexity bounds\nfor the last iterate nearly match (i.e., match up to a square-root-log or a log\nfactor) the best known oracle complexity bounds for the average iterate, for\nboth classes of methods. We further obtain generalizations of our results to\nweighted averaging of the iterates with increasing weights and for randomly\npermuted ordering of updates. We study incremental proximal methods as a model\nof continual learning with generalization and argue that large amount of\nregularization is crucial to preventing catastrophic forgetting. Our results\ngeneralize last iterate guarantees for incremental methods compared to state of\nthe art, as such results were previously known only for overparameterized\nlinear models, which correspond to convex quadratic problems with infinitely\nmany solutions.\n","authors":["Xufeng Cai","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2403.06873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19602v1","updated":"2024-06-28T02:18:16Z","published":"2024-06-28T02:18:16Z","title":"A Survey on Deep Clustering: From the Prior Perspective","summary":"  Facilitated by the powerful feature extraction ability of neural networks,\ndeep clustering has achieved great success in analyzing high-dimensional and\ncomplex real-world data. The performance of deep clustering methods is affected\nby various factors such as network structures and learning objectives. However,\nas pointed out in this survey, the essence of deep clustering lies in the\nincorporation and utilization of prior knowledge, which is largely ignored by\nexisting works. From pioneering deep clustering methods based on data structure\nassumptions to recent contrastive clustering methods based on data augmentation\ninvariances, the development of deep clustering intrinsically corresponds to\nthe evolution of prior knowledge. In this survey, we provide a comprehensive\nreview of deep clustering methods by categorizing them into six types of prior\nknowledge. We find that in general the prior innovation follows two trends,\nnamely, i) from mining to constructing, and ii) from internal to external.\nBesides, we provide a benchmark on five widely-used datasets and analyze the\nperformance of methods with diverse priors. By providing a novel prior\nknowledge perspective, we hope this survey could provide some novel insights\nand inspire future research in the deep clustering community.\n","authors":["Yiding Lu","Haobin Li","Yunfan Li","Yijie Lin","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2406.19602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19596v1","updated":"2024-06-28T01:37:46Z","published":"2024-06-28T01:37:46Z","title":"Optimizing Cyber Defense in Dynamic Active Directories through\n  Reinforcement Learning","summary":"  This paper addresses a significant gap in Autonomous Cyber Operations (ACO)\nliterature: the absence of effective edge-blocking ACO strategies in dynamic,\nreal-world networks. It specifically targets the cybersecurity vulnerabilities\nof organizational Active Directory (AD) systems. Unlike the existing literature\non edge-blocking defenses which considers AD systems as static entities, our\nstudy counters this by recognizing their dynamic nature and developing advanced\nedge-blocking defenses through a Stackelberg game model between attacker and\ndefender. We devise a Reinforcement Learning (RL)-based attack strategy and an\nRL-assisted Evolutionary Diversity Optimization-based defense strategy, where\nthe attacker and defender improve each other strategy via parallel gameplay. To\naddress the computational challenges of training attacker-defender strategies\non numerous dynamic AD graphs, we propose an RL Training Facilitator that\nprunes environments and neural networks to eliminate irrelevant elements,\nenabling efficient and scalable training for large graphs. We extensively train\nthe attacker strategy, as a sophisticated attacker model is essential for a\nrobust defense. Our empirical results successfully demonstrate that our\nproposed approach enhances defender's proficiency in hardening dynamic AD\ngraphs while ensuring scalability for large-scale AD.\n","authors":["Diksha Goel","Kristen Moore","Mingyu Guo","Derui Wang","Minjune Kim","Seyit Camtepe"],"pdf_url":"https://arxiv.org/pdf/2406.19596v1.pdf","comment":"The manuscript has been accepted as full paper at European Symposium\n  on Research in Computer Security (ESORICS) 2024"},{"id":"http://arxiv.org/abs/2404.14527v3","updated":"2024-06-28T01:24:22Z","published":"2024-04-22T18:56:18Z","title":"Mélange: Cost Efficient Large Language Model Serving by Exploiting GPU\n  Heterogeneity","summary":"  Large language models (LLMs) are increasingly integrated into many online\nservices, yet they remain cost-prohibitive to deploy due to the requirement of\nexpensive GPU instances. Prior work has addressed the high cost of LLM serving\nby improving the inference engine, but less attention has been given to\nselecting the most cost-efficient GPU type(s) for a specific LLM service. There\nis a large and growing landscape of GPU types and, within these options, higher\ncost does not always lead to increased performance. Instead, through a\ncomprehensive investigation, we find that three key LLM service characteristics\n(request size, request rate, SLO) strongly influence GPU cost efficiency, and\ndiffering GPU types are most cost efficient for differing LLM service settings.\nAs a result, the most cost-efficient allocation for a given service is\ntypically a mix of heterogeneous GPU types. Based on this analysis, we\nintroduce M\\'elange, a GPU allocation framework that navigates these diverse\nLLM service characteristics and heterogeneous GPU option space to automatically\nand efficiently derive the minimal-cost GPU allocation for a given LLM service.\nWe formulate the GPU allocation task as a cost-aware bin packing problem where\nGPUs are bins and items are slices of the service workload. Our formulation's\nconstraints account for a service's unique characteristics, allowing M\\'elange\nto be flexible to support diverse service settings and heterogeneity-aware to\nadapt the GPU allocation to a specific service. Compared to using only a single\nGPU type, M\\'elange reduces deployment costs by up to 77% in conversational\nsettings, 33% in document-based settings, and 51% in a mixed setting.\n","authors":["Tyler Griggs","Xiaoxuan Liu","Jiaxiang Yu","Doyoung Kim","Wei-Lin Chiang","Alvin Cheung","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2404.14527v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19589v1","updated":"2024-06-28T00:39:17Z","published":"2024-06-28T00:39:17Z","title":"Network Bending of Diffusion Models for Audio-Visual Generation","summary":"  In this paper we present the first steps towards the creation of a tool which\nenables artists to create music visualizations using pre-trained, generative,\nmachine learning models. First, we investigate the application of network\nbending, the process of applying transforms within the layers of a generative\nnetwork, to image generation diffusion models by utilizing a range of\npoint-wise, tensor-wise, and morphological operators. We identify a number of\nvisual effects that result from various operators, including some that are not\neasily recreated with standard image editing tools. We find that this process\nallows for continuous, fine-grain control of image generation which can be\nhelpful for creative applications. Next, we generate music-reactive videos\nusing Stable Diffusion by passing audio features as parameters to network\nbending operators. Finally, we comment on certain transforms which radically\nshift the image and the possibilities of learning more about the latent space\nof Stable Diffusion based on these transforms.\n","authors":["Luke Dzwonczyk","Carmine Emanuele Cella","David Ban"],"pdf_url":"https://arxiv.org/pdf/2406.19589v1.pdf","comment":"8 pages, 5 figures, to be published in the proceedings of the 27th\n  International Conference on Digital Audio Effects (DAFx24), for additional\n  image and video examples see https://dzluke.github.io/DAFX2024/"},{"id":"http://arxiv.org/abs/2406.19581v1","updated":"2024-06-28T00:08:13Z","published":"2024-06-28T00:08:13Z","title":"HarmonICA: Neural non-stationarity correction and source separation for\n  motor neuron interfaces","summary":"  A major outstanding problem when interfacing with spinal motor neurons is how\nto accurately compensate for non-stationary effects in the signal during source\nseparation routines, particularly when they cannot be estimated in advance.\nThis forces current systems to instead use undifferentiated bulk signal, which\nlimits the potential degrees of freedom for control. In this study we propose a\npotential solution, using an unsupervised learning algorithm to blindly correct\nfor the effects of latent processes which drive the signal non-stationarities.\nWe implement this methodology within the theoretical framework of a quasilinear\nversion of independent component analysis (ICA). The proposed design,\nHarmonICA, sidesteps the identifiability problems of nonlinear ICA, allowing\nfor equivalent predictability to linear ICA whilst retaining the ability to\nlearn complex nonlinear relationships between non-stationary latents and their\neffects on the signal. We test HarmonICA on both invasive and non-invasive\nrecordings both simulated and real, demonstrating an ability to blindly\ncompensate for the non-stationary effects specific to each, and thus to\nsignificantly enhance the quality of a source separation routine.\n","authors":["Alexander Kenneth Clarke","Agnese Grison","Irene Mendez Guerra","Pranav Mamidanna","Shihan Ma","Silvia Muceli","Dario Farina"],"pdf_url":"https://arxiv.org/pdf/2406.19581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19580v1","updated":"2024-06-28T00:05:53Z","published":"2024-06-28T00:05:53Z","title":"FRED: Flexible REduction-Distribution Interconnect and Communication\n  Implementation for Wafer-Scale Distributed Training of DNN Models","summary":"  Distributed Deep Neural Network (DNN) training is a technique to reduce the\ntraining overhead by distributing the training tasks into multiple\naccelerators, according to a parallelization strategy. However,\nhigh-performance compute and interconnects are needed for maximum speed-up and\nlinear scaling of the system. Wafer-scale systems are a promising technology\nthat allows for tightly integrating high-end accelerators with high-speed\nwafer-scale interconnects, making it an attractive platform for distributed\ntraining. However, the wafer-scale interconnect should offer high performance\nand flexibility for various parallelization strategies to enable maximum\noptimizations for compute and memory usage. In this paper, we propose FRED, a\nwafer-scale interconnect that is tailored for the high-BW requirements of\nwafer-scale networks and can efficiently execute communication patterns of\ndifferent parallelization strategies. Furthermore, FRED supports in-switch\ncollective communication execution that reduces the network traffic by\napproximately 2X. Our results show that FRED can improve the average end-to-end\ntraining time of ResNet-152, Transformer-17B, GPT-3, and Transformer-1T by\n1.76X, 1.87X, 1.34X, and 1.4X, respectively when compared to a baseline\nwaferscale 2D-Mesh fabric.\n","authors":["Saeed Rashidi","William Won","Sudarshan Srinivasan","Puneet Gupta","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.19580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05480v2","updated":"2024-06-28T00:05:14Z","published":"2024-05-09T00:37:56Z","title":"FloorSet -- a VLSI Floorplanning Dataset with Design Constraints of\n  Real-World SoCs","summary":"  Floorplanning for systems-on-a-chip (SoCs) and its sub-systems is a crucial\nand non-trivial step of the physical design flow. It represents a difficult\ncombinatorial optimization problem. A typical large scale SoC with 120\npartitions generates a search-space of nearly 10E250. As novel machine learning\n(ML) approaches emerge to tackle such problems, there is a growing need for a\nmodern benchmark that comprises a large training dataset and performance\nmetrics that better reflect real-world constraints and objectives compared to\nexisting benchmarks. To address this need, we present FloorSet -- two\ncomprehensive datasets of synthetic fixed-outline floorplan layouts that\nreflect the distribution of real SoCs. Each dataset has 1M training samples and\n100 test samples where each sample is a synthetic floor-plan. FloorSet-Prime\ncomprises fully-abutted rectilinear partitions and near-optimal wire-length. A\nsimplified dataset that reflects early design phases, FloorSet-Lite comprises\nrectangular partitions, with under 5 percent white-space and near-optimal\nwire-length. Both datasets define hard constraints seen in modern design flows\nsuch as shape constraints, edge-affinity, grouping constraints, and\npre-placement constraints. FloorSet is intended to spur fundamental research on\nlarge-scale constrained optimization problems. Crucially, FloorSet alleviates\nthe core issue of reproducibility in modern ML driven solutions to such\nproblems. FloorSet is available as an open-source repository for the research\ncommunity.\n","authors":["Uday Mallappa","Hesham Mostafa","Mikhail Galkin","Mariano Phielipp","Somdeb Majumdar"],"pdf_url":"https://arxiv.org/pdf/2405.05480v2.pdf","comment":"10 pages, 11 figures"}],"Robotics":[{"id":"http://arxiv.org/abs/2406.20095v1","updated":"2024-06-28T17:59:12Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Large Language Models (LLMs) equipped with extensive world knowledge and\nstrong reasoning skills can tackle diverse tasks across domains, often by\nposing them as conversation-style instruction-response pairs. In this paper, we\npropose LLaRA: Large Language and Robotics Assistant, a framework which\nformulates robot action policy as conversations, and provides improved\nresponses when trained with auxiliary data that complements policy learning.\nLLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity\nto process state information as visual-textual prompts and generate optimal\npolicy decisions in text. To train such action policy VLMs, we first introduce\nan automated pipeline to generate diverse high-quality robotics instruction\ndata from existing behavior cloning data. A VLM finetuned with the resulting\ncollection of datasets based on a conversation-style formulation tailored for\nrobotics tasks, can generate meaningful robot action policy decisions. Our\nexperiments across multiple simulated and real-world environments demonstrate\nthe state-of-the-art performance of the proposed LLaRA framework. The code,\ndatasets, and pretrained models are available at\nhttps://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20083v1","updated":"2024-06-28T17:51:10Z","published":"2024-06-28T17:51:10Z","title":"PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful\n  Navigators","summary":"  We present PoliFormer (Policy Transformer), an RGB-only indoor navigation\nagent trained end-to-end with reinforcement learning at scale that generalizes\nto the real-world without adaptation despite being trained purely in\nsimulation. PoliFormer uses a foundational vision transformer encoder with a\ncausal transformer decoder enabling long-term memory and reasoning. It is\ntrained for hundreds of millions of interactions across diverse environments,\nleveraging parallelized, multi-machine rollouts for efficient training with\nhigh throughput. PoliFormer is a masterful navigator, producing\nstate-of-the-art results across two distinct embodiments, the LoCoBot and\nStretch RE-1 robots, and four navigation benchmarks. It breaks through the\nplateaus of previous work, achieving an unprecedented 85.5% success rate in\nobject goal navigation on the CHORES-S benchmark, a 28.5% absolute improvement.\nPoliFormer can also be trivially extended to a variety of downstream\napplications such as object tracking, multi-object navigation, and\nopen-vocabulary navigation with no finetuning.\n","authors":["Kuo-Hao Zeng","Zichen Zhang","Kiana Ehsani","Rose Hendrix","Jordi Salvador","Alvaro Herrasti","Ross Girshick","Aniruddha Kembhavi","Luca Weihs"],"pdf_url":"https://arxiv.org/pdf/2406.20083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20061v1","updated":"2024-06-28T17:17:04Z","published":"2024-06-28T17:17:04Z","title":"Modeling and LQR Control of Insect Sized Flapping Wing Robot","summary":"  Flying insects can perform rapid, sophisticated maneuvers like backflips,\nsharp banked turns, and in-flight collision recovery. To emulate these in\naerial robots weighing less than a gram, known as flying insect robots (FIRs),\na fast and responsive control system is essential. To date, these have largely\nbeen, at their core, elaborations of proportional-integral-derivative\n(PID)-type feedback control. Without exception, their gains have been\npainstakingly tuned by hand. Aggressive maneuvers have further required\ntask-specific tuning. Optimal control has the potential to mitigate these\nissues, but has to date only been demonstrated using approxiate models and\nreceding horizon controllers (RHC) that are too computationally demanding to be\ncarried out onboard the robot. Here we used a more accurate stroke-averaged\nmodel of forces and torques to implement the first demonstration of optimal\ncontrol on an FIR that is computationally efficient enough to be performed by a\nmicroprocessor carried onboard. We took force and torque measurements from a\n150 mg FIR, the UW Robofly, using a custom-built sensitive force-torque sensor,\nand validated them using motion capture data in free flight. We demonstrated\nstable hovering (RMS error of about 4 cm) and trajectory tracking maneuvers at\ntranslational velocities up to 25 cm/s using an optimal linear quadratic\nregulator (LQR). These results were enabled by a more accurate model and lay\nthe foundation for future work that uses our improved model and optimal\ncontroller in conjunction with recent advances in low-power receding horizon\ncontrol to perform accurate aggressive maneuvers without iterative,\ntask-specific tuning.\n","authors":["Daksh Dhingra","Kadierdan Kaheman","Sawyer B. Fuller"],"pdf_url":"https://arxiv.org/pdf/2406.20061v1.pdf","comment":"The video of the results can be accessed using\n  www.youtube.com/watch?v=0o7j1nS2KHA"},{"id":"http://arxiv.org/abs/2402.11658v2","updated":"2024-06-28T15:16:53Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behavior could be explained in terms of an active\ninferential process - either as discrete decision-making or continuous motor\ncontrol - inspiring innovative solutions in robotics and artificial\nintelligence. Still, the literature lacks a comprehensive outlook on how to\neffectively plan actions in changing environments. Setting ourselves the goal\nof modeling tool use, we delve into the topic of dynamic planning in active\ninference, keeping in mind two crucial aspects of biological goal-directed\nbehavior: the capacity to understand and exploit affordances for object\nmanipulation, and to learn the hierarchical interactions between the self and\nthe environment, including other agents. We start from a simple unit and\ngradually describe more advanced structures, comparing recently proposed design\nchoices and providing basic examples for each section. This study distances\nitself from traditional views centered on neural networks and reinforcement\nlearning, and points toward a yet unexplored direction in active inference:\nhybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19972v1","updated":"2024-06-28T15:00:46Z","published":"2024-06-28T15:00:46Z","title":"HumanVLA: Towards Vision-Language Directed Object Rearrangement by\n  Physical Humanoid","summary":"  Physical Human-Scene Interaction (HSI) plays a crucial role in numerous\napplications.\n  However, existing HSI techniques are limited to specific object dynamics and\nprivileged information, which prevents the development of more comprehensive\napplications.\n  To address this limitation, we introduce HumanVLA for general object\nrearrangement directed by practical vision and language.\n  A teacher-student framework is utilized to develop HumanVLA.\n  A state-based teacher policy is trained first using goal-conditioned\nreinforcement learning and adversarial motion prior.\n  Then, it is distilled into a vision-language-action model via behavior\ncloning.\n  We propose several key insights to facilitate the large-scale learning\nprocess.\n  To support general object rearrangement by physical humanoid, we introduce a\nnovel Human-in-the-Room dataset encompassing various rearrangement tasks.\n  Through extensive experiments and analysis, we demonstrate the effectiveness\nof the proposed approach.\n","authors":["Xinyu Xu","Yizheng Zhang","Yong-Lu Li","Lei Han","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2406.19972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19971v1","updated":"2024-06-28T15:00:16Z","published":"2024-06-28T15:00:16Z","title":"Perception Stitching: Zero-Shot Perception Encoder Transfer for\n  Visuomotor Robot Policies","summary":"  Vision-based imitation learning has shown promising capabilities of endowing\nrobots with various motion skills given visual observation. However, current\nvisuomotor policies fail to adapt to drastic changes in their visual\nobservations. We present Perception Stitching that enables strong zero-shot\nadaptation to large visual changes by directly stitching novel combinations of\nvisual encoders. Our key idea is to enforce modularity of visual encoders by\naligning the latent visual features among different visuomotor policies. Our\nmethod disentangles the perceptual knowledge with the downstream motion skills\nand allows the reuse of the visual encoders by directly stitching them to a\npolicy network trained with partially different visual conditions. We evaluate\nour method in various simulated and real-world manipulation tasks. While\nbaseline methods failed at all attempts, our method could achieve zero-shot\nsuccess in real-world visuomotor tasks. Our quantitative and qualitative\nanalysis of the learned features of the policy network provides more insights\ninto the high performance of our proposed method.\n","authors":["Pingcheng Jian","Easop Lee","Zachary Bell","Michael M. Zavlanos","Boyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19963v1","updated":"2024-06-28T14:51:01Z","published":"2024-06-28T14:51:01Z","title":"Text2Robot: Evolutionary Robot Design from Text Descriptions","summary":"  Robot design has traditionally been costly and labor-intensive. Despite\nadvancements in automated processes, it remains challenging to navigate a vast\ndesign space while producing physically manufacturable robots. We introduce\nText2Robot, a framework that converts user text specifications and performance\npreferences into physical quadrupedal robots. Within minutes, Text2Robot can\nuse text-to-3D models to provide strong initializations of diverse\nmorphologies. Within a day, our geometric processing algorithms and\nbody-control co-optimization produce a walking robot by explicitly considering\nreal-world electronics and manufacturability. Text2Robot enables rapid\nprototyping and opens new opportunities for robot design with generative\nmodels.\n","authors":["Ryan P. Ringel","Zachary S. Charlick","Jiaxun Liu","Boxi Xia","Boyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19963v1.pdf","comment":"Our project website is at: https://generalroboticslab.com/Text2Robot"},{"id":"http://arxiv.org/abs/2312.00592v2","updated":"2024-06-28T14:02:06Z","published":"2023-12-01T13:56:28Z","title":"Tracking Object Positions in Reinforcement Learning: A Metric for\n  Keypoint Detection (extended version)","summary":"  Reinforcement learning (RL) for robot control typically requires a detailed\nrepresentation of the environment state, including information about\ntask-relevant objects not directly measurable. Keypoint detectors, such as\nspatial autoencoders (SAEs), are a common approach to extracting a\nlow-dimensional representation from high-dimensional image data. SAEs aim at\nspatial features such as object positions, which are often useful\nrepresentations in robotic RL. However, whether an SAE is actually able to\ntrack objects in the scene and thus yields a spatial state representation well\nsuited for RL tasks has rarely been examined due to a lack of established\nmetrics. In this paper, we propose to assess the performance of an SAE instance\nby measuring how well keypoints track ground truth objects in images. We\npresent a computationally lightweight metric and use it to evaluate common\nbaseline SAE architectures on image data from a simulated robot task. We find\nthat common SAEs differ substantially in their spatial extraction capability.\nFurthermore, we validate that SAEs that perform well in our metric achieve\nsuperior performance when used in downstream RL. Thus, our metric is an\neffective and lightweight indicator of RL performance before executing\nexpensive RL training. Building on these insights, we identify three key\nmodifications of SAE architectures to improve tracking performance. We make our\ncode available at anonymous.4open.science/r/sae-rl.\n","authors":["Emma Cramer","Jonas Reiher","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2312.00592v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.19930v1","updated":"2024-06-28T13:57:51Z","published":"2024-06-28T13:57:51Z","title":"Exploring 6G Potential for Industrial Digital Twinning and Swarm\n  Intelligence in Obstacle-Rich","summary":"  With the advent of 6G technology, the demand for efficient and intelligent\nsystems in industrial applications has surged, driving the need for advanced\nsolutions in target localization. Utilizing swarm robots to locate unknown\ntargets involves navigating increasingly complex environments. Digital Twinning\n(DT) offers a robust solution by creating a virtual replica of the physical\nworld, which enhances the swarm's navigation capabilities. Our framework\nleverages DT and integrates Swarm Intelligence to store physical map\ninformation in the cloud, enabling robots to efficiently locate unknown\ntargets. The simulation results demonstrate that the DT framework, augmented by\nSwarm Intelligence, significantly improves target location efficiency in\nobstacle-rich environments compared to traditional methods. This research\nunderscores the potential of combining DT and Swarm Intelligence to advance the\nfield of robotic navigation and target localization in complex industrial\nsettings.\n","authors":["Siyu Yuan","Khurshid Alam","Bin Han","Dennis Krummacker","Hans D. Schotten"],"pdf_url":"https://arxiv.org/pdf/2406.19930v1.pdf","comment":"Submitted to IEEE VTM"},{"id":"http://arxiv.org/abs/2404.18383v2","updated":"2024-06-28T13:10:02Z","published":"2024-04-29T02:42:02Z","title":"A Framework for Learning and Reusing Robotic Skills","summary":"  In this paper, we present our work in progress towards creating a library of\nmotion primitives. This library facilitates easier and more intuitive learning\nand reusing of robotic skills. Users can teach robots complex skills through\nLearning from Demonstration, which is automatically segmented into primitives\nand stored in clusters of similar skills. We propose a novel multimodal\nsegmentation method as well as a novel trajectory clustering method. Then, when\nneeded for reuse, we transform primitives into new environments using\ntrajectory editing. We present simulated results for our framework with\ndemonstrations taken on real-world robots.\n","authors":["Brendan Hertel","Nhu Tran","Meriem Elkoudi","Reza Azadeh"],"pdf_url":"https://arxiv.org/pdf/2404.18383v2.pdf","comment":"4 pages, 4 figures. Accepted for publication as work-in-progress\n  paper at Ubiquitous Robots (UR) 2024. Code available here:\n  https://github.com/brenhertel/Probabilistic-Segmentation and here:\n  https://github.com/brenhertel/Elastic-Clustering"},{"id":"http://arxiv.org/abs/2406.19893v1","updated":"2024-06-28T13:00:44Z","published":"2024-06-28T13:00:44Z","title":"Learning Human-Robot Handshaking Preferences for Quadruped Robots","summary":"  Quadruped robots are showing impressive abilities to navigate the real world.\nIf they are to become more integrated into society, social trust in\ninteractions with humans will become increasingly important. Additionally,\nrobots will need to be adaptable to different humans based on individual\npreferences. In this work, we study the social interaction task of learning\noptimal handshakes for quadruped robots based on user preferences. While\nmaintaining balance on three legs, we parameterize handshakes with a Central\nPattern Generator consisting of an amplitude, frequency, stiffness, and\nduration. Through 10 binary choices between handshakes, we learn a belief model\nto fit individual preferences for 25 different subjects. Our results show that\nthis is an effective strategy, with 76% of users feeling happy with their\nidentified optimal handshake parameters, and 20% feeling neutral. Moreover,\ncompared with random and test handshakes, the optimized handshakes have\nsignificantly decreased errors in amplitude and frequency, lower Dynamic Time\nWarping scores, and improved energy efficiency, all of which indicate robot\nsynchronization to the user's preferences. Video results can be found at\nhttps://youtu.be/elvPv8mq1KM .\n","authors":["Alessandra Chappuis","Guillaume Bellegarda","Auke Ijspeert"],"pdf_url":"https://arxiv.org/pdf/2406.19893v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN)"},{"id":"http://arxiv.org/abs/2305.03091v3","updated":"2024-06-28T12:59:46Z","published":"2023-05-04T18:13:59Z","title":"Confidence-Based Skill Reproduction Through Perturbation Analysis","summary":"  Several methods exist for teaching robots, with one of the most prominent\nbeing Learning from Demonstration (LfD). Many LfD representations can be\nformulated as constrained optimization problems. We propose a novel convex\nformulation of the LfD problem represented as elastic maps, which models\nreproductions as a series of connected springs. Relying on the properties of\nstrong duality and perturbation analysis of the constrained optimization\nproblem, we create a confidence metric. Our method allows the demonstrated\nskill to be reproduced with varying confidence level yielding different levels\nof smoothness and flexibility. Our confidence-based method provides\nreproductions of the skill that perform better for a given set of constraints.\nBy analyzing the constraints, our method can also remove unnecessary\nconstraints. We validate our approach using several simulated and real-world\nexperiments using a Jaco2 7DOF manipulator arm.\n","authors":["Brendan Hertel","S. Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2305.03091v3.pdf","comment":"7 pages, 5 figures. Accepted to UR 2023. Code available at\n  https://github.com/brenhertel/LfD-Perturbations Accompanying video at:\n  https://youtu.be/IQDxbhEiNbk"},{"id":"http://arxiv.org/abs/2208.02207v2","updated":"2024-06-28T12:57:27Z","published":"2022-08-03T16:42:07Z","title":"Robot Learning from Demonstration Using Elastic Maps","summary":"  Learning from Demonstration (LfD) is a popular method of reproducing and\ngeneralizing robot skills from human-provided demonstrations. In this paper, we\npropose a novel optimization-based LfD method that encodes demonstrations as\nelastic maps. An elastic map is a graph of nodes connected through a mesh of\nsprings. We build a skill model by fitting an elastic map to the set of\ndemonstrations. The formulated optimization problem in our approach includes\nthree objectives with natural and physical interpretations. The main term\nrewards the mean squared error in the Cartesian coordinate. The second term\npenalizes the non-equidistant distribution of points resulting in the optimum\ntotal length of the trajectory. The third term rewards smoothness while\npenalizing nonlinearity. These quadratic objectives form a convex problem that\ncan be solved efficiently with local optimizers. We examine nine methods for\nconstructing and weighting the elastic maps and study their performance in\nrobotic tasks. We also evaluate the proposed method in several simulated and\nreal-world experiments using a UR5e manipulator arm, and compare it to other\nLfD approaches to demonstrate its benefits and flexibility across a variety of\nmetrics.\n","authors":["Brendan Hertel","Matthew Pelland","S. Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2208.02207v2.pdf","comment":"7 pages, 9 figures, 3 tables. Accepted to IROS 2022. Code available\n  at: https://github.com/brenhertel/ElMapTrajectories Accompanying video at:\n  https://youtu.be/rZgN9Pkw0tg"},{"id":"http://arxiv.org/abs/2111.07438v2","updated":"2024-06-28T12:50:45Z","published":"2021-11-14T20:33:01Z","title":"Methods for Combining and Representing Non-Contextual Autonomy Scores\n  for Unmanned Aerial Systems","summary":"  Measuring an overall autonomy score for a robotic system requires the\ncombination of a set of relevant aspects and features of the system that might\nbe measured in different units, qualitative, and/or discordant. In this paper,\nwe build upon an existing non-contextual autonomy framework that measures and\ncombines the Autonomy Level and the Component Performance of a system as\noverall autonomy score. We examine several methods of combining features,\nshowing how some methods find different rankings of the same data, and we\nemploy the weighted product method to resolve this issue. Furthermore, we\nintroduce the non-contextual autonomy coordinate and represent the overall\nautonomy of a system with an autonomy distance. We apply our method to a set of\nseven Unmanned Aerial Systems (UAS) and obtain their absolute autonomy score as\nwell as their relative score with respect to the best system.\n","authors":["Brendan Hertel","Ryan Donald","Christian Dumas","S. Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2111.07438v2.pdf","comment":"8 pages, 2 figures, 6 tables"},{"id":"http://arxiv.org/abs/2110.14817v2","updated":"2024-06-28T12:47:52Z","published":"2021-10-28T00:00:24Z","title":"Similarity-Aware Skill Reproduction based on Multi-Representational\n  Learning from Demonstration","summary":"  Learning from Demonstration (LfD) algorithms enable humans to teach new\nskills to robots through demonstrations. The learned skills can be robustly\nreproduced from the identical or near boundary conditions (e.g., initial\npoint). However, when generalizing a learned skill over boundary conditions\nwith higher variance, the similarity of the reproductions changes from one\nboundary condition to another, and a single LfD representation cannot preserve\na consistent similarity across a generalization region. We propose a novel\nsimilarity-aware framework including multiple LfD representations and a\nsimilarity metric that can improve skill generalization by finding\nreproductions with the highest similarity values for a given boundary\ncondition. Given a demonstration of the skill, our framework constructs a\nsimilarity region around a point of interest (e.g., initial point) by\nevaluating individual LfD representations using the similarity metric. Any\npoint within this volume corresponds to a representation that reproduces the\nskill with the greatest similarity. We validate our multi-representational\nframework in three simulated and four sets of real-world experiments using a\nphysical 6-DOF robot. We also evaluate 11 different similarity metrics and\ncategorize them according to their biases in 286 simulated experiments.\n","authors":["Brendan Hertel","S. Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2110.14817v2.pdf","comment":"6 pages, 7 figures. Accepted to ICAR 2021. Code available at:\n  https://github.com/brenhertel/SAMLfD, Accompanying video at:\n  https://youtu.be/LZW3MWrNFSI"},{"id":"http://arxiv.org/abs/2107.11918v2","updated":"2024-06-28T12:38:47Z","published":"2021-07-26T01:03:49Z","title":"Learning from Successful and Failed Demonstrations via Optimization","summary":"  Learning from Demonstration (LfD) is a popular approach that allows humans to\nteach robots new skills by showing the correct way(s) of performing the desired\nskill. Human-provided demonstrations, however, are not always optimal and the\nteacher usually addresses this issue by discarding or replacing sub-optimal\n(noisy or faulty) demonstrations. We propose a novel LfD representation that\nlearns from both successful and failed demonstrations of a skill. Our approach\nencodes the two subsets of captured demonstrations (labeled by the teacher)\ninto a statistical skill model, constructs a set of quadratic costs, and finds\nan optimal reproduction of the skill under novel problem conditions (i.e.\nconstraints). The optimal reproduction balances convergence towards successful\nexamples and divergence from failed examples. We evaluate our approach through\nseveral 2D and 3D experiments in real-world using a UR5e manipulator arm and\nalso show that it can reproduce a skill from only failed demonstrations. The\nbenefits of exploiting both failed and successful demonstrations are shown\nthrough comparison with two existing LfD approaches. We also compare our\napproach against an existing skill refinement method and show its capabilities\nin a multi-coordinate setting.\n","authors":["Brendan Hertel","S. Reza Ahmadzadeh"],"pdf_url":"https://arxiv.org/pdf/2107.11918v2.pdf","comment":"6 pages, 7 figures. Accepted to IROS 2021. Code available at\n  https://github.com/brenhertel/TLFSD Accompanying video at:\n  https://youtu.be/sRdOm_9nJ8g"},{"id":"http://arxiv.org/abs/2406.19848v1","updated":"2024-06-28T11:43:05Z","published":"2024-06-28T11:43:05Z","title":"3D Operation of Autonomous Excavator based on Reinforcement Learning\n  through Independent Reward for Individual Joints","summary":"  In this paper, we propose a control algorithm based on reinforcement\nlearning, employing independent rewards for each joint to control excavators in\na 3D space. The aim of this research is to address the challenges associated\nwith achieving precise control of excavators, which are extensively utilized in\nconstruction sites but prove challenging to control with precision due to their\nhydraulic structures. Traditional methods relied on operator expertise for\nprecise excavator operation, occasionally resulting in safety accidents.\nTherefore, there have been endeavors to attain precise excavator control\nthrough equation-based control algorithms. However, these methods had the\nlimitation of necessitating prior information related to physical values of the\nexcavator, rendering them unsuitable for the diverse range of excavators used\nin the field. To overcome these limitations, we have explored reinforcement\nlearning-based control methods that do not demand prior knowledge of specific\nequipment but instead utilize data to train models. Nevertheless, existing\nreinforcement learning-based methods overlooked cabin swing rotation and\nconfined the bucket's workspace to a 2D plane. Control confined within such a\nlimited area diminishes the applicability of the algorithm in construction\nsites. We address this issue by expanding the previous 2D plane workspace of\nthe bucket operation into a 3D space, incorporating cabin swing rotation. By\nexpanding the workspace into 3D, excavators can execute continuous operations\nwithout requiring human intervention. To accomplish this objective, distinct\ntargets were established for each joint, facilitating the training of action\nvalues for each joint independently, regardless of the progress of other joint\nlearning.\n","authors":["Yoonkyu Yoo","Donghwi Jung","Seong-Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2406.19848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19844v1","updated":"2024-06-28T11:35:35Z","published":"2024-06-28T11:35:35Z","title":"StreamMOTP: Streaming and Unified Framework for Joint 3D Multi-Object\n  Tracking and Trajectory Prediction","summary":"  3D multi-object tracking and trajectory prediction are two crucial modules in\nautonomous driving systems. Generally, the two tasks are handled separately in\ntraditional paradigms and a few methods have started to explore modeling these\ntwo tasks in a joint manner recently. However, these approaches suffer from the\nlimitations of single-frame training and inconsistent coordinate\nrepresentations between tracking and prediction tasks. In this paper, we\npropose a streaming and unified framework for joint 3D Multi-Object Tracking\nand trajectory Prediction (StreamMOTP) to address the above challenges.\nFirstly, we construct the model in a streaming manner and exploit a memory bank\nto preserve and leverage the long-term latent features for tracked objects more\neffectively. Secondly, a relative spatio-temporal positional encoding strategy\nis introduced to bridge the gap of coordinate representations between the two\ntasks and maintain the pose-invariance for trajectory prediction. Thirdly, we\nfurther improve the quality and consistency of predicted trajectories with a\ndual-stream predictor. We conduct extensive experiments on popular nuSences\ndataset and the experimental results demonstrate the effectiveness and\nsuperiority of StreamMOTP, which outperforms previous methods significantly on\nboth tasks. Furthermore, we also prove that the proposed framework has great\npotential and advantages in actual applications of autonomous driving.\n","authors":["Jiaheng Zhuang","Guoan Wang","Siyu Zhang","Xiyang Wang","Hangning Zhou","Ziyao Xu","Chi Zhang","Zhiheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.19844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14237v2","updated":"2024-06-28T11:34:56Z","published":"2023-09-25T15:54:32Z","title":"Hierarchical Reinforcement Learning Based on Planning Operators","summary":"  Long-horizon manipulation tasks such as stacking represent a longstanding\nchallenge in the field of robotic manipulation, particularly when using\nreinforcement learning (RL) methods which often struggle to learn the correct\nsequence of actions for achieving these complex goals. To learn this sequence,\nsymbolic planning methods offer a good solution based on high-level reasoning,\nhowever, planners often fall short in addressing the low-level control\nspecificity needed for precise execution. This paper introduces a novel\nframework that integrates symbolic planning with hierarchical RL through the\ncooperation of high-level operators and low-level policies. Our contribution\nintegrates planning operators (e.g. preconditions and effects) as part of the\nhierarchical RL algorithm based on the Scheduled Auxiliary Control (SAC-X)\nmethod. We developed a dual-purpose high-level operator, which can be used both\nin holistic planning and as independent, reusable policies. Our approach offers\na flexible solution for long-horizon tasks, e.g., stacking a cube. The\nexperimental results show that our proposed method obtained an average of 97.2%\nsuccess rate for learning and executing the whole stack sequence, and the\nsuccess rate for learning independent policies, e.g. reach (98.9%), lift\n(99.7%), stack (85%), etc. The training time is also reduced by 68% when using\nour proposed approach.\n","authors":["Jing Zhang","Emmanuel Dean","Karinne Ramirez-Amaro"],"pdf_url":"https://arxiv.org/pdf/2309.14237v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19800v1","updated":"2024-06-28T10:13:50Z","published":"2024-06-28T10:13:50Z","title":"Modeling the Real World with High-Density Visual Particle Dynamics","summary":"  We present High-Density Visual Particle Dynamics (HD-VPD), a learned world\nmodel that can emulate the physical dynamics of real scenes by processing\nmassive latent point clouds containing 100K+ particles. To enable efficiency at\nthis scale, we introduce a novel family of Point Cloud Transformers (PCTs)\ncalled Interlacers leveraging intertwined linear-attention Performer layers and\ngraph-based neighbour attention layers. We demonstrate the capabilities of\nHD-VPD by modeling the dynamics of high degree-of-freedom bi-manual robots with\ntwo RGB-D cameras. Compared to the previous graph neural network approach, our\nInterlacer dynamics is twice as fast with the same prediction quality, and can\nachieve higher quality using 4x as many particles. We illustrate how HD-VPD can\nevaluate motion plan quality with robotic box pushing and can grasping tasks.\nSee videos and particle dynamics rendered by HD-VPD at\nhttps://sites.google.com/view/hd-vpd.\n","authors":["William F. Whitney","Jacob Varley","Deepali Jain","Krzysztof Choromanski","Sumeet Singh","Vikas Sindhwani"],"pdf_url":"https://arxiv.org/pdf/2406.19800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19798v1","updated":"2024-06-28T10:12:34Z","published":"2024-06-28T10:12:34Z","title":"Integrating occlusion awareness in urban motion prediction for enhanced\n  autonomous vehicle navigation","summary":"  Motion prediction is a key factor towards the full deployment of autonomous\nvehicles. It is fundamental in order to ensure safety while navigating through\nhighly interactive and complex scenarios. Lack of visibility due to an\nobstructed view or sensor range poses a great safety issue for autonomous\nvehicles. The inclusion of occlusion in interaction-aware approaches is not\nvery well explored in the literature. In this work, the MultIAMP framework,\nwhich produces multimodal probabilistic outputs from the integration of a\nDynamic Bayesian Network and Markov chains, is extended to tackle occlusions.\nThe framework is evaluated with a state-of-the-art motion planner in two\nrealistic use cases.\n","authors":["Vinicius Trentin","Juan Medina-Lee","Antonio Artuñedo","Jorge Villagra"],"pdf_url":"https://arxiv.org/pdf/2406.19798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19791v1","updated":"2024-06-28T09:54:44Z","published":"2024-06-28T09:54:44Z","title":"Mobile Robot Oriented Large-Scale Indoor Dataset for Dynamic Scene\n  Understanding","summary":"  Most existing robotic datasets capture static scene data and thus are limited\nin evaluating robots' dynamic performance. To address this, we present a mobile\nrobot oriented large-scale indoor dataset, denoted as THUD (Tsinghua University\nDynamic) robotic dataset, for training and evaluating their dynamic scene\nunderstanding algorithms. Specifically, the THUD dataset construction is first\ndetailed, including organization, acquisition, and annotation methods. It\ncomprises both real-world and synthetic data, collected with a real robot\nplatform and a physical simulation platform, respectively. Our current dataset\nincludes 13 larges-scale dynamic scenarios, 90K image frames, 20M 2D/3D\nbounding boxes of static and dynamic objects, camera poses, and IMU. The\ndataset is still continuously expanding. Then, the performance of mainstream\nindoor scene understanding tasks, e.g. 3D object detection, semantic\nsegmentation, and robot relocalization, is evaluated on our THUD dataset. These\nexperiments reveal serious challenges for some robot scene understanding tasks\nin dynamic scenes. By sharing this dataset, we aim to foster and iterate new\nmobile robot algorithms quickly for robot actual working dynamic environment,\ni.e. complex crowded dynamic scenes.\n","authors":["Yifan Tang","Cong Tai","Fangxing Chen","Wanting Zhang","Tao Zhang","Xueping Liu","Yongjin Liu","Long Zeng"],"pdf_url":"https://arxiv.org/pdf/2406.19791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19781v1","updated":"2024-06-28T09:36:40Z","published":"2024-06-28T09:36:40Z","title":"LCSim: A Large-Scale Controllable Traffic Simulator","summary":"  With the rapid development of urban transportation and the continuous\nadvancement in autonomous vehicles, the demand for safely and efficiently\ntesting autonomous driving and traffic optimization algorithms arises, which\nneeds accurate modeling of large-scale urban traffic scenarios. Existing\ntraffic simulation systems encounter two significant limitations. Firstly, they\noften rely on open-source datasets or manually crafted maps, constraining the\nscale of simulations. Secondly, vehicle models within these systems tend to be\neither oversimplified or lack controllability, compromising the authenticity\nand diversity of the simulations. In this paper, we propose LCSim, a\nlarge-scale controllable traffic simulator. LCSim provides map tools for\nconstructing unified high-definition map (HD map) descriptions from open-source\ndatasets including Waymo and Argoverse or publicly available data sources like\nOpenStreetMap to scale up the simulation scenarios. Also, we integrate\ndiffusion-based traffic simulation into the simulator for realistic and\ncontrollable microscopic traffic flow modeling. By leveraging these features,\nLCSim provides realistic and diverse virtual traffic environments. Code and\nDemos are available at https://github.com/tsinghua-fib-lab/LCSim.\n","authors":["Yuheng Zhang","Tianjian Ouyang","Fudan Yu","Cong Ma","Lei Qiao","Wei Wu","Jian Yuan","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2406.19781v1.pdf","comment":"Submitted to the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2406.19741v1","updated":"2024-06-28T08:28:38Z","published":"2024-06-28T08:28:38Z","title":"ROS-LLM: A ROS framework for embodied AI with task feedback and\n  structured reasoning","summary":"  We present a framework for intuitive robot programming by non-experts,\nleveraging natural language prompts and contextual information from the Robot\nOperating System (ROS). Our system integrates large language models (LLMs),\nenabling non-experts to articulate task requirements to the system through a\nchat interface. Key features of the framework include: integration of ROS with\nan AI agent connected to a plethora of open-source and commercial LLMs,\nautomatic extraction of a behavior from the LLM output and execution of ROS\nactions/services, support for three behavior modes (sequence, behavior tree,\nstate machine), imitation learning for adding new robot actions to the library\nof possible actions, and LLM reflection via human and environment feedback.\nExtensive experiments validate the framework, showcasing robustness,\nscalability, and versatility in diverse scenarios, including long-horizon\ntasks, tabletop rearrangements, and remote supervisory control. To facilitate\nthe adoption of our framework and support the reproduction of our results, we\nhave made our code open-source. You can access it at:\nhttps://github.com/huawei-noah/HEBO/tree/master/ROSLLM.\n","authors":["Christopher E. Mower","Yuhui Wan","Hongzhan Yu","Antoine Grosnit","Jonas Gonzalez-Billandon","Matthieu Zimmer","Jinlong Wang","Xinyu Zhang","Yao Zhao","Anbang Zhai","Puze Liu","Davide Tateo","Cesar Cadena","Marco Hutter","Jan Peters","Guangjian Tian","Yuzheng Zhuang","Kun Shao","Xingyue Quan","Jianye Hao","Jun Wang","Haitham Bou-Ammar"],"pdf_url":"https://arxiv.org/pdf/2406.19741v1.pdf","comment":"This document contains 26 pages and 13 figures"},{"id":"http://arxiv.org/abs/2406.19693v1","updated":"2024-06-28T07:09:06Z","published":"2024-06-28T07:09:06Z","title":"MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?","summary":"  It is fundamentally challenging for robots to serve as useful assistants in\nhuman environments because this requires addressing a spectrum of sub-problems\nacross robotics, including perception, language understanding, reasoning, and\nplanning. The recent advancements in Multimodal Large Language Models (MLLMs)\nhave demonstrated their exceptional abilities in solving complex mathematical\nproblems, mastering commonsense and abstract reasoning. This has led to the\nrecent utilization of MLLMs as the brain in robotic systems, enabling these\nmodels to conduct high-level planning prior to triggering low-level control\nactions for task execution. However, it remains uncertain whether existing\nMLLMs are reliable in serving the brain role of robots. In this study, we\nintroduce the first benchmark for evaluating Multimodal LLM for Robotic (MMRo)\nbenchmark, which tests the capability of MLLMs for robot applications.\nSpecifically, we identify four essential capabilities perception, task\nplanning, visual reasoning, and safety measurement that MLLMs must possess to\nqualify as the robot's central processing unit. We have developed several\nscenarios for each capability, resulting in a total of 14 metrics for\nevaluation. We present experimental results for various MLLMs, including both\ncommercial and open-source models, to assess the performance of existing\nsystems. Our findings indicate that no single model excels in all areas,\nsuggesting that current MLLMs are not yet trustworthy enough to serve as the\ncognitive core for robots. Our data can be found in\nhttps://mm-robobench.github.io/.\n","authors":["Jinming Li","Yichen Zhu","Zhiyuan Xu","Jindong Gu","Minjie Zhu","Xin Liu","Ning Liu","Yaxin Peng","Feifei Feng","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2406.19693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19678v1","updated":"2024-06-28T06:31:26Z","published":"2024-06-28T06:31:26Z","title":"UltraGelBot: Autonomous Gel Dispenser for Robotic Ultrasound","summary":"  Telerobotic and Autonomous Robotic Ultrasound Systems (RUS) help alleviate\nthe need for operator-dependability in free-hand ultrasound examinations.\nHowever, the state-of-the-art RUSs still rely on a human operator to apply the\nultrasound gel. The lack of standardization in this process often leads to poor\nimaging of the scanned region. The reason for this has to do with air-gaps\nbetween the probe and the human body. In this paper, we developed a end-of-arm\ntool for RUS, referred to as UltraGelBot. This bot can autonomously detect and\ndispense the gel. It uses a deep learning model to detect the gel from images\nacquired using an on-board camera. A motorized mechanism is also developed,\nwhich will use this feedback and dispense the gel. Experiments on phantom\nrevealed that UltraGelBot increases the acquired image quality by $18.6\\%$ and\nreduces the procedure time by $37.2\\%$.\n","authors":["Deepak Raina","Ziming Zhao","Richard Voyles","Juan Wachs","Subir K. Saha","S. H. Chandrashekhara"],"pdf_url":"https://arxiv.org/pdf/2406.19678v1.pdf","comment":"2024 16th Hamlyn Symposium on Medical Robotics (HSMR)"},{"id":"http://arxiv.org/abs/2405.05702v6","updated":"2024-06-28T06:23:27Z","published":"2024-05-09T11:57:42Z","title":"NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap","summary":"  SLAM systems based on Gaussian Splatting have garnered attention due to their\ncapabilities for rapid real-time rendering and high-fidelity mapping. However,\ncurrent Gaussian Splatting SLAM systems usually struggle with large scene\nrepresentation and lack effective loop closure detection. To address these\nissues, we introduce NGM-SLAM, the first 3DGS based SLAM system that utilizes\nneural radiance field submaps for progressive scene expression, effectively\nintegrating the strengths of neural radiance fields and 3D Gaussian Splatting.\nWe utilize neural radiance field submaps as supervision and achieve\nhigh-quality scene expression and online loop closure adjustments through\nGaussian rendering of fused submaps. Our results on multiple real-world scenes\nand large-scale scene datasets demonstrate that our method can achieve accurate\nhole filling and high-quality scene expression, supporting monocular, stereo,\nand RGB-D inputs, and achieving state-of-the-art scene reconstruction and\ntracking performance.\n","authors":["Mingrui Li","Jingwei Huang","Lei Sun","Aaron Xuxiang Tian","Tianchen Deng","Hongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2405.05702v6.pdf","comment":"9pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.19646v1","updated":"2024-06-28T04:21:40Z","published":"2024-06-28T04:21:40Z","title":"Time-optimal Flight in Cluttered Environments via Safe Reinforcement\n  Learning","summary":"  This paper addresses the problem of guiding a quadrotor through a predefined\nsequence of waypoints in cluttered environments, aiming to minimize the flight\ntime while avoiding collisions. Previous approaches either suffer from\nprolonged computational time caused by solving complex non-convex optimization\nproblems or are limited by the inherent smoothness of polynomial trajectory\nrepresentations, thereby restricting the flexibility of movement. In this work,\nwe present a safe reinforcement learning approach for autonomous drone racing\nwith time-optimal flight in cluttered environments. The reinforcement learning\npolicy, trained using safety and terminal rewards specifically designed to\nenforce near time-optimal and collision-free flight, outperforms current\nstate-of-the-art algorithms. Additionally, experimental results demonstrate the\nefficacy of the proposed approach in achieving both minimum flight time and\nobstacle avoidance objectives in complex environments, with a commendable\n$66.7\\%$ success rate in unseen, challenging settings.\n","authors":["Wei Xiao","Zhaohan Feng","Ziyu Zhou","Jian Sun","Gang Wang","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2406.19646v1.pdf","comment":"7 pages, 3 figures,"},{"id":"http://arxiv.org/abs/2403.03181v2","updated":"2024-06-28T04:15:33Z","published":"2024-03-05T18:19:29Z","title":"Behavior Generation with Latent Actions","summary":"  Generative modeling of complex behaviors from labeled datasets has been a\nlongstanding problem in decision making. Unlike language or image generation,\ndecision making requires modeling actions - continuous-valued vectors that are\nmultimodal in their distribution, potentially drawn from uncurated sources,\nwhere generation errors can compound in sequential prediction. A recent class\nof models called Behavior Transformers (BeT) addresses this by discretizing\nactions using k-means clustering to capture different modes. However, k-means\nstruggles to scale for high-dimensional action spaces or long sequences, and\nlacks gradient information, and thus BeT suffers in modeling long-range\nactions. In this work, we present Vector-Quantized Behavior Transformer\n(VQ-BeT), a versatile model for behavior generation that handles multimodal\naction prediction, conditional generation, and partial observations. VQ-BeT\naugments BeT by tokenizing continuous actions with a hierarchical vector\nquantization module. Across seven environments including simulated\nmanipulation, autonomous driving, and robotics, VQ-BeT improves on\nstate-of-the-art models such as BeT and Diffusion Policies. Importantly, we\ndemonstrate VQ-BeT's improved ability to capture behavior modes while\naccelerating inference speed 5x over Diffusion Policies. Videos and code can be\nfound https://sjlee.cc/vq-bet\n","authors":["Seungjae Lee","Yibin Wang","Haritheja Etukuru","H. Jin Kim","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2403.03181v2.pdf","comment":"Github repo: https://github.com/jayLEE0301/vq_bet_official"},{"id":"http://arxiv.org/abs/2406.19634v1","updated":"2024-06-28T03:45:51Z","published":"2024-06-28T03:45:51Z","title":"CLOi-Mapper: Consistent, Lightweight, Robust, and Incremental Mapper\n  With Embedded Systems for Commercial Robot Services","summary":"  In commercial autonomous service robots with several form factors,\nsimultaneous localization and mapping (SLAM) is an essential technology for\nproviding proper services such as cleaning and guidance. Such robots require\nSLAM algorithms suitable for specific applications and environments. Hence,\nseveral SLAM frameworks have been proposed to address various requirements in\nthe past decade. However, we have encountered challenges in implementing recent\ninnovative frameworks when handling service robots with low-end processors and\ninsufficient sensor data, such as low-resolution 2D LiDAR sensors.\nSpecifically, regarding commercial robots, consistent performance in different\nhardware configurations and environments is more crucial than the performance\ndedicated to specific sensors or environments. Therefore, we propose a) a\nmulti-stage %hierarchical approach for global pose estimation in embedded\nsystems; b) a graph generation method with zero constraints for synchronized\nsensors; and c) a robust and memory-efficient method for long-term pose-graph\noptimization. As verified in in-home and large-scale indoor environments, the\nproposed method yields consistent global pose estimation for services in\ncommercial fields. Furthermore, the proposed method exhibits potential\ncommercial viability considering the consistent performance verified via mass\nproduction and long-term (> 5 years) operation.\n","authors":["DongKi Noh","Hyungtae Lim","Gyuho Eoh","Duckyu Choi","Jeongsik Choi","Hyunjun Lim","SeungMin Baek","Hyun Myung"],"pdf_url":"https://arxiv.org/pdf/2406.19634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00808v2","updated":"2024-06-28T02:16:13Z","published":"2024-02-01T17:44:46Z","title":"Exploring the Dynamics between Cobot's Production Rhythm, Locus of\n  Control and Emotional State in a Collaborative Assembly Scenario","summary":"  In industrial scenarios, there is widespread use of collaborative robots\n(cobots), and growing interest is directed at evaluating and measuring the\nimpact of some characteristics of the cobot on the human factor. In the present\npilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 -\nAdapted to the participant's pace) of a cobot has on the Experiential Locus of\nControl (ELoC) and the emotional state of 31 participants has been examined.\nThe operators' performance, the degree of basic internal Locus of Control, and\nthe attitude towards the robots were also considered. No difference was found\nregarding the emotional state and the ELoC in the three conditions, but\nconsidering the other psychological variables, a more complex situation\nemerges. Overall, results seem to indicate a need to consider the person's\npsychological characteristics to offer a differentiated and optimal interaction\nexperience.\n","authors":["Marta Mondellini","Matteo Lavit Nicora","Pooja Prajod","Elisabeth André","Rocco Vertechy","Alessandro Antonietti","Matteo Malosio"],"pdf_url":"https://arxiv.org/pdf/2402.00808v2.pdf","comment":"Accepted to 4th IEEE International Conference on Human-Machine\n  Systems"},{"id":"http://arxiv.org/abs/2406.18915v2","updated":"2024-06-28T02:13:22Z","published":"2024-06-27T06:12:01Z","title":"Manipulate-Anything: Automating Real-World Robots using Vision-Language\n  Models","summary":"  Large-scale endeavors like RT-1 and widespread community efforts such as\nOpen-X-Embodiment have contributed to growing the scale of robot demonstration\ndata. However, there is still an opportunity to improve the quality, quantity,\nand diversity of robot demonstration data. Although vision-language models have\nbeen shown to automatically generate demonstration data, their utility has been\nlimited to environments with privileged state information, they require\nhand-designed skills, and are limited to interactions with few object\ninstances. We propose Manipulate-Anything, a scalable automated generation\nmethod for real-world robotic manipulation. Unlike prior work, our method can\noperate in real-world environments without any privileged state information,\nhand-designed skills, and can manipulate any static object. We evaluate our\nmethod using two setups. First, Manipulate-Anything successfully generates\ntrajectories for all 5 real-world and 12 simulation tasks, significantly\noutperforming existing methods like VoxPoser. Second, Manipulate-Anything's\ndemonstrations can train more robust behavior cloning policies than training\nwith human demonstrations, or from data generated by VoxPoser and\nCode-As-Policies. We believe Manipulate-Anything can be the scalable method for\nboth generating data for robotics and solving novel tasks in a zero-shot\nsetting.\n","authors":["Jiafei Duan","Wentao Yuan","Wilbert Pumacay","Yi Ru Wang","Kiana Ehsani","Dieter Fox","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.18915v2.pdf","comment":"Project page: https://robot-ma.github.io/"}]}}